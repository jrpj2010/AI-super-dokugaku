# Generative AI for Developers ‚Äì Comprehensive Course

**„ÉÅ„É£„É≥„Éç„É´:** freeCodeCamp.org
**ÂÖ¨ÈñãÊó•:** 2024-10-31
**URL:** https://www.youtube.com/watch?v=F0GQ0l2NfHA

## Ë™¨Êòé

In this comprehensive Generative AI course from @dswithbappy, you'll dive deep into the world of generative AI, exploring key concepts such as large language models, data preprocessing, and advanced techniques like fine-tuning and RAG. Through hands-on projects with tools like Hugging Face, OpenAI, and LangChain, you‚Äôll build real-world applications from text summarization to custom chatbots. By the end, you'll have mastered AI pipelines, vector databases, and deployment techniques using platforms like Google Cloud Vertex AI and AWS Bedrock.

üíª Code and resources: https://github.com/entbappy/Generative-AI-Mastery-Resources

Boktiar's other channel and LinkedIn:
https://www.youtube.com/@CodeCommander-d6t
https://www.linkedin.com/in/boktiarahmed73/

More courses: https://euron.one/

‚ù§Ô∏è Try interactive AI courses we love, right in your browser: https://scrimba.com/freeCodeCamp-AI (Made possible by a grant from our friends at Scrimba)

‚≠êÔ∏è Contents ‚≠êÔ∏è
0:00:00 Course Introduction
0:04:36 Introduction of the Instructor
0:05:52 Introduction to Generative AI
0:23:51 End to end Generative AI Pipeline
0:59:53 Data Preprocessing & cleaning
1:25:12 Data representation & vectorization for the model training
2:28:57 Text Classification Practical
2:42:05 Introduction to Large Language Models & its architecture
3:03:28 In depth intuition of Transformer-Attention all your need Paper
3:33:19 How ChatGPT is trained
3:43:44 Introduction of Hugging Face
3:56:02 Hands-On Hugging Face - Transformers, HF Pipeline, Datasets, LLMs
4:10:20 Data processing,Tokenizing and Feature Extraction with hugging face
4:17:34 Fine-tuning using a pretrain models
4:30:19 Hugging face API key generation
4:31:40 Project: Text summarization with hugging face
4:54:56 Project: Text to Image generation with LLM with hugging face
5:09:45 Project: Text to speech generation with LLM with hugging face
5:12:14 Introduction to OpenAI
5:21:12 How to generate OpenAI API key?
5:24:46 Local Environment Setup
5:27:13 Hands on OpenAI - ChatCompletion API and Completion API
5:54:44 Function Calling in OpenAI
6:09:11 Project: Telegram bot using OpenAI
6:44:18 Project: Finetuning of GPT-3 model for text classification
6:54:51 Project: Audio Transcript Translation with Whishper
7:12:54 Project: Image genration with DALL-E
7:18:22 Mastering Prompt Engineering
7:42:49 The Complete Introduction to Vector Databases
8:11:05 Mastering Vector Databases with ChromaDB
8:54:45 Mastering Vector Databases with Pinecone
9:19:39 Mastering Vector Databases with Weaviate
9:35:25 Introduction & Installation and setup of langchain
9:51:32 Prompt Templates in Langchain
9:55:33 Chains in Langchain
10:05:01 Langchain Agents and Tools
10:10:29 Memory in Langchain
10:17:41 Documents Loader in Langchain
10:21:25 Multi-Dataframe Agents in Langchain
10:25:50 How to use Hugging face Open Source LLM with Langchain
10:32:00 Project: Interview Questions Creator Application
11:29:26 Project: Custom Website Chatbot
11:46:21 Introduction to Open Source LLMs - Llama
12:20:39 How to use open source llms with Langchain
12:41:59 Custom Website Chatbot using Open source LLMs
13:12:41 Open Source LLMs - Falcon
13:29:11 Introduction & Importance of RAG 
13:34:43 RAG Practical demo
13:45:10 RAG Vs Fine-tuning
13:48:31 Build a Q&A App with RAG using Gemini Pro and Langchain
13:57:35 What is Fine Tuning? Parameter Efficient Fine-Tuning - LoRA & QLoRA
14:10:07 Fine-Tuning Meta Llama 2 on Custom Data
14:28:55 Introduction to LlamaIndex & end to end Demo
14:57:41 Open Source Mistral LLM with LlamaIndex
15:09:57 Project: Financial Stock Analysis using LlamaIndex
15:23:51 Project: End to End Medical Chatbot with LLM, Pinecone, LangChain 
16:34:38 Project: End to End Source Code Analysis with LangChain, LLM and ChromaDB
17:06:31 Project: Implementing Zomato chatbot with Chainlit
17:40:11 How to Deploy Generative AI Application as CICD on AWS
18:10:32 Introduction to LLMOps & Why we need it?
18:35:06 Generative AI with Google Cloud (Vertex AI) a LLMOps Platform
18:49:37 Vertex AI Hands-On on Google Cloud 
19:13:36 Vertex AI Local Setup - Run Gemini Pro on Local Machine
19:24:59 RAG on Vertex AI with Vector Search and Gemini Pro
19:41:06 LLM powered application on Vertex AI
19:44:57 Fine-tuning Foundation Model on VertexAI
19:57:51 Introduction to AWS Bedrock 
20:14:52 End to End RAG Project using AWS Bedrock

## Â≠óÂπï

[00:00 - 00:04]
in this comprehensive generative AI

[00:02 - 00:08]
course you'll dive deep into the world

[00:04 - 00:11]
of generative AI exploring key Concepts

[00:08 - 00:14]
such as large language models data

[00:11 - 00:17]
pre-processing and Advanced Techniques

[00:14 - 00:19]
like fine-tuning and rag through

[00:17 - 00:22]
Hands-On projects with tools like

[00:19 - 00:25]
hugging face open Ai and Lang chain

[00:22 - 00:28]
you'll build real world applications

[00:25 - 00:31]
from text summarization to custom

[00:28 - 00:33]
chatbots by the end you'll have mastered

[00:31 - 00:36]
AI pipelines Vector databases and

[00:33 - 00:39]
deployment techniques using platforms

[00:36 - 00:43]
like Google Cloud vertex Ai and AWS

[00:39 - 00:46]
Bedrock Baker Ahmed B created this

[00:43 - 00:49]
course JV is the most demandable skills

[00:46 - 00:51]
nowadays across Industries if you see

[00:49 - 00:54]
all the industries have started using

[00:51 - 00:55]
genv in their product development if you

[00:54 - 00:57]
want to level up your skill and if you

[00:55 - 00:58]
want to crack good job nowadays with a

[00:57 - 01:00]
good package definitely you should know

[00:58 - 01:03]
about genbi if you're looking for well

[01:00 - 01:05]
organized n2n complete genv course I

[01:03 - 01:06]
have a very much good news for you

[01:05 - 01:09]
recently I have published one amazing

[01:06 - 01:10]
n2n genv course so here I have covered

[01:09 - 01:12]
everything you need to know to master

[01:10 - 01:14]
the genbi this course will cover Basics

[01:12 - 01:16]
to Advanced concept of genv so here we

[01:14 - 01:18]
are not only going to focus on the

[01:16 - 01:21]
theoretical part we'll be also focusing

[01:18 - 01:22]
on the Practical implementation of genbi

[01:21 - 01:24]
we'll be exploring different different

[01:22 - 01:25]
kinds of large language model with that

[01:24 - 01:27]
we'll be creating different different

[01:25 - 01:29]
kinds of gen VI based application so let

[01:27 - 01:31]
me show you the course content of this

[01:29 - 01:32]
course so guys as you can see this is

[01:31 - 01:34]
the course content as I already told you

[01:32 - 01:36]
we'll be starting from very basics of

[01:34 - 01:38]
the Gen and we'll be covering till

[01:36 - 01:40]
Advanced part of the Gen so here we'll

[01:38 - 01:42]
be starting from uh introduction of the

[01:40 - 01:43]
Gen VI so if you're completely new to

[01:42 - 01:45]
this field no need to worry I'll cover

[01:43 - 01:46]
each and everything you need to know

[01:45 - 01:48]
about gen VI then we'll be learning

[01:46 - 01:50]
about data pre-processing and emitting

[01:48 - 01:52]
because going forward whenever you'll be

[01:50 - 01:54]
using large language model and to give

[01:52 - 01:55]
your data to the large language model

[01:54 - 01:56]
first of all you have to know how to

[01:55 - 01:59]
process this data and how to generate

[01:56 - 02:00]
the embeddings of the data and to

[01:59 - 02:02]
process our data we need to know some of

[02:00 - 02:04]
the technique so here we'll be covering

[02:02 - 02:05]
these are the technique in this section

[02:04 - 02:06]
then we'll be starting with the large

[02:05 - 02:08]
language model we'll be learning about

[02:06 - 02:09]
different kinds of large language model

[02:08 - 02:10]
we'll be learning about commercial large

[02:09 - 02:13]
language model we'll be also learning

[02:10 - 02:14]
about open source large language model

[02:13 - 02:16]
we'll be starting with the hugging F

[02:14 - 02:18]
platform and its API because if you see

[02:16 - 02:20]
the hugging pH hugging pH is having all

[02:18 - 02:21]
kinds of large language model whether

[02:20 - 02:23]
it's a commercial model whether it's a

[02:21 - 02:25]
open source model all kinds of model are

[02:23 - 02:27]
available inside the hugging face

[02:25 - 02:29]
platform then we'll be also learning

[02:27 - 02:31]
about open Ai and its platform because

[02:29 - 02:32]
if you see nowaday open AI is evolving a

[02:31 - 02:35]
lot they are coming up with different

[02:32 - 02:37]
different kinds of large language model

[02:35 - 02:38]
like they are coming up with image model

[02:37 - 02:40]
language model OKAY different different

[02:38 - 02:41]
kinds of model they are bringing so in

[02:40 - 02:43]
this course we'll be learning about the

[02:41 - 02:45]
complete openi and its platform so that

[02:43 - 02:48]
you can use openi platform to implement

[02:45 - 02:50]
any of genv based application we'll be

[02:48 - 02:51]
learning about prompt engineering

[02:50 - 02:53]
because if you see prompt is everything

[02:51 - 02:55]
for the large language model so if you

[02:53 - 02:57]
are designing a good prompt definitely

[02:55 - 02:58]
you will be getting a good response from

[02:57 - 03:00]
the large language model so here we'll

[02:58 - 03:01]
be learning how we can designer

[03:00 - 03:03]
efficient prompt and we'll be also

[03:01 - 03:05]
learning about different different kinds

[03:03 - 03:07]
of prompting inside large language model

[03:05 - 03:08]
in this course we'll be mastering the

[03:07 - 03:10]
vector database we'll be learning

[03:08 - 03:13]
different kinds of vector database like

[03:10 - 03:14]
Pine con we chroma files and so on this

[03:13 - 03:16]
Vector database will help you to create

[03:14 - 03:17]
a knowledge base so whenever you will be

[03:16 - 03:18]
creating any kinds of rack based

[03:17 - 03:20]
application any kinds of LM powered

[03:18 - 03:22]
application this Vector database concept

[03:20 - 03:24]
will help you a lot in this course we'll

[03:22 - 03:26]
be mastering different different kinds

[03:24 - 03:28]
of genbi based framework like we'll be

[03:26 - 03:30]
mastering Lang chain llama index CH leit

[03:28 - 03:31]
and so on these are the fr work will

[03:30 - 03:33]
help you to implement different

[03:31 - 03:35]
different kinds of jni based application

[03:33 - 03:37]
in this course we'll also learn one very

[03:35 - 03:39]
important topic inside jtbi called

[03:37 - 03:41]
retable augmented generation that means

[03:39 - 03:42]
rack so we'll be learning how we can

[03:41 - 03:44]
create different kinds of rack based

[03:42 - 03:46]
application with our custom data even

[03:44 - 03:48]
we'll be also learning how we can find

[03:46 - 03:50]
you any kinds of large language model on

[03:48 - 03:52]
top of our custom data after completing

[03:50 - 03:54]
all the topics inside genbi we'll be

[03:52 - 03:56]
starting with some n2n project

[03:54 - 03:57]
implementation with the deployment so

[03:56 - 03:58]
here we'll be implementing these kinds

[03:57 - 04:00]
of project from scratch we'll be using

[03:58 - 04:02]
modular coding to implement this kinds

[04:00 - 04:04]
of project at the last of the course

[04:02 - 04:06]
we'll be also discussing about llm Ops

[04:04 - 04:08]
if you see inside genbi llm Ops is the

[04:06 - 04:10]
most trending topic nowadays we'll be

[04:08 - 04:11]
learning how we can use different

[04:10 - 04:14]
different kinds of llm Ops platform like

[04:11 - 04:16]
we'll be learning about Bedrock vertex

[04:14 - 04:17]
Ai and we'll be learning how we can use

[04:16 - 04:19]
these are the platform to implement

[04:17 - 04:22]
efficient large language based

[04:19 - 04:24]
application so yes this is the complete

[04:22 - 04:26]
curriculum of our course so if you want

[04:24 - 04:27]
to start your career with jvi guys so

[04:26 - 04:29]
this would be the amazing course for you

[04:27 - 04:32]
so make sure you complete this course

[04:29 - 04:33]
till till the end and this is my promise

[04:32 - 04:35]
guys you will become Champion inside

[04:33 - 04:39]
geni with that guys all the best and I

[04:35 - 04:41]
will see you in the course hi everyone

[04:39 - 04:44]
welcome to the course of generative VI

[04:41 - 04:46]
my name is BK Ahmed Bui and I am a data

[04:44 - 04:48]
scientist and Mentor I'm having more

[04:46 - 04:49]
than four years of working experience in

[04:48 - 04:52]
the field of machine learning deep

[04:49 - 04:53]
learning generative mlops and so on I

[04:52 - 04:55]
have already worked with so many

[04:53 - 04:57]
multinational company as a developer

[04:55 - 04:59]
even I also work with so many attech

[04:57 - 05:02]
company as a mentor I have also taken

[04:59 - 05:03]
lots of bats related generative machine

[05:02 - 05:05]
learning deep learning computer vision

[05:03 - 05:07]
national language processing and so on

[05:05 - 05:09]
so throughout the entire course I'm

[05:07 - 05:11]
going to be your Mentor so as I already

[05:09 - 05:12]
have some experience from the industry

[05:11 - 05:14]
so in this particular course I'm going

[05:12 - 05:15]
to share my knowledge and experience

[05:14 - 05:17]
with you so in this course we'll be

[05:15 - 05:19]
starting with the very Basics concept of

[05:17 - 05:22]
generative and we'll be completing till

[05:19 - 05:23]
Advanced part of the generative a so if

[05:22 - 05:25]
you're a beginner if you want to start

[05:23 - 05:27]
your career with the genbi so this

[05:25 - 05:28]
course is for you I have designed this

[05:27 - 05:30]
particular course in a such a way so

[05:28 - 05:32]
that anyone is coming from any kinds of

[05:30 - 05:33]
domain they will be also able to

[05:32 - 05:34]
understand so if you're from non-tech

[05:33 - 05:36]
background if you're from Tech

[05:34 - 05:38]
background it doesn't matter so if you

[05:36 - 05:39]
are interested in Genera only you just

[05:38 - 05:41]
need to start with this course

[05:39 - 05:43]
everything I will take care apart from

[05:41 - 05:45]
the theoretical understanding I'm also

[05:43 - 05:47]
going to show you lots of practical in

[05:45 - 05:48]
this particular course we'll be doing

[05:47 - 05:49]
lots of Hands-On in this particular

[05:48 - 05:51]
course we'll be solving different

[05:49 - 05:52]
different problem statement in this

[05:51 - 05:55]
course so that your understanding would

[05:52 - 05:57]
be more clear hello everyone welcome

[05:55 - 05:59]
back with another video in this video

[05:57 - 06:01]
we'll be discussing about what is gener

[05:59 - 06:03]
tvi so before discussing about

[06:01 - 06:04]
generative a first of all uh let me

[06:03 - 06:06]
introduce some of the real world

[06:04 - 06:08]
application of the generative you are

[06:06 - 06:11]
using in your day-to-day life so I think

[06:08 - 06:13]
you know about chat GPT Google Jin metal

[06:11 - 06:15]
Lama right so these are the application

[06:13 - 06:18]
you are using in your day-to-day life I

[06:15 - 06:20]
hope everyone has used chat GPT at least

[06:18 - 06:22]
right since at chat GPT what we can

[06:20 - 06:25]
perform we can give any kinds of prompt

[06:22 - 06:27]
we can uh do the conversation we can do

[06:25 - 06:29]
the summarization we can generate the

[06:27 - 06:31]
content we can generate the code we can

[06:29 - 06:34]
do the Tex summarization any kinds of

[06:31 - 06:36]
task we can perform in the chat gbt

[06:34 - 06:38]
right so similar wise Google has

[06:36 - 06:39]
developed their own product called jini

[06:38 - 06:41]
Okay Google jini so with the help of

[06:39 - 06:43]
Google jini also we can perform the same

[06:41 - 06:45]
things the things actually we perform

[06:43 - 06:46]
usually in our chat gbt so the same

[06:45 - 06:49]
thing we can perform with the help of

[06:46 - 06:52]
metal amar2 as well that means chat GPT

[06:49 - 06:54]
is developed by open AI uh Google J mini

[06:52 - 06:57]
is developed by Google and Lama is

[06:54 - 07:00]
developed by meta okay meta that means

[06:57 - 07:02]
Facebook so all the TS company iies are

[07:00 - 07:04]
working on generative day by day they

[07:02 - 07:06]
are improving this particular generative

[07:04 - 07:07]
they're bringing actually different

[07:06 - 07:09]
different large language model and

[07:07 - 07:12]
they're uh launching different different

[07:09 - 07:14]
application okay for the users nowadays

[07:12 - 07:16]
all the companies are using generate to

[07:14 - 07:18]
implement their product So currently in

[07:16 - 07:21]
the market uh genbi having more

[07:18 - 07:23]
popularity so that's why you have to

[07:21 - 07:26]
know what is genbi exactly how genbi

[07:23 - 07:27]
works and definitely if you want to work

[07:26 - 07:29]
in the current job market you have to

[07:27 - 07:30]
know about this genbi you have to learn

[07:29 - 07:32]
about generative value okay this is the

[07:30 - 07:34]
idea see all the application I showed

[07:32 - 07:37]
you here like chart GPT Google jini

[07:34 - 07:38]
metal Lama so they are using something

[07:37 - 07:40]
called large language model in the back

[07:38 - 07:42]
end okay with the help of large language

[07:40 - 07:44]
model they're able to perform these are

[07:42 - 07:46]
the operation now first of all let's try

[07:44 - 07:48]
to understand what is generative a

[07:46 - 07:50]
exactly see generative a is nothing but

[07:48 - 07:52]
generative AI generates new data based

[07:50 - 07:55]
on training samples generative model can

[07:52 - 07:58]
generate image text audio video and so

[07:55 - 08:00]
on data as an output so I think you have

[07:58 - 08:02]
already worked with machine learning

[08:00 - 08:04]
deep learning computer vision and so on

[08:02 - 08:05]
right so there you used to use something

[08:04 - 08:08]
called discriminative model and what is

[08:05 - 08:10]
discriminative model based on some input

[08:08 - 08:12]
actually it will predict the output of

[08:10 - 08:14]
that particular data okay so this was

[08:12 - 08:16]
actually discriminative model and to

[08:14 - 08:17]
train the discriminative model actually

[08:16 - 08:19]
we used to use something called label

[08:17 - 08:20]
data that means that means whenever we

[08:19 - 08:23]
used to prepare the data for the

[08:20 - 08:25]
training we used to prepare the let's

[08:23 - 08:27]
say uh input data as well as the output

[08:25 - 08:29]
data that means you have to pass the X

[08:27 - 08:32]
data and Y data that means input output

[08:29 - 08:33]
both okay and if you uh give input and

[08:32 - 08:35]
output both it will learn the

[08:33 - 08:37]
relationship between input and output it

[08:35 - 08:39]
will learn the pattern from the data

[08:37 - 08:41]
then it will able to predict something

[08:39 - 08:42]
on top of the test data so that was the

[08:41 - 08:44]
idea in the discriminative model that

[08:42 - 08:46]
means in the prediction model right but

[08:44 - 08:48]
generative models are different okay so

[08:46 - 08:50]
generative models can generate a new

[08:48 - 08:51]
data based on the training samples so

[08:50 - 08:53]
here you'll be giving some training

[08:51 - 08:55]
sample which is called unstructured Data

[08:53 - 08:57]
So based on this training sample data it

[08:55 - 08:59]
will try to generate some new data that

[08:57 - 09:01]
means inside jna when whenever you are

[08:59 - 09:04]
giving any kinds of unstructured data as

[09:01 - 09:05]
an input your generative model will try

[09:04 - 09:06]
to understand this unstructured data it

[09:05 - 09:08]
will learn the pattern from the

[09:06 - 09:10]
unstructured data and it will try to

[09:08 - 09:11]
generate something from that particular

[09:10 - 09:13]
sample you are giving okay this is the

[09:11 - 09:15]
idea and the output can be anything it

[09:13 - 09:17]
can be text it can be audios it can be

[09:15 - 09:20]
videos and so on okay as I already told

[09:17 - 09:22]
you inser generative we not only work

[09:20 - 09:24]
with the text but also we also work with

[09:22 - 09:26]
the image videos audios and so on okay

[09:24 - 09:28]
so all the unstructured data can be used

[09:26 - 09:30]
inside generate this is the idea so

[09:28 - 09:33]
that's why I generative AI is a very

[09:30 - 09:35]
huge topic inside generative AI actually

[09:33 - 09:37]
we are having generative image model as

[09:35 - 09:38]
well as the generative language model

[09:37 - 09:40]
that means you can work with the

[09:38 - 09:42]
languages that means text you can also

[09:40 - 09:44]
work with the images videos okay and

[09:42 - 09:46]
audios so there is another model you can

[09:44 - 09:48]
consider generative Audio model but at

[09:46 - 09:50]
the end you are converting this audio to

[09:48 - 09:52]
the text representation that means

[09:50 - 09:53]
language representation that's why I

[09:52 - 09:55]
haven't mentioned this Audio model

[09:53 - 09:56]
separately okay this is the idea because

[09:55 - 09:59]
audio is nothing but it's a frequency

[09:56 - 10:01]
and from the frequency we can convert to

[09:59 - 10:02]
the textual representation okay this is

[10:01 - 10:05]
the idea there are so many API you will

[10:02 - 10:07]
get even Google has the API you can

[10:05 - 10:08]
let's say convert SP to text okay with

[10:07 - 10:10]
the help of is to text you can easily

[10:08 - 10:12]
convert any of audio to textual

[10:10 - 10:14]
representation okay this is the idea

[10:12 - 10:16]
that means what is generative a Genera a

[10:14 - 10:17]
is nothing but it generates new data

[10:16 - 10:19]
based on the training sample you are

[10:17 - 10:22]
giving and generative model can generate

[10:19 - 10:24]
any kinds of output whether it can be

[10:22 - 10:26]
image it can be text or it can be audios

[10:24 - 10:28]
okay now let me tell you how they got

[10:26 - 10:30]
the idea like how this generative model

[10:28 - 10:32]
can work see this idea had taken from

[10:30 - 10:34]
real life only let's say uh if I give

[10:32 - 10:37]
you 10 different scat book okay let's

[10:34 - 10:38]
say if I give you 10 different cats book

[10:37 - 10:40]
and if I tell you just try to read all

[10:38 - 10:43]
the 10 different cat book let's say you

[10:40 - 10:46]
have read all the 10 different cat books

[10:43 - 10:48]
now if I'm asking anything related cats

[10:46 - 10:50]
okay you will be able to give me the

[10:48 - 10:52]
answer because you have already studied

[10:50 - 10:54]
about the cats like uh 10 different

[10:52 - 10:56]
books I have given and this was the

[10:54 - 10:58]
enough data for you right to learn about

[10:56 - 11:00]
the cats so that's why if I'm asking

[10:58 - 11:02]
anything related to the cats you'll be

[11:00 - 11:05]
able to give me the response so here you

[11:02 - 11:07]
have become one cat model okay you have

[11:05 - 11:08]
become one cat model and that is why if

[11:07 - 11:10]
I'm giving any kinds of question you

[11:08 - 11:12]
will be able to give me the response

[11:10 - 11:14]
okay so similar concept applied in the

[11:12 - 11:16]
generative also so they implemented one

[11:14 - 11:18]
model called generative model in the

[11:16 - 11:20]
generative model they feed actually tons

[11:18 - 11:22]
of data that means huge amount of data

[11:20 - 11:23]
they uh trained okay that particular

[11:22 - 11:25]
model and then actually they were uh

[11:23 - 11:27]
giving some kinds of question and that

[11:25 - 11:29]
particular model was able to give the

[11:27 - 11:30]
response okay this is the idea that

[11:29 - 11:33]
means here you are feeding tons of

[11:30 - 11:35]
unstructured data and your model is able

[11:33 - 11:36]
to uh let's say learn the pattern from

[11:35 - 11:38]
the unstructured data and there would be

[11:36 - 11:41]
a position your model will be able to

[11:38 - 11:42]
capable enough to give any kinds of

[11:41 - 11:45]
response okay based on the question you

[11:42 - 11:47]
are asking now you can ask me why

[11:45 - 11:48]
generative models are required see I can

[11:47 - 11:50]
give you thousands reasons of the

[11:48 - 11:52]
generative model requirement but here I

[11:50 - 11:53]
have listed down some of them so the

[11:52 - 11:55]
first thing you can consider understand

[11:53 - 11:57]
the complex pattern from the data

[11:55 - 11:59]
because nowadays you can see people are

[11:57 - 12:01]
using unstructured data a lot

[11:59 - 12:03]
unstructured data means it can be text

[12:01 - 12:04]
Data it can be audio data it can be

[12:03 - 12:06]
videos data right so this is called

[12:04 - 12:08]
actually unstructured data and in

[12:06 - 12:10]
today's world actually people are using

[12:08 - 12:12]
internet broadly and in in Internet

[12:10 - 12:14]
actually people are generating huge

[12:12 - 12:15]
amount of unstructured data okay they're

[12:14 - 12:16]
using different different social media

[12:15 - 12:19]
they are using different different

[12:16 - 12:21]
platform so that's how actually they're

[12:19 - 12:23]
generating tons of unstructured data so

[12:21 - 12:25]
that's why it's very hard to understand

[12:23 - 12:27]
the pattern from these kinds of

[12:25 - 12:29]
unstructured data with traditional

[12:27 - 12:31]
machine learning model okay so that's

[12:29 - 12:32]
why this gentic model comes into picture

[12:31 - 12:34]
so it can easily understand the complex

[12:32 - 12:36]
pattern from these kinds of unstructured

[12:34 - 12:38]
data the second thing you can consider

[12:36 - 12:39]
the content generation that means that

[12:38 - 12:41]
means your generative model can generate

[12:39 - 12:43]
any kinds of content it can generate

[12:41 - 12:45]
code it can generate let's say any kinds

[12:43 - 12:47]
of story it can generate any kinds of

[12:45 - 12:49]
music any kinds of videos I think

[12:47 - 12:51]
nowadays you have seen like there are so

[12:49 - 12:53]
many application came in the market so

[12:51 - 12:55]
if you give any kinds of prompt it will

[12:53 - 12:57]
generate the video for you okay the

[12:55 - 12:59]
complete video for you that means it is

[12:57 - 13:01]
generating some content okay it is

[12:59 - 13:03]
generating some content based on the

[13:01 - 13:05]
prompt prompt you are giving and that's

[13:03 - 13:07]
how for the content creator also it is

[13:05 - 13:09]
becoming one of the very uh used tool

[13:07 - 13:11]
okay for their content generation and

[13:09 - 13:13]
all let's say you are a Blog

[13:11 - 13:15]
writer now you don't need to write the

[13:13 - 13:17]
blog from scratch so what you can do you

[13:15 - 13:19]
can just pass the topic and your model

[13:17 - 13:21]
will generate the blog for you and what

[13:19 - 13:23]
you can do you can just modify this

[13:21 - 13:24]
particular blog with respect to your

[13:23 - 13:26]
requirement and you can publish okay

[13:24 - 13:28]
anywhere you can also generate any kinds

[13:26 - 13:30]
of videos you can also generate any

[13:28 - 13:32]
kinds of skills okay everything is

[13:30 - 13:33]
possible nowadays with the help of this

[13:32 - 13:35]
generative models okay so that is why

[13:33 - 13:37]
content generation is one of the very uh

[13:35 - 13:40]
important let's say features inside

[13:37 - 13:41]
generative models okay I can talk about

[13:40 - 13:43]
now the third thing you can consider

[13:41 - 13:45]
build powerful application as I already

[13:43 - 13:47]
told you we are already using uh tons of

[13:45 - 13:50]
powerful application in our day-to-day

[13:47 - 13:52]
life like CH GPT gini okay then Lama so

[13:50 - 13:53]
different different actually powerful

[13:52 - 13:55]
application we are using in our

[13:53 - 13:57]
day-to-day life and just try to think

[13:55 - 13:59]
about when we didn't have these kinds of

[13:57 - 14:01]
application we had to complete of work

[13:59 - 14:02]
actually manually but nowadays we are

[14:01 - 14:04]
having this kinds of powerful

[14:02 - 14:06]
application now you can do any kinds of

[14:04 - 14:08]
work actually in a few seconds okay it

[14:06 - 14:10]
is possible let's say if I give you one

[14:08 - 14:11]
example as a developer whenever let's

[14:10 - 14:13]
say you are getting any kinds of error

[14:11 - 14:15]
okay from your let's say application

[14:13 - 14:16]
what you can do you can copy that error

[14:15 - 14:18]
and you can ask through the chat GPT

[14:16 - 14:20]
chat GPT will give you the solution okay

[14:18 - 14:22]
how you can solve it but previously when

[14:20 - 14:23]
we didn't have any kind of chat GPT what

[14:22 - 14:25]
we used to do we used to search that

[14:23 - 14:27]
particular error inside Google we used

[14:25 - 14:29]
to open this track overflow and we used

[14:27 - 14:31]
to see lots of let's say Solutions then

[14:29 - 14:32]
we used to solve that particular let's

[14:31 - 14:34]
say error and nowadays actually we are

[14:32 - 14:37]
using these kinds of application and it

[14:34 - 14:38]
is actually saving lots of our time so

[14:37 - 14:41]
we don't have to spend actually lots of

[14:38 - 14:42]
time to fix any kinds of bugs uh in a

[14:41 - 14:44]
few seconds actually it is possible

[14:42 - 14:47]
nowadays uh if we are using these kinds

[14:44 - 14:49]
of powerful generative AI based

[14:47 - 14:50]
application okay this is the idea those

[14:49 - 14:52]
who have already studied about

[14:50 - 14:54]
artificial intelligence machine learning

[14:52 - 14:56]
deep learning maybe you have already

[14:54 - 14:59]
seen these kinds of V diagram okay this

[14:56 - 15:02]
is the V diagram of our AI the complete

[14:59 - 15:04]
AI now you can see machine learning is a

[15:02 - 15:05]
subset of artificial intelligence deep

[15:04 - 15:08]
learning is the subset of machine

[15:05 - 15:10]
learning and now here you can see gen VI

[15:08 - 15:11]
is the subset of deep learning okay it

[15:10 - 15:13]
is the subset of deep learning that

[15:11 - 15:16]
means machine learning is the subset of

[15:13 - 15:17]
artificial intelligence deep learning is

[15:16 - 15:19]
the subset of machine learning and

[15:17 - 15:21]
generative is the subset of deep

[15:19 - 15:23]
learning okay this is the complete V

[15:21 - 15:26]
diagram of the complete artificial

[15:23 - 15:27]
intelligence okay I hope it is clear now

[15:26 - 15:29]
let's try to see the difference between

[15:27 - 15:31]
discriminative model and generative

[15:29 - 15:32]
model you can see uh discriminative

[15:31 - 15:35]
model is nothing but it's just a

[15:32 - 15:37]
prediction model let's say here you have

[15:35 - 15:38]
given two input one is the cat image

[15:37 - 15:40]
other is the dog image what your

[15:38 - 15:42]
discriminator model will do it will try

[15:40 - 15:43]
to predict whether it's a cat image or

[15:42 - 15:45]
whether it's a dog image that means you

[15:43 - 15:47]
are trying to do some prediction here I

[15:45 - 15:49]
think you already use these kinds of

[15:47 - 15:50]
model in your deep learning let's say

[15:49 - 15:52]
whenever you used to perform something

[15:50 - 15:54]
called image classification there we had

[15:52 - 15:58]
different different model like resonet

[15:54 - 15:59]
50 Inception V3 right mobile net vg6 so

[15:58 - 16:01]
with the help of this particular model

[15:59 - 16:04]
we can perform the image classification

[16:01 - 16:06]
task on the other hand generative model

[16:04 - 16:08]
can take actually any kinds of sample

[16:06 - 16:10]
data any of noise data and from that

[16:08 - 16:13]
particular noise data it will generate a

[16:10 - 16:14]
complete new image for you okay new data

[16:13 - 16:16]
for you now let's say here you are

[16:14 - 16:18]
passing one noise data noise data means

[16:16 - 16:19]
it can be any kinds of unstructured data

[16:18 - 16:21]
and what generative model will do it

[16:19 - 16:22]
will try to understand the pattern it

[16:21 - 16:24]
will try to understand the pattern from

[16:22 - 16:26]
these kinds of data okay then it will

[16:24 - 16:28]
generate a new data for you new data

[16:26 - 16:30]
point for you this is the idea okay this

[16:28 - 16:32]
this is the idea of the generative model

[16:30 - 16:33]
see I have kept another example here

[16:32 - 16:36]
let's say so here we are using

[16:33 - 16:38]
distributive model to classify the music

[16:36 - 16:39]
type you can see here we are uh giving

[16:38 - 16:42]
actually different different music rock

[16:39 - 16:44]
classical and romantic so here your

[16:42 - 16:45]
discriminative model that means your

[16:44 - 16:47]
discriminator deep learning model will

[16:45 - 16:49]
try to classify whether it's a rock

[16:47 - 16:51]
music whether it's a classical music or

[16:49 - 16:53]
whether it's a romantic music on the

[16:51 - 16:56]
other hand generative model what it will

[16:53 - 16:57]
do you will just give some music sample

[16:56 - 16:59]
okay and generative model will try to

[16:57 - 17:01]
understand the pattern and it will

[16:59 - 17:03]
generate a complete new music for you

[17:01 - 17:05]
maybe you have already heard of AI has

[17:03 - 17:08]
created Music AI has created songs AI

[17:05 - 17:09]
has written Story how that's how

[17:08 - 17:10]
actually they're using something called

[17:09 - 17:13]
generative model they're actually

[17:10 - 17:15]
feeding lots of training samples okay

[17:13 - 17:17]
and this model is learning and it is

[17:15 - 17:19]
generating a new content okay with

[17:17 - 17:21]
respect to the data they are giving this

[17:19 - 17:23]
is the idea of the generative model and

[17:21 - 17:25]
the distributive model I hope now it is

[17:23 - 17:27]
clear now if I discuss a little bit low

[17:25 - 17:30]
level like how things are working here

[17:27 - 17:31]
see maybe you have heard of something

[17:30 - 17:33]
called supervised learning okay in

[17:31 - 17:35]
supervised learning uh what we do we

[17:33 - 17:37]
give the X data as well as the Y data

[17:35 - 17:39]
that means input and output and here we

[17:37 - 17:41]
try to find the relationship between our

[17:39 - 17:42]
input and output okay this is called

[17:41 - 17:44]
actually supervised learning and

[17:42 - 17:46]
whatever actually let's say discret

[17:44 - 17:48]
model actually we're using it is called

[17:46 - 17:49]
actually supervised learning on the

[17:48 - 17:51]
other hand we are having another

[17:49 - 17:52]
learning called unsupervised learning in

[17:51 - 17:53]
the unsupervised learning what we use to

[17:52 - 17:55]
perform we us to perform something

[17:53 - 17:57]
called clustering technique let's say

[17:55 - 17:59]
here we are only giving the X data that

[17:57 - 18:00]
means the input data and what my model

[17:59 - 18:02]
will try to do it will try to make a

[18:00 - 18:04]
cluster let's say this is uh one cluster

[18:02 - 18:06]
this is another cluster this is another

[18:04 - 18:08]
cluster that's how it is separated out

[18:06 - 18:10]
my data okay that's how it will find out

[18:08 - 18:12]
the relationship between the data okay

[18:10 - 18:14]
this is the idea now you can consider

[18:12 - 18:16]
this unsupervised learning as a

[18:14 - 18:18]
generative model so generative model

[18:16 - 18:19]
will also work in the same way so

[18:18 - 18:21]
instead of actually finding the

[18:19 - 18:22]
relationship what it will try to do it

[18:21 - 18:24]
will try to make a class chart okay it

[18:22 - 18:25]
will try to make a cluster from the

[18:24 - 18:27]
unstructured data actually will be

[18:25 - 18:29]
feding this is actually lowlevel

[18:27 - 18:31]
actually understanding I'm giving you

[18:29 - 18:32]
how things are working here but on top

[18:31 - 18:34]
of that they have added some more

[18:32 - 18:37]
technique to actually build this kinds

[18:34 - 18:38]
of genbi model okay this is the idea so

[18:37 - 18:39]
in summary actually you can see

[18:38 - 18:41]
generative VI is a subset of deep

[18:39 - 18:43]
learning and generative models are

[18:41 - 18:45]
trained on huge amount of data as I

[18:43 - 18:46]
already told you while training the

[18:45 - 18:48]
generative model we don't need to

[18:46 - 18:50]
provide any kinds of label data we only

[18:48 - 18:52]
give the unstructured input data because

[18:50 - 18:54]
whenever uh you are working with huge

[18:52 - 18:56]
amount of data it's not possible to

[18:54 - 18:57]
label the data okay that's why you are

[18:56 - 19:00]
giving the unstructured data as an input

[18:57 - 19:01]
to the generating model so here you can

[19:00 - 19:03]
see in generative AI we give the

[19:01 - 19:06]
unstructured data to the large language

[19:03 - 19:07]
model for the training purpose and

[19:06 - 19:09]
whatever things I explain so far you can

[19:07 - 19:11]
see what your distributive model will do

[19:09 - 19:13]
it will try to uh actually predict

[19:11 - 19:15]
whether it's a dog image or whether it's

[19:13 - 19:17]
a cat image okay by finding the

[19:15 - 19:19]
relationship on the other hand your

[19:17 - 19:21]
generative model will try to uh make a

[19:19 - 19:24]
cluster okay let's say this is a cat

[19:21 - 19:25]
cluster this is a dog cluster okay then

[19:24 - 19:27]
with the help of that it will able to

[19:25 - 19:28]
generate a new content from you I think

[19:27 - 19:31]
you have heard of something called gan

[19:28 - 19:33]
the generative aders neural network okay

[19:31 - 19:35]
so Gan is also called generative model

[19:33 - 19:37]
okay because here you will be giving

[19:35 - 19:38]
noise data and from the noise data

[19:37 - 19:40]
itself it will able to generate a new

[19:38 - 19:43]
content okay new data this is the idea

[19:40 - 19:44]
of the Gans so so far I told you about

[19:43 - 19:46]
generative model but what exactly this

[19:44 - 19:48]
generative model see generative model is

[19:46 - 19:50]
nothing but it's a large language model

[19:48 - 19:53]
which is also called llm see a large

[19:50 - 19:55]
language model is nothing but uh it's a

[19:53 - 19:56]
foundational machine learning model that

[19:55 - 19:58]
uses a deep learning algorithm to

[19:56 - 20:00]
process and understand the natural

[19:58 - 20:02]
language these models are trained on

[20:00 - 20:04]
massive amount of Text data to learn

[20:02 - 20:07]
patterns and entity relationships in a

[20:04 - 20:09]
language it can be also considered in a

[20:07 - 20:12]
image data as well okay not only text

[20:09 - 20:13]
Data you can also use llm for the image

[20:12 - 20:16]
as well because I told you we are having

[20:13 - 20:18]
two kinds of model uh generative

[20:16 - 20:20]
language model generative image model

[20:18 - 20:22]
okay so you can also use image data here

[20:20 - 20:23]
not only text data and it is a language

[20:22 - 20:25]
model which is responsible for

[20:23 - 20:27]
performing tasks such as text to text

[20:25 - 20:29]
generation text to image Generation

[20:27 - 20:30]
image to text generation generation as I

[20:29 - 20:32]
already told you as I already told you

[20:30 - 20:34]
generative model can support actually

[20:32 - 20:36]
all kinds of data you can generate text

[20:34 - 20:38]
to text you can generate text to image

[20:36 - 20:39]
even you can also generate image to text

[20:38 - 20:41]
okay everything is possible with the

[20:39 - 20:43]
help of this large language model

[20:41 - 20:45]
nowadays okay and we also call it as

[20:43 - 20:48]
multimodel that means you can perform

[20:45 - 20:50]
multiple task here not one specific task

[20:48 - 20:52]
you can perform multiple task like text

[20:50 - 20:54]
to text text to image and image to text

[20:52 - 20:55]
generation apart from that you can

[20:54 - 20:57]
perform uh some more tasks let's say you

[20:55 - 21:00]
can perform uh language translation you

[20:57 - 21:02]
can perform text generation you can

[21:00 - 21:04]
perform let's say text classification

[21:02 - 21:06]
you can perform sentiment analysis name

[21:04 - 21:08]
entity recognization all kinds of task

[21:06 - 21:10]
you can perform with the help of only

[21:08 - 21:12]
one model and which is nothing but our

[21:10 - 21:14]
large language model okay and large

[21:12 - 21:16]
language model is nothing but our

[21:14 - 21:18]
generative model okay this is the

[21:16 - 21:20]
complete idea about our generative AI I

[21:18 - 21:23]
hope it is clear now now let's try to

[21:20 - 21:25]
understand what makes llm so powerful as

[21:23 - 21:27]
I already told you in case of llm one

[21:25 - 21:30]
model can be used for whole variety of

[21:27 - 21:32]
the task okay I I told you now uh Tex

[21:30 - 21:33]
generation you can perform chatboard you

[21:32 - 21:35]
can perform summarization you can

[21:33 - 21:36]
perform translation you can perform code

[21:35 - 21:38]
generation you can perform that means

[21:36 - 21:40]
whatever task actually you have inside

[21:38 - 21:42]
the NLP all the task you can perform

[21:40 - 21:43]
with the help of one model which is

[21:42 - 21:45]
nothing but large language model so

[21:43 - 21:48]
that's why we call this llm is so

[21:45 - 21:49]
powerful and that makes llm so powerful

[21:48 - 21:51]
because in our traditional model

[21:49 - 21:53]
whatever model we used to use that means

[21:51 - 21:55]
the language model only we can only

[21:53 - 21:57]
perform one specific task let's say you

[21:55 - 21:59]
are you want to do actually language

[21:57 - 22:01]
translation for language translation you

[21:59 - 22:03]
need to only 10 mon language translation

[22:01 - 22:05]
model that model can't do the code

[22:03 - 22:07]
generation or let's say t summarization

[22:05 - 22:08]
that model can perform but if you're

[22:07 - 22:10]
using large language model you can

[22:08 - 22:12]
perform all kinds of task with the help

[22:10 - 22:14]
of one model only okay so that's why llm

[22:12 - 22:16]
is so powerful because of this

[22:14 - 22:17]
particular idea so as I already told you

[22:16 - 22:19]
if you're using your traditional

[22:17 - 22:22]
actually language model it can only

[22:19 - 22:23]
perform one specific task at a time

[22:22 - 22:25]
let's say you want to build a sentiment

[22:23 - 22:27]
analysis so one model you have to train

[22:25 - 22:28]
for the sentiment analysis which will

[22:27 - 22:30]
only able to do the sentiment analysis

[22:28 - 22:31]
whether this particular let's say

[22:30 - 22:33]
sentiment is positive neutral or

[22:31 - 22:35]
negative let's see you want to perform

[22:33 - 22:36]
language translation you have to read

[22:35 - 22:38]
another model for the language

[22:36 - 22:40]
translation and that model will be able

[22:38 - 22:42]
to translate any kinds of text okay that

[22:40 - 22:44]
means you have created two separate

[22:42 - 22:46]
model okay for two separate task but if

[22:44 - 22:47]
you're using large language model you

[22:46 - 22:49]
need to only train one specific model

[22:47 - 22:52]
okay and that can perform multiple task

[22:49 - 22:53]
this is the idea of large language model

[22:52 - 22:55]
so let's see some of the large language

[22:53 - 22:58]
model so here you can see we are having

[22:55 - 23:01]
gini GPT uh xlm then we are having t

[22:58 - 23:02]
five Lama mral Falcon apart from that

[23:01 - 23:04]
there are so many large language models

[23:02 - 23:05]
are available over the internet I'm

[23:04 - 23:07]
going to discuss I'm going to show you

[23:05 - 23:08]
each and everything so here I just

[23:07 - 23:10]
mentioned some of the large language

[23:08 - 23:12]
model just to show you but I will tell

[23:10 - 23:14]
you uh how you can see all the large

[23:12 - 23:16]
language models are available over the

[23:14 - 23:17]
Internet even I will also show you how

[23:16 - 23:19]
you can access those model and how we

[23:17 - 23:21]
can use those model to create your

[23:19 - 23:23]
application okay on top of it everything

[23:21 - 23:25]
I'll try to clarify so yes guys this is

[23:23 - 23:26]
the introduction of generative I now I

[23:25 - 23:28]
think you got the clear-cut idea about

[23:26 - 23:31]
generative like what exactly the

[23:28 - 23:32]
generative Ai and inside generative a

[23:31 - 23:34]
actually what are the things are

[23:32 - 23:36]
available and why it is actually mostly

[23:34 - 23:38]
used technology inside any kinds of

[23:36 - 23:40]
software product nowadays and inside

[23:38 - 23:42]
generative models actually uh what is

[23:40 - 23:45]
uses it is uses something called large

[23:42 - 23:47]
language model and not body I'll discuss

[23:45 - 23:48]
about large language model uh in detail

[23:47 - 23:50]
like how large language model works and

[23:48 - 23:51]
inside that what are the architecture

[23:50 - 23:53]
they're using everything I will try to

[23:51 - 23:56]
clarify and now you can ask me what is

[23:53 - 23:58]
N2 pipeline of generi no need to worry I

[23:56 - 24:01]
will explain uh each and everything what

[23:58 - 24:03]
is Pipeline and all and why pipeline is

[24:01 - 24:06]
super important whenever you are working

[24:03 - 24:07]
in the generative field see it's not

[24:06 - 24:10]
like that whenever you are getting uh

[24:07 - 24:11]
some problem statement from your company

[24:10 - 24:13]
whenever let's say you are receiving the

[24:11 - 24:15]
data it's not like that you will be

[24:13 - 24:17]
directly applying the model on top of it

[24:15 - 24:19]
before applying the model we have to

[24:17 - 24:22]
perform some specific task okay and

[24:19 - 24:24]
those stepbystep task is called pipeline

[24:22 - 24:27]
so you can see gener TBI pipeline is a

[24:24 - 24:29]
set of steps followed to build an n2n

[24:27 - 24:31]
genni software okay that means here you

[24:29 - 24:34]
will be breaking the problem statement

[24:31 - 24:36]
into several sub problems then you will

[24:34 - 24:38]
be trying to develop a step byst step

[24:36 - 24:39]
procedure to solve them and here you can

[24:38 - 24:42]
see since language processing is

[24:39 - 24:44]
involved okay inside generative AI so we

[24:42 - 24:48]
would also list all the forms of text

[24:44 - 24:49]
processing needed at each step this step

[24:48 - 24:54]
byst step processing of the text is

[24:49 - 24:55]
known as a pipeline okay that means uh

[24:54 - 24:57]
that means whenever you are getting any

[24:55 - 24:59]
kinds of problem statement from the

[24:57 - 25:01]
company first of all break that problem

[24:59 - 25:03]
statement in a several sub problems okay

[25:01 - 25:05]
then try to solve one by one and to

[25:03 - 25:06]
solve that you have to perform some

[25:05 - 25:09]
steps okay you have to perform some

[25:06 - 25:10]
steps and those steps is called actually

[25:09 - 25:12]
pipelines okay pipelines inside

[25:10 - 25:14]
generative a now let's see one end to

[25:12 - 25:16]
end pipelines actually we have to follow

[25:14 - 25:18]
for all the projects we'll be developing

[25:16 - 25:20]
in Futures see in Genera pipeline we are

[25:18 - 25:22]
having these are the step we have to

[25:20 - 25:25]
follow the first step actually we have

[25:22 - 25:27]
to follow the data acquisition because

[25:25 - 25:29]
here data is everything right at the end

[25:27 - 25:31]
you have to work with the data here so

[25:29 - 25:33]
first of all you have to get the data

[25:31 - 25:35]
and this steps falls into data

[25:33 - 25:36]
acquisition part okay then after that

[25:35 - 25:39]
data acquisition we have to perform

[25:36 - 25:40]
something called Data preparation okay

[25:39 - 25:41]
what is data preparation I'll will let

[25:40 - 25:44]
you know that means here you will be

[25:41 - 25:45]
doing the cleaning of your data okay

[25:44 - 25:46]
after that you'll be starting with

[25:45 - 25:48]
something called feature

[25:46 - 25:50]
engineering inside feature engineering

[25:48 - 25:52]
there are so many steps you can follow

[25:50 - 25:53]
like so the main uh step actually will

[25:52 - 25:55]
be doing inside feature engineering

[25:53 - 25:57]
called text representation that means

[25:55 - 25:59]
you will represent your text to the

[25:57 - 26:01]
vector that means number so that your

[25:59 - 26:03]
model can take the input then after that

[26:01 - 26:04]
you'll be doing the modeling then you

[26:03 - 26:06]
have to select different different model

[26:04 - 26:08]
and you have to fit the data there okay

[26:06 - 26:10]
this is the idea after uh modeling what

[26:08 - 26:11]
you have to do we have to evaluate that

[26:10 - 26:13]
particular model Because unless and

[26:11 - 26:16]
until you are not evaluating the model

[26:13 - 26:17]
on top of test data you won't be able to

[26:16 - 26:20]
decide whether this particular model is

[26:17 - 26:23]
suitable for our production or not okay

[26:20 - 26:24]
then once let's say you got your uh

[26:23 - 26:27]
let's say production model what you can

[26:24 - 26:29]
do you can do the deployment deployment

[26:27 - 26:31]
of your model you can poost your model

[26:29 - 26:33]
so that other people can use your model

[26:31 - 26:35]
OKAY other user can use your model and

[26:33 - 26:37]
they can give the feedback okay based on

[26:35 - 26:38]
the feedback last step what you can do

[26:37 - 26:40]
you can perform monitoring and model

[26:38 - 26:42]
updating that means you have to monitor

[26:40 - 26:44]
you have to uh keep on monitoring your

[26:42 - 26:47]
application like uh I think you saw the

[26:44 - 26:49]
chart GPT right so previously I think

[26:47 - 26:50]
you saw in chart GPT whenever let's say

[26:49 - 26:52]
you are giving any kinds of prompt so it

[26:50 - 26:54]
will give you one actually let's say

[26:52 - 26:56]
input form it will tell you are you

[26:54 - 26:58]
enjoying this CH GPT or any kinds of

[26:56 - 27:00]
feedb feedback you want to give or not

[26:58 - 27:02]
not so they actually they were taking

[27:00 - 27:04]
the input in real time okay this is

[27:02 - 27:05]
called actually monitoring okay

[27:04 - 27:06]
monitoring their application that means

[27:05 - 27:08]
they're monitoring whether this

[27:06 - 27:10]
application is working fine or not in

[27:08 - 27:11]
the production if something going wrong

[27:10 - 27:13]
in the application if let's say user is

[27:11 - 27:15]
giving negative feedback that time what

[27:13 - 27:17]
they will do they will try to update

[27:15 - 27:19]
this model again okay this is the idea

[27:17 - 27:20]
so it's not like that you are only

[27:19 - 27:22]
building your model you are only

[27:20 - 27:24]
deploying your model it's not like that

[27:22 - 27:26]
you have to monitor the model in

[27:24 - 27:27]
production and based on the feedback you

[27:26 - 27:30]
have to keep on updating the model

[27:27 - 27:32]
itself okay this is the complete idea

[27:30 - 27:33]
and these are the steps involves inside

[27:32 - 27:36]
the generative VI pipeline I hope it is

[27:33 - 27:38]
clear now let's break down all the let's

[27:36 - 27:40]
say pipeline steps one by one and try to

[27:38 - 27:42]
understand what we have to do in each

[27:40 - 27:43]
and every step the first step was

[27:42 - 27:46]
actually

[27:43 - 27:48]
data acquisition so inside data

[27:46 - 27:51]
acquisition you can follow some step to

[27:48 - 27:52]
collect your data so the first thing you

[27:51 - 27:54]
have to check whether you have available

[27:52 - 27:58]
data or not so

[27:54 - 28:00]
available data available data means

[27:58 - 28:01]
let's say you are having a CSV file

[28:00 - 28:04]
directly you are having let's say text

[28:01 - 28:06]
file you are having let's say PDF

[28:04 - 28:08]
documents you are having docs documents

[28:06 - 28:10]
then you might also have something

[28:08 - 28:15]
called

[28:10 - 28:16]
Excel Excel SX okay H so if you have

[28:15 - 28:18]
these are the files apart from if you

[28:16 - 28:19]
have any other file format it's

[28:18 - 28:21]
completely fine but first of all you

[28:19 - 28:24]
have to check whether you have available

[28:21 - 28:25]
data or not okay this is the idea now if

[28:24 - 28:27]
you don't have the available data what

[28:25 - 28:29]
you have to do you have to look for

[28:27 - 28:33]
other data

[28:29 - 28:35]
okay other data other data means you can

[28:33 - 28:39]
collect the data from the

[28:35 - 28:41]
database you can see in the

[28:39 - 28:44]
internet whether someone is having the

[28:41 - 28:47]
data set or not then you can also use

[28:44 - 28:48]
the API let's say someone will give you

[28:47 - 28:50]
the data but you have to fix the data

[28:48 - 28:52]
through the API that time actually what

[28:50 - 28:55]
you can do you can collect the data from

[28:52 - 28:56]
the API itself okay then you have then

[28:55 - 28:59]
you can perform something called

[28:56 - 29:01]
scrapping that me web scrapping let's

[28:59 - 29:03]
say uh you don't have the data in

[29:01 - 29:05]
database internet API then what you can

[29:03 - 29:07]
do you can do the web web scrapping okay

[29:05 - 29:09]
we web scrapping means uh you'll be

[29:07 - 29:10]
scrapping the data from a website okay

[29:09 - 29:12]
this is the idea now there is another

[29:10 - 29:14]
possibility you have no data that time

[29:12 - 29:17]
what you will do okay that time what you

[29:14 - 29:21]
will do that time you have to create

[29:17 - 29:23]
your create your own data create your

[29:21 - 29:25]
own data means either you can collect

[29:23 - 29:27]
the data okay either you can do the

[29:25 - 29:29]
survey you can collect the data or what

[29:27 - 29:31]
you can do you can use large language

[29:29 - 29:33]
model to generate the data okay LM to

[29:31 - 29:35]
generate data nowadays actually you will

[29:33 - 29:41]
see people are using open AI okay open

[29:35 - 29:43]
AI GPT model OKAY GPT model to generate

[29:41 - 29:45]
the data okay so with the help of llm

[29:43 - 29:47]
also you can generate your own data but

[29:45 - 29:49]
whenever you are uh creating your own

[29:47 - 29:51]
data there is a possibility let's say uh

[29:49 - 29:54]
your data will be less let's say here I

[29:51 - 29:55]
will just write you have to note let's

[29:54 - 29:59]
say whenever you are collecting your own

[29:55 - 30:01]
data your data quantity might be less so

[29:59 - 30:05]
that time what you can do so let me

[30:01 - 30:09]
write here if you have less data then

[30:05 - 30:11]
you can perform data augmentation I

[30:09 - 30:13]
think you know what is data augmentation

[30:11 - 30:15]
okay so data augmentation is nothing but

[30:13 - 30:17]
you will be augmenting the data let's

[30:15 - 30:19]
say uh I'll give you one example so the

[30:17 - 30:21]
first augmentation technique you can

[30:19 - 30:24]
perform so let me give you the example

[30:21 - 30:27]
you can do something called replace you

[30:24 - 30:29]
can do replace with synonyms okay now

[30:27 - 30:32]
how to do the syon see let's say here is

[30:29 - 30:34]
one example I'll will give you let's say

[30:32 - 30:38]
I

[30:34 - 30:38]
am a data

[30:39 - 30:43]
scientist okay so let's say this is my

[30:42 - 30:46]
text now what you can do you can just

[30:43 - 30:46]
replace the

[30:46 - 30:55]
synonym so here you can write I am

[30:51 - 30:58]
a AI engineer that means you are

[30:55 - 31:00]
replacing this particular

[30:58 - 31:02]
uh entity with this entity so this is

[31:00 - 31:04]
called actually replace with synonyms

[31:02 - 31:06]
okay this is the idea I hope you got it

[31:04 - 31:08]
because here you will be working with

[31:06 - 31:10]
textual data mostly and if you have the

[31:08 - 31:11]
image that time what you can perform so

[31:10 - 31:13]
there are lots of image augmentation

[31:11 - 31:15]
technique as well let me show you so you

[31:13 - 31:18]
can simply search

[31:15 - 31:18]
image

[31:18 - 31:22]
augmentation so there are different

[31:20 - 31:25]
different technique you can follow see

[31:22 - 31:27]
let me show you one example let's say

[31:25 - 31:28]
let's say this is the example I can show

[31:27 - 31:30]
you let's say this is your original

[31:28 - 31:32]
image so what you can do you can do the

[31:30 - 31:34]
horizontal flip you can do the vertical

[31:32 - 31:36]
flip you can do the rotation of the

[31:34 - 31:38]
image you can also do the negative

[31:36 - 31:40]
rotation you can do the blower operation

[31:38 - 31:43]
you can change the brightness you can

[31:40 - 31:44]
add some noise you can add some darker

[31:43 - 31:46]
okay so that's how actually you can

[31:44 - 31:48]
change the original image okay you can

[31:46 - 31:49]
change the original image and make

[31:48 - 31:50]
different different variants okay this

[31:49 - 31:52]
is called actually image data

[31:50 - 31:55]
augmentation because I already told you

[31:52 - 31:56]
inside jni we use both kinds of data

[31:55 - 31:59]
whether it can be textual data it can be

[31:56 - 32:00]
image data it can be audio data okay

[31:59 - 32:04]
anything actually you can consider here

[32:00 - 32:07]
now the next technique you can uh apply

[32:04 - 32:07]
which is called diagram

[32:07 - 32:14]
flip Bagram flip now you can ask me sir

[32:12 - 32:16]
how to perform Bagram flip see it's very

[32:14 - 32:20]
easy let's say I'll give another

[32:16 - 32:23]
example uh I am

[32:20 - 32:28]
buppy all right now you can write this

[32:23 - 32:28]
sentence like that puppy

[32:28 - 32:33]
is my

[32:31 - 32:35]
name okay so this is called actually

[32:33 - 32:38]
Byram plate that's how actually you can

[32:35 - 32:40]
also do the data augmentation because at

[32:38 - 32:41]
the end you are increasing the data that

[32:40 - 32:44]
is the idea and whenever you are

[32:41 - 32:45]
increasing the data it should have the

[32:44 - 32:47]
meaning it doesn't have the meaning that

[32:45 - 32:49]
means there is no use of the data so you

[32:47 - 32:51]
have to make sure whenever you are

[32:49 - 32:54]
performing these are the technique this

[32:51 - 32:57]
data should have some meaning I hope you

[32:54 - 32:59]
getting my point now the next thing you

[32:57 - 33:00]
can perform third step you can perform

[32:59 - 33:03]
back

[33:00 - 33:06]
translate

[33:03 - 33:08]
back

[33:06 - 33:09]
translate now how to perform back

[33:08 - 33:12]
translate let me show you so let me go

[33:09 - 33:15]
to my uh

[33:12 - 33:17]
translator so I'll open the translator

[33:15 - 33:19]
Okay Google translator let's say here if

[33:17 - 33:23]
I write one sentence or I can just copy

[33:19 - 33:24]
one story let's say we whatever will do

[33:23 - 33:27]
let's say I will copy

[33:24 - 33:29]
this uh copy this text and here let me

[33:27 - 33:31]
paste it now you can see it is uh

[33:29 - 33:33]
translating to the Bengali now what I

[33:31 - 33:36]
will do I'll copy this Bengali transl

[33:33 - 33:38]
translation and here uh the input

[33:36 - 33:40]
language I'll be selecting the Bengali

[33:38 - 33:43]
right now so let me select the Bengali

[33:40 - 33:44]
and I can paste it here now here you can

[33:43 - 33:46]
select any other language let's say I'll

[33:44 - 33:49]
select Spanish now see Spanish text it

[33:46 - 33:52]
is giving now let me copy okay now what

[33:49 - 33:55]
I can do again uh I can come here I can

[33:52 - 33:57]
past the Spanish text and let's say I

[33:55 - 33:58]
want to convert to English again so here

[33:57 - 34:00]
let me select the English you got your

[33:58 - 34:02]
English text now so here if you see

[34:00 - 34:04]
carefully uh some of the word would be

[34:02 - 34:05]
different okay then your previous

[34:04 - 34:07]
actually text you have copied after

[34:05 - 34:10]
doing the Byram flip that means you will

[34:07 - 34:12]
be converting um it a language to

[34:10 - 34:15]
another language that language to

[34:12 - 34:17]
another language then uh again in your

[34:15 - 34:18]
English language so that's how if you do

[34:17 - 34:21]
multiple time translation you will see

[34:18 - 34:23]
some word would be changed and see this

[34:21 - 34:25]
this will work if you have actually lots

[34:23 - 34:27]
of text actually lots of sentence not

[34:25 - 34:29]
like that you are only copi one to two

[34:27 - 34:31]
line if you have multiple let's say line

[34:29 - 34:33]
multiple text that time actually the

[34:31 - 34:35]
reflection actually will able to see

[34:33 - 34:37]
okay I'm just only showing you how we

[34:35 - 34:39]
can perform the back translation because

[34:37 - 34:40]
there are so many um API nowadays inside

[34:39 - 34:42]
python you can use for the back

[34:40 - 34:44]
translate I think translation API is

[34:42 - 34:45]
already there with the help of that you

[34:44 - 34:47]
can do the translation first of all

[34:45 - 34:48]
let's say you have the English text

[34:47 - 34:50]
first of all try to translate to the

[34:48 - 34:52]
Hindi Hindi to let's say uh Spanish

[34:50 - 34:54]
Spanish to English again that's how you

[34:52 - 34:56]
can do the back translation and you can

[34:54 - 34:58]
increase the data so this is another

[34:56 - 35:00]
amazing data mentation technique you can

[34:58 - 35:02]
follow okay I hope you're cleared the

[35:00 - 35:04]
last step actually you can follow

[35:02 - 35:05]
something called add additional data or

[35:04 - 35:07]
additional noise how you can add

[35:05 - 35:12]
additional noise let's say here you have

[35:07 - 35:14]
one sentence I am a data scientist so

[35:12 - 35:18]
with this sentence you can add one more

[35:14 - 35:20]
line let's say uh I

[35:18 - 35:24]
love this

[35:20 - 35:26]
job okay so this is your additional data

[35:24 - 35:28]
or additional noise you have added okay

[35:26 - 35:30]
with your data again this is called

[35:28 - 35:32]
actually data augmentation technique and

[35:30 - 35:34]
again uh it's an amazing technique you

[35:32 - 35:36]
can follow okay Al together so these are

[35:34 - 35:38]
the step actually you can perform inside

[35:36 - 35:40]
data acquisition okay so first of all

[35:38 - 35:42]
try to check whether you have available

[35:40 - 35:45]
data or not if you don't have try to see

[35:42 - 35:47]
the other data if you don't have try to

[35:45 - 35:49]
uh create your own data for this you can

[35:47 - 35:50]
use large language model even I will I

[35:49 - 35:52]
will also show you how you can generate

[35:50 - 35:55]
your data with the help of large

[35:52 - 35:56]
language model and after generating

[35:55 - 35:58]
let's say if you have less amount of

[35:56 - 35:59]
data in that case you can perform

[35:58 - 36:01]
something called Data augmentation

[35:59 - 36:02]
technique inside data augmentation

[36:01 - 36:06]
technique these are the step you can

[36:02 - 36:08]
perform okay so this is the first step

[36:06 - 36:10]
of the pipeline now let's discuss the

[36:08 - 36:12]
second step of the pipeline okay the

[36:10 - 36:16]
Second Step I think you remember

[36:12 - 36:20]
data preprocessing so inside data

[36:16 - 36:22]
pre-processing you can perform cleanup

[36:20 - 36:24]
operation okay cleanup operation that

[36:22 - 36:29]
means you can remove

[36:24 - 36:32]
HTML tags then you can remove let's say

[36:29 - 36:34]
Emoji you can do the spelling check okay

[36:32 - 36:36]
spelling correction fine so these are

[36:34 - 36:38]
the technique actually you can perform

[36:36 - 36:40]
inside cleanup now there is another uh

[36:38 - 36:41]
step you can follow called basic

[36:40 - 36:43]
pre-processing I'll tell you what what

[36:41 - 36:44]
are the basics pre-processing are

[36:43 - 36:46]
available even I'll also show you the

[36:44 - 36:48]
Practical how you can perform then you

[36:46 - 36:50]
can also perform something called

[36:48 - 36:52]
Advanced preprocessing because nowadays

[36:50 - 36:54]
the application actually we have let's

[36:52 - 36:56]
say chat GPT Jin so these are the

[36:54 - 36:58]
actually Advanced application advanc

[36:56 - 37:00]
let's say large language model so for

[36:58 - 37:01]
this we have to also perform some

[37:00 - 37:04]
Advanced pre-processing technique okay

[37:01 - 37:06]
let's say whenever I'm having that data

[37:04 - 37:09]
nowadays because let me show

[37:06 - 37:12]
you let's say if I open my chat GPT okay

[37:09 - 37:15]
if I open the chat GPT see if I give any

[37:12 - 37:16]
kinds of emoji nowadays inside chat GPT

[37:15 - 37:19]
still it will be able to understand

[37:16 - 37:22]
let's say if I give this haha okay haha

[37:19 - 37:25]
let's Emoji now if I send it to my chat

[37:22 - 37:28]
GPT see it is automatically detecting

[37:25 - 37:30]
what's so funny okay so that's kinds of

[37:28 - 37:33]
a text also we need to handle because

[37:30 - 37:35]
whenever we are uh collecting the text

[37:33 - 37:38]
Data it will have emojis it will have

[37:35 - 37:40]
HML tags okay so many things it will

[37:38 - 37:43]
have so sometimes it is also necessary

[37:40 - 37:45]
to keep the Emojis because I told you

[37:43 - 37:46]
now this kinds of application is

[37:45 - 37:49]
Advanced so it is also understand the

[37:46 - 37:51]
Emojis any kinds of text so we also need

[37:49 - 37:54]
to handle these are the let's say uh I

[37:51 - 37:57]
mean text in that time now inside basic

[37:54 - 37:58]
speed processing let me just write here

[37:57 - 38:01]
inside

[37:58 - 38:03]
basic pre-processing so inside basic

[38:01 - 38:06]
pre-processing the very important things

[38:03 - 38:08]
you have to perform something called

[38:06 - 38:12]
tokenization okay so you have two kinds

[38:08 - 38:14]
of tokenization one is called sentence

[38:12 - 38:17]
level

[38:14 - 38:19]
tokenization other one is Word level

[38:17 - 38:20]
tokenization so I'll be discussing each

[38:19 - 38:22]
and everything no need to worry and

[38:20 - 38:24]
there are some optional pre-processing

[38:22 - 38:26]
are available so inside optional

[38:24 - 38:28]
pre-processing the first thing you can

[38:26 - 38:32]
perform stop word

[38:28 - 38:34]
removal okay stop word removal then the

[38:32 - 38:36]
second uh things you can perform

[38:34 - 38:38]
something called steaming and this is

[38:36 - 38:40]
like very less used nowadays okay less

[38:38 - 38:43]
used actually technique the third thing

[38:40 - 38:46]
you can perform something called latiz

[38:43 - 38:48]
and the lemmatization actually more

[38:46 - 38:50]
used more used okay I'll tell you what

[38:48 - 38:52]
is steaming LZ whenever I'll show the

[38:50 - 38:53]
Practical that time I'll discuss then

[38:52 - 38:55]
the

[38:53 - 38:57]
fourth uh things you can perform

[38:55 - 39:00]
something called punctuation removal so

[38:57 - 39:02]
punctuation means let's say you have uh

[39:00 - 39:04]
question symbol you have dot you have

[39:02 - 39:06]
comma you have uh exclamation sign okay

[39:04 - 39:08]
you have dollar symbol so these are the

[39:06 - 39:10]
things are actually punctuation so you

[39:08 - 39:11]
have to also handle the punctuation then

[39:10 - 39:14]
you have to perform something called

[39:11 - 39:15]
lower case then the sixth you can

[39:14 - 39:17]
perform something called language

[39:15 - 39:19]
detection because nowadays if you open

[39:17 - 39:21]
the chat GPT or gini if you give any

[39:19 - 39:23]
kinds of language it will first of all

[39:21 - 39:25]
detect in which language you are asking

[39:23 - 39:27]
the question B not that it will give you

[39:25 - 39:28]
the reply okay in the same language so

[39:27 - 39:30]
uh so they are also applying this

[39:28 - 39:32]
language detection technique okay in the

[39:30 - 39:34]
back end so that's actually one real

[39:32 - 39:35]
world product Implement okay it's not

[39:34 - 39:37]
like that you are getting the data you

[39:35 - 39:38]
are directly applying the model it's not

[39:37 - 39:40]
like that so you have to follow the

[39:38 - 39:42]
entire pipeline to build the endend

[39:40 - 39:44]
software okay that's why I'm showing you

[39:42 - 39:46]
these are the pipeline why this gen VI

[39:44 - 39:48]
pipeline is super important and what are

[39:46 - 39:50]
the steps are uh involved inside the

[39:48 - 39:52]
pipeline so that after learning it it

[39:50 - 39:54]
would be easy for you to develop any

[39:52 - 39:56]
kinds of software in future and this is

[39:54 - 39:58]
my promise if you understand this okay

[39:56 - 40:01]
if you can do this you can design any

[39:58 - 40:03]
kinds of software in future okay because

[40:01 - 40:04]
what is generative Genera is nothing but

[40:03 - 40:07]
just a technology so you have to use

[40:04 - 40:09]
that technology you have to learn how to

[40:07 - 40:10]
use the large language model how to

[40:09 - 40:13]
prepare the data for the large language

[40:10 - 40:15]
model okay how to use let's say Lang

[40:13 - 40:17]
chain how to use Vector database you

[40:15 - 40:18]
have to connect everything together then

[40:17 - 40:21]
you have to build one application that

[40:18 - 40:23]
is the idea only but the root things

[40:21 - 40:25]
available inside the pipeline how you're

[40:23 - 40:27]
designing the pipeline whether pipeline

[40:25 - 40:29]
has all the steps available or not I

[40:27 - 40:31]
hope you getting my point right so now I

[40:29 - 40:34]
think these are the steps are clear uh

[40:31 - 40:36]
but I think some of them still you are

[40:34 - 40:39]
getting confused like what is steaming

[40:36 - 40:40]
what is let's say LZ what is let's say

[40:39 - 40:43]
why we have to perform the lowercase

[40:40 - 40:45]
operation and what is this uh

[40:43 - 40:46]
tokenization see let me just discuss all

[40:45 - 40:48]
of them one by one so first of all let

[40:46 - 40:50]
me discuss the tokenization that means

[40:48 - 40:51]
let's see you are having a sentence here

[40:50 - 40:53]
let's say

[40:51 - 40:57]
my

[40:53 - 40:59]
name is buy so this is a cent right this

[40:57 - 41:01]
is a complete

[40:59 - 41:03]
sentence right so whenever I will be

[41:01 - 41:05]
converting this sentence to number that

[41:03 - 41:07]
means Vector representation first of all

[41:05 - 41:08]
I have to I have to actually do the

[41:07 - 41:11]
tokenization tokenization means you will

[41:08 - 41:17]
be uh taking the individual words let's

[41:11 - 41:22]
say like that my comma

[41:17 - 41:25]
name okay comma is

[41:22 - 41:25]
comma

[41:25 - 41:32]
buy this is called actually Word level

[41:28 - 41:34]
tokenization okay Word level

[41:32 - 41:36]
tokenization okay that means you had one

[41:34 - 41:39]
complete sentence you just did the

[41:36 - 41:41]
tokenization and you got the word as a

[41:39 - 41:43]
token okay everywhere now you can take

[41:41 - 41:44]
the word and you can convert to number

[41:43 - 41:45]
there is some technique we can follow

[41:44 - 41:47]
I'll tell you those are the technique

[41:45 - 41:48]
what are the technique you can follow to

[41:47 - 41:50]
convert your text to number

[41:48 - 41:52]
representation okay and there is another

[41:50 - 41:53]
technique called uh let's say sentence

[41:52 - 41:58]
level tokenization let's say you are

[41:53 - 42:01]
having a sentence like that let's say my

[41:58 - 42:01]
name is

[42:03 - 42:11]
bbby

[42:05 - 42:13]
uh I am a data scientist okay now if I

[42:11 - 42:15]
perform sentence level tokenization so

[42:13 - 42:19]
sentence wise actually I have to convert

[42:15 - 42:24]
so it will come like that my

[42:19 - 42:27]
name is buy so this is my one token then

[42:24 - 42:30]
comma then I

[42:27 - 42:33]
am a

[42:30 - 42:35]
data scientist okay this is another

[42:33 - 42:37]
token that means two token I'm having in

[42:35 - 42:38]
the list okay this is called actually

[42:37 - 42:41]
sentence level

[42:38 - 42:43]
tokenization sentence level tokenization

[42:41 - 42:45]
okay so we'll be using this word level

[42:43 - 42:47]
tokenization a lot sentence level you

[42:45 - 42:49]
can also use sometimes you have to use

[42:47 - 42:50]
sentence level tokenization sometimes

[42:49 - 42:52]
you'll be using Word level tokenization

[42:50 - 42:53]
but most of the application I saw people

[42:52 - 42:56]
are using what level tokenization that

[42:53 - 42:57]
is the idea so this is what actually our

[42:56 - 43:00]
tokenization okay

[42:57 - 43:02]
now let's try to understand what is

[43:00 - 43:04]
steaming see steaming is nothing but see

[43:02 - 43:05]
steaming is nothing but you are bringing

[43:04 - 43:07]
one word in a root form let's say here

[43:05 - 43:11]
we are having three kinds of

[43:07 - 43:14]
word play played and

[43:11 - 43:17]
playing so if you see them carefully

[43:14 - 43:19]
meaning are same yes or no meaning are

[43:17 - 43:21]
same only the ver representation is

[43:19 - 43:24]
different now instead of taking actually

[43:21 - 43:27]
three okay separately what I can do I

[43:24 - 43:29]
can um convert in a root form so root

[43:27 - 43:34]
form is nothing but

[43:29 - 43:34]
play okay because player represents

[43:34 - 43:41]
Sports okay Sports so this is called

[43:38 - 43:43]
actually Ste steaming that means you

[43:41 - 43:45]
have different different uh actually

[43:43 - 43:47]
word form that means different different

[43:45 - 43:49]
V form and you are trying to bring in a

[43:47 - 43:51]
root representation okay this is called

[43:49 - 43:54]
actually uh steaming and again it's

[43:51 - 43:56]
important because it will reduce the

[43:54 - 43:57]
dimension okay it will reduce the

[43:56 - 43:58]
dimension whenever let's say will be

[43:57 - 44:00]
converting your data to the vector

[43:58 - 44:02]
representation because if you have three

[44:00 - 44:04]
word so it will create actually three

[44:02 - 44:08]
dimensions separately but if you convert

[44:04 - 44:09]
it to one let's say word only so it will

[44:08 - 44:11]
only have one dimensional and we know

[44:09 - 44:13]
that inside artificial intelligence

[44:11 - 44:16]
Dimension is like the issue so if you

[44:13 - 44:18]
have let's say more Dimension that time

[44:16 - 44:19]
your model will get confused because

[44:18 - 44:21]
there is a concept of curs of

[44:19 - 44:23]
dimensionality so you have to also take

[44:21 - 44:26]
care about the dimension okay that's why

[44:23 - 44:29]
we perform this streamming operation and

[44:26 - 44:32]
LZ is the same okay the way actually

[44:29 - 44:34]
perform the steaming LZ is also same

[44:32 - 44:37]
only whenever you will perform the LZ

[44:34 - 44:39]
your root meaning of the word would be

[44:37 - 44:41]
readable but whenever you will perform

[44:39 - 44:42]
actually let's say streaming sometimes

[44:41 - 44:44]
it won't be readable I'll tell you

[44:42 - 44:46]
whenever I'll do the Practical of it

[44:44 - 44:48]
that time actually will get it okay what

[44:46 - 44:50]
I'm trying to say that is the idea now

[44:48 - 44:52]
you can ask me what is lower casing okay

[44:50 - 44:55]
because fation you already know now you

[44:52 - 44:56]
can ask me why lower casing is important

[44:55 - 45:00]
why you have to perform the lower case

[44:56 - 45:02]
operation let's say if I write two

[45:00 - 45:05]
sentence

[45:02 - 45:10]
buppy is

[45:05 - 45:10]
very good boy and

[45:10 - 45:17]
buppy is a data scientist let's say

[45:15 - 45:21]
these kinds of sentence we are having

[45:17 - 45:23]
now here you can see I think buy and buy

[45:21 - 45:25]
both name are same but here you can see

[45:23 - 45:28]
the first character it's a Capital One

[45:25 - 45:31]
the second character it's a l one so as

[45:28 - 45:33]
a human actually you can consider these

[45:31 - 45:35]
two buy are same but whenever you will

[45:33 - 45:37]
be passing to the model that means in

[45:35 - 45:38]
your computer your computer will be

[45:37 - 45:41]
considering this two word is a different

[45:38 - 45:43]
word because here you are using capital

[45:41 - 45:44]
and here you using lowercase character

[45:43 - 45:46]
because all the character is having

[45:44 - 45:49]
their asky value right that means the

[45:46 - 45:50]
asky code uni code so with the help of

[45:49 - 45:53]
that it will consider these two words

[45:50 - 45:54]
are separate so that time this bu would

[45:53 - 45:56]
be different this bu would be different

[45:54 - 45:58]
although they are same okay this is

[45:56 - 45:59]
another issue so that's why we perform

[45:58 - 46:01]
lower case operation so whenever

[45:59 - 46:02]
actually we're having the upper case

[46:01 - 46:06]
we'll try to convert to the lower case

[46:02 - 46:08]
okay we'll try to convert so let me show

[46:06 - 46:11]
you we'll try to convert to the lower

[46:08 - 46:13]
case Okay so this is now you can see

[46:11 - 46:14]
this buy and this buppy will become same

[46:13 - 46:16]
okay now if you give pass to the

[46:14 - 46:18]
computer also your computer will

[46:16 - 46:20]
identify this buy and this buy is the

[46:18 - 46:22]
same right now okay so that's why we

[46:20 - 46:25]
perform the lowercase operation so that

[46:22 - 46:26]
my model won't be getting the confused

[46:25 - 46:29]
okay this is the idea so I think most of

[46:26 - 46:30]
the things I clarified and yeah so

[46:29 - 46:31]
everything I'll show you as a practical

[46:30 - 46:34]
as well how we can perform as a

[46:31 - 46:35]
practical I'll tell I'll discuss it okay

[46:34 - 46:37]
no need to worry now apart from basic

[46:35 - 46:39]
pre-processing I also told you we have

[46:37 - 46:40]
something called uh Advanced

[46:39 - 46:42]
preprocessing as well now let's try to

[46:40 - 46:44]
see what are the steps are involved

[46:42 - 46:47]
inside Advan preprocessing see inside

[46:44 - 46:49]
advance

[46:47 - 46:52]
preprocessing

[46:49 - 46:58]
advance pre-processing we have something

[46:52 - 46:58]
called parts of space tagging parts of

[46:58 - 47:02]
speech tagging so if you're good with

[47:00 - 47:04]
English grammar I think you know what is

[47:02 - 47:07]
parts of speech okay then you are also

[47:04 - 47:09]
having something called parsing then you

[47:07 - 47:12]
have something called Co reference okay

[47:09 - 47:13]
Co reference resolution now if you want

[47:12 - 47:15]
to understand them let me show you one

[47:13 - 47:17]
uh image I think then this part would be

[47:15 - 47:21]
cleared so guys I think you can see this

[47:17 - 47:23]
image so here you can see uh this is the

[47:21 - 47:25]
um input text we are having chaplain

[47:23 - 47:28]
wrote directed and composed the music of

[47:25 - 47:30]
uh for the most of is film now if I

[47:28 - 47:31]
perform tokenization and LZ so I already

[47:30 - 47:33]
told you what is tokenization you will

[47:31 - 47:35]
be taking individual word see I have

[47:33 - 47:38]
taken individual word here and if you

[47:35 - 47:41]
perform the LZ LZ means it will bring

[47:38 - 47:43]
the uh let's say any kinds of verb in a

[47:41 - 47:45]
root word now we can see root root if I

[47:43 - 47:48]
bring to the root what it will be right

[47:45 - 47:49]
directed it would be direct okay then

[47:48 - 47:52]
compost it would be compos it would be

[47:49 - 47:55]
compos so that's how actually you can

[47:52 - 47:57]
understand the tokenization and LZ now

[47:55 - 47:59]
what is po is tagging P tagging means

[47:57 - 48:01]
parts of spe tagging the things I showed

[47:59 - 48:02]
you in my Advan preprocessing so this is

[48:01 - 48:04]
what actually parts of spe tagging that

[48:02 - 48:06]
means you are assigning what is noun

[48:04 - 48:07]
what is verb what is adjective okay so

[48:06 - 48:10]
that's how you are defining different

[48:07 - 48:11]
kinds of part parts of speech if you're

[48:10 - 48:13]
good with grammar I think you will be

[48:11 - 48:15]
understanding better than me uh just try

[48:13 - 48:17]
to consider here you are uh tagging

[48:15 - 48:19]
everything that means you are tagging

[48:17 - 48:21]
all the let's say noun verb okay then

[48:19 - 48:23]
pronoun everything you are tagging now

[48:21 - 48:25]
there is another one called parsing okay

[48:23 - 48:26]
I think I showed you parsing so this is

[48:25 - 48:28]
the parsing tree that means you will be

[48:26 - 48:29]
creating a tree and inside this tree you

[48:28 - 48:31]
will have the entire sentence word you

[48:29 - 48:33]
can see chaplain Road directed okay all

[48:31 - 48:35]
the words so in the parts three you will

[48:33 - 48:38]
be again assigning the POS tagging apart

[48:35 - 48:39]
from that you will be also dividing

[48:38 - 48:40]
these are the word in a separate

[48:39 - 48:43]
separate

[48:40 - 48:45]
form again this is a advanc actually

[48:43 - 48:47]
grammatical rules uh you have to learn

[48:45 - 48:48]
but no need to worry let's say when will

[48:47 - 48:50]
be working in the industry there you

[48:48 - 48:52]
will have something called domain

[48:50 - 48:54]
expertise okay let's say language

[48:52 - 48:56]
expertise actually people will get so

[48:54 - 48:58]
they will help you to do it because I

[48:56 - 49:00]
know as a developer you know you don't

[48:58 - 49:02]
know about let's say uh this English

[49:00 - 49:04]
grammar and all but whenever you'll be

[49:02 - 49:05]
designing the software that time

[49:04 - 49:07]
language expert will help you okay how

[49:05 - 49:09]
we can perform the pursing how we can

[49:07 - 49:11]
perform the P tagging everything they

[49:09 - 49:13]
will help you out now this is the last

[49:11 - 49:14]
example core reference resolution so cor

[49:13 - 49:17]
reference resolution means let's say

[49:14 - 49:19]
Chaplin wrote directed and composed the

[49:17 - 49:22]
music for the most of his film now here

[49:19 - 49:23]
chaplain and his it is indicating the

[49:22 - 49:25]
both person uh sorry it is indicating

[49:23 - 49:26]
the same person right so this is called

[49:25 - 49:28]
actually core reference resolution

[49:26 - 49:32]
Solutions sometimes you your model has

[49:28 - 49:33]
to understand uh this Chap and his so it

[49:32 - 49:35]
is mentioning the both uh it is

[49:33 - 49:36]
mentioning the same person okay so this

[49:35 - 49:37]
is called actually core reference

[49:36 - 49:39]
resolution because nowadays if you see

[49:37 - 49:41]
the chat GPD G so these kinds of

[49:39 - 49:44]
application is able to understand okay

[49:41 - 49:45]
this kinds of input disc kind of prompt

[49:44 - 49:47]
okay so in the back end actually they're

[49:45 - 49:51]
handling like that I hope it is clear

[49:47 - 49:54]
now then the third actually step were

[49:51 - 49:58]
available inside uh gen pipeline which

[49:54 - 50:02]
is nothing but feature engineer

[49:58 - 50:05]
ing feature engineering so inside

[50:02 - 50:08]
feature engineering you can perform

[50:05 - 50:10]
text

[50:08 - 50:11]
vectorization so to perform the text

[50:10 - 50:14]
vectorization you can follow some

[50:11 - 50:17]
technique like uh you have

[50:14 - 50:22]
tfidf

[50:17 - 50:22]
tfidf you have something called bag

[50:23 - 50:28]
oford you have something called word to

[50:30 - 50:33]
you can also perform something called

[50:31 - 50:33]
one not

[50:33 - 50:39]
encoding then you can also use some

[50:36 - 50:42]
Transformer okay Transformers model to

[50:39 - 50:44]
perform the text vectorization as well

[50:42 - 50:46]
because these are the very old technique

[50:44 - 50:47]
so if you're using any deep learning and

[50:46 - 50:49]
machine learning model that time you can

[50:47 - 50:51]
use these are the technique but if you

[50:49 - 50:53]
are creating advanc application like

[50:51 - 50:55]
let's if we using large language model

[50:53 - 50:57]
Transformer based architecture like say

[50:55 - 50:58]
encoder and decoder architecture

[50:57 - 51:01]
that time you have to use Transformer

[50:58 - 51:03]
model to perform the text vectorization

[51:01 - 51:04]
technique okay I hope it is clear so

[51:03 - 51:07]
these are the steps are available inside

[51:04 - 51:08]
feature engineering so inside feature

[51:07 - 51:10]
engineering you'll just try to convert

[51:08 - 51:13]
your text to Vector representation it

[51:10 - 51:15]
can be also uh work with the image as

[51:13 - 51:16]
well let's say you are having an image

[51:15 - 51:17]
okay let's say you having an image and

[51:16 - 51:20]
in that image actually you are having a

[51:17 - 51:23]
cat image let's say this is a

[51:20 - 51:26]
cat let this is a cat okay now image is

[51:23 - 51:28]
nothing but it's a pixel so if you just

[51:26 - 51:29]
see the image so here you will see

[51:28 - 51:31]
different different pixel value okay

[51:29 - 51:32]
different different pixel value so that

[51:31 - 51:34]
time what you can do you can use any

[51:32 - 51:35]
kinds of vision Transformer model to

[51:34 - 51:37]
convert this image to the vector

[51:35 - 51:38]
representation okay Vector

[51:37 - 51:41]
representation and you can pass to the

[51:38 - 51:44]
model okay so that is the idea now

[51:41 - 51:46]
fourth step actually I think you

[51:44 - 51:47]
saw after feature engineering you can do

[51:46 - 51:50]
the

[51:47 - 51:52]
modeling okay modeling modeling means

[51:50 - 51:53]
you have you'll be training the model

[51:52 - 51:55]
that means uh you'll fit the data to the

[51:53 - 51:59]
model okay so here you can choose

[51:55 - 52:01]
different model you can choose actually

[51:59 - 52:03]
different kinds of model so here you can

[52:01 - 52:07]
either use open

[52:03 - 52:09]
source okay open source LM that means

[52:07 - 52:13]
large language model either you can use

[52:09 - 52:15]
paid one okay paid paid

[52:13 - 52:18]
model

[52:15 - 52:19]
so so what is the difference between

[52:18 - 52:21]
open source and paid see if you're using

[52:19 - 52:24]
paid see if you're using paid one this

[52:21 - 52:25]
model would be available in the server

[52:24 - 52:27]
that means you don't need to download

[52:25 - 52:28]
this model in your machine okay so you

[52:27 - 52:31]
don't need to download instead of that

[52:28 - 52:32]
what you will do you will only let's say

[52:31 - 52:34]
pass the data okay let's say you are

[52:32 - 52:36]
using open a because I think you know

[52:34 - 52:38]
opena provides actually paid model

[52:36 - 52:40]
that's a GPT model so in opena you will

[52:38 - 52:42]
upload your data and in their server it

[52:40 - 52:44]
will train the model okay you don't need

[52:42 - 52:46]
to download the model in your machine

[52:44 - 52:47]
and you don't need to train there

[52:46 - 52:50]
because I know that people onlyon be

[52:47 - 52:52]
having good GPU in their system okay

[52:50 - 52:54]
it's not possible actually to buy uh

[52:52 - 52:55]
expensive GPU for training these are

[52:54 - 52:57]
kinds of large language model because if

[52:55 - 52:59]
you see this large language it's very

[52:57 - 53:01]
huge okay if you see the parameter size

[52:59 - 53:03]
is very huge so we can't download in our

[53:01 - 53:05]
machine and we can't train it it's not

[53:03 - 53:07]
possible so that's why most of the time

[53:05 - 53:09]
we'll be using Cloud platform to train

[53:07 - 53:11]
the model okay so that time actually you

[53:09 - 53:12]
can use the paid model because paid

[53:11 - 53:13]
model if you're using paid platform if

[53:12 - 53:15]
you're using everything they will take

[53:13 - 53:17]
care only you have to upload your data

[53:15 - 53:19]
there but if using open source large

[53:17 - 53:21]
language model that time you have to

[53:19 - 53:22]
download this model in your machine you

[53:21 - 53:23]
have to prepare everything you have to

[53:22 - 53:25]
set up the environment and then you have

[53:23 - 53:30]
to train the model and for this you need

[53:25 - 53:33]
a good GPU okay good GPU good CPU good

[53:30 - 53:34]
memory okay everything you need and

[53:33 - 53:38]
after training this model you have to

[53:34 - 53:39]
deploy this model uh in a cloud platform

[53:38 - 53:41]
okay manually you have to deploy this

[53:39 - 53:43]
model in a cloud platform and again you

[53:41 - 53:45]
will get the challenges there like uh

[53:43 - 53:46]
you have to buy a good instance then you

[53:45 - 53:48]
have to set up the load balancing and

[53:46 - 53:49]
all okay then you have to deploy this

[53:48 - 53:52]
particular model but if you're using

[53:49 - 53:54]
Cloud platform they directly will get

[53:52 - 53:55]
one option to deploy the model in their

[53:54 - 53:57]
server only okay so that people can

[53:55 - 53:59]
access the model in their platform only

[53:57 - 54:01]
okay so you don't need to take care

[53:59 - 54:02]
about the infrastructure you don't need

[54:01 - 54:04]
to take care about the instance

[54:02 - 54:06]
everything they will take care that is

[54:04 - 54:08]
the difference got it we'll be also

[54:06 - 54:09]
understanding how we can use paid model

[54:08 - 54:11]
how we can use open source model and I

[54:09 - 54:12]
will also discuss the difficulty level

[54:11 - 54:14]
actually we'll be getting whenever

[54:12 - 54:15]
you'll be using open source llm whenever

[54:14 - 54:17]
you will be using let's say paid llm

[54:15 - 54:19]
everything I'll try to clarify no need

[54:17 - 54:22]
to worry uh train your model you have to

[54:19 - 54:22]
perform something called Model

[54:22 - 54:26]
evaluation okay evaluation so inside

[54:25 - 54:29]
evaluation you have to part from two

[54:26 - 54:35]
kinds of evaluation one is like

[54:29 - 54:39]
inin evaluation other is like extrinsic

[54:35 - 54:42]
evaluation so intrinsic Evolution

[54:39 - 54:43]
means you'll be using some

[54:42 - 54:45]
metrics okay you'll be using some

[54:43 - 54:47]
metrics to evaluate the model I think

[54:45 - 54:48]
you know we are having different

[54:47 - 54:50]
different metrics for the evaluation let

[54:48 - 54:52]
we are having accuracy score R2 score

[54:50 - 54:53]
then we are having AOC card so these are

[54:52 - 54:56]
the different different metrics we are

[54:53 - 54:57]
having okay so after trading a model you

[54:56 - 54:59]
have to perform something called

[54:57 - 55:01]
intrinsic evaluation and this is

[54:59 - 55:03]
performed by the and this evaluation

[55:01 - 55:07]
will perform by the jna engineer okay

[55:03 - 55:09]
jna engineer because they training the

[55:07 - 55:11]
model and after training the model they

[55:09 - 55:13]
have to actually uh evaluate the model

[55:11 - 55:16]
with the help of these are the matrixes

[55:13 - 55:18]
and the extensive evaluation when they

[55:16 - 55:20]
have to perform after doing the

[55:18 - 55:23]
deployment okay after doing the

[55:20 - 55:25]
deployment deployment so this uh

[55:23 - 55:27]
evaluation can be applied during the

[55:25 - 55:29]
production okay let's say whenever this

[55:27 - 55:31]
model is in the production people are

[55:29 - 55:33]
using it that time this extensive

[55:31 - 55:36]
evaluation can be performed let's say I

[55:33 - 55:39]
already told you chat GPT will uh launch

[55:36 - 55:41]
one input sometimes it will uh ask you

[55:39 - 55:43]
give the feedback not only chat GPT if

[55:41 - 55:45]
you see any kinds of application so if

[55:43 - 55:47]
you just consider your phone keyboard so

[55:45 - 55:49]
whenever you use the keyboard okay so

[55:47 - 55:50]
initially I think you won't be getting

[55:49 - 55:53]
any of suggestion but whenever you will

[55:50 - 55:55]
be using that particular keyboard okay

[55:53 - 55:56]
um long time then you will see that

[55:55 - 55:58]
automatically you will get the

[55:56 - 56:00]
suggestion because it is learning okay

[55:58 - 56:01]
how what kinds of input you are giving

[56:00 - 56:03]
it is learning and sometimes it will ask

[56:01 - 56:06]
for one kinds of feedback whether you

[56:03 - 56:07]
are enjoying this app or not okay any

[56:06 - 56:09]
feedback you want to give or not and

[56:07 - 56:10]
whenever you are giving the feedback

[56:09 - 56:11]
whenever you are giving the five rating

[56:10 - 56:13]
four rating that time so that time

[56:11 - 56:15]
actually they're getting this

[56:13 - 56:16]
application is working fine there is no

[56:15 - 56:18]
issue but whenever you are giving

[56:16 - 56:20]
negative feedback that time they're

[56:18 - 56:22]
getting actually there is some issue

[56:20 - 56:24]
with the application that time what they

[56:22 - 56:25]
will do again they will they will uh

[56:24 - 56:26]
retain the model okay they will retain

[56:25 - 56:28]
the model

[56:26 - 56:29]
and they will again push the model

[56:28 - 56:32]
through the production okay so that's

[56:29 - 56:34]
how extensive Evolution works that means

[56:32 - 56:36]
after deployment after uh going to the

[56:34 - 56:37]
production okay after going to the

[56:36 - 56:38]
production of that model you will be

[56:37 - 56:40]
performing this particular extensive

[56:38 - 56:44]
evaluation this is the idea and the

[56:40 - 56:47]
sixth I told you we have to perform

[56:44 - 56:49]
deployment okay deployment and inside

[56:47 - 56:53]
deployment you will be also doing the

[56:49 - 56:53]
monitoring monitoring and

[56:54 - 56:58]
retraining okay retraining

[56:58 - 57:02]
because you'll be doing the monitoring

[57:00 - 57:04]
in the extensive evaluation and if

[57:02 - 57:06]
something going wrong you'll be doing

[57:04 - 57:08]
the rning of the model this is the idea

[57:06 - 57:10]
so these things are involved inside so

[57:08 - 57:12]
the entire generative AI pipeline I hope

[57:10 - 57:15]
it is clear so first of all data

[57:12 - 57:17]
acquisation then uh data preparation

[57:15 - 57:19]
then uh feature engineering modeling

[57:17 - 57:21]
evaluation and deployment and here one

[57:19 - 57:23]
thing you have to remember because going

[57:21 - 57:25]
forward I'll be using this Trum a lot so

[57:23 - 57:27]
let me just write here common Trum let

[57:25 - 57:30]
me call copy this

[57:27 - 57:32]
text and let me paste here let's say

[57:30 - 57:34]
this is my data now here you will see

[57:32 - 57:37]
some of the actually let's say common

[57:34 - 57:41]
term the first ter actually we'll

[57:37 - 57:44]
see uh called

[57:41 - 57:48]
cordus okay Corpus then the second term

[57:44 - 57:48]
you will see which is nothing but

[57:49 - 57:53]
vocabulary and the third term you will

[57:51 - 57:53]
see which is nothing but

[57:54 - 57:59]
documents and the fourth you will see

[57:56 - 58:01]
something called word okay word now what

[57:59 - 58:03]
is Corpus Corpus is nothing but the

[58:01 - 58:06]
entire

[58:03 - 58:09]
text entire text that means the entire

[58:06 - 58:12]
text is called Corpus okay and what is

[58:09 - 58:12]
vocabulary unique

[58:13 - 58:19]
word unique word now you can see this is

[58:18 - 58:22]
unique word this is unique word this is

[58:19 - 58:24]
unique word this un this un okay so

[58:22 - 58:25]
these are the uh what is unique and if

[58:24 - 58:26]
you see any of the word is coming

[58:25 - 58:27]
duplicates only you have to take the

[58:26 - 58:30]
unique word okay this is called actually

[58:27 - 58:32]
vocable okay then what is documents

[58:30 - 58:34]
document is nothing but one row that

[58:32 - 58:37]
means one line only so till here

[58:34 - 58:41]
actually one documents D1 then this is

[58:37 - 58:43]
called actually D2 okay D2 then D3 so

[58:41 - 58:46]
this is called actually documents so I

[58:43 - 58:49]
can write one line okay one line is the

[58:46 - 58:53]
documents okay or one row and what is

[58:49 - 58:56]
what what is n this

[58:53 - 58:57]
single word okay single word is called

[58:56 - 58:58]
word so you can see this is a single

[58:57 - 59:00]
word is a single word this called

[58:58 - 59:01]
actually word so these are the common

[59:00 - 59:03]
term you have to remember because going

[59:01 - 59:05]
forward whenever we'll be actually

[59:03 - 59:07]
playing with the data that time actually

[59:05 - 59:08]
I may um tell you these are the actually

[59:07 - 59:10]
common term okay that time you won't be

[59:08 - 59:11]
getting confused what is corus what is

[59:10 - 59:13]
vocabulary what is documents what is

[59:11 - 59:15]
what okay that's time so that's why I

[59:13 - 59:16]
showed you okay here in this video so

[59:15 - 59:19]
yes Guys these are the actually

[59:16 - 59:21]
generative VI Pipeline and uh here I

[59:19 - 59:22]
have just showed you as a theoretical so

[59:21 - 59:24]
in the next video we'll be doing the

[59:22 - 59:25]
Practical of it like how we can perform

[59:24 - 59:27]
different different text cleaning

[59:25 - 59:28]
technique like different different text

[59:27 - 59:30]
pre-processing technique after that

[59:28 - 59:31]
we'll also see how we can perform

[59:30 - 59:32]
feature engineering technique as well

[59:31 - 59:33]
okay different different feature

[59:32 - 59:35]
engineering technique because what I

[59:33 - 59:37]
feel like before starting with our large

[59:35 - 59:38]
language model first of all we have to

[59:37 - 59:40]
understand the data first of all we have

[59:38 - 59:41]
to know how to prepare the data for the

[59:40 - 59:43]
model okay then we'll be starting with

[59:41 - 59:46]
the large language model okay so this

[59:43 - 59:48]
thing actually is uh so this uh thing

[59:46 - 59:50]
actually very important before learning

[59:48 - 59:52]
uh your gen before learning the large

[59:50 - 59:54]
language model and application building

[59:52 - 59:56]
so that's why I'm teaching you this part

[59:54 - 59:58]
uh in our previous video I already

[59:56 - 01:00:00]
discussed about end to end generate TBI

[59:58 - 01:00:02]
pipeline so there I told you what is the

[01:00:00 - 01:00:04]
use of data preprocessing right because

[01:00:02 - 01:00:06]
if you want to use the model that means

[01:00:04 - 01:00:08]
large language model the first thing you

[01:00:06 - 01:00:09]
have to do the data P processing Because

[01:00:08 - 01:00:12]
unless and until you are not processing

[01:00:09 - 01:00:13]
the data how your model will try to

[01:00:12 - 01:00:15]
understand that one right that is the

[01:00:13 - 01:00:17]
idea so here we'll be learning various

[01:00:15 - 01:00:19]
kinds of technique uh to clean up about

[01:00:17 - 01:00:22]
data so for this what I have done I have

[01:00:19 - 01:00:24]
created a beautiful uh collab notebook

[01:00:22 - 01:00:26]
so there actually I have uh added all

[01:00:24 - 01:00:28]
the examples you can uh use for the data

[01:00:26 - 01:00:29]
cleanup operation so guys now let's try

[01:00:28 - 01:00:31]
to see how we can do the data

[01:00:29 - 01:00:33]
preprocessing part so guys as you can

[01:00:31 - 01:00:35]
see this is The Notebook I already

[01:00:33 - 01:00:38]
prepared so here you can see I'm using

[01:00:35 - 01:00:39]
one data set uh from kagle so let me

[01:00:38 - 01:00:43]
open the

[01:00:39 - 01:00:45]
link um this is the link so the data set

[01:00:43 - 01:00:48]
name is IMDb uh data set and it is

[01:00:45 - 01:00:50]
having actually 50k uh movie reviews

[01:00:48 - 01:00:51]
okay 50k actually movie reviews if you

[01:00:50 - 01:00:53]
are already from let's say machine

[01:00:51 - 01:00:55]
learning deep learning background I

[01:00:53 - 01:00:57]
think you know about this data set right

[01:00:55 - 01:00:58]
it's like very common data set and why I

[01:00:57 - 01:01:00]
took this particular data set because in

[01:00:58 - 01:01:03]
this data set you will see uh there are

[01:01:00 - 01:01:05]
so many U actually unnecessary text okay

[01:01:03 - 01:01:07]
because it's a movie review so what they

[01:01:05 - 01:01:09]
did actually they extracted they scra

[01:01:07 - 01:01:12]
this data from the IMDb website if you

[01:01:09 - 01:01:14]
don't know this is the IMDB website IMDb

[01:01:12 - 01:01:16]
so in this website you will see uh all

[01:01:14 - 01:01:18]
the movies reviews and rating and what

[01:01:16 - 01:01:20]
they did actually they published this

[01:01:18 - 01:01:22]
data set in the Kagel website so that if

[01:01:20 - 01:01:24]
anyone is working in the field of let's

[01:01:22 - 01:01:27]
say genv or natural language processing

[01:01:24 - 01:01:28]
they can use the data set it now here

[01:01:27 - 01:01:30]
what you just need to do you just need

[01:01:28 - 01:01:33]
to download this data okay it's around

[01:01:30 - 01:01:35]
uh I think 27 MB just click on download

[01:01:33 - 01:01:37]
button it will download okay so I

[01:01:35 - 01:01:38]
already downloaded this data set so it

[01:01:37 - 01:01:40]
is available inside my download folder

[01:01:38 - 01:01:42]
so I'm going to upload in my collab

[01:01:40 - 01:01:43]
notebook so here first of all what you

[01:01:42 - 01:01:45]
have to do you have to connect this

[01:01:43 - 01:01:46]
particular notebook so there is a

[01:01:45 - 01:01:48]
connect button just try to connect and

[01:01:46 - 01:01:50]
no need to worry I will also share this

[01:01:48 - 01:01:52]
notebook Link in the resources section

[01:01:50 - 01:01:55]
from there you can open it up so my

[01:01:52 - 01:01:57]
notebook is connected so first of all

[01:01:55 - 01:01:58]
let's import some of the library first

[01:01:57 - 01:02:00]
of all I need something called pandas

[01:01:58 - 01:02:03]
because if you see the data uh it's a

[01:02:00 - 01:02:04]
csb data okay it's a csb data so let me

[01:02:03 - 01:02:06]
upload and let me show you so if you

[01:02:04 - 01:02:07]
want to upload anything in the Google

[01:02:06 - 01:02:09]
Drive just try to right click and there

[01:02:07 - 01:02:12]
is a upload button click on upload and

[01:02:09 - 01:02:15]
try to upload this data

[01:02:12 - 01:02:17]
here now see it's a CSV file okay and if

[01:02:15 - 01:02:20]
I want to load any kinds of CSV file

[01:02:17 - 01:02:22]
Json file or let's Excel file whatever

[01:02:20 - 01:02:24]
file you can use the pandas package for

[01:02:22 - 01:02:27]
that so you can see my data set is

[01:02:24 - 01:02:28]
uploaded now if I want to load the data

[01:02:27 - 01:02:30]
set what I have to do I have to assign

[01:02:28 - 01:02:32]
the path and see you don't need to

[01:02:30 - 01:02:34]
execute deser the code because uh this

[01:02:32 - 01:02:36]
code I have added let's say if your data

[01:02:34 - 01:02:37]
set is available in your Google Drive

[01:02:36 - 01:02:39]
that time what you have to do you have

[01:02:37 - 01:02:40]
to Mount Your Google Drive first of all

[01:02:39 - 01:02:42]
Mount means you will be connecting with

[01:02:40 - 01:02:44]
your Google Drive then will'll be

[01:02:42 - 01:02:46]
relocating the folder okay like inside

[01:02:44 - 01:02:47]
which folder you kept your data okay

[01:02:46 - 01:02:50]
with the help of CD command CD means

[01:02:47 - 01:02:51]
change directory okay then after that

[01:02:50 - 01:02:53]
what he will do he will assign the data

[01:02:51 - 01:02:55]
path but here I haven't kept my data

[01:02:53 - 01:02:58]
inside my Google Drive I kept inside my

[01:02:55 - 01:03:00]
col collab actually you can see drive

[01:02:58 - 01:03:02]
this is the collab disc I'm using here

[01:03:00 - 01:03:05]
you will get around 74 GB of space so

[01:03:02 - 01:03:07]
here you also you can keep your data so

[01:03:05 - 01:03:09]
I don't need to execute this code what I

[01:03:07 - 01:03:11]
will do I'll just go below and if I

[01:03:09 - 01:03:14]
check my current working directory that

[01:03:11 - 01:03:15]
means PWD you'll see I'm inside content

[01:03:14 - 01:03:17]
content means this is the directory

[01:03:15 - 01:03:20]
right now now here I'll just simply

[01:03:17 - 01:03:23]
Define my data path I'll copy the path

[01:03:20 - 01:03:27]
copy and let me paste it here okay

[01:03:23 - 01:03:30]
that's it now let me

[01:03:27 - 01:03:32]
execute now see if I now load the data

[01:03:30 - 01:03:35]
pd. csb I'm doing now see it will load

[01:03:32 - 01:03:38]
the data see it has loaded the data if

[01:03:35 - 01:03:40]
you want to see the shape of the data

[01:03:38 - 01:03:43]
this is the shape okay you have around

[01:03:40 - 01:03:45]
50 uh 50k actually movies movies reviews

[01:03:43 - 01:03:46]
in this particular csb file and two

[01:03:45 - 01:03:48]
columns two columns means one is the

[01:03:46 - 01:03:50]
reviews column other is like the

[01:03:48 - 01:03:51]
sentiment column okay sentiment means

[01:03:50 - 01:03:53]
whether it's a positive sentiment

[01:03:51 - 01:03:56]
whether it's a negative sentiment this

[01:03:53 - 01:03:58]
kinds of sentiment you will get here I

[01:03:56 - 01:04:00]
hope it is clear now see here I'm having

[01:03:58 - 01:04:02]
50k movie reviews but here I'm not going

[01:04:00 - 01:04:04]
to use all the reviews here I'm going to

[01:04:02 - 01:04:05]
show you the demo like how we can

[01:04:04 - 01:04:07]
perform the text pre-processing and if

[01:04:05 - 01:04:09]
I'm taking all the 50k reviews so it

[01:04:07 - 01:04:11]
will take like lots of time um to

[01:04:09 - 01:04:13]
process those are the text so what I

[01:04:11 - 01:04:15]
will do I only take the 100 example okay

[01:04:13 - 01:04:17]
the first 100 example I I'll be taking

[01:04:15 - 01:04:19]
and on top of that I will perform all

[01:04:17 - 01:04:21]
the text processing task right so this

[01:04:19 - 01:04:23]
is the code you can execute so it will

[01:04:21 - 01:04:26]
load 100 example now if I show you the

[01:04:23 - 01:04:29]
shape see now we are having 100 example

[01:04:26 - 01:04:31]
and only two columns fine now if I want

[01:04:29 - 01:04:33]
to show you the data see this is the

[01:04:31 - 01:04:36]
data so I think you remember in my uh

[01:04:33 - 01:04:38]
theoretical class I was discussing about

[01:04:36 - 01:04:41]
some pre-processing technique uh here I

[01:04:38 - 01:04:44]
think H so here you can perform

[01:04:41 - 01:04:46]
something called HTML tag removal Emoji

[01:04:44 - 01:04:47]
handle art then spelling correction then

[01:04:46 - 01:04:48]
in the basic preprocessing we saw that

[01:04:47 - 01:04:50]
we can perform something called

[01:04:48 - 01:04:53]
tokenization then we had some optional

[01:04:50 - 01:04:55]
preing as well like stop word streaming

[01:04:53 - 01:04:57]
LZ punctation lower case Okay language

[01:04:55 - 01:04:58]
detection each and everything so first

[01:04:57 - 01:05:00]
thing we'll be learning how we can

[01:04:58 - 01:05:02]
perform the lower case operation and why

[01:05:00 - 01:05:03]
lower case important I already explained

[01:05:02 - 01:05:05]
here I think you remember let's say

[01:05:03 - 01:05:06]
let's say if one of the name is

[01:05:05 - 01:05:08]
containing uppercase character it will

[01:05:06 - 01:05:10]
consider these are actually separate

[01:05:08 - 01:05:12]
name okay these are actually separate

[01:05:10 - 01:05:13]
entity that is the idea so that's how we

[01:05:12 - 01:05:15]
have to bring everything in a lower case

[01:05:13 - 01:05:17]
character so that's why you have to

[01:05:15 - 01:05:18]
apply this lower operation and how to

[01:05:17 - 01:05:20]
perform lower operation I think you

[01:05:18 - 01:05:21]
already know in Python we are having a

[01:05:20 - 01:05:23]
function called Lower with the help of

[01:05:21 - 01:05:25]
lower also we can do it right now see

[01:05:23 - 01:05:27]
here let me show you one example let's

[01:05:25 - 01:05:29]
say I'm taking the reviews three so here

[01:05:27 - 01:05:31]
I'm taking the three three three number

[01:05:29 - 01:05:34]
rows this is the three number rows now

[01:05:31 - 01:05:35]
you can see some of the uh character is

[01:05:34 - 01:05:37]
uppercase character here so this is

[01:05:35 - 01:05:38]
uppercase this is uppercase okay so

[01:05:37 - 01:05:39]
that's how actually you will see

[01:05:38 - 01:05:41]
different different uppercase character

[01:05:39 - 01:05:42]
would be there now if I want to make

[01:05:41 - 01:05:44]
them lower case what I have to do first

[01:05:42 - 01:05:45]
of all I have to select my column like

[01:05:44 - 01:05:47]
in which column you have to apply the

[01:05:45 - 01:05:49]
lower function I have to apply on top of

[01:05:47 - 01:05:51]
my review column now first of all I'm

[01:05:49 - 01:05:53]
converting everything to the string okay

[01:05:51 - 01:05:55]
string data type then I'm applying the

[01:05:53 - 01:05:56]
lower because lower is a string method

[01:05:55 - 01:05:58]
okay okay L is string method I think you

[01:05:56 - 01:06:01]
already know that then whatever changes

[01:05:58 - 01:06:03]
actually I'm doing I'm saving inside my

[01:06:01 - 01:06:04]
column that means I'm just doing the

[01:06:03 - 01:06:07]
permanent change okay inside my column

[01:06:04 - 01:06:08]
so that's why I have given review again

[01:06:07 - 01:06:11]
that is the idea now if I

[01:06:08 - 01:06:12]
execute now see if I show you the data

[01:06:11 - 01:06:14]
now see guys all the character has

[01:06:12 - 01:06:17]
become lower case right now now if I

[01:06:14 - 01:06:20]
want to show you the now if I again

[01:06:17 - 01:06:22]
execute that review three you will see

[01:06:20 - 01:06:24]
that all the character has converted to

[01:06:22 - 01:06:25]
the lower case character okay that is

[01:06:24 - 01:06:28]
the idea now the next thing will be

[01:06:25 - 01:06:29]
learning how we can handle the HTML tags

[01:06:28 - 01:06:31]
that means how we can remove the HTML

[01:06:29 - 01:06:32]
tags for this here I have written a

[01:06:31 - 01:06:35]
function here I'm using something called

[01:06:32 - 01:06:37]
regular expression regx okay inside regx

[01:06:35 - 01:06:38]
you can give a pattern let's say here

[01:06:37 - 01:06:39]
you are giving a pattern if you are

[01:06:38 - 01:06:41]
getting this kinds of symbol okay if you

[01:06:39 - 01:06:43]
are getting this kinds of symbol it's a

[01:06:41 - 01:06:45]
like HTML tag you have to remove those

[01:06:43 - 01:06:47]
HTML tags and you have to replace with

[01:06:45 - 01:06:49]
empty okay empty string that is the idea

[01:06:47 - 01:06:49]
now this is the function we can use now

[01:06:49 - 01:06:52]
if I

[01:06:49 - 01:06:54]
execute now let's say this is a one text

[01:06:52 - 01:06:57]
I have prepared you can see in this text

[01:06:54 - 01:06:59]
actually we are having lots of HTML tags

[01:06:57 - 01:07:00]
now if I pass this particular text to my

[01:06:59 - 01:07:02]
function see it will automatically

[01:07:00 - 01:07:04]
remove all the tags now see I'm only

[01:07:02 - 01:07:06]
getting the text okay relevant text that

[01:07:04 - 01:07:08]
is the idea so this notebook I prepared

[01:07:06 - 01:07:10]
in such a way so that you can use it as

[01:07:08 - 01:07:11]
a template let's say whenever you need

[01:07:10 - 01:07:12]
anything any kinds of functionality you

[01:07:11 - 01:07:14]
can come here you can copy those

[01:07:12 - 01:07:16]
function so please try to keep this

[01:07:14 - 01:07:17]
particular notebook with you because

[01:07:16 - 01:07:19]
this is going to help you a lot okay

[01:07:17 - 01:07:20]
whenever you'll be developing the

[01:07:19 - 01:07:22]
projects this is going to help you a lot

[01:07:20 - 01:07:24]
now if you want to apply on top of the

[01:07:22 - 01:07:26]
entire data set again just call this

[01:07:24 - 01:07:28]
column name let's say review column okay

[01:07:26 - 01:07:30]
and there is a function called apply and

[01:07:28 - 01:07:32]
inside that just try to pass this

[01:07:30 - 01:07:35]
function okay apply function takes

[01:07:32 - 01:07:36]
actually uh one function object now here

[01:07:35 - 01:07:38]
I'm giving the function object so what

[01:07:36 - 01:07:40]
it will do it will try to apply this

[01:07:38 - 01:07:42]
particular function on top of the entire

[01:07:40 - 01:07:44]
uh rows you are having in your data set

[01:07:42 - 01:07:45]
okay now see if I execute and and the

[01:07:44 - 01:07:48]
changes actually I'm doing I'm saving

[01:07:45 - 01:07:51]
everything permanent okay now let me

[01:07:48 - 01:07:53]
execute now if I show you any kinds of

[01:07:51 - 01:07:55]
random let's say rows now you'll see all

[01:07:53 - 01:07:59]
the uh now let's see if I also show you

[01:07:55 - 01:08:01]
um seven okay seven number rows now just

[01:07:59 - 01:08:04]
try to see there is no HTML tags in this

[01:08:01 - 01:08:06]
particular text you can pick up any

[01:08:04 - 01:08:07]
kinds of let's say index so let's say if

[01:08:06 - 01:08:10]
I show you the

[01:08:07 - 01:08:12]
10 nowhere you will see the HTML tags

[01:08:10 - 01:08:14]
here now we'll be learning how we can

[01:08:12 - 01:08:16]
remove actually URL let's say if you are

[01:08:14 - 01:08:18]
having some URL in the text how we can

[01:08:16 - 01:08:20]
remove it for this again I'm using

[01:08:18 - 01:08:21]
regular expression and there is a

[01:08:20 - 01:08:24]
pattern I have given if you are getting

[01:08:21 - 01:08:26]
this kinds of let's say word HTTP then

[01:08:24 - 01:08:28]
slash then ww

[01:08:26 - 01:08:29]
that means it is a URL and you have to

[01:08:28 - 01:08:31]
remove the URL with the empty string

[01:08:29 - 01:08:33]
okay this is the function now let me

[01:08:31 - 01:08:34]
execute now here I have just mentioned

[01:08:33 - 01:08:36]
some of the URL so this is my YouTube

[01:08:34 - 01:08:39]
channel URL this is my LinkedIn URL and

[01:08:36 - 01:08:41]
google.com and kaggle.com okay now these

[01:08:39 - 01:08:43]
are the text I have prepared one by one

[01:08:41 - 01:08:45]
now let's say if I'm passing any kinds

[01:08:43 - 01:08:48]
of text inside my remove URL function it

[01:08:45 - 01:08:49]
will remove that URL let me show you see

[01:08:48 - 01:08:51]
I'm giving the text to that means my

[01:08:49 - 01:08:54]
LinkedIn URL now you can see check out

[01:08:51 - 01:08:55]
my LinkedIn I hope it is clear see again

[01:08:54 - 01:08:57]
I'm telling you it's not a mandate

[01:08:55 - 01:09:00]
things let's say you need URL in your

[01:08:57 - 01:09:02]
data at that time you can keep it let's

[01:09:00 - 01:09:03]
say you need actually HTML tags you can

[01:09:02 - 01:09:06]
keep it but if you don't need it you can

[01:09:03 - 01:09:08]
remove it because I already told you uh

[01:09:06 - 01:09:10]
nowadays actually we are having Advanced

[01:09:08 - 01:09:13]
genbi application it also supports all

[01:09:10 - 01:09:14]
kinds of text like emojis HTML okay

[01:09:13 - 01:09:16]
everything it supports so if you're

[01:09:14 - 01:09:18]
creating these kinds of advanced let's

[01:09:16 - 01:09:19]
say u i mean application that time you

[01:09:18 - 01:09:22]
need Des are the data you don't need to

[01:09:19 - 01:09:24]
remove it okay but sometimes actually

[01:09:22 - 01:09:26]
you also need to remove this data set so

[01:09:24 - 01:09:27]
that's why I'm sure you how you can

[01:09:26 - 01:09:29]
remove it and if you want to keep it you

[01:09:27 - 01:09:30]
can also keep it it's up to you okay you

[01:09:29 - 01:09:33]
have to decide based on your project

[01:09:30 - 01:09:34]
architecture that time this is the idea

[01:09:33 - 01:09:36]
now we'll be learning how we can handle

[01:09:34 - 01:09:38]
the punctuation so if you want to see

[01:09:36 - 01:09:39]
the punctuation so there is a string

[01:09:38 - 01:09:41]
package you can use now if you just

[01:09:39 - 01:09:43]
write string. punctuation you will see

[01:09:41 - 01:09:45]
all kinds of function are available now

[01:09:43 - 01:09:47]
what I have done I just stored these are

[01:09:45 - 01:09:49]
the function in a variable called

[01:09:47 - 01:09:50]
exclude now here I have written a

[01:09:49 - 01:09:52]
function okay here I've written a

[01:09:50 - 01:09:54]
function called remove punctuation and

[01:09:52 - 01:09:56]
here I've written a for Loop so I'm just

[01:09:54 - 01:09:58]
uh looping through this punctuation one

[01:09:56 - 01:09:59]
by one and user is giving the text and

[01:09:58 - 01:10:02]
I'm just checking whether if there is

[01:09:59 - 01:10:04]
any punctuation okay I'm just replacing

[01:10:02 - 01:10:06]
with the empty string now let me show

[01:10:04 - 01:10:08]
you how it will work now let's say this

[01:10:06 - 01:10:09]
is one text string with a punctuation

[01:10:08 - 01:10:12]
you can see there are so many

[01:10:09 - 01:10:13]
punctuation I have assigned now if I

[01:10:12 - 01:10:15]
pass this particular text to my

[01:10:13 - 01:10:17]
punctuation function it will remove the

[01:10:15 - 01:10:19]
punctuation now see there is no

[01:10:17 - 01:10:21]
punctuation right now even I'm also

[01:10:19 - 01:10:22]
calculating the time like how much time

[01:10:21 - 01:10:24]
it is taking to remove the punctuation

[01:10:22 - 01:10:25]
because there is another way you can

[01:10:24 - 01:10:27]
follow to remove the punctuation I'll

[01:10:25 - 01:10:29]
tell you how you can do it see this is

[01:10:27 - 01:10:32]
the function guys uh so here you can use

[01:10:29 - 01:10:33]
something called text. translate inside

[01:10:32 - 01:10:35]
that just try to use this particular

[01:10:33 - 01:10:37]
function okay make translate and inside

[01:10:35 - 01:10:39]
that just try to mention the punctuation

[01:10:37 - 01:10:40]
so what it will do it will uh take your

[01:10:39 - 01:10:42]
text and it will remove all the

[01:10:40 - 01:10:44]
punctuation so this is another approach

[01:10:42 - 01:10:45]
now see if I calculate the time of this

[01:10:44 - 01:10:47]
function you will see that this is the

[01:10:45 - 01:10:49]
time that means this function is taking

[01:10:47 - 01:10:51]
less time than your this function

[01:10:49 - 01:10:52]
because here you are using one for Loop

[01:10:51 - 01:10:54]
and for Loop has the linear time

[01:10:52 - 01:10:55]
complexity I think you know that if you

[01:10:54 - 01:10:57]
are familiar with DSA con I you know

[01:10:55 - 01:10:59]
that it is having linear time time

[01:10:57 - 01:11:01]
complexity okay so this particular

[01:10:59 - 01:11:03]
approach is good so let's say if you're

[01:11:01 - 01:11:05]
are applying this particular Logic on

[01:11:03 - 01:11:06]
top of 50k data set just try to think

[01:11:05 - 01:11:09]
how much time it will take this full

[01:11:06 - 01:11:10]
loop and in other hand if you're using

[01:11:09 - 01:11:12]
this particular method it will take very

[01:11:10 - 01:11:13]
less time to perform the operation now

[01:11:12 - 01:11:15]
if you want to see the time difference

[01:11:13 - 01:11:17]
you can also see the time difference now

[01:11:15 - 01:11:21]
if I show you

[01:11:17 - 01:11:23]
my uh text now see inside this text

[01:11:21 - 01:11:25]
actually I'm having lots of punctuation

[01:11:23 - 01:11:26]
now what I will do I will use my uh

[01:11:25 - 01:11:27]
remove function one that means this

[01:11:26 - 01:11:30]
particular function and inside that I'm

[01:11:27 - 01:11:32]
going to pass my entire review now see

[01:11:30 - 01:11:34]
it will remove the punctuation okay see

[01:11:32 - 01:11:36]
all the punctuation has been removed now

[01:11:34 - 01:11:39]
you can also pass the entire data like

[01:11:36 - 01:11:40]
that you can also pass the entire data

[01:11:39 - 01:11:42]
it will remove all the punctuation

[01:11:40 - 01:11:44]
inside your entire data now we'll be

[01:11:42 - 01:11:45]
learning how we can handle the chat

[01:11:44 - 01:11:48]
conversation see sometimes whenever we

[01:11:45 - 01:11:50]
perform the chatting operation we give

[01:11:48 - 01:11:53]
uh like lots of shortcut let's say if I

[01:11:50 - 01:11:56]
want to write as far as I know what you

[01:11:53 - 01:11:59]
will give you will give AF a ik then

[01:11:56 - 01:12:01]
let's say away from keyboard AFK then as

[01:11:59 - 01:12:04]
soon as possible ASAP that's how we use

[01:12:01 - 01:12:05]
lots of chat keyword okay we use lots of

[01:12:04 - 01:12:07]
chat shortcut keyword okay here I have

[01:12:05 - 01:12:10]
listed down some of them you can see for

[01:12:07 - 01:12:11]
your information FYI so that's how I

[01:12:10 - 01:12:13]
have listed all the chat conversation

[01:12:11 - 01:12:15]
short uh word now let's say you are

[01:12:13 - 01:12:16]
working with actually social media data

[01:12:15 - 01:12:18]
set in the social media data set you

[01:12:16 - 01:12:20]
will see these kinds of data a lot

[01:12:18 - 01:12:22]
people will be using short form okay

[01:12:20 - 01:12:24]
short form so how we can handle this

[01:12:22 - 01:12:25]
particular short form for this first of

[01:12:24 - 01:12:27]
all try to create a dictionary like that

[01:12:25 - 01:12:28]
the entire dictionary you have to create

[01:12:27 - 01:12:30]
then after that here I've written a

[01:12:28 - 01:12:33]
function so this is the function chat

[01:12:30 - 01:12:34]
conversation handle so inside that I'm

[01:12:33 - 01:12:36]
just taking the text okay I'm just

[01:12:34 - 01:12:37]
taking the text and I'm checking and

[01:12:36 - 01:12:39]
inside that with the help of this for

[01:12:37 - 01:12:40]
Loop I'm checking if we are having this

[01:12:39 - 01:12:42]
kinds of word okay if you're having

[01:12:40 - 01:12:44]
these kinds of word what we doing we're

[01:12:42 - 01:12:47]
just mapping with the value that means

[01:12:44 - 01:12:49]
let's say if anyone having actually this

[01:12:47 - 01:12:51]
particular let's say shortcut word let's

[01:12:49 - 01:12:53]
say FYI what I will do instead of FYI I

[01:12:51 - 01:12:55]
will just return for your information

[01:12:53 - 01:12:57]
because this is a dictionary if I if I

[01:12:55 - 01:12:59]
want to get the value I want to call the

[01:12:57 - 01:13:01]
key okay that's how we are mapping now

[01:12:59 - 01:13:04]
see if I execute the program now let's

[01:13:01 - 01:13:06]
say here we are giving a short masses uh

[01:13:04 - 01:13:07]
do this work as up now see it will

[01:13:06 - 01:13:09]
return me do this work as soon as

[01:13:07 - 01:13:11]
possible okay because here it is coming

[01:13:09 - 01:13:13]
here and it is mapping and it is giving

[01:13:11 - 01:13:15]
me this value okay this is the idea now

[01:13:13 - 01:13:18]
let me see how we can handle the

[01:13:15 - 01:13:20]
incorrect text let's say sometimes what

[01:13:18 - 01:13:22]
happens whenever you are using real time

[01:13:20 - 01:13:24]
data there would be lots of spelling M

[01:13:22 - 01:13:26]
mistake right let's say this is one

[01:13:24 - 01:13:28]
example s 10 so certain spelling is not

[01:13:26 - 01:13:29]
correct then condition spelling is not

[01:13:28 - 01:13:31]
correct that's how so that's how you'll

[01:13:29 - 01:13:33]
see different different word is having

[01:13:31 - 01:13:35]
the spelling mistake so how to handle

[01:13:33 - 01:13:37]
this spelling mistake for this you have

[01:13:35 - 01:13:38]
to use one package called text blob so

[01:13:37 - 01:13:41]
let me import this text

[01:13:38 - 01:13:43]
blob and now see here I'm having my

[01:13:41 - 01:13:45]
incorrect text now if I pass this

[01:13:43 - 01:13:47]
incorrect text to my text block and if I

[01:13:45 - 01:13:49]
call this particular function called

[01:13:47 - 01:13:51]
correct now see it will uh handle

[01:13:49 - 01:13:54]
everything now see certain conditions

[01:13:51 - 01:13:55]
during several see all the word has been

[01:13:54 - 01:13:57]
corrected so this amazing package you

[01:13:55 - 01:14:00]
can use if you want to handle the

[01:13:57 - 01:14:01]
spelling okay spelling of any word now

[01:14:00 - 01:14:03]
the next thing we'll be learning how we

[01:14:01 - 01:14:05]
can handle the stop words so inside

[01:14:03 - 01:14:06]
English language not only English

[01:14:05 - 01:14:08]
language inside all kinds of language

[01:14:06 - 01:14:09]
we're having some stop words okay now

[01:14:08 - 01:14:11]
here we're working with the English

[01:14:09 - 01:14:13]
language so let me show you some English

[01:14:11 - 01:14:16]
related stop wordss for this I will be

[01:14:13 - 01:14:17]
importing stop wordss from the nltk nltk

[01:14:16 - 01:14:19]
is a so nltk is nothing but it's a

[01:14:17 - 01:14:21]
natural language toolkit Library so with

[01:14:19 - 01:14:23]
the help of NLP also you can perform

[01:14:21 - 01:14:25]
lots of NLP related task so here you can

[01:14:23 - 01:14:27]
see I'm importing the stop word so here

[01:14:25 - 01:14:28]
I'm performing nltk do download it will

[01:14:27 - 01:14:31]
download all the stop wordss from the

[01:14:28 - 01:14:34]
internet now see now see if I uh click

[01:14:31 - 01:14:36]
this cell it will download the stop

[01:14:34 - 01:14:37]
wordss now if you want to list down all

[01:14:36 - 01:14:40]
the stop wordss you can just write stop

[01:14:37 - 01:14:42]
words. wordss and here you can specify

[01:14:40 - 01:14:44]
the language so here I working with the

[01:14:42 - 01:14:45]
so here I'm working with the English

[01:14:44 - 01:14:47]
language so here I've given the English

[01:14:45 - 01:14:49]
let's say you are working with Hindi

[01:14:47 - 01:14:52]
Bengali you can give that language also

[01:14:49 - 01:14:54]
it will give you the stop what related

[01:14:52 - 01:14:55]
that language so you can uh see the

[01:14:54 - 01:14:58]
documentation of anal we'll see that how

[01:14:55 - 01:15:00]
we can pass the parameter here now see

[01:14:58 - 01:15:02]
these are the words we are having inside

[01:15:00 - 01:15:04]
English so this is called stop words so

[01:15:02 - 01:15:06]
this word doesn't have any kind of

[01:15:04 - 01:15:09]
meaning okay in a sentence okay we use

[01:15:06 - 01:15:11]
it uh to represent one sentence but

[01:15:09 - 01:15:12]
there is no meaning so let me show you

[01:15:11 - 01:15:14]
why I'm telling there is no meaning

[01:15:12 - 01:15:16]
let's if you want to perform uh

[01:15:14 - 01:15:18]
sentiment analysis so let's say there is

[01:15:16 - 01:15:21]
one uh review we are having so let me

[01:15:18 - 01:15:25]
just write this

[01:15:21 - 01:15:25]
movie is awesome

[01:15:27 - 01:15:32]
I loved

[01:15:30 - 01:15:35]
it now just try to see here you are

[01:15:32 - 01:15:37]
having some stop word right like is is

[01:15:35 - 01:15:39]
there this is there I is there it is

[01:15:37 - 01:15:40]
there right but if I want to get the

[01:15:39 - 01:15:44]
sentiment of this particular let's say

[01:15:40 - 01:15:47]
reviews I can see movies is required

[01:15:44 - 01:15:49]
awesome is required loved is required

[01:15:47 - 01:15:51]
now if I'm getting these kinds of word

[01:15:49 - 01:15:53]
actually this kind of positive word that

[01:15:51 - 01:15:55]
means it's a positive sentiment okay

[01:15:53 - 01:15:57]
it's a positive sentiment yes or no no

[01:15:55 - 01:15:59]
right so here actually I don't need

[01:15:57 - 01:16:01]
these are the stop word okay I don't

[01:15:59 - 01:16:02]
need these are the stop word to

[01:16:01 - 01:16:04]
understand whether this particular

[01:16:02 - 01:16:06]
reviews is a positive or negative and if

[01:16:04 - 01:16:07]
you're using these are the stop word in

[01:16:06 - 01:16:09]
the sentence what will happen whenever

[01:16:07 - 01:16:11]
you will perform the text vectorization

[01:16:09 - 01:16:13]
it will make actually extra Dimension

[01:16:11 - 01:16:15]
okay it will make the extra dimension in

[01:16:13 - 01:16:17]
the data and whenever it is making the

[01:16:15 - 01:16:20]
extra Dimension that means if Dimension

[01:16:17 - 01:16:22]
is increasing that time uh your model

[01:16:20 - 01:16:23]
might get uh difficulties right because

[01:16:22 - 01:16:25]
we know that there is a concept of card

[01:16:23 - 01:16:27]
of dimensionality so so we always need

[01:16:25 - 01:16:28]
to reduce the dimensionality somehow I

[01:16:27 - 01:16:30]
think you have learned in your machine

[01:16:28 - 01:16:32]
learning okay machine learning let's say

[01:16:30 - 01:16:34]
topic so that is why we don't need these

[01:16:32 - 01:16:36]
are the stop WS so we have to remove

[01:16:34 - 01:16:37]
this particular stop W sometimes and

[01:16:36 - 01:16:40]
sometimes actually we have to also keep

[01:16:37 - 01:16:43]
it so these are the stop W guys you saw

[01:16:40 - 01:16:45]
now let me show you the length so around

[01:16:43 - 01:16:48]
we are having

[01:16:45 - 01:16:50]
179 stop words present inside English

[01:16:48 - 01:16:51]
now here I've written a function so this

[01:16:50 - 01:16:53]
function will remove the stop parts from

[01:16:51 - 01:16:55]
a text now let me show you let's say

[01:16:53 - 01:16:56]
this is a text I have given so inside

[01:16:55 - 01:16:58]
that you can see different different

[01:16:56 - 01:17:01]
stop wordss are there now if I pass to

[01:16:58 - 01:17:03]
my function so see now see there is no

[01:17:01 - 01:17:04]
stop word in this particular text right

[01:17:03 - 01:17:06]
now okay that's how you can use this

[01:17:04 - 01:17:09]
particular function now again this is my

[01:17:06 - 01:17:10]
data and if I want to apply on top of my

[01:17:09 - 01:17:12]
entire reviews I can do it I can use the

[01:17:10 - 01:17:15]
apply function and I can pass my uh

[01:17:12 - 01:17:18]
function object remove stop

[01:17:15 - 01:17:19]
words and if you want to uh store

[01:17:18 - 01:17:23]
permanently what you can do you can

[01:17:19 - 01:17:25]
write this code okay uh DF reviews is

[01:17:23 - 01:17:27]
equal to DF reviews apply stop words

[01:17:25 - 01:17:28]
okay it will save everything permanent

[01:17:27 - 01:17:30]
but I don't want to save it permanent as

[01:17:28 - 01:17:32]
of now because I'm showing you as a demo

[01:17:30 - 01:17:34]
if you want to do the permanent you can

[01:17:32 - 01:17:36]
do it so now guys I think it is clear

[01:17:34 - 01:17:38]
how we can uh remove the stop words now

[01:17:36 - 01:17:40]
the next thing we'll be learning how to

[01:17:38 - 01:17:42]
handle the Emoji okay see Emoji is

[01:17:40 - 01:17:44]
nothing but it's a uni code actually uh

[01:17:42 - 01:17:45]
character okay if I show you if you just

[01:17:44 - 01:17:47]
write

[01:17:45 - 01:17:49]
Emoji uni

[01:17:47 - 01:17:52]
code you will see different different

[01:17:49 - 01:17:55]
uni codes of different different emojis

[01:17:52 - 01:17:56]
so let me open it up see

[01:17:55 - 01:17:57]
uh here we are having different

[01:17:56 - 01:17:59]
different emagis based on that we are

[01:17:57 - 01:18:02]
having the uni code okay unic code

[01:17:59 - 01:18:03]
character okay Unicode character so

[01:18:02 - 01:18:06]
that's why I just collected some of the

[01:18:03 - 01:18:10]
Unicode character like for the emotions

[01:18:06 - 01:18:12]
emojis symbols then uh pictur graphs

[01:18:10 - 01:18:13]
then we're having transport map symbol

[01:18:12 - 01:18:15]
flag okay so these are the emagis

[01:18:13 - 01:18:18]
related uni code I collected here and I

[01:18:15 - 01:18:20]
just written a function okay and again

[01:18:18 - 01:18:22]
I'm using the regular expression so here

[01:18:20 - 01:18:23]
I'm telling if you're getting this kinds

[01:18:22 - 01:18:25]
of unic code in a sentence that means

[01:18:23 - 01:18:27]
it's a Emoji so what you have to do to

[01:18:25 - 01:18:28]
remove this emoji with the empty space

[01:18:27 - 01:18:31]
okay now let me show you so let's say

[01:18:28 - 01:18:34]
this is one text I'm giving love the the

[01:18:31 - 01:18:36]
movie it was flying Cas okay now see if

[01:18:34 - 01:18:38]
I uh pass this particular text now see

[01:18:36 - 01:18:41]
it will remove the Emojis automatically

[01:18:38 - 01:18:43]
now this is the next one now see only

[01:18:41 - 01:18:45]
LMO is coming now sometimes actually I

[01:18:43 - 01:18:47]
told you emojis are required because let

[01:18:45 - 01:18:48]
say I told you in the chat GPT example

[01:18:47 - 01:18:50]
so if you pass any kinds of emoji

[01:18:48 - 01:18:52]
through the chat GPT it will also able

[01:18:50 - 01:18:53]
to understand okay what you are trying

[01:18:52 - 01:18:55]
to say let's say if I pass any kinds of

[01:18:53 - 01:18:57]
emoji here let's say I'll give

[01:18:55 - 01:18:59]
this

[01:18:57 - 01:19:01]
Emoji hey there what's on your mind

[01:18:59 - 01:19:04]
today see it is trying to understand my

[01:19:01 - 01:19:05]
feelings right now if I want to handle

[01:19:04 - 01:19:06]
these kinds of situations what I have to

[01:19:05 - 01:19:09]
do I have to keep the Emoji that time

[01:19:06 - 01:19:11]
what I can do I can uh extract the

[01:19:09 - 01:19:14]
meaning of the Emoji so for this I can

[01:19:11 - 01:19:15]
use one Library called uh Emoji okay now

[01:19:14 - 01:19:16]
let me show you first of all you have to

[01:19:15 - 01:19:19]
install

[01:19:16 - 01:19:21]
it now just import the Emoji and inside

[01:19:19 - 01:19:23]
Emoji you are having one method called

[01:19:21 - 01:19:25]
demo eyes okay now inside that just try

[01:19:23 - 01:19:27]
to pass the text python is fire I'm

[01:19:25 - 01:19:29]
giving the fire Emoji now it will

[01:19:27 - 01:19:32]
automatically convert to the word python

[01:19:29 - 01:19:33]
is fire okay that means it is trying to

[01:19:32 - 01:19:35]
extract the meaning of that particular

[01:19:33 - 01:19:37]
Emoji right now I hope you you cleared

[01:19:35 - 01:19:39]
so that's how whenever you are passing

[01:19:37 - 01:19:41]
any of emoji as input to the chat GPT it

[01:19:39 - 01:19:42]
is trying to convert this Emoji to the

[01:19:41 - 01:19:44]
word and is trying to understand what

[01:19:42 - 01:19:46]
you are trying to say now there is

[01:19:44 - 01:19:48]
another example I have given love this

[01:19:46 - 01:19:51]
movie it was flying case see see love

[01:19:48 - 01:19:52]
this movie it was face blowing a keys

[01:19:51 - 01:19:53]
now we'll be understanding the

[01:19:52 - 01:19:55]
tokenization I told you we are having

[01:19:53 - 01:19:57]
two kinds of tokenization sentence level

[01:19:55 - 01:19:59]
tokenization and Word level tokenization

[01:19:57 - 01:20:01]
so let's try to see see if you want to

[01:19:59 - 01:20:03]
perform the tokenization uh directly you

[01:20:01 - 01:20:05]
can use the split function because spit

[01:20:03 - 01:20:07]
also will give you the individual word

[01:20:05 - 01:20:09]
in the list see if I have one sentence

[01:20:07 - 01:20:10]
now if I perform the split operation see

[01:20:09 - 01:20:12]
I'm giving I'm getting actually

[01:20:10 - 01:20:13]
individual part so with the help of

[01:20:12 - 01:20:15]
split also you can perform the

[01:20:13 - 01:20:17]
tokenization so similar wise you can

[01:20:15 - 01:20:18]
also do the sentence level tokenization

[01:20:17 - 01:20:20]
this is the word level tokenization now

[01:20:18 - 01:20:22]
for this you have to mention this

[01:20:20 - 01:20:24]
particular fully stop sign so whenever

[01:20:22 - 01:20:27]
it is getting the fully stop that means

[01:20:24 - 01:20:29]
this is sentence okay now see if I

[01:20:27 - 01:20:31]
execute so here I'm having three

[01:20:29 - 01:20:34]
sentence so I am going to DHI I will

[01:20:31 - 01:20:36]
stay there for 3 Days Let's uh hope the

[01:20:34 - 01:20:37]
tree to be great okay see three sentence

[01:20:36 - 01:20:39]
I'm getting so this is called sentence

[01:20:37 - 01:20:43]
level tokenization so again some of the

[01:20:39 - 01:20:45]
example with the split

[01:20:43 - 01:20:47]
function now with the help of regular

[01:20:45 - 01:20:49]
expression you can also do the um

[01:20:47 - 01:20:51]
tokenization so this one example I give

[01:20:49 - 01:20:52]
with the regular expression so here is

[01:20:51 - 01:20:54]
my sentence and it will give you the

[01:20:52 - 01:20:56]
individual word this is the sentence

[01:20:54 - 01:20:58]
level tokenization okay and this is the

[01:20:56 - 01:20:59]
pattern for the word level this is the

[01:20:58 - 01:21:01]
pattern for the sentence level okay this

[01:20:59 - 01:21:04]
is the idea now you can also use

[01:21:01 - 01:21:05]
something called nltk okay that means

[01:21:04 - 01:21:07]
natural language toolkit library for

[01:21:05 - 01:21:09]
this tokenization as well inside that we

[01:21:07 - 01:21:11]
are having to fun two actually function

[01:21:09 - 01:21:13]
mod level tokenizer and Cent level

[01:21:11 - 01:21:15]
tokenizer now let me and if you want to

[01:21:13 - 01:21:17]
perform the tokenization you have to

[01:21:15 - 01:21:19]
download this particular thing called p

[01:21:17 - 01:21:21]
n KT okay this particular thing you have

[01:21:19 - 01:21:23]
to download okay now see here is my

[01:21:21 - 01:21:25]
sentence and I want to perform Word

[01:21:23 - 01:21:27]
level tokenization I will pass this so

[01:21:25 - 01:21:28]
it will give me the B level tokenization

[01:21:27 - 01:21:30]
so automatically this function will

[01:21:28 - 01:21:31]
handle now if you want to perform

[01:21:30 - 01:21:34]
sentence level tokenization you can use

[01:21:31 - 01:21:35]
send tokenizer okay from here and you

[01:21:34 - 01:21:38]
are getting the sentence level

[01:21:35 - 01:21:41]
tokenization okay so again some of the

[01:21:38 - 01:21:43]
example you can try I have given and I

[01:21:41 - 01:21:45]
created this notebook in a such a way

[01:21:43 - 01:21:46]
you can use it as a template I already

[01:21:45 - 01:21:48]
told you I have written like like the

[01:21:46 - 01:21:51]
function wise right if you need any

[01:21:48 - 01:21:52]
kinds of let's say um I mean cleanup

[01:21:51 - 01:21:54]
technique you can copy from here and you

[01:21:52 - 01:21:55]
can use it in your code that's that's

[01:21:54 - 01:21:57]
the idea now there is another package

[01:21:55 - 01:21:59]
you can use called Spacey with the help

[01:21:57 - 01:22:01]
of Spacey also you can perform the

[01:21:59 - 01:22:04]
tokenization fine so we can explore this

[01:22:01 - 01:22:06]
part now let me go to the steamr okay I

[01:22:04 - 01:22:08]
already told you what is steamr steamr

[01:22:06 - 01:22:10]
means you are trying to bring the

[01:22:08 - 01:22:12]
different different word in the root

[01:22:10 - 01:22:14]
form that that means uh let's say you

[01:22:12 - 01:22:16]
are having play playing played so what

[01:22:14 - 01:22:18]
you will do you will Apple steamr and

[01:22:16 - 01:22:20]
you will just try to convert it is to

[01:22:18 - 01:22:21]
the and you'll just try to convert to

[01:22:20 - 01:22:23]
the root word that means play right

[01:22:21 - 01:22:26]
because it is meaning the same okay in

[01:22:23 - 01:22:28]
the sentence so now let me show you so

[01:22:26 - 01:22:31]
inside nltk we are having this steamr

[01:22:28 - 01:22:32]
post poster pter steamr now we are

[01:22:31 - 01:22:34]
importing pter steamr and here we have

[01:22:32 - 01:22:35]
created a function steam word so

[01:22:34 - 01:22:38]
whenever you will give any kinds of

[01:22:35 - 01:22:39]
let's say uh sentence it will perform

[01:22:38 - 01:22:43]
the streaming operation now see here I'm

[01:22:39 - 01:22:44]
giving work Works working work now if I

[01:22:43 - 01:22:46]
give this particular sentence it will

[01:22:44 - 01:22:49]
give me the root form that means work

[01:22:46 - 01:22:51]
work work and all okay now see here I

[01:22:49 - 01:22:52]
kept one sentence so this is the entire

[01:22:51 - 01:22:53]
sentence you can see now I want to

[01:22:52 - 01:22:55]
perform streaming operation on top of

[01:22:53 - 01:22:58]
the sentence so I'm using my function

[01:22:55 - 01:23:01]
inside that I'm passing the sentence now

[01:22:58 - 01:23:04]
see uh it will give me the um steaming

[01:23:01 - 01:23:06]
word right now now see probably it has

[01:23:04 - 01:23:08]
been uh probable okay probable that's

[01:23:06 - 01:23:09]
why I told you streaming is not readable

[01:23:08 - 01:23:12]
sometimes you will get some kinds of

[01:23:09 - 01:23:14]
what it's not readable but your model

[01:23:12 - 01:23:16]
will try to understand okay but as a

[01:23:14 - 01:23:18]
human it's not readable see favorite has

[01:23:16 - 01:23:20]
been converted to favorite right now

[01:23:18 - 01:23:23]
okay so in case actually what you can do

[01:23:20 - 01:23:24]
you can use something called LZ okay LZ

[01:23:23 - 01:23:26]
will handle this kinds of situation it

[01:23:24 - 01:23:28]
will give you readable word actually now

[01:23:26 - 01:23:31]
see this is the LZ code so it is

[01:23:28 - 01:23:33]
available inside nltk I'm importing the

[01:23:31 - 01:23:35]
LZ initializing the LZ and if you want

[01:23:33 - 01:23:38]
to use latiz you have to download these

[01:23:35 - 01:23:41]
at the things wnet and OMW and now if I

[01:23:38 - 01:23:44]
execute this code you will see that it

[01:23:41 - 01:23:47]
will give you the LZ for all the word

[01:23:44 - 01:23:48]
see so this is the word this is the LZ

[01:23:47 - 01:23:50]
this is the word this is the

[01:23:48 - 01:23:53]
lemmatization now see it's readable okay

[01:23:50 - 01:23:55]
it's readable then your streaming one I

[01:23:53 - 01:23:57]
hope it is clear fine so so that's why I

[01:23:55 - 01:24:00]
just written uh streaming and LZ are

[01:23:57 - 01:24:03]
same to retrieve root words but LZ is

[01:24:00 - 01:24:05]
work uh good LZ is slow and streaming is

[01:24:03 - 01:24:06]
fast because lemmatization will give you

[01:24:05 - 01:24:08]
the readable output that's why it's

[01:24:06 - 01:24:10]
little bit slow than your streaming okay

[01:24:08 - 01:24:11]
I hope it is clear so yes these are the

[01:24:10 - 01:24:13]
technique you can follow for the text

[01:24:11 - 01:24:15]
pre-processing if you're having any

[01:24:13 - 01:24:17]
kinds of text you can perform text

[01:24:15 - 01:24:18]
pre-processing with the help of these

[01:24:17 - 01:24:20]
are the technique you can clean up your

[01:24:18 - 01:24:22]
text okay and again I'm tell telling you

[01:24:20 - 01:24:24]
it's not required to perform all the

[01:24:22 - 01:24:26]
text cleaning uh let's say uh I mean

[01:24:24 - 01:24:28]
technique sometimes if you need anything

[01:24:26 - 01:24:30]
just try to keep it as it is that is the

[01:24:28 - 01:24:32]
idea fine so yes this is all from this

[01:24:30 - 01:24:34]
video and what you can do right now you

[01:24:32 - 01:24:36]
can download any other data set from the

[01:24:34 - 01:24:37]
Kagel kaggle.com because kagle is having

[01:24:36 - 01:24:39]
different different data set not only

[01:24:37 - 01:24:41]
movie data set you will also get

[01:24:39 - 01:24:44]
something called Twitter data set I

[01:24:41 - 01:24:46]
think Twitter data set is also available

[01:24:44 - 01:24:47]
see Twitter data set is also available

[01:24:46 - 01:24:49]
just try to download the Twitter

[01:24:47 - 01:24:50]
sentiment data set and try to apply

[01:24:49 - 01:24:52]
these are the text preprocessing on top

[01:24:50 - 01:24:53]
of the twetter data data set okay so

[01:24:52 - 01:24:55]
this should be one task guys from my

[01:24:53 - 01:24:56]
side please try to attempt Because

[01:24:55 - 01:24:58]
unless and until you are not practicing

[01:24:56 - 01:25:00]
things would be more complicated and

[01:24:58 - 01:25:02]
whenever you will be doing the Practical

[01:25:00 - 01:25:04]
okay by yourself things would be more

[01:25:02 - 01:25:05]
clear here so in the next video we'll be

[01:25:04 - 01:25:07]
learning how we can perform the tech

[01:25:05 - 01:25:09]
data representation that means text

[01:25:07 - 01:25:11]
representation how we can vectorize our

[01:25:09 - 01:25:13]
text that means we'll be converting our

[01:25:11 - 01:25:14]
text to numbers okay for the model so I

[01:25:13 - 01:25:16]
think you already know what is data

[01:25:14 - 01:25:18]
representation that means uh inside

[01:25:16 - 01:25:20]
generative AI you will be working with

[01:25:18 - 01:25:22]
textual data so not only textual data

[01:25:20 - 01:25:24]
you'll be also working with something

[01:25:22 - 01:25:26]
called image kinds of data now these are

[01:25:24 - 01:25:28]
the actually raw file if you see any

[01:25:26 - 01:25:30]
kinds of text Data any kinds of image

[01:25:28 - 01:25:33]
data okay so these are actually raw data

[01:25:30 - 01:25:35]
these are actually unstructured data so

[01:25:33 - 01:25:37]
I can't directly pass these kinds of

[01:25:35 - 01:25:39]
data to my model because uh model is

[01:25:37 - 01:25:41]
nothing but uh at the end it's a

[01:25:39 - 01:25:44]
mathematical equation only right and

[01:25:41 - 01:25:47]
mathematical equation can only support

[01:25:44 - 01:25:49]
uh numerical data so what we have to do

[01:25:47 - 01:25:51]
uh whatever text Data whatever image

[01:25:49 - 01:25:53]
data we are using here we have to

[01:25:51 - 01:25:55]
convert them to the vector that means we

[01:25:53 - 01:25:57]
have to convert them to the number okay

[01:25:55 - 01:25:59]
numerical representation so this concept

[01:25:57 - 01:26:02]
we call it as a data representation you

[01:25:59 - 01:26:05]
can also call it as a data vectorization

[01:26:02 - 01:26:07]
okay so here we'll be uh seeing couple

[01:26:05 - 01:26:09]
of Technique we can follow to perform

[01:26:07 - 01:26:11]
these kinds of uh vectorization

[01:26:09 - 01:26:13]
technique on top of our data even I will

[01:26:11 - 01:26:15]
also show you some drawbacks uh with

[01:26:13 - 01:26:17]
different different technique and what

[01:26:15 - 01:26:19]
which technique actually at the end you

[01:26:17 - 01:26:21]
have to follow for the generative VI if

[01:26:19 - 01:26:22]
you're working in the generative VI if

[01:26:21 - 01:26:24]
you're working with the large language

[01:26:22 - 01:26:26]
model so which technique would be

[01:26:24 - 01:26:28]
suitable for your task okay so here

[01:26:26 - 01:26:30]
everything I'll try to clarify so please

[01:26:28 - 01:26:32]
try to uh watch this video till the end

[01:26:30 - 01:26:34]
and if you have any kinds of doubt you

[01:26:32 - 01:26:36]
can also ask me in the comment section

[01:26:34 - 01:26:38]
so let's start guys with our data

[01:26:36 - 01:26:41]
representation topic so guys in this

[01:26:38 - 01:26:44]
video I'll be discussing about like what

[01:26:41 - 01:26:47]
is feature extraction

[01:26:44 - 01:26:47]
from

[01:26:47 - 01:26:55]
text you can also consider as image then

[01:26:50 - 01:26:57]
we'll be discussing about why

[01:26:55 - 01:26:57]
we need

[01:26:59 - 01:27:09]
it then third I'm going to

[01:27:02 - 01:27:12]
discuss why it is so difficult then

[01:27:09 - 01:27:14]
we'll be discussing

[01:27:12 - 01:27:18]
about what is

[01:27:14 - 01:27:18]
the core

[01:27:18 - 01:27:25]
idea and

[01:27:21 - 01:27:27]
some techniques so so this should be my

[01:27:25 - 01:27:28]
entire video agenda so first of all

[01:27:27 - 01:27:30]
we'll be discussing about what is a

[01:27:28 - 01:27:32]
feature extraction from text you can

[01:27:30 - 01:27:34]
also consider as image because I told

[01:27:32 - 01:27:36]
you not in genbi you can use any kinds

[01:27:34 - 01:27:38]
of data whether it can be text image

[01:27:36 - 01:27:40]
audio okay anything see first of all we

[01:27:38 - 01:27:41]
have to understand what is feature

[01:27:40 - 01:27:44]
extraction see feature extraction is

[01:27:41 - 01:27:46]
nothing but let's say you are having a

[01:27:44 - 01:27:47]
unstructured data let's say you are

[01:27:46 - 01:27:49]
having a text data or let's say image

[01:27:47 - 01:27:51]
data so from this data you are

[01:27:49 - 01:27:53]
extracting some features to represent

[01:27:51 - 01:27:54]
that particular data so I think those

[01:27:53 - 01:27:56]
who are already familiar with with

[01:27:54 - 01:27:58]
computer vision uh you already learned

[01:27:56 - 01:28:01]
about convolutional neural network so

[01:27:58 - 01:28:03]
with the help of CNN what we can perform

[01:28:01 - 01:28:05]
we can perform a feature extraction that

[01:28:03 - 01:28:07]
means we just try to extract some of the

[01:28:05 - 01:28:10]
features from a image so what kinds of

[01:28:07 - 01:28:12]
features let's say the ages okay then uh

[01:28:10 - 01:28:14]
you'll be also extracting some patterns

[01:28:12 - 01:28:15]
so these are the actually features so

[01:28:14 - 01:28:16]
with the help of this particular

[01:28:15 - 01:28:18]
features my model will able to

[01:28:16 - 01:28:20]
understand about the data and it will be

[01:28:18 - 01:28:22]
able to predict something okay on top of

[01:28:20 - 01:28:24]
the test data so this is the idea so in

[01:28:22 - 01:28:25]
generative way also uh what kinds of

[01:28:24 - 01:28:27]
data actually we're using we also need

[01:28:25 - 01:28:29]
to perform something called feature

[01:28:27 - 01:28:31]
extraction because whether it can be

[01:28:29 - 01:28:32]
Text data image data any kinds of data

[01:28:31 - 01:28:34]
the first thing what you have to do you

[01:28:32 - 01:28:36]
have to extract the features from that

[01:28:34 - 01:28:38]
particular data okay this is the idea

[01:28:36 - 01:28:39]
and feature extraction means you are

[01:28:38 - 01:28:41]
converting your textual data to

[01:28:39 - 01:28:42]
numerical representation that means to

[01:28:41 - 01:28:44]
the vector representation okay this is

[01:28:42 - 01:28:47]
the idea then the second thing actually

[01:28:44 - 01:28:50]
you can see why we need it because as I

[01:28:47 - 01:28:51]
already told you uh in general tvi

[01:28:50 - 01:28:53]
whatever model you are using whatever

[01:28:51 - 01:28:56]
large language model you are using every

[01:28:53 - 01:28:58]
model is a mathematical equation and

[01:28:56 - 01:29:01]
mathematical equation can take actually

[01:28:58 - 01:29:02]
your textual data or image data directly

[01:29:01 - 01:29:04]
so for this definitely you have to

[01:29:02 - 01:29:07]
convert to the

[01:29:04 - 01:29:10]
number okay numbers you can also call it

[01:29:07 - 01:29:12]
as a vector okay vectors so if you can

[01:29:10 - 01:29:14]
convert to the numbers or vectors then

[01:29:12 - 01:29:16]
your model will be able to take this

[01:29:14 - 01:29:19]
particular data as an input and it will

[01:29:16 - 01:29:21]
learn okay what kinds of uh actually

[01:29:19 - 01:29:22]
pattern it is having based on that it

[01:29:21 - 01:29:25]
will try to generate something this is

[01:29:22 - 01:29:28]
the idea okay now why it is so difficult

[01:29:25 - 01:29:29]
so whenever I'm talking about text Data

[01:29:28 - 01:29:31]
okay whenever I'm talking about text

[01:29:29 - 01:29:33]
Data it would be little bit difficult

[01:29:31 - 01:29:35]
for you to extract the features from the

[01:29:33 - 01:29:38]
data why so let me show you some example

[01:29:35 - 01:29:41]
let's say if I'm considering let's say

[01:29:38 - 01:29:44]
uh ml in machine learning I think you

[01:29:41 - 01:29:45]
remember inside machine learning what

[01:29:44 - 01:29:47]
kinds of data we used to use I think you

[01:29:45 - 01:29:50]
remember we used to use something called

[01:29:47 - 01:29:52]
tabular Data okay tabular data uh

[01:29:50 - 01:29:55]
tabular data like we used to use

[01:29:52 - 01:29:57]
something called csb Data then Excel

[01:29:55 - 01:29:59]
fine so these are the actually tabular

[01:29:57 - 01:30:01]
data that means here you will have a

[01:29:59 - 01:30:05]
table so let's say this is your

[01:30:01 - 01:30:07]
table so it will have one fixed table so

[01:30:05 - 01:30:09]
in this table you will have the fixed

[01:30:07 - 01:30:13]
column size let's say you are having

[01:30:09 - 01:30:19]
here uh 1 2 3 four column and some of

[01:30:13 - 01:30:22]
the rows so 1 2 3 four columns 1 2 three

[01:30:19 - 01:30:24]
four five rows okay so here your uh

[01:30:22 - 01:30:27]
table dimension is

[01:30:24 - 01:30:29]
5 cross 4 okay so this is the table

[01:30:27 - 01:30:31]
dimension that means it's a fixed size

[01:30:29 - 01:30:34]
it's a tabular data okay it's a tabular

[01:30:31 - 01:30:38]
data so here you will have the

[01:30:34 - 01:30:41]
column okay here you have the

[01:30:38 - 01:30:43]
column and here you will have the row I

[01:30:41 - 01:30:45]
hope you cleared now you will restore

[01:30:43 - 01:30:48]
the

[01:30:45 - 01:30:51]
data fine now whenever you are taking

[01:30:48 - 01:30:52]
any kinds of let's say uh machine

[01:30:51 - 01:30:54]
learning model let's say this is your

[01:30:52 - 01:30:58]
machine learning model

[01:30:54 - 01:31:00]
your ml model so what you will do so how

[01:30:58 - 01:31:02]
so what is the X feature size X feature

[01:31:00 - 01:31:04]
size is nothing but your input size okay

[01:31:02 - 01:31:05]
input size that means the independence

[01:31:04 - 01:31:07]
variable let's say you are doing house

[01:31:05 - 01:31:10]
price prediction so let's say this is uh

[01:31:07 - 01:31:13]
number of room let's say this is the

[01:31:10 - 01:31:16]
area of the house let's say this is uh

[01:31:13 - 01:31:18]
number of bathroom and this is the price

[01:31:16 - 01:31:20]
price of the house so this is your y

[01:31:18 - 01:31:23]
variable okay and these are your X

[01:31:20 - 01:31:25]
variable okay so X variable I'm having

[01:31:23 - 01:31:28]
how many one 2 three 3x variable I'm

[01:31:25 - 01:31:30]
having okay that means you will give

[01:31:28 - 01:31:32]
three input to the model and only one

[01:31:30 - 01:31:35]
output you will get which is nothing but

[01:31:32 - 01:31:37]
y hat okay this is the idea that means

[01:31:35 - 01:31:39]
to the model you have to give X data

[01:31:37 - 01:31:40]
three column and Y data one column which

[01:31:39 - 01:31:42]
is nothing but your price and this is

[01:31:40 - 01:31:45]
your target variable okay and once you

[01:31:42 - 01:31:47]
pass the data you will get the output

[01:31:45 - 01:31:49]
that means here your column size is

[01:31:47 - 01:31:51]
fixed so here what you saw your column

[01:31:49 - 01:31:53]
size is fixed that means your input size

[01:31:51 - 01:31:54]
is fixed okay to the model okay there is

[01:31:53 - 01:31:57]
no issue

[01:31:54 - 01:31:59]
that means we can easily use our tabular

[01:31:57 - 01:32:00]
data okay for in the machine learning or

[01:31:59 - 01:32:01]
you can also use in the Deep learning

[01:32:00 - 01:32:02]
for this you have to use something

[01:32:01 - 01:32:05]
called Neal Network that means

[01:32:02 - 01:32:09]
artificial uh neural network right now

[01:32:05 - 01:32:11]
let's consider uh image data let's say

[01:32:09 - 01:32:15]
inside computer vision we use something

[01:32:11 - 01:32:17]
called image data okay image

[01:32:15 - 01:32:20]
videos and whenever I'm talking about

[01:32:17 - 01:32:22]
videos videos is nothing but it's a

[01:32:20 - 01:32:24]
frame of image right it's a sequence of

[01:32:22 - 01:32:26]
image so you can convert videos to image

[01:32:24 - 01:32:27]
then you can analyze again you can

[01:32:26 - 01:32:29]
convert to videos so let's consider

[01:32:27 - 01:32:31]
image only here so let me show you see

[01:32:29 - 01:32:32]
image is nothing but it's a pixel okay

[01:32:31 - 01:32:33]
inside image actually we will see

[01:32:32 - 01:32:35]
different different pixel value so let

[01:32:33 - 01:32:37]
me show you one example so guys here you

[01:32:35 - 01:32:40]
can see here I kept one image and this

[01:32:37 - 01:32:41]
is a Mist uh digit image so here you can

[01:32:40 - 01:32:43]
see three has been written so if you

[01:32:41 - 01:32:45]
just zoom this image what you will see

[01:32:43 - 01:32:46]
you will see these kinds of pixel okay

[01:32:45 - 01:32:48]
and inside pixel you are having

[01:32:46 - 01:32:49]
different different numbers you can see

[01:32:48 - 01:32:53]
these are actually numbers so this

[01:32:49 - 01:32:55]
number range would be 0 to 255 okay 0 to

[01:32:53 - 01:32:57]
255 this is the range of the number and

[01:32:55 - 01:32:58]
one thing whever you can see the zero

[01:32:57 - 01:33:01]
okay zero number you can see it's a

[01:32:58 - 01:33:02]
white pixel okay it's a white pixel and

[01:33:01 - 01:33:05]
whenever you see some number okay it's a

[01:33:02 - 01:33:08]
black pixel you can see whenever you can

[01:33:05 - 01:33:10]
see much darker color it's a that means

[01:33:08 - 01:33:13]
it is close to 255 and whenever you see

[01:33:10 - 01:33:16]
some mild like darker color that means

[01:33:13 - 01:33:17]
it is close to zero okay so this is the

[01:33:16 - 01:33:21]
idea let's see your three looks like

[01:33:17 - 01:33:21]
that let's say this is the three in this

[01:33:22 - 01:33:27]
image and here is the three

[01:33:24 - 01:33:29]
representation in the number that means

[01:33:27 - 01:33:30]
if you zoom this image you will see some

[01:33:29 - 01:33:32]
numbers that some value pixel value

[01:33:30 - 01:33:34]
would be there okay so that's how

[01:33:32 - 01:33:36]
actually your three looks like so

[01:33:34 - 01:33:37]
whatever image you are taking you'll be

[01:33:36 - 01:33:39]
getting this kinds of pixel value okay

[01:33:37 - 01:33:41]
at the end now whenever I'm talking

[01:33:39 - 01:33:43]
about image data so you can easily

[01:33:41 - 01:33:44]
convert image to a table representation

[01:33:43 - 01:33:46]
because it's a pixel value at the end so

[01:33:44 - 01:33:48]
what you can do you can create a fixed

[01:33:46 - 01:33:50]
table you can create a fix table let's

[01:33:48 - 01:33:54]
say this image image Dimension is 28

[01:33:50 - 01:33:55]
cross 28 okay now just try to the pixel

[01:33:54 - 01:33:57]
value based on that just try to create

[01:33:55 - 01:33:59]
the table and add all the number here

[01:33:57 - 01:34:02]
add all the pixel now if you calculate

[01:33:59 - 01:34:04]
all the pixels uh here so if you just

[01:34:02 - 01:34:07]
multiply 28 cross 28 you will get

[01:34:04 - 01:34:09]
something called 7 84 okay I think that

[01:34:07 - 01:34:10]
many of pixel so this should be your

[01:34:09 - 01:34:12]
input size okay this should be your

[01:34:10 - 01:34:16]
input size now what you can do you can

[01:34:12 - 01:34:19]
create a neural network okay dot dot dot

[01:34:16 - 01:34:22]
7 uh 84 now just pass all the data one

[01:34:19 - 01:34:25]
by

[01:34:22 - 01:34:29]
one okay pass all the data one by

[01:34:25 - 01:34:31]
one and so on okay till uh

[01:34:29 - 01:34:34]
784 okay so that's how again you can

[01:34:31 - 01:34:35]
create a easy neural network and here

[01:34:34 - 01:34:36]
input size is also fixed which is

[01:34:35 - 01:34:38]
nothing but this is the input size

[01:34:36 - 01:34:40]
because because all the image will have

[01:34:38 - 01:34:42]
the dimension fixed Dimension okay I

[01:34:40 - 01:34:44]
hope it is clear that means there is no

[01:34:42 - 01:34:47]
issue with the input size now the next

[01:34:44 - 01:34:50]
data let's talk about audio data okay

[01:34:47 - 01:34:52]
audio data so audio audio is what audio

[01:34:50 - 01:34:55]
is nothing but so what is audio audio is

[01:34:52 - 01:34:57]
nothing but it's a frequency you can see

[01:34:55 - 01:34:59]
uh it's a frequency so whenever you will

[01:34:57 - 01:35:02]
see some audio you will get get this

[01:34:59 - 01:35:04]
kinds of frequency response and the

[01:35:02 - 01:35:05]
parameter of the audio would be DB okay

[01:35:04 - 01:35:08]
that means

[01:35:05 - 01:35:11]
decibel okay this is the frequency of

[01:35:08 - 01:35:13]
the audio now you can easily convert

[01:35:11 - 01:35:14]
this audio signal to a number

[01:35:13 - 01:35:16]
representation because here you can see

[01:35:14 - 01:35:18]
let's say this is your uh Hearts okay

[01:35:16 - 01:35:21]
this is your hearts frequency HS and

[01:35:18 - 01:35:22]
this is your TB that means decibel like

[01:35:21 - 01:35:25]
now you can see this is the uh actually

[01:35:22 - 01:35:26]
frequency now just try to see the graph

[01:35:25 - 01:35:27]
and based on that just try to collect

[01:35:26 - 01:35:29]
the number let's say you have created

[01:35:27 - 01:35:32]
one table let's say this is your table

[01:35:29 - 01:35:34]
so one column you just consider let's

[01:35:32 - 01:35:36]
say this is the

[01:35:34 - 01:35:38]
frequency and this is the decibel okay

[01:35:36 - 01:35:43]
DB now just try to collect the data

[01:35:38 - 01:35:45]
let's say here you can see 400

[01:35:43 - 01:35:49]
Heartz and the decibel value was let's

[01:35:45 - 01:35:51]
say minus 10 DB okay that's how just

[01:35:49 - 01:35:53]
collect all the data okay collect all

[01:35:51 - 01:35:55]
the data now again you will see we will

[01:35:53 - 01:35:57]
have one fixed table okay we'll have one

[01:35:55 - 01:35:59]
fixed table again you can take a deep

[01:35:57 - 01:36:02]
learning model here let's say artificial

[01:35:59 - 01:36:03]
neural network and you can fit the data

[01:36:02 - 01:36:05]
you can fit the data and you can get the

[01:36:03 - 01:36:08]
prediction okay again you don't have any

[01:36:05 - 01:36:11]
issue with the input size but whenever

[01:36:08 - 01:36:13]
I'm talking about let's say Tex data

[01:36:11 - 01:36:16]
whenever I'm talking

[01:36:13 - 01:36:18]
about Text data so here you will get the

[01:36:16 - 01:36:21]
difficulty how so let me show you so

[01:36:18 - 01:36:24]
let's say this one sentence I'm having

[01:36:21 - 01:36:28]
my name

[01:36:24 - 01:36:31]
is buy so here just try to see how many

[01:36:28 - 01:36:35]
tokens you are having so we are having

[01:36:31 - 01:36:37]
uh 1 2 3 4 that means four tokens let's

[01:36:35 - 01:36:38]
say somehow you converted this text to a

[01:36:37 - 01:36:40]
number representation that means Vector

[01:36:38 - 01:36:41]
representation let's say my you are

[01:36:40 - 01:36:44]
considering as zero name you are

[01:36:41 - 01:36:46]
considering as one e is considering as

[01:36:44 - 01:36:48]
two and byy you are considering as three

[01:36:46 - 01:36:52]
now you'll be creating a network let's

[01:36:48 - 01:36:54]
say this is your Neal Network 1 2 3 and

[01:36:52 - 01:36:56]
four then what you will do he will feed

[01:36:54 - 01:36:59]
the data let's say my will come here

[01:36:56 - 01:37:01]
name will come here e will come here and

[01:36:59 - 01:37:03]
buy will come here okay now let's you

[01:37:01 - 01:37:05]
have taken some hidden NE Network and

[01:37:03 - 01:37:09]
here you will get the Yad okay now let's

[01:37:05 - 01:37:11]
say there is another sentence how are

[01:37:09 - 01:37:13]
you now see here you will get the

[01:37:11 - 01:37:15]
difficulties because in the previous

[01:37:13 - 01:37:18]
sentence how many tokens I had I had

[01:37:15 - 01:37:21]
four tokens now if you count this

[01:37:18 - 01:37:23]
sentence you are having one two three

[01:37:21 - 01:37:26]
only three tokens now let's say you have

[01:37:23 - 01:37:28]
represent presented this tokens four 5 6

[01:37:26 - 01:37:30]
okay let's say this is your vector

[01:37:28 - 01:37:32]
representation now tell me can you can I

[01:37:30 - 01:37:34]
pass this particular data to the model

[01:37:32 - 01:37:36]
right now because what is the model

[01:37:34 - 01:37:38]
input size four but here what is the

[01:37:36 - 01:37:41]
input you are having three so here you

[01:37:38 - 01:37:43]
will get one dimensional issue okay

[01:37:41 - 01:37:46]
Dimension Dimension issue you will get

[01:37:43 - 01:37:48]
okay so it will give you one error so it

[01:37:46 - 01:37:50]
is expecting four dimensional input but

[01:37:48 - 01:37:52]
you have given three dimensional input

[01:37:50 - 01:37:53]
now just try to consider whenever we

[01:37:52 - 01:37:56]
write any kinds of text it doesn't have

[01:37:53 - 01:37:58]
any kinds of input length similarity

[01:37:56 - 01:38:00]
okay you can write anything you can

[01:37:58 - 01:38:03]
write my name is buy how are you I'm

[01:38:00 - 01:38:04]
okay so it should be any kinds of length

[01:38:03 - 01:38:06]
sentence okay it can be any kinds of

[01:38:04 - 01:38:08]
length sentence and there actually we

[01:38:06 - 01:38:10]
usually face the difficulty whenever we

[01:38:08 - 01:38:13]
use these kinds of textual data because

[01:38:10 - 01:38:15]
it doesn't have any kinds of input size

[01:38:13 - 01:38:18]
because it's a completely unstructured

[01:38:15 - 01:38:21]
data and representing this uh text to

[01:38:18 - 01:38:23]
numbers is very much difficult because I

[01:38:21 - 01:38:24]
can't assign 0 1 to three like that

[01:38:23 - 01:38:26]
because if you're Ling 0 1 to three like

[01:38:24 - 01:38:28]
that your model won't be able to

[01:38:26 - 01:38:30]
understand it's not a meaningful number

[01:38:28 - 01:38:32]
but previously the data I showed you we

[01:38:30 - 01:38:34]
can easily we can easily convert them to

[01:38:32 - 01:38:35]
the numerical representation because

[01:38:34 - 01:38:37]
tabular data is already a numerical

[01:38:35 - 01:38:39]
representation data right then image is

[01:38:37 - 01:38:41]
already a numbers because at the end you

[01:38:39 - 01:38:42]
are getting a pixel here then audio is

[01:38:41 - 01:38:45]
already a number you are getting a

[01:38:42 - 01:38:47]
number here but what about text text is

[01:38:45 - 01:38:49]
a string but how we can convert string

[01:38:47 - 01:38:51]
to a number representation so that it

[01:38:49 - 01:38:53]
will it will have the same meaning of my

[01:38:51 - 01:38:55]
sentence let's say here I have written a

[01:38:53 - 01:38:57]
my name is buy so after my name is

[01:38:55 - 01:38:59]
coming after name is is coming after is

[01:38:57 - 01:39:03]
buy is coming so with the help of number

[01:38:59 - 01:39:06]
how I can uh let's say contain that

[01:39:03 - 01:39:09]
particular relationship is it possible

[01:39:06 - 01:39:11]
yeah it is possible but it would be

[01:39:09 - 01:39:12]
little bit difficult for you initially

[01:39:11 - 01:39:14]
because you don't know like what kinds

[01:39:12 - 01:39:15]
of let's say vectorization you can

[01:39:14 - 01:39:17]
perform here to represent this

[01:39:15 - 01:39:19]
particular sentence to a let's say

[01:39:17 - 01:39:21]
meaningful representation that is what

[01:39:19 - 01:39:23]
I'm trying to say right so now you can

[01:39:21 - 01:39:26]
ask me sir we can apply actually two

[01:39:23 - 01:39:27]
techniqu we have learned previously I

[01:39:26 - 01:39:29]
will tell you what kinds of Technique we

[01:39:27 - 01:39:30]
can apply you told me let's say the

[01:39:29 - 01:39:32]
first Technique we can apply something

[01:39:30 - 01:39:37]
called one hot

[01:39:32 - 01:39:40]
encoding one hot

[01:39:37 - 01:39:41]
encoding so this encoding technique you

[01:39:40 - 01:39:43]
have learned in your machine learning

[01:39:41 - 01:39:44]
right that's whenever you have any kinds

[01:39:43 - 01:39:47]
of categorical data used to perform this

[01:39:44 - 01:39:48]
one not encoding right then the second

[01:39:47 - 01:39:53]
technique you can also perform something

[01:39:48 - 01:39:56]
called bag of word bag of word we can

[01:39:53 - 01:39:57]
also call it as a bow okay bag of work

[01:39:56 - 01:40:01]
so now let's try to discuss this two

[01:39:57 - 01:40:02]
technique uh how it can be applied and

[01:40:01 - 01:40:04]
what are some drawbacks okay if I were

[01:40:02 - 01:40:06]
applying this these kinds of technique

[01:40:04 - 01:40:08]
okay so first of all let me discuss why

[01:40:06 - 01:40:11]
not encoding so what I'll do I'll just

[01:40:08 - 01:40:16]
create a table here so let me create a

[01:40:11 - 01:40:16]
table so here I will take uh two

[01:40:17 - 01:40:23]
columns and four rows as of now I'm only

[01:40:21 - 01:40:26]
taking four example just just to show

[01:40:23 - 01:40:28]
you okay how things will be working but

[01:40:26 - 01:40:30]
in actual way you will have uh more than

[01:40:28 - 01:40:32]
actually four rows okay that means you

[01:40:30 - 01:40:35]
might have thousands rows let's say

[01:40:32 - 01:40:37]
lacks of rows okay uh it doesn't matter

[01:40:35 - 01:40:41]
let's say this is your data one so here

[01:40:37 - 01:40:41]
you are having a sentence let's say

[01:40:41 - 01:40:45]
people

[01:40:43 - 01:40:49]
watch let's say I'll give my YouTube

[01:40:45 - 01:40:51]
channel name DS with

[01:40:49 - 01:40:52]
buy so if you don't know guys this is my

[01:40:51 - 01:40:54]
YouTube channel name if you're

[01:40:52 - 01:40:59]
interested you can also so Vis it then

[01:40:54 - 01:41:02]
let's say data two we are having DS

[01:40:59 - 01:41:05]
with

[01:41:02 - 01:41:07]
buy

[01:41:05 - 01:41:10]
much DS with

[01:41:07 - 01:41:12]
buy I'm writing any kinds of sentence

[01:41:10 - 01:41:14]
guys as of now whatever things I'm

[01:41:12 - 01:41:18]
thinking in my mind now it's a data

[01:41:14 - 01:41:18]
three you are having

[01:41:18 - 01:41:25]
people

[01:41:21 - 01:41:25]
write comments

[01:41:26 - 01:41:34]
and data 4 I'll be writing D4 DS

[01:41:31 - 01:41:37]
with

[01:41:34 - 01:41:37]
buy

[01:41:37 - 01:41:41]
right

[01:41:39 - 01:41:43]
comments okay let's say this kinds of

[01:41:41 - 01:41:45]
data we are having initially fine so

[01:41:43 - 01:41:48]
that means how many rows we are having

[01:41:45 - 01:41:52]
we are having Row one row

[01:41:48 - 01:41:54]
two then Row three and row four that

[01:41:52 - 01:41:55]
means only four row Pro we are having as

[01:41:54 - 01:41:57]
of now okay four example we are having

[01:41:55 - 01:41:59]
four data points we are having right now

[01:41:57 - 01:42:00]
if I want to perform one not encoding so

[01:41:59 - 01:42:02]
first thing what I have to do I have to

[01:42:00 - 01:42:04]
take the entire Corpus okay and I

[01:42:02 - 01:42:06]
already told you what is Corpus uh I

[01:42:04 - 01:42:08]
think in my previous session the text uh

[01:42:06 - 01:42:11]
pre-processing session at the last I was

[01:42:08 - 01:42:12]
discussing about some like key important

[01:42:11 - 01:42:14]
things you have to remember okay so

[01:42:12 - 01:42:15]
whenever I'm talking about Corpus that

[01:42:14 - 01:42:18]
means your entire data so just try to

[01:42:15 - 01:42:21]
collect your entire data let's say

[01:42:18 - 01:42:25]
people then you have the

[01:42:21 - 01:42:25]
watch then you have the with

[01:42:28 - 01:42:32]
puy then you are having

[01:42:32 - 01:42:36]
um then again you are having D with

[01:42:38 - 01:42:44]
buppy Ds

[01:42:40 - 01:42:48]
with buppy then again

[01:42:44 - 01:42:48]
watch then again DS with

[01:42:50 - 01:42:55]
buy then you are having people

[01:42:54 - 01:42:59]
then

[01:42:55 - 01:42:59]
write then

[01:42:59 - 01:43:03]
comments then again DS with

[01:43:04 - 01:43:08]
buy

[01:43:06 - 01:43:13]
write

[01:43:08 - 01:43:16]
comments okay so this is your entire

[01:43:13 - 01:43:18]
Corpus okay Corpus okay Corpus of your

[01:43:16 - 01:43:21]
data now from here you have to figure

[01:43:18 - 01:43:23]
out how many unique word you are having

[01:43:21 - 01:43:29]
so we are having people

[01:43:23 - 01:43:32]
we are having watch DS with buy then uh

[01:43:29 - 01:43:35]
write and comments so these are the

[01:43:32 - 01:43:37]
unique words that means 1 2 3 4 and five

[01:43:35 - 01:43:39]
that means n is equal to five okay five

[01:43:37 - 01:43:41]
unique word we are having now what we

[01:43:39 - 01:43:43]
have to do we have to uh create a table

[01:43:41 - 01:43:46]
let's say I'll create a table with this

[01:43:43 - 01:43:49]
five unique words so the first word will

[01:43:46 - 01:43:49]
come

[01:43:50 - 01:43:55]
people the second one will come watch

[01:43:55 - 01:43:59]
then the third B will come let's say DS

[01:43:56 - 01:43:59]
with

[01:43:59 - 01:44:05]
buy then

[01:44:02 - 01:44:08]
write then

[01:44:05 - 01:44:10]
comments okay comments okay so that's

[01:44:08 - 01:44:11]
how your one encoding will try to

[01:44:10 - 01:44:13]
represent the data okay let's say

[01:44:11 - 01:44:15]
whenever you using any uh let's say

[01:44:13 - 01:44:17]
library in Python so how this Library

[01:44:15 - 01:44:18]
works exactly to perform the one

[01:44:17 - 01:44:20]
encoding that is what I'm explaining

[01:44:18 - 01:44:22]
here fine now see how it will try to

[01:44:20 - 01:44:24]
convert your text data to numerical

[01:44:22 - 01:44:26]
represent ation so first of all it will

[01:44:24 - 01:44:29]
take the row one that means

[01:44:26 - 01:44:30]
D1 let's say people now just try to find

[01:44:29 - 01:44:33]
people here so you can see people is

[01:44:30 - 01:44:35]
there that means this should be one and

[01:44:33 - 01:44:38]
everything would be

[01:44:35 - 01:44:40]
zero okay then watch now just try to

[01:44:38 - 01:44:42]
find out the watch so here is the watch

[01:44:40 - 01:44:44]
so it should be one and everything would

[01:44:42 - 01:44:49]
be zero

[01:44:44 - 01:44:51]
again okay then D is with BP so it

[01:44:49 - 01:44:54]
should be one and everything would be

[01:44:51 - 01:44:57]
zero okay so here the number actually we

[01:44:54 - 01:44:59]
got this is for the D1 that means data

[01:44:57 - 01:45:02]
one row one so here I can write like

[01:44:59 - 01:45:05]
that let's I'll just simply write D1

[01:45:02 - 01:45:11]
okay D1 is equal to so here I got one

[01:45:05 - 01:45:17]
two dimensional Vector so here 1 0 0

[01:45:11 - 01:45:17]
0 uh zero okay then

[01:45:19 - 01:45:30]
comma comma 0 1 0 0 0 then

[01:45:24 - 01:45:32]
comma I got 0 0 1 0 0 okay so this is my

[01:45:30 - 01:45:34]
D1 that means sentence one okay this is

[01:45:32 - 01:45:36]
for the sentence one okay I hope you're

[01:45:34 - 01:45:39]
clear now again you will take the

[01:45:36 - 01:45:43]
sentence two that means D2 okay

[01:45:39 - 01:45:44]
D2 now you'll just try to find the

[01:45:43 - 01:45:47]
numerical representation now let's find

[01:45:44 - 01:45:50]
the D2 as well so let's say d is with B

[01:45:47 - 01:45:53]
so again let's say this one would be um

[01:45:50 - 01:45:56]
one and everything would be zero

[01:45:53 - 01:45:59]
okay so this is for actually

[01:45:56 - 01:46:03]
D1 and now we are doing for D2 now again

[01:45:59 - 01:46:04]
it will see the watch so watch is here

[01:46:03 - 01:46:07]
it would be one and everything would be

[01:46:04 - 01:46:09]
zero again now the next thing would be

[01:46:07 - 01:46:12]
DS with B again so let's say this is a

[01:46:09 - 01:46:14]
DS with buy and everything would be zero

[01:46:12 - 01:46:16]
again okay so this is what actually your

[01:46:14 - 01:46:18]
D2 so again I can represent like that

[01:46:16 - 01:46:27]
let's say D2 is equal

[01:46:18 - 01:46:32]
to uh 0 0 1 0 0 comma 0 1 0 0 0 okay

[01:46:27 - 01:46:34]
then comma I'll take 0 0 1 0 0 okay so

[01:46:32 - 01:46:36]
this is my D2 so that's how you have to

[01:46:34 - 01:46:37]
complete for all the sentence that's how

[01:46:36 - 01:46:39]
you have to complete for all the

[01:46:37 - 01:46:41]
sentence and at the end you will get all

[01:46:39 - 01:46:43]
the vector representation okay you will

[01:46:41 - 01:46:45]
get all the vector representation I hope

[01:46:43 - 01:46:47]
it is clear okay how one encoding can be

[01:46:45 - 01:46:49]
applied now let's say you have completed

[01:46:47 - 01:46:50]
for all the sentence and you got your

[01:46:49 - 01:46:52]
vector now what you will do you will

[01:46:50 - 01:46:55]
just try to create a newal network now

[01:46:52 - 01:46:57]
just see the input size the input size

[01:46:55 - 01:47:00]
for the model you can see uh input size

[01:46:57 - 01:47:02]
would be 1 2 3 4 5 because we are having

[01:47:00 - 01:47:05]
five unique W only so everywhere you can

[01:47:02 - 01:47:06]
see five dimensional Vector 1 2 3 4 5

[01:47:05 - 01:47:10]
that means you'll be taking a neural

[01:47:06 - 01:47:12]
network like that 1 2 3 four and five

[01:47:10 - 01:47:14]
okay inside that you will take some

[01:47:12 - 01:47:16]
hidden layer and you will get your y hat

[01:47:14 - 01:47:20]
here okay so that means you will pass

[01:47:16 - 01:47:22]
the data okay you will pass the data in

[01:47:20 - 01:47:25]
this particular layer that means you

[01:47:22 - 01:47:27]
will take this particular Vector so

[01:47:25 - 01:47:28]
first of all you will you will do for

[01:47:27 - 01:47:30]
the D1 you will take this particular

[01:47:28 - 01:47:32]
Vector you will pass it here okay then

[01:47:30 - 01:47:33]
the second one you will pass it here

[01:47:32 - 01:47:35]
then the third one you will pass it here

[01:47:33 - 01:47:36]
okay that's how you'll be passing for

[01:47:35 - 01:47:39]
all the

[01:47:36 - 01:47:42]
sentence okay you'll be passing for all

[01:47:39 - 01:47:45]
the sentence but let's say in case in

[01:47:42 - 01:47:48]
your Corpus okay in your Corpus the

[01:47:45 - 01:47:51]
number of unique word is 1,000 number of

[01:47:48 - 01:47:52]
unique word is 1,000 in that case what

[01:47:51 - 01:47:54]
should be the input size of the model

[01:47:52 - 01:47:55]
definitely it will also become 1,000

[01:47:54 - 01:47:59]
that means you have to take one

[01:47:55 - 01:48:02]
dimensional sorry uh 1,000 1,000 neuron

[01:47:59 - 01:48:04]
okay at the very first that means again

[01:48:02 - 01:48:06]
complexity is increasing let's say in

[01:48:04 - 01:48:08]
your entire Corpus you are having 2,000

[01:48:06 - 01:48:11]
okay 2,000 uniqu so you have to take

[01:48:08 - 01:48:12]
2,000 actually neurons so if you're

[01:48:11 - 01:48:14]
using one in coding that means the

[01:48:12 - 01:48:16]
number of unique word you are having in

[01:48:14 - 01:48:19]
that particular Corpus based on that

[01:48:16 - 01:48:20]
your input layer would be decided okay

[01:48:19 - 01:48:22]
it's not a recommended because if your

[01:48:20 - 01:48:25]
input if your let's say unique word is

[01:48:22 - 01:48:27]
inre ining your uh neurons is also

[01:48:25 - 01:48:29]
increasing and whenever you are

[01:48:27 - 01:48:31]
increasing the neurons your uh

[01:48:29 - 01:48:32]
calculation would be increased also

[01:48:31 - 01:48:34]
because at the end you are doing uh

[01:48:32 - 01:48:36]
neuron calculation you are doing the

[01:48:34 - 01:48:38]
computation here so computational cost

[01:48:36 - 01:48:40]
will also increase right so that's why

[01:48:38 - 01:48:42]
it's not a recommended way again there

[01:48:40 - 01:48:44]
is another issue let's say I'm having a

[01:48:42 - 01:48:46]
sentence and which have actually the

[01:48:44 - 01:48:50]
word which is not present in my Corpus

[01:48:46 - 01:48:51]
let's say I can write my name is buy

[01:48:50 - 01:48:53]
let's say this sentence actually I'm

[01:48:51 - 01:48:54]
having

[01:48:53 - 01:48:58]
okay now just try to see these are the

[01:48:54 - 01:49:00]
word is having in my entire Corpus no

[01:48:58 - 01:49:02]
these are the word is not present inside

[01:49:00 - 01:49:03]
my entire Corpus okay that means what

[01:49:02 - 01:49:06]
will happen it would be out of

[01:49:03 - 01:49:08]
vocabulary issue that means the vocabul

[01:49:06 - 01:49:10]
you are having right now it is not

[01:49:08 - 01:49:12]
present inside your Corpus so your model

[01:49:10 - 01:49:14]
won be able to understand these are the

[01:49:12 - 01:49:16]
what because you haven't used this data

[01:49:14 - 01:49:18]
during training so whenever you are

[01:49:16 - 01:49:19]
giving doing testing definitely it won't

[01:49:18 - 01:49:21]
be able to understand what kinds of

[01:49:19 - 01:49:23]
sentence you are giving so again it is

[01:49:21 - 01:49:27]
called actually out of vocabulary issue

[01:49:23 - 01:49:29]
O oov Okay out of vocabulary issue so if

[01:49:27 - 01:49:31]
you're using one encoding so you will

[01:49:29 - 01:49:32]
get this kinds of issue okay out of

[01:49:31 - 01:49:35]
vocabulary issue and another issue I

[01:49:32 - 01:49:37]
think you saw here you are having lots

[01:49:35 - 01:49:39]
of zeros you are having lots of zeros

[01:49:37 - 01:49:41]
and zero is what it's a sparity problem

[01:49:39 - 01:49:43]
that means it's a SP sparse Matrix you

[01:49:41 - 01:49:45]
are having okay and whenever you are

[01:49:43 - 01:49:47]
doing the computation and whenever you

[01:49:45 - 01:49:50]
are using zero okay to perform any kinds

[01:49:47 - 01:49:52]
of operation with number so there is uh

[01:49:50 - 01:49:54]
no meaning right that's why zero is

[01:49:52 - 01:49:56]
unnecessary number here zero is

[01:49:54 - 01:49:58]
unnecessary number here so you are

[01:49:56 - 01:50:01]
unnecessarily increasing the computation

[01:49:58 - 01:50:04]
here because with because you can see

[01:50:01 - 01:50:07]
zeros is increasing the dimension in

[01:50:04 - 01:50:09]
this particular case so let me just

[01:50:07 - 01:50:13]
write some of the drawbacks of the one

[01:50:09 - 01:50:13]
encoding so here I'll just write the

[01:50:14 - 01:50:18]
drawbacks so the first drawbacks you can

[01:50:16 - 01:50:20]
see the

[01:50:18 - 01:50:23]
sparity that means here you are having

[01:50:20 - 01:50:27]
lots of zeros then the second you you

[01:50:23 - 01:50:29]
can see the no fix sized because anytime

[01:50:27 - 01:50:31]
your sentence might be anything okay

[01:50:29 - 01:50:33]
let's say here I have taken uh people

[01:50:31 - 01:50:35]
watch DS with buy I can take also my

[01:50:33 - 01:50:37]
name is buy then I'm a data scientist

[01:50:35 - 01:50:39]
now just count of the sentence length

[01:50:37 - 01:50:43]
you will see that it would be bigger

[01:50:39 - 01:50:45]
okay so you can write no fixed size then

[01:50:43 - 01:50:47]
the third you saw o that means out of

[01:50:45 - 01:50:49]
vocabulary issue and the fourth

[01:50:47 - 01:50:54]
important things it is

[01:50:49 - 01:50:54]
not not capturing semantic mining

[01:50:55 - 01:50:59]
meaning semantic meaning semantic

[01:50:58 - 01:51:02]
meaning

[01:50:59 - 01:51:04]
means uh after people watch is coming

[01:51:02 - 01:51:06]
after watch DS with buy is coming before

[01:51:04 - 01:51:08]
DS with buy watch is coming before watch

[01:51:06 - 01:51:10]
people is coming these kinds of semantic

[01:51:08 - 01:51:11]
information semantic relationship this

[01:51:10 - 01:51:13]
is not capturing because it's just a

[01:51:11 - 01:51:15]
number and whenever this word is present

[01:51:13 - 01:51:17]
it is giving one otherwise everything it

[01:51:15 - 01:51:18]
is giving as zero that means this

[01:51:17 - 01:51:21]
particular number is not capturing the

[01:51:18 - 01:51:24]
semantic information of your sentence

[01:51:21 - 01:51:25]
but whenever we are using Text data so

[01:51:24 - 01:51:27]
definitely it will have the semantic

[01:51:25 - 01:51:29]
relationship that means it will follow

[01:51:27 - 01:51:30]
on grammar what is what kinds of grammar

[01:51:29 - 01:51:32]
let's say whenever I'm writing any kinds

[01:51:30 - 01:51:35]
of sentence let's say my name is buy so

[01:51:32 - 01:51:39]
my is a subject so my is a subject name

[01:51:35 - 01:51:40]
is noun okay is is verb bu is also noun

[01:51:39 - 01:51:43]
that's how it is following on

[01:51:40 - 01:51:44]
grammatical rule grammatical rule okay

[01:51:43 - 01:51:48]
that means after my name will come after

[01:51:44 - 01:51:49]
name uh is will come after is buy will

[01:51:48 - 01:51:51]
come okay so it is following one

[01:51:49 - 01:51:52]
relationship it is following one

[01:51:51 - 01:51:54]
relationship like that right so this

[01:51:52 - 01:51:55]
kinds of relationship it won't be able

[01:51:54 - 01:51:58]
to capture if you're using one not

[01:51:55 - 01:52:00]
encoding okay so that's why we can't use

[01:51:58 - 01:52:02]
this particular uh method okay we can't

[01:52:00 - 01:52:05]
use this particular method

[01:52:02 - 01:52:07]
whenever we want to convert our data to

[01:52:05 - 01:52:09]
numerical representation that means

[01:52:07 - 01:52:11]
Vector representation okay inside

[01:52:09 - 01:52:14]
generative so this technique you don't

[01:52:11 - 01:52:16]
have to follow because it's like very

[01:52:14 - 01:52:17]
basic technique if you're doing any

[01:52:16 - 01:52:19]
machine learning project if you have

[01:52:17 - 01:52:22]
some if you have some level of

[01:52:19 - 01:52:24]
categorical data in a column you can use

[01:52:22 - 01:52:26]
this uh I mean one not encoding that but

[01:52:24 - 01:52:29]
whenever you are working with completely

[01:52:26 - 01:52:30]
textual data inside Genera VI I own

[01:52:29 - 01:52:32]
suggest don't use this particular method

[01:52:30 - 01:52:34]
because I already showed you some of the

[01:52:32 - 01:52:35]
drawbacks you will get here so now the

[01:52:34 - 01:52:39]
second technique we'll be discussing

[01:52:35 - 01:52:41]
about bag of word okay bag of word now

[01:52:39 - 01:52:43]
let's try to see the back back of word

[01:52:41 - 01:52:45]
example like how it will work so for

[01:52:43 - 01:52:47]
this I'm going to copy the same table so

[01:52:45 - 01:52:50]
again uh you can consider the same

[01:52:47 - 01:52:51]
things Corpus so I'm using the same

[01:52:50 - 01:52:54]
table that means it will have the same

[01:52:51 - 01:52:57]
Corpus again again the number of let's

[01:52:54 - 01:52:59]
say uh uni word would be five and you

[01:52:57 - 01:53:02]
have to create a five uni word table so

[01:52:59 - 01:53:04]
let me again copy now how this bag of

[01:53:02 - 01:53:07]
word will work see see this bag of word

[01:53:04 - 01:53:10]
will work based on the count okay based

[01:53:07 - 01:53:12]
on the count of the what present in your

[01:53:10 - 01:53:15]
entire Corpus so let's say first of all

[01:53:12 - 01:53:17]
it will see people um so now just try to

[01:53:15 - 01:53:19]
tell me how many times people you can

[01:53:17 - 01:53:21]
see in this particular

[01:53:19 - 01:53:25]
sentence uh I can see only one time so

[01:53:21 - 01:53:28]
people is coming only one time okay

[01:53:25 - 01:53:29]
now now the next word watch so how many

[01:53:28 - 01:53:32]
time watch is occurring in this

[01:53:29 - 01:53:35]
particular sentence only one then DS

[01:53:32 - 01:53:37]
with buy one time and right is there no

[01:53:35 - 01:53:38]
so right is not there it would be zero

[01:53:37 - 01:53:41]
and comment is not also there it would

[01:53:38 - 01:53:44]
be zero okay then the next sentence you

[01:53:41 - 01:53:45]
can see DS with buy only one uh DS with

[01:53:44 - 01:53:48]
buppy now occurring two times so it

[01:53:45 - 01:53:51]
would be two then watch is occurring

[01:53:48 - 01:53:54]
only one time one and uh people is not

[01:53:51 - 01:53:56]
there right is are not there comment is

[01:53:54 - 01:53:59]
not is not also there right now the

[01:53:56 - 01:54:01]
third sentence people is coming one time

[01:53:59 - 01:54:05]
right is coming one

[01:54:01 - 01:54:07]
time okay comment is coming one time and

[01:54:05 - 01:54:10]
watch is not there the is not there now

[01:54:07 - 01:54:13]
now the last sentence DS with the p only

[01:54:10 - 01:54:17]
one time write is only one time comment

[01:54:13 - 01:54:18]
is only one time DS with uh sorry uh

[01:54:17 - 01:54:20]
watch is not there people is not there

[01:54:18 - 01:54:22]
okay so this is how actually you'll be

[01:54:20 - 01:54:23]
generating the vector okay this is how

[01:54:22 - 01:54:25]
actually be generating the vector now

[01:54:23 - 01:54:28]
just try to match with your previous

[01:54:25 - 01:54:30]
Vector what you have observed you

[01:54:28 - 01:54:32]
see the bag of what technique you have

[01:54:30 - 01:54:34]
applied it is having very less zeros

[01:54:32 - 01:54:36]
than your one not encoding okay that

[01:54:34 - 01:54:38]
means it is slight better than your one

[01:54:36 - 01:54:40]
not encoding okay because it is working

[01:54:38 - 01:54:43]
based on the counting okay based on the

[01:54:40 - 01:54:46]
counting okay counting of the word

[01:54:43 - 01:54:49]
present in the sentence okay this is the

[01:54:46 - 01:54:51]
idea now research proven

[01:54:49 - 01:54:53]
research okay research already proven

[01:54:51 - 01:54:54]
that

[01:54:53 - 01:54:56]
if if you if you want to do something

[01:54:54 - 01:54:59]
called classification kinds of task

[01:54:56 - 01:55:01]
let's say sentiment analysis okay

[01:54:59 - 01:55:03]
sentiment analysis then let's say we are

[01:55:01 - 01:55:06]
performing positive negative reviews

[01:55:03 - 01:55:09]
okay these kinds of task you can use

[01:55:06 - 01:55:11]
this uh V for technique to perform the

[01:55:09 - 01:55:13]
text vectorization because this is

[01:55:11 - 01:55:14]
suitable for this particular task

[01:55:13 - 01:55:16]
because if you see any kinds of

[01:55:14 - 01:55:20]
sentiment analysis problem let's say

[01:55:16 - 01:55:24]
here I'm having some sentiments this

[01:55:20 - 01:55:24]
movie is

[01:55:24 - 01:55:30]
wow or you can also write this

[01:55:31 - 01:55:34]
movie is

[01:55:35 - 01:55:39]
amazing

[01:55:38 - 01:55:41]
amazing

[01:55:39 - 01:55:43]
performance okay performance let's say

[01:55:41 - 01:55:45]
this kinds of reviews you are having now

[01:55:43 - 01:55:47]
if you want to find the positive okay

[01:55:45 - 01:55:51]
positive or it's a negative I can see

[01:55:47 - 01:55:53]
the let's say word so movie amazing

[01:55:51 - 01:55:55]
amazing performance okay you can see

[01:55:53 - 01:55:57]
amazing this particular positive ver is

[01:55:55 - 01:55:58]
occurring like multiple time that that

[01:55:57 - 01:56:01]
time I can consider it's a positive

[01:55:58 - 01:56:02]
review okay it's a positive review so

[01:56:01 - 01:56:04]
that is why it's a frequence frequency

[01:56:02 - 01:56:06]
based actually approach so it will

[01:56:04 - 01:56:08]
always try to see the frequency

[01:56:06 - 01:56:09]
frequency count in in a sentence and

[01:56:08 - 01:56:12]
based on that it will decide whether

[01:56:09 - 01:56:14]
it's a let's say positive sentiment or

[01:56:12 - 01:56:15]
whether it's a negative sentiments okay

[01:56:14 - 01:56:16]
so that is why it is recommended if

[01:56:15 - 01:56:19]
you're performing any classification

[01:56:16 - 01:56:22]
kinds of task inside a text you can use

[01:56:19 - 01:56:24]
this particular approach okay but again

[01:56:22 - 01:56:26]
um one drawbacks you'll see it is not

[01:56:24 - 01:56:27]
capturing the semantic information like

[01:56:26 - 01:56:29]
after DS with buy watch is coming after

[01:56:27 - 01:56:31]
watch DS with buy is coming all people

[01:56:29 - 01:56:33]
watch is coming afterward with bu is

[01:56:31 - 01:56:35]
coming so this kinds of semantic

[01:56:33 - 01:56:37]
information it is not able to capture so

[01:56:35 - 01:56:40]
again it's a drawback okay and some of

[01:56:37 - 01:56:41]
the zeros still you can see okay because

[01:56:40 - 01:56:44]
again it will increase that uh your

[01:56:41 - 01:56:45]
computational cost because zero doesn't

[01:56:44 - 01:56:47]
have any kinds of meaning if you're

[01:56:45 - 01:56:49]
doing any kinds of operation right this

[01:56:47 - 01:56:51]
is the idea fine so apart from that we

[01:56:49 - 01:56:55]
are having some more Technique we can

[01:56:51 - 01:56:58]
follow like we having something called

[01:56:55 - 01:57:01]
TFI DF so we are having tfidf then we

[01:56:58 - 01:57:05]
are also having another technique called

[01:57:01 - 01:57:08]
word uh word to V so this one use one

[01:57:05 - 01:57:10]
statistical let's equation to perform

[01:57:08 - 01:57:12]
let's say vectorization and this one is

[01:57:10 - 01:57:14]
the de deep learning based actually

[01:57:12 - 01:57:16]
vectorization technique okay and from

[01:57:14 - 01:57:18]
this technique actually lots of idea

[01:57:16 - 01:57:20]
came how we can use the Transformer

[01:57:18 - 01:57:22]
model to perform the feature extraction

[01:57:20 - 01:57:24]
because uh whenever I'll teach you this

[01:57:22 - 01:57:25]
word to B technique I'll show you the

[01:57:24 - 01:57:27]
feature extraction technique so how it

[01:57:25 - 01:57:29]
will extract the features from a

[01:57:27 - 01:57:32]
sentence let's say from a text okay so

[01:57:29 - 01:57:34]
from here actually idea came then people

[01:57:32 - 01:57:36]
have uh actually launched Transformer

[01:57:34 - 01:57:38]
based actually

[01:57:36 - 01:57:39]
Transformer based actually encoding

[01:57:38 - 01:57:41]
technique that means with the help of

[01:57:39 - 01:57:42]
Transformer model you can perform the

[01:57:41 - 01:57:44]
text representation that means you can

[01:57:42 - 01:57:46]
convert your text to Vector

[01:57:44 - 01:57:48]
representation and whatever large

[01:57:46 - 01:57:49]
language model you using okay llm you'll

[01:57:48 - 01:57:51]
be using this Transformer based approach

[01:57:49 - 01:57:52]
only to convert your data to the

[01:57:51 - 01:57:54]
numerical representation so whenever

[01:57:52 - 01:57:55]
we'll do the Practical that time

[01:57:54 - 01:57:56]
definitely I'll will show you okay we'll

[01:57:55 - 01:57:58]
be downloading the model from the

[01:57:56 - 01:58:01]
hugging face hugging face is also having

[01:57:58 - 01:58:04]
lots of tokenizer that means these kinds

[01:58:01 - 01:58:05]
of uh encoding encoding model okay with

[01:58:04 - 01:58:07]
the help of that we can easily convert

[01:58:05 - 01:58:09]
our data to the numerical representation

[01:58:07 - 01:58:11]
fine so as of now let me uh show you all

[01:58:09 - 01:58:14]
the Practical that means this bag of

[01:58:11 - 01:58:15]
word then TF IDF then what to B okay how

[01:58:14 - 01:58:17]
we can use it and all but before

[01:58:15 - 01:58:19]
discussing tfidf and what to B I just

[01:58:17 - 01:58:21]
wanted to show you this bag of word

[01:58:19 - 01:58:23]
practical so for this what I will do I

[01:58:21 - 01:58:24]
will uh open up up my collab notebook

[01:58:23 - 01:58:26]
and there I'll show you this particular

[01:58:24 - 01:58:28]
practical so guys here you can see I

[01:58:26 - 01:58:30]
already prepared one collab notebook for

[01:58:28 - 01:58:32]
you so one not encoding I'm not going to

[01:58:30 - 01:58:35]
show you because uh you already know how

[01:58:32 - 01:58:36]
to perform one encoding so with the help

[01:58:35 - 01:58:39]
of Panda's Library also we can perform

[01:58:36 - 01:58:41]
one one encoding even uh we also have

[01:58:39 - 01:58:44]
one let's say class inside esal and

[01:58:41 - 01:58:46]
Library okay to perform the one encoding

[01:58:44 - 01:58:47]
so I'm expecting if you already work

[01:58:46 - 01:58:49]
with machine learning you'll know how to

[01:58:47 - 01:58:50]
perform one encoding and again we are

[01:58:49 - 01:58:53]
not going to use one encoding technique

[01:58:50 - 01:58:55]
in our analysis but bag of what we be

[01:58:53 - 01:58:56]
using sometimes because I told you now

[01:58:55 - 01:58:58]
if you're doing any kind of sentiment

[01:58:56 - 01:59:00]
analysis and all that time you can

[01:58:58 - 01:59:03]
perform because it's easy to implement

[01:59:00 - 01:59:04]
okay at the end now see uh bag of word

[01:59:03 - 01:59:08]
for this I need two library npay and

[01:59:04 - 01:59:09]
Panda so let me import them so with the

[01:59:08 - 01:59:11]
pandas actually I'll be creating a data

[01:59:09 - 01:59:13]
set first of all so the same data set

[01:59:11 - 01:59:15]
example I have taken the data set I

[01:59:13 - 01:59:17]
showed in my whiteboard okay so you can

[01:59:15 - 01:59:18]
see people watch this with buy D with

[01:59:17 - 01:59:21]
what DS with buy okay these kinds of

[01:59:18 - 01:59:23]
example I have taken now let me prepare

[01:59:21 - 01:59:25]
the data frame

[01:59:23 - 01:59:27]
okay so this is my data frame and here I

[01:59:25 - 01:59:28]
also have taken another let's say column

[01:59:27 - 01:59:29]
called output let's say whether it's a

[01:59:28 - 01:59:31]
positive whether it's a negative so

[01:59:29 - 01:59:33]
that's how have just given a number okay

[01:59:31 - 01:59:35]
it's just a assumption number as of now

[01:59:33 - 01:59:37]
um don't try to think it's a actual

[01:59:35 - 01:59:38]
number fine one means it's a positive

[01:59:37 - 01:59:40]
zero means it's a negative okay but

[01:59:38 - 01:59:42]
whenever you will be using actual data

[01:59:40 - 01:59:44]
there will have the positive negative

[01:59:42 - 01:59:46]
previews okay based on the text you are

[01:59:44 - 01:59:48]
having I hope it is clear now if you

[01:59:46 - 01:59:50]
want to perform bag of word technique

[01:59:48 - 01:59:52]
you have to use one uh Library called

[01:59:50 - 01:59:54]
escalan from escalan you you have to use

[01:59:52 - 01:59:55]
something called count vectorizer okay

[01:59:54 - 01:59:57]
so count vectorizer is nothing but it's

[01:59:55 - 01:59:59]
a bag of word technique so I I know that

[01:59:57 - 02:00:00]
many of you already use this count

[01:59:59 - 02:00:02]
vectorizer in your machine learning but

[02:00:00 - 02:00:03]
you don't know this is a bag of word

[02:00:02 - 02:00:06]
okay so now just try to remember it's a

[02:00:03 - 02:00:08]
bag of word technique only right now we

[02:00:06 - 02:00:10]
have created the U like uh counter

[02:00:08 - 02:00:13]
vectorizer object now here I just need

[02:00:10 - 02:00:15]
to fit my data and I want to fit my data

[02:00:13 - 02:00:18]
on top of my text that means Text data

[02:00:15 - 02:00:21]
now here I'm fitting the data now it

[02:00:18 - 02:00:23]
will return me all the vocab now see uh

[02:00:21 - 02:00:25]
what will happen here it will just uh

[02:00:23 - 02:00:26]
assign some of the index number okay it

[02:00:25 - 02:00:29]
will just assign some of the index

[02:00:26 - 02:00:30]
number with all the words now who

[02:00:29 - 02:00:32]
whoever having actually zero that means

[02:00:30 - 02:00:33]
this is the first index that means this

[02:00:32 - 02:00:36]
word would be considered at the very

[02:00:33 - 02:00:38]
first then uh this one that means number

[02:00:36 - 02:00:40]
one then two three and so on right now

[02:00:38 - 02:00:42]
how it is generating this particular

[02:00:40 - 02:00:44]
array so let me just try to discuss now

[02:00:42 - 02:00:45]
just try to see which word is coming at

[02:00:44 - 02:00:47]
the very first based on the index

[02:00:45 - 02:00:50]
comments now let's try to see comment is

[02:00:47 - 02:00:52]
there in the first sentence no comment

[02:00:50 - 02:00:54]
is not there that's why it is coming as

[02:00:52 - 02:00:55]
zero got it now the second sentence you

[02:00:54 - 02:00:58]
can

[02:00:55 - 02:01:00]
see now the second word you can see DS

[02:00:58 - 02:01:02]
with buy now tell me DS with bu is there

[02:01:00 - 02:01:05]
yes how many time only one time that's

[02:01:02 - 02:01:07]
why it's coming as one okay then the

[02:01:05 - 02:01:10]
next one people people is there yes how

[02:01:07 - 02:01:12]
many time only one time okay then the

[02:01:10 - 02:01:14]
next word watch watch is there yes is

[02:01:12 - 02:01:16]
there how many time only one time then

[02:01:14 - 02:01:17]
the next one I think last one right

[02:01:16 - 02:01:20]
right is there no right is not there

[02:01:17 - 02:01:22]
that's why uh it is coming zero okay now

[02:01:20 - 02:01:25]
let's consider the second sentence okay

[02:01:22 - 02:01:28]
now again you have to consider based on

[02:01:25 - 02:01:29]
the index again comments is there no

[02:01:28 - 02:01:33]
comment is not there so that's why it's

[02:01:29 - 02:01:35]
zero now next thing yes with B yes it is

[02:01:33 - 02:01:37]
there how many time two time that's why

[02:01:35 - 02:01:40]
it's coming as two okay then uh you can

[02:01:37 - 02:01:43]
see the next one people people is not

[02:01:40 - 02:01:45]
there that's why it's coming as zero

[02:01:43 - 02:01:47]
okay it's coming as zero zero then after

[02:01:45 - 02:01:49]
people actually we are having watch

[02:01:47 - 02:01:53]
watch is there is there how many time

[02:01:49 - 02:01:56]
only one time okay then after that uh we

[02:01:53 - 02:01:58]
are having something called um this one

[02:01:56 - 02:01:59]
right right is there no right is not

[02:01:58 - 02:02:02]
there that's why it's coming as zero

[02:01:59 - 02:02:03]
that's how it you have to consider for

[02:02:02 - 02:02:06]
all the sentence I hope it is clear how

[02:02:03 - 02:02:08]
it is generating this particular number

[02:02:06 - 02:02:10]
okay and this is your vector okay this

[02:02:08 - 02:02:11]
Vector actually you can pass to the

[02:02:10 - 02:02:13]
model okay this Vector you can pass to

[02:02:11 - 02:02:16]
the model so if you're only printing

[02:02:13 - 02:02:19]
this B object see what you will get you

[02:02:16 - 02:02:21]
will get one object here okay you will

[02:02:19 - 02:02:22]
get one sperse Matrix object and if you

[02:02:21 - 02:02:24]
want to get the

[02:02:22 - 02:02:26]
uh number that means the complete array

[02:02:24 - 02:02:27]
you have to use this particular method

[02:02:26 - 02:02:29]
called two array that's why every time

[02:02:27 - 02:02:31]
I'm doing this one okay just to show you

[02:02:29 - 02:02:33]
uh to show you all the number that is

[02:02:31 - 02:02:35]
the idea fine now if I want to perform

[02:02:33 - 02:02:37]
on top of my new data let's say this is

[02:02:35 - 02:02:39]
one sentence I've given B watch this

[02:02:37 - 02:02:41]
with buy uh so I have to use this

[02:02:39 - 02:02:43]
particular transform okay transform

[02:02:41 - 02:02:45]
function that time cv. transform pass

[02:02:43 - 02:02:48]
your data and convert it to two again

[02:02:45 - 02:02:50]
you will see your data representation

[02:02:48 - 02:02:52]
fine now what you can do you can store

[02:02:50 - 02:02:57]
your X and Y data let's say x is nothing

[02:02:52 - 02:02:59]
but my entire B and uh Y is nothing but

[02:02:57 - 02:03:01]
my output so this is my output okay

[02:02:59 - 02:03:03]
positive or negative now you can pass

[02:03:01 - 02:03:06]
this data to the model okay this is the

[02:03:03 - 02:03:08]
idea got it now there is another things

[02:03:06 - 02:03:11]
inside bag of for called NRS okay what

[02:03:08 - 02:03:13]
is NRS NRS is nothing but here you see

[02:03:11 - 02:03:15]
NRS is nothing but here you do the same

[02:03:13 - 02:03:18]
thing only you give one NRS parameter so

[02:03:15 - 02:03:19]
let's say if engram parameter is two so

[02:03:18 - 02:03:21]
what will happen let's say engram

[02:03:19 - 02:03:22]
parameter is equal to two that means it

[02:03:21 - 02:03:24]
will consider two two word as a one

[02:03:22 - 02:03:26]
token okay two word as a one token see

[02:03:24 - 02:03:28]
previously I I took individual word

[02:03:26 - 02:03:30]
right now it will consider two word as

[02:03:28 - 02:03:32]
one token that means here it will come

[02:03:30 - 02:03:34]
people watch okay inside this box people

[02:03:32 - 02:03:36]
watch will come then watch DS with buppy

[02:03:34 - 02:03:38]
will come okay so that's how you have to

[02:03:36 - 02:03:39]
take pair of word pair of word okay and

[02:03:38 - 02:03:41]
you have to perform the same thing so

[02:03:39 - 02:03:44]
this is called actually n Gams now let's

[02:03:41 - 02:03:45]
say n is equal to three that time three

[02:03:44 - 02:03:48]
pair will come that means three word you

[02:03:45 - 02:03:50]
have to consider okay but I saw that

[02:03:48 - 02:03:52]
people are using only two uh parameter

[02:03:50 - 02:03:54]
because sometimes uh it is required so

[02:03:52 - 02:03:56]
let me show you one example why it is

[02:03:54 - 02:03:59]
required so let's say here I'm having a

[02:03:56 - 02:04:02]
review

[02:03:59 - 02:04:05]
movie is very good and here I can write

[02:04:02 - 02:04:05]
it this

[02:04:06 - 02:04:12]
movie is

[02:04:08 - 02:04:15]
not very

[02:04:12 - 02:04:16]
good now this one is the positive uh

[02:04:15 - 02:04:19]
sentiment you know this one is the

[02:04:16 - 02:04:21]
negative sentiment you know okay but how

[02:04:19 - 02:04:22]
about your model okay how it will

[02:04:21 - 02:04:24]
identify because I told you based on the

[02:04:22 - 02:04:26]
frequency count it can decide let's say

[02:04:24 - 02:04:29]
let's say you are having some word let's

[02:04:26 - 02:04:31]
say very good movie okay that means it's

[02:04:29 - 02:04:33]
a positive one and if it is coming to

[02:04:31 - 02:04:35]
the second sentence let's say this is

[02:04:33 - 02:04:38]
the first sent the second sentence again

[02:04:35 - 02:04:39]
it can consider movie very good and it

[02:04:38 - 02:04:41]
will ignore this one because it's a stop

[02:04:39 - 02:04:42]
word I think I taught you the stop word

[02:04:41 - 02:04:45]
concept right not would be considered

[02:04:42 - 02:04:46]
stop word so again your model will try

[02:04:45 - 02:04:48]
to consider it's a positive okay it's a

[02:04:46 - 02:04:50]
positive review but all it's a negative

[02:04:48 - 02:04:52]
review but how I can capture this

[02:04:50 - 02:04:55]
negative information so if I am doing

[02:04:52 - 02:04:57]
this n gs that means if n is equal to

[02:04:55 - 02:05:00]
let's say n g is equal to two it will

[02:04:57 - 02:05:03]
consider two word as a pair okay two

[02:05:00 - 02:05:05]
word as appear so the first two word

[02:05:03 - 02:05:07]
then second two word then these two word

[02:05:05 - 02:05:09]
and this two word okay so it's a

[02:05:07 - 02:05:11]
positive one you can see now you can see

[02:05:09 - 02:05:14]
it's a positive one so this movie very

[02:05:11 - 02:05:17]
good okay now again if I just uh make

[02:05:14 - 02:05:21]
this this sentence let's say this word

[02:05:17 - 02:05:23]
this word this word this word and this

[02:05:21 - 02:05:25]
word now you can see easily it is

[02:05:23 - 02:05:27]
capturing is not okay is not now see it

[02:05:25 - 02:05:30]
is easily capturing this is not that

[02:05:27 - 02:05:33]
means not word as well okay now easily

[02:05:30 - 02:05:35]
your model can identify it's a negative

[02:05:33 - 02:05:36]
okay it's a negative sentiments okay so

[02:05:35 - 02:05:39]
that's why sometimes we have to perform

[02:05:36 - 02:05:41]
this particular n Gams operation okay

[02:05:39 - 02:05:42]
because if you're giving nram parameter

[02:05:41 - 02:05:45]
is equal to two that time it will

[02:05:42 - 02:05:47]
consider two tokens okay in one just

[02:05:45 - 02:05:49]
let's say representation and it can

[02:05:47 - 02:05:50]
capture some of the hidden information

[02:05:49 - 02:05:53]
okay this is the idea now let's see the

[02:05:50 - 02:05:55]
practical so here you can see the same

[02:05:53 - 02:05:58]
uh example only you have to use the

[02:05:55 - 02:06:00]
counter vectorizer I'll convert to the

[02:05:58 - 02:06:02]
text now see whenever I used counter

[02:06:00 - 02:06:04]
vectorizer here I have given a parameter

[02:06:02 - 02:06:06]
NRS range is equal to 2 2 comma 2 that

[02:06:04 - 02:06:08]
means it will consider two words okay

[02:06:06 - 02:06:10]
now you can see people watch watch DS

[02:06:08 - 02:06:12]
with PDS with B P Watch okay now it is

[02:06:10 - 02:06:14]
considering two tokens okay uh in just

[02:06:12 - 02:06:16]
one representation that is the idea if

[02:06:14 - 02:06:17]
you give three so if you give three here

[02:06:16 - 02:06:19]
it will consider as a three word okay

[02:06:17 - 02:06:22]
three word as a count okay that's how

[02:06:19 - 02:06:23]
you can consider fine and if you're

[02:06:22 - 02:06:25]
using three three word that means it

[02:06:23 - 02:06:28]
would be considered as a tyram okay

[02:06:25 - 02:06:29]
tyram and the if you're using two words

[02:06:28 - 02:06:31]
if you're using two it would be

[02:06:29 - 02:06:33]
considered as a pams okay this is the

[02:06:31 - 02:06:34]
idea now there is another technique I

[02:06:33 - 02:06:37]
already show you TF IDF that means TR

[02:06:34 - 02:06:38]
frequency inverse document frequency so

[02:06:37 - 02:06:40]
this will work based on one equation

[02:06:38 - 02:06:42]
based on one let's statistical equation

[02:06:40 - 02:06:45]
so simply in Google you can search for

[02:06:42 - 02:06:49]
this equation

[02:06:45 - 02:06:52]
TF uh TF I DF so you'll see this

[02:06:49 - 02:06:55]
particular formula so yes this is the

[02:06:52 - 02:06:57]
formula guys it use okay to perform this

[02:06:55 - 02:06:59]
uh text representation technique okay so

[02:06:57 - 02:07:02]
it will work based on the let's say

[02:06:59 - 02:07:04]
weight let's say let's say if anyone

[02:07:02 - 02:07:06]
what is having let's say uh frequent

[02:07:04 - 02:07:07]
count okay in a sentence it will give

[02:07:06 - 02:07:09]
more weight okay it will give more

[02:07:07 - 02:07:11]
weight now if I show you the

[02:07:09 - 02:07:13]
representation so you have to use this

[02:07:11 - 02:07:15]
escalan to initialize TF tfidf

[02:07:13 - 02:07:17]
vectorizer now inside that you can pass

[02:07:15 - 02:07:18]
your data let say text dataa I'm passing

[02:07:17 - 02:07:20]
again I'm converting to the array

[02:07:18 - 02:07:22]
representation now see you are getting

[02:07:20 - 02:07:24]
the entire array okay now see none of

[02:07:22 - 02:07:27]
the number is zero complete zero you

[02:07:24 - 02:07:30]
will still get some number okay it would

[02:07:27 - 02:07:32]
be a floating number so this technique

[02:07:30 - 02:07:34]
helps us to reduce that sparse Matrix

[02:07:32 - 02:07:36]
dimensionality issue because uh if

[02:07:34 - 02:07:37]
you're are using zero okay zero in your

[02:07:36 - 02:07:39]
let's say Vector you are doing

[02:07:37 - 02:07:42]
unnecessary computation that's why it

[02:07:39 - 02:07:43]
will assign the weights and weight is

[02:07:42 - 02:07:45]
nothing but it's a floating number okay

[02:07:43 - 02:07:47]
and everywhere you will see the floating

[02:07:45 - 02:07:48]
number so this particular issue will be

[02:07:47 - 02:07:50]
resolved because still after performing

[02:07:48 - 02:07:53]
bag of word you are generating some

[02:07:50 - 02:07:54]
zeros but if you're using tfidf you are

[02:07:53 - 02:07:56]
not generating any kinds of zeros okay

[02:07:54 - 02:07:58]
so this is the B benefit here and this

[02:07:56 - 02:08:01]
is better than your uh let's say this

[02:07:58 - 02:08:03]
one uh bort okay sometimes you can also

[02:08:01 - 02:08:05]
use this tfidf technique again I won't

[02:08:03 - 02:08:08]
be recommended to use this one because

[02:08:05 - 02:08:09]
we have some better option to do next uh

[02:08:08 - 02:08:11]
thing I'll be teaching you that what to

[02:08:09 - 02:08:12]
V technique that means we'll be using

[02:08:11 - 02:08:15]
deep learning model for the fure

[02:08:12 - 02:08:16]
extraction okay and this will uh contain

[02:08:15 - 02:08:19]
the santic information because again if

[02:08:16 - 02:08:21]
you see this TF IDF is not able to uh

[02:08:19 - 02:08:23]
actually contain the centic information

[02:08:21 - 02:08:25]
that means after let's say people watch

[02:08:23 - 02:08:27]
is coming after watch D with B is coming

[02:08:25 - 02:08:30]
these kinds of santic information is not

[02:08:27 - 02:08:32]
able to capture okay so again I won't be

[02:08:30 - 02:08:34]
recommended to use this TF IDF technique

[02:08:32 - 02:08:37]
here as well fine and here is the some

[02:08:34 - 02:08:38]
TF IDF value okay if you are

[02:08:37 - 02:08:39]
understanding this formula you'll get it

[02:08:38 - 02:08:41]
okay what kinds of things it is

[02:08:39 - 02:08:43]
generating but initially I won't be

[02:08:41 - 02:08:44]
suggesting you to Deep dive in this

[02:08:43 - 02:08:46]
equation because again because again

[02:08:44 - 02:08:48]
it's not a recommended we won't be using

[02:08:46 - 02:08:50]
it okay we'll be understanding whatever

[02:08:48 - 02:08:52]
actually we need okay for our large

[02:08:50 - 02:08:53]
language model that's that idea so yes

[02:08:52 - 02:08:55]
these are some actually practical I

[02:08:53 - 02:08:56]
showed you for the text representation

[02:08:55 - 02:08:58]
technique and word embedding technique

[02:08:56 - 02:09:01]
now the next thing we'll be discussing

[02:08:58 - 02:09:02]
about uh this one a word to V technique

[02:09:01 - 02:09:04]
a word to V technique okay now let's try

[02:09:02 - 02:09:06]
to see how word to V technique works

[02:09:04 - 02:09:09]
okay so guys now we'll be discussing

[02:09:06 - 02:09:12]
about word to

[02:09:09 - 02:09:15]
V so this is the Deep learning approach

[02:09:12 - 02:09:17]
actually so how what to vake uh works

[02:09:15 - 02:09:20]
and how it will extract the features

[02:09:17 - 02:09:23]
from the uh data itself I'll try to

[02:09:20 - 02:09:25]
clarify see what to V actually use uh

[02:09:23 - 02:09:28]
two kinds of architecture so if you want

[02:09:25 - 02:09:32]
to see just write word

[02:09:28 - 02:09:32]
to V

[02:09:32 - 02:09:36]
architecture so you'll see it has

[02:09:35 - 02:09:39]
actually two kinds of architecture

[02:09:36 - 02:09:41]
called cow so here you can see guys uh

[02:09:39 - 02:09:44]
it uses two kinds of architectur cow and

[02:09:41 - 02:09:45]
Skip gram so it's a neural network only

[02:09:44 - 02:09:47]
right so let me show you the code

[02:09:45 - 02:09:49]
mechanism of what to W like how it

[02:09:47 - 02:09:50]
extract the features let's see you are

[02:09:49 - 02:09:52]
having a documents let's see you are

[02:09:50 - 02:09:53]
having entire Cor

[02:09:52 - 02:09:55]
and in the Corpus let's say you are

[02:09:53 - 02:09:58]
having some unique word so let me create

[02:09:55 - 02:10:02]
a table so I can create a table just a

[02:09:58 - 02:10:04]
minute so here I'll be adding all the

[02:10:02 - 02:10:05]
features and this side I'll be adding

[02:10:04 - 02:10:09]
all the unique word let's say you are

[02:10:05 - 02:10:10]
having the word of King let's say

[02:10:09 - 02:10:12]
queen let's say

[02:10:10 - 02:10:15]
[Music]

[02:10:12 - 02:10:17]
man let's say

[02:10:15 - 02:10:19]
woman and let's say

[02:10:17 - 02:10:21]
monkey so as of now just try to consider

[02:10:19 - 02:10:24]
these are the unique word you are having

[02:10:21 - 02:10:25]
in in that particular entire corpus now

[02:10:24 - 02:10:28]
how your word to V will try to extract

[02:10:25 - 02:10:30]
the features so see it's a neural

[02:10:28 - 02:10:32]
network and neural network uh Works

[02:10:30 - 02:10:34]
based on the back propagation because

[02:10:32 - 02:10:35]
every time it will adjust the weight

[02:10:34 - 02:10:37]
based on that it will learn and if you

[02:10:35 - 02:10:39]
see the neural networks uh you can't see

[02:10:37 - 02:10:40]
like what kinds of feature it is

[02:10:39 - 02:10:42]
extracting because it's a completely

[02:10:40 - 02:10:45]
hidden thing if you see for the let's

[02:10:42 - 02:10:46]
say CNN if you see the for the NN so

[02:10:45 - 02:10:48]
these feature extraction things is a

[02:10:46 - 02:10:50]
completely hidden you don't know what

[02:10:48 - 02:10:52]
kinds of feature it will extract but as

[02:10:50 - 02:10:54]
of now let's consider

[02:10:52 - 02:10:55]
uh it has let's say generated some of

[02:10:54 - 02:10:58]
the features let say the first features

[02:10:55 - 02:11:02]
it has generated based on this word

[02:10:58 - 02:11:03]
gender because gender features can match

[02:11:02 - 02:11:06]
with all the words you can see because

[02:11:03 - 02:11:07]
all the let's say word I'm having let's

[02:11:06 - 02:11:10]
say all the entity I'm having it has the

[02:11:07 - 02:11:11]
gender yes or no right then it has also

[02:11:10 - 02:11:13]
generated another features let's say

[02:11:11 - 02:11:15]
wealth now you can see wealth is also

[02:11:13 - 02:11:18]
matching with all the words now we can

[02:11:15 - 02:11:22]
also consider

[02:11:18 - 02:11:22]
power then weight

[02:11:22 - 02:11:26]
then

[02:11:24 - 02:11:28]
speak see as of now I'm just assuming

[02:11:26 - 02:11:29]
these are the features my model has

[02:11:28 - 02:11:31]
generated because here we are using deep

[02:11:29 - 02:11:33]
learning model I think I showed you now

[02:11:31 - 02:11:35]
see that's how actually it will identify

[02:11:33 - 02:11:37]
the features that means the vector

[02:11:35 - 02:11:39]
representation first of all it will see

[02:11:37 - 02:11:41]
King has gender or not yes King has

[02:11:39 - 02:11:43]
gender and it's a male king let's say

[02:11:41 - 02:11:46]
male king queen has gender yes let's say

[02:11:43 - 02:11:49]
zero zero means female man as gender yes

[02:11:46 - 02:11:51]
one woman yes that means zero because

[02:11:49 - 02:11:53]
man I'm considering as one and women I'm

[02:11:51 - 02:11:56]
considering as zero right monkey has

[02:11:53 - 02:11:58]
also genda let's say one now wealth King

[02:11:56 - 02:12:00]
has wealth yes King has wealth let's say

[02:11:58 - 02:12:02]
I can assign as one because King is

[02:12:00 - 02:12:04]
having lots of wealth Queen is also

[02:12:02 - 02:12:06]
having wealth let's say because Queen is

[02:12:04 - 02:12:08]
a part of King right man is also having

[02:12:06 - 02:12:10]
wealth but less than king and queen so I

[02:12:08 - 02:12:13]
can give let's say

[02:12:10 - 02:12:15]
0.5 okay or I can give let's say

[02:12:13 - 02:12:17]
0.2 fine because again they are king and

[02:12:15 - 02:12:20]
queen right woman has also wealth that's

[02:12:17 - 02:12:22]
a 0.2 less than man monkey doesn't have

[02:12:20 - 02:12:24]
any wealth I will give zero Now power

[02:12:22 - 02:12:26]
yes definitely King has the power Queen

[02:12:24 - 02:12:29]
also has the has the power

[02:12:26 - 02:12:32]
okay but I can just decrease a little

[02:12:29 - 02:12:34]
bit let's say less than K King okay I

[02:12:32 - 02:12:37]
can give 0.7 man has also power let's

[02:12:34 - 02:12:42]
say 0.3 women has also power let's say 0

[02:12:37 - 02:12:45]
point um 0.2 monkey no monkey doesn't

[02:12:42 - 02:12:47]
have any power now wait yes King has

[02:12:45 - 02:12:50]
weight let's say I will give 0.8 let's

[02:12:47 - 02:12:52]
say this king is little bit obese Queen

[02:12:50 - 02:12:57]
yes she has Al weight I can give let's

[02:12:52 - 02:13:02]
say 0.5 very slim Queen man let's say 0.

[02:12:57 - 02:13:05]
7 wom let's say 0.5 monkey let's say 0.3

[02:13:02 - 02:13:07]
fine King can speak yes King can speak

[02:13:05 - 02:13:10]
Queen can also speak man can also speak

[02:13:07 - 02:13:13]
woman can also speak monkey let's say

[02:13:10 - 02:13:14]
can't speak okay now see beautifully I

[02:13:13 - 02:13:16]
have generated some of the vector okay

[02:13:14 - 02:13:18]
beautifully I have generated some of the

[02:13:16 - 02:13:20]
vector and I haven't generated it has

[02:13:18 - 02:13:24]
generated by your what to fake algorithm

[02:13:20 - 02:13:26]
okay part to V model that means this

[02:13:24 - 02:13:27]
architecture that deep learning

[02:13:26 - 02:13:32]
architecture you saw

[02:13:27 - 02:13:34]
cow okay CBO and Es skip

[02:13:32 - 02:13:36]
gram okay so these are the architecture

[02:13:34 - 02:13:38]
let's say it has generated this features

[02:13:36 - 02:13:39]
now if I tell you just try to give me

[02:13:38 - 02:13:43]
the king Vector so what it will give me

[02:13:39 - 02:13:45]
it'll give me let's say king is equal to

[02:13:43 - 02:13:47]
let's say this is the king Vector so I

[02:13:45 - 02:13:47]
can write here

[02:13:47 - 02:13:52]
one then one

[02:13:51 - 02:13:56]
then

[02:13:52 - 02:13:58]
one then let's say 0.8 let's say one

[02:13:56 - 02:14:01]
this my king Vector you can also give me

[02:13:58 - 02:14:06]
the queen Vector so here is the queen

[02:14:01 - 02:14:10]
Vector 0 1 0.7 let me just write 0 1

[02:14:06 - 02:14:12]
0.7 then 0.5 and one okay this is the

[02:14:10 - 02:14:14]
queen Vector you can also give me the

[02:14:12 - 02:14:19]
man

[02:14:14 - 02:14:26]
Vector yes the man Vector 1 0.3 0.3 0.7

[02:14:19 - 02:14:28]
1 0.3 0 3 0.7 and 1 okay then woman 0

[02:14:26 - 02:14:35]
0.2 0.2

[02:14:28 - 02:14:38]
0.5 0 0.2 0.2 0.5 and 1 then let's say

[02:14:35 - 02:14:41]
this is the monkey Vector 1 0

[02:14:38 - 02:14:44]
0.2

[02:14:41 - 02:14:49]
monkey one sorry should be

[02:14:44 - 02:14:51]
one then 0 0 0.3 0 0

[02:14:49 - 02:14:56]
0.3 sorry

[02:14:51 - 02:14:58]
0.3 and I think zero okay see all the

[02:14:56 - 02:15:02]
vector I got now if you plot them in a

[02:14:58 - 02:15:04]
dimensional space let's say this is my

[02:15:02 - 02:15:07]
Dimension as of now I'm just drawing two

[02:15:04 - 02:15:09]
dimensional Dimension okay because uh 3D

[02:15:07 - 02:15:11]
4D I can draw here that's why I just

[02:15:09 - 02:15:13]
consider two dimensional space now here

[02:15:11 - 02:15:15]
you can uh let's say this is your x

[02:15:13 - 02:15:17]
coordinate this is your y

[02:15:15 - 02:15:20]
coordinate now let's say first of all I

[02:15:17 - 02:15:22]
want to let's say represent King here so

[02:15:20 - 02:15:25]
let's say King King is here let's say

[02:15:22 - 02:15:28]
this is the King this is the king Vector

[02:15:25 - 02:15:30]
okay this is the king Vector I can write

[02:15:28 - 02:15:30]
this is the

[02:15:30 - 02:15:36]
king now if you just now if you just uh

[02:15:34 - 02:15:39]
plot the queen also you will see that

[02:15:36 - 02:15:42]
Queen will come close to King okay Queen

[02:15:39 - 02:15:44]
will come close to King why because if

[02:15:42 - 02:15:47]
you see the

[02:15:44 - 02:15:48]
vector okay if you see the vector they

[02:15:47 - 02:15:51]
are very closely related Vector you can

[02:15:48 - 02:15:52]
see let's say if you calculate the queen

[02:15:51 - 02:15:54]
distance with respect to all the vector

[02:15:52 - 02:15:57]
you'll see that Queen will have very

[02:15:54 - 02:15:59]
less distance with the King because both

[02:15:57 - 02:16:01]
are similar okay both are similar okay

[02:15:59 - 02:16:03]
because uh you can see Queen is Queen is

[02:16:01 - 02:16:05]
the part of King so all the features are

[02:16:03 - 02:16:07]
already messing with the king that's why

[02:16:05 - 02:16:09]
it is coming to close so that means it's

[02:16:07 - 02:16:11]
a it's a cluster okay it's a cluster of

[02:16:09 - 02:16:13]
king and queen so they are falling in

[02:16:11 - 02:16:14]
the same cluster now similar wise if you

[02:16:13 - 02:16:17]
plot the man and woman Vector you will

[02:16:14 - 02:16:22]
see that they will uh they will come

[02:16:17 - 02:16:24]
nearly let's say this is your man

[02:16:22 - 02:16:25]
okay man vector and let's say this is

[02:16:24 - 02:16:28]
the woman

[02:16:25 - 02:16:31]
[Music]

[02:16:28 - 02:16:33]
Vector because if you see carefully men

[02:16:31 - 02:16:35]
and women Vector they are closely

[02:16:33 - 02:16:36]
related okay they uh they are almost

[02:16:35 - 02:16:39]
similar so that's why they are coming in

[02:16:36 - 02:16:41]
the same cluster so again it's a cluster

[02:16:39 - 02:16:43]
okay for men and women and if you see

[02:16:41 - 02:16:44]
the monkey okay monkey is a completely

[02:16:43 - 02:16:47]
different entity you can see the vector

[02:16:44 - 02:16:50]
is also different so let's say monkey

[02:16:47 - 02:16:53]
will come here so I can take a new pen

[02:16:50 - 02:16:53]
let's say this the

[02:16:53 - 02:16:59]
monkey monkey okay and monkey and monkey

[02:16:57 - 02:17:01]
it is present in the different cluster

[02:16:59 - 02:17:04]
okay so that's how it is capturing the

[02:17:01 - 02:17:06]
centic information okay between multiple

[02:17:04 - 02:17:09]
word now let's say there is another

[02:17:06 - 02:17:10]
sentence you are writing let's say I am

[02:17:09 - 02:17:13]
a

[02:17:10 - 02:17:15]
princess okay princess now tell me where

[02:17:13 - 02:17:18]
this princess will come in which Vector

[02:17:15 - 02:17:19]
me which space okay in which cluster it

[02:17:18 - 02:17:22]
will come definitely inside this

[02:17:19 - 02:17:24]
particular cluster because if you uh

[02:17:22 - 02:17:26]
just extract the features from The

[02:17:24 - 02:17:28]
Princess you'll see that uh it would be

[02:17:26 - 02:17:31]
close to King and Queen okay so that's

[02:17:28 - 02:17:33]
how uh this word to V can uh actually

[02:17:31 - 02:17:36]
understand the semantic information of a

[02:17:33 - 02:17:39]
word okay so that's why it is uh so

[02:17:36 - 02:17:40]
that's why what to V is the much better

[02:17:39 - 02:17:42]
than your previous whatever technique

[02:17:40 - 02:17:45]
you have learned so far okay and from

[02:17:42 - 02:17:46]
here actually your actual concept starts

[02:17:45 - 02:17:47]
like whatever things you will be

[02:17:46 - 02:17:50]
learning in future let a Transformer

[02:17:47 - 02:17:51]
based encoding like how Transformer

[02:17:50 - 02:17:53]
model extract the features that's how it

[02:17:51 - 02:17:55]
extract the features okay because at

[02:17:53 - 02:17:56]
then it's a deep learning model and by

[02:17:55 - 02:17:58]
the back propagation itself it will

[02:17:56 - 02:18:00]
generate deser the features but as a

[02:17:58 - 02:18:02]
human you won't be able to see the

[02:18:00 - 02:18:04]
features but here we are assuming let's

[02:18:02 - 02:18:05]
say these are the features your model

[02:18:04 - 02:18:07]
May create and based on that that's how

[02:18:05 - 02:18:09]
it will generate the vectors embedding

[02:18:07 - 02:18:11]
okay and when it comes to centic

[02:18:09 - 02:18:12]
information that's how it will uh let's

[02:18:11 - 02:18:15]
say capture the centic information

[02:18:12 - 02:18:17]
because it will plot the all the vector

[02:18:15 - 02:18:18]
in a dimensional space and then it will

[02:18:17 - 02:18:20]
try to find the relationship whether

[02:18:18 - 02:18:22]
king and queen are same or not man and

[02:18:20 - 02:18:24]
moment same or not monkey is a different

[02:18:22 - 02:18:25]
or not okay I hope it is clear now so

[02:18:24 - 02:18:28]
let me show me show you one image

[02:18:25 - 02:18:30]
actually uh experiment of what to V you

[02:18:28 - 02:18:32]
can see this is one experiment for the

[02:18:30 - 02:18:35]
word to so here you can see we are

[02:18:32 - 02:18:37]
having three kinds of word King man and

[02:18:35 - 02:18:39]
woman and whenever what to is applying

[02:18:37 - 02:18:40]
on top of it it is generating some

[02:18:39 - 02:18:42]
features you can see so this color

[02:18:40 - 02:18:43]
represent the features let's say uh

[02:18:42 - 02:18:46]
these are the features it has generated

[02:18:43 - 02:18:48]
let's say this is uh wealth this is uh

[02:18:46 - 02:18:50]
Power this is speak this is and let's

[02:18:48 - 02:18:53]
say this is the weight you can see King

[02:18:50 - 02:18:55]
uh color is different than your man and

[02:18:53 - 02:18:57]
woman now see man and women color

[02:18:55 - 02:18:59]
they're closely related you can see all

[02:18:57 - 02:19:01]
the color is messing okay all the colors

[02:18:59 - 02:19:03]
are messing that's how it is making a

[02:19:01 - 02:19:05]
separate cluster of man and woman and

[02:19:03 - 02:19:06]
King is a different entity here okay I

[02:19:05 - 02:19:09]
hope it is clear now so now let's see

[02:19:06 - 02:19:11]
the Practical of what to V how we can

[02:19:09 - 02:19:13]
use what to V in a python code so for

[02:19:11 - 02:19:15]
this I'm going to use one data set so

[02:19:13 - 02:19:19]
let me show you the data set here so the

[02:19:15 - 02:19:25]
data set name is games of

[02:19:19 - 02:19:26]
ss book data set okay data set in Kagel

[02:19:25 - 02:19:28]
I think you know what is games of th

[02:19:26 - 02:19:30]
okay it's a series actually so if you

[02:19:28 - 02:19:34]
don't know you can simply search on

[02:19:30 - 02:19:36]
image see uh this is one actually uh

[02:19:34 - 02:19:38]
series okay this is a movie series

[02:19:36 - 02:19:40]
actually games of THS and it is having

[02:19:38 - 02:19:41]
different different characters so if you

[02:19:40 - 02:19:43]
have already watched this particular

[02:19:41 - 02:19:45]
let's say series you will know okay

[02:19:43 - 02:19:46]
about this particular character and all

[02:19:45 - 02:19:50]
So based on this particular series one

[02:19:46 - 02:19:51]
book has been published and uh this data

[02:19:50 - 02:19:54]
set is avable in the Kagel also this

[02:19:51 - 02:19:56]
book data set now this book contains all

[02:19:54 - 02:19:57]
the dialogue okay present in that

[02:19:56 - 02:19:58]
particular series okay see all that

[02:19:57 - 02:20:01]
dialogue it is having different

[02:19:58 - 02:20:03]
different txt file you can see based on

[02:20:01 - 02:20:04]
the let's say season okay it is having

[02:20:03 - 02:20:07]
different different

[02:20:04 - 02:20:08]
dialogue from all the characters so what

[02:20:07 - 02:20:11]
I'll do I'll just try to download one

[02:20:08 - 02:20:12]
txt file and I'll just try to apply what

[02:20:11 - 02:20:14]
to V on top of it and I'll try to see

[02:20:12 - 02:20:16]
what the Character Are closely related

[02:20:14 - 02:20:18]
that means I'll see these kinds of let's

[02:20:16 - 02:20:21]
say uh this kinds of say representation

[02:20:18 - 02:20:22]
that means whether some character are uh

[02:20:21 - 02:20:24]
in the same clust on not because if you

[02:20:22 - 02:20:26]
see this series now some of the

[02:20:24 - 02:20:29]
character would be closely related okay

[02:20:26 - 02:20:31]
let's say character one that's a

[02:20:29 - 02:20:33]
character two they're similar kinds of

[02:20:31 - 02:20:34]
character so these two Vector will come

[02:20:33 - 02:20:37]
closely okay that's how we want to see

[02:20:34 - 02:20:39]
the relationship okay between the data

[02:20:37 - 02:20:40]
so I already downloaded one txt file you

[02:20:39 - 02:20:42]
can also download just try to search for

[02:20:40 - 02:20:43]
games of th books in kagle you will see

[02:20:42 - 02:20:46]
this particular data just try to

[02:20:43 - 02:20:47]
download one txt file so let me show you

[02:20:46 - 02:20:49]
the notebook so guys this is the

[02:20:47 - 02:20:51]
notebook and here we'll be showing you

[02:20:49 - 02:20:53]
the what to fake now let me connect and

[02:20:51 - 02:20:55]
this data set is already available in

[02:20:53 - 02:20:56]
this link I have already given now let

[02:20:55 - 02:20:59]
me download and let me upload in my

[02:20:56 - 02:21:02]
Google collab so here I can upload this

[02:20:59 - 02:21:05]
data so I'll create a folder

[02:21:02 - 02:21:07]
here called

[02:21:05 - 02:21:10]
data and inside that I can upload this

[02:21:07 - 02:21:10]
txt

[02:21:13 - 02:21:18]
file now first of all let's import some

[02:21:16 - 02:21:21]
Library naai pandas and Jim I'm

[02:21:18 - 02:21:23]
importing because what V is there inside

[02:21:21 - 02:21:25]
genim Library okay if you want to use

[02:21:23 - 02:21:27]
whatto you have to use this particular

[02:21:25 - 02:21:30]
Library called Jim inside that you have

[02:21:27 - 02:21:32]
the whatto architecture now let me

[02:21:30 - 02:21:34]
import

[02:21:32 - 02:21:35]
them now if you're using Google cab

[02:21:34 - 02:21:38]
first of all you have to update the

[02:21:35 - 02:21:41]
genim because otherwise you will get

[02:21:38 - 02:21:41]
some of the issue so let me

[02:21:41 - 02:21:46]
update okay update is done now I'm

[02:21:43 - 02:21:48]
importing like sentence tokenizer from

[02:21:46 - 02:21:50]
the nltk and I'm also importing simple

[02:21:48 - 02:21:53]
pre-process from the genim library

[02:21:50 - 02:21:55]
because uh before passing my data to my

[02:21:53 - 02:21:57]
let's say uh whatto model first of all I

[02:21:55 - 02:21:58]
have to apply some processing okay

[02:21:57 - 02:22:00]
processing means it will do some

[02:21:58 - 02:22:04]
cleaning operation and all then uh you

[02:22:00 - 02:22:06]
can pass the data so let me import

[02:22:04 - 02:22:08]
them now this Cod spp it will load your

[02:22:06 - 02:22:10]
data from the data folder you can see

[02:22:08 - 02:22:12]
okay so here I'm having test.txt so it

[02:22:10 - 02:22:15]
will load the

[02:22:12 - 02:22:18]
data and it will extract all the let's

[02:22:15 - 02:22:20]
say uh word that means all the sentence

[02:22:18 - 02:22:22]
one by one and it will perform from the

[02:22:20 - 02:22:23]
tokenization okay it will perform the

[02:22:22 - 02:22:25]
tokenization that means every word will

[02:22:23 - 02:22:27]
have the tokenizer okay now if I show

[02:22:25 - 02:22:29]
you the story that means start story

[02:22:27 - 02:22:31]
list now

[02:22:29 - 02:22:34]
see you got your all the sentence okay

[02:22:31 - 02:22:35]
see this is the entire sentence and

[02:22:34 - 02:22:37]
inside the sentence you you have done

[02:22:35 - 02:22:39]
the word level tokenization okay this is

[02:22:37 - 02:22:42]
the idea now if you check the length of

[02:22:39 - 02:22:45]
the entire story you have more than

[02:22:42 - 02:22:47]
8,000 uh actually let's say example here

[02:22:45 - 02:22:50]
so here you are having more than 8,000

[02:22:47 - 02:22:52]
sentence that means 8,000 dialogue okay

[02:22:50 - 02:22:55]
now we can see the entire

[02:22:52 - 02:22:57]
story now if you want to see the story

[02:22:55 - 02:22:59]
one that means the first uh let's say

[02:22:57 - 02:23:01]
dialogue the first sentence this is the

[02:22:59 - 02:23:02]
first sentence okay you can see and

[02:23:01 - 02:23:05]
again we have done the word level

[02:23:02 - 02:23:07]
tokenization okay individual token now

[02:23:05 - 02:23:08]
we have to initialize the genim model so

[02:23:07 - 02:23:10]
that's how we can initialize the genim

[02:23:08 - 02:23:12]
model so let me

[02:23:10 - 02:23:14]
initialize then if you want to let's say

[02:23:12 - 02:23:16]
convert to the vector representation

[02:23:14 - 02:23:18]
just try to call this particular

[02:23:16 - 02:23:20]
function bu uh build vocab now inside

[02:23:18 - 02:23:22]
that pass your data

[02:23:20 - 02:23:25]
then you have to train the model so you

[02:23:22 - 02:23:26]
have to give your data total example

[02:23:25 - 02:23:28]
then total example you will get total

[02:23:26 - 02:23:29]
example from the model. Corpus count

[02:23:28 - 02:23:31]
that means it will count the entire

[02:23:29 - 02:23:33]
Corpus and it will give the count and

[02:23:31 - 02:23:35]
you have to give the epoch okay Epoch

[02:23:33 - 02:23:37]
you can take the default actually Epoch

[02:23:35 - 02:23:38]
from the model itself now see my

[02:23:37 - 02:23:41]
training is completed now if I want to

[02:23:38 - 02:23:43]
see the similar so similar of Deniz so

[02:23:41 - 02:23:46]
Deniz is a character inside this

[02:23:43 - 02:23:49]
particular let's say uh Series so see

[02:23:46 - 02:23:51]
she is the character now you can see the

[02:23:49 - 02:23:53]
similar score

[02:23:51 - 02:23:55]
of the D with these are the word okay

[02:23:53 - 02:23:58]
these are the word but see again you

[02:23:55 - 02:23:59]
will get some let's say random output

[02:23:58 - 02:24:02]
because here we are only using one

[02:23:59 - 02:24:03]
dialogue that means one txt file I'm not

[02:24:02 - 02:24:05]
using the entire txt entire dialogue

[02:24:03 - 02:24:07]
Because unless and until my model is not

[02:24:05 - 02:24:10]
getting the entire dialogue it would be

[02:24:07 - 02:24:13]
a little bit difficult for uh it to

[02:24:10 - 02:24:14]
match those character yes or no right so

[02:24:13 - 02:24:16]
if you're doing it just try to take all

[02:24:14 - 02:24:18]
the data and try to perform this job but

[02:24:16 - 02:24:20]
here just to show you I have taken only

[02:24:18 - 02:24:23]
one THD file now you can see with still

[02:24:20 - 02:24:26]
word it is having 0.99 okay per

[02:24:23 - 02:24:30]
relationship okay din eyes then and

[02:24:26 - 02:24:31]
Prince so Prince is another

[02:24:30 - 02:24:33]
character

[02:24:31 - 02:24:35]
prince in

[02:24:33 - 02:24:39]
gamesof

[02:24:35 - 02:24:41]
songs see with him actually uh her

[02:24:39 - 02:24:42]
character is matching if you watch the

[02:24:41 - 02:24:44]
series actually you will see that with

[02:24:42 - 02:24:49]
him her character is matching okay

[02:24:44 - 02:24:52]
mostly so you can see then deny then uh

[02:24:49 - 02:24:52]
doar key also is a

[02:24:55 - 02:25:00]
character see okay so that's how you can

[02:24:58 - 02:25:02]
actually match now see it's not actually

[02:25:00 - 02:25:05]
properly visible so what I can do I can

[02:25:02 - 02:25:07]
also plot them in a so what I can do I

[02:25:05 - 02:25:09]
can also plot them in a uh visual graph

[02:25:07 - 02:25:10]
representation I'll tell you but before

[02:25:09 - 02:25:12]
that let me show you if you want to

[02:25:10 - 02:25:15]
let's say see the relationship between

[02:25:12 - 02:25:16]
two character you can use the similarity

[02:25:15 - 02:25:19]
function inside that give two character

[02:25:16 - 02:25:21]
let's say Arya and Sansa so if I give

[02:25:19 - 02:25:25]
Arya and Sansa so they are

[02:25:21 - 02:25:27]
having this is the relationship

[02:25:25 - 02:25:29]
okay now if you want to get all the

[02:25:27 - 02:25:30]
vectors you can execute this code it

[02:25:29 - 02:25:34]
will give me it will give you all the

[02:25:30 - 02:25:36]
vectors okay all the vectors for the

[02:25:34 - 02:25:38]
entire text you have given okay and the

[02:25:36 - 02:25:40]
shape of the vector see now let me show

[02:25:38 - 02:25:41]
you the visualization I apply the PCA

[02:25:40 - 02:25:43]
that means principal component analysis

[02:25:41 - 02:25:45]
to reduce the dimension that means I

[02:25:43 - 02:25:47]
want to plot in a threedimensional space

[02:25:45 - 02:25:50]
right now so here I'm initializing PCA

[02:25:47 - 02:25:52]
component now pca. fit I'm giving my

[02:25:50 - 02:25:54]
data that means Vector so it will give

[02:25:52 - 02:25:56]
me the uh three dimensional Vector right

[02:25:54 - 02:25:58]
now that means from 100 Dimension it has

[02:25:56 - 02:25:59]
reduced to three dimensional Vector I

[02:25:58 - 02:26:01]
think you know what is PCA principal

[02:25:59 - 02:26:03]
compound analysis in machine learning we

[02:26:01 - 02:26:05]
can use it to reduce the dimension size

[02:26:03 - 02:26:07]
now you can see the dimension right now

[02:26:05 - 02:26:07]
so this is the dimension 3 and here we

[02:26:07 - 02:26:10]
are having

[02:26:07 - 02:26:12]
3,840 example in this particular entire

[02:26:10 - 02:26:14]
text now see if I want to plot it I can

[02:26:12 - 02:26:16]
use plotly library now inside that just

[02:26:14 - 02:26:18]
pass your data and set the colors it

[02:26:16 - 02:26:21]
will show you the interre representation

[02:26:18 - 02:26:21]
of the data

[02:26:22 - 02:26:26]
see that's how you are getting a 3D

[02:26:23 - 02:26:29]
space see this is the 3D space now see

[02:26:26 - 02:26:30]
the see the different different uh word

[02:26:29 - 02:26:32]
okay different different word and their

[02:26:30 - 02:26:35]
similarity so here you can see they are

[02:26:32 - 02:26:38]
closely related these are the cluster so

[02:26:35 - 02:26:40]
this word is nothing but so this red is

[02:26:38 - 02:26:43]
nothing but just try to see it's a take

[02:26:40 - 02:26:45]
and this blue is nothing but it's a put

[02:26:43 - 02:26:46]
that means put and take they're falling

[02:26:45 - 02:26:49]
in the same cluster because they have

[02:26:46 - 02:26:50]
the relationship okay if you just find

[02:26:49 - 02:26:52]
uh in a grammatical way you will see

[02:26:50 - 02:26:53]
that they have the relationship and

[02:26:52 - 02:26:55]
apart from that you will also see some

[02:26:53 - 02:26:56]
character okay you can also match the

[02:26:55 - 02:26:58]
character you will see that they're

[02:26:56 - 02:27:00]
falling in the same

[02:26:58 - 02:27:01]
cluster so you can play with this

[02:27:00 - 02:27:03]
particular

[02:27:01 - 02:27:05]
graph uh I'll share the notebook you can

[02:27:03 - 02:27:07]
play with this particular graph see

[02:27:05 - 02:27:09]
that's a beautifully it has stored the

[02:27:07 - 02:27:12]
data in the dimensional space okay and

[02:27:09 - 02:27:15]
that's how your model will identify okay

[02:27:12 - 02:27:17]
the semantic relationship okay between

[02:27:15 - 02:27:20]
two wordss that means I showed you now

[02:27:17 - 02:27:23]
here here the centic information from

[02:27:20 - 02:27:26]
the word itself I hope it is clear now

[02:27:23 - 02:27:27]
fine so yes so that's how actually we

[02:27:26 - 02:27:29]
can use this word to V and if you're

[02:27:27 - 02:27:32]
using word to V you have to pass this

[02:27:29 - 02:27:34]
this particular data sorry uh after this

[02:27:32 - 02:27:36]
data okay the vector we are getting the

[02:27:34 - 02:27:37]
entire Vector that normalized Vector

[02:27:36 - 02:27:39]
okay and this is your vector

[02:27:37 - 02:27:41]
representation this Vector you have to

[02:27:39 - 02:27:42]
pass to the model but again we won't be

[02:27:41 - 02:27:45]
using that we have just learned this

[02:27:42 - 02:27:47]
part to V just to understand how my

[02:27:45 - 02:27:48]
Transformer architecture will be working

[02:27:47 - 02:27:50]
how it will extract the features and how

[02:27:48 - 02:27:52]
it will get the let's say semantic

[02:27:50 - 02:27:54]
information so in Transformer

[02:27:52 - 02:27:56]
architecture you use something called

[02:27:54 - 02:27:58]
attention mechanism let's say attention

[02:27:56 - 02:28:00]
model with the help of attention model

[02:27:58 - 02:28:02]
uh uh it can actually understand the

[02:28:00 - 02:28:05]
semantic information in a good way okay

[02:28:02 - 02:28:07]
this is little bit Advanced concept okay

[02:28:05 - 02:28:09]
that's the idea so yes this is what

[02:28:07 - 02:28:10]
actually we can perform our data

[02:28:09 - 02:28:12]
representation that means text

[02:28:10 - 02:28:13]
representation and that's how we can

[02:28:12 - 02:28:15]
perform the vectorization technique so

[02:28:13 - 02:28:16]
why we learned this because going

[02:28:15 - 02:28:18]
forward whenever we'll be learning about

[02:28:16 - 02:28:20]
let's say large language model and all

[02:28:18 - 02:28:21]
uh before understanding large language

[02:28:20 - 02:28:23]
model I just wanted to let you know how

[02:28:21 - 02:28:25]
data would be prepared for the model

[02:28:23 - 02:28:27]
okay now I think you got it how we can

[02:28:25 - 02:28:29]
prepare our data for the large language

[02:28:27 - 02:28:30]
model okay if I have any kind of raw

[02:28:29 - 02:28:32]
text how we can convert to the numerical

[02:28:30 - 02:28:34]
representation and which approach would

[02:28:32 - 02:28:36]
be better because finally we saw that

[02:28:34 - 02:28:39]
this what to V approach is better

[02:28:36 - 02:28:41]
because it is able to extract the

[02:28:39 - 02:28:42]
semantic information okay semantic

[02:28:41 - 02:28:44]
information because it is a deep

[02:28:42 - 02:28:46]
learning model okay this is the idea so

[02:28:44 - 02:28:48]
yes I hope guys you got it now in the

[02:28:46 - 02:28:50]
next video we'll be using all the let's

[02:28:48 - 02:28:51]
say topic we have learned so let's say

[02:28:50 - 02:28:53]
text pre-processing and text

[02:28:51 - 02:28:55]
representation technique uh and we'll be

[02:28:53 - 02:28:57]
doing one small project with the help of

[02:28:55 - 02:28:59]
machine learning we'll be doing one text

[02:28:57 - 02:29:01]
classification project as of now we have

[02:28:59 - 02:29:03]
learned about text pre-processing and uh

[02:29:01 - 02:29:06]
text representation technique like how

[02:29:03 - 02:29:07]
we can convert our textual data to new

[02:29:06 - 02:29:09]
medical representation that means the

[02:29:07 - 02:29:11]
vectorization right so we'll be using

[02:29:09 - 02:29:13]
all the concept we have learned so far

[02:29:11 - 02:29:15]
and we'll be uh bring one hands on that

[02:29:13 - 02:29:17]
means we'll be doing one practical so

[02:29:15 - 02:29:20]
here we'll be implementing one text

[02:29:17 - 02:29:21]
classification model so in this video my

[02:29:20 - 02:29:24]
objective is to show you how we can

[02:29:21 - 02:29:25]
prepare your data set for the model that

[02:29:24 - 02:29:28]
means how we can apply all the

[02:29:25 - 02:29:29]
preprocessing technique how we can apply

[02:29:28 - 02:29:32]
uh these kinds of text factorization

[02:29:29 - 02:29:34]
techniqu so that you can use those data

[02:29:32 - 02:29:35]
okay for the model training but model

[02:29:34 - 02:29:37]
wise actually I'm not going to use large

[02:29:35 - 02:29:39]
language model as of now I'm going to

[02:29:37 - 02:29:41]
use simple machine learning model later

[02:29:39 - 02:29:43]
on I will also show you how you can use

[02:29:41 - 02:29:44]
large language model okay because it's a

[02:29:43 - 02:29:46]
like very initial phase we are doing as

[02:29:44 - 02:29:48]
of now we haven't learned about the llm

[02:29:46 - 02:29:50]
that's why I'll be using simple machine

[02:29:48 - 02:29:52]
learning model so let's uh open open up

[02:29:50 - 02:29:55]
our Google collab and uh let me show you

[02:29:52 - 02:29:57]
the text classification practical there

[02:29:55 - 02:29:59]
so guys as you can see here I already

[02:29:57 - 02:30:01]
prepared one notebook for you and the

[02:29:59 - 02:30:04]
data set actually I'm going to use so

[02:30:01 - 02:30:07]
this is the link of the data so the data

[02:30:04 - 02:30:10]
set name is IMDb movie review data set

[02:30:07 - 02:30:12]
so this data set is having uh 50k movie

[02:30:10 - 02:30:14]
reviews so you can download this data

[02:30:12 - 02:30:15]
from the kagle so kagle website it is

[02:30:14 - 02:30:17]
available so it is having reviews based

[02:30:15 - 02:30:19]
on the sentiment whether this reviews is

[02:30:17 - 02:30:21]
a positive or negative okay so it's a

[02:30:19 - 02:30:22]
classification problem statement so I

[02:30:21 - 02:30:24]
already downloaded the data I have

[02:30:22 - 02:30:26]
already given the link you can download

[02:30:24 - 02:30:29]
the data so let me upload the data here

[02:30:26 - 02:30:33]
so I'll just try to upload so this is my

[02:30:29 - 02:30:33]
data so here let me upload

[02:30:35 - 02:30:39]
it okay my data set is uploaded here now

[02:30:38 - 02:30:41]
the first thing what we have to do we

[02:30:39 - 02:30:42]
have to import some of the libraries so

[02:30:41 - 02:30:44]
here I've already listed down all the

[02:30:42 - 02:30:46]
libraries you need uh for this

[02:30:44 - 02:30:49]
experiment so I need naai pandas mat

[02:30:46 - 02:30:51]
plot leave okay then I also need uh

[02:30:49 - 02:30:53]
10est Le counter vectorizer tfidf

[02:30:51 - 02:30:55]
Transformer okay so everything I have

[02:30:53 - 02:30:58]
just imported here and as of now I'm not

[02:30:55 - 02:31:00]
going to use this Keras so let me just

[02:30:58 - 02:31:02]
remove it it's not required so here I

[02:31:00 - 02:31:03]
already told you I'll be using simple

[02:31:02 - 02:31:05]
machine learning approach so I don't

[02:31:03 - 02:31:07]
need to use any kinds of deep learning

[02:31:05 - 02:31:08]
library as of now so fine you can see

[02:31:07 - 02:31:10]
guys I have imported all the library

[02:31:08 - 02:31:12]
required Library I need and definitely I

[02:31:10 - 02:31:13]
will explain whenever I will use it I'll

[02:31:12 - 02:31:15]
tell you okay why we're using this

[02:31:13 - 02:31:16]
particular library now let me import all

[02:31:15 - 02:31:19]
of

[02:31:16 - 02:31:21]
them I think naai and pandas we already

[02:31:19 - 02:31:23]
imported here so so I don't need it I

[02:31:21 - 02:31:25]
can delete it now you don't need to

[02:31:23 - 02:31:27]
execute this line because uh here I have

[02:31:25 - 02:31:29]
my data in my uh Google collab you can

[02:31:27 - 02:31:31]
see Google collab space but if you have

[02:31:29 - 02:31:32]
your data in your Google Drive that case

[02:31:31 - 02:31:34]
uh what you can do you can mount your

[02:31:32 - 02:31:35]
Google Drive so I'm not going to execute

[02:31:34 - 02:31:38]
this line so directly I going I'm going

[02:31:35 - 02:31:41]
to assign my data path so I'll copy and

[02:31:38 - 02:31:44]
here I'm going to mention the path of my

[02:31:41 - 02:31:47]
data okay so let's say this is my data

[02:31:44 - 02:31:50]
part now I'll execute now I will load

[02:31:47 - 02:31:52]
the data with the help of pandas Library

[02:31:50 - 02:31:55]
now see guys this is the entire data you

[02:31:52 - 02:31:58]
are having and here you are having the

[02:31:55 - 02:32:00]
uh this one your reviews as well as the

[02:31:58 - 02:32:01]
sentiment of that reviews now if you

[02:32:00 - 02:32:04]
want to see the shape so here you are

[02:32:01 - 02:32:07]
having 50,000 movie reviews and two

[02:32:04 - 02:32:09]
columns uh reviews and sentiment now see

[02:32:07 - 02:32:11]
here uh I don't want to take all the

[02:32:09 - 02:32:13]
data because again if I'm taking all the

[02:32:11 - 02:32:15]
data it will take lots of time to

[02:32:13 - 02:32:18]
process so I'll only take the 10,000

[02:32:15 - 02:32:19]
example okay from uh this 15,000 example

[02:32:18 - 02:32:21]
so here you can see I'm taking only

[02:32:19 - 02:32:23]
10,000 example first

[02:32:21 - 02:32:25]
10,000 and now you can see this is my

[02:32:23 - 02:32:28]
data now if I show you the data shape

[02:32:25 - 02:32:29]
now see only 10,000 example I have taken

[02:32:28 - 02:32:30]
now if you want to see any kinds of

[02:32:29 - 02:32:33]
reviews you can also check this is the

[02:32:30 - 02:32:35]
first reviews now if you want to see the

[02:32:33 - 02:32:36]
sentiment value count that means how

[02:32:35 - 02:32:39]
many sentiment it is having it is having

[02:32:36 - 02:32:41]
two sentiment um positive and negative

[02:32:39 - 02:32:44]
you can see so positive sentiment is

[02:32:41 - 02:32:48]
having around uh 5,000 and negative

[02:32:44 - 02:32:51]
sentiment is having around uh it is also

[02:32:48 - 02:32:54]
around 5,000 you can see 4 4,000

[02:32:51 - 02:32:55]
972 that means it's a balanced data okay

[02:32:54 - 02:32:57]
we don't have any issue with the data

[02:32:55 - 02:32:59]
now let's see whether it is having any

[02:32:57 - 02:33:01]
missing value or not for this I can use

[02:32:59 - 02:33:02]
is Nal function now see there is no

[02:33:01 - 02:33:04]
missing value now let's see any

[02:33:02 - 02:33:06]
duplicates is there or not so you can

[02:33:04 - 02:33:08]
see we are having a 17 duplicates what I

[02:33:06 - 02:33:10]
can do I can drop the duplicates for

[02:33:08 - 02:33:11]
this you can execute this line of code

[02:33:10 - 02:33:12]
drop duplicates and in place is equal to

[02:33:11 - 02:33:15]
true that means you want to permanently

[02:33:12 - 02:33:18]
delete the duplicate now if I

[02:33:15 - 02:33:20]
execute now see there is no duplicate uh

[02:33:18 - 02:33:23]
data in my data set right now now let's

[02:33:20 - 02:33:25]
perform some basic pre-processing so as

[02:33:23 - 02:33:27]
I already told you inside basic

[02:33:25 - 02:33:29]
pre-processing you can perform HTML tag

[02:33:27 - 02:33:31]
removal then lower case operation stop

[02:33:29 - 02:33:33]
remember so these are the thing you can

[02:33:31 - 02:33:35]
perform now see uh from my previous

[02:33:33 - 02:33:36]
notebook that text prosing notebook I

[02:33:35 - 02:33:38]
have taken the same function that

[02:33:36 - 02:33:40]
removes tag function that means it will

[02:33:38 - 02:33:42]
remove all kinds of HTML tags from the

[02:33:40 - 02:33:44]
data because if you show if I show you

[02:33:42 - 02:33:46]
the data it is having lots of HTML tags

[02:33:44 - 02:33:48]
because it's a it's a extracted data

[02:33:46 - 02:33:51]
from the website right so let's apply

[02:33:48 - 02:33:54]
this function I will apply on top of the

[02:33:51 - 02:33:56]
reviews so it will uh remove all the

[02:33:54 - 02:33:59]
let's say HTML tags now see this is the

[02:33:56 - 02:34:02]
clean data I'm having now see there is

[02:33:59 - 02:34:03]
no HTML tags present inside this data

[02:34:02 - 02:34:04]
now the next pre-processing technique

[02:34:03 - 02:34:07]
will be performing the lower casing

[02:34:04 - 02:34:09]
operation so let's apart from it so here

[02:34:07 - 02:34:11]
you can see I'm applying lower casing

[02:34:09 - 02:34:15]
now if I show you see all of my word has

[02:34:11 - 02:34:16]
become lower case right now fine now

[02:34:15 - 02:34:18]
what we'll be doing we'll be removing

[02:34:16 - 02:34:21]
the stop Parts because as I already told

[02:34:18 - 02:34:23]
you some stop word doesn't have any

[02:34:21 - 02:34:25]
kinds of meaning u in a reviews whenever

[02:34:23 - 02:34:26]
you are performing any kind of sentiment

[02:34:25 - 02:34:28]
analysis because it will see the

[02:34:26 - 02:34:30]
positive and negative words okay to

[02:34:28 - 02:34:32]
differentiate whether this sentiment is

[02:34:30 - 02:34:34]
a positive or negative so here you can

[02:34:32 - 02:34:36]
see uh here I have written a Lambda

[02:34:34 - 02:34:38]
function so it is doing the same thing

[02:34:36 - 02:34:40]
you can also use the previous function I

[02:34:38 - 02:34:41]
showed you in that notebook I you can

[02:34:40 - 02:34:43]
also follow this particular approach

[02:34:41 - 02:34:45]
okay so here I'm using Lambda function

[02:34:43 - 02:34:47]
and Lambda is a on line function okay in

[02:34:45 - 02:34:49]
the one line I'm taking all the word one

[02:34:47 - 02:34:51]
by one and if any stop words is there

[02:34:49 - 02:34:53]
okay I'm just trying to remove that stop

[02:34:51 - 02:34:55]
W with the empt space that is the idea

[02:34:53 - 02:34:55]
now let me

[02:34:58 - 02:35:05]
execute now see there is uh no stop word

[02:35:02 - 02:35:08]
present in this data right now fine now

[02:35:05 - 02:35:11]
let me show you my head of the

[02:35:08 - 02:35:14]
data now what I have to do I have to uh

[02:35:11 - 02:35:16]
just uh separate out my X data and Y

[02:35:14 - 02:35:17]
data that means my independent variable

[02:35:16 - 02:35:19]
and dependent variable so independent

[02:35:17 - 02:35:20]
variable means this is the review one

[02:35:19 - 02:35:22]
independent variable means this is the

[02:35:20 - 02:35:25]
sentiment that means this sentiment is

[02:35:22 - 02:35:28]
my level right now so I'll store inside

[02:35:25 - 02:35:29]
X and level I will store inside y now

[02:35:28 - 02:35:32]
this is my

[02:35:29 - 02:35:35]
X that means the entire review and this

[02:35:32 - 02:35:38]
is my y that means my

[02:35:35 - 02:35:40]
sentiment now one issue you can see

[02:35:38 - 02:35:41]
sentiment is nothing but it's a text

[02:35:40 - 02:35:43]
okay it's a text you can see it's a

[02:35:41 - 02:35:45]
string but what I have to do I have to

[02:35:43 - 02:35:47]
convert to the numerical representation

[02:35:45 - 02:35:50]
so here I can simply apply uh label

[02:35:47 - 02:35:52]
encoder so it will assign positive with

[02:35:50 - 02:35:54]
one and negative with zero so let me

[02:35:52 - 02:35:56]
apply so for this I'm using level

[02:35:54 - 02:35:58]
encoder from escalan initializing the

[02:35:56 - 02:36:01]
object and I'm fitting my Y

[02:35:58 - 02:36:03]
data now see your data will become 0 by

[02:36:01 - 02:36:05]
one okay that means it has converted to

[02:36:03 - 02:36:06]
the numerical representation then what I

[02:36:05 - 02:36:08]
have to do I have to perform the 10 test

[02:36:06 - 02:36:10]
speed because I have to keep my data for

[02:36:08 - 02:36:12]
my training as well as the testing and

[02:36:10 - 02:36:13]
the test size is I have given 0.2 that

[02:36:12 - 02:36:16]
means 20% data I'm keeping for the

[02:36:13 - 02:36:17]
testing and 80% data I'm giving for the

[02:36:16 - 02:36:20]
training so let me

[02:36:17 - 02:36:22]
perform now this is the training site

[02:36:20 - 02:36:24]
and this is the testing size fine now

[02:36:22 - 02:36:25]
I'll be applying first of all bag of

[02:36:24 - 02:36:28]
word okay I already taught you the bag

[02:36:25 - 02:36:31]
of word I think you remember so I can

[02:36:28 - 02:36:33]
use the counter vectorizer for this now

[02:36:31 - 02:36:35]
I have to apply the bag of for on top of

[02:36:33 - 02:36:37]
my reviews okay reviews is my uh like

[02:36:35 - 02:36:38]
input data right then I'm also

[02:36:37 - 02:36:40]
performing on top of my test data

[02:36:38 - 02:36:41]
because I'm having two kinds of data

[02:36:40 - 02:36:43]
training data as well as the testing

[02:36:41 - 02:36:45]
data and I think you know whenever you

[02:36:43 - 02:36:47]
are performing on top of training data

[02:36:45 - 02:36:48]
you have to use feed transform and

[02:36:47 - 02:36:50]
whenever you are performing on top of

[02:36:48 - 02:36:52]
testing data you have to use transform

[02:36:50 - 02:36:56]
okay Ma function for this then I'm

[02:36:52 - 02:36:56]
converting to the array

[02:36:56 - 02:37:02]
representation now this is my

[02:36:59 - 02:37:05]
training uh vector and if you want to

[02:37:02 - 02:37:07]
also see the testing Vector this is your

[02:37:05 - 02:37:07]
testing

[02:37:07 - 02:37:12]
Vector okay now here we'll be using one

[02:37:10 - 02:37:15]
machine learning model called KN bias

[02:37:12 - 02:37:18]
inside KN bias we are having uh one NAB

[02:37:15 - 02:37:19]
version called goian NB okay goian NAB

[02:37:18 - 02:37:21]
we'll be using this particular algorithm

[02:37:19 - 02:37:24]
so here you can see I'm fitting my data

[02:37:21 - 02:37:26]
so X train and Y train now let me train

[02:37:24 - 02:37:26]
my

[02:37:28 - 02:37:32]
data so here I'm only showing you how

[02:37:30 - 02:37:34]
you can pre-process your data how you

[02:37:32 - 02:37:36]
can prepare your data for the model

[02:37:34 - 02:37:38]
training and all but going forward here

[02:37:36 - 02:37:40]
we'll be using uh actually Transformer

[02:37:38 - 02:37:42]
based architecture okay that means large

[02:37:40 - 02:37:44]
language model we'll be using here now

[02:37:42 - 02:37:45]
this is the training I have done now

[02:37:44 - 02:37:47]
we'll be doing the prediction on top of

[02:37:45 - 02:37:49]
my test data then we'll be calculating

[02:37:47 - 02:37:51]
the accuracy score okay now let me

[02:37:49 - 02:37:55]
execute see this is the ACC score I'm

[02:37:51 - 02:37:56]
getting uh if I'm using goian NB and if

[02:37:55 - 02:38:00]
I'm using bag of word okay bag of word

[02:37:56 - 02:38:02]
technique so I'm getting 63% accuracy

[02:38:00 - 02:38:04]
now you can see this is the confusion

[02:38:02 - 02:38:06]
metrix now if I'm applying random Forest

[02:38:04 - 02:38:08]
classifier on top of it so now let's see

[02:38:06 - 02:38:11]
the accuracy I

[02:38:08 - 02:38:13]
got so guys you can see after applying

[02:38:11 - 02:38:16]
random forest classifier and uh I was

[02:38:13 - 02:38:19]
using bag of word I I'm getting this

[02:38:16 - 02:38:22]
accuracy 84% accuracy now see uh we'll

[02:38:19 - 02:38:24]
be using bag of word only now instead of

[02:38:22 - 02:38:27]
uh see taking all the features what I

[02:38:24 - 02:38:29]
will do I'll take maximum features uh

[02:38:27 - 02:38:31]
3,000 okay now you can ask me what is

[02:38:29 - 02:38:33]
maximum feature 3,000 I think you saw

[02:38:31 - 02:38:35]
the entire Corpus right I I already told

[02:38:33 - 02:38:38]
you the Corpus okay about the Corpus

[02:38:35 - 02:38:40]
corpa means the entire data and from the

[02:38:38 - 02:38:43]
entire data I'm only considering 3,000

[02:38:40 - 02:38:45]
unique word okay 3,000 unique word 3,000

[02:38:43 - 02:38:47]
frequent uni word okay this is called

[02:38:45 - 02:38:49]
maximum features because see I don't

[02:38:47 - 02:38:51]
need all the features because if I'm

[02:38:49 - 02:38:52]
using all the features my Dimension will

[02:38:51 - 02:38:54]
increase right and I don't need to

[02:38:52 - 02:38:56]
increase my Dimension okay if my

[02:38:54 - 02:38:58]
Dimension is increasing that means my

[02:38:56 - 02:39:00]
model will get more complexity right to

[02:38:58 - 02:39:02]
perform the prediction on top of it and

[02:39:00 - 02:39:04]
here I'm using a machine learning model

[02:39:02 - 02:39:06]
okay I think you are uh you can see so

[02:39:04 - 02:39:08]
that's why I'm taking most frequent

[02:39:06 - 02:39:10]
3,000 uh maximum features instead of

[02:39:08 - 02:39:12]
taking all the features right now it

[02:39:10 - 02:39:14]
will create uh 3,000 dimensional space

[02:39:12 - 02:39:17]
okay 3,000 dimensional space instead of

[02:39:14 - 02:39:19]
taking all the uh unique word right now

[02:39:17 - 02:39:20]
see again I'm performing the bag of word

[02:39:19 - 02:39:22]
operation now again I'm taking random

[02:39:20 - 02:39:25]
first classifier and I'm training and

[02:39:22 - 02:39:26]
checking the accuracy now if I execute

[02:39:25 - 02:39:29]
uh so you can see this is the result but

[02:39:26 - 02:39:31]
this result is not good enough so we are

[02:39:29 - 02:39:34]
getting close related accuracy only if

[02:39:31 - 02:39:36]
I'm using all the let's say um features

[02:39:34 - 02:39:38]
and if I'm taking 3,000 features the

[02:39:36 - 02:39:40]
accuracy I'm getting it is almost same

[02:39:38 - 02:39:42]
now let's try with NRS because I already

[02:39:40 - 02:39:45]
told you about NRS right what is NRS

[02:39:42 - 02:39:48]
exactly so here let me uh pass the range

[02:39:45 - 02:39:50]
of 2 two because I want to consider a

[02:39:48 - 02:39:51]
pair okay pair of word that's why I have

[02:39:50 - 02:39:53]
given two two that means it will

[02:39:51 - 02:39:55]
consider two word okay as a one pair

[02:39:53 - 02:39:59]
that's the idea and here I'm only taking

[02:39:55 - 02:40:01]
uh 5,000 uh most reent word okay now

[02:39:59 - 02:40:04]
again I'm performing back back of word

[02:40:01 - 02:40:06]
operation then uh random for classifier

[02:40:04 - 02:40:09]
then I'm uh calculating the accuracy now

[02:40:06 - 02:40:11]
let me show you so guys you can see uh

[02:40:09 - 02:40:13]
this is the result actually I'm getting

[02:40:11 - 02:40:17]
so now in the summary you can see uh

[02:40:13 - 02:40:19]
your like bag of word is working fine

[02:40:17 - 02:40:22]
instead of taking the grams so in some

[02:40:19 - 02:40:24]
case actually bag of word will work fine

[02:40:22 - 02:40:25]
in some case engrams will work fine it's

[02:40:24 - 02:40:27]
completely experimental things okay you

[02:40:25 - 02:40:31]
have to perform now let's try with TF

[02:40:27 - 02:40:33]
IDF okay um tfidf technique so here is

[02:40:31 - 02:40:34]
the TF IDF code I think you remember so

[02:40:33 - 02:40:37]
first of all we have to initialize the

[02:40:34 - 02:40:38]
TF IDF then I will apply on top of my

[02:40:37 - 02:40:41]
data okay training data as well as the

[02:40:38 - 02:40:43]
testing data so it will give me the

[02:40:41 - 02:40:45]
vector and again I'll be using random

[02:40:43 - 02:40:47]
first classifier to train the model and

[02:40:45 - 02:40:51]
I will show you the accuracy score now

[02:40:47 - 02:40:51]
see if I show you the accuracy

[02:40:52 - 02:40:56]
see so here we are using machine

[02:40:54 - 02:40:57]
learning model that's why performance is

[02:40:56 - 02:40:59]
not good but if you're using any kinds

[02:40:57 - 02:41:01]
of deep Landing model you will see that

[02:40:59 - 02:41:03]
your model will perform good now here

[02:41:01 - 02:41:06]
you can see this is the performance of

[02:41:03 - 02:41:08]
the now you can see this is the accuracy

[02:41:06 - 02:41:10]
I got so here I showed you almost all

[02:41:08 - 02:41:12]
the vectorization technique we have

[02:41:10 - 02:41:15]
learned but one thing I want you to

[02:41:12 - 02:41:16]
explore this uh what to vake one so I

[02:41:15 - 02:41:18]
already shared you the code of the what

[02:41:16 - 02:41:21]
to vake so what you have to do just try

[02:41:18 - 02:41:23]
to apply what V get the vector and try

[02:41:21 - 02:41:25]
to train with random first model and

[02:41:23 - 02:41:27]
just observe the accuracy okay so this

[02:41:25 - 02:41:28]
should be your task guys from my side

[02:41:27 - 02:41:30]
Because unless and until you are not

[02:41:28 - 02:41:32]
doing anything things would be um much

[02:41:30 - 02:41:33]
difficult for you to learn right but if

[02:41:32 - 02:41:35]
you're practicing by yourself I think

[02:41:33 - 02:41:37]
this will help you a lot to learn any

[02:41:35 - 02:41:38]
kinds of topic so yes this is how

[02:41:37 - 02:41:40]
actually we can perform the text

[02:41:38 - 02:41:41]
classification with the help of machine

[02:41:40 - 02:41:43]
learning and that's how actually we can

[02:41:41 - 02:41:45]
perform the data cleaning task like data

[02:41:43 - 02:41:47]
preprocessing and text representation

[02:41:45 - 02:41:48]
okay everything we can perform like that

[02:41:47 - 02:41:51]
but again I'm telling you guys this is

[02:41:48 - 02:41:52]
not ual way we create our application

[02:41:51 - 02:41:54]
this is just a basic introduction I have

[02:41:52 - 02:41:56]
given like how we can uh like do the

[02:41:54 - 02:41:58]
data preparation okay this is my main

[02:41:56 - 02:42:00]
objective now in the next video we'll be

[02:41:58 - 02:42:02]
learning about large language model like

[02:42:00 - 02:42:04]
what exactly this large language model

[02:42:02 - 02:42:05]
and how this large language model got

[02:42:04 - 02:42:07]
trained okay everything we'll be trying

[02:42:05 - 02:42:10]
to discuss so as of now we have seen so

[02:42:07 - 02:42:11]
many things like we saw the entire genbi

[02:42:10 - 02:42:13]
pipeline we saw the text preprocessing

[02:42:11 - 02:42:15]
as well as the data

[02:42:13 - 02:42:18]
representation and uh I also did one

[02:42:15 - 02:42:19]
practical uh I just implemented one text

[02:42:18 - 02:42:21]
classification

[02:42:19 - 02:42:23]
uh with the help of machine learning

[02:42:21 - 02:42:26]
model but I already told you uh see it

[02:42:23 - 02:42:27]
was just experiment uh but going forward

[02:42:26 - 02:42:29]
actually we have to use something called

[02:42:27 - 02:42:31]
large language model because here we are

[02:42:29 - 02:42:33]
learning generative and inside

[02:42:31 - 02:42:35]
generative VI the core component is the

[02:42:33 - 02:42:37]
large language model now let's try to

[02:42:35 - 02:42:39]
understand what exactly uh the large

[02:42:37 - 02:42:41]
language model is and what is the code

[02:42:39 - 02:42:43]
architecture behind this large language

[02:42:41 - 02:42:46]
model so guys as you can see a large

[02:42:43 - 02:42:47]
language model uh is a trained deep

[02:42:46 - 02:42:50]
learning model that understand and

[02:42:47 - 02:42:53]
generate text in in a humanlike fashion

[02:42:50 - 02:42:55]
okay LMS are good at understanding and

[02:42:53 - 02:42:57]
generating the human language as I

[02:42:55 - 02:42:58]
already told you inside generative by we

[02:42:57 - 02:43:01]
having large language model we also call

[02:42:58 - 02:43:03]
it as a generative model and what is the

[02:43:01 - 02:43:06]
use of generative model generative model

[02:43:03 - 02:43:07]
can generate a new data okay so that is

[02:43:06 - 02:43:09]
why here I have mentioned a large

[02:43:07 - 02:43:11]
language model is a trained deep

[02:43:09 - 02:43:13]
learning models that understand and

[02:43:11 - 02:43:16]
generate text like a human fashion that

[02:43:13 - 02:43:17]
means whatever model you used previously

[02:43:16 - 02:43:20]
let's say whatever traditional model you

[02:43:17 - 02:43:21]
used let's say U machine larning model

[02:43:20 - 02:43:23]
it can be any kinds of traditional deep

[02:43:21 - 02:43:26]
larning model those are the model can't

[02:43:23 - 02:43:28]
generate the text like a human fashion

[02:43:26 - 02:43:29]
okay it can only do the prediction

[02:43:28 - 02:43:31]
because I told you the difference

[02:43:29 - 02:43:34]
between descriptive model as well as the

[02:43:31 - 02:43:36]
generative model but here this large

[02:43:34 - 02:43:38]
language model can generate a text okay

[02:43:36 - 02:43:40]
and it would be human fashion that means

[02:43:38 - 02:43:42]
the way human generate any kinds of text

[02:43:40 - 02:43:44]
let's say currently I'm speaking right

[02:43:42 - 02:43:46]
I'm giving you the understanding so the

[02:43:44 - 02:43:48]
same concept can be applied in the large

[02:43:46 - 02:43:50]
language model also so large language

[02:43:48 - 02:43:52]
model can also mimic the human behavior

[02:43:50 - 02:43:54]
okay this is the main idea here and LMS

[02:43:52 - 02:43:56]
are good at understanding and rting the

[02:43:54 - 02:43:59]
human language as I already told you and

[02:43:56 - 02:44:02]
how this llm works see the core working

[02:43:59 - 02:44:04]
mechanism inside llm uh it will generate

[02:44:02 - 02:44:06]
the next word so here I have given

[02:44:04 - 02:44:09]
example let's say the garden was full of

[02:44:06 - 02:44:11]
the beautiful now see this particular

[02:44:09 - 02:44:13]
sentence you are giving to the large

[02:44:11 - 02:44:16]
language model okay and large language

[02:44:13 - 02:44:18]
model is able to generate flowers that

[02:44:16 - 02:44:20]
means it is trying to generate okay next

[02:44:18 - 02:44:23]
word always okay is trying to generate

[02:44:20 - 02:44:25]
next word that is the main uh core idea

[02:44:23 - 02:44:27]
inside large language model that means

[02:44:25 - 02:44:28]
whatever let's say prompt we are giving

[02:44:27 - 02:44:30]
okay whatever prompt we are giving

[02:44:28 - 02:44:32]
whatever let's say uh text it is

[02:44:30 - 02:44:35]
generating it will try to generate the

[02:44:32 - 02:44:37]
next word always okay this is the main U

[02:44:35 - 02:44:38]
logic behind the large language model so

[02:44:37 - 02:44:40]
here are some more example you can see

[02:44:38 - 02:44:42]
it's raining cats and so this is my

[02:44:40 - 02:44:44]
let's say input to the large language

[02:44:42 - 02:44:46]
model large language model will uh try

[02:44:44 - 02:44:48]
to uh actually generate this particular

[02:44:46 - 02:44:50]
word called dogs okay now there is

[02:44:48 - 02:44:53]
another one I have two apples and I at

[02:44:50 - 02:44:54]
one I'm left with so this is the input

[02:44:53 - 02:44:56]
you are passing to the large language

[02:44:54 - 02:44:58]
model so Palm is nothing but it's a

[02:44:56 - 02:45:00]
large language model and it is able to

[02:44:58 - 02:45:03]
predict one okay that means it is able

[02:45:00 - 02:45:05]
to generate the next word of the prompt

[02:45:03 - 02:45:06]
you have given okay this is the main

[02:45:05 - 02:45:08]
working mechanism of a large language

[02:45:06 - 02:45:10]
model apart from that there are some

[02:45:08 - 02:45:13]
more advanced technique it usually used

[02:45:10 - 02:45:15]
I will uh also explain so I'll will also

[02:45:13 - 02:45:17]
explain like how chat GPT was trained

[02:45:15 - 02:45:19]
and how it is working and all okay I

[02:45:17 - 02:45:20]
think this concept would be more clear

[02:45:19 - 02:45:22]
as of now this is the high level

[02:45:20 - 02:45:23]
understanding I'm giving you how this

[02:45:22 - 02:45:25]
model is working okay let's say whenever

[02:45:23 - 02:45:27]
it is generating something new data how

[02:45:25 - 02:45:29]
it is working this is the main idea here

[02:45:27 - 02:45:31]
now let's try to understand why we call

[02:45:29 - 02:45:34]
it as a large language model because you

[02:45:31 - 02:45:35]
can see um because of the size and

[02:45:34 - 02:45:38]
complexity of the neural network as well

[02:45:35 - 02:45:40]
as the size of the data set that it was

[02:45:38 - 02:45:41]
trained on that means if you see any

[02:45:40 - 02:45:43]
kinds of large language model OKAY over

[02:45:41 - 02:45:46]
the Internet any kind of LM model you

[02:45:43 - 02:45:48]
will see it is using very big and

[02:45:46 - 02:45:49]
complex neural network okay very big and

[02:45:48 - 02:45:52]
complex neural network right even it is

[02:45:49 - 02:45:54]
trained with massive amount of data okay

[02:45:52 - 02:45:56]
and the model actually we are using it

[02:45:54 - 02:45:57]
is called actually pre-end model that

[02:45:56 - 02:45:59]
means this model is already trained with

[02:45:57 - 02:46:01]
massive amount of data okay it is called

[02:45:59 - 02:46:02]
pre-rain model and we call it as a

[02:46:01 - 02:46:03]
transfer learning I think you have

[02:46:02 - 02:46:05]
already learned transform learning in

[02:46:03 - 02:46:07]
your uh previous days right in you know

[02:46:05 - 02:46:08]
deep learning computer visual machine

[02:46:07 - 02:46:10]
learning so what is transform learning

[02:46:08 - 02:46:12]
transform learning means we are using an

[02:46:10 - 02:46:14]
existing model okay that model is

[02:46:12 - 02:46:15]
already trended with some kinds of data

[02:46:14 - 02:46:17]
set okay this is called actually

[02:46:15 - 02:46:19]
transfer learning so here so this

[02:46:17 - 02:46:21]
transfer learning makes this gen is so

[02:46:19 - 02:46:23]
powerful because they are training these

[02:46:21 - 02:46:25]
kinds of complex neural network with the

[02:46:23 - 02:46:27]
massive amount of data set so as you can

[02:46:25 - 02:46:30]
see researcher started to make this

[02:46:27 - 02:46:32]
model large and trained on huge data

[02:46:30 - 02:46:34]
sets that they started showing

[02:46:32 - 02:46:36]
impressive results like understanding

[02:46:34 - 02:46:38]
the complex natural language and

[02:46:36 - 02:46:40]
generating language more eloquently than

[02:46:38 - 02:46:43]
ever okay this is the main idea that's

[02:46:40 - 02:46:45]
why we call it as a large language model

[02:46:43 - 02:46:48]
now you can see the large language model

[02:46:45 - 02:46:50]
code architecture now many people uh has

[02:46:48 - 02:46:52]
this kind of question what is the

[02:46:50 - 02:46:54]
architecture actually llm is using okay

[02:46:52 - 02:46:57]
see this is the core architecture all

[02:46:54 - 02:46:59]
kinds of llm are using a large language

[02:46:57 - 02:47:01]
models are based on the Transformer a

[02:46:59 - 02:47:03]
type of neural network architecture

[02:47:01 - 02:47:05]
invented by Google those who have

[02:47:03 - 02:47:06]
already learned about natural language

[02:47:05 - 02:47:08]
processing right those you have already

[02:47:06 - 02:47:10]
learned about attention mechanism

[02:47:08 - 02:47:13]
Transformer so you are already familiar

[02:47:10 - 02:47:14]
with this architecture yes or no right

[02:47:13 - 02:47:15]
so you are already familiar with this

[02:47:14 - 02:47:18]
architecture and this architecture is

[02:47:15 - 02:47:20]
known as Transformer architecture okay

[02:47:18 - 02:47:22]
and it is invented by Google okay and

[02:47:20 - 02:47:25]
this was the main breakthrough in the

[02:47:22 - 02:47:27]
field of uh natural language processing

[02:47:25 - 02:47:29]
even in the field of generative because

[02:47:27 - 02:47:30]
based on this particular architecture

[02:47:29 - 02:47:33]
all kinds of large language model you

[02:47:30 - 02:47:34]
can see over the market okay everything

[02:47:33 - 02:47:36]
has been

[02:47:34 - 02:47:38]
developed fine so this is the main

[02:47:36 - 02:47:39]
architecture here so it is having two

[02:47:38 - 02:47:42]
kinds of part one is the encoder part

[02:47:39 - 02:47:43]
and other is like decoder part and

[02:47:42 - 02:47:45]
inside that you are having something

[02:47:43 - 02:47:47]
called multi-head attention okay no need

[02:47:45 - 02:47:49]
to worry I will explain this particular

[02:47:47 - 02:47:52]
concept uh I will uh create a dedicated

[02:47:49 - 02:47:54]
video for this how uh this Transformer

[02:47:52 - 02:47:55]
architecture is working inside a

[02:47:54 - 02:47:57]
Transformer architecture what the

[02:47:55 - 02:47:59]
component it is having okay everything

[02:47:57 - 02:48:01]
I'll try to clarify okay for this I'll

[02:47:59 - 02:48:02]
keep a dedicated uh video okay so that

[02:48:01 - 02:48:04]
you can understand this Transformer in

[02:48:02 - 02:48:07]
depth fine as of now just try to

[02:48:04 - 02:48:09]
consider this is the core architecture

[02:48:07 - 02:48:11]
behind all kinds of large language model

[02:48:09 - 02:48:13]
okay and it is invented by Google and

[02:48:11 - 02:48:15]
this is known as Transformer

[02:48:13 - 02:48:17]
architecture and it is having two layer

[02:48:15 - 02:48:19]
called uh um your encoder layer and is

[02:48:17 - 02:48:21]
like decoder layer

[02:48:19 - 02:48:23]
so this one left left side this is

[02:48:21 - 02:48:24]
called encoder layer and right side this

[02:48:23 - 02:48:25]
is called decoder layer okay inside that

[02:48:24 - 02:48:27]
you can see different different

[02:48:25 - 02:48:30]
component like input in coding multi

[02:48:27 - 02:48:32]
head attention add normalization feed

[02:48:30 - 02:48:34]
forward okay that's how you are having

[02:48:32 - 02:48:36]
different different component inside

[02:48:34 - 02:48:38]
that I hope it is cleared fine now on

[02:48:36 - 02:48:39]
top of this architecture what they did

[02:48:38 - 02:48:41]
actually they added some more layer they

[02:48:39 - 02:48:43]
added some more functionality and they

[02:48:41 - 02:48:44]
brought these kinds of large language

[02:48:43 - 02:48:46]
model different different large language

[02:48:44 - 02:48:48]
model now let's try to see some large

[02:48:46 - 02:48:49]
language model but before that uh first

[02:48:48 - 02:48:51]
of all let me tell you what makes large

[02:48:49 - 02:48:53]
language model so powerful because I

[02:48:51 - 02:48:55]
already told you in case of llm one

[02:48:53 - 02:48:57]
model can be used for whole variety of

[02:48:55 - 02:48:59]
task like you can perform Tech

[02:48:57 - 02:49:01]
generation chatboard summarization

[02:48:59 - 02:49:04]
translation code generation and so on

[02:49:01 - 02:49:06]
with one model you can perform all kinds

[02:49:04 - 02:49:08]
of task but whenever we used to use our

[02:49:06 - 02:49:10]
traditional NLP model that means only

[02:49:08 - 02:49:12]
the language model we can only perform

[02:49:10 - 02:49:14]
one specific task let's say you want to

[02:49:12 - 02:49:15]
do language translation for this you

[02:49:14 - 02:49:17]
have to only use language translation

[02:49:15 - 02:49:20]
model and that model can't do the code

[02:49:17 - 02:49:22]
generation okay but here in the large

[02:49:20 - 02:49:25]
language model you can do whole variety

[02:49:22 - 02:49:27]
of task I think you saw the chat gbt let

[02:49:25 - 02:49:29]
me show you one example so guys this is

[02:49:27 - 02:49:31]
our chat GPT now inside that I can give

[02:49:29 - 02:49:33]
any kinds of input let's say I'll give

[02:49:31 - 02:49:37]
uh give

[02:49:33 - 02:49:40]
me the German

[02:49:37 - 02:49:43]
translation of this text now here you

[02:49:40 - 02:49:46]
can pass the text let's say how

[02:49:43 - 02:49:49]
are you fine now see if I give this

[02:49:46 - 02:49:49]
prompt

[02:49:49 - 02:49:54]
so it will give me the translation in

[02:49:52 - 02:49:56]
German of this text okay now see this is

[02:49:54 - 02:49:59]
the translation in German now you can

[02:49:56 - 02:50:03]
also do the sentiment analysis so here I

[02:49:59 - 02:50:06]
can write give me the let's say

[02:50:03 - 02:50:09]
um

[02:50:06 - 02:50:09]
sentiment okay of this

[02:50:10 - 02:50:15]
text see it's a neutral sentiment now

[02:50:14 - 02:50:18]
you can also perform something called

[02:50:15 - 02:50:20]
language detection so I'll give give me

[02:50:18 - 02:50:20]
the

[02:50:21 - 02:50:25]
language or I can write detect the

[02:50:23 - 02:50:27]
language okay detect the language of

[02:50:25 - 02:50:30]
this text now see it it should give me

[02:50:27 - 02:50:33]
English fine so that's how with the help

[02:50:30 - 02:50:34]
of one model you can do variety of task

[02:50:33 - 02:50:37]
you can also generate the code so I'll

[02:50:34 - 02:50:44]
give give

[02:50:37 - 02:50:47]
me a python code for adding two

[02:50:44 - 02:50:48]
numbers see it can also generate the

[02:50:47 - 02:50:50]
codes so this is how actually large

[02:50:48 - 02:50:53]
language model works okay and that makes

[02:50:50 - 02:50:55]
llm so powerful now let's try to see

[02:50:53 - 02:50:58]
some of the large language models are

[02:50:55 - 02:51:00]
available over the internet see I have

[02:50:58 - 02:51:01]
just listed down some of them but you

[02:51:00 - 02:51:03]
will see thousands of models are

[02:51:01 - 02:51:06]
available I will also tell you where you

[02:51:03 - 02:51:09]
will get all the model list and all okay

[02:51:06 - 02:51:10]
so as of now just try to see guys uh we

[02:51:09 - 02:51:12]
are having different different large

[02:51:10 - 02:51:14]
language model like jman so I think you

[02:51:12 - 02:51:17]
know jini right ji was developed by

[02:51:14 - 02:51:19]
Google even we are having also uh one

[02:51:17 - 02:51:21]
application of the Jin let me show you

[02:51:19 - 02:51:24]
so in Google if you search for J.G

[02:51:21 - 02:51:26]
google.com so you'll see these kinds of

[02:51:24 - 02:51:28]
application and this is the same kinds

[02:51:26 - 02:51:30]
of application like your CH GPT okay

[02:51:28 - 02:51:31]
here here also you can give the prompt

[02:51:30 - 02:51:32]
and here also you can get the response

[02:51:31 - 02:51:35]
let's say the previous prompt I have

[02:51:32 - 02:51:36]
given here I can also pass it here okay

[02:51:35 - 02:51:38]
and in the back end they're using

[02:51:36 - 02:51:40]
something called jini model OKAY jini

[02:51:38 - 02:51:42]
large language model then we are having

[02:51:40 - 02:51:44]
something called GPT okay GPT stand for

[02:51:42 - 02:51:47]
generative pre-end Transformer okay the

[02:51:44 - 02:51:48]
model was developed by open AI that

[02:51:47 - 02:51:50]
means the chart GPT you are using it is

[02:51:48 - 02:51:52]
using something called GPT based model

[02:51:50 - 02:51:55]
okay we are having GPT 3 4 okay these

[02:51:52 - 02:51:57]
are the model we are having even uh

[02:51:55 - 02:51:59]
recently actually GPT published one

[02:51:57 - 02:52:01]
amazing model I think GPT 40 model okay

[02:51:59 - 02:52:03]
with that you can also generate videos

[02:52:01 - 02:52:04]
you can also generate like so many

[02:52:03 - 02:52:06]
things okay if you just search on Google

[02:52:04 - 02:52:09]
you will see different different uh

[02:52:06 - 02:52:10]
version of the GPT even uh there uh

[02:52:09 - 02:52:12]
application and all like okay everything

[02:52:10 - 02:52:14]
you can see there then we are having

[02:52:12 - 02:52:16]
something called xlm that means cross

[02:52:14 - 02:52:18]
lingual language model okay so this is

[02:52:16 - 02:52:20]
one of the large language model it is is

[02:52:18 - 02:52:22]
Al also available now we're having

[02:52:20 - 02:52:24]
something called llama okay and it was

[02:52:22 - 02:52:26]
developed by m so llama is having

[02:52:24 - 02:52:28]
different different variant like llama 2

[02:52:26 - 02:52:30]
llama 3 okay recently Lama 3 was

[02:52:28 - 02:52:33]
published 3.1 is published I think and

[02:52:30 - 02:52:35]
uh this model is uh amazing uh it can

[02:52:33 - 02:52:37]
also let's say uh generate text like a

[02:52:35 - 02:52:39]
human even uh going forward we'll be

[02:52:37 - 02:52:41]
also learning how we can use Lama 23

[02:52:39 - 02:52:42]
model OKAY in our application with the

[02:52:41 - 02:52:44]
help of that we'll be building different

[02:52:42 - 02:52:45]
different application now you can see

[02:52:44 - 02:52:47]
there is another model called Megatron

[02:52:45 - 02:52:49]
so Megatron is a large language model

[02:52:47 - 02:52:52]
and it's like very powerful Transformer

[02:52:49 - 02:52:54]
model OKAY developed by um Nvidia

[02:52:52 - 02:52:56]
research team I think you know Nvidia so

[02:52:54 - 02:52:58]
we are using Nvidia gpus in our system

[02:52:56 - 02:52:59]
right so Nvidia uh team has developed

[02:52:58 - 02:53:01]
this particular Megatron model and this

[02:52:59 - 02:53:04]
is one of the large language model now

[02:53:01 - 02:53:05]
we having something called M2M 100 so

[02:53:04 - 02:53:07]
this is called actually multilingual

[02:53:05 - 02:53:09]
encoder and decoder sequence to sequence

[02:53:07 - 02:53:11]
model okay and it was developed by

[02:53:09 - 02:53:12]
Facebook so these are the models

[02:53:11 - 02:53:13]
actually we are having apart from that I

[02:53:12 - 02:53:15]
told you now we are having thousands of

[02:53:13 - 02:53:17]
model let me show you so this is the

[02:53:15 - 02:53:20]
GitHub guys so the GitHub name is open

[02:53:17 - 02:53:22]
llms okay now now what uh this guy did

[02:53:20 - 02:53:24]
actually this guy actually listed all

[02:53:22 - 02:53:26]
the large language models are available

[02:53:24 - 02:53:29]
over the Internet okay now see he has uh

[02:53:26 - 02:53:31]
created one beautiful GitHub repository

[02:53:29 - 02:53:32]
and in the rme file he listed down all

[02:53:31 - 02:53:34]
the large language model as well as

[02:53:32 - 02:53:35]
their uh checkpoints let's see want to

[02:53:34 - 02:53:37]
download this model you can also

[02:53:35 - 02:53:39]
download this model from this particular

[02:53:37 - 02:53:41]
link if you want to read the papers and

[02:53:39 - 02:53:43]
blog of this particular model he has

[02:53:41 - 02:53:45]
also given the link apart from that the

[02:53:43 - 02:53:47]
parameter size context length and as

[02:53:45 - 02:53:49]
well as the license so every information

[02:53:47 - 02:53:51]
you will get uh of any kinds of large

[02:53:49 - 02:53:54]
language model now see T5 is one of the

[02:53:51 - 02:53:56]
large language model then RW kv4 okay

[02:53:54 - 02:54:01]
then GPT neox then

[02:53:56 - 02:54:02]
yl2 Bloom chat glm okay now see

[02:54:01 - 02:54:05]
different different large language model

[02:54:02 - 02:54:08]
you are having see okay Falcon is also

[02:54:05 - 02:54:10]
there then Lama 2 I already told you

[02:54:08 - 02:54:11]
then Mistral is also there okay see

[02:54:10 - 02:54:13]
different different large language model

[02:54:11 - 02:54:15]
and it is having so many large language

[02:54:13 - 02:54:16]
model guys so many large language model

[02:54:15 - 02:54:18]
if you want to explore open this

[02:54:16 - 02:54:21]
particular link just write open LM

[02:54:18 - 02:54:22]
inside Google you will able to see these

[02:54:21 - 02:54:24]
kinds of GitHub okay and you can also

[02:54:22 - 02:54:27]
keep this link with you so that if you

[02:54:24 - 02:54:28]
need any model later on um if you want

[02:54:27 - 02:54:29]
to develop any kinds of projects with

[02:54:28 - 02:54:32]
the help of any kinds of large language

[02:54:29 - 02:54:34]
model you can use this repository later

[02:54:32 - 02:54:36]
on so that you can see the uh paper blog

[02:54:34 - 02:54:38]
link okay it will help you to understand

[02:54:36 - 02:54:40]
this particular model so guys as I

[02:54:38 - 02:54:42]
already told you uh all the large

[02:54:40 - 02:54:43]
language model using one code

[02:54:42 - 02:54:45]
architecture which is nothing but

[02:54:43 - 02:54:47]
Transformer architecture and inside

[02:54:45 - 02:54:48]
Transformer architecture I showed you

[02:54:47 - 02:54:52]
there are two kinds of layer called

[02:54:48 - 02:54:54]
encoding layer and decoder layer okay

[02:54:52 - 02:54:55]
now see uh here is the Transformer

[02:54:54 - 02:54:57]
architecture let's say and it is having

[02:54:55 - 02:54:59]
two kinds of part like encoder and

[02:54:57 - 02:55:00]
decoder now I think I showed you

[02:54:59 - 02:55:02]
different different large language model

[02:55:00 - 02:55:05]
like thousands of large language model

[02:55:02 - 02:55:06]
now see all the models are not using

[02:55:05 - 02:55:08]
both layer that means encoder and

[02:55:06 - 02:55:10]
decoder layer some of the models are

[02:55:08 - 02:55:13]
using encoder layer some of the models

[02:55:10 - 02:55:15]
are using decoder layer okay and some of

[02:55:13 - 02:55:17]
the models are using both layer that

[02:55:15 - 02:55:19]
means encoder and decoder both now here

[02:55:17 - 02:55:21]
I've listed down some of the models so

[02:55:19 - 02:55:23]
this will give you the idea what kinds

[02:55:21 - 02:55:24]
of models are using encoder layer only

[02:55:23 - 02:55:26]
what kinds of models are using decoder

[02:55:24 - 02:55:28]
layer only and what kinds of models are

[02:55:26 - 02:55:30]
using both layer okay you can see

[02:55:28 - 02:55:31]
encoder uh based architecture these are

[02:55:30 - 02:55:35]
the encoder based architecture like

[02:55:31 - 02:55:39]
distill b b Robata okay ex xlm then

[02:55:35 - 02:55:41]
Alber Electra okay then darta so these

[02:55:39 - 02:55:43]
are the model based on the encoder layer

[02:55:41 - 02:55:46]
only okay now you can see the decoder

[02:55:43 - 02:55:47]
layer model so GPT gpt2 gpt3 okay

[02:55:46 - 02:55:49]
whatever GPT series you are having it is

[02:55:47 - 02:55:51]
using something called decoder layer

[02:55:49 - 02:55:53]
only okay decoder architecture only fine

[02:55:51 - 02:55:55]
then both actually layer that means

[02:55:53 - 02:55:57]
encoder and decoder both layer so we are

[02:55:55 - 02:56:00]
having something called T5 B then we are

[02:55:57 - 02:56:03]
having something called uh see this is

[02:56:00 - 02:56:06]
Bart actually b a r t not b r t okay

[02:56:03 - 02:56:09]
this is another model now M2 m00 and Big

[02:56:06 - 02:56:10]
B so these are the models are using

[02:56:09 - 02:56:12]
encoder and decoder see it's not

[02:56:10 - 02:56:14]
possible to list down all the models

[02:56:12 - 02:56:16]
here that's why I just listed down some

[02:56:14 - 02:56:18]
of them but there are so many models

[02:56:16 - 02:56:19]
that using like both architecture there

[02:56:18 - 02:56:20]
are so many model that using only

[02:56:19 - 02:56:21]
encoder architecture there are so many

[02:56:20 - 02:56:23]
model that are using decoder

[02:56:21 - 02:56:25]
architecture okay and this is called

[02:56:23 - 02:56:27]
actually Transformer T okay this is

[02:56:25 - 02:56:29]
called actually Transformer T so with

[02:56:27 - 02:56:32]
the so by referring this particular T

[02:56:29 - 02:56:34]
you can easily understand um what kinds

[02:56:32 - 02:56:36]
of models are using which kinds of

[02:56:34 - 02:56:38]
architecture okay this is the main idea

[02:56:36 - 02:56:40]
here now let's try to see some open

[02:56:38 - 02:56:41]
based large language model uh because

[02:56:40 - 02:56:43]
going forward we'll be using something

[02:56:41 - 02:56:45]
called open platform okay we'll be

[02:56:43 - 02:56:46]
generating open key and we'll be

[02:56:45 - 02:56:48]
implementing different different

[02:56:46 - 02:56:50]
projects now see inside open we having

[02:56:48 - 02:56:53]
different different models like GPT 4

[02:56:50 - 02:56:56]
then GPT 3.5 GPT based Deli whisper

[02:56:53 - 02:56:58]
embeddings model even moderation model

[02:56:56 - 02:57:00]
gp3 Legacy model so these are the models

[02:56:58 - 02:57:02]
are available in the open AI platform

[02:57:00 - 02:57:04]
apart from that I think recently they

[02:57:02 - 02:57:06]
have released more model because it's a

[02:57:04 - 02:57:10]
uh continuous research fi it's not like

[02:57:06 - 02:57:12]
that uh it will be like uh fixed

[02:57:10 - 02:57:14]
research every day they bringing new new

[02:57:12 - 02:57:15]
technology in their platform okay so if

[02:57:14 - 02:57:17]
you want to learn all of them you have

[02:57:15 - 02:57:19]
to keep updated with their technology

[02:57:17 - 02:57:20]
always for this you can you can refer

[02:57:19 - 02:57:22]
their website okay you can refer their

[02:57:20 - 02:57:24]
website and try to see what are the

[02:57:22 - 02:57:25]
models they're bringing okay so like

[02:57:24 - 02:57:27]
that actually you'll be learning a lot

[02:57:25 - 02:57:30]
it's not like that you only need to rely

[02:57:27 - 02:57:31]
on your Mentor okay as a mentor I can

[02:57:30 - 02:57:33]
give you the entire path how we can get

[02:57:31 - 02:57:35]
started with I will teach you how you

[02:57:33 - 02:57:37]
can use them but as a learner what you

[02:57:35 - 02:57:38]
have to do you have to explore by

[02:57:37 - 02:57:40]
yourself unless and until you are not

[02:57:38 - 02:57:43]
exploring uh by yourself it would be

[02:57:40 - 02:57:45]
very much difficult for you okay um to

[02:57:43 - 02:57:47]
learn any kinds of topic so that should

[02:57:45 - 02:57:50]
be my suggestion please try to explore

[02:57:47 - 02:57:51]
from your end uh after this uh actually

[02:57:50 - 02:57:53]
video what you can do you can search

[02:57:51 - 02:57:54]
open AI you can search different

[02:57:53 - 02:57:57]
different open source website and you

[02:57:54 - 02:57:58]
can see what are the models are came

[02:57:57 - 02:58:00]
actually recently okay that's how

[02:57:58 - 02:58:01]
actually you can learn and you can also

[02:58:00 - 02:58:03]
create a GitHub repository like that and

[02:58:01 - 02:58:05]
you can list down all the models okay

[02:58:03 - 02:58:06]
you will be exploring okay in future

[02:58:05 - 02:58:08]
that is the idea now let's try to see

[02:58:06 - 02:58:10]
some other open source large language

[02:58:08 - 02:58:12]
model see there are two kinds of large

[02:58:10 - 02:58:14]
language models are available one is

[02:58:12 - 02:58:15]
like commercial model commercial model

[02:58:14 - 02:58:17]
means this is the commercial model like

[02:58:15 - 02:58:19]
open AI based model so if you want to

[02:58:17 - 02:58:21]
use these are the model you have to pay

[02:58:19 - 02:58:23]
okay you have to pay uh you have to take

[02:58:21 - 02:58:25]
the subscription okay but but if you're

[02:58:23 - 02:58:26]
not interested in paying what you can do

[02:58:25 - 02:58:28]
you can use open source our language

[02:58:26 - 02:58:30]
model so these are the models are

[02:58:28 - 02:58:31]
available in the hugging phase platform

[02:58:30 - 02:58:34]
so if you're using these are the model

[02:58:31 - 02:58:37]
you don't need to pay okay freely you

[02:58:34 - 02:58:38]
can access but there you will get some

[02:58:37 - 02:58:40]
difficulty because these are the B you

[02:58:38 - 02:58:42]
have to download manually in your system

[02:58:40 - 02:58:43]
you have to set up everything okay let's

[02:58:42 - 02:58:45]
say you want to F tune this mistal what

[02:58:43 - 02:58:46]
you have to do you have to download the

[02:58:45 - 02:58:49]
M model in your system now just try to

[02:58:46 - 02:58:53]
see what is the size of the m model OKAY

[02:58:49 - 02:58:55]
more than 30 to 40 GB okay so you should

[02:58:53 - 02:58:56]
have good uh actually resources in your

[02:58:55 - 02:58:58]
system let's say you should have good

[02:58:56 - 02:59:00]
CPU good GPU good memory otherwise you

[02:58:58 - 02:59:02]
can ever train this particular model but

[02:59:00 - 02:59:04]
if you're using commercial model okay

[02:59:02 - 02:59:05]
let's say you are using openi model okay

[02:59:04 - 02:59:07]
that time what you can do you can use

[02:59:05 - 02:59:09]
their platform like open a platform to

[02:59:07 - 02:59:10]
find you these are the model okay you

[02:59:09 - 02:59:12]
don't need to download these are the

[02:59:10 - 02:59:14]
model in your system so going forward I

[02:59:12 - 02:59:15]
will teach you how you can use

[02:59:14 - 02:59:17]
commercial model as well as the open

[02:59:15 - 02:59:18]
source model both then you can decide

[02:59:17 - 02:59:20]
which one you will be using okay it's up

[02:59:18 - 02:59:22]
to you now these are some open source

[02:59:20 - 02:59:26]
large language model like Mr Lama gini

[02:59:22 - 02:59:29]
Falcon okay cloudy then MPT 30b and St

[02:59:26 - 02:59:30]
STM okay these are the models actually

[02:59:29 - 02:59:32]
we are having as an open source model

[02:59:30 - 02:59:33]
apart from that there are so many model

[02:59:32 - 02:59:35]
I will tell you there is a platform

[02:59:33 - 02:59:37]
called hugging face inside hugging face

[02:59:35 - 02:59:39]
you will see all kinds of large language

[02:59:37 - 02:59:41]
models are available there fine uh what

[02:59:39 - 02:59:43]
can llm be used for I already told you

[02:59:41 - 02:59:45]
you can use large language model for the

[02:59:43 - 02:59:47]
text classification uh for the text

[02:59:45 - 02:59:48]
generation for text summarization

[02:59:47 - 02:59:50]
conversation like chart board question

[02:59:48 - 02:59:52]
answering speech recognization speeech

[02:59:50 - 02:59:54]
identification spelling correction and

[02:59:52 - 02:59:55]
so on that means whatever task you can

[02:59:54 - 02:59:57]
see in the field of natural language

[02:59:55 - 02:59:58]
processing okay all kinds of task you

[02:59:57 - 03:00:00]
can perform with the help of large

[02:59:58 - 03:00:03]
language model only one model I think I

[03:00:00 - 03:00:05]
showed you one example of the Char GPT

[03:00:03 - 03:00:06]
now there is another uh concept uh you

[03:00:05 - 03:00:07]
will be getting inside large language

[03:00:06 - 03:00:10]
model which is nothing but prompt

[03:00:07 - 03:00:11]
engineering and prompt designing now you

[03:00:10 - 03:00:13]
can ask me what is prompt engineering

[03:00:11 - 03:00:16]
and prompt designing so you can see all

[03:00:13 - 03:00:18]
the Tes that we feed uh into an llm as

[03:00:16 - 03:00:20]
an input it is called actually prompt

[03:00:18 - 03:00:22]
and this whole art is known as prompt

[03:00:20 - 03:00:24]
designing or prompt engineering which is

[03:00:22 - 03:00:28]
about figuring out how to write and

[03:00:24 - 03:00:30]
formate prompt takes to get llms to do

[03:00:28 - 03:00:32]
what you want to do okay that means

[03:00:30 - 03:00:33]
whatever input you will be passing

[03:00:32 - 03:00:35]
inside large language model okay this is

[03:00:33 - 03:00:37]
called actually prompt and the way

[03:00:35 - 03:00:38]
actually will be giving the prompt the

[03:00:37 - 03:00:39]
way actually will be preparing the

[03:00:38 - 03:00:42]
prompt this is called prompt designing

[03:00:39 - 03:00:45]
or prompt uh engineering okay now let's

[03:00:42 - 03:00:47]
say here two example I have kept it's

[03:00:45 - 03:00:49]
raining cats and okay let's say this is

[03:00:47 - 03:00:50]
your prom you are giving this particular

[03:00:49 - 03:00:52]
input to the large language model and

[03:00:50 - 03:00:53]
your large language model will try to

[03:00:52 - 03:00:56]
predict dog I think I showed you okay

[03:00:53 - 03:00:58]
that text uh uh word generation okay

[03:00:56 - 03:01:00]
next word generation then I have another

[03:00:58 - 03:01:02]
example I have two apples and I at one I

[03:01:00 - 03:01:05]
left with this is the input now your

[03:01:02 - 03:01:06]
model will try to generate one okay now

[03:01:05 - 03:01:08]
apart from that we are having some types

[03:01:06 - 03:01:10]
of prompt like few short prompt zero

[03:01:08 - 03:01:12]
short prompt okay these are the types

[03:01:10 - 03:01:13]
types of prompt prompts are available

[03:01:12 - 03:01:15]
let me show you so this is called

[03:01:13 - 03:01:17]
actually zero shot learning zero shot

[03:01:15 - 03:01:19]
prompting that means here you are only

[03:01:17 - 03:01:21]
giving the you you can see the approach

[03:01:19 - 03:01:23]
uh using a single command to get an LM

[03:01:21 - 03:01:25]
to take on a behavior is it uh it is

[03:01:23 - 03:01:27]
called actually zero short learning that

[03:01:25 - 03:01:29]
means you are only giving a input only

[03:01:27 - 03:01:31]
giving an input and your large language

[03:01:29 - 03:01:32]
model will give you the output let's say

[03:01:31 - 03:01:35]
this is your prompt write me a poem

[03:01:32 - 03:01:37]
about add a less in the style of

[03:01:35 - 03:01:38]
Shakespeare okay this is the input now

[03:01:37 - 03:01:41]
there is another one explain the quantum

[03:01:38 - 03:01:42]
physics to me like I am 5 years old now

[03:01:41 - 03:01:44]
you are giving this prom to the large

[03:01:42 - 03:01:47]
language model and large language model

[03:01:44 - 03:01:48]
is generating the uh response for you

[03:01:47 - 03:01:50]
the answer for for you okay this is

[03:01:48 - 03:01:52]
called actually zero short learning okay

[03:01:50 - 03:01:54]
zero short learning now there is another

[03:01:52 - 03:01:56]
learning called few short learning in

[03:01:54 - 03:01:58]
few short learning in addition uh to

[03:01:56 - 03:02:01]
just providing an instruction it can be

[03:01:58 - 03:02:03]
helpful to show the model what you want

[03:02:01 - 03:02:04]
to uh what you want by adding the

[03:02:03 - 03:02:06]
example it is called actually F short

[03:02:04 - 03:02:09]
learning so in F short learning what you

[03:02:06 - 03:02:10]
will do you will give some example okay

[03:02:09 - 03:02:11]
The Prompt actually you are giving let's

[03:02:10 - 03:02:13]
say let's say here you are giving a

[03:02:11 - 03:02:15]
prompt convert the text from English to

[03:02:13 - 03:02:18]
France so with this prompt you will pass

[03:02:15 - 03:02:20]
some example like English to FRS example

[03:02:18 - 03:02:22]
let me show you so let's say this is the

[03:02:20 - 03:02:24]
few short from example let's say this is

[03:02:22 - 03:02:27]
the prompt you are giving convert the

[03:02:24 - 03:02:28]
text from English to frames now you are

[03:02:27 - 03:02:29]
giving English as well as the frames

[03:02:28 - 03:02:31]
English as well as the frames okay that

[03:02:29 - 03:02:33]
means you are passing some example okay

[03:02:31 - 03:02:36]
instruction as well as the example and

[03:02:33 - 03:02:37]
your model will try to uh give you the

[03:02:36 - 03:02:39]
response okay after that that means

[03:02:37 - 03:02:41]
you're teaching your model how you're

[03:02:39 - 03:02:43]
expecting the results okay this is how

[03:02:41 - 03:02:44]
actually you can pass the few short

[03:02:43 - 03:02:46]
learning or few short prompting inside

[03:02:44 - 03:02:48]
large language model okay so going

[03:02:46 - 03:02:49]
forward we'll be also learning this this

[03:02:48 - 03:02:51]
thing how we can add our system prompt

[03:02:49 - 03:02:53]
how we can add the user prompt okay how

[03:02:51 - 03:02:55]
we can give few shot actually prompting

[03:02:53 - 03:02:56]
how we can give let zero shot prompting

[03:02:55 - 03:02:58]
we'll be learning whenever we'll be

[03:02:56 - 03:02:59]
using large language model and always

[03:02:58 - 03:03:00]
try to remember if you want to get a

[03:02:59 - 03:03:02]
good response from the large language

[03:03:00 - 03:03:04]
model you have to go with the prompt

[03:03:02 - 03:03:06]
engineering and prompt designing this is

[03:03:04 - 03:03:09]
the main idea here so yes guys this is

[03:03:06 - 03:03:11]
all about our uh large language model

[03:03:09 - 03:03:12]
okay which is uh llms so I hope you got

[03:03:11 - 03:03:14]
the clearcut understanding about large

[03:03:12 - 03:03:15]
language model what exactly large

[03:03:14 - 03:03:18]
language model is and what is the core

[03:03:15 - 03:03:20]
architecture it is using uh in the back

[03:03:18 - 03:03:23]
so in the next video I'll try to um

[03:03:20 - 03:03:25]
explain that uh core architecture the

[03:03:23 - 03:03:26]
Transformer architecture how Transformer

[03:03:25 - 03:03:27]
architecture works and and what are the

[03:03:26 - 03:03:30]
components are available inside

[03:03:27 - 03:03:31]
Transformer architecture so here we'll

[03:03:30 - 03:03:34]
be discussing one amazing research paper

[03:03:31 - 03:03:35]
called attention is all you need so This

[03:03:34 - 03:03:37]
research paper published by Google and

[03:03:35 - 03:03:39]
Google actually brought this particular

[03:03:37 - 03:03:41]
research called Transformer so here is

[03:03:39 - 03:03:43]
the research paper guys attention is all

[03:03:41 - 03:03:44]
you need if you are interested uh read

[03:03:43 - 03:03:46]
this particular paper what you can do

[03:03:44 - 03:03:48]
simply search by this name you will get

[03:03:46 - 03:03:50]
this research paper you can see this is

[03:03:48 - 03:03:52]
from Google brain okay and uh you can

[03:03:50 - 03:03:54]
see this is the architecture Transformer

[03:03:52 - 03:03:55]
architecture but I know that first time

[03:03:54 - 03:03:58]
uh it would be a little bit difficult

[03:03:55 - 03:04:00]
for you uh understanding this uh

[03:03:58 - 03:04:02]
architecture from this particular paper

[03:04:00 - 03:04:04]
so what I will do I'll just try to break

[03:04:02 - 03:04:06]
down this uh actually architecture and I

[03:04:04 - 03:04:09]
will discuss each and everything all the

[03:04:06 - 03:04:10]
components like what is input encoding

[03:04:09 - 03:04:12]
like what is multi-ad attention what is

[03:04:10 - 03:04:14]
ad normalization okay everything I'll

[03:04:12 - 03:04:15]
try to discuss okay then this part would

[03:04:14 - 03:04:17]
be more clear then once we got the

[03:04:15 - 03:04:19]
understanding then if you come to this

[03:04:17 - 03:04:21]
paper this would be very much easy for

[03:04:19 - 03:04:23]
you to understand this architecture okay

[03:04:21 - 03:04:25]
like how they have uh let's say created

[03:04:23 - 03:04:26]
this architecture and if you're

[03:04:25 - 03:04:28]
interested learning the mathematics

[03:04:26 - 03:04:30]
behind it you can go through this paper

[03:04:28 - 03:04:31]
okay if you want to Deep dive into this

[03:04:30 - 03:04:34]
you can go through the paper it will

[03:04:31 - 03:04:36]
give you the comprehensive idea now to

[03:04:34 - 03:04:38]
explain this uh actually Transformer

[03:04:36 - 03:04:40]
let's say concept I'm going to refer one

[03:04:38 - 03:04:44]
amazing blog by J alar okay so this is

[03:04:40 - 03:04:46]
one of the uh amazing guy uh and he has

[03:04:44 - 03:04:49]
created so many content related actually

[03:04:46 - 03:04:50]
NLP so this is one of of the best uh

[03:04:49 - 03:04:52]
resources you will find over the

[03:04:50 - 03:04:54]
internet if you want to understand the

[03:04:52 - 03:04:55]
Transformer architecture so this guy

[03:04:54 - 03:04:57]
actually used so many visualization so

[03:04:55 - 03:05:00]
many image to explain this architecture

[03:04:57 - 03:05:01]
okay so we'll be referring this blog to

[03:05:00 - 03:05:03]
understand the entire architecture I

[03:05:01 - 03:05:05]
could have written everything on my

[03:05:03 - 03:05:07]
Blackboard but I thought if I show you

[03:05:05 - 03:05:09]
the visualization it would be more uh

[03:05:07 - 03:05:11]
let's say good than the writing on my

[03:05:09 - 03:05:12]
Blackboard right so if you want to

[03:05:11 - 03:05:14]
understand this Transformer architecture

[03:05:12 - 03:05:15]
so what I feel like this is this is

[03:05:14 - 03:05:17]
going to be one best resources for you

[03:05:15 - 03:05:19]
because it is having so many

[03:05:17 - 03:05:21]
visualization okay we can easily

[03:05:19 - 03:05:23]
understand what is happening inside

[03:05:21 - 03:05:24]
Transformer architecture so now guys

[03:05:23 - 03:05:26]
let's try to understand this

[03:05:24 - 03:05:28]
architecture now let's say this is your

[03:05:26 - 03:05:30]
Transformer architecture as of now just

[03:05:28 - 03:05:32]
try to consider this is a black box okay

[03:05:30 - 03:05:34]
it's a transform architecture and you

[03:05:32 - 03:05:36]
don't know uh what are the component it

[03:05:34 - 03:05:38]
is having so here you are giving one

[03:05:36 - 03:05:40]
input data okay and here you are getting

[03:05:38 - 03:05:41]
one output data that means you are

[03:05:40 - 03:05:43]
performing language translation

[03:05:41 - 03:05:45]
operation so here you are passing this

[03:05:43 - 03:05:47]
FR input and you are getting English

[03:05:45 - 03:05:49]
output okay this is the idea now let's

[03:05:47 - 03:05:51]
let's try to see what inside this

[03:05:49 - 03:05:53]
particular Transformer okay Transformer

[03:05:51 - 03:05:55]
block now see inside Transformer block

[03:05:53 - 03:05:58]
you are having two kinds of layer one is

[03:05:55 - 03:06:00]
the encoder layer and and another is the

[03:05:58 - 03:06:03]
decoder layer as I already told you uh

[03:06:00 - 03:06:05]
Transformer architecture is having two

[03:06:03 - 03:06:07]
kinds of layer one is encoded layer

[03:06:05 - 03:06:09]
another one is decoder layer now you are

[03:06:07 - 03:06:11]
passing the input okay you are passing

[03:06:09 - 03:06:13]
the input to the encoder layer see this

[03:06:11 - 03:06:15]
PR uh input you are passing to the

[03:06:13 - 03:06:17]
encoder layer and the output you are

[03:06:15 - 03:06:18]
getting that English translation you are

[03:06:17 - 03:06:22]
you'll be getting from the decoder layer

[03:06:18 - 03:06:25]
okay this is the main idea now let's try

[03:06:22 - 03:06:26]
to break this encoder and let's see what

[03:06:25 - 03:06:29]
are the component we are having inside

[03:06:26 - 03:06:32]
encoder layer now see if I show you this

[03:06:29 - 03:06:33]
entire architecture okay in a low level

[03:06:32 - 03:06:35]
now you can see inside encoder we are

[03:06:33 - 03:06:37]
having some more encoded layer okay we

[03:06:35 - 03:06:40]
are having some more encoded layer how

[03:06:37 - 03:06:42]
many encoded layer you can see 1 2 3 4 5

[03:06:40 - 03:06:45]
six that means six encoder layer we are

[03:06:42 - 03:06:47]
having and how many decoder layer we

[03:06:45 - 03:06:49]
having again we are having six decoder

[03:06:47 - 03:06:51]
layer that means the architecture you

[03:06:49 - 03:06:53]
can see here okay the box you can see

[03:06:51 - 03:06:56]
here encoder box and decoder box inside

[03:06:53 - 03:06:59]
that you are using six okay six stack of

[03:06:56 - 03:07:02]
encoder and six stack of decoder layer

[03:06:59 - 03:07:04]
okay and inside that your input is going

[03:07:02 - 03:07:06]
and it is processing this input and you

[03:07:04 - 03:07:08]
are getting the output okay this is the

[03:07:06 - 03:07:11]
so that's how this architecture consist

[03:07:08 - 03:07:13]
of okay I hope it is clear now let's try

[03:07:11 - 03:07:15]
to see what we are having inside the

[03:07:13 - 03:07:17]
encoder layer okay now if I show you the

[03:07:15 - 03:07:19]
encoder layer see inside encoder layer

[03:07:17 - 03:07:22]
we are having two kinds of layer one is

[03:07:19 - 03:07:24]
like self attention other is like fit

[03:07:22 - 03:07:25]
foral neural network and what is fit for

[03:07:24 - 03:07:27]
neural network I think you know that

[03:07:25 - 03:07:29]
means the artificial neural network okay

[03:07:27 - 03:07:31]
if you're already familiar with an and

[03:07:29 - 03:07:33]
you know what is f foral neural network

[03:07:31 - 03:07:35]
okay it's a artificial neural network at

[03:07:33 - 03:07:37]
the end now let's try to understand the

[03:07:35 - 03:07:38]
self attention because I know that many

[03:07:37 - 03:07:41]
people will have the confusion what is

[03:07:38 - 03:07:42]
self attention here okay now let's see

[03:07:41 - 03:07:44]
uh now you can see this is the encoder

[03:07:42 - 03:07:46]
inside encoder we are having self

[03:07:44 - 03:07:48]
attention as well as the feed forward

[03:07:46 - 03:07:50]
and inside decoder also we are having

[03:07:48 - 03:07:51]
self attention and another actually

[03:07:50 - 03:07:54]
additional layer we having which is

[03:07:51 - 03:07:55]
called encoder and decoder attention and

[03:07:54 - 03:07:57]
the last layer you are having which is

[03:07:55 - 03:07:58]
nothing but feed forward Nal Network so

[03:07:57 - 03:08:00]
this part we'll be discussing later on

[03:07:58 - 03:08:02]
as of now let's try to uh discuss this

[03:08:00 - 03:08:05]
encoded layer and this self attention

[03:08:02 - 03:08:07]
part okay now let's say you are passing

[03:08:05 - 03:08:09]
the friends input you can see this is

[03:08:07 - 03:08:11]
your friend input I don't know how to

[03:08:09 - 03:08:12]
spell them but just try to consider this

[03:08:11 - 03:08:14]
is your friend input so the first thing

[03:08:12 - 03:08:16]
what you have to do the first thing you

[03:08:14 - 03:08:18]
have to perform the text pre-processing

[03:08:16 - 03:08:19]
then text representation yes or no so

[03:08:18 - 03:08:21]
here first of all you have to convert

[03:08:19 - 03:08:24]
your textual data to the vector

[03:08:21 - 03:08:25]
representation okay so based on the

[03:08:24 - 03:08:28]
paper they're using something called

[03:08:25 - 03:08:30]
what to V technique to perform the text

[03:08:28 - 03:08:32]
representation technique that means

[03:08:30 - 03:08:34]
they're converting their text to vectors

[03:08:32 - 03:08:35]
with the help of what to V technique and

[03:08:34 - 03:08:38]
what is the dimension okay what is the

[03:08:35 - 03:08:41]
dimension of the vector they're getting

[03:08:38 - 03:08:44]
512 Dimension okay 512 dimension for the

[03:08:41 - 03:08:45]
each of the vector okay this is the idea

[03:08:44 - 03:08:47]
now let's say they have converted to the

[03:08:45 - 03:08:49]
vector representation now what they are

[03:08:47 - 03:08:50]
doing they're passing this particular

[03:08:49 - 03:08:52]
input to the self attention layer you

[03:08:50 - 03:08:53]
can see they're passing the input to the

[03:08:52 - 03:08:56]
self attention layer self attention

[03:08:53 - 03:08:59]
layer is uh giving one output which is

[03:08:56 - 03:09:00]
nothing but Z1 Z2 and Z3 and this Z1 Z2

[03:08:59 - 03:09:03]
and Z3 will pass to the FED for all

[03:09:00 - 03:09:05]
neural network okay now let's try to

[03:09:03 - 03:09:08]
understand how it is encoding okay how

[03:09:05 - 03:09:10]
it is encoding this particular input now

[03:09:08 - 03:09:12]
see to simplify this particular

[03:09:10 - 03:09:14]
understanding what J is doing he's using

[03:09:12 - 03:09:17]
two words actually which is nothing but

[03:09:14 - 03:09:18]
thinking and machines okay let's say you

[03:09:17 - 03:09:19]
having two words thinking and machine

[03:09:18 - 03:09:21]
first of all what you have to do you

[03:09:19 - 03:09:22]
have to convert this text to Vector

[03:09:21 - 03:09:24]
representation with the help of word to

[03:09:22 - 03:09:27]
V and what dimensional Vector you will

[03:09:24 - 03:09:30]
be getting 52 I think I showed you here

[03:09:27 - 03:09:31]
512 dimensional Vector it will return

[03:09:30 - 03:09:33]
and this Vector will be passing to the

[03:09:31 - 03:09:35]
self attention layer self attention

[03:09:33 - 03:09:37]
layer will give you Z1 and Z2 then we'll

[03:09:35 - 03:09:39]
be passing to the feed foral neural

[03:09:37 - 03:09:41]
network again feed foral neural network

[03:09:39 - 03:09:43]
will give you some of the output and

[03:09:41 - 03:09:45]
that output again you will pass to the

[03:09:43 - 03:09:46]
encoded two layer that means I showed

[03:09:45 - 03:09:49]
you now we are having stack of the

[03:09:46 - 03:09:51]
encoded layer here see stack that means

[03:09:49 - 03:09:52]
after uh getting one output from one

[03:09:51 - 03:09:54]
encoder layer it will come it will go to

[03:09:52 - 03:09:56]
the another encoder layer then again it

[03:09:54 - 03:09:58]
will pass to the another then another

[03:09:56 - 03:10:00]
then another that's how you have to

[03:09:58 - 03:10:02]
that's how actually it will pass through

[03:10:00 - 03:10:03]
six encoded layer okay so that is what

[03:10:02 - 03:10:05]
actually he's explaining here you can

[03:10:03 - 03:10:07]
see so here you can see after one

[03:10:05 - 03:10:09]
encoding it is passing to the second

[03:10:07 - 03:10:11]
encoding layer okay this is the idea now

[03:10:09 - 03:10:13]
let's try to understand what we are

[03:10:11 - 03:10:15]
having inside self attention now see

[03:10:13 - 03:10:17]
self attention at high level let's say

[03:10:15 - 03:10:18]
here we are having a sentence the animal

[03:10:17 - 03:10:21]
didn't didn't cross the street because

[03:10:18 - 03:10:23]
it was true tried now here just try to

[03:10:21 - 03:10:25]
understand the animal didn't cross the

[03:10:23 - 03:10:29]
street because it was true tied okay it

[03:10:25 - 03:10:31]
was true tied now who was true tied here

[03:10:29 - 03:10:33]
okay definitely the animal was true tied

[03:10:31 - 03:10:35]
yes or no so as a human actually we can

[03:10:33 - 03:10:37]
understand it means this is the animal

[03:10:35 - 03:10:39]
it is indicating the animal but what

[03:10:37 - 03:10:41]
about the machine how machine will

[03:10:39 - 03:10:43]
identify whether this animal is the it

[03:10:41 - 03:10:45]
or not okay so for this it used

[03:10:43 - 03:10:46]
something called self attention Okay

[03:10:45 - 03:10:49]
self attention mechanism now let's try

[03:10:46 - 03:10:50]
to understand how it will uh use that

[03:10:49 - 03:10:52]
particular concept but before

[03:10:50 - 03:10:54]
understanding self attention just try to

[03:10:52 - 03:10:56]
see how it will give the self attention

[03:10:54 - 03:10:58]
to the word let's say here you are

[03:10:56 - 03:10:59]
having the input so this is the input

[03:10:58 - 03:11:02]
the animal didn't cross the street

[03:10:59 - 03:11:04]
because it was true Tri okay now

[03:11:02 - 03:11:06]
whenever I'm referring this it now here

[03:11:04 - 03:11:09]
what it represents definitely it

[03:11:06 - 03:11:11]
represents the animal okay you can see

[03:11:09 - 03:11:13]
this darker color that means it is more

[03:11:11 - 03:11:15]
focusing on the the animal part okay the

[03:11:13 - 03:11:17]
animal part because the animal is

[03:11:15 - 03:11:19]
nothing but it okay that means your

[03:11:17 - 03:11:21]
machine will try to understand okay if I

[03:11:19 - 03:11:24]
want to consider it I have to give the

[03:11:21 - 03:11:26]
vage to the the animal didn't okay these

[03:11:24 - 03:11:28]
are the actually word okay even two also

[03:11:26 - 03:11:30]
okay two Triad also these are the word

[03:11:28 - 03:11:32]
it has to give the attention okay unless

[03:11:30 - 03:11:34]
and until it is not giving the attention

[03:11:32 - 03:11:35]
to this word how it will identify

[03:11:34 - 03:11:39]
whether this eight is represents the

[03:11:35 - 03:11:41]
animal or not okay now you can ask me

[03:11:39 - 03:11:43]
how it is identifying whether it has to

[03:11:41 - 03:11:45]
give the more weightage to this words or

[03:11:43 - 03:11:46]
not okay so for this we'll be

[03:11:45 - 03:11:48]
understanding the self attention in

[03:11:46 - 03:11:51]
detail so here you can see he has given

[03:11:48 - 03:11:52]
one example let's say this is your input

[03:11:51 - 03:11:54]
input means your two words thinking and

[03:11:52 - 03:11:55]
machine so the first thing what you have

[03:11:54 - 03:11:56]
to do you have to convert them to the

[03:11:55 - 03:11:58]
embedding representation that means the

[03:11:56 - 03:12:00]
vector representation then what will

[03:11:58 - 03:12:02]
happen your Transformer will generate

[03:12:00 - 03:12:04]
actually three weights okay you can see

[03:12:02 - 03:12:09]
you can see it will generate three words

[03:12:04 - 03:12:11]
W okay WQ w k and WV and how weight

[03:12:09 - 03:12:12]
initialization happens I think you know

[03:12:11 - 03:12:14]
okay there are different different

[03:12:12 - 03:12:16]
techniques for the weight initialization

[03:12:14 - 03:12:18]
and these weights would be updated

[03:12:16 - 03:12:19]
during back prop propagation okay BP I

[03:12:18 - 03:12:22]
think you already know about artificial

[03:12:19 - 03:12:24]
neural network okay how it got trained

[03:12:22 - 03:12:25]
usually right how it do the back

[03:12:24 - 03:12:27]
propagation and all this like very basic

[03:12:25 - 03:12:28]
concept I'm expecting you are familiar

[03:12:27 - 03:12:30]
with already right so these are the

[03:12:28 - 03:12:33]
weight would be initialized at the very

[03:12:30 - 03:12:35]
first and this weight should be updated

[03:12:33 - 03:12:37]
during back propagation technique okay

[03:12:35 - 03:12:40]
now you can see it is generating some

[03:12:37 - 03:12:42]
more actually Vector the first Vector it

[03:12:40 - 03:12:43]
is generating queries keys and values

[03:12:42 - 03:12:45]
okay now you can ask me how it is

[03:12:43 - 03:12:47]
generating these are the values see see

[03:12:45 - 03:12:49]
first of all what it will do it will

[03:12:47 - 03:12:50]
take this particular X1 okay it will

[03:12:49 - 03:12:53]
take this particular X1 and it will

[03:12:50 - 03:12:55]
multiply with the WQ okay it will

[03:12:53 - 03:12:59]
multiply with the WQ so it will return

[03:12:55 - 03:13:02]
you q1 okay then it will take the X2 it

[03:12:59 - 03:13:04]
will multiply with the WQ it will return

[03:13:02 - 03:13:05]
Q2 okay so that's why actually you will

[03:13:04 - 03:13:08]
be getting something called query Vector

[03:13:05 - 03:13:11]
okay query Vector then again it will

[03:13:08 - 03:13:15]
multiply X1 with w k okay and it will

[03:13:11 - 03:13:17]
return you K1 then it you will multiply

[03:13:15 - 03:13:19]
uh X2 with WK it will return return new

[03:13:17 - 03:13:22]
K2 so here you will be getting Keys

[03:13:19 - 03:13:26]
Vector okay then you will be multiplying

[03:13:22 - 03:13:29]
this X1 with WV and it will return you

[03:13:26 - 03:13:32]
V1 then X2 with w v it will return you

[03:13:29 - 03:13:34]
V2 okay so that's how you'll be getting

[03:13:32 - 03:13:36]
values Vector okay so that's how this

[03:13:34 - 03:13:38]
three Vector would be generated queries

[03:13:36 - 03:13:41]
keys and values okay I hope it is clear

[03:13:38 - 03:13:44]
now okay now let me clear all the uh

[03:13:41 - 03:13:48]
line here yeah now let's see the next

[03:13:44 - 03:13:49]
actually uh mechanism see I think you

[03:13:48 - 03:13:52]
got it uh that means we are having our

[03:13:49 - 03:13:54]
input uh data uh that means input word

[03:13:52 - 03:13:56]
thinking and machine and first of all we

[03:13:54 - 03:13:58]
have to generate the EMB Bings then

[03:13:56 - 03:14:00]
after that with the help of X1 and X2

[03:13:58 - 03:14:02]
that means this Vector we are generating

[03:14:00 - 03:14:04]
queries keys and values okay and how I

[03:14:02 - 03:14:06]
think you got it the multiplication

[03:14:04 - 03:14:08]
actually strategy now the thing is like

[03:14:06 - 03:14:11]
it will generate one score okay how it

[03:14:08 - 03:14:13]
will generate the score see to generate

[03:14:11 - 03:14:16]
this code it will use this q1 okay q1

[03:14:13 - 03:14:18]
vector and it will multiply with the K1

[03:14:16 - 03:14:20]
okay that means q1 will multiply with

[03:14:18 - 03:14:22]
the K1 okay this Vector that means Keys

[03:14:20 - 03:14:24]
Vector where will multiply with the keys

[03:14:22 - 03:14:25]
okay and you will get one score let's

[03:14:24 - 03:14:29]
say as of now this is the Assumption

[03:14:25 - 03:14:30]
score he has given here 112 F then for

[03:14:29 - 03:14:35]
the next word you can see it will uh

[03:14:30 - 03:14:38]
multiply q1 uh with K2 okay q1 with K2

[03:14:35 - 03:14:40]
and here the score let's say 96 okay now

[03:14:38 - 03:14:42]
from this score you can see it is giving

[03:14:40 - 03:14:44]
more score to the thinking word okay to

[03:14:42 - 03:14:46]
the thinking word than the machine word

[03:14:44 - 03:14:48]
okay that means it will more refer this

[03:14:46 - 03:14:50]
thinking word it will more give the

[03:14:48 - 03:14:51]
attention to the thinking word okay and

[03:14:50 - 03:14:53]
that's how actually it is calculating

[03:14:51 - 03:14:55]
this particular score I think you saw

[03:14:53 - 03:14:57]
this graph now so how it is giving the

[03:14:55 - 03:14:58]
attention to the word okay that's how

[03:14:57 - 03:14:59]
actually it is calculating okay with the

[03:14:58 - 03:15:02]
help of this particular Vector

[03:14:59 - 03:15:04]
calculation it is creating this score

[03:15:02 - 03:15:06]
and based on the score value it is

[03:15:04 - 03:15:07]
giving the uh attention to that specific

[03:15:06 - 03:15:09]
word let's say we are having two words

[03:15:07 - 03:15:11]
thinking and machine so it will give the

[03:15:09 - 03:15:13]
more attention to the thinking word now

[03:15:11 - 03:15:16]
see after getting this Cod what it will

[03:15:13 - 03:15:18]
perform it will perform this uh s Max

[03:15:16 - 03:15:20]
operation now see what what will happen

[03:15:18 - 03:15:23]
you are getting this score now this

[03:15:20 - 03:15:25]
score will be uh divided by uh8 okay

[03:15:23 - 03:15:27]
that means you will divide this score by

[03:15:25 - 03:15:29]
8 now if you divide this number you will

[03:15:27 - 03:15:31]
get 14 and if you divide this number

[03:15:29 - 03:15:33]
okay you will get 12 now you'll just

[03:15:31 - 03:15:34]
calculate the soft Max okay I think you

[03:15:33 - 03:15:36]
know the soft Max okay soft Max is an

[03:15:34 - 03:15:38]
activation function it's an equation the

[03:15:36 - 03:15:39]
probability score and if you just add

[03:15:38 - 03:15:42]
this probability score you will see that

[03:15:39 - 03:15:45]
it would be 100% probability okay always

[03:15:42 - 03:15:47]
so here you are getting actually 88% and

[03:15:45 - 03:15:48]
here you are getting only 12% that means

[03:15:47 - 03:15:51]
it is giving more attention to the

[03:15:48 - 03:15:53]
thinking word that means 88% attention

[03:15:51 - 03:15:55]
it is giving to the thinking word and

[03:15:53 - 03:15:57]
only 12% attention it is giving to the

[03:15:55 - 03:15:59]
machine word now I think it is clear how

[03:15:57 - 03:16:01]
it is giving the attention to a specific

[03:15:59 - 03:16:03]
word now in the sixth step what will

[03:16:01 - 03:16:05]
happen see uh I think you saw we are

[03:16:03 - 03:16:06]
getting the sof Max output now with the

[03:16:05 - 03:16:08]
sof Max output what it will do it will

[03:16:06 - 03:16:09]
try to multiply this value that means

[03:16:08 - 03:16:11]
the value I think you are getting

[03:16:09 - 03:16:13]
remember this particular value so it

[03:16:11 - 03:16:14]
would be multiplied and after

[03:16:13 - 03:16:17]
multiplying you will get one vector

[03:16:14 - 03:16:19]
called V1 and again it will perform for

[03:16:17 - 03:16:22]
the next word as well so here you will

[03:16:19 - 03:16:24]
get V2 now let's see you having multiple

[03:16:22 - 03:16:26]
word so for all the words actually it

[03:16:24 - 03:16:28]
will do the multiplication with the

[03:16:26 - 03:16:31]
value so here he only used two words but

[03:16:28 - 03:16:33]
you can consider more than two word as

[03:16:31 - 03:16:35]
well okay the working mechanism will

[03:16:33 - 03:16:36]
remain same then after getting this V1

[03:16:35 - 03:16:38]
and V2 what it will apply it will apply

[03:16:36 - 03:16:40]
the sumission operation that means it

[03:16:38 - 03:16:44]
will sum up this two vector and it will

[03:16:40 - 03:16:46]
get Zed one and Z2 okay and now I think

[03:16:44 - 03:16:47]
you remember what is this zed1 and zed2

[03:16:46 - 03:16:51]
so let me show you

[03:16:47 - 03:16:53]
that high level architecture um here see

[03:16:51 - 03:16:55]
this is the Z1 and Z2 that means this Z1

[03:16:53 - 03:16:57]
and Z2 is the output from the self

[03:16:55 - 03:17:00]
attention Okay self attention layer and

[03:16:57 - 03:17:01]
how self attention is working as of now

[03:17:00 - 03:17:03]
whatever discussion I have given you

[03:17:01 - 03:17:05]
whatever let's say operation I showed

[03:17:03 - 03:17:06]
you this is the work of self attention

[03:17:05 - 03:17:07]
and that's why actually it will perform

[03:17:06 - 03:17:10]
all the mathematical operation and it

[03:17:07 - 03:17:13]
will return Z1 and Z2 and this Z1 and Z2

[03:17:10 - 03:17:15]
will pass to the next okay next layer

[03:17:13 - 03:17:17]
okay next layer next layer means I think

[03:17:15 - 03:17:19]
uh this layer

[03:17:17 - 03:17:21]
yeah to the fit foral neural network

[03:17:19 - 03:17:23]
okay this is the idea now whatever I

[03:17:21 - 03:17:25]
have discussed so far if you want to see

[03:17:23 - 03:17:27]
as a matrix representation see the same

[03:17:25 - 03:17:29]
thing that means you are getting your

[03:17:27 - 03:17:31]
input okay you are getting your input

[03:17:29 - 03:17:32]
that means here we are giving our input

[03:17:31 - 03:17:34]
it will first of all convert it to the

[03:17:32 - 03:17:36]
vector representation then it is

[03:17:34 - 03:17:38]
generating some weights okay WQ WK and

[03:17:36 - 03:17:41]
WV I think remember then we are getting

[03:17:38 - 03:17:43]
query keys and values okay then it was

[03:17:41 - 03:17:45]
multiplying this query with keys okay

[03:17:43 - 03:17:47]
and we are uh dividing with eight okay

[03:17:45 - 03:17:48]
and we are calculating the Sol soft Max

[03:17:47 - 03:17:50]
okay and soft Max and after that

[03:17:48 - 03:17:52]
whatever softmax output we are getting

[03:17:50 - 03:17:54]
we're performing the addition operation

[03:17:52 - 03:17:58]
with the values okay and it will give me

[03:17:54 - 03:17:59]
Z okay Z that means the output now so

[03:17:58 - 03:18:01]
far whatever actually operation you saw

[03:17:59 - 03:18:02]
this is for actually single head

[03:18:01 - 03:18:06]
attention Okay single head attention

[03:18:02 - 03:18:08]
that means only one self attention Okay

[03:18:06 - 03:18:10]
only one self attention mechanism now

[03:18:08 - 03:18:11]
inside Transformer architecture they're

[03:18:10 - 03:18:13]
using something called multi-head

[03:18:11 - 03:18:15]
attention you can see so here is the TR

[03:18:13 - 03:18:17]
called multi-head attention so what is

[03:18:15 - 03:18:20]
multi-head attention see

[03:18:17 - 03:18:22]
uh if I show you this uh graph again see

[03:18:20 - 03:18:24]
if I'm considering it that means it is

[03:18:22 - 03:18:26]
giving attention to the the animal did

[03:18:24 - 03:18:28]
okay these are the word even you can see

[03:18:26 - 03:18:30]
it is also giving some attention to this

[03:18:28 - 03:18:33]
word as well but see this thickness is

[03:18:30 - 03:18:35]
like very uh I mean less here because it

[03:18:33 - 03:18:37]
is not able to give the proper attention

[03:18:35 - 03:18:39]
to this word okay because it is using

[03:18:37 - 03:18:41]
only single head attention okay and and

[03:18:39 - 03:18:42]
it is only using this three weight okay

[03:18:41 - 03:18:44]
this three weight is not enough let's

[03:18:42 - 03:18:46]
say you are having huge amount of data

[03:18:44 - 03:18:48]
your input length is very big that time

[03:18:46 - 03:18:50]
I only this three Vector is not only

[03:18:48 - 03:18:52]
this three weight is not actually enough

[03:18:50 - 03:18:53]
so for this actually what we have to do

[03:18:52 - 03:18:55]
we have to apply something something

[03:18:53 - 03:18:57]
called multi multiple actually weights

[03:18:55 - 03:18:59]
okay and if I want to apply multiple

[03:18:57 - 03:19:01]
weights so what we have to do we have to

[03:18:59 - 03:19:03]
use something called multi-head

[03:19:01 - 03:19:05]
attention so uh Google Inu actually

[03:19:03 - 03:19:07]
multi-ad attention so they're telling

[03:19:05 - 03:19:09]
instead of only using one head okay one

[03:19:07 - 03:19:10]
head attention so they're telling

[03:19:09 - 03:19:12]
instead of using only single head

[03:19:10 - 03:19:13]
attention we'll be using multi-head

[03:19:12 - 03:19:15]
attention to perform the same operation

[03:19:13 - 03:19:17]
that means what will happen see this is

[03:19:15 - 03:19:19]
the attention head one that mean single

[03:19:17 - 03:19:20]
attention and you'll be taking another

[03:19:19 - 03:19:22]
attention head okay so this called

[03:19:20 - 03:19:24]
attention head one that's how you'll be

[03:19:22 - 03:19:25]
taking another attention and how many

[03:19:24 - 03:19:27]
attention head it will be taking I'll

[03:19:25 - 03:19:28]
I'll tell you as of now let's try to

[03:19:27 - 03:19:31]
consider we are having multi-ad that

[03:19:28 - 03:19:33]
means only two head okay zero and one

[03:19:31 - 03:19:35]
now the same thing they are doing that

[03:19:33 - 03:19:36]
means they're generating this weights

[03:19:35 - 03:19:38]
okay also this side also they are

[03:19:36 - 03:19:40]
generating the weights and the same

[03:19:38 - 03:19:41]
operation would be happening as here as

[03:19:40 - 03:19:43]
well that means the operation I showed

[03:19:41 - 03:19:44]
you now previously the same operation

[03:19:43 - 03:19:46]
will be happening here as well now you

[03:19:44 - 03:19:48]
can ask me what is the main objective to

[03:19:46 - 03:19:50]
perform this multi-ad attention because

[03:19:48 - 03:19:52]
if you see in the Transformer

[03:19:50 - 03:19:53]
architecture we can give very big size

[03:19:52 - 03:19:55]
input let's say my input prompt would be

[03:19:53 - 03:19:57]
very big I think you saw in the chat GPT

[03:19:55 - 03:20:00]
we can pass a very bigger prompt okay

[03:19:57 - 03:20:02]
very bigger prompt to the uh this one

[03:20:00 - 03:20:05]
our uh chat GPT input right that means

[03:20:02 - 03:20:06]
to my GPT model so how it is processing

[03:20:05 - 03:20:08]
that that particular bigger input

[03:20:06 - 03:20:10]
because it is using this multi-head

[03:20:08 - 03:20:12]
attention concept that means with the

[03:20:10 - 03:20:14]
help of multi-ad attention concept it it

[03:20:12 - 03:20:16]
is able to give the attention to all the

[03:20:14 - 03:20:17]
specific word actually present in that

[03:20:16 - 03:20:19]
particular Pro okay so this is the main

[03:20:17 - 03:20:21]
idea that means if you're only using

[03:20:19 - 03:20:23]
single head it won't be able to handle

[03:20:21 - 03:20:24]
that particular bigger promt that's why

[03:20:23 - 03:20:26]
you have to use multi-head attention

[03:20:24 - 03:20:27]
here okay this is the main concept now

[03:20:26 - 03:20:29]
see that's how actually things are

[03:20:27 - 03:20:32]
working let's say you are passing two

[03:20:29 - 03:20:34]
words thinking and machine so you you

[03:20:32 - 03:20:35]
are passing as a vector representation

[03:20:34 - 03:20:37]
so this Vector will go to the different

[03:20:35 - 03:20:38]
different attention and now here you can

[03:20:37 - 03:20:40]
see they're using eight different

[03:20:38 - 03:20:41]
attention heads eight different

[03:20:40 - 03:20:43]
attention heads that means whatever

[03:20:41 - 03:20:46]
things we have learned so far we have

[03:20:43 - 03:20:48]
learned for only one one uh self head

[03:20:46 - 03:20:50]
attention right B self attention Okay

[03:20:48 - 03:20:52]
but they're using something called eight

[03:20:50 - 03:20:54]
different self attention eight different

[03:20:52 - 03:20:57]
self attention here you can see okay

[03:20:54 - 03:20:59]
attention head 0 1 dot dot dot 7 because

[03:20:57 - 03:21:01]
it is starting from zero that's why it

[03:20:59 - 03:21:02]
is ending till 10 now if you count it

[03:21:01 - 03:21:04]
they're using something called eight

[03:21:02 - 03:21:07]
different attention head here okay so

[03:21:04 - 03:21:08]
inside eight different uh attention all

[03:21:07 - 03:21:12]
the calculation is happening after that

[03:21:08 - 03:21:13]
whatever z z 0 Z1 Z3 they are getting

[03:21:12 - 03:21:16]
they're doing the sumission operation

[03:21:13 - 03:21:17]
okay and this is your final Vector okay

[03:21:16 - 03:21:22]
this is your final Vector that means the

[03:21:17 - 03:21:24]
Z that means this one let me show

[03:21:22 - 03:21:26]
you this one okay now inside that

[03:21:24 - 03:21:28]
they're using eight different s

[03:21:26 - 03:21:30]
attention and this is the Z One output

[03:21:28 - 03:21:33]
you are getting okay I hope you got it

[03:21:30 - 03:21:35]
now see how beautifully uh Jammer

[03:21:33 - 03:21:38]
created this blog how beautifully he has

[03:21:35 - 03:21:39]
used all the visualization okay so to

[03:21:38 - 03:21:41]
explain this particular concept so

[03:21:39 - 03:21:43]
that's why I feel like this is the best

[03:21:41 - 03:21:45]
resources for the Transformer okay if

[03:21:43 - 03:21:47]
you want to understand you can use this

[03:21:45 - 03:21:48]
particular blog

[03:21:47 - 03:21:51]
now I think we have understood uh till

[03:21:48 - 03:21:53]
here that means we are getting the Z now

[03:21:51 - 03:21:55]
see if you see the entire architecture

[03:21:53 - 03:21:57]
that's how it is working so you are

[03:21:55 - 03:21:59]
having the input you are uh it is

[03:21:57 - 03:22:01]
initializing the weights okay so it is

[03:21:59 - 03:22:03]
generating the weights for eight

[03:22:01 - 03:22:05]
different actually self attention Okay

[03:22:03 - 03:22:07]
then uh you can see the query Keys

[03:22:05 - 03:22:09]
values then the Z okay that means the

[03:22:07 - 03:22:11]
output from my self head attention then

[03:22:09 - 03:22:12]
it is concatenating all the vector and

[03:22:11 - 03:22:15]
we are getting only one vector which is

[03:22:12 - 03:22:17]
nothing but Z now see after using multi

[03:22:15 - 03:22:18]
detention that is this is how your

[03:22:17 - 03:22:21]
output looks like now see it is able to

[03:22:18 - 03:22:23]
give the attention to all of the word

[03:22:21 - 03:22:25]
actually it needs okay to represent this

[03:22:23 - 03:22:28]
particular it right now now see this uh

[03:22:25 - 03:22:29]
line is more darker right now okay this

[03:22:28 - 03:22:32]
line is more darker that means it is

[03:22:29 - 03:22:33]
performing better than previous that

[03:22:32 - 03:22:35]
means previous we are using only one

[03:22:33 - 03:22:37]
head attention now we are using multi-ad

[03:22:35 - 03:22:38]
attention and the performance is very

[03:22:37 - 03:22:41]
good right now okay this is the main

[03:22:38 - 03:22:42]
idea now see uh he has captured some of

[03:22:41 - 03:22:45]
the images okay experimental images you

[03:22:42 - 03:22:47]
can see here now let's try to understand

[03:22:45 - 03:22:49]
uh another important thing

[03:22:47 - 03:22:51]
uh I told you now so let's say whenever

[03:22:49 - 03:22:53]
we are using any let's say traditional

[03:22:51 - 03:22:56]
embedding model let's say TF IDF what to

[03:22:53 - 03:22:58]
V or let's say any other embedding model

[03:22:56 - 03:23:01]
let's say this one bag of word so it

[03:22:58 - 03:23:02]
won't be able to capture the semantic

[03:23:01 - 03:23:04]
meaning okay semantic meaning of a

[03:23:02 - 03:23:06]
sentence let's say here we are having a

[03:23:04 - 03:23:09]
sentence this is the let's say France

[03:23:06 - 03:23:11]
sentence z swiss uh uh a to dend I don't

[03:23:09 - 03:23:14]
know how to spell but let's say this is

[03:23:11 - 03:23:16]
my sentence now after Z this particular

[03:23:14 - 03:23:18]
word is coming after this word this word

[03:23:16 - 03:23:21]
is is coming okay how it will remember

[03:23:18 - 03:23:22]
that means how it will understand the

[03:23:21 - 03:23:24]
contextual meaning that means the

[03:23:22 - 03:23:26]
sequence meaning okay sequence meaning

[03:23:24 - 03:23:28]
of a sentence so to understand that

[03:23:26 - 03:23:29]
sequence uh actually meaning they're

[03:23:28 - 03:23:32]
using something called positional

[03:23:29 - 03:23:33]
encoding okay positional encoding now

[03:23:32 - 03:23:35]
let's try to understand what is

[03:23:33 - 03:23:37]
positional encoding see let's say this

[03:23:35 - 03:23:38]
is my input it is converting to the

[03:23:37 - 03:23:40]
vector now you can see this particular

[03:23:38 - 03:23:42]
Vector there adding with the positional

[03:23:40 - 03:23:43]
encoding positional encoding is nothing

[03:23:42 - 03:23:46]
but it's a vector only okay it's a

[03:23:43 - 03:23:47]
vector only you can see T1 T2 and T3 and

[03:23:46 - 03:23:49]
there will and they're doing the

[03:23:47 - 03:23:50]
addition operation okay after that they

[03:23:49 - 03:23:52]
getting the embedding with the time

[03:23:50 - 03:23:56]
signal that means whenever we write any

[03:23:52 - 03:23:58]
kinds of let's say sentence let's say my

[03:23:56 - 03:24:01]
name okay is

[03:23:58 - 03:24:04]
buy so it always follows one time

[03:24:01 - 03:24:06]
sequence let's say my I have written at

[03:24:04 - 03:24:08]
the time of T1 name I have written at

[03:24:06 - 03:24:10]
the time of T2 is I have written at the

[03:24:08 - 03:24:13]
time of T3 and byy T4 okay that's how it

[03:24:10 - 03:24:15]
follows on sequence okay so that's why

[03:24:13 - 03:24:16]
Text data can be also called as

[03:24:15 - 03:24:19]
sequential data okay it's sequential

[03:24:16 - 03:24:20]
data because it follows the time okay so

[03:24:19 - 03:24:23]
that's why they are telling embedding

[03:24:20 - 03:24:25]
with the time signal that means whatever

[03:24:23 - 03:24:27]
input you have given okay whatever input

[03:24:25 - 03:24:29]
you have given it is having one time

[03:24:27 - 03:24:32]
let's say T1 T2 and 33 and so on right

[03:24:29 - 03:24:33]
so on so that they're adding this

[03:24:32 - 03:24:36]
positional encoding now how this

[03:24:33 - 03:24:39]
portional encoding helping us to uh

[03:24:36 - 03:24:41]
identify whether after Z this word is

[03:24:39 - 03:24:43]
coming after Swiss this word is coming

[03:24:41 - 03:24:45]
because if you see positional encoding

[03:24:43 - 03:24:47]
nothing but it's a vector okay and after

[03:24:45 - 03:24:48]
adding okay after add in this Vector

[03:24:47 - 03:24:51]
with my embedding so again we are

[03:24:48 - 03:24:52]
getting another Vector yes or no okay

[03:24:51 - 03:24:54]
now if you calculate the distance okay

[03:24:52 - 03:24:56]
between this three Vector you will see

[03:24:54 - 03:24:58]
that this vector and this Vector would

[03:24:56 - 03:25:00]
be closely uh together because if you

[03:24:58 - 03:25:01]
just do the subtraction okay if you just

[03:25:00 - 03:25:03]
find the distance you'll see that it

[03:25:01 - 03:25:05]
will get very less distance between

[03:25:03 - 03:25:07]
these two Vector okay and you will you

[03:25:05 - 03:25:09]
will see that this vector and this V

[03:25:07 - 03:25:11]
Vector distance will be more okay

[03:25:09 - 03:25:13]
because uh you can see the number okay

[03:25:11 - 03:25:15]
so that's actually it is identifying

[03:25:13 - 03:25:17]
after Z this particular word is coming

[03:25:15 - 03:25:19]
after this word this word is coming okay

[03:25:17 - 03:25:20]
based on this particular Vector okay

[03:25:19 - 03:25:22]
that's how they're doing distance

[03:25:20 - 03:25:24]
calculation and they're trying to

[03:25:22 - 03:25:26]
understand the sequence information of a

[03:25:24 - 03:25:28]
sentence okay let's say after my bu is

[03:25:26 - 03:25:30]
coming sorry after my name is coming

[03:25:28 - 03:25:32]
after name is is coming after is BU is

[03:25:30 - 03:25:34]
coming okay I hope it is clear so that's

[03:25:32 - 03:25:37]
how they're handling this particular SE

[03:25:34 - 03:25:38]
uh sequence okay now now I think you got

[03:25:37 - 03:25:39]
it whenever we are passing any against

[03:25:38 - 03:25:41]
of bigger prompt to the large language

[03:25:39 - 03:25:44]
model how it is identifying that

[03:25:41 - 03:25:45]
particular contextual meaning how it is

[03:25:44 - 03:25:46]
remembering that particular sequence

[03:25:45 - 03:25:48]
let's say after this sequence this

[03:25:46 - 03:25:50]
sequence is coming now he has added some

[03:25:48 - 03:25:52]
more graph so as of now let's skip okay

[03:25:50 - 03:25:54]
it's not required okay now the next

[03:25:52 - 03:25:56]
thing we'll be discussing about the

[03:25:54 - 03:25:59]
residual block those who have learned

[03:25:56 - 03:26:01]
about like computer vision so I think

[03:25:59 - 03:26:03]
you learn one model called resonet okay

[03:26:01 - 03:26:05]
so in resonet also we had these kinds of

[03:26:03 - 03:26:07]
architecture okay I think you remember

[03:26:05 - 03:26:08]
so I think you remember so let's say

[03:26:07 - 03:26:11]
here we are having different different

[03:26:08 - 03:26:13]
layer okay different different

[03:26:11 - 03:26:15]
layer

[03:26:13 - 03:26:17]
fine and we also had something called

[03:26:15 - 03:26:19]
residual block so that's how actually it

[03:26:17 - 03:26:22]
will look like that means whatever input

[03:26:19 - 03:26:24]
actually you give usually so sometimes

[03:26:22 - 03:26:26]
let's say if this block is not working

[03:26:24 - 03:26:29]
good okay let's say this block is not

[03:26:26 - 03:26:31]
working good not good then what will

[03:26:29 - 03:26:33]
happen it will escape this block and

[03:26:31 - 03:26:34]
this output will go to the next block

[03:26:33 - 03:26:38]
okay this is called actually skip

[03:26:34 - 03:26:40]
connection okay skip

[03:26:38 - 03:26:42]
connection okay and this is called

[03:26:40 - 03:26:45]
actually residual block so we already

[03:26:42 - 03:26:47]
learned this residual Block in our CNN

[03:26:45 - 03:26:48]
architecture so the the same residual

[03:26:47 - 03:26:50]
concept has also applied in this

[03:26:48 - 03:26:52]
particular Transformer architecture as

[03:26:50 - 03:26:53]
well so here we are also having residual

[03:26:52 - 03:26:55]
connection you can see let's say this is

[03:26:53 - 03:26:57]
the input we are giving okay let's see

[03:26:55 - 03:26:58]
if this particular self attention layer

[03:26:57 - 03:27:01]
is not working good what will happen

[03:26:58 - 03:27:03]
this input will go to the next okay next

[03:27:01 - 03:27:05]
layer now they are also using something

[03:27:03 - 03:27:06]
called add and normalization and what is

[03:27:05 - 03:27:08]
normalization I think you know with the

[03:27:06 - 03:27:11]
help of normalization we just uh bring

[03:27:08 - 03:27:12]
our data distribution in a normal okay

[03:27:11 - 03:27:14]
normal distribution I think you remember

[03:27:12 - 03:27:16]
right this is whatever weight actually

[03:27:14 - 03:27:18]
we're having so if you if you just

[03:27:16 - 03:27:20]
visualize them you'll see it will be it

[03:27:18 - 03:27:22]
will be a normal distributed okay normal

[03:27:20 - 03:27:24]
distributed output so it helps us during

[03:27:22 - 03:27:26]
back propagation whenever it will try to

[03:27:24 - 03:27:28]
find the global Minima okay that time

[03:27:26 - 03:27:30]
actually this concept helps a lot now

[03:27:28 - 03:27:31]
you can see again we are having another

[03:27:30 - 03:27:34]
residual block connection skip

[03:27:31 - 03:27:36]
connection okay that means uh if any of

[03:27:34 - 03:27:37]
the layer is not working good this uh

[03:27:36 - 03:27:39]
this will actually skip this part and it

[03:27:37 - 03:27:40]
will go to the next okay next layer so

[03:27:39 - 03:27:42]
this is the idea of the residual

[03:27:40 - 03:27:44]
connection because it's a very huge

[03:27:42 - 03:27:45]
layer because you can see this uh

[03:27:44 - 03:27:47]
Transformer architecture it's a very

[03:27:45 - 03:27:50]
huge layer so sometimes let's if you are

[03:27:47 - 03:27:52]
using any simple data very simple data

[03:27:50 - 03:27:54]
so you don't need all the layer now you

[03:27:52 - 03:27:56]
don't need all the layer to process your

[03:27:54 - 03:27:58]
let's say input so sometimes uh whenever

[03:27:56 - 03:28:00]
you are having the simple data it will

[03:27:58 - 03:28:01]
go to some of the layer and it will

[03:28:00 - 03:28:04]
perform better okay that time actually

[03:28:01 - 03:28:05]
it will skip these are the let's say

[03:28:04 - 03:28:07]
layer okay so this called actually skip

[03:28:05 - 03:28:09]
connection and rual block and if you

[03:28:07 - 03:28:10]
want to see the normalization how it is

[03:28:09 - 03:28:13]
performing the normalization so here you

[03:28:10 - 03:28:16]
can see the normalization so it will do

[03:28:13 - 03:28:18]
the addition operation um X and Zed okay

[03:28:16 - 03:28:19]
Zed vector and it will perform the

[03:28:18 - 03:28:21]
normalization like that okay then

[03:28:19 - 03:28:23]
whatever output it is having it will

[03:28:21 - 03:28:24]
pass to the fit forward and F Feit

[03:28:23 - 03:28:26]
forward again will pass to the

[03:28:24 - 03:28:28]
normalization and again it will pass to

[03:28:26 - 03:28:29]
the next okay layer this is the idea now

[03:28:28 - 03:28:31]
here you can see the entire architecture

[03:28:29 - 03:28:34]
guys so far whatever we have discussed

[03:28:31 - 03:28:36]
now he has given inside one block only

[03:28:34 - 03:28:38]
now we are giving our input we are

[03:28:36 - 03:28:39]
adding the positional inod then self

[03:28:38 - 03:28:41]
attention then we are also adding

[03:28:39 - 03:28:43]
something called add normalization then

[03:28:41 - 03:28:45]
it will pass to the fit forward then add

[03:28:43 - 03:28:47]
normalization again then it will pass

[03:28:45 - 03:28:49]
the next encoder okay and inside that we

[03:28:47 - 03:28:51]
are also having some resist connection

[03:28:49 - 03:28:52]
okay then whatever output we are getting

[03:28:51 - 03:28:54]
okay let's say whatever let's say

[03:28:52 - 03:28:56]
encoder we are using like I think I

[03:28:54 - 03:28:58]
showed you six encoder layer we're using

[03:28:56 - 03:29:00]
so this output will go to the decoder

[03:28:58 - 03:29:02]
okay now see directly is going to the

[03:29:00 - 03:29:04]
decoder layer now at the same time this

[03:29:02 - 03:29:05]
output is also going to the encoder and

[03:29:04 - 03:29:07]
decoder attention now you can ask me

[03:29:05 - 03:29:08]
what is encoder and decoder attention

[03:29:07 - 03:29:10]
see this is the same whatever things we

[03:29:08 - 03:29:12]
have learned encoder and decoder the

[03:29:10 - 03:29:14]
same architecture they're using in this

[03:29:12 - 03:29:16]
particular layer okay that means

[03:29:14 - 03:29:17]
whatever output you are get here again

[03:29:16 - 03:29:19]
passing to this particular encoder and

[03:29:17 - 03:29:21]
decoder again it will process those are

[03:29:19 - 03:29:23]
the input and it will pass to the next

[03:29:21 - 03:29:25]
layer okay so that's how actually your

[03:29:23 - 03:29:27]
output is passing to the encoder and

[03:29:25 - 03:29:29]
decoder as well as the decoder and how

[03:29:27 - 03:29:30]
many decoder we had we had six decoder

[03:29:29 - 03:29:33]
layer now let's try to see the decoder

[03:29:30 - 03:29:35]
side now see here we are passing the

[03:29:33 - 03:29:38]
input so this is the input we are

[03:29:35 - 03:29:40]
passing to the encoder encoder will pass

[03:29:38 - 03:29:42]
this uh output to the decoder but before

[03:29:40 - 03:29:45]
passing this output it will add some

[03:29:42 - 03:29:46]
Vector you can see K vector and V Vector

[03:29:45 - 03:29:48]
okay it will first of all multi mly then

[03:29:46 - 03:29:50]
it will pass to the decoder okay and

[03:29:48 - 03:29:51]
decoder will pass to the linear and soft

[03:29:50 - 03:29:54]
Max that means it will apply the soft

[03:29:51 - 03:29:56]
Max function on top of it now one thing

[03:29:54 - 03:29:59]
will happen let's see if you're doing

[03:29:56 - 03:30:01]
actually language translation so the

[03:29:59 - 03:30:03]
input you are giving to the encoder so

[03:30:01 - 03:30:05]
this output actually you're are passing

[03:30:03 - 03:30:06]
to the decoder and decoder will predict

[03:30:05 - 03:30:07]
something see decoder will predict

[03:30:06 - 03:30:10]
something it will generate something

[03:30:07 - 03:30:11]
let's say I so you are giving friends

[03:30:10 - 03:30:16]
input and you're getting English output

[03:30:11 - 03:30:18]
let's say Z means I Swiss mean M and it

[03:30:16 - 03:30:20]
means a student okay so that means it is

[03:30:18 - 03:30:23]
first of all see if you see the first

[03:30:20 - 03:30:25]
iteration let me show you it's animation

[03:30:23 - 03:30:27]
if I show you the first

[03:30:25 - 03:30:28]
iteration see this is the first

[03:30:27 - 03:30:31]
iteration first of all it is predicting

[03:30:28 - 03:30:33]
I so this I again it is coming as an

[03:30:31 - 03:30:35]
input to the decoder side you can see I

[03:30:33 - 03:30:38]
then it is predicting M again this m

[03:30:35 - 03:30:39]
will go to the input of the decoder side

[03:30:38 - 03:30:41]
okay then it will predict something

[03:30:39 - 03:30:43]
called a that means based on this two

[03:30:41 - 03:30:44]
word it is predicting the next word okay

[03:30:43 - 03:30:46]
based on this word it is predicting the

[03:30:44 - 03:30:48]
next next word okay I already showed you

[03:30:46 - 03:30:50]
now that llm concept like it will

[03:30:48 - 03:30:52]
predict the next word always okay that's

[03:30:50 - 03:30:54]
how it is predicting the next next word

[03:30:52 - 03:30:56]
okay unless and until it is having the

[03:30:54 - 03:30:59]
EOS sign that means end of the sentence

[03:30:56 - 03:31:01]
okay EOS okay this is the tag I think

[03:30:59 - 03:31:03]
you know okay what is eos and there is

[03:31:01 - 03:31:05]
another one called SOS okay start of the

[03:31:03 - 03:31:06]
sentence and end of the sentence

[03:31:05 - 03:31:08]
whenever it is getting the tag that

[03:31:06 - 03:31:10]
means this sentence is complete and it

[03:31:08 - 03:31:12]
will stop the execution that time okay

[03:31:10 - 03:31:15]
so that's how your encoder and decoder

[03:31:12 - 03:31:16]
is working okay and inside encoder

[03:31:15 - 03:31:18]
whatever things were having I already

[03:31:16 - 03:31:20]
expand inside decoder also whatever

[03:31:18 - 03:31:20]
things you have I already expand okay

[03:31:20 - 03:31:23]
that's

[03:31:20 - 03:31:25]
how that's how it is uh actually

[03:31:23 - 03:31:26]
building one amazing architecture called

[03:31:25 - 03:31:29]
Transformer okay

[03:31:26 - 03:31:30]
Transformer and and that is why

[03:31:29 - 03:31:32]
Transformer is so powerful because it is

[03:31:30 - 03:31:34]
having so many component inside that it

[03:31:32 - 03:31:36]
is using something called multi-head

[03:31:34 - 03:31:38]
attention Okay that is the main concept

[03:31:36 - 03:31:41]
here so this is the entire understanding

[03:31:38 - 03:31:43]
guys and I hope guys you got the high

[03:31:41 - 03:31:45]
level understanding of this Transformer

[03:31:43 - 03:31:47]
like how it is working and what is the

[03:31:45 - 03:31:49]
internal mechanism of the Transformer

[03:31:47 - 03:31:51]
now if I open the actual architecture in

[03:31:49 - 03:31:53]
the paper now I think you will get it

[03:31:51 - 03:31:54]
see this is the encoder site okay this

[03:31:53 - 03:31:56]
is the encoder site and now I think you

[03:31:54 - 03:31:57]
know what is input embedding and what is

[03:31:56 - 03:32:00]
the positional encoding what is multi

[03:31:57 - 03:32:01]
attention what is AD normalization and

[03:32:00 - 03:32:02]
what is these are the arrow that means

[03:32:01 - 03:32:05]
this is the skip connection residual

[03:32:02 - 03:32:06]
block then feed forwall again uh add

[03:32:05 - 03:32:08]
normalization again you are passing to

[03:32:06 - 03:32:11]
the MTI attention and you are also

[03:32:08 - 03:32:12]
passing this in uh output to the decoder

[03:32:11 - 03:32:14]
side you can see this is the decoder

[03:32:12 - 03:32:15]
side and inside decoder we are having

[03:32:14 - 03:32:17]
multi-ad attention again add

[03:32:15 - 03:32:20]
normalization M attention feed forward

[03:32:17 - 03:32:21]
okay s Max and so on okay and whatever

[03:32:20 - 03:32:24]
output you are getting you are again

[03:32:21 - 03:32:26]
passing this output to the input of the

[03:32:24 - 03:32:28]
uh decoder input okay this is the idea

[03:32:26 - 03:32:29]
now I think this architecture is clear

[03:32:28 - 03:32:31]
how they have developed okay now you

[03:32:29 - 03:32:34]
simply just try to go through this paper

[03:32:31 - 03:32:35]
once just try to read or you can also

[03:32:34 - 03:32:37]
read this particular blog okay so it

[03:32:35 - 03:32:38]
will give you the clearcut idea about

[03:32:37 - 03:32:40]
the Transformer architecture okay so

[03:32:38 - 03:32:42]
this should be my suggestion guys please

[03:32:40 - 03:32:44]
go through uh one time this particular

[03:32:42 - 03:32:46]
blog just try to read everything okay

[03:32:44 - 03:32:48]
see the way actually has written if

[03:32:46 - 03:32:50]
anyone is from college background they

[03:32:48 - 03:32:52]
will also able to understand okay that

[03:32:50 - 03:32:54]
much easy it is so yes this is all about

[03:32:52 - 03:32:57]
our Transformer interation I hope you

[03:32:54 - 03:32:59]
got it how Transformer is working so uh

[03:32:57 - 03:33:01]
based on this Transformer today's

[03:32:59 - 03:33:03]
actually whatever large language model

[03:33:01 - 03:33:04]
we are having they have developed now in

[03:33:03 - 03:33:06]
the next video we'll be learning about

[03:33:04 - 03:33:09]
like uh how chat GPT got trained because

[03:33:06 - 03:33:11]
you can see chat GPT so chat GPT is

[03:33:09 - 03:33:14]
using one large language model called uh

[03:33:11 - 03:33:16]
GPT okay so we'll be understanding how

[03:33:14 - 03:33:19]
chat GPT actually the train like what is

[03:33:16 - 03:33:21]
the internal mechanism of the chat GPT

[03:33:19 - 03:33:22]
okay we'll be discussing this part so I

[03:33:21 - 03:33:25]
think you are already familiar with chat

[03:33:22 - 03:33:28]
GPT right so chat GPT is a product of

[03:33:25 - 03:33:30]
open AI so inside chat GPT we can pass

[03:33:28 - 03:33:32]
any kinds of prompt and we can get the

[03:33:30 - 03:33:33]
response so it is kinds of

[03:33:32 - 03:33:36]
conversational let's say chatboard they

[03:33:33 - 03:33:37]
have developed but uh by that particular

[03:33:36 - 03:33:40]
chatboard what you can do you can

[03:33:37 - 03:33:41]
perform all kinds of NLP task I think I

[03:33:40 - 03:33:43]
showed you one example I think you

[03:33:41 - 03:33:46]
remember we can perform language

[03:33:43 - 03:33:48]
translation text summarization we can

[03:33:46 - 03:33:50]
part from sentiment analysis okay we can

[03:33:48 - 03:33:52]
also let's say generate the codes every

[03:33:50 - 03:33:54]
everything is possible because I already

[03:33:52 - 03:33:57]
told you now llm why it is powerful

[03:33:54 - 03:33:58]
because it can perform multitask right

[03:33:57 - 03:34:00]
multiple task it can perform with the

[03:33:58 - 03:34:03]
help of one model only task wise it is

[03:34:00 - 03:34:05]
clear like how uh it will able to

[03:34:03 - 03:34:06]
perform the task right but what about

[03:34:05 - 03:34:09]
the conversational agents let's say

[03:34:06 - 03:34:11]
whenever I'm passing any kinds of prompt

[03:34:09 - 03:34:12]
how it is identifying okay how it is

[03:34:11 - 03:34:15]
identifying what kinds of let's say

[03:34:12 - 03:34:17]
prompt I'm giving and what kinds of

[03:34:15 - 03:34:19]
tasks actually I'm expecting from my uh

[03:34:17 - 03:34:20]
chat GPT okay so this is what actually

[03:34:19 - 03:34:22]
will be understanding uh in this

[03:34:20 - 03:34:24]
particular video because because if this

[03:34:22 - 03:34:25]
understanding is clear so going forward

[03:34:24 - 03:34:27]
whatever model you'll be learning

[03:34:25 - 03:34:29]
whatever application you'll be building

[03:34:27 - 03:34:31]
this would be more clear in your mind so

[03:34:29 - 03:34:34]
first of all you have to remember one

[03:34:31 - 03:34:36]
thing see chat GPT is not a model okay

[03:34:34 - 03:34:39]
so chat GPT is just a application

[03:34:36 - 03:34:42]
internally it is using a llm which is

[03:34:39 - 03:34:45]
GPT 3.5 or GPT 4 it has trained on large

[03:34:42 - 03:34:47]
amount of data which is also available

[03:34:45 - 03:34:50]
over the internet that means that means

[03:34:47 - 03:34:53]
over the Internet till 2023 whatever

[03:34:50 - 03:34:55]
actually data we are having so all the

[03:34:53 - 03:34:58]
data they have used to train this gpt3

[03:34:55 - 03:35:01]
or GPT 4 model right now to train this

[03:34:58 - 03:35:03]
chat GPT they actually follow three step

[03:35:01 - 03:35:05]
the first step is generative preing the

[03:35:03 - 03:35:07]
second step is supervised fine tuning

[03:35:05 - 03:35:09]
and the third step is reinforcement

[03:35:07 - 03:35:10]
learning I'll discuss all of them one by

[03:35:09 - 03:35:12]
one no need to worry but first of all

[03:35:10 - 03:35:14]
just try to see as I already told you

[03:35:12 - 03:35:16]
Char gbt is not a model it's just a

[03:35:14 - 03:35:18]
application it's just a interface right

[03:35:16 - 03:35:21]
so whenever you are giving any kinds of

[03:35:18 - 03:35:23]
prompt to the CH GPT it is using one

[03:35:21 - 03:35:25]
open API key right I think you know what

[03:35:23 - 03:35:28]
is openi API key with the help of openi

[03:35:25 - 03:35:31]
API key it is sending that particular uh

[03:35:28 - 03:35:32]
request to the model you can see it is

[03:35:31 - 03:35:35]
it can access different different model

[03:35:32 - 03:35:37]
of the GPT like GPT 3.5 GPT 4 okay or

[03:35:35 - 03:35:39]
any other model actually GPT is bringing

[03:35:37 - 03:35:40]
in future right so this is the idea

[03:35:39 - 03:35:41]
let's say you want to powerform language

[03:35:40 - 03:35:44]
translation you are giving the prompt

[03:35:41 - 03:35:45]
here so this chat GPT interface

[03:35:44 - 03:35:48]
receiving your prompt then it is sending

[03:35:45 - 03:35:50]
that particular prom to the uh model

[03:35:48 - 03:35:52]
with the help of open API key that is

[03:35:50 - 03:35:55]
the idea okay so that means CH GPT is an

[03:35:52 - 03:35:57]
application and it is using uh

[03:35:55 - 03:36:01]
internally it is using some kinds of llm

[03:35:57 - 03:36:03]
which is known GPT 4 or GPT 3.5 now as I

[03:36:01 - 03:36:05]
already told you um they used actually

[03:36:03 - 03:36:07]
three step to train this model now you

[03:36:05 - 03:36:09]
can see the first stage is generative

[03:36:07 - 03:36:11]
pre-training so here you can see this

[03:36:09 - 03:36:14]
base model GPT trained on a brnch of

[03:36:11 - 03:36:16]
stuff from internet for a whole bunch of

[03:36:14 - 03:36:18]
different things by

[03:36:16 - 03:36:19]
uh using the Transformer architecture

[03:36:18 - 03:36:21]
that means they're using Transformer

[03:36:19 - 03:36:23]
architecture internally and they're

[03:36:21 - 03:36:25]
training on top of the internet data

[03:36:23 - 03:36:26]
okay or Internet documents data you can

[03:36:25 - 03:36:29]
talk about then they are getting

[03:36:26 - 03:36:31]
something called Bas GPT model OKAY B

[03:36:29 - 03:36:33]
GPT model then this B GPT model then

[03:36:31 - 03:36:35]
again they doing something called

[03:36:33 - 03:36:37]
supervised fine tuning okay in the St

[03:36:35 - 03:36:39]
two they're doing supervised fine tuning

[03:36:37 - 03:36:40]
so what is supervised fine tuning I'll

[03:36:39 - 03:36:43]
discuss uh everything don't need to

[03:36:40 - 03:36:46]
worry so next with the human AI trainers

[03:36:43 - 03:36:49]
you get to have conversation

[03:36:46 - 03:36:51]
where they play Both Sides you and AI

[03:36:49 - 03:36:53]
assistant okay now after performing the

[03:36:51 - 03:36:56]
supervised fine tuning they get one

[03:36:53 - 03:36:58]
model called fine tune chat GPT model

[03:36:56 - 03:36:59]
now they'll be performing something

[03:36:58 - 03:37:01]
called reinforcement Landing through

[03:36:59 - 03:37:03]
human feedback so here you can see next

[03:37:01 - 03:37:05]
uh let's take the model to the next

[03:37:03 - 03:37:07]
level by optimizing it's even more

[03:37:05 - 03:37:10]
reinforcement learning by training it

[03:37:07 - 03:37:11]
against a reward model okay that means

[03:37:10 - 03:37:13]
they will be creating something called

[03:37:11 - 03:37:14]
reward model and why they'll be creating

[03:37:13 - 03:37:16]
the reward model I will tell you then

[03:37:14 - 03:37:17]
after that they will be getting the CH

[03:37:16 - 03:37:19]
GPT model and this is what actually we

[03:37:17 - 03:37:21]
are using okay this is what we are using

[03:37:19 - 03:37:23]
in our day-to-day life this is the idea

[03:37:21 - 03:37:24]
now let's discuss all the St one by one

[03:37:23 - 03:37:26]
now first of all let's try to discuss

[03:37:24 - 03:37:28]
generative pretaining okay now see what

[03:37:26 - 03:37:30]
is generative pretaining as I already

[03:37:28 - 03:37:31]
told you they're using a bunch of data

[03:37:30 - 03:37:34]
from the internet and they're training

[03:37:31 - 03:37:36]
one Transformer model okay so they're

[03:37:34 - 03:37:37]
using the code Transformer architecture

[03:37:36 - 03:37:40]
only on top of that they're adding some

[03:37:37 - 03:37:42]
more layer okay and they're creating one

[03:37:40 - 03:37:45]
GPT model okay this is called a GPT

[03:37:42 - 03:37:47]
model now this model will be able to uh

[03:37:45 - 03:37:49]
do actually various kinds of task like

[03:37:47 - 03:37:51]
text summarization sentiment analysis

[03:37:49 - 03:37:53]
sentiment sentence completion

[03:37:51 - 03:37:55]
translation and so on but what is our

[03:37:53 - 03:37:58]
expectation from our chat GPD so here

[03:37:55 - 03:38:00]
user can pass any kinds of prompt he or

[03:37:58 - 03:38:01]
she can chat with uh chat and

[03:38:00 - 03:38:04]
conversation with this uh let's say

[03:38:01 - 03:38:05]
application yes or no right but after

[03:38:04 - 03:38:07]
training this particular let's say

[03:38:05 - 03:38:09]
Transformer model we are only getting

[03:38:07 - 03:38:11]
the uh we are only getting the actually

[03:38:09 - 03:38:13]
task output let's say this model only

[03:38:11 - 03:38:15]
can perform Tex summarization s analysis

[03:38:13 - 03:38:17]
sentence completion and language

[03:38:15 - 03:38:18]
translation apart from that actually it

[03:38:17 - 03:38:21]
can't do anything let's say it can't do

[03:38:18 - 03:38:23]
the chat conversation with the human

[03:38:21 - 03:38:25]
Okay this model can't do so this is our

[03:38:23 - 03:38:27]
expectation okay with that this is our

[03:38:25 - 03:38:28]
expectation so for this actually what

[03:38:27 - 03:38:30]
they did actually they follow another

[03:38:28 - 03:38:32]
stage called supervised fine tuning in

[03:38:30 - 03:38:34]
supervised fine tuning what they have

[03:38:32 - 03:38:37]
done so they have actually taken two

[03:38:34 - 03:38:39]
human so one human called human agent

[03:38:37 - 03:38:41]
acting like a bot another human the

[03:38:39 - 03:38:43]
actual human agent okay that means both

[03:38:41 - 03:38:45]
are human but one human actually will

[03:38:43 - 03:38:47]
act like a bot and another human will

[03:38:45 - 03:38:49]
act like a human only right so this

[03:38:47 - 03:38:51]
particular human will give some request

[03:38:49 - 03:38:53]
okay let's say he will put some let's

[03:38:51 - 03:38:55]
say text let's say how are you so this

[03:38:53 - 03:38:57]
human will give the reply let's say I'm

[03:38:55 - 03:38:59]
fine what about you again he will give

[03:38:57 - 03:39:01]
I'm also fine then he will tell I need

[03:38:59 - 03:39:03]
help from your side this particular

[03:39:01 - 03:39:05]
let's say human will uh tell so this

[03:39:03 - 03:39:06]
particular human will tell how I can

[03:39:05 - 03:39:08]
help you okay so that's actually they

[03:39:06 - 03:39:09]
will be doing the conversation the way

[03:39:08 - 03:39:12]
actually we do the conversation with our

[03:39:09 - 03:39:16]
chat GPT okay so initially we have to

[03:39:12 - 03:39:18]
create our data that means chat data

[03:39:16 - 03:39:19]
okay chat data so to collect the chat

[03:39:18 - 03:39:21]
data they're using this particular

[03:39:19 - 03:39:22]
technique called supervised finetuning

[03:39:21 - 03:39:24]
okay supervised fining they're

[03:39:22 - 03:39:27]
supervising the model okay this is the

[03:39:24 - 03:39:29]
main idea now see after uh doing these

[03:39:27 - 03:39:31]
kinds of conversation you will have

[03:39:29 - 03:39:33]
different different data let's say uh

[03:39:31 - 03:39:35]
from The Human Side you will get lots of

[03:39:33 - 03:39:37]
request and from the B size that means

[03:39:35 - 03:39:39]
human Agent B size you will be getting

[03:39:37 - 03:39:41]
lots of response now you'll be using uh

[03:39:39 - 03:39:43]
this particular data to train again your

[03:39:41 - 03:39:45]
base GPT model okay you'll be again fine

[03:39:43 - 03:39:47]
tuning your base GPT model and you'll be

[03:39:45 - 03:39:49]
using something called stochastic

[03:39:47 - 03:39:52]
gradient decent Optimizer okay AGD

[03:39:49 - 03:39:54]
Optimizer they're using and they're

[03:39:52 - 03:39:56]
training one model called sft Char GPT

[03:39:54 - 03:39:58]
model that means supervised fine tuning

[03:39:56 - 03:40:00]
model okay this is the main idea here

[03:39:58 - 03:40:02]
and this is called actually sft and

[03:40:00 - 03:40:03]
supervised fine tuning but one issue

[03:40:02 - 03:40:06]
actually they observed after uh doing

[03:40:03 - 03:40:07]
the supervised fine tuning this model

[03:40:06 - 03:40:09]
can only

[03:40:07 - 03:40:11]
perform uh related uh to the training

[03:40:09 - 03:40:13]
data let's say let's say if someone is

[03:40:11 - 03:40:15]
giving any kinds of input which was not

[03:40:13 - 03:40:17]
present in the training example that

[03:40:15 - 03:40:20]
time this model was giving some random

[03:40:17 - 03:40:22]
output okay so to actually overcome this

[03:40:20 - 03:40:24]
issue and to make this particular model

[03:40:22 - 03:40:25]
more good they followed something called

[03:40:24 - 03:40:27]
reinforcement learning through human

[03:40:25 - 03:40:29]
feedback technique so inside uh

[03:40:27 - 03:40:31]
reinforcement learning uh through human

[03:40:29 - 03:40:34]
feedback what they are doing whatever

[03:40:31 - 03:40:37]
let's a conversation uh having between

[03:40:34 - 03:40:39]
this human agent and sft chat GPT model

[03:40:37 - 03:40:41]
so they're trying to rank the results

[03:40:39 - 03:40:44]
okay rank the response you can see let's

[03:40:41 - 03:40:46]
say this sft model will give actually

[03:40:44 - 03:40:48]
multiple response now there would be a

[03:40:46 - 03:40:50]
human okay there would be a human agent

[03:40:48 - 03:40:53]
so this human agent will rank the result

[03:40:50 - 03:40:56]
let's say here we are getting uh 1 2 3

[03:40:53 - 03:40:59]
four four different response let's say a

[03:40:56 - 03:41:01]
b c and d now between these four results

[03:40:59 - 03:41:03]
which one is the good okay which one is

[03:41:01 - 03:41:06]
the good and which one is the let's say

[03:41:03 - 03:41:08]
suitable with the user input user has

[03:41:06 - 03:41:11]
given now he will just try to rank the

[03:41:08 - 03:41:13]
results now let's say uh B is B response

[03:41:11 - 03:41:15]
is good then a then D then C okay this

[03:41:13 - 03:41:17]
is the rank response that's how actually

[03:41:15 - 03:41:18]
he will try to prepare then what they

[03:41:17 - 03:41:20]
have done they created one reward model

[03:41:18 - 03:41:21]
and what is reward model reward model is

[03:41:20 - 03:41:23]
nothing but it's a reinforcement

[03:41:21 - 03:41:25]
learning model those so those who are

[03:41:23 - 03:41:27]
familiar with reinforcement learning I

[03:41:25 - 03:41:28]
think you know what is reward model so

[03:41:27 - 03:41:30]
here you can see they're giving actually

[03:41:28 - 03:41:32]
different different response and they're

[03:41:30 - 03:41:34]
uh actually generating one score okay

[03:41:32 - 03:41:35]
like what is the score for this response

[03:41:34 - 03:41:37]
what is the score for this response okay

[03:41:35 - 03:41:39]
that's how they're generating the score

[03:41:37 - 03:41:41]
now whoever actually having like more

[03:41:39 - 03:41:43]
score this particular response would be

[03:41:41 - 03:41:44]
considered as my final output okay

[03:41:43 - 03:41:46]
that's how actually they're doing

[03:41:44 - 03:41:47]
reinforcement planning through human

[03:41:46 - 03:41:49]
feedback and they're improving the

[03:41:47 - 03:41:51]
accuracy of the model this is the main

[03:41:49 - 03:41:54]
idea that means if you see uh in high

[03:41:51 - 03:41:56]
level so you are using reward model and

[03:41:54 - 03:41:58]
you are ranking uh this particular let's

[03:41:56 - 03:41:59]
say response based on that you are and

[03:41:58 - 03:42:01]
based on that actually you are providing

[03:41:59 - 03:42:03]
the actual response and this reward

[03:42:01 - 03:42:05]
model will uh give some policy let's say

[03:42:03 - 03:42:07]
if this response is good if user is

[03:42:05 - 03:42:08]
liking that particular response so

[03:42:07 - 03:42:10]
definitely it will give some reward

[03:42:08 - 03:42:12]
otherwise it won't be giving any kinds

[03:42:10 - 03:42:14]
of reward so sometimes in the chat GPT

[03:42:12 - 03:42:15]
will see that it will ask for your

[03:42:14 - 03:42:17]
feedback whether

[03:42:15 - 03:42:19]
uh you are getting the correct output or

[03:42:17 - 03:42:21]
not if you give the let a low rating

[03:42:19 - 03:42:22]
that time they will consider this model

[03:42:21 - 03:42:25]
is not working good that time they will

[03:42:22 - 03:42:26]
give negative reward so again they uh

[03:42:25 - 03:42:28]
this reinforcement learning will

[03:42:26 - 03:42:30]
automatically learn okay how to improve

[03:42:28 - 03:42:32]
the quality of the model and if you're

[03:42:30 - 03:42:33]
giving positive fitmap that means it

[03:42:32 - 03:42:34]
will give the positive reward that time

[03:42:33 - 03:42:36]
okay so that is how actually

[03:42:34 - 03:42:39]
reinforcement learning works so here in

[03:42:36 - 03:42:40]
the environment you just put on agents

[03:42:39 - 03:42:42]
that particular agents learn the

[03:42:40 - 03:42:44]
environment and whatever activity you

[03:42:42 - 03:42:46]
are doing it will try to learn and based

[03:42:44 - 03:42:48]
on that it will uh try to update the

[03:42:46 - 03:42:50]
reward model this is the main idea right

[03:42:48 - 03:42:53]
so yes this was actually core uh concept

[03:42:50 - 03:42:55]
to train this chat GPT model and that's

[03:42:53 - 03:42:58]
how actually not only we get that task

[03:42:55 - 03:43:00]
specific model we can also perform the

[03:42:58 - 03:43:03]
conversation with that particular model

[03:43:00 - 03:43:04]
okay because they have done because I I

[03:43:03 - 03:43:06]
think I showed you now how they have

[03:43:04 - 03:43:08]
done this particular entire strategy and

[03:43:06 - 03:43:09]
how we can perform the conversation so

[03:43:08 - 03:43:11]
whenever we are giving any kind of

[03:43:09 - 03:43:12]
prompt first of all it will trying to

[03:43:11 - 03:43:14]
understand my prompt because of that

[03:43:12 - 03:43:16]
particular supervised fine tuning let's

[03:43:14 - 03:43:18]
say I'm giving a prompt PRP I want to do

[03:43:16 - 03:43:20]
the language translation French to

[03:43:18 - 03:43:21]
English so it will try to understand

[03:43:20 - 03:43:24]
that particular prompt then based on

[03:43:21 - 03:43:26]
that it will decide what kinds of task

[03:43:24 - 03:43:27]
you want to perform okay apart from that

[03:43:26 - 03:43:30]
if you're doing some casual conversation

[03:43:27 - 03:43:32]
also it can also handle because again it

[03:43:30 - 03:43:34]
was trained with huge amount of data

[03:43:32 - 03:43:36]
okay that's the idea so yes guys I hope

[03:43:34 - 03:43:38]
this makes sense now and you got how

[03:43:36 - 03:43:40]
Char gbt was trained and now this

[03:43:38 - 03:43:42]
concept will help you to understand

[03:43:40 - 03:43:44]
whatever let's say model will be

[03:43:42 - 03:43:46]
understanding in future okay so I think

[03:43:44 - 03:43:48]
you enjoyed so if you don't know about

[03:43:46 - 03:43:50]
hugging face hugging face is a platform

[03:43:48 - 03:43:52]
so with the help of this platform you

[03:43:50 - 03:43:54]
can do genbi project you can do NLP

[03:43:52 - 03:43:57]
project even you can also perform

[03:43:54 - 03:43:58]
computer vision related project so here

[03:43:57 - 03:44:00]
we are more focusing on the generative

[03:43:58 - 03:44:03]
AI so we'll be using this hugging face

[03:44:00 - 03:44:04]
platform for the gener vi related task

[03:44:03 - 03:44:07]
so this hugging face platform is having

[03:44:04 - 03:44:09]
all kinds of large language model even

[03:44:07 - 03:44:11]
it is also having so many data sets you

[03:44:09 - 03:44:13]
can use to train these kinds of large

[03:44:11 - 03:44:14]
language model and hugging F provides

[03:44:13 - 03:44:16]
one pipeline so with the help of this

[03:44:14 - 03:44:18]
pipeline you can easily perform any

[03:44:16 - 03:44:20]
kinds of task and hugging fish is also

[03:44:18 - 03:44:22]
having one python Library called

[03:44:20 - 03:44:24]
Transformer with the help of Transformer

[03:44:22 - 03:44:26]
Library you can easily Implement any

[03:44:24 - 03:44:28]
kinds of genbi based project so let me

[03:44:26 - 03:44:30]
show you this hugging face platform what

[03:44:28 - 03:44:32]
are the things it is having so guys if

[03:44:30 - 03:44:35]
you want to open the hugging face uh

[03:44:32 - 03:44:37]
platform just search for hugging face

[03:44:35 - 03:44:39]
okay hugging face in Google you will see

[03:44:37 - 03:44:41]
this first link just try to open it up

[03:44:39 - 03:44:43]
and make sure you create one account

[03:44:41 - 03:44:44]
here so for me I already have one

[03:44:43 - 03:44:45]
account so what I will do I'll just try

[03:44:44 - 03:44:47]
to log in with with my account so if you

[03:44:45 - 03:44:49]
don't have the account you just need to

[03:44:47 - 03:44:51]
do the sign up operation okay so with

[03:44:49 - 03:44:52]
your email address you can also create

[03:44:51 - 03:44:54]
an account so let me login with my

[03:44:52 - 03:44:56]
account so guys as you can see I already

[03:44:54 - 03:44:58]
logged in with my account and this is

[03:44:56 - 03:45:00]
the interface of the hugging face now as

[03:44:58 - 03:45:02]
I already told you uh hugging face is a

[03:45:00 - 03:45:04]
platform so with this platform you can

[03:45:02 - 03:45:06]
perform uh lots of task you can perform

[03:45:04 - 03:45:07]
geni related task you can perform

[03:45:06 - 03:45:09]
natural language processing related task

[03:45:07 - 03:45:11]
even you can also perform computer

[03:45:09 - 03:45:13]
vision related task okay even you can

[03:45:11 - 03:45:15]
also do audios kinds of task let's say

[03:45:13 - 03:45:18]
you are having audio data okay you can

[03:45:15 - 03:45:20]
also do these kinds of task in this

[03:45:18 - 03:45:21]
hugging face platform okay now it is

[03:45:20 - 03:45:24]
having actually different different

[03:45:21 - 03:45:26]
Services the first the very popular

[03:45:24 - 03:45:28]
Services it is having called models that

[03:45:26 - 03:45:29]
means this hugging face is having all

[03:45:28 - 03:45:31]
kinds of large language model let me

[03:45:29 - 03:45:34]
show you if I click on the model section

[03:45:31 - 03:45:36]
now see it is having that many of model

[03:45:34 - 03:45:38]
just try to see the count that many of

[03:45:36 - 03:45:40]
models are available and these are the

[03:45:38 - 03:45:41]
models are completely open source so you

[03:45:40 - 03:45:43]
don't need to pay here okay if you want

[03:45:41 - 03:45:45]
to use these are the model you don't

[03:45:43 - 03:45:47]
need to pay here only you just need to

[03:45:45 - 03:45:48]
use hugging face python library for this

[03:45:47 - 03:45:49]
okay with the help of hugging face

[03:45:48 - 03:45:51]
python Library you can easily access

[03:45:49 - 03:45:52]
these other the model even I will also

[03:45:51 - 03:45:54]
tell you how we can access different

[03:45:52 - 03:45:56]
different open source large language

[03:45:54 - 03:45:59]
model and how we can Implement different

[03:45:56 - 03:46:00]
different application on top of it right

[03:45:59 - 03:46:02]
now if you see left hand side it is

[03:46:00 - 03:46:04]
having different different task you can

[03:46:02 - 03:46:06]
select the multi model that means if you

[03:46:04 - 03:46:08]
want to generate image text to text if

[03:46:06 - 03:46:09]
you want to do visual question answering

[03:46:08 - 03:46:11]
if you want to do let's say document

[03:46:09 - 03:46:13]
question answering if you want to let's

[03:46:11 - 03:46:15]
say do video text to text everything you

[03:46:13 - 03:46:17]
can perform here then it is having

[03:46:15 - 03:46:18]
computer vision related task you can

[03:46:17 - 03:46:21]
perform object detection image

[03:46:18 - 03:46:23]
classification image segmentation text

[03:46:21 - 03:46:24]
to image okay all kinds of computer

[03:46:23 - 03:46:26]
vision related task are available even

[03:46:24 - 03:46:29]
nowadays whatever multi model you can

[03:46:26 - 03:46:30]
see let's say uh large language model

[03:46:29 - 03:46:32]
will generate image large language model

[03:46:30 - 03:46:34]
will generate videos these kinds of

[03:46:32 - 03:46:36]
models are also available in this

[03:46:34 - 03:46:37]
hugging F platform now you can see it is

[03:46:36 - 03:46:39]
also having natural language processing

[03:46:37 - 03:46:41]
related task that means you can perform

[03:46:39 - 03:46:43]
text classification to token

[03:46:41 - 03:46:45]
classification summarization feature

[03:46:43 - 03:46:47]
extraction Tex generation code gener

[03:46:45 - 03:46:48]
everything you can perform here okay

[03:46:47 - 03:46:50]
apart from that I already told you it is

[03:46:48 - 03:46:52]
also having some audios model let you

[03:46:50 - 03:46:54]
want to perform text to speech text to

[03:46:52 - 03:46:56]
audio okay automatic speech

[03:46:54 - 03:46:58]
recognization these are the task also

[03:46:56 - 03:46:59]
you can perform here apart from that it

[03:46:58 - 03:47:01]
also provides tabular kinds of task

[03:46:59 - 03:47:02]
let's say you can perform tab

[03:47:01 - 03:47:04]
classification tabular regression time

[03:47:02 - 03:47:06]
series forecasting these are the task

[03:47:04 - 03:47:08]
you can also perform then they they have

[03:47:06 - 03:47:10]
added another amazing technology the

[03:47:08 - 03:47:11]
reinforcement learning so those who are

[03:47:10 - 03:47:14]
interested in reinforcement learing you

[03:47:11 - 03:47:16]
can also perform reinforcement learning

[03:47:14 - 03:47:18]
operation with the help of hugging face

[03:47:16 - 03:47:20]
platform so it is having all kinds of

[03:47:18 - 03:47:22]
reinforcement learning model you can

[03:47:20 - 03:47:23]
also perform something called graph

[03:47:22 - 03:47:26]
machine learning with this hugging face

[03:47:23 - 03:47:28]
platform so here I'm not going to focus

[03:47:26 - 03:47:31]
on all the actually task here because we

[03:47:28 - 03:47:32]
are more focusing on the generative and

[03:47:31 - 03:47:34]
for generative actually we'll be more

[03:47:32 - 03:47:35]
focusing on the NLP that means national

[03:47:34 - 03:47:37]
language processing and we'll be

[03:47:35 - 03:47:38]
focusing on the multimodel section okay

[03:47:37 - 03:47:40]
because it is having different different

[03:47:38 - 03:47:42]
large language model as I already told

[03:47:40 - 03:47:44]
you now you can select any kinds of task

[03:47:42 - 03:47:46]
let's say you want to perform let's say

[03:47:44 - 03:47:49]
uh this one you want to perform let's

[03:47:46 - 03:47:51]
say a text classification okay just

[03:47:49 - 03:47:52]
select the text classification now see

[03:47:51 - 03:47:54]
automatically it will suggest you all

[03:47:52 - 03:47:56]
the text classification related model

[03:47:54 - 03:47:58]
now see these are the model from

[03:47:56 - 03:48:00]
different different organization see

[03:47:58 - 03:48:02]
this model is from meta AI okay Meta

[03:48:00 - 03:48:04]
Meta Lama see with the help of meta Lama

[03:48:02 - 03:48:05]
you can also do text classification and

[03:48:04 - 03:48:07]
this is one of the large language model

[03:48:05 - 03:48:09]
it is having 86 million parameter and

[03:48:07 - 03:48:10]
this is the download see this is that

[03:48:09 - 03:48:13]
that many times actually this model got

[03:48:10 - 03:48:14]
downloaded okay so you can also start

[03:48:13 - 03:48:16]
you can also download this model if you

[03:48:14 - 03:48:18]
are let's say I you like this model you

[03:48:16 - 03:48:19]
can also start this you can also like

[03:48:18 - 03:48:21]
this even they have already given the

[03:48:19 - 03:48:23]
model card let's say you want to read

[03:48:21 - 03:48:25]
about this model like what this model

[03:48:23 - 03:48:27]
can perform how many parameters it is

[03:48:25 - 03:48:28]
having what kinds of data it got PR okay

[03:48:27 - 03:48:29]
everything they have given okay

[03:48:28 - 03:48:31]
everything they have given even they

[03:48:29 - 03:48:33]
have also given the code snippit you can

[03:48:31 - 03:48:35]
use okay let's say you want to test this

[03:48:33 - 03:48:37]
model you can copy this code snippit and

[03:48:35 - 03:48:39]
you can execute it here okay so it's one

[03:48:37 - 03:48:40]
of the amazing platform guys if you are

[03:48:39 - 03:48:42]
working in the field of generative I so

[03:48:40 - 03:48:44]
definitely you should learn the hugging

[03:48:42 - 03:48:45]
face platform and know it to body

[03:48:44 - 03:48:47]
everything I'm going to teach you here

[03:48:45 - 03:48:49]
so let me show you what are the things

[03:48:47 - 03:48:51]
we'll be discussing here see inside

[03:48:49 - 03:48:51]
hugging face

[03:48:52 - 03:48:57]
actually hugging face we have to learn

[03:48:55 - 03:48:58]
some of the very important concept the

[03:48:57 - 03:49:00]
first concept we have to learn the

[03:48:58 - 03:49:01]
pipeline because inside hugging face

[03:49:00 - 03:49:04]
everything is all about pipeline okay

[03:49:01 - 03:49:06]
whenever you'll be using one python

[03:49:04 - 03:49:08]
library of the hugging fish called

[03:49:06 - 03:49:10]
Transformer okay

[03:49:08 - 03:49:12]
Transformers see Transformers is the

[03:49:10 - 03:49:14]
architecture but they have also named it

[03:49:12 - 03:49:16]
as a library okay because it is having

[03:49:14 - 03:49:18]
all the model which is based on the

[03:49:16 - 03:49:19]
Transformer architecture only so that's

[03:49:18 - 03:49:22]
why they name this particular Library as

[03:49:19 - 03:49:23]
a Transformer Library okay so inside

[03:49:22 - 03:49:25]
Transformer Library whenever you will be

[03:49:23 - 03:49:26]
writing the code let's say you want to

[03:49:25 - 03:49:28]
perform language translation

[03:49:26 - 03:49:30]
summarization you have to create a

[03:49:28 - 03:49:31]
pipeline for this okay so we have to

[03:49:30 - 03:49:34]
discuss the pipeline then we'll be

[03:49:31 - 03:49:36]
discussing different different NLP task

[03:49:34 - 03:49:38]
you can perform with the help of this

[03:49:36 - 03:49:39]
hugging face library then we'll be

[03:49:38 - 03:49:42]
discussing very important concept called

[03:49:39 - 03:49:43]
tokenization okay because in hugging

[03:49:42 - 03:49:45]
face everything is all about

[03:49:43 - 03:49:47]
tokenization so whatever pre-processing

[03:49:45 - 03:49:49]
whatever textt representation you have

[03:49:47 - 03:49:50]
to do with the help of tokenization only

[03:49:49 - 03:49:53]
then we'll be discussing about the data

[03:49:50 - 03:49:54]
set like what are the data set it is

[03:49:53 - 03:49:57]
having then we'll be also discussing

[03:49:54 - 03:49:59]
about another super important uh service

[03:49:57 - 03:50:01]
called spaces let's say you don't have

[03:49:59 - 03:50:03]
good configuration PC but you want to

[03:50:01 - 03:50:04]
train one large language model so what

[03:50:03 - 03:50:06]
you can do you can also take the hugging

[03:50:04 - 03:50:08]
face spaces that means hugging face

[03:50:06 - 03:50:10]
infrastructure but definitely you have

[03:50:08 - 03:50:11]
to pay for this so there actually you

[03:50:10 - 03:50:13]
can train any kind of large language

[03:50:11 - 03:50:16]
model okay and this machine is like very

[03:50:13 - 03:50:18]
good configur tion machine you can take

[03:50:16 - 03:50:20]
there then the fifth topic we'll be

[03:50:18 - 03:50:22]
discussing about fine

[03:50:20 - 03:50:26]
tuning okay fine

[03:50:22 - 03:50:28]
tuning llm okay uh with the help of

[03:50:26 - 03:50:30]
hugging F that means we'll be learning

[03:50:28 - 03:50:32]
how we can fine tune any kinds of llm

[03:50:30 - 03:50:34]
okay with help of hugging face platform

[03:50:32 - 03:50:37]
then at the last we'll be seeing some of

[03:50:34 - 03:50:38]
the project implementation okay so with

[03:50:37 - 03:50:40]
the help of hugging face we'll be doing

[03:50:38 - 03:50:41]
some of the project implementation that

[03:50:40 - 03:50:43]
means we'll be doing Tex summarization

[03:50:41 - 03:50:45]
language translation even we'll be also

[03:50:43 - 03:50:46]
doing the research papers summarization

[03:50:45 - 03:50:48]
so these are the project we'll be

[03:50:46 - 03:50:50]
implementing month by month so I hope

[03:50:48 - 03:50:52]
this is enough to know know about

[03:50:50 - 03:50:54]
hugging F and if you understand these

[03:50:52 - 03:50:56]
are the concept definitely you can use

[03:50:54 - 03:50:58]
hugging F platform um if you want to

[03:50:56 - 03:51:00]
build any kinds of application okay

[03:50:58 - 03:51:02]
later on and trust me guys if you want

[03:51:00 - 03:51:05]
to use open source large language model

[03:51:02 - 03:51:07]
that means open llm okay open llm so

[03:51:05 - 03:51:10]
hugging face is the only way okay you

[03:51:07 - 03:51:12]
can use open llm okay hugging face is

[03:51:10 - 03:51:13]
the only platform uh it will help you to

[03:51:12 - 03:51:15]
work with the open source large language

[03:51:13 - 03:51:17]
model but if you want to work with paid

[03:51:15 - 03:51:19]
large language model let's say if I want

[03:51:17 - 03:51:21]
to take any kinds of commercial large

[03:51:19 - 03:51:23]
language model that time you can use

[03:51:21 - 03:51:24]
something called open AI okay open a

[03:51:23 - 03:51:26]
platform even there are some Cloud

[03:51:24 - 03:51:28]
platform as well let's say Bedrock is

[03:51:26 - 03:51:31]
there okay Amazon Bedrock is there then

[03:51:28 - 03:51:32]
vertex AI is also there so we'll be also

[03:51:31 - 03:51:34]
learning these are the things one by one

[03:51:32 - 03:51:36]
no need to worry first of all let's try

[03:51:34 - 03:51:39]
to understand the hugging face because

[03:51:36 - 03:51:40]
uh this is the starting point okay this

[03:51:39 - 03:51:43]
the starting point in the field of

[03:51:40 - 03:51:45]
generative so what I feel like if you

[03:51:43 - 03:51:46]
want to understand the

[03:51:45 - 03:51:47]
if you want to understand the large

[03:51:46 - 03:51:49]
language model if you want to uh let's

[03:51:47 - 03:51:51]
say use them as a practical so I will

[03:51:49 - 03:51:53]
suggest first of all start with hugging

[03:51:51 - 03:51:54]
face platform then try to learn openi

[03:51:53 - 03:51:56]
and whatever Services you are having

[03:51:54 - 03:51:57]
okay everything I going to teach you no

[03:51:56 - 03:51:59]
need to worry okay so apart from that it

[03:51:57 - 03:52:01]
is also having data sets guys as you can

[03:51:59 - 03:52:03]
see different different data sets let's

[03:52:01 - 03:52:06]
say you want to train one language

[03:52:03 - 03:52:08]
translation model so simply you can

[03:52:06 - 03:52:10]
select the task here let's say I want to

[03:52:08 - 03:52:12]
uh do the language translation I select

[03:52:10 - 03:52:14]
the task here so this is the translation

[03:52:12 - 03:52:15]
now see these are the data related langu

[03:52:14 - 03:52:17]
language translation okay see these are

[03:52:15 - 03:52:19]
the data related language translation so

[03:52:17 - 03:52:21]
it is having all kinds of language

[03:52:19 - 03:52:23]
translation data you can see so see this

[03:52:21 - 03:52:25]
data set is containing Canadian actually

[03:52:23 - 03:52:26]
text as well as the English text that

[03:52:25 - 03:52:28]
means you can part from Canadian to

[03:52:26 - 03:52:30]
English otherwise English to Canadian I

[03:52:28 - 03:52:31]
think okay apart from that you are

[03:52:30 - 03:52:34]
having different different data set even

[03:52:31 - 03:52:35]
you can also sarch here if you want to

[03:52:34 - 03:52:37]
let's say find any kind of data set you

[03:52:35 - 03:52:39]
can also search here it is also possible

[03:52:37 - 03:52:40]
now apart from that you can also select

[03:52:39 - 03:52:43]
different different libraries let's say

[03:52:40 - 03:52:45]
I want to perform one task let's say I

[03:52:43 - 03:52:47]
want to find a model let's say I want to

[03:52:45 - 03:52:49]
perform something called uh text

[03:52:47 - 03:52:51]
classification now I want to use one

[03:52:49 - 03:52:52]
specific Library so see it is having

[03:52:51 - 03:52:55]
different different Library you can use

[03:52:52 - 03:52:57]
P torch then you can use transer flow

[03:52:55 - 03:52:59]
then you have safe transource okay then

[03:52:57 - 03:53:00]
you are having kasas different different

[03:52:59 - 03:53:03]
Library it supports let's I want to

[03:53:00 - 03:53:05]
perform with the help of pytorch okay py

[03:53:03 - 03:53:06]
toor framework so these are the model

[03:53:05 - 03:53:08]
related pytorch so if you want to use

[03:53:06 - 03:53:10]
these are the model you have to use

[03:53:08 - 03:53:11]
pytorch code so similar wise if you want

[03:53:10 - 03:53:13]
to perform with the help of let's say

[03:53:11 - 03:53:14]
tensor flow you can select the tensor

[03:53:13 - 03:53:16]
flow it will give you all the model

[03:53:14 - 03:53:18]
related tensor flow that time okay that

[03:53:16 - 03:53:20]
time you have to install tensorflow

[03:53:18 - 03:53:21]
Library okay not the py library so

[03:53:20 - 03:53:22]
that's how it has given different

[03:53:21 - 03:53:24]
different flexibility different

[03:53:22 - 03:53:26]
different functionality so that you can

[03:53:24 - 03:53:28]
filter out filter out the specific model

[03:53:26 - 03:53:30]
filter out the specific data okay

[03:53:28 - 03:53:32]
everything you can do here and it is

[03:53:30 - 03:53:33]
having another uh amazing Service as I

[03:53:32 - 03:53:36]
already told you the spaces so spaces

[03:53:33 - 03:53:37]
will give you let's say uh this

[03:53:36 - 03:53:39]
infrastructure if you want to train any

[03:53:37 - 03:53:40]
kinds of large language model you can

[03:53:39 - 03:53:42]
use their spaces service so there you

[03:53:40 - 03:53:44]
can buy their instance and you can train

[03:53:42 - 03:53:45]
your model see it is having different

[03:53:44 - 03:53:47]
different spaces even you you can also

[03:53:45 - 03:53:49]
create your own spaces now apart from

[03:53:47 - 03:53:50]
that it is having another amazing

[03:53:49 - 03:53:53]
documentation now see if you want to

[03:53:50 - 03:53:54]
Deep dive uh in this hugging face

[03:53:53 - 03:53:56]
platform like how you can use this

[03:53:54 - 03:53:58]
hugging face platform properly so they

[03:53:56 - 03:54:00]
are also having their official tutorials

[03:53:58 - 03:54:02]
if you just go to the documentation so

[03:54:00 - 03:54:03]
there they are having one uh

[03:54:02 - 03:54:05]
documentation and inside that you will

[03:54:03 - 03:54:07]
get one section called task now let's

[03:54:05 - 03:54:09]
click on the task now see let's say I

[03:54:07 - 03:54:11]
want to perform image classification

[03:54:09 - 03:54:12]
task so I'll just simply click here now

[03:54:11 - 03:54:14]
see it will give me the official

[03:54:12 - 03:54:16]
tutorial so they have their the YouTube

[03:54:14 - 03:54:18]
videos you can also refer the YouTube

[03:54:16 - 03:54:20]
videos even you can also refer their

[03:54:18 - 03:54:21]
blog okay how we can perform the text

[03:54:20 - 03:54:23]
classification that time sorry how we

[03:54:21 - 03:54:25]
can perform the image classification so

[03:54:23 - 03:54:27]
everything they have written here okay

[03:54:25 - 03:54:29]
so this is one of the amazing actually

[03:54:27 - 03:54:31]
let's say platform I personally prefer

[03:54:29 - 03:54:32]
if I want to implement any kinds of

[03:54:31 - 03:54:33]
project and if you want to learn

[03:54:32 - 03:54:35]
anything let's say I don't know about

[03:54:33 - 03:54:37]
let's say zero short image

[03:54:35 - 03:54:39]
classification I will go I'll come here

[03:54:37 - 03:54:41]
I'll go to their tutorial section and

[03:54:39 - 03:54:43]
easily I can learn okay how we can use

[03:54:41 - 03:54:44]
this particular model okay so that's how

[03:54:43 - 03:54:46]
actually you can also Deep dive but if

[03:54:44 - 03:54:48]
you cover this video I hope you'll be

[03:54:46 - 03:54:50]
learning everything about this hugging F

[03:54:48 - 03:54:52]
platform but still if you want to dip

[03:54:50 - 03:54:54]
dive you can refer their tutorial as

[03:54:52 - 03:54:56]
well fine and if you want to take their

[03:54:54 - 03:54:58]
premium subscription you can also see

[03:54:56 - 03:55:00]
their pricing and all you can also check

[03:54:58 - 03:55:01]
it up but as of now premium subscription

[03:55:00 - 03:55:03]
is not required we'll be using free

[03:55:01 - 03:55:04]
services okay free services is enough

[03:55:03 - 03:55:06]
for us because here we'll be only

[03:55:04 - 03:55:08]
accessing the models data set okay these

[03:55:06 - 03:55:09]
are the thing as of now I'm not going to

[03:55:08 - 03:55:11]
take this spaces everything I'll be

[03:55:09 - 03:55:13]
doing in my Google collab because in

[03:55:11 - 03:55:14]
Google collab we'll be getting free gpus

[03:55:13 - 03:55:17]
okay that is the idea so yes guys this

[03:55:14 - 03:55:18]
is the introduction of the hugging phase

[03:55:17 - 03:55:21]
now I think you got it what exactly this

[03:55:18 - 03:55:22]
hugging phase is and uh we saw like

[03:55:21 - 03:55:25]
different different Services of the

[03:55:22 - 03:55:27]
hugging face now in the next video uh

[03:55:25 - 03:55:28]
we'll be doing some handson on top of

[03:55:27 - 03:55:29]
the hugging face like how we can use the

[03:55:28 - 03:55:31]
hugging face with the help of Python

[03:55:29 - 03:55:33]
Programming so there we'll be installing

[03:55:31 - 03:55:34]
my amazing Library called Transformer

[03:55:33 - 03:55:37]
okay with the help of Transformer we'll

[03:55:34 - 03:55:38]
be using the hugging face and it is also

[03:55:37 - 03:55:41]
give you the API functionality guys if

[03:55:38 - 03:55:42]
you want to take the hugging F API key

[03:55:41 - 03:55:44]
you can also take for this you have to

[03:55:42 - 03:55:46]
go to the settings now here you having

[03:55:44 - 03:55:47]
something called access token okay you

[03:55:46 - 03:55:49]
can also take the access token so with

[03:55:47 - 03:55:50]
the help of access access token also we

[03:55:49 - 03:55:53]
can access the model let's say some of

[03:55:50 - 03:55:54]
the models you will be getting here

[03:55:53 - 03:55:55]
those model actually you can directly

[03:55:54 - 03:55:58]
download for this you need this hugging

[03:55:55 - 03:55:59]
F access token okay so we'll be also

[03:55:58 - 03:56:01]
learning how we can use the access token

[03:55:59 - 03:56:02]
to access any kinds of model and how we

[03:56:01 - 03:56:05]
can generate these are the access token

[03:56:02 - 03:56:07]
as well so here I already created one uh

[03:56:05 - 03:56:08]
collab notebook and here I have already

[03:56:07 - 03:56:10]
mentioned each and everything you need

[03:56:08 - 03:56:12]
uh for the hugging face okay practical

[03:56:10 - 03:56:14]
understanding so as I already told you

[03:56:12 - 03:56:16]
if I want to use hugging face platform

[03:56:14 - 03:56:17]
form with the help of python we need to

[03:56:16 - 03:56:19]
install one Library called Transformers

[03:56:17 - 03:56:21]
okay so this is the library so

[03:56:19 - 03:56:23]
Transformers Library is having all the

[03:56:21 - 03:56:25]
functionality uh present inside the

[03:56:23 - 03:56:27]
hugging face platform right so if you

[03:56:25 - 03:56:28]
want to install Transformer Library so

[03:56:27 - 03:56:31]
you have to execute this command called

[03:56:28 - 03:56:33]
pip install uh Transformers okay now let

[03:56:31 - 03:56:35]
me first of all connect this

[03:56:33 - 03:56:37]
notebook and the resources should be

[03:56:35 - 03:56:39]
shared guys in the resources section so

[03:56:37 - 03:56:42]
from there you can download and you can

[03:56:39 - 03:56:44]
also um code with me okay it is

[03:56:42 - 03:56:45]
connected now now the first thing what

[03:56:44 - 03:56:48]
what you have to do you have to select

[03:56:45 - 03:56:49]
the run time uh to GPU okay because I'm

[03:56:48 - 03:56:51]
I'm not going to use the CPU

[03:56:49 - 03:56:52]
configuration machine here I'll be

[03:56:51 - 03:56:54]
taking the GPU machine because here

[03:56:52 - 03:56:56]
we'll be using large language model so

[03:56:54 - 03:56:58]
definitely uh you have to select the GPU

[03:56:56 - 03:56:59]
based machine there fine so let me

[03:56:58 - 03:57:01]
select the GPU machine and if you're

[03:56:59 - 03:57:03]
using free collab you'll be getting T4

[03:57:01 - 03:57:05]
GPU and if you're using collab Pro uh

[03:57:03 - 03:57:07]
there also you can take actually

[03:57:05 - 03:57:09]
different different uh see let me show

[03:57:07 - 03:57:12]
you if I click on since run type see you

[03:57:09 - 03:57:13]
can also take a00 GPU and L4 GPU as well

[03:57:12 - 03:57:15]
okay these are the GPU you can also

[03:57:13 - 03:57:17]
access so now guys you can see my

[03:57:15 - 03:57:19]
notebook is connected now if I want to

[03:57:17 - 03:57:20]
check the GPU you can execute this

[03:57:19 - 03:57:24]
command called

[03:57:20 - 03:57:27]
Nvidia okay hen SMI so this will uh show

[03:57:24 - 03:57:28]
you the GPU configuration you got so

[03:57:27 - 03:57:31]
here I'm using free collab that's why I

[03:57:28 - 03:57:34]
got Tesla T4 GPU now first of all I have

[03:57:31 - 03:57:34]
to install the Transformer Library

[03:57:40 - 03:57:45]
here see Transformer is already

[03:57:43 - 03:57:47]
installed now now see inside hugging

[03:57:45 - 03:57:48]
face we are having different different

[03:57:47 - 03:57:50]
task as I already showed you so if I

[03:57:48 - 03:57:51]
let's say click on the models and if you

[03:57:50 - 03:57:53]
see the left hand side you can see you

[03:57:51 - 03:57:54]
are having different different task so

[03:57:53 - 03:57:56]
here you are having different different

[03:57:54 - 03:57:57]
task let's say uh here we are focusing

[03:57:56 - 03:58:00]
on generative AI that means the natural

[03:57:57 - 03:58:01]
language processing so here we can

[03:58:00 - 03:58:03]
perform different different tasks let's

[03:58:01 - 03:58:06]
say we can perform text classification

[03:58:03 - 03:58:07]
uh token classification okay all kinds

[03:58:06 - 03:58:10]
of tasks actually can perform whatever

[03:58:07 - 03:58:12]
task actually you in the field of NLP or

[03:58:10 - 03:58:14]
in the field of let's say generative all

[03:58:12 - 03:58:16]
kinds of task you can perform here so if

[03:58:14 - 03:58:18]
I want to perform these other the task I

[03:58:16 - 03:58:21]
have to use one uh functionality from

[03:58:18 - 03:58:22]
the hugging fist called pipeline okay so

[03:58:21 - 03:58:24]
here you can see I have imported this

[03:58:22 - 03:58:26]
pipeline from the Transformer okay so it

[03:58:24 - 03:58:28]
is available inside Transformer now

[03:58:26 - 03:58:30]
let's say uh we are having various uh

[03:58:28 - 03:58:32]
NLP task as I already showed you text

[03:58:30 - 03:58:33]
classification then we are having uh

[03:58:32 - 03:58:36]
here you can see text classification

[03:58:33 - 03:58:37]
token classification uh table question

[03:58:36 - 03:58:39]
answering question answering zero shot

[03:58:37 - 03:58:41]
classification translation okay now see

[03:58:39 - 03:58:43]
I have listed down all the task here now

[03:58:41 - 03:58:44]
let's say if I want to perform text

[03:58:43 - 03:58:45]
classification so what you have to do

[03:58:44 - 03:58:47]
inside pipeline you have to mention I

[03:58:45 - 03:58:49]
want to perform text classification so

[03:58:47 - 03:58:51]
this Transformer Library what it will do

[03:58:49 - 03:58:53]
it will automatically try to understand

[03:58:51 - 03:58:55]
you want to perform test classification

[03:58:53 - 03:58:57]
so all the code actually it is having in

[03:58:55 - 03:58:58]
the back end it will execute that

[03:58:57 - 03:59:01]
particular code CIP it that means it's a

[03:58:58 - 03:59:03]
high level raer okay on top of let's say

[03:59:01 - 03:59:05]
hugging face it's a high level rapper

[03:59:03 - 03:59:06]
this particular Transformer Library so

[03:59:05 - 03:59:08]
you don't need to write the code from

[03:59:06 - 03:59:10]
scratch let's say you don't need to

[03:59:08 - 03:59:12]
write the code I want to perform uh text

[03:59:10 - 03:59:14]
classification so code you don't need to

[03:59:12 - 03:59:16]
write from scratch only just need to

[03:59:14 - 03:59:19]
give this particular input to the

[03:59:16 - 03:59:21]
pipeline and pipeline will automatically

[03:59:19 - 03:59:23]
take care you have to do the uh text

[03:59:21 - 03:59:24]
classification task and for this

[03:59:23 - 03:59:27]
whatever uh let's say strategy you have

[03:59:24 - 03:59:29]
to follow everything it will take care

[03:59:27 - 03:59:31]
okay I hope you got it now see similar

[03:59:29 - 03:59:32]
wise if you want to perform token

[03:59:31 - 03:59:34]
classification you can mention token

[03:59:32 - 03:59:35]
classification if you want to perform

[03:59:34 - 03:59:36]
question answer you can also give

[03:59:35 - 03:59:39]
question answering if you want to

[03:59:36 - 03:59:41]
perform text generation summarization

[03:59:39 - 03:59:42]
translation even also you can select the

[03:59:41 - 03:59:44]
model let's say which model you want to

[03:59:42 - 03:59:46]
use as I already showed you now now we

[03:59:44 - 03:59:48]
are having so many model now let's say I

[03:59:46 - 03:59:50]
want to perform uh translation now see

[03:59:48 - 03:59:51]
you are having different different model

[03:59:50 - 03:59:53]
OKAY different different model now see

[03:59:51 - 03:59:55]
you can also give the model OKAY model

[03:59:53 - 03:59:57]
ID now let's say I want to use this

[03:59:55 - 03:59:59]
model I'll just click here and I'll copy

[03:59:57 - 04:00:01]
the model ID this the model I'll copy

[03:59:59 - 04:00:02]
and here I just need to mention so it

[04:00:01 - 04:00:04]
will automatically download this model

[04:00:02 - 04:00:06]
from the hugging face so you don't need

[04:00:04 - 04:00:09]
to manually download it as well so that

[04:00:06 - 04:00:10]
must powerful it is okay so that is why

[04:00:09 - 04:00:12]
I told you you have to master this

[04:00:10 - 04:00:14]
pipeline concept because going forward

[04:00:12 - 04:00:16]
whatever let's say you'll be

[04:00:14 - 04:00:18]
implementing you need this particular

[04:00:16 - 04:00:19]
pipeline approach fine now see I have

[04:00:18 - 04:00:21]
given different different actually

[04:00:19 - 04:00:22]
example computer vision example also

[04:00:21 - 04:00:24]
let's say you want to part from image

[04:00:22 - 04:00:26]
classification in the pipeline just

[04:00:24 - 04:00:28]
mention image classification okay even

[04:00:26 - 04:00:29]
also you can specify the model it's up

[04:00:28 - 04:00:31]
to you now see different different

[04:00:29 - 04:00:32]
example I have given just for your

[04:00:31 - 04:00:35]
reference so that you can refer this

[04:00:32 - 04:00:36]
notebook later on now let's perform one

[04:00:35 - 04:00:39]
specific NLP task let's say I want to

[04:00:36 - 04:00:41]
perform sentiment analysis so here you

[04:00:39 - 04:00:43]
can see the task as well as uh you will

[04:00:41 - 04:00:46]
also get the all kinds of task in the

[04:00:43 - 04:00:48]
document section so here you are having

[04:00:46 - 04:00:50]
one tab called task now see all the task

[04:00:48 - 04:00:52]
is also visible red computer vision naal

[04:00:50 - 04:00:54]
language processing audios and multim

[04:00:52 - 04:00:56]
model okay everything is there now let's

[04:00:54 - 04:00:57]
say I want to perform sentiment analysis

[04:00:56 - 04:01:00]
and sentiment analysis is what kinds of

[04:00:57 - 04:01:02]
task it's a text classification task I

[04:01:00 - 04:01:04]
think you saw it's a text classification

[04:01:02 - 04:01:06]
task okay now either you can give the

[04:01:04 - 04:01:08]
text classification okay either you can

[04:01:06 - 04:01:10]
pass the text classification here either

[04:01:08 - 04:01:11]
you can also give the sentiment analysis

[04:01:10 - 04:01:13]
okay both it will work so I have given

[04:01:11 - 04:01:15]
sentiment analysis okay I want to

[04:01:13 - 04:01:16]
perform sentiment analysis in the

[04:01:15 - 04:01:18]
pipeline now it will give you one object

[04:01:16 - 04:01:20]
called pipeline object and this is my

[04:01:18 - 04:01:22]
classifier now inside that you have to

[04:01:20 - 04:01:25]
pass the input let's say here I given

[04:01:22 - 04:01:28]
the input I was uh so not happy with the

[04:01:25 - 04:01:30]
last mission impossible movie now this

[04:01:28 - 04:01:32]
is the sentence I have given now see if

[04:01:30 - 04:01:34]
I execute this line of code so it will

[04:01:32 - 04:01:36]
automatically download one specific

[04:01:34 - 04:01:38]
model now see here I haven't given any

[04:01:36 - 04:01:40]
kinds of model name so it will download

[04:01:38 - 04:01:41]
one default model and it will try to

[04:01:40 - 04:01:43]
predict whether this particular

[04:01:41 - 04:01:47]
sentiment is a positive or negative okay

[04:01:43 - 04:01:50]
let me show you see if I execute this

[04:01:47 - 04:01:53]
code see it is using one model default

[04:01:50 - 04:01:57]
model called um distill bbased case Okay

[04:01:53 - 04:01:58]
F tune SST to English model and this is

[04:01:57 - 04:02:00]
the link of the model if I open it up

[04:01:58 - 04:02:02]
see it is using this model this is the

[04:02:00 - 04:02:04]
default model okay and here is the

[04:02:02 - 04:02:08]
prediction guys it's a negative

[04:02:04 - 04:02:10]
sentiment and it is telling 99 99%

[04:02:08 - 04:02:13]
confidence it's a negative sentiment

[04:02:10 - 04:02:15]
okay that mean it is performing amazing

[04:02:13 - 04:02:18]
see that much actually it is easy to use

[04:02:15 - 04:02:19]
this Transformer library and that's how

[04:02:18 - 04:02:21]
actually pipeline helps us to perform

[04:02:19 - 04:02:23]
any kinds of task I want to perform so I

[04:02:21 - 04:02:25]
don't need to write the code from

[04:02:23 - 04:02:26]
scratch only I just need to mention the

[04:02:25 - 04:02:28]
specific task name it will automatically

[04:02:26 - 04:02:30]
do it for me now there is another way

[04:02:28 - 04:02:32]
you can pass the input let's say so

[04:02:30 - 04:02:34]
let's say here is my pipeline inside

[04:02:32 - 04:02:36]
pipeline you can mention the task I want

[04:02:34 - 04:02:38]
to perform let's say a sentiment

[04:02:36 - 04:02:40]
analysis and the second parameter you

[04:02:38 - 04:02:41]
can give the input let's say this is the

[04:02:40 - 04:02:44]
input I have given I was confused with

[04:02:41 - 04:02:46]
the Barbie movie okay now now it will

[04:02:44 - 04:02:47]
give you the same output so either you

[04:02:46 - 04:02:48]
can follow this approach either you can

[04:02:47 - 04:02:50]
follow this approach this is the one

[04:02:48 - 04:02:52]
line approach okay so both it is

[04:02:50 - 04:02:54]
possible now if you are having any big

[04:02:52 - 04:02:56]
text that time what you can do you can

[04:02:54 - 04:02:58]
also use multi-line actually string

[04:02:56 - 04:03:01]
there also you can pass the text like

[04:02:58 - 04:03:03]
that see again it's a positive review

[04:03:01 - 04:03:05]
and this is the confidence score

[04:03:03 - 04:03:08]
fine now let me show you how we can

[04:03:05 - 04:03:09]
specify any kinds of model so let's say

[04:03:08 - 04:03:11]
now I want to perform sentiment analysis

[04:03:09 - 04:03:13]
and I want to use any other model let's

[04:03:11 - 04:03:15]
say I want to use this model Facebook

[04:03:13 - 04:03:18]
Bart large M let me search this model

[04:03:15 - 04:03:19]
you'll see this is one of the large

[04:03:18 - 04:03:24]
language

[04:03:19 - 04:03:25]
model you can see but large uh mnl see

[04:03:24 - 04:03:28]
again it's not a large language model I

[04:03:25 - 04:03:29]
can say it's a language model because

[04:03:28 - 04:03:32]
this model only can perform one specific

[04:03:29 - 04:03:34]
task which is nothing but the um

[04:03:32 - 04:03:35]
sentiment analysis but going forward

[04:03:34 - 04:03:39]
we'll be using large language model like

[04:03:35 - 04:03:41]
we'll be using Lama mistal Falcon jini

[04:03:39 - 04:03:42]
okay so these are the model actually

[04:03:41 - 04:03:44]
we'll be using and these are the model

[04:03:42 - 04:03:46]
is multitasking model model okay that

[04:03:44 - 04:03:48]
means large language model so there are

[04:03:46 - 04:03:51]
two kinds of models are available guys

[04:03:48 - 04:03:54]
uh just try to remember one is the large

[04:03:51 - 04:03:56]
language model that means llm okay and

[04:03:54 - 04:03:58]
this is like only LM that means language

[04:03:56 - 04:04:00]
model only so language model can only

[04:03:58 - 04:04:02]
perform one specific task okay one

[04:04:00 - 04:04:04]
specific task and large language model

[04:04:02 - 04:04:07]
can perform multiple

[04:04:04 - 04:04:10]
task multiple

[04:04:07 - 04:04:12]
task even it can also perform chat

[04:04:10 - 04:04:15]
operation okay chat operation because I

[04:04:12 - 04:04:17]
already told you now how large language

[04:04:15 - 04:04:19]
model was trained okay because of that

[04:04:17 - 04:04:21]
supervised fine tuning reinforcement

[04:04:19 - 04:04:23]
learning through human feedback these

[04:04:21 - 04:04:25]
are the technique has applied but

[04:04:23 - 04:04:26]
whatever LM model you can see it has

[04:04:25 - 04:04:28]
only trained with the transform

[04:04:26 - 04:04:30]
Transformer architecture okay

[04:04:28 - 04:04:32]
Transformer architecture okay I think I

[04:04:30 - 04:04:34]
showed you the transform architecture

[04:04:32 - 04:04:35]
example I think you remember fine so

[04:04:34 - 04:04:37]
these are the model we using this is

[04:04:35 - 04:04:39]
called actually language model only it

[04:04:37 - 04:04:41]
can only perform one specific task so

[04:04:39 - 04:04:43]
that's why here we are mentioning the

[04:04:41 - 04:04:44]
task name sentiment analysis now see

[04:04:43 - 04:04:46]
here we are giving the model name now

[04:04:44 - 04:04:48]
you can use any kinds of model just go

[04:04:46 - 04:04:50]
to the model section go to the model

[04:04:48 - 04:04:52]
section now let's say I want to perform

[04:04:50 - 04:04:55]
sentiment analyis for this I have to use

[04:04:52 - 04:04:56]
text classification now just try to get

[04:04:55 - 04:05:00]
any kinds of model let's say you want to

[04:04:56 - 04:05:02]
use this model copy the model ID try to

[04:05:00 - 04:05:04]
paste it here okay it will download that

[04:05:02 - 04:05:05]
model and it will do the operation now

[04:05:04 - 04:05:06]
let me show you see first of all this

[04:05:05 - 04:05:08]
model will be downloaded from the

[04:05:06 - 04:05:11]
hugging F now see it is downloaded and

[04:05:08 - 04:05:13]
see the model size it's around 1.63 GB

[04:05:11 - 04:05:15]
this is actually sentiment I'm getting

[04:05:13 - 04:05:17]
this neutral sentiment okay it's not a

[04:05:15 - 04:05:18]
positive it's not a negative it's a

[04:05:17 - 04:05:21]
neutral sentiment and this is The

[04:05:18 - 04:05:24]
Confidence Code you are getting fine

[04:05:21 - 04:05:25]
great now how to perform the batch

[04:05:24 - 04:05:28]
actually sentiment if you're having

[04:05:25 - 04:05:30]
batch data let's say multiple let's say

[04:05:28 - 04:05:31]
uh sentence that time how we can do you

[04:05:30 - 04:05:33]
can use something called B sentiment

[04:05:31 - 04:05:36]
analysis so again just try to create a

[04:05:33 - 04:05:38]
pipeline and whenever you are preparing

[04:05:36 - 04:05:39]
your input data just try to uh give

[04:05:38 - 04:05:40]
inside a list you can see it's a python

[04:05:39 - 04:05:42]
list and inside that I'm having

[04:05:40 - 04:05:44]
different different sentence okay

[04:05:42 - 04:05:45]
different different sentence now you

[04:05:44 - 04:05:48]
have to pass this particular uh list

[04:05:45 - 04:05:50]
inside your classifier now see it will

[04:05:48 - 04:05:52]
take one by one all the sentence and it

[04:05:50 - 04:05:54]
will show you the uh sentiment now see

[04:05:52 - 04:05:56]
this is the first sentence sentiment

[04:05:54 - 04:05:58]
second sentence third sentence and

[04:05:56 - 04:05:59]
fourth sentence okay I hope it is clear

[04:05:58 - 04:06:02]
but the model actually it is using the

[04:05:59 - 04:06:03]
default model uh it is having only two

[04:06:02 - 04:06:05]
level which is nothing but positive and

[04:06:03 - 04:06:08]
negative but if you see this sentence it

[04:06:05 - 04:06:09]
is having some emotion okay it is having

[04:06:08 - 04:06:10]
some different different sentiment and

[04:06:09 - 04:06:11]
if you want to capture different

[04:06:10 - 04:06:13]
different sentiments you can use any

[04:06:11 - 04:06:15]
other model let's say I will be using

[04:06:13 - 04:06:18]
this model robot based go emotion model

[04:06:15 - 04:06:20]
so this can actually detect multiple uh

[04:06:18 - 04:06:21]
sentiment from a sentence okay you can

[04:06:20 - 04:06:23]
see all kinds of sentiment they have

[04:06:21 - 04:06:25]
mentioned see these are the sentiment it

[04:06:23 - 04:06:27]
is having okay so that many of sentiment

[04:06:25 - 04:06:29]
it can detect now let me use this model

[04:06:27 - 04:06:32]
and let me again apply the same data now

[04:06:29 - 04:06:34]
see it will give you different different

[04:06:32 - 04:06:36]
sentiment see again it is downloading

[04:06:34 - 04:06:38]
the model after that it will do the

[04:06:36 - 04:06:41]
sentiment analysis now the first

[04:06:38 - 04:06:44]
sentence it is uh admiration second one

[04:06:41 - 04:06:46]
confusion then uh

[04:06:44 - 04:06:48]
Amusement then anger okay I hope you're

[04:06:46 - 04:06:50]
cleared so I can say this is one of the

[04:06:48 - 04:06:53]
very powerful Library okay if you want

[04:06:50 - 04:06:55]
to work in the field of gen or natural

[04:06:53 - 04:06:57]
language processing now you can also

[04:06:55 - 04:06:58]
perform T generation task so for this in

[04:06:57 - 04:07:00]
the pipeline you have to mention T

[04:06:58 - 04:07:02]
generation only okay I think I showed

[04:07:00 - 04:07:04]
you different different task that's I

[04:07:02 - 04:07:05]
want to perform TCH generation right now

[04:07:04 - 04:07:07]
so Tech generation I think it is there

[04:07:05 - 04:07:10]
natural language processing text

[04:07:07 - 04:07:12]
generation okay now see they have also

[04:07:10 - 04:07:14]
mentioned in the tutorial you have to

[04:07:12 - 04:07:16]
give Tex generation in the pipeline okay

[04:07:14 - 04:07:17]
and you can also give the model so the

[04:07:16 - 04:07:20]
same thing I'm doing TCH generation

[04:07:17 - 04:07:21]
model I'm using distill but and inside

[04:07:20 - 04:07:24]
that I'm passing my input today is the

[04:07:21 - 04:07:25]
rainy day in London now it will refer

[04:07:24 - 04:07:27]
this sentence and it will generate the

[04:07:25 - 04:07:30]
text okay based on this particular

[04:07:27 - 04:07:30]
content now if I execute

[04:07:33 - 04:07:36]
see see guys beautifully it has

[04:07:35 - 04:07:39]
generated the text today is rainy day in

[04:07:36 - 04:07:42]
London and one that no other City can

[04:07:39 - 04:07:44]
remember orever uh even no a few days

[04:07:42 - 04:07:46]
year ago the police arrested okay see

[04:07:44 - 04:07:47]
beautifully it has generated the text

[04:07:46 - 04:07:49]
okay so that's actually you can also

[04:07:47 - 04:07:50]
perform Tex generation now if you want

[04:07:49 - 04:07:52]
to perform question answering just give

[04:07:50 - 04:07:54]
question answering and you have to give

[04:07:52 - 04:07:57]
the question as well as the context okay

[04:07:54 - 04:07:59]
so based on the context it will uh so by

[04:07:57 - 04:08:01]
refering this context it will uh give

[04:07:59 - 04:08:02]
you give you the answer okay let's say

[04:08:01 - 04:08:04]
this is my question what is my job and

[04:08:02 - 04:08:06]
here I'm giving the context I'm

[04:08:04 - 04:08:08]
developing an AI model with the python

[04:08:06 - 04:08:09]
okay now if I give my question as well

[04:08:08 - 04:08:13]
as the context it will give me the

[04:08:09 - 04:08:17]
answer again you can check their uh

[04:08:13 - 04:08:17]
document ation for the question

[04:08:17 - 04:08:22]
answering question answering so they're

[04:08:21 - 04:08:24]
telling like that so you have to give

[04:08:22 - 04:08:28]
the question context and you have to

[04:08:24 - 04:08:30]
pass to the uh pipeline okay now see uh

[04:08:28 - 04:08:34]
answer is developing AI model that means

[04:08:30 - 04:08:36]
this is my job okay I hope it is clear

[04:08:34 - 04:08:38]
so I hope guys uh now it is clear how we

[04:08:36 - 04:08:40]
can use this uh hugging face platform if

[04:08:38 - 04:08:41]
I want to perform different different

[04:08:40 - 04:08:43]
task and how we can access different

[04:08:41 - 04:08:45]
different model now let's see want to

[04:08:43 - 04:08:47]
use large language model that means llm

[04:08:45 - 04:08:51]
so I think I showed you one uh amazing

[04:08:47 - 04:08:53]
uh GitHub open llm GitHub so you can

[04:08:51 - 04:08:54]
open this GitHub and you can see

[04:08:53 - 04:08:57]
different different large language model

[04:08:54 - 04:09:00]
name let's say you want to use this

[04:08:57 - 04:09:00]
model let's say you want to use

[04:09:00 - 04:09:04]
um let's see we want to use this Falcon

[04:09:03 - 04:09:06]
model falcon is a large language model

[04:09:04 - 04:09:08]
you can copy the name and simply you can

[04:09:06 - 04:09:11]
go to the hugging face go to the model

[04:09:08 - 04:09:15]
section and simply s

[04:09:11 - 04:09:17]
here okay simply s here now see Falcon

[04:09:15 - 04:09:19]
model would be there see Falcon models

[04:09:17 - 04:09:20]
is there and Falcon is nothing but it's

[04:09:19 - 04:09:22]
a large language model it's not a

[04:09:20 - 04:09:24]
language model okay with the help of

[04:09:22 - 04:09:26]
Falcon actually we can perform different

[04:09:24 - 04:09:29]
different task even we can also perform

[04:09:26 - 04:09:30]
chart operation not only that all kinds

[04:09:29 - 04:09:32]
of models are available let me show you

[04:09:30 - 04:09:34]
let's say Lama 2 if you want to use l 2

[04:09:32 - 04:09:38]
I'll copy and I'll come here I'll search

[04:09:34 - 04:09:40]
for the Lama 2 see Lama 2 is from M okay

[04:09:38 - 04:09:42]
like that we are having some another

[04:09:40 - 04:09:45]
model Also let's say mral is there then

[04:09:42 - 04:09:47]
we are having something called Jimma so

[04:09:45 - 04:09:48]
this model is from Google site so that's

[04:09:47 - 04:09:49]
how we are having different different

[04:09:48 - 04:09:51]
large language model and no need to

[04:09:49 - 04:09:53]
worry going forward we'll be using these

[04:09:51 - 04:09:54]
other the model but before using these

[04:09:53 - 04:09:56]
are the model uh we have to learn some

[04:09:54 - 04:09:58]
additional let's say um tools and

[04:09:56 - 04:10:01]
Technology like we'll be learning some

[04:09:58 - 04:10:03]
gen VI framework like Lama index then

[04:10:01 - 04:10:05]
langin then we'll be also learning about

[04:10:03 - 04:10:06]
Vector database okay then we'll be

[04:10:05 - 04:10:08]
learning these are the model as well

[04:10:06 - 04:10:11]
fine so yes guys this is all about from

[04:10:08 - 04:10:13]
this video I hope it is uh clear now so

[04:10:11 - 04:10:15]
in the next video we'll be understanding

[04:10:13 - 04:10:17]
about tokenizer uh tokenizer inside

[04:10:15 - 04:10:19]
actually hugging face what exactly this

[04:10:17 - 04:10:21]
tokenizer okay and why we need it okay

[04:10:19 - 04:10:23]
why tokenization is required so as I

[04:10:21 - 04:10:25]
already told you inside hugging face

[04:10:23 - 04:10:27]
actually we're having another uh super

[04:10:25 - 04:10:29]
important concept called

[04:10:27 - 04:10:30]
tokenization and now we'll try to

[04:10:29 - 04:10:32]
understand why tokenization is important

[04:10:30 - 04:10:34]
and why we use tokenization inside

[04:10:32 - 04:10:36]
hugging pH I think you remember I taught

[04:10:34 - 04:10:39]
you one concept called text reprocessing

[04:10:36 - 04:10:41]
and text representation so there uh

[04:10:39 - 04:10:42]
whenever I was passing any kinds of text

[04:10:41 - 04:10:44]
to my model first of all I was doing the

[04:10:42 - 04:10:45]
processing then I was converting that

[04:10:44 - 04:10:47]
particular text to the vector

[04:10:45 - 04:10:49]
representation right and for this I was

[04:10:47 - 04:10:51]
using different different technique like

[04:10:49 - 04:10:54]
for text vectorization I was using TF

[04:10:51 - 04:10:56]
Ida what to F bag of word then that time

[04:10:54 - 04:10:57]
actually I told you we are also having

[04:10:56 - 04:10:59]
some other technique which is nothing

[04:10:57 - 04:11:00]
but Transformer based technique okay

[04:10:59 - 04:11:03]
because it is having something called

[04:11:00 - 04:11:05]
attention mechanism and uh then I taught

[04:11:03 - 04:11:07]
you the attention mechanism concept the

[04:11:05 - 04:11:09]
Transformer architecture so there I show

[04:11:07 - 04:11:11]
you how it will give the attention to a

[04:11:09 - 04:11:13]
specific word now it's time to show you

[04:11:11 - 04:11:14]
this part as a practical that means now

[04:11:13 - 04:11:16]
we are using Transformer based

[04:11:14 - 04:11:18]
architecture Transformer based model and

[04:11:16 - 04:11:19]
whatever data see whatever data actually

[04:11:18 - 04:11:22]
we're passing as an input to my model

[04:11:19 - 04:11:24]
okay so internally how it is processing

[04:11:22 - 04:11:25]
that okay internally how it is

[04:11:24 - 04:11:27]
processing that internally how it is

[04:11:25 - 04:11:29]
converting to the vector representation

[04:11:27 - 04:11:31]
so it is using something called

[04:11:29 - 04:11:32]
tokenization technique okay tokenizer so

[04:11:31 - 04:11:34]
inside actually Transformer we are

[04:11:32 - 04:11:36]
having something called Auto

[04:11:34 - 04:11:37]
tokenizer okay so inside Auto tokenizer

[04:11:36 - 04:11:39]
we have to first of all give the model

[04:11:37 - 04:11:41]
name like which model you have to use

[04:11:39 - 04:11:43]
for that particular tokenization task so

[04:11:41 - 04:11:44]
to explain this tokenization I I just

[04:11:43 - 04:11:46]
simplified this particular code so first

[04:11:44 - 04:11:48]
of all I'm importing some of the library

[04:11:46 - 04:11:49]
necessary Library I need and here you

[04:11:48 - 04:11:51]
can see I'm importing Auto tokenizer

[04:11:49 - 04:11:52]
okay so let me import all the library if

[04:11:51 - 04:11:54]
you want to use any kinds of

[04:11:52 - 04:11:56]
tokenization so first of all you have to

[04:11:54 - 04:11:58]
define the model name like which model

[04:11:56 - 04:12:01]
you want to use so here I I'm using this

[04:11:58 - 04:12:04]
model bbased multilingual an sentiment

[04:12:01 - 04:12:06]
model so this model will uh so with the

[04:12:04 - 04:12:07]
help of this particular Transformer

[04:12:06 - 04:12:09]
based model first of all it will perform

[04:12:07 - 04:12:11]
the tokenization that means this input

[04:12:09 - 04:12:13]
we are giving to the model right now yes

[04:12:11 - 04:12:15]
or no right so first of all it will um

[04:12:13 - 04:12:17]
this tokenizer what this tokenizer will

[04:12:15 - 04:12:19]
do it will first of all pre-process

[04:12:17 - 04:12:21]
let's say if it is having some HTML tags

[04:12:19 - 04:12:23]
or any kind of word it will try to

[04:12:21 - 04:12:24]
remove then it will try to convert this

[04:12:23 - 04:12:26]
text to the vector representation okay

[04:12:24 - 04:12:29]
then it will pass to the model and model

[04:12:26 - 04:12:31]
will uh actually do the sentiment

[04:12:29 - 04:12:32]
analysis now see if I execute the code

[04:12:31 - 04:12:34]
so first of all it will download the

[04:12:32 - 04:12:36]
tokenizer okay then after downloading

[04:12:34 - 04:12:38]
the tokenizer it will also initialize

[04:12:36 - 04:12:40]
the model after that it will do the

[04:12:38 - 04:12:42]
sentiment

[04:12:40 - 04:12:43]
analysis so this is the high level

[04:12:42 - 04:12:45]
understanding and I will also show you

[04:12:43 - 04:12:46]
the low level how it is generating the

[04:12:45 - 04:12:48]
vector even we can also visualize the

[04:12:46 - 04:12:51]
vector as well see now we can see this

[04:12:48 - 04:12:53]
is the result we are getting fine now

[04:12:51 - 04:12:54]
let's try to see how tokenizer is

[04:12:53 - 04:12:56]
working so if you want to use tokenizer

[04:12:54 - 04:12:58]
you have to import one Library called

[04:12:56 - 04:12:59]
Auto tokenizer from Transformer the

[04:12:58 - 04:13:00]
first thing what you have to do you have

[04:12:59 - 04:13:02]
to load one pre0 model OKAY pre-end

[04:13:00 - 04:13:04]
Transformer based model so here let's

[04:13:02 - 04:13:07]
say we are using bbased Case Model so

[04:13:04 - 04:13:09]
this is one of the Transformer based

[04:13:07 - 04:13:10]
model okay you can see this one of the

[04:13:09 - 04:13:12]
Transformer Bas model so we're giving

[04:13:10 - 04:13:14]
the model ID here then this is my

[04:13:12 - 04:13:17]
example text let's say I'm giving into

[04:13:14 - 04:13:18]
my tokenizer okay so inside tokenizer

[04:13:17 - 04:13:20]
we're having another function called

[04:13:18 - 04:13:22]
tokenize now after tokenize it I'm just

[04:13:20 - 04:13:24]
printing okay after tokenizing I'm just

[04:13:22 - 04:13:27]
printing now let me show you what it

[04:13:24 - 04:13:29]
will give me the output so I can card

[04:13:27 - 04:13:31]
these are the example now let me execute

[04:13:29 - 04:13:31]
as of

[04:13:33 - 04:13:38]
now H now see when you apply tokenizer

[04:13:37 - 04:13:40]
do tokenize it will give you the

[04:13:38 - 04:13:42]
individual token that means the

[04:13:40 - 04:13:43]
tokenization we used to perform with the

[04:13:42 - 04:13:45]
help of NL iCal Library I think I

[04:13:43 - 04:13:47]
remember right sentence level and level

[04:13:45 - 04:13:50]
tokenization now it is possible with the

[04:13:47 - 04:13:52]
help of this tokenizer class only okay

[04:13:50 - 04:13:54]
that's why I told you Transformer is

[04:13:52 - 04:13:56]
like very powerful so it's a high level

[04:13:54 - 04:13:57]
rapper inside that they have written all

[04:13:56 - 04:13:58]
kinds of code it will handle each and

[04:13:57 - 04:14:00]
everything you don't need to write any

[04:13:58 - 04:14:02]
kinds of code from scratch okay now if I

[04:14:00 - 04:14:04]
want to convert this textual

[04:14:02 - 04:14:05]
representation to the vector what I have

[04:14:04 - 04:14:08]
to do I have to pass this particular

[04:14:05 - 04:14:10]
token to the convert tokens to IDs this

[04:14:08 - 04:14:12]
particular method okay and it is

[04:14:10 - 04:14:14]
available inside tokenizer object the

[04:14:12 - 04:14:16]
tokenizer object we have find here now

[04:14:14 - 04:14:18]
it will give you the input IDs now let

[04:14:16 - 04:14:20]
me show you this input IDs I can take

[04:14:18 - 04:14:23]
different cell and here I can

[04:14:20 - 04:14:25]
execute see this is the input ID and

[04:14:23 - 04:14:26]
this is nothing but your representation

[04:14:25 - 04:14:29]
of the text the text actually you have

[04:14:26 - 04:14:32]
given I was so not happy with the Barbie

[04:14:29 - 04:14:34]
movie now you can see this is the vector

[04:14:32 - 04:14:36]
representation of this particular text

[04:14:34 - 04:14:38]
and it is using Transformer model okay

[04:14:36 - 04:14:40]
it is using Transformer architecture in

[04:14:38 - 04:14:42]
the back end and it's like more powerful

[04:14:40 - 04:14:44]
okay it's like more powerful technique

[04:14:42 - 04:14:46]
than your bag of word or TF IDF or what

[04:14:44 - 04:14:47]
to whatever you have learned okay and

[04:14:46 - 04:14:49]
going forward we'll be using this

[04:14:47 - 04:14:51]
particular approach only okay I hope you

[04:14:49 - 04:14:53]
cleared but whenever I have to pass this

[04:14:51 - 04:14:55]
particular Vector to my model I won't be

[04:14:53 - 04:14:57]
using this particular method for this

[04:14:55 - 04:15:01]
you have to use this particular method

[04:14:57 - 04:15:03]
so here there is another function uh so

[04:15:01 - 04:15:05]
here you have to pass your data uh to

[04:15:03 - 04:15:07]
the tokenizer okay directly you have to

[04:15:05 - 04:15:09]
pass to the tokenizer and tokenizer will

[04:15:07 - 04:15:11]
give you this output let me show you see

[04:15:09 - 04:15:13]
this is the entire output encoded input

[04:15:11 - 04:15:15]
now see input IDs now it is familiar so

[04:15:13 - 04:15:18]
this is the input

[04:15:15 - 04:15:20]
IDs and here one additional token you

[04:15:18 - 04:15:22]
can see one1 what is one1 this is the

[04:15:20 - 04:15:24]
start of the sentence and start of the

[04:15:22 - 04:15:27]
sentence represent 101 and end of the

[04:15:24 - 04:15:28]
sentence represent one2 and in between

[04:15:27 - 04:15:30]
actually you can see your entire Vector

[04:15:28 - 04:15:32]
the vector actually you got okay now it

[04:15:30 - 04:15:34]
is having another actually uh things

[04:15:32 - 04:15:37]
called token type IDs as of now just try

[04:15:34 - 04:15:38]
to skip this part it's not required and

[04:15:37 - 04:15:40]
this is the important things guys

[04:15:38 - 04:15:42]
attention mask okay now I think you

[04:15:40 - 04:15:45]
remember what is attention mask that uh

[04:15:42 - 04:15:47]
attention mechanism concept that means

[04:15:45 - 04:15:48]
uh whenever let's say it will pass this

[04:15:47 - 04:15:50]
particular data to my model in which

[04:15:48 - 04:15:52]
word it will give the more attention

[04:15:50 - 04:15:54]
Okay it is telling now see it is giving

[04:15:52 - 04:15:56]
the attention to all the word because

[04:15:54 - 04:15:58]
every word is one one one one you can

[04:15:56 - 04:16:00]
see that means this one will get the

[04:15:58 - 04:16:01]
same attention this one would give the

[04:16:00 - 04:16:03]
same attention Okay this one will give

[04:16:01 - 04:16:05]
the same attention okay and how it is

[04:16:03 - 04:16:07]
getting to know how to give the let's

[04:16:05 - 04:16:10]
say attention uh I think I showed you

[04:16:07 - 04:16:12]
the calculation that uh I mean one one

[04:16:10 - 04:16:14]
calculation I was discussing in that uh

[04:16:12 - 04:16:16]
J our blog okay that's how it is

[04:16:14 - 04:16:18]
calculating the score and it is able to

[04:16:16 - 04:16:20]
decide okay I have to give the attention

[04:16:18 - 04:16:21]
to this particular specific word okay I

[04:16:20 - 04:16:23]
hope it is clear so these are the

[04:16:21 - 04:16:24]
actually output you'll be getting after

[04:16:23 - 04:16:26]
doing the

[04:16:24 - 04:16:27]
tokenization now if you want to decode

[04:16:26 - 04:16:29]
the tokenization that means if you want

[04:16:27 - 04:16:31]
to again convert this uh let's say

[04:16:29 - 04:16:33]
Vector to text representation you can

[04:16:31 - 04:16:35]
use decode function for this now I'll

[04:16:33 - 04:16:37]
give my input ID so whatever input ID

[04:16:35 - 04:16:39]
I'm giving getting I'm I'll pass in in

[04:16:37 - 04:16:41]
the decode function and decode will give

[04:16:39 - 04:16:44]
me the previous text actually you can

[04:16:41 - 04:16:46]
see I was so have uh so I was not happy

[04:16:44 - 04:16:49]
with the Barbie movie okay I hope it is

[04:16:46 - 04:16:52]
clear now now if I execute all of them

[04:16:49 - 04:16:52]
all together you can see this is the

[04:16:54 - 04:16:58]
output this is your tokens this is input

[04:16:56 - 04:17:00]
IDs this is the encoded input this is

[04:16:58 - 04:17:02]
the decode output that means this

[04:17:00 - 04:17:04]
tokenization will first of all perform

[04:17:02 - 04:17:06]
the pre-processing then it will perform

[04:17:04 - 04:17:09]
the tokenization then it will convert

[04:17:06 - 04:17:11]
your let's say Tex to Vector

[04:17:09 - 04:17:13]
representation okay and additionally it

[04:17:11 - 04:17:15]
will also give you some of the let's say

[04:17:13 - 04:17:17]
number which is nothing but attention

[04:17:15 - 04:17:19]
mask okay based on this attention mask

[04:17:17 - 04:17:21]
your model will decide in which word it

[04:17:19 - 04:17:23]
has to give the uh let's say attention

[04:17:21 - 04:17:25]
mode so now I think guys this uh token

[04:17:23 - 04:17:27]
tokenizer is clear like what is

[04:17:25 - 04:17:28]
tokenizer exactly inside hugging face

[04:17:27 - 04:17:30]
because many people will have this

[04:17:28 - 04:17:31]
question later on that's why I just

[04:17:30 - 04:17:32]
clarified right now because going

[04:17:31 - 04:17:34]
forward whatever experiment we'll be

[04:17:32 - 04:17:36]
doing we'll be using the tokenizer okay

[04:17:34 - 04:17:38]
from the Hing itself so for this again I

[04:17:36 - 04:17:40]
kept one example so here we'll be fine

[04:17:38 - 04:17:43]
tuning uh one data set called IMDb okay

[04:17:40 - 04:17:45]
IMDb movie review data set and and we'll

[04:17:43 - 04:17:47]
be using one uh language model OKAY from

[04:17:45 - 04:17:48]
the hugging face itself so for this year

[04:17:47 - 04:17:50]
we'll be using hugging face data set

[04:17:48 - 04:17:52]
only because I already told you hugging

[04:17:50 - 04:17:54]
face is having data set okay data set

[04:17:52 - 04:17:56]
actually services so you can also get

[04:17:54 - 04:17:58]
see different different data set and

[04:17:56 - 04:17:59]
this is the data set count guys okay now

[04:17:58 - 04:18:00]
you can search any kinds of data set now

[04:17:59 - 04:18:04]
let's say I want to use something called

[04:18:00 - 04:18:05]
IMDb data set so IMDb so this data set

[04:18:04 - 04:18:07]
is already available see this is the

[04:18:05 - 04:18:09]
IMDB data set okay so this is a movie

[04:18:07 - 04:18:12]
reviews data set so here you have the

[04:18:09 - 04:18:13]
movies and based on that you have the uh

[04:18:12 - 04:18:16]
reviews okay whether it's a negative or

[04:18:13 - 04:18:17]
positive so here we'll be fing one uh

[04:18:16 - 04:18:19]
text classification model that means

[04:18:17 - 04:18:22]
we'll be performing sentiment analysis

[04:18:19 - 04:18:23]
okay this is our main objective so if

[04:18:22 - 04:18:24]
you want to use actually hugging face

[04:18:23 - 04:18:26]
data set for this you have to install

[04:18:24 - 04:18:29]
one Library called data set okay so

[04:18:26 - 04:18:31]
first of all try to install data

[04:18:29 - 04:18:32]
set and make sure you also install

[04:18:31 - 04:18:34]
Transformers okay because I already

[04:18:32 - 04:18:35]
installed Transformers so that's why I'm

[04:18:34 - 04:18:38]
not going to install again now you have

[04:18:35 - 04:18:38]
to restart the run

[04:18:40 - 04:18:45]
time now see it is restarting the on

[04:18:43 - 04:18:47]
time after that we'll load the data and

[04:18:45 - 04:18:49]
loading data is very much easy only you

[04:18:47 - 04:18:52]
just need to give the data set name okay

[04:18:49 - 04:18:53]
so there is a load data set uh function

[04:18:52 - 04:18:54]
inside data set you have to call it and

[04:18:53 - 04:18:56]
inside that you have to pass the data

[04:18:54 - 04:18:58]
set name it will automatically download

[04:18:56 - 04:19:00]
the data from the hugging face okay now

[04:18:58 - 04:19:02]
see this is the data set name IMDb just

[04:19:00 - 04:19:03]
copy the name and give it here okay it

[04:19:02 - 04:19:05]
will automatically download now if I

[04:19:03 - 04:19:05]
show

[04:19:08 - 04:19:13]
you so not only this data you can use

[04:19:11 - 04:19:14]
any kinds of data even I think you

[04:19:13 - 04:19:16]
remember in the previous video I showed

[04:19:14 - 04:19:17]
you that tokenizer so in the tokenizer

[04:19:16 - 04:19:19]
also you can take different different

[04:19:17 - 04:19:21]
model OKAY different different model for

[04:19:19 - 04:19:23]
the tokenization so there I was using BB

[04:19:21 - 04:19:25]
Cas model you can also use any other

[04:19:23 - 04:19:27]
model but remember whatever actually

[04:19:25 - 04:19:28]
model you are using for the tokenizer

[04:19:27 - 04:19:30]
the same model you have to use for the

[04:19:28 - 04:19:32]
model training as well for the model

[04:19:30 - 04:19:35]
inference as well okay this is the uh

[04:19:32 - 04:19:37]
idea now let me show you huh see my data

[04:19:35 - 04:19:38]
set is downloaded now if you want to see

[04:19:37 - 04:19:41]
the data set metadata so this is the

[04:19:38 - 04:19:43]
data set now we are having um uh

[04:19:41 - 04:19:45]
training data take and labels we are

[04:19:43 - 04:19:45]
having and this is the example that

[04:19:45 - 04:19:47]
means

[04:19:45 - 04:19:50]
25,000 actually rows we are having

[04:19:47 - 04:19:52]
inside training example and test data we

[04:19:50 - 04:19:54]
are having 25,000 and here we are also

[04:19:52 - 04:19:56]
having unsupervised data so here we'll

[04:19:54 - 04:19:59]
be using this data only train and test

[04:19:56 - 04:20:01]
data okay uh for my analysis now first

[04:19:59 - 04:20:04]
of all let's do the pre-processing task

[04:20:01 - 04:20:05]
so for this I think remember we have to

[04:20:04 - 04:20:07]
perform the tokenizer so here I'm

[04:20:05 - 04:20:09]
importing Auto tokenizer so again I'm

[04:20:07 - 04:20:11]
using this model but best Case Model

[04:20:09 - 04:20:13]
okay so first of all I initialize my

[04:20:11 - 04:20:15]
tokenizer then here I have created a

[04:20:13 - 04:20:18]
function tokenize function inside that

[04:20:15 - 04:20:19]
I'm just tokenizing my example now which

[04:20:18 - 04:20:21]
example I have to tokenize guys I think

[04:20:19 - 04:20:23]
remember if I show you the data let's if

[04:20:21 - 04:20:25]
I show you the first example you can see

[04:20:23 - 04:20:27]
this is the text okay this is my reviews

[04:20:25 - 04:20:29]
okay this is my reviews and this is the

[04:20:27 - 04:20:31]
sentiment so I have to apply on top of

[04:20:29 - 04:20:34]
the reviews only okay so that's why I'm

[04:20:31 - 04:20:36]
giving text example text because inside

[04:20:34 - 04:20:37]
example we are having the text okay text

[04:20:36 - 04:20:40]
uh Keys actually you can see because

[04:20:37 - 04:20:43]
it's a dictionary format okay that's the

[04:20:40 - 04:20:45]
idea and here I'm adding pad padding max

[04:20:43 - 04:20:47]
length let's say what is padding I think

[04:20:45 - 04:20:49]
remember let's say there is a sentence

[04:20:47 - 04:20:52]
this

[04:20:49 - 04:20:54]
movie is

[04:20:52 - 04:20:57]
good now now let's say there is another

[04:20:54 - 04:21:01]
sentence I

[04:20:57 - 04:21:05]
hit this okay now just see the actually

[04:21:01 - 04:21:07]
input length 1 2 3 4 1 2 3 so this input

[04:21:05 - 04:21:08]
length actually having one word list so

[04:21:07 - 04:21:10]
in case actually what you can do you can

[04:21:08 - 04:21:12]
add some padding padding means zero

[04:21:10 - 04:21:13]
value okay so that's why actually we

[04:21:12 - 04:21:15]
adding this particular

[04:21:13 - 04:21:16]
parameter padding is equal to max length

[04:21:15 - 04:21:18]
that means first of all it will try to

[04:21:16 - 04:21:20]
figure out the maximum length sentence

[04:21:18 - 04:21:22]
based on that it will decide what would

[04:21:20 - 04:21:24]
be the padding size okay this is the

[04:21:22 - 04:21:26]
idea now uh here we are applying this

[04:21:24 - 04:21:28]
particular function you can see this

[04:21:26 - 04:21:30]
tokenized function on top of my entire

[04:21:28 - 04:21:32]
data set okay and for this I'm using map

[04:21:30 - 04:21:34]
function and map will apply on top of

[04:21:32 - 04:21:37]
the entire rows okay this is the idea

[04:21:34 - 04:21:39]
now if I execute see uh this tokenizer

[04:21:37 - 04:21:43]
will apply on top of my entire data set

[04:21:39 - 04:21:45]
then I will get all of my vector

[04:21:43 - 04:21:48]
now previously I only had this many of

[04:21:45 - 04:21:50]
example now after tokenization you will

[04:21:48 - 04:21:53]
see uh you will you will have some more

[04:21:50 - 04:21:55]
actually Keys like your attention uh

[04:21:53 - 04:21:56]
attention mask then you'll also get the

[04:21:55 - 04:21:58]
input IDs okay these are the thing

[04:21:56 - 04:22:00]
you'll also

[04:21:58 - 04:22:02]
getting so guys as you can see my

[04:22:00 - 04:22:05]
tokenization is completed now if I show

[04:22:02 - 04:22:08]
you my tokenized data set right now so

[04:22:05 - 04:22:10]
see now I'm having uh all of the

[04:22:08 - 04:22:12]
features like input IDs token type IDs

[04:22:10 - 04:22:15]
and as well as the attention mask okay

[04:22:12 - 04:22:17]
uh everything now if I want to show you

[04:22:15 - 04:22:19]
the data how it will look like so here

[04:22:17 - 04:22:21]
you can visualize that's I want to see

[04:22:19 - 04:22:22]
my training data let's say I want to

[04:22:21 - 04:22:24]
show you the first example now you can

[04:22:22 - 04:22:28]
see the first example this is the raw

[04:22:24 - 04:22:30]
text okay and after doing the

[04:22:28 - 04:22:31]
tokenization uh you got the input IDs

[04:22:30 - 04:22:34]
and input ID is nothing but is the

[04:22:31 - 04:22:35]
vector representation of the entire text

[04:22:34 - 04:22:37]
okay you can see this the vector

[04:22:35 - 04:22:41]
representation and it will also have

[04:22:37 - 04:22:44]
something called uh this one attention

[04:22:41 - 04:22:49]
mask let me show you token type IDs

[04:22:44 - 04:22:49]
would be there as well as the attention

[04:22:51 - 04:22:56]
mask see attention mask okay I hope it

[04:22:55 - 04:22:58]
is clear now that means we have

[04:22:56 - 04:23:01]
successfully converted our uh textual

[04:22:58 - 04:23:02]
data to Vector representation now we can

[04:23:01 - 04:23:05]
start the training but before that I

[04:23:02 - 04:23:06]
have to first of all set some of the

[04:23:05 - 04:23:09]
training argument and Transformer

[04:23:06 - 04:23:11]
provides actually one uh actually

[04:23:09 - 04:23:13]
function called training arguments okay

[04:23:11 - 04:23:16]
inside that you can mention training

[04:23:13 - 04:23:17]
arguments so these are the default

[04:23:16 - 04:23:18]
actually arguments you can keep as of

[04:23:17 - 04:23:21]
now no need to change anything because

[04:23:18 - 04:23:23]
again it's a hyper parameter tuning only

[04:23:21 - 04:23:24]
just uh change you can do number of

[04:23:23 - 04:23:26]
epoch let's say how many Epoch you want

[04:23:24 - 04:23:28]
to train let I want only want to train

[04:23:26 - 04:23:30]
only let's say one Epoch as of now okay

[04:23:28 - 04:23:32]
only one EPO I want to train and output

[04:23:30 - 04:23:33]
directory so it will create a folder

[04:23:32 - 04:23:35]
here called output directory inside that

[04:23:33 - 04:23:36]
it will save all the models and

[04:23:35 - 04:23:39]
everything right now let me set the

[04:23:36 - 04:23:39]
training

[04:23:39 - 04:23:43]
arguments so again this is kinds of

[04:23:41 - 04:23:44]
template kind of code you don't need to

[04:23:43 - 04:23:47]
remember anything all the codes are

[04:23:44 - 04:23:48]
available in the hugging face platform

[04:23:47 - 04:23:50]
so from there you can refer okay you

[04:23:48 - 04:23:52]
don't need to remember anything here F

[04:23:50 - 04:23:53]
now see that many of actually training

[04:23:52 - 04:23:55]
argument you can set here okay after

[04:23:53 - 04:23:57]
printing you can see okay but I don't

[04:23:55 - 04:23:58]
need to set all the training arguments

[04:23:57 - 04:24:01]
we can only set these are the training

[04:23:58 - 04:24:03]
argument F now we can initialize the

[04:24:01 - 04:24:04]
model so here to initialize the model

[04:24:03 - 04:24:06]
first of all you have to import to

[04:24:04 - 04:24:07]
library Auto so here you have to import

[04:24:06 - 04:24:09]
one Library called Auto model for

[04:24:07 - 04:24:11]
sequence classification because here we

[04:24:09 - 04:24:13]
are doing text classification for this

[04:24:11 - 04:24:15]
you have to use this particular class

[04:24:13 - 04:24:16]
then you have to also import the trainer

[04:24:15 - 04:24:18]
now first of all you have to load the

[04:24:16 - 04:24:21]
model you can see this is the model part

[04:24:18 - 04:24:22]
based case model I'm loading okay so if

[04:24:21 - 04:24:24]
you give it here it will automatically

[04:24:22 - 04:24:25]
download and number of labels I'm giving

[04:24:24 - 04:24:27]
two because we are having only two

[04:24:25 - 04:24:28]
labels positive and negative we are

[04:24:27 - 04:24:30]
doing the sentiment analysis now of the

[04:24:28 - 04:24:32]
IMDb data set and if you see the

[04:24:30 - 04:24:34]
sentiment only positive and negative

[04:24:32 - 04:24:36]
fine if you're having let's say four

[04:24:34 - 04:24:39]
four sentiment that time you can give

[04:24:36 - 04:24:41]
four okay I hope you're clear now simply

[04:24:39 - 04:24:42]
we can initialize the trainer inside

[04:24:41 - 04:24:44]
trainer give the model give the the

[04:24:42 - 04:24:46]
training arguments okay the training

[04:24:44 - 04:24:48]
arguments we're getting from here this

[04:24:46 - 04:24:49]
is the training arguments then we have

[04:24:48 - 04:24:52]
to pass

[04:24:49 - 04:24:54]
the train data so this is my train data

[04:24:52 - 04:24:56]
tokenized data train okay training

[04:24:54 - 04:25:01]
sample and evaluation data I'm giving my

[04:24:56 - 04:25:01]
testing data fine now let me click

[04:25:01 - 04:25:05]
here now see it will download the model

[04:25:04 - 04:25:07]
and it will initialize all the trainer

[04:25:05 - 04:25:09]
now see training has not started yet

[04:25:07 - 04:25:09]
because if you want to start the

[04:25:09 - 04:25:12]
training you have to call this

[04:25:09 - 04:25:13]
particular things okay trainer. train

[04:25:12 - 04:25:16]
now see if I click here now it will

[04:25:13 - 04:25:17]
start the training and after training it

[04:25:16 - 04:25:19]
will save all the artifacts in the

[04:25:17 - 04:25:21]
result folder okay so it will take some

[04:25:19 - 04:25:23]
time guys so let's wait once training is

[04:25:21 - 04:25:25]
completed I will come back if you're

[04:25:23 - 04:25:28]
using free collab so training will take

[04:25:25 - 04:25:30]
some time so you have to wait now what

[04:25:28 - 04:25:31]
you can do you can also evaluate uh the

[04:25:30 - 04:25:34]
model on top of the test data so just

[04:25:31 - 04:25:34]
try to execute this

[04:25:38 - 04:25:42]
code so again it will take some time

[04:25:41 - 04:25:45]
let's wait after this execution you will

[04:25:42 - 04:25:47]
see the evaluation metrics and in

[04:25:45 - 04:25:48]
between let me show you the training

[04:25:47 - 04:25:50]
loss and validation loss you got after

[04:25:48 - 04:25:52]
training so this is the training loss

[04:25:50 - 04:25:54]
and this is the validation loss in only

[04:25:52 - 04:25:56]
one Epoch so here if you increase the

[04:25:54 - 04:25:57]
epoch size you'll see that this loss

[04:25:56 - 04:25:59]
would be decreased so try to increase

[04:25:57 - 04:26:01]
the EPO size whenever you are uh

[04:25:59 - 04:26:02]
training your actual model as of now I'm

[04:26:01 - 04:26:05]
only training monip because I just

[04:26:02 - 04:26:07]
wanted to show you okay this the

[04:26:05 - 04:26:10]
idea now let's see the evaluation metrix

[04:26:07 - 04:26:13]
uh what is the evaluation metrix we get

[04:26:10 - 04:26:15]
here so guys as you can see this is your

[04:26:13 - 04:26:18]
evaluation result so this is the

[04:26:15 - 04:26:21]
evaluation loss this is the evaluation

[04:26:18 - 04:26:23]
runtime uh that means uh that many

[04:26:21 - 04:26:25]
seconds actually took to execute this

[04:26:23 - 04:26:27]
entire code and you can see we only

[04:26:25 - 04:26:29]
train manip okay so you just only need

[04:26:27 - 04:26:31]
to see this losses like how much loss

[04:26:29 - 04:26:33]
you are getting so this loss should be

[04:26:31 - 04:26:34]
close to zero if it is close to zero

[04:26:33 - 04:26:37]
that means your model is performing

[04:26:34 - 04:26:38]
better that time now you can also save

[04:26:37 - 04:26:40]
the model the model you have trained you

[04:26:38 - 04:26:42]
can also save the model even you can

[04:26:40 - 04:26:44]
also save the tokenizer why you have to

[04:26:42 - 04:26:47]
to save the tokenizer because uh let's

[04:26:44 - 04:26:48]
say uh in future user will come here and

[04:26:47 - 04:26:50]
they will be using your model so they

[04:26:48 - 04:26:52]
will give some input right and input is

[04:26:50 - 04:26:54]
what it's a text so again you have to

[04:26:52 - 04:26:56]
convert that particular into the vector

[04:26:54 - 04:26:58]
representation yes or no right so to uh

[04:26:56 - 04:26:59]
convert this input to the vector

[04:26:58 - 04:27:01]
representation I need to use my

[04:26:59 - 04:27:03]
tokenizer my train tokenizer okay not

[04:27:01 - 04:27:05]
the previous tokenizer okay that's the

[04:27:03 - 04:27:06]
thing you have to remember and as well

[04:27:05 - 04:27:07]
as I also need to save my model now let

[04:27:06 - 04:27:08]
me save both of

[04:27:07 - 04:27:10]
[Music]

[04:27:08 - 04:27:12]
them now you can see in the results

[04:27:10 - 04:27:14]
folder we are having all the check

[04:27:12 - 04:27:16]
points of our model training and all I

[04:27:14 - 04:27:18]
think you already know if you have

[04:27:16 - 04:27:20]
already learned previously like how to

[04:27:18 - 04:27:21]
train uh computer vision model

[04:27:20 - 04:27:23]
tensorflow model I think you know what

[04:27:21 - 04:27:25]
is checkpoints okay now see we have

[04:27:23 - 04:27:27]
successfully saved our model now if I

[04:27:25 - 04:27:30]
refresh now see this model has been

[04:27:27 - 04:27:31]
saved here now inside uh this folder

[04:27:30 - 04:27:33]
actually we are having different

[04:27:31 - 04:27:36]
different actually file sequency config

[04:27:33 - 04:27:38]
Json then uh save Tor okay Json so this

[04:27:36 - 04:27:40]
is how actually uh your hugging face

[04:27:38 - 04:27:42]
save the model okay it will contain

[04:27:40 - 04:27:43]
actually multiple file inside config you

[04:27:42 - 04:27:46]
will have the entire configuration of

[04:27:43 - 04:27:47]
the model okay this is the main idea so

[04:27:46 - 04:27:50]
see we have successfully saved our model

[04:27:47 - 04:27:52]
as well as the tokenizer now let's see

[04:27:50 - 04:27:54]
actually one uh project now let's try to

[04:27:52 - 04:27:58]
do one small project so here we'll be

[04:27:54 - 04:28:01]
using uh this uh archive actually so I

[04:27:58 - 04:28:02]
think you know archive is a website so

[04:28:01 - 04:28:04]
here you will get different different

[04:28:02 - 04:28:07]
research paper okay all kinds of

[04:28:04 - 04:28:09]
research article um you will get here so

[04:28:07 - 04:28:11]
first of all we'll install this

[04:28:09 - 04:28:12]
Library uh because in Python we have

[04:28:11 - 04:28:15]
this library with the help of this

[04:28:12 - 04:28:17]
Library we can uh actually download all

[04:28:15 - 04:28:21]
kinds of article right we can get all

[04:28:17 - 04:28:24]
kinds of article data so now let me

[04:28:21 - 04:28:26]
import now see if I want to now see if

[04:28:24 - 04:28:27]
you want to use this particular Library

[04:28:26 - 04:28:29]
archive first of all you have to prepare

[04:28:27 - 04:28:31]
one query you need AI or artificial

[04:28:29 - 04:28:32]
intelligence or machine learning related

[04:28:31 - 04:28:35]
let's say paper here you are giving the

[04:28:32 - 04:28:36]
query now here you have to search okay

[04:28:35 - 04:28:38]
you have to search in the archive now

[04:28:36 - 04:28:40]
here you can see I've given the query

[04:28:38 - 04:28:41]
maximum result I need 10 and you have to

[04:28:40 - 04:28:44]
pass this particular parameter called

[04:28:41 - 04:28:45]
sorted by just try to mention submitted

[04:28:44 - 04:28:46]
dat as of now now it will give me

[04:28:45 - 04:28:48]
different different page and I'm looking

[04:28:46 - 04:28:50]
through the page and I'm extracting the

[04:28:48 - 04:28:52]
published date

[04:28:50 - 04:28:54]
title and abstraction and category of

[04:28:52 - 04:28:56]
the paper okay then whatever data I'm

[04:28:54 - 04:28:58]
getting I'm converting to the data frame

[04:28:56 - 04:29:00]
and I'm just plotting it here now let me

[04:28:58 - 04:29:02]
execute and let me show

[04:29:00 - 04:29:05]
you so guys you can see I got the

[04:29:02 - 04:29:07]
results now this is the publish date

[04:29:05 - 04:29:08]
this is the title of the paper and this

[04:29:07 - 04:29:09]
is the abstraction of the paper Okay

[04:29:08 - 04:29:12]
abstract of the paper and this is the

[04:29:09 - 04:29:14]
category now let's say I want to uh

[04:29:12 - 04:29:16]
create a research paper summarization

[04:29:14 - 04:29:17]
system so what I can do in the pipeline

[04:29:16 - 04:29:20]
I can mention I want to perform

[04:29:17 - 04:29:22]
summarization okay and which things I

[04:29:20 - 04:29:23]
want to summarize I want to summarize

[04:29:22 - 04:29:25]
this abstraction okay this abstraction I

[04:29:23 - 04:29:28]
got you can see this is the abstraction

[04:29:25 - 04:29:29]
column okay abstract column now that's

[04:29:28 - 04:29:31]
why I'm passing the abstract column from

[04:29:29 - 04:29:34]
the data F and here I'm using this

[04:29:31 - 04:29:36]
Facebook part large CNN model okay

[04:29:34 - 04:29:38]
inside that I'm passing my abstraction

[04:29:36 - 04:29:40]
now see will give me the summary so this

[04:29:38 - 04:29:42]
model actually they train on the summary

[04:29:40 - 04:29:44]
okay summarization task

[04:29:42 - 04:29:45]
you can open it up and you can see the

[04:29:44 - 04:29:47]
description of the model they're doing

[04:29:45 - 04:29:49]
the summarization task okay so execution

[04:29:47 - 04:29:51]
is completed now I got all of my

[04:29:49 - 04:29:53]
summarization result now let's say I

[04:29:51 - 04:29:56]
only want to uh see the first one okay

[04:29:53 - 04:29:58]
first summarization text now I can

[04:29:56 - 04:29:59]
execute this code you can also print all

[04:29:58 - 04:30:00]
of them it's up to you but I'm only

[04:29:59 - 04:30:03]
showing the first example see this is

[04:30:00 - 04:30:06]
the summary of the first results okay so

[04:30:03 - 04:30:08]
I hope guys uh it is clear how we can

[04:30:06 - 04:30:10]
perform the let's say fine tuning

[04:30:08 - 04:30:11]
operation on top of a pre-end model and

[04:30:10 - 04:30:13]
no need to worry going forward also will

[04:30:11 - 04:30:15]
be exploring lots of model and we'll be

[04:30:13 - 04:30:16]
doing the fine tuning operation we'll be

[04:30:15 - 04:30:18]
implementing different different

[04:30:16 - 04:30:19]
application okay on top of it we'll be

[04:30:18 - 04:30:21]
implementing different different

[04:30:19 - 04:30:24]
projects in this video I will show you

[04:30:21 - 04:30:26]
how we can generate hugging face API key

[04:30:24 - 04:30:27]
because I told you sometimes we need

[04:30:26 - 04:30:30]
this API key with the help of API key

[04:30:27 - 04:30:32]
will be accessing the model okay so for

[04:30:30 - 04:30:33]
this uh we have to learn how we can

[04:30:32 - 04:30:35]
generate a key so as of now we'll be

[04:30:33 - 04:30:37]
generating the key later on we'll be

[04:30:35 - 04:30:38]
using that so for this uh definitely

[04:30:37 - 04:30:39]
first of all you have to login with your

[04:30:38 - 04:30:42]
hugging face account now click on the

[04:30:39 - 04:30:43]
profile icon now go to the settings now

[04:30:42 - 04:30:46]
left hand side you will see one option

[04:30:43 - 04:30:48]
called access key okay access token now

[04:30:46 - 04:30:49]
click here now see previously I already

[04:30:48 - 04:30:51]
created some of the access token but for

[04:30:49 - 04:30:52]
you it would be empty now if you want to

[04:30:51 - 04:30:53]
create a new one just click on create

[04:30:52 - 04:30:55]
new

[04:30:53 - 04:30:57]
token now you can give the token name

[04:30:55 - 04:31:01]
let's say I give

[04:30:57 - 04:31:04]
uh my new okay my new

[04:31:01 - 04:31:06]
token now you can uh give the permission

[04:31:04 - 04:31:08]
now here you can uh provide the

[04:31:06 - 04:31:09]
permission whether uh you want to create

[04:31:08 - 04:31:12]
for the read access or whether you want

[04:31:09 - 04:31:14]
to create for the right access okay so

[04:31:12 - 04:31:15]
let's say uh as of now I want to create

[04:31:14 - 04:31:18]
for the read access I only want to

[04:31:15 - 04:31:20]
perform the read operation and uh later

[04:31:18 - 04:31:22]
on I will also show you how you can push

[04:31:20 - 04:31:23]
your train model to the hugging face Hub

[04:31:22 - 04:31:27]
so that time actually you need the right

[04:31:23 - 04:31:29]
access okay so as of now let's create my

[04:31:27 - 04:31:31]
token this is your token just try to

[04:31:29 - 04:31:32]
copy and save it somewhere don't no need

[04:31:31 - 04:31:35]
to share with anyone otherwise they will

[04:31:32 - 04:31:37]
also access your account okay so it

[04:31:35 - 04:31:38]
should be private I'll delete it after

[04:31:37 - 04:31:42]
the recording that's why I'm showing you

[04:31:38 - 04:31:44]
now let me uh close it so as of now uh I

[04:31:42 - 04:31:46]
showed you the hugging F demo like how

[04:31:44 - 04:31:47]
we can use this hugging face platform

[04:31:46 - 04:31:49]
how we can access different different

[04:31:47 - 04:31:51]
model even how we can also fine tune

[04:31:49 - 04:31:54]
those are the model on top of our custom

[04:31:51 - 04:31:56]
data so in this video we'll be uh using

[04:31:54 - 04:31:57]
the same technique and we'll be

[04:31:56 - 04:31:59]
implementing one project called takech

[04:31:57 - 04:32:01]
summarization okay so here is The

[04:31:59 - 04:32:03]
Notebook guys I already prepared so the

[04:32:01 - 04:32:04]
first thing what you have to do first

[04:32:03 - 04:32:06]
thing just connect the notebook and make

[04:32:04 - 04:32:08]
sure you change the run time to the GPU

[04:32:06 - 04:32:10]
because here you need the GPU if you

[04:32:08 - 04:32:12]
want to let's say uh implement this

[04:32:10 - 04:32:14]
project because here will be fine tuning

[04:32:12 - 04:32:17]
one uh Transformer based model okay

[04:32:14 - 04:32:18]
we'll be fine tuning one LM model here

[04:32:17 - 04:32:21]
on top of our custom data I'll tell you

[04:32:18 - 04:32:23]
which model we going to f tune even on

[04:32:21 - 04:32:25]
top of which data set actually we're

[04:32:23 - 04:32:26]
going to find tune but first of all uh

[04:32:25 - 04:32:28]
let me tell you what is take

[04:32:26 - 04:32:29]
summarization take summarization means

[04:32:28 - 04:32:32]
let's say you are having a bigger

[04:32:29 - 04:32:33]
paragraph and you are uh summarizing

[04:32:32 - 04:32:35]
that particular paragraph I think you

[04:32:33 - 04:32:37]
know okay what is the summary right what

[04:32:35 - 04:32:38]
is the T summarization project so in

[04:32:37 - 04:32:40]
Internet actually you will be getting

[04:32:38 - 04:32:42]
different different summarization

[04:32:40 - 04:32:44]
actually application let's say if I

[04:32:42 - 04:32:46]
write text

[04:32:44 - 04:32:50]
summarization

[04:32:46 - 04:32:51]
online so there are so many application

[04:32:50 - 04:32:55]
you will see see this is another

[04:32:51 - 04:32:56]
application from qu bot actually so here

[04:32:55 - 04:32:57]
actually you can also give any kinds of

[04:32:56 - 04:32:58]
text and it will give you the summary so

[04:32:57 - 04:33:02]
let me show

[04:32:58 - 04:33:05]
you if I search for English story so

[04:33:02 - 04:33:09]
what I can do I can copy this text as of

[04:33:05 - 04:33:09]
now as it is and here let me paste

[04:33:09 - 04:33:14]
it now if I click on summarize button

[04:33:13 - 04:33:16]
you'll see that it will give me the

[04:33:14 - 04:33:20]
summary of the entire text now you can

[04:33:16 - 04:33:21]
also control like how much uh summary

[04:33:20 - 04:33:24]
you need so let's say I need a little

[04:33:21 - 04:33:27]
bit bigger summary now if I again res

[04:33:24 - 04:33:29]
summarize now see this result I'm

[04:33:27 - 04:33:31]
getting uh this is the actually little

[04:33:29 - 04:33:33]
bit long than our previous summary okay

[04:33:31 - 04:33:34]
so that's how actually we're having

[04:33:33 - 04:33:36]
different different application over the

[04:33:34 - 04:33:38]
Internet so we'll be implementing this

[04:33:36 - 04:33:40]
kinds of project but here I'm not going

[04:33:38 - 04:33:41]
to implement a user interface user

[04:33:40 - 04:33:43]
interface wise will be implementing

[04:33:41 - 04:33:44]
later on so as of now we'll be only

[04:33:43 - 04:33:46]
doing the experiment on the collab

[04:33:44 - 04:33:48]
notebook okay we'll be using uh

[04:33:46 - 04:33:51]
Transformer based model we'll be using

[04:33:48 - 04:33:52]
uh LM model and we'll be doing this kind

[04:33:51 - 04:33:54]
kinds of project okay this is the main

[04:33:52 - 04:33:56]
objective here so let me so let me get

[04:33:54 - 04:33:58]
back to my collab notebook and first of

[04:33:56 - 04:34:01]
all let me execute this command so this

[04:33:58 - 04:34:02]
command will uh show you which uh GPU

[04:34:01 - 04:34:05]
actually you are using so here I'm using

[04:34:02 - 04:34:07]
Tesla T4 GPU because here I'm using free

[04:34:05 - 04:34:08]
Google collab now the first thing what

[04:34:07 - 04:34:10]
you have to do you have to install

[04:34:08 - 04:34:12]
Transformer Library okay why because

[04:34:10 - 04:34:14]
here we'll be using hugging face

[04:34:12 - 04:34:15]
actually platform and to use hugging

[04:34:14 - 04:34:17]
face platform I already showed you you

[04:34:15 - 04:34:19]
have to install Transformer Library

[04:34:17 - 04:34:21]
apart from that you need some additional

[04:34:19 - 04:34:24]
package like sentence pieces okay then

[04:34:21 - 04:34:28]
you need uh scare blue then row score

[04:34:24 - 04:34:29]
okay and Pi 7 Zer and data sets why data

[04:34:28 - 04:34:31]
set because with the help of data sets

[04:34:29 - 04:34:33]
we'll be downloading the data set from

[04:34:31 - 04:34:35]
the hugging phe itself okay that is why

[04:34:33 - 04:34:36]
and these are the dependency package you

[04:34:35 - 04:34:41]
also need to install here fine so let me

[04:34:36 - 04:34:41]
install all the package one by one

[04:34:43 - 04:34:46]
so my installation is completed so the

[04:34:45 - 04:34:49]
next thing what you have to do you have

[04:34:46 - 04:34:50]
to update some of the package the first

[04:34:49 - 04:34:52]
package you have to update called

[04:34:50 - 04:34:54]
accelerate then you have to uninstall

[04:34:52 - 04:34:55]
your older version of Transformer and

[04:34:54 - 04:34:57]
accelerate and you have to install the

[04:34:55 - 04:34:59]
latest one because what happens actually

[04:34:57 - 04:35:00]
in Google collab sometimes uh they're

[04:34:59 - 04:35:02]
using older version of the Transformer

[04:35:00 - 04:35:05]
package and accelerate package okay so

[04:35:02 - 04:35:06]
that's why I'm updating it again okay

[04:35:05 - 04:35:08]
that's is the things you have to do and

[04:35:06 - 04:35:10]
what is accelerate see accelerate will

[04:35:08 - 04:35:12]
help you actually to access your GPU

[04:35:10 - 04:35:15]
that means here you are using GPU you're

[04:35:12 - 04:35:18]
using something called cuda okay so to

[04:35:15 - 04:35:19]
use your Cuda uh actually instance this

[04:35:18 - 04:35:21]
accelerate will help you so whenever it

[04:35:19 - 04:35:23]
will do the find un operation that time

[04:35:21 - 04:35:25]
actually it will access your GPU right

[04:35:23 - 04:35:28]
so that's why actually this package is

[04:35:25 - 04:35:28]
required now let me update all of

[04:35:30 - 04:35:35]
them so as you can see uh update is

[04:35:33 - 04:35:37]
successful there is no error that means

[04:35:35 - 04:35:39]
everything is working fine now the next

[04:35:37 - 04:35:40]
thing you have to import some of the

[04:35:39 - 04:35:42]
necessary library to test whether

[04:35:40 - 04:35:44]
everything is working fine or not so

[04:35:42 - 04:35:45]
here you can see I'm importing pipeline

[04:35:44 - 04:35:47]
then I'm also importing load data set

[04:35:45 - 04:35:48]
from the data set okay and apart from

[04:35:47 - 04:35:51]
that I'm also importing some additional

[04:35:48 - 04:35:53]
Library okay some extra Library also I'm

[04:35:51 - 04:35:55]
importing here it is not required but

[04:35:53 - 04:35:57]
what the library actually I'm going to

[04:35:55 - 04:35:59]
use like later on I'll tell you okay why

[04:35:57 - 04:36:03]
I'm using that one so as of now let me

[04:35:59 - 04:36:05]
import all of them see this execution is

[04:36:03 - 04:36:06]
fine that means there is no error we

[04:36:05 - 04:36:08]
have successfully install all the

[04:36:06 - 04:36:10]
package now I think I already imported

[04:36:08 - 04:36:12]
torch so I don't need to import this

[04:36:10 - 04:36:14]
line I can delete HM now the first thing

[04:36:12 - 04:36:17]
what I have to do I have to check the

[04:36:14 - 04:36:19]
device okay whether it is utilizing my

[04:36:17 - 04:36:20]
Cuda or whether it is utilizing my CPU

[04:36:19 - 04:36:23]
so as I already showed you I have

[04:36:20 - 04:36:24]
changed my runtime to the GPU right and

[04:36:23 - 04:36:27]
here you can see it is connected with my

[04:36:24 - 04:36:28]
T4 GPU that means it should use my Cuda

[04:36:27 - 04:36:31]
so let me

[04:36:28 - 04:36:33]
check see it is utilizing my Cuda so

[04:36:31 - 04:36:35]
here I'm using torch pytor library to

[04:36:33 - 04:36:37]
check it whether Cuda is available or

[04:36:35 - 04:36:39]
not if yes print CA otherwise print CPU

[04:36:37 - 04:36:41]
so you don't need to manually set the

[04:36:39 - 04:36:43]
your machine type so if you have the

[04:36:41 - 04:36:46]
like GPU install in your system and if

[04:36:43 - 04:36:48]
all the tools and let's say services are

[04:36:46 - 04:36:49]
already installed so it will utilize

[04:36:48 - 04:36:51]
that particular GPU that means your ca

[04:36:49 - 04:36:53]
otherwise it will automatically utilize

[04:36:51 - 04:36:55]
your CPU okay so if you see any kinds of

[04:36:53 - 04:36:57]
pyos implementation pyto use this

[04:36:55 - 04:37:00]
particular cod in the pit okay to map

[04:36:57 - 04:37:01]
with your Cuda or with your CPU I hope

[04:37:00 - 04:37:03]
it is clear now the first thing what I

[04:37:01 - 04:37:06]
have to do I have to load my tokenizer

[04:37:03 - 04:37:07]
okay tokenizer and what is tokenizer I

[04:37:06 - 04:37:08]
already explained with the help of

[04:37:07 - 04:37:10]
tokenizer we'll be preprocessing our

[04:37:08 - 04:37:12]
data and I will be converting my text to

[04:37:10 - 04:37:14]
Vector representation so for this I'm

[04:37:12 - 04:37:16]
going to import auto tokenizer from

[04:37:14 - 04:37:18]
Transformer library and another class I

[04:37:16 - 04:37:21]
have imported Auto model for sequence to

[04:37:18 - 04:37:23]
sequence LM because here we'll be uh

[04:37:21 - 04:37:25]
loading one LM model that means we'll be

[04:37:23 - 04:37:27]
loading one Transformer based model and

[04:37:25 - 04:37:28]
to load the Transformer based model

[04:37:27 - 04:37:31]
actually you have to use this particular

[04:37:28 - 04:37:34]
class fine now let me import this

[04:37:31 - 04:37:37]
package now here is the model checkpoint

[04:37:34 - 04:37:39]
guys so here we'll be using one model

[04:37:37 - 04:37:43]
called Google pagas CNN daily mail okay

[04:37:39 - 04:37:44]
so this is the Transformer pre- model

[04:37:43 - 04:37:46]
and this is the model guys this is from

[04:37:44 - 04:37:47]
Google so Google has trained this model

[04:37:46 - 04:37:49]
and this model can perform T

[04:37:47 - 04:37:51]
summarization okay now if you want to

[04:37:49 - 04:37:53]
test it here is the inference API now

[04:37:51 - 04:37:55]
here you can see it will give you the

[04:37:53 - 04:37:57]
summary okay summary of the entire text

[04:37:55 - 04:37:59]
now you can see like what kinds of data

[04:37:57 - 04:38:00]
set they use to train this model every

[04:37:59 - 04:38:03]
information they have given okay about

[04:38:00 - 04:38:04]
the model so if you're interested uh to

[04:38:03 - 04:38:06]
De dive you can check this documentation

[04:38:04 - 04:38:08]
you can check this model card you will

[04:38:06 - 04:38:09]
see each and every details now if you

[04:38:08 - 04:38:12]
want to see the model just click on

[04:38:09 - 04:38:15]
files and version you will see the GB of

[04:38:12 - 04:38:17]
the model it is around 2.28 GB and there

[04:38:15 - 04:38:20]
is another file it is around 3 3 GB okay

[04:38:17 - 04:38:22]
so total I think 5 to 6 GB this

[04:38:20 - 04:38:23]
particular model so whenever I will

[04:38:22 - 04:38:26]
download this model you'll see that okay

[04:38:23 - 04:38:29]
what is the like model size as of now

[04:38:26 - 04:38:31]
let's let's get back so now let's load

[04:38:29 - 04:38:33]
the tokenizer and I already told you uh

[04:38:31 - 04:38:34]
the model actually will be using the

[04:38:33 - 04:38:36]
same model you have to use for the

[04:38:34 - 04:38:38]
tokenization as well fine this is the

[04:38:36 - 04:38:39]
idea now let me load the tokenizer so

[04:38:38 - 04:38:41]
for this I'm using Auto tokenizer from

[04:38:39 - 04:38:42]
pre0 and here I'm giving the model

[04:38:41 - 04:38:46]
checkpoint it will automatically

[04:38:42 - 04:38:46]
download from the hugging face

[04:38:49 - 04:38:54]
itself so fine I have already downloaded

[04:38:52 - 04:38:56]
the tokenizer now we'll be downloading

[04:38:54 - 04:38:58]
the model okay so to download the model

[04:38:56 - 04:39:00]
I'll be using this class Auto model for

[04:38:58 - 04:39:02]
sequence to sequence LM this class and

[04:39:00 - 04:39:04]
there is a function called from preent

[04:39:02 - 04:39:06]
you have to give the model checkpoint

[04:39:04 - 04:39:07]
and two device like in which device you

[04:39:06 - 04:39:09]
want to load the model I want to load

[04:39:07 - 04:39:11]
the model inside my GPU okay that's why

[04:39:09 - 04:39:15]
I'm giving GPU two device is equal to my

[04:39:11 - 04:39:15]
device now let me load it load

[04:39:16 - 04:39:21]
it okay my model has also loaded now

[04:39:20 - 04:39:23]
we'll be loading the data set and data

[04:39:21 - 04:39:25]
set wise we'll be using my data set

[04:39:23 - 04:39:28]
named Samsung data set so this is the

[04:39:25 - 04:39:29]
data set guys so this data set is from

[04:39:28 - 04:39:31]
Samsung actually so they have published

[04:39:29 - 04:39:33]
this data and the Samsung data is

[04:39:31 - 04:39:36]
nothing but it's a data set containing

[04:39:33 - 04:39:38]
about uh 60 16k messenger like

[04:39:36 - 04:39:40]
conversation with somebody that means it

[04:39:38 - 04:39:41]
is having actually different different

[04:39:40 - 04:39:43]
conversation okay

[04:39:41 - 04:39:45]
and uh in the another column actually it

[04:39:43 - 04:39:47]
is having the summaries okay of that

[04:39:45 - 04:39:50]
particular let's say conversation so if

[04:39:47 - 04:39:50]
I show you let's say this is the

[04:39:51 - 04:39:55]
conversation okay this side you are

[04:39:53 - 04:39:59]
having the conversation and this side

[04:39:55 - 04:40:01]
you are having the summary so let's say

[04:39:59 - 04:40:03]
this is the conversation and this is the

[04:40:01 - 04:40:05]
summary okay again this is the

[04:40:03 - 04:40:06]
conversation this is the summary so

[04:40:05 - 04:40:08]
that's how they have collected the

[04:40:06 - 04:40:10]
entire data and it is having 16k

[04:40:08 - 04:40:12]
actually messenger like conversation

[04:40:10 - 04:40:14]
data fine and the data set name is

[04:40:12 - 04:40:18]
Samsung data and if you want to see the

[04:40:14 - 04:40:21]
data set is split so it is having around

[04:40:18 - 04:40:23]
14732 example for the training

[04:40:21 - 04:40:26]
validation that many example and testing

[04:40:23 - 04:40:27]
that many example fine so again you can

[04:40:26 - 04:40:29]
uh see this documentation if you want to

[04:40:27 - 04:40:31]
learn more about this data now let's

[04:40:29 - 04:40:33]
download the data so for this I'll be

[04:40:31 - 04:40:35]
using load data set from my data set uh

[04:40:33 - 04:40:38]
package now let me download the data as

[04:40:35 - 04:40:38]
well

[04:40:43 - 04:40:49]
now I'll give yes and I'll press enter

[04:40:46 - 04:40:52]
it should download the data okay now if

[04:40:49 - 04:40:53]
I show you the data set metadata so this

[04:40:52 - 04:40:55]
is the metadata guys so as I already

[04:40:53 - 04:40:58]
told you it is having dialogue and

[04:40:55 - 04:41:00]
summary and that many of example you are

[04:40:58 - 04:41:02]
having for the training testing and

[04:41:00 - 04:41:04]
validation fine now if you want to see

[04:41:02 - 04:41:07]
any kinds of let's say dialogue that

[04:41:04 - 04:41:08]
means your entire let's say conversation

[04:41:07 - 04:41:09]
you can also visualize so let me

[04:41:08 - 04:41:12]
visualize one of the

[04:41:09 - 04:41:13]
example so this this is the dialogue

[04:41:12 - 04:41:16]
guys you can see Olivia is telling who

[04:41:13 - 04:41:19]
are you voting for this election then

[04:41:16 - 04:41:21]
Olivia is saying Liber as well and

[04:41:19 - 04:41:23]
Olivia me too Olivia great okay so this

[04:41:21 - 04:41:25]
kinds of conversation it is having and

[04:41:23 - 04:41:26]
based on that it is having one summary

[04:41:25 - 04:41:27]
so let me show also show you the summary

[04:41:26 - 04:41:30]
so I'm printing the summary here you can

[04:41:27 - 04:41:33]
see so Olivia and Oliver are voting for

[04:41:30 - 04:41:34]
the Liberals uh in the in this election

[04:41:33 - 04:41:36]
okay so this these kinds of actually

[04:41:34 - 04:41:39]
data set they have prepared now this

[04:41:36 - 04:41:40]
particular quote cipit will print the

[04:41:39 - 04:41:43]
number of example you are having in this

[04:41:40 - 04:41:45]
data set as as well as the split length

[04:41:43 - 04:41:47]
and the let's say enter dialogue and ENT

[04:41:45 - 04:41:50]
summary now let me show

[04:41:47 - 04:41:53]
you see this is the split length this is

[04:41:50 - 04:41:55]
the training validation and testing and

[04:41:53 - 04:41:56]
these are the features it is having like

[04:41:55 - 04:41:59]
ID dialogue and summary and this is the

[04:41:56 - 04:42:01]
entire dialogue you can see okay and

[04:41:59 - 04:42:02]
this is the summary of the dialogue so

[04:42:01 - 04:42:04]
this is the preview of the data that's

[04:42:02 - 04:42:06]
why I just printed let I just wanted to

[04:42:04 - 04:42:08]
show you okay how what kinds of data

[04:42:06 - 04:42:09]
they collected now let's say you are

[04:42:08 - 04:42:12]
having some different kinds of data so

[04:42:09 - 04:42:14]
what you can do you can give your let's

[04:42:12 - 04:42:16]
say entire let's say paragraph As a

[04:42:14 - 04:42:18]
dialogue and the summary as a summary

[04:42:16 - 04:42:21]
okay and you can follow the same

[04:42:18 - 04:42:22]
approach okay it doesn't matter now the

[04:42:21 - 04:42:24]
next thing what I have to do guys I

[04:42:22 - 04:42:25]
think you remember I have to pre-process

[04:42:24 - 04:42:27]
my data and convert to the vector

[04:42:25 - 04:42:29]
representation so for this what I have

[04:42:27 - 04:42:31]
to use I have to use my tokenizer okay I

[04:42:29 - 04:42:32]
think you know and on top of which

[04:42:31 - 04:42:34]
actually let's say column I have to

[04:42:32 - 04:42:35]
apply my tokenizer under dialogue

[04:42:34 - 04:42:39]
because dialogue is

[04:42:35 - 04:42:41]
my uh dialog is my actually paragraph

[04:42:39 - 04:42:42]
and again if you see the summary summary

[04:42:41 - 04:42:44]
is also at text okay so I also need to

[04:42:42 - 04:42:46]
apply the tokenizer on top of the

[04:42:44 - 04:42:48]
summary as well so here I've written a

[04:42:46 - 04:42:49]
function convert example to Features so

[04:42:48 - 04:42:51]
it will take the example batches that

[04:42:49 - 04:42:53]
means your dialogue and summary and it

[04:42:51 - 04:42:55]
will perform the tokenization operation

[04:42:53 - 04:42:57]
you can see so first of all I'm applying

[04:42:55 - 04:43:00]
tokenization on top of my dialogue then

[04:42:57 - 04:43:02]
I'm applying tokenization on top of my

[04:43:00 - 04:43:03]
summary then whatever results actually

[04:43:02 - 04:43:05]
I'm getting I'm just returning that

[04:43:03 - 04:43:06]
means you will get input IDs attention

[04:43:05 - 04:43:08]
mask as well as the labels I think I

[04:43:06 - 04:43:11]
showed you okay from that example now

[04:43:08 - 04:43:12]
let me execute and now let me map this

[04:43:11 - 04:43:14]
this function on top of my entire data

[04:43:12 - 04:43:16]
set okay so see here I'm doing the map

[04:43:14 - 04:43:20]
operation now first of all let me

[04:43:16 - 04:43:22]
convert uh to vectorization then I will

[04:43:20 - 04:43:24]
show you okay how it will look

[04:43:22 - 04:43:28]
like so see execution is done now if I

[04:43:24 - 04:43:29]
show you my data set right now now see

[04:43:28 - 04:43:31]
it is having different different

[04:43:29 - 04:43:32]
features ID dialog summary input IDs

[04:43:31 - 04:43:35]
attention mask and labels okay because I

[04:43:32 - 04:43:36]
converted to the vector representation

[04:43:35 - 04:43:38]
right now now if you want to see the

[04:43:36 - 04:43:39]
input IDs so these are this is nothing

[04:43:38 - 04:43:42]
but your input IDs that means this is

[04:43:39 - 04:43:46]
the vector represent of the first first

[04:43:42 - 04:43:47]
dialogue okay and if you want to see the

[04:43:46 - 04:43:49]
attention mask you can also print

[04:43:47 - 04:43:52]
attention mask so this is the attention

[04:43:49 - 04:43:53]
mask that means uh it is giving all the

[04:43:52 - 04:43:55]
word as the same attention I already

[04:43:53 - 04:43:57]
explained this part fine and if you want

[04:43:55 - 04:43:58]
to print the level as well that me the

[04:43:57 - 04:44:04]
summary you can also print it let me

[04:43:58 - 04:44:04]
show you so here I will print the

[04:44:05 - 04:44:09]
labels so this is the labels okay that

[04:44:08 - 04:44:12]
means this is the summary of this

[04:44:09 - 04:44:14]
dialogue fine I hope it is clear now

[04:44:12 - 04:44:16]
we'll start the training but before that

[04:44:14 - 04:44:17]
what I have to do I have to set some

[04:44:16 - 04:44:19]
training arguments I think you remember

[04:44:17 - 04:44:22]
right but before that one thing you have

[04:44:19 - 04:44:25]
to do if you're using uh large amount of

[04:44:22 - 04:44:27]
data so you have to uh initiate this

[04:44:25 - 04:44:30]
data collator okay so what data collator

[04:44:27 - 04:44:32]
will do data cator will help you to load

[04:44:30 - 04:44:34]
your data as a batches in the memory see

[04:44:32 - 04:44:36]
here you are having so many example I

[04:44:34 - 04:44:38]
showed you now in the training

[04:44:36 - 04:44:40]
validation and testing so I don't need

[04:44:38 - 04:44:42]
to load the entire data in my memory

[04:44:40 - 04:44:45]
because here if you see my memory size

[04:44:42 - 04:44:47]
uh I got actually uh 12gb RAM so if

[04:44:45 - 04:44:50]
you're having huge amount of data so

[04:44:47 - 04:44:51]
12gb Ram is not enough so for this what

[04:44:50 - 04:44:53]
you can do you can load your data as a

[04:44:51 - 04:44:54]
batches that means that means some

[04:44:53 - 04:44:56]
amount of data you will be loading

[04:44:54 - 04:44:57]
you'll be training again you'll be

[04:44:56 - 04:44:59]
taking another batches again you will be

[04:44:57 - 04:45:01]
training that's how you can perform the

[04:44:59 - 04:45:03]
operation so this data collator will

[04:45:01 - 04:45:04]
help you to load your data as a batches

[04:45:03 - 04:45:06]
and if you want to define the data

[04:45:04 - 04:45:08]
collator you have to use this class from

[04:45:06 - 04:45:10]
Transformer data cator for sequence to

[04:45:08 - 04:45:13]
sequence so here you can see I'm passing

[04:45:10 - 04:45:14]
my tokenizer and model inside the data C

[04:45:13 - 04:45:15]
letteror fine then you have to

[04:45:14 - 04:45:18]
initialize this data call letteror

[04:45:15 - 04:45:19]
object so let me initialize it right now

[04:45:18 - 04:45:21]
now the same thing you have to set the

[04:45:19 - 04:45:23]
trading arguments so as I already told

[04:45:21 - 04:45:25]
you just keep all the arguments as same

[04:45:23 - 04:45:27]
no need to change anything only you can

[04:45:25 - 04:45:28]
change the number of epoch okay you will

[04:45:27 - 04:45:31]
be training so as of now I'll be showing

[04:45:28 - 04:45:33]
you only one Epoch training because

[04:45:31 - 04:45:36]
again uh it will take time we are we are

[04:45:33 - 04:45:37]
using free Google collab okay and the

[04:45:36 - 04:45:39]
output directory I want to create

[04:45:37 - 04:45:41]
Pegasus Samsung okay so it will create

[04:45:39 - 04:45:43]
our output directory Pegasus inside that

[04:45:41 - 04:45:46]
it will save all the ARs fine so let me

[04:45:43 - 04:45:48]
initialize the argument as well then I

[04:45:46 - 04:45:50]
will initialize my trainer object so it

[04:45:48 - 04:45:52]
will take the model your training

[04:45:50 - 04:45:54]
argument tokenizer data cator and you

[04:45:52 - 04:45:56]
have to pass the training data now see

[04:45:54 - 04:45:58]
here one small hack actually I'm doing

[04:45:56 - 04:46:01]
see if you see the training data size

[04:45:58 - 04:46:02]
it's very huge so as I already showed

[04:46:01 - 04:46:05]
you

[04:46:02 - 04:46:07]
here so that many training example it is

[04:46:05 - 04:46:09]
having almost 15,000 so if I'm taking

[04:46:07 - 04:46:11]
15,000 data for the training it will

[04:46:09 - 04:46:13]
take lots of time and this is my

[04:46:11 - 04:46:15]
validation and testing so what I'm done

[04:46:13 - 04:46:18]
actually uh instead of taking the

[04:46:15 - 04:46:21]
training data I used actually uh test

[04:46:18 - 04:46:22]
data as my training data because inside

[04:46:21 - 04:46:24]
test data I'm having very less example

[04:46:22 - 04:46:26]
so that I want to show you the quick

[04:46:24 - 04:46:28]
training but if you're training actually

[04:46:26 - 04:46:29]
okay if you are doing the actual

[04:46:28 - 04:46:31]
training that time you just use train

[04:46:29 - 04:46:33]
data okay not the test data so this is

[04:46:31 - 04:46:34]
the hack Guys small hack I'm doing

[04:46:33 - 04:46:36]
because if you want to experiment

[04:46:34 - 04:46:38]
something and you don't have that much

[04:46:36 - 04:46:39]
of time so you can do you can take a

[04:46:38 - 04:46:41]
small amount of data and you can perform

[04:46:39 - 04:46:43]
the let's experiment okay so that is

[04:46:41 - 04:46:44]
what actually you can you can perform

[04:46:43 - 04:46:46]
and here you can see evaluation data I'm

[04:46:44 - 04:46:47]
giving my validation data it's

[04:46:46 - 04:46:50]
completely fine okay now let me

[04:46:47 - 04:46:51]
initialize my trainer now if you want to

[04:46:50 - 04:46:53]
start the training you have to call

[04:46:51 - 04:46:55]
trainer. train now it will start the

[04:46:53 - 04:46:55]
training of the

[04:46:56 - 04:47:01]
model so it will take some time so I

[04:46:59 - 04:47:03]
will pause the video and once training

[04:47:01 - 04:47:05]
is completed I'll come back okay so my

[04:47:03 - 04:47:07]
training is completed now here you can

[04:47:05 - 04:47:09]
see my training

[04:47:07 - 04:47:11]
losses and uh different different matric

[04:47:09 - 04:47:13]
that it is giving but you have to take

[04:47:11 - 04:47:14]
the training losses so this loss should

[04:47:13 - 04:47:15]
be close to zero guys okay if it is

[04:47:14 - 04:47:17]
close to zero that means your model is

[04:47:15 - 04:47:19]
performing well now if you want to

[04:47:17 - 04:47:21]
evaluate this model on of of the test

[04:47:19 - 04:47:24]
data you have to use this function

[04:47:21 - 04:47:26]
calculate Matrix on test DS okay so here

[04:47:24 - 04:47:29]
uh you'll be calculating something

[04:47:26 - 04:47:33]
called row score okay what is row score

[04:47:29 - 04:47:35]
see row score is a matrix for the uh

[04:47:33 - 04:47:37]
summarization model take summarization

[04:47:35 - 04:47:39]
model you can search on Google you will

[04:47:37 - 04:47:41]
find the row row score actually equation

[04:47:39 - 04:47:43]
but as of now I won't suggest just don't

[04:47:41 - 04:47:45]
deep dive into the equation just try to

[04:47:43 - 04:47:47]
consider it just a evaluation Matrix

[04:47:45 - 04:47:49]
like for the classification actually

[04:47:47 - 04:47:51]
what evaluation Matrix we used to use

[04:47:49 - 04:47:55]
like accuracy score then we used to use

[04:47:51 - 04:47:56]
confusion metrics AOC carve right and

[04:47:55 - 04:47:58]
here we are performing something called

[04:47:56 - 04:48:00]
T summarization and T summarization uses

[04:47:58 - 04:48:02]
one Matrix called row score if you want

[04:48:00 - 04:48:04]
to evaluate that model so similar wise

[04:48:02 - 04:48:06]
for language translation we use another

[04:48:04 - 04:48:07]
kinds of matric for let's say name

[04:48:06 - 04:48:09]
entity recognization we use another

[04:48:07 - 04:48:11]
kinds of Matrix for let's say a

[04:48:09 - 04:48:13]
conversational agents we use another

[04:48:11 - 04:48:14]
kinds of metrics okay all kinds of task

[04:48:13 - 04:48:16]
is having their different different

[04:48:14 - 04:48:19]
evaluation metrics okay this is the main

[04:48:16 - 04:48:20]
idea here now before that let me show

[04:48:19 - 04:48:22]
you the models actually it has trained

[04:48:20 - 04:48:24]
now inside Pegasus Samsung folder this

[04:48:22 - 04:48:26]
is the checkpoints inside that you will

[04:48:24 - 04:48:28]
you can see this is the model actually

[04:48:26 - 04:48:30]
it has train now we'll be saving this

[04:48:28 - 04:48:32]
model as well just uh let me first of

[04:48:30 - 04:48:33]
all show you the evaluation matrics then

[04:48:32 - 04:48:36]
I will say uh tell you how we can save

[04:48:33 - 04:48:37]
the model and now you can ask me where I

[04:48:36 - 04:48:40]
got this function see if you just go to

[04:48:37 - 04:48:42]
the hugging face that documentation go

[04:48:40 - 04:48:44]
to the T iation task you will see that

[04:48:42 - 04:48:45]
they are suggesting this function okay

[04:48:44 - 04:48:48]
so they're suggesting if you want to

[04:48:45 - 04:48:49]
perform the evaluation on top of the

[04:48:48 - 04:48:51]
let's say your Tex summarization model

[04:48:49 - 04:48:53]
you can use this row score function okay

[04:48:51 - 04:48:56]
this is the idea now here we'll be

[04:48:53 - 04:48:58]
calculating our row score so here you

[04:48:56 - 04:49:01]
are having actually Four kinds of row

[04:48:58 - 04:49:04]
like Row one row two row large and row L

[04:49:01 - 04:49:06]
sum okay now let me calculate the row

[04:49:04 - 04:49:11]
Score first of all I'll be loading all

[04:49:06 - 04:49:13]
the row matrixes I have to give yes

[04:49:11 - 04:49:17]
then I'll be calculating the score on

[04:49:13 - 04:49:19]
top of my testing data okay now let me

[04:49:17 - 04:49:22]
execute and again I'm only taking 10

[04:49:19 - 04:49:24]
example guys because again because uh it

[04:49:22 - 04:49:25]
is having actually lots of data and it

[04:49:24 - 04:49:28]
will take time that's why I have taken

[04:49:25 - 04:49:30]
only 10 example but if you're performing

[04:49:28 - 04:49:31]
actually so what you can you can remove

[04:49:30 - 04:49:33]
this line that means you are performing

[04:49:31 - 04:49:35]
on top of the entire data right now fine

[04:49:33 - 04:49:36]
this is the small small hack you can

[04:49:35 - 04:49:38]
follow if you're doing the experiment

[04:49:36 - 04:49:41]
only now see guys this is my row code I

[04:49:38 - 04:49:42]
got now guys you can see I got the row

[04:49:41 - 04:49:44]
score and this row score should be close

[04:49:42 - 04:49:46]
to one okay if it is close to one that

[04:49:44 - 04:49:48]
means your model is performing better so

[04:49:46 - 04:49:50]
as of now we used our test data for the

[04:49:48 - 04:49:52]
training and we only train one Epoch

[04:49:50 - 04:49:54]
that's why this uh Roy score is not good

[04:49:52 - 04:49:56]
okay but if you're using actual training

[04:49:54 - 04:49:57]
data and if you train multiple EPO you

[04:49:56 - 04:50:00]
will see that you will get a good Roy

[04:49:57 - 04:50:04]
score here fine now let's save the model

[04:50:00 - 04:50:06]
my Pegasus model so I'm using save F pen

[04:50:04 - 04:50:07]
function and here I'm giving the name it

[04:50:06 - 04:50:10]
will save my

[04:50:07 - 04:50:13]
model so now if I refresh you can see my

[04:50:10 - 04:50:15]
model has saved so this is my model

[04:50:13 - 04:50:18]
Pegasus model my train Pegasus model

[04:50:15 - 04:50:21]
then I also need to save my

[04:50:18 - 04:50:24]
tokenizer because uh later on I'll be

[04:50:21 - 04:50:25]
giving my uh let's say testing data and

[04:50:24 - 04:50:27]
if I want to do the let's say

[04:50:25 - 04:50:28]
summarization task that time it will

[04:50:27 - 04:50:29]
also convert that data to the vector

[04:50:28 - 04:50:32]
representation now see this is my

[04:50:29 - 04:50:33]
tokenizer I also save fine now if you

[04:50:32 - 04:50:36]
want to load any kinds of pretend

[04:50:33 - 04:50:37]
tokenizer what you can do you can use uh

[04:50:36 - 04:50:39]
Auto tokenizer from pretin now you can

[04:50:37 - 04:50:40]
give your tokenizer location okay now

[04:50:39 - 04:50:43]
see here I'm giving my tokenizer

[04:50:40 - 04:50:46]
location not the tokenizer we downloaded

[04:50:43 - 04:50:47]
from the hugging pH okay now let me load

[04:50:46 - 04:50:49]
my tokenizer so this is my custom

[04:50:47 - 04:50:51]
tokenizer right now now this is the

[04:50:49 - 04:50:52]
prediction code okay now to perform the

[04:50:51 - 04:50:55]
prediction first of all you have to

[04:50:52 - 04:50:57]
generate some arguments now you have to

[04:50:55 - 04:50:59]
set the length penalty then number of

[04:50:57 - 04:51:01]
beams then max length so you don't need

[04:50:59 - 04:51:03]
to change this parameter just keep it as

[04:51:01 - 04:51:05]
it is only you can change this length

[04:51:03 - 04:51:07]
panalty what is length penalty I think

[04:51:05 - 04:51:10]
you remember so here we had one let's

[04:51:07 - 04:51:12]
say interface like we can generate short

[04:51:10 - 04:51:13]
output we can generate long output now

[04:51:12 - 04:51:15]
if this parameter is close to one that

[04:51:13 - 04:51:17]
means it will uh generate actually long

[04:51:15 - 04:51:18]
output if it is close to let's say zero

[04:51:17 - 04:51:20]
it will generate short output okay this

[04:51:18 - 04:51:22]
is the idea now here you can see I'm

[04:51:20 - 04:51:25]
taking a sample text from my test data

[04:51:22 - 04:51:26]
I'm taking actually dialogue one uh

[04:51:25 - 04:51:28]
dialog the first dialogue okay you can

[04:51:26 - 04:51:31]
see from the testing data I'm picking up

[04:51:28 - 04:51:34]
the first dialogue let me show you so if

[04:51:31 - 04:51:36]
I execute it

[04:51:34 - 04:51:39]
here so this is the first dialogue I'm

[04:51:36 - 04:51:41]
taking from my test data and I'm Al also

[04:51:39 - 04:51:42]
taking the reference that is the actual

[04:51:41 - 04:51:45]
summary of

[04:51:42 - 04:51:47]
it because I want to match this summary

[04:51:45 - 04:51:49]
with my actual prediction of my model

[04:51:47 - 04:51:52]
this is the actual summary

[04:51:49 - 04:51:53]
right then what I'm doing I'm creating a

[04:51:52 - 04:51:55]
pipeline I think you know what is

[04:51:53 - 04:51:57]
pipeline in hugging Fist and here I'm

[04:51:55 - 04:51:59]
telling I want to perform summarization

[04:51:57 - 04:52:01]
right now and I want to use my model the

[04:51:59 - 04:52:03]
model train so this is the model train

[04:52:01 - 04:52:05]
I'm giving the name of the model you can

[04:52:03 - 04:52:07]
see okay Pegasus Samsung model and here

[04:52:05 - 04:52:10]
I'm passing my tokenizer the tokenizer

[04:52:07 - 04:52:12]
actually I loaded here F then I'm

[04:52:10 - 04:52:13]
creating the pipeline now here I'm

[04:52:12 - 04:52:17]
printing my sample text that means the

[04:52:13 - 04:52:19]
text actually we have loaded this uh

[04:52:17 - 04:52:21]
first dialogue as well as the uh

[04:52:19 - 04:52:24]
reference that means my actual uh

[04:52:21 - 04:52:26]
summary then I'm predicting my uh model

[04:52:24 - 04:52:29]
you can see I'm passing this sample text

[04:52:26 - 04:52:31]
to my pipe object okay my Pipeline and

[04:52:29 - 04:52:34]
here I'm giving all the parameter I set

[04:52:31 - 04:52:35]
here okay then whatever output I'm

[04:52:34 - 04:52:37]
getting I'm only printing the summary

[04:52:35 - 04:52:38]
text of it now let me show you if I

[04:52:37 - 04:52:42]
execute this

[04:52:38 - 04:52:45]
code see this is is my actual dialogue

[04:52:42 - 04:52:47]
this is my actual summary now my model

[04:52:45 - 04:52:49]
is predicting okay the prediction

[04:52:47 - 04:52:51]
summary let's wait and let's try to

[04:52:49 - 04:52:53]
match okay how much accurate it is now

[04:52:51 - 04:52:56]
see guys I got the prediction now just

[04:52:53 - 04:52:58]
try to see now you can see this is the

[04:52:56 - 04:53:00]
model summary that means my model has uh

[04:52:58 - 04:53:03]
given me the summary now see it's not

[04:53:00 - 04:53:05]
very accurate but still it is close to

[04:53:03 - 04:53:07]
because again I told you we only trained

[04:53:05 - 04:53:09]
one oke and we used our testing data for

[04:53:07 - 04:53:11]
the training okay that is why uh it is

[04:53:09 - 04:53:12]
uh actually

[04:53:11 - 04:53:14]
it is not giving actually good

[04:53:12 - 04:53:15]
performance okay and if you want to

[04:53:14 - 04:53:17]
increase the performance what you can do

[04:53:15 - 04:53:19]
you can increase Theo size and you can

[04:53:17 - 04:53:21]
test and you have to train on top of the

[04:53:19 - 04:53:23]
training data okay not on top of the

[04:53:21 - 04:53:25]
test data okay this is the small

[04:53:23 - 04:53:27]
modification you can apply so I hope

[04:53:25 - 04:53:29]
guys uh it make sense right now how we

[04:53:27 - 04:53:30]
can actually Implement different

[04:53:29 - 04:53:32]
different projects with the help of

[04:53:30 - 04:53:33]
hugging face platform now okay that

[04:53:32 - 04:53:35]
means I showed you how we can use

[04:53:33 - 04:53:37]
different different model whether it can

[04:53:35 - 04:53:38]
be LM model whether it can be llm model

[04:53:37 - 04:53:40]
how we can use different different data

[04:53:38 - 04:53:42]
sets okay and how we can use use the

[04:53:40 - 04:53:44]
hugging face pipeline okay to create

[04:53:42 - 04:53:46]
your application so this was my main

[04:53:44 - 04:53:49]
objective the proper use of hugging face

[04:53:46 - 04:53:50]
okay because going forward we we'll be

[04:53:49 - 04:53:53]
utilizing this particular let's say

[04:53:50 - 04:53:55]
technique only to perform all of the

[04:53:53 - 04:53:56]
let's say project okay whatever project

[04:53:55 - 04:53:57]
we'll be doing we'll be following this

[04:53:56 - 04:53:59]
particular approach only and going

[04:53:57 - 04:54:01]
forward I will be also showing you how

[04:53:59 - 04:54:03]
we can use large language model so see

[04:54:01 - 04:54:04]
now we are using LM model only okay

[04:54:03 - 04:54:06]
language model only but going forward

[04:54:04 - 04:54:10]
we'll be using large language model that

[04:54:06 - 04:54:12]
means we'll be using uh uh Lama model

[04:54:10 - 04:54:15]
okay we'll be using Lama model from meta

[04:54:12 - 04:54:17]
we'll be using let's say mral model okay

[04:54:15 - 04:54:19]
we'll be using Falcon model different

[04:54:17 - 04:54:22]
different like large language model will

[04:54:19 - 04:54:24]
be exploring okay so I hope guys this is

[04:54:22 - 04:54:26]
clear now how we can uh perform this TCH

[04:54:24 - 04:54:28]
summarization project now one task I

[04:54:26 - 04:54:29]
want to give you see I already told you

[04:54:28 - 04:54:31]
now we are having different different

[04:54:29 - 04:54:33]
data sets in the hugging phase so you

[04:54:31 - 04:54:34]
can select based on the task let's say

[04:54:33 - 04:54:36]
if I go to the task let's say I want to

[04:54:34 - 04:54:37]
perform summarization I'll click the

[04:54:36 - 04:54:39]
summarization now see these are the data

[04:54:37 - 04:54:42]
related summarization now what you can

[04:54:39 - 04:54:44]
do you can pick up any kinds of data set

[04:54:42 - 04:54:46]
from here okay and you can perform that

[04:54:44 - 04:54:48]
t summarization on top of the data see

[04:54:46 - 04:54:50]
here I used Samsung data but I want you

[04:54:48 - 04:54:52]
to use some many other data okay so

[04:54:50 - 04:54:54]
please try to attempt this task Because

[04:54:52 - 04:54:56]
unless and until you are not doing like

[04:54:54 - 04:54:58]
a practical from your s it would be

[04:54:56 - 04:55:00]
little bit difficult for you so if you

[04:54:58 - 04:55:02]
want to uh actually generate image from

[04:55:00 - 04:55:04]
the text so you have to use something

[04:55:02 - 04:55:05]
called diffusion model OKAY diffusion

[04:55:04 - 04:55:07]
model and what is diffusion model

[04:55:05 - 04:55:09]
diffusion model is kinds of actually

[04:55:07 - 04:55:11]
large language model it is available in

[04:55:09 - 04:55:13]
the hugging phas okay and if you want to

[04:55:11 - 04:55:16]
use diffusion model you have to use one

[04:55:13 - 04:55:18]
Library called diffuser okay diffuser so

[04:55:16 - 04:55:20]
this diffuser will help you to actually

[04:55:18 - 04:55:21]
load these kinds of diffusion model and

[04:55:20 - 04:55:23]
you can perform these kinds of text

[04:55:21 - 04:55:25]
image generation so again it is

[04:55:23 - 04:55:27]
available inside hugging face only so

[04:55:25 - 04:55:29]
you don't need to go to the any any

[04:55:27 - 04:55:31]
other platform okay so additionally we

[04:55:29 - 04:55:32]
just need to install another Library

[04:55:31 - 04:55:34]
called diffuser and with the help of

[04:55:32 - 04:55:36]
that we can easily access that diffusion

[04:55:34 - 04:55:38]
model as of now I don't need the gradio

[04:55:36 - 04:55:40]
here I can remove it so these are the

[04:55:38 - 04:55:42]
library actually I have to install here

[04:55:40 - 04:55:44]
so as you can see diffusers is the

[04:55:42 - 04:55:46]
hugging face page for uh using the

[04:55:44 - 04:55:48]
diffuser diffusion model from the

[04:55:46 - 04:55:50]
hugging face Hub so here you can see let

[04:55:48 - 04:55:54]
me show you the page actually I have

[04:55:50 - 04:55:54]
already um given the

[04:55:57 - 04:56:02]
link so see this diffusers is available

[04:56:00 - 04:56:04]
inside huging face only so they have

[04:56:02 - 04:56:06]
already uh written like how we can

[04:56:04 - 04:56:08]
install it okay and how we can load the

[04:56:06 - 04:56:09]
diffusion model and all every example

[04:56:08 - 04:56:11]
they have already given here fine so I

[04:56:09 - 04:56:13]
have followed this documentation guys

[04:56:11 - 04:56:15]
and I prepared one notebook for you and

[04:56:13 - 04:56:17]
let me show you how we can perform this

[04:56:15 - 04:56:19]
texture image generation with the help

[04:56:17 - 04:56:20]
of different different large language

[04:56:19 - 04:56:22]
model and here the model actually

[04:56:20 - 04:56:24]
will'll be using guys this is actually

[04:56:22 - 04:56:27]
multi model that means this model uses

[04:56:24 - 04:56:28]
both kinds of architecture your uh NLP

[04:56:27 - 04:56:30]
architecture as well as the computer

[04:56:28 - 04:56:32]
vision architecture because here you

[04:56:30 - 04:56:34]
have to give the prompt that means text

[04:56:32 - 04:56:36]
is nothing but your prompt okay and it

[04:56:34 - 04:56:38]
will generate the image that means first

[04:56:36 - 04:56:39]
of all it will process the text then it

[04:56:38 - 04:56:41]
will process that particular image okay

[04:56:39 - 04:56:43]
image output so that's why it is using

[04:56:41 - 04:56:45]
something called hybrid architecture

[04:56:43 - 04:56:47]
okay so it is called actually multimodel

[04:56:45 - 04:56:50]
I hope you cleared now let me install

[04:56:47 - 04:56:50]
all required package I need

[04:56:53 - 04:56:57]
here now let me import this stable

[04:56:55 - 04:57:00]
diffusion pipeline for diffuses uh the

[04:56:57 - 04:57:01]
same way actually we used to load our

[04:57:00 - 04:57:03]
pipeline I think you remember from the

[04:57:01 - 04:57:05]
Transformer so here also we have to load

[04:57:03 - 04:57:07]
the pipeline for the defur okay now I

[04:57:05 - 04:57:09]
also need the matte plot Le because I

[04:57:07 - 04:57:11]
want to visualize the image then I also

[04:57:09 - 04:57:12]
need the torch Library

[04:57:11 - 04:57:14]
now if you want to see the version of

[04:57:12 - 04:57:16]
any package you can execute this command

[04:57:14 - 04:57:19]
keep show the package name it will show

[04:57:16 - 04:57:21]
you the version okay now here I kept

[04:57:19 - 04:57:23]
actually two kinds of diffusion model uh

[04:57:21 - 04:57:24]
this is the model ID one and this is the

[04:57:23 - 04:57:27]
model ID 2 you can see the first model

[04:57:24 - 04:57:30]
this is the first model so the model

[04:57:27 - 04:57:32]
name is uh dream like diffusion 1.0 so

[04:57:30 - 04:57:35]
this is the model guys and it is

[04:57:32 - 04:57:37]
available in the hugging fiz Hub okay

[04:57:35 - 04:57:38]
see whatever models actually you can see

[04:57:37 - 04:57:40]
in the model section this is called

[04:57:38 - 04:57:42]
actually hugging fiz Hub that means in

[04:57:40 - 04:57:43]
the hub also you can upload your own

[04:57:42 - 04:57:46]
model it is possible let's say if I

[04:57:43 - 04:57:48]
click on the model now so inside this

[04:57:46 - 04:57:50]
model you can upload your own model

[04:57:48 - 04:57:51]
let's see fine tuned one model and you

[04:57:50 - 04:57:53]
want to share with the community you can

[04:57:51 - 04:57:54]
also push your model here okay so that

[04:57:53 - 04:57:56]
other people can download your model and

[04:57:54 - 04:57:58]
they can use it okay I also tell you how

[04:57:56 - 04:58:00]
you can push your model to the hugging

[04:57:58 - 04:58:02]
pH Hub everything I'll try to show you

[04:58:00 - 04:58:03]
even you can also upload your own data

[04:58:02 - 04:58:05]
set okay it is also possible here now

[04:58:03 - 04:58:07]
this is the model guys you can read

[04:58:05 - 04:58:08]
about the model and this is the few

[04:58:07 - 04:58:09]
results actually you can see they have

[04:58:08 - 04:58:11]
given different different prompt and

[04:58:09 - 04:58:12]
these these are the results they have

[04:58:11 - 04:58:14]
generated okay this is one of the

[04:58:12 - 04:58:15]
amazing model even they have also given

[04:58:14 - 04:58:17]
the code s it how we can use it and all

[04:58:15 - 04:58:20]
everything they have given now another

[04:58:17 - 04:58:23]
model actually uh this one the model

[04:58:20 - 04:58:25]
name is St diffusions Exel base 1.0 this

[04:58:23 - 04:58:26]
is the model so this is the model

[04:58:25 - 04:58:27]
architecture high level architecture

[04:58:26 - 04:58:29]
that means first of all you have to give

[04:58:27 - 04:58:31]
the prompt and with the help of actually

[04:58:29 - 04:58:33]
Transformer

[04:58:31 - 04:58:34]
model uh what they will do they will

[04:58:33 - 04:58:37]
just try to understand this prompt and

[04:58:34 - 04:58:38]
they to try to perform the tokenization

[04:58:37 - 04:58:39]
convert to the vector representation

[04:58:38 - 04:58:41]
okay that means converting to the

[04:58:39 - 04:58:45]
embedding then they'll be creating one

[04:58:41 - 04:58:48]
latent Dimension 120x 120x and this

[04:58:45 - 04:58:51]
latent Dimension will pass to the unit

[04:58:48 - 04:58:53]
model if you don't know uh inside stable

[04:58:51 - 04:58:55]
defion actually unit model is used so

[04:58:53 - 04:58:56]
Unit Model will try to generate the

[04:58:55 - 04:58:57]
image okay with respect to the prompt

[04:58:56 - 04:58:59]
user has given okay you can see last

[04:58:57 - 04:59:01]
time getting the image output again they

[04:58:59 - 04:59:02]
have already given the paper link and

[04:59:01 - 04:59:04]
all if you're interested you can open it

[04:59:02 - 04:59:06]
up and you can learn okay see they have

[04:59:04 - 04:59:08]
also given the code example now let me

[04:59:06 - 04:59:10]
show you how we can use this model so

[04:59:08 - 04:59:12]
what I've done guys uh I'm loading the

[04:59:10 - 04:59:14]
first model you can see uh St divion

[04:59:12 - 04:59:16]
pipeline from preon I'm loading the

[04:59:14 - 04:59:18]
first model and here you have to give

[04:59:16 - 04:59:21]
some parameter okay that means TS uh

[04:59:18 - 04:59:22]
data type t. float 64 and use uh save

[04:59:21 - 04:59:25]
tensor is equal to two Okay you have to

[04:59:22 - 04:59:27]
pass this two parameter now I'm loading

[04:59:25 - 04:59:29]
this uh model inside my Cuda that means

[04:59:27 - 04:59:31]
inside my GPU because if you load inside

[04:59:29 - 04:59:32]
your CPU it will take lots of time right

[04:59:31 - 04:59:36]
so that's why I'm loading everything

[04:59:32 - 04:59:36]
inside my GPU now let me show

[04:59:38 - 04:59:43]
you see it is downloading the model now

[04:59:42 - 04:59:47]
here I have prepared one prompt guys you

[04:59:43 - 04:59:51]
can see this prompt dream like art a uh

[04:59:47 - 04:59:54]
gri woman with uh rainbow hair traveling

[04:59:51 - 04:59:59]
between Dimensions Dynamic poses happy

[04:59:54 - 05:00:02]
soft eyes and narrow CH chain uh extreme

[04:59:59 - 05:00:06]
bouet Dy figure long hair straight down

[05:00:02 - 05:00:08]
and tone uh qualy shot and baggy okay so

[05:00:06 - 05:00:10]
this is my prompt actually I have

[05:00:08 - 05:00:13]
prepared now you can give any kinds of

[05:00:10 - 05:00:14]
prompt if you feel like okay you have to

[05:00:13 - 05:00:16]
use this prompt you can give it here now

[05:00:14 - 05:00:17]
this prompt actually I have to give my

[05:00:16 - 05:00:20]
pipeline object that means inside my

[05:00:17 - 05:00:23]
model and model will give me the image

[05:00:20 - 05:00:26]
Matrix okay so let me show

[05:00:23 - 05:00:28]
you so it is generating this image right

[05:00:26 - 05:00:31]
now I think currently in the chat GPT

[05:00:28 - 05:00:35]
also it is having one model called GPT

[05:00:31 - 05:00:37]
4.0 okay so this model also can generate

[05:00:35 - 05:00:40]
uh actually different different image so

[05:00:37 - 05:00:41]
see create an image for my presentation

[05:00:40 - 05:00:44]
now if I click here now see it is

[05:00:41 - 05:00:47]
utilizing something called GPT

[05:00:44 - 05:00:50]
4.0 see if I click here see GPT 4.0

[05:00:47 - 05:00:52]
they're using now it is asking uh just

[05:00:50 - 05:00:55]
try to give any kinds of prompt let's

[05:00:52 - 05:00:58]
say if I give same prompt

[05:00:55 - 05:00:58]
here let's see what

[05:00:59 - 05:01:03]
happens see it is generating the image

[05:01:01 - 05:01:06]
right

[05:01:03 - 05:01:08]
now so they are also using these kinds

[05:01:06 - 05:01:10]
of uh like diffusion model in the back

[05:01:08 - 05:01:11]
endend U multimodel model that means

[05:01:10 - 05:01:15]
they're understanding The Prompt then

[05:01:11 - 05:01:15]
they're generating the image

[05:01:15 - 05:01:21]
okay see okay this is the output I got

[05:01:19 - 05:01:22]
now let's see uh from my model actually

[05:01:21 - 05:01:25]
the model actually I'm referring from

[05:01:22 - 05:01:26]
the hugging face see if I uh plot this

[05:01:25 - 05:01:29]
image right now you can see this is the

[05:01:26 - 05:01:32]
results I got now see the chat GPT and

[05:01:29 - 05:01:33]
see my results both are pretty good now

[05:01:32 - 05:01:35]
you can also plot with the help of M

[05:01:33 - 05:01:38]
plot Le it is also

[05:01:35 - 05:01:39]
possible first of all I'm uh like uh

[05:01:38 - 05:01:42]
printing The Prompt then I'm printing

[05:01:39 - 05:01:44]
the image okay now let me give another

[05:01:42 - 05:01:47]
prompt a girl is sitting on a chair and

[05:01:44 - 05:01:49]
she is accompanied by her tiger make

[05:01:47 - 05:01:54]
sure to keep it cinematic and color to

[05:01:49 - 05:01:54]
be golden ID okay now let me see the

[05:01:54 - 05:02:00]
output the same prompt you can give to

[05:01:56 - 05:02:00]
the chat GPT as well let's

[05:02:02 - 05:02:09]
see so here I think I got the results

[05:02:05 - 05:02:09]
now let me plot the image

[05:02:11 - 05:02:16]
see this is the image I got and see this

[05:02:14 - 05:02:18]
is the image I got from my chat GPT so

[05:02:16 - 05:02:20]
both are good guys now I think you got

[05:02:18 - 05:02:22]
it how we can use these kinds of

[05:02:20 - 05:02:24]
actually multimodel as well okay if I

[05:02:22 - 05:02:26]
want to let's say generate text to image

[05:02:24 - 05:02:29]
or image to text okay everything is

[05:02:26 - 05:02:32]
possible now if I show you so if you

[05:02:29 - 05:02:35]
just go to the hugging phas model

[05:02:32 - 05:02:36]
section uh here if you click on the

[05:02:35 - 05:02:38]
model now see here you are having

[05:02:36 - 05:02:39]
different different task let's say you

[05:02:38 - 05:02:41]
want to perform text to image gener

[05:02:39 - 05:02:43]
generation so here is the task guys

[05:02:41 - 05:02:44]
inside computer vision you can select it

[05:02:43 - 05:02:46]
now see you are having different

[05:02:44 - 05:02:48]
different model so here I was using

[05:02:46 - 05:02:50]
diffusion model you can also use any

[05:02:48 - 05:02:53]
other model okay see how that many of

[05:02:50 - 05:02:55]
models are available around 34,000 model

[05:02:53 - 05:02:56]
you can use any of the model okay any of

[05:02:55 - 05:02:59]
the model and you can try so this should

[05:02:56 - 05:03:01]
be your task guys I will uh leave it to

[05:02:59 - 05:03:03]
you you can explore any kinds of model

[05:03:01 - 05:03:05]
from The Hub itself okay only select

[05:03:03 - 05:03:06]
this task text to image okay now let's

[05:03:05 - 05:03:08]
see if you want to perform image to text

[05:03:06 - 05:03:10]
that time select this one and you can

[05:03:08 - 05:03:13]
see the different different even if you

[05:03:10 - 05:03:15]
want to see the example open it up they

[05:03:13 - 05:03:16]
have also given the lots of example here

[05:03:15 - 05:03:19]
okay for snippit everything they have

[05:03:16 - 05:03:20]
given you can learn from here so this is

[05:03:19 - 05:03:23]
the best platform guys if you want to

[05:03:20 - 05:03:25]
Deep dive inside hugging face fine now

[05:03:23 - 05:03:26]
we'll be learning some uh parameters of

[05:03:25 - 05:03:29]
the diffusion model like you can set

[05:03:26 - 05:03:30]
some of the parameter okay uh let's say

[05:03:29 - 05:03:32]
You Want U actually different

[05:03:30 - 05:03:34]
dimensional image you want to let's add

[05:03:32 - 05:03:35]
some more uh parameter in that image you

[05:03:34 - 05:03:37]
can also do it for this I created a

[05:03:35 - 05:03:39]
function generate image so it will take

[05:03:37 - 05:03:40]
the pipeline object prompt as well as

[05:03:39 - 05:03:42]
the parameter

[05:03:40 - 05:03:43]
and whatever things actually will be

[05:03:42 - 05:03:45]
assigning the parameter it will set

[05:03:43 - 05:03:47]
inside Pipeline and it will render the

[05:03:45 - 05:03:50]
image with the help of M plot l so let

[05:03:47 - 05:03:51]
me execute see that many of actually

[05:03:50 - 05:03:54]
parameter you can play with negative

[05:03:51 - 05:03:57]
prompting n num inference St height

[05:03:54 - 05:03:59]
weight okay number uh number of IM part

[05:03:57 - 05:04:00]
prompt okay let to say this is another

[05:03:59 - 05:04:02]
prompt I have prepared as of now

[05:04:00 - 05:04:04]
parameter I'm not giving anything it's

[05:04:02 - 05:04:06]
empty now if I pause these are the thing

[05:04:04 - 05:04:09]
inside my generate function so it will

[05:04:06 - 05:04:09]
give me the image

[05:04:11 - 05:04:16]
so this is the prompt uh dream like

[05:04:13 - 05:04:19]
beautiful girl playing the Festival of

[05:04:16 - 05:04:22]
Color wrapped in traditional India uh at

[05:04:19 - 05:04:23]
throwing uh colors okay this is my

[05:04:22 - 05:04:25]
prompt now you can see based on the

[05:04:23 - 05:04:26]
prompt it has given me one beautiful

[05:04:25 - 05:04:28]
image okay see beautiful image it has

[05:04:26 - 05:04:30]
generated now you can give any kinds of

[05:04:28 - 05:04:31]
prompt let's say number of inference

[05:04:30 - 05:04:33]
step I have given 100 now let's see what

[05:04:31 - 05:04:37]
kinds of input I

[05:04:33 - 05:04:39]
get you can see the documentation of the

[05:04:37 - 05:04:41]
like this one uh def diffusers you will

[05:04:39 - 05:04:43]
see different different um actually

[05:04:41 - 05:04:46]
parameter we having there see this is

[05:04:43 - 05:04:47]
another example now you can see both

[05:04:46 - 05:04:50]
image are

[05:04:47 - 05:04:51]
same I can't see any difference now

[05:04:50 - 05:04:53]
let's see with any other actually

[05:04:51 - 05:04:55]
parameter let's say height I want to

[05:04:53 - 05:04:57]
change actually different height uh

[05:04:55 - 05:04:58]
height and weight so for this you can

[05:04:57 - 05:05:01]
pass this height and weight parameter

[05:04:58 - 05:05:01]
here now let me

[05:05:04 - 05:05:10]
see so now you can see guys I got the

[05:05:07 - 05:05:11]
results and in a different height and

[05:05:10 - 05:05:13]
width right now so that's how you can

[05:05:11 - 05:05:15]
play with different different parameter

[05:05:13 - 05:05:17]
now let's see another parameter uh

[05:05:15 - 05:05:19]
number per image prompt that means if I

[05:05:17 - 05:05:21]
want to let's say generate multiple

[05:05:19 - 05:05:22]
image that time I can give image number

[05:05:21 - 05:05:24]
of image per prom two that means it will

[05:05:22 - 05:05:27]
give me two image right

[05:05:24 - 05:05:29]
now so here is the results now I'm

[05:05:27 - 05:05:31]
getting two uh output from my image now

[05:05:29 - 05:05:33]
let's say you want to get three you can

[05:05:31 - 05:05:35]
give three here now let's also see the

[05:05:33 - 05:05:38]
negative prompting so here I have added

[05:05:35 - 05:05:40]
negative prompt ugly destroyed and low

[05:05:38 - 05:05:41]
quality let's say this this is my

[05:05:40 - 05:05:44]
negative prompt now let's see whether it

[05:05:41 - 05:05:44]
is able to generate or

[05:05:46 - 05:05:52]
not so right now you can see uh See this

[05:05:50 - 05:05:54]
results and this results I think you can

[05:05:52 - 05:05:57]
see the difference this is little bit uh

[05:05:54 - 05:05:59]
low quality and the prompt I have given

[05:05:57 - 05:06:01]
ugly destroyed and low quality so it is

[05:05:59 - 05:06:04]
almost matching I think fine so yes

[05:06:01 - 05:06:07]
that's how we can uh use this kinds of

[05:06:04 - 05:06:10]
like multimodel and I can uh do the text

[05:06:07 - 05:06:11]
to image generation fine now I already

[05:06:10 - 05:06:13]
showed you we are having so many model

[05:06:11 - 05:06:15]
guys just try to explore from your end

[05:06:13 - 05:06:17]
some of the model and try to um like

[05:06:15 - 05:06:20]
Implement any kinds of projects fine so

[05:06:17 - 05:06:22]
guys so far what we have learned so we

[05:06:20 - 05:06:25]
saw like uh how we can use the existing

[05:06:22 - 05:06:27]
model from the uh hugging pH that means

[05:06:25 - 05:06:28]
let's say if you want to use any

[05:06:27 - 05:06:30]
pre-rain

[05:06:28 - 05:06:33]
model

[05:06:30 - 05:06:35]
pre-train model you can directly use it

[05:06:33 - 05:06:37]
so you have to use something called

[05:06:35 - 05:06:38]
pipeline okay pipeline for this inside

[05:06:37 - 05:06:40]
pipeline you have to mention the task

[05:06:38 - 05:06:41]
you want to perform

[05:06:40 - 05:06:42]
okay let's say you want to perform

[05:06:41 - 05:06:44]
sentiment analysis you want to perform

[05:06:42 - 05:06:45]
let's say translation you want to

[05:06:44 - 05:06:48]
perform let's say summarization you can

[05:06:45 - 05:06:50]
mention all else what you can do you can

[05:06:48 - 05:06:52]
also do the fine tuning operation okay

[05:06:50 - 05:06:56]
fine

[05:06:52 - 05:06:56]
tuning of a pre-end

[05:06:57 - 05:07:02]
model okay and I already showed you one

[05:07:00 - 05:07:04]
fine tuning example like I did the tex

[05:07:02 - 05:07:07]
summarization okay take summarization so

[05:07:04 - 05:07:09]
there I trained on top of my custom data

[05:07:07 - 05:07:10]
now you can ask me when we have to use

[05:07:09 - 05:07:13]
pretend model and when you have to do

[05:07:10 - 05:07:15]
the fing operation so let's say whenever

[05:07:13 - 05:07:17]
you are having a problem statement let's

[05:07:15 - 05:07:19]
say uh let's say you want to do T

[05:07:17 - 05:07:22]
summarization only take summarization

[05:07:19 - 05:07:23]
only okay take summarization only first

[05:07:22 - 05:07:26]
of all try to use the existing model

[05:07:23 - 05:07:28]
that means the pre-end model OKAY

[05:07:26 - 05:07:30]
pre-end model let's say I showed you one

[05:07:28 - 05:07:32]
model now Google Pegasus that CNN daily

[05:07:30 - 05:07:33]
mail model try to use that model and try

[05:07:32 - 05:07:36]
to see whether your model is able to

[05:07:33 - 05:07:38]
give the correct let's say summary or

[05:07:36 - 05:07:39]
not correct summary or not if it is able

[05:07:38 - 05:07:42]
to give the correct summary then why you

[05:07:39 - 05:07:44]
need to do fine tuning definitely not

[05:07:42 - 05:07:46]
you can use this model as it is right

[05:07:44 - 05:07:47]
but let's say if your data is little bit

[05:07:46 - 05:07:49]
different let's say you are using

[05:07:47 - 05:07:52]
something called um let's say banking

[05:07:49 - 05:07:54]
data okay banking data banking related

[05:07:52 - 05:07:55]
let's say conversation you are having

[05:07:54 - 05:07:58]
and this conversation is not working

[05:07:55 - 05:08:00]
with that pre-end model that time what

[05:07:58 - 05:08:03]
you can do you can collect your own data

[05:08:00 - 05:08:07]
that means your custom data okay custom

[05:08:03 - 05:08:10]
data and based on that you can f you one

[05:08:07 - 05:08:12]
okay f t one pre model

[05:08:10 - 05:08:14]
that means you are using one freend

[05:08:12 - 05:08:16]
model on top of that you are adding some

[05:08:14 - 05:08:18]
more knowledge then this model will be

[05:08:16 - 05:08:20]
able to also work with the banking data

[05:08:18 - 05:08:21]
as well this is the idea only okay now I

[05:08:20 - 05:08:23]
think you got it when you have to use

[05:08:21 - 05:08:25]
the pre-end model and when you have to

[05:08:23 - 05:08:27]
do the F evening operation it can be for

[05:08:25 - 05:08:29]
all kinds of let's say model it can be

[05:08:27 - 05:08:31]
for the multi model it can be for the

[05:08:29 - 05:08:34]
for the let's say LM model it can be for

[05:08:31 - 05:08:36]
the LM model any kinds of model actually

[05:08:34 - 05:08:37]
it can be applied okay so the model I

[05:08:36 - 05:08:40]
showed you now right now this diffusion

[05:08:37 - 05:08:42]
model this text image generation model

[05:08:40 - 05:08:44]
let's say if it is not able to generate

[05:08:42 - 05:08:46]
the image the way actually you are

[05:08:44 - 05:08:48]
generate giving the prompt that what you

[05:08:46 - 05:08:50]
can do you can find tune this model it

[05:08:48 - 05:08:52]
is also possible you can also F tune the

[05:08:50 - 05:08:53]
division model and how to fine tune

[05:08:52 - 05:08:55]
again they have given all the let's say

[05:08:53 - 05:08:57]
article here fine tuning everything they

[05:08:55 - 05:08:59]
have given if you just go to their

[05:08:57 - 05:09:01]
documentation you easily learn even I I

[05:08:59 - 05:09:02]
will also show you in future okay how we

[05:09:01 - 05:09:05]
can do the fine tuning of the large

[05:09:02 - 05:09:10]
language model for this we'll be using

[05:09:05 - 05:09:12]
another technique called p e f T okay

[05:09:10 - 05:09:15]
that means parameter efficient fine

[05:09:12 - 05:09:17]
tuning what is PF I will tell you

[05:09:15 - 05:09:18]
parameter efficient fine tuning because

[05:09:17 - 05:09:20]
what happens these kinds of large

[05:09:18 - 05:09:23]
language model is very huge and I can't

[05:09:20 - 05:09:24]
train this kinds of model actually on my

[05:09:23 - 05:09:26]
uh this kinds of machine the Google

[05:09:24 - 05:09:28]
collab actually I'm taking because it's

[05:09:26 - 05:09:29]
a huge model huge parameter for this we

[05:09:28 - 05:09:31]
have to follow this parameter equation

[05:09:29 - 05:09:33]
fing process okay that time I'll discuss

[05:09:31 - 05:09:35]
what is the use of that and how we can

[05:09:33 - 05:09:37]
find tune those example on example and

[05:09:35 - 05:09:40]
all okay everything I'll try to clarify

[05:09:37 - 05:09:41]
as of now I'm only the exploring like uh

[05:09:40 - 05:09:43]
the service actually it is having so

[05:09:41 - 05:09:45]
that you can get familiar with okay that

[05:09:43 - 05:09:46]
are the things actually we can perform

[05:09:45 - 05:09:49]
with this particular platform like how

[05:09:46 - 05:09:52]
we can do text to speech generation with

[05:09:49 - 05:09:54]
the uh llm okay uh with the help of this

[05:09:52 - 05:09:56]
hugging face platform so again I have to

[05:09:54 - 05:09:59]
install this Transformer library because

[05:09:56 - 05:10:02]
inside that uh only I'm having all the

[05:09:59 - 05:10:05]
let's say if I search for hugging fish

[05:10:02 - 05:10:06]
so if I go to the model section so now

[05:10:05 - 05:10:08]
let's say we'll be working with the

[05:10:06 - 05:10:11]
audios that means text to speech now if

[05:10:08 - 05:10:12]
I click on text T to speech see uh it is

[05:10:11 - 05:10:14]
having actually different different

[05:10:12 - 05:10:15]
model OKAY different different model

[05:10:14 - 05:10:17]
actually it is having but the model

[05:10:15 - 05:10:20]
actually I'm going to use this model

[05:10:17 - 05:10:22]
called Sono bark small model so this is

[05:10:20 - 05:10:24]
one of the Transformer Bas text to Audio

[05:10:22 - 05:10:26]
model created by Sono okay now if you

[05:10:24 - 05:10:27]
want to read about this you can go ahead

[05:10:26 - 05:10:30]
and try to read about this particular

[05:10:27 - 05:10:31]
model even they also given the example

[05:10:30 - 05:10:32]
even though they have also given the

[05:10:31 - 05:10:34]
collab notebook how you can use it see

[05:10:32 - 05:10:36]
this the collab notebook they have given

[05:10:34 - 05:10:37]
but so many things they have written so

[05:10:36 - 05:10:38]
what I have done I just simplified this

[05:10:37 - 05:10:40]
notebook and this notebook I created

[05:10:38 - 05:10:42]
okay now let me show you how you can

[05:10:40 - 05:10:43]
perform the text to speech Generation

[05:10:42 - 05:10:45]
Now for this first of all I have to

[05:10:43 - 05:10:48]
import the uh pipeline from the

[05:10:45 - 05:10:49]
Transformer and here is the text guys so

[05:10:48 - 05:10:52]
this text actually I'll be converting to

[05:10:49 - 05:10:54]
the audio now see python is a high level

[05:10:52 - 05:10:56]
uh uh general purpose programming

[05:10:54 - 05:10:57]
language this is my text now in the

[05:10:56 - 05:10:58]
pipeline I want to perform text to

[05:10:57 - 05:11:01]
speech I Have to Give and I have to give

[05:10:58 - 05:11:04]
the model so here I'm giving my model ID

[05:11:01 - 05:11:05]
this is my model ID bark small model

[05:11:04 - 05:11:07]
then device is equal to CODA because I

[05:11:05 - 05:11:09]
want to load my model inside my GPU now

[05:11:07 - 05:11:11]
it will give you the output and output

[05:11:09 - 05:11:15]
would be a uh numpy array so let me show

[05:11:11 - 05:11:17]
you if I just execute this program see

[05:11:15 - 05:11:19]
now if I print the output output would

[05:11:17 - 05:11:21]
be a numpy array okay now I have to

[05:11:19 - 05:11:23]
convert this numpy array to audio that

[05:11:21 - 05:11:25]
me audio frequency for this I'll be

[05:11:23 - 05:11:27]
using one Library I python display audio

[05:11:25 - 05:11:29]
this Library will be using and I have to

[05:11:27 - 05:11:31]
give this array as well as the sampling

[05:11:29 - 05:11:33]
rate okay so here you can see I'm

[05:11:31 - 05:11:35]
passing my audio that means this array

[05:11:33 - 05:11:37]
as well as the sampling rate now if I

[05:11:35 - 05:11:39]
execute it will automatically convert

[05:11:37 - 05:11:43]
this uh array to the audio now see if I

[05:11:39 - 05:11:46]
play python is a high level general

[05:11:43 - 05:11:48]
purpose programming language um see I

[05:11:46 - 05:11:50]
think you uh hard of okay it is uh

[05:11:48 - 05:11:51]
speaking that particular text now you

[05:11:50 - 05:11:54]
can give any kinds of text it will

[05:11:51 - 05:11:55]
generate the speech for that fine now

[05:11:54 - 05:11:57]
you can play with different different

[05:11:55 - 05:11:58]
model guys I already showed you it is

[05:11:57 - 05:12:01]
having different different model you can

[05:11:58 - 05:12:03]
try with different different model OKAY

[05:12:01 - 05:12:05]
U see I was using this model bar uh

[05:12:03 - 05:12:07]
small model you can also use any other

[05:12:05 - 05:12:08]
model okay it's up to you so that's how

[05:12:07 - 05:12:10]
guys you can explore this hugging face

[05:12:08 - 05:12:12]
it's an amazing platform and it's like

[05:12:10 - 05:12:14]
very powerful platform guys in the field

[05:12:12 - 05:12:16]
of generative a or in the field of

[05:12:14 - 05:12:18]
natural language processing if you don't

[05:12:16 - 05:12:20]
know about open a open is a platform for

[05:12:18 - 05:12:22]
the generative a so with the help of

[05:12:20 - 05:12:25]
open you can Implement any kinds of

[05:12:22 - 05:12:26]
generative a application open provides

[05:12:25 - 05:12:29]
lots of commercial large language model

[05:12:26 - 05:12:31]
like GPT series uh I think you already

[05:12:29 - 05:12:33]
used hugging F right so this is the

[05:12:31 - 05:12:36]
similar kinds of platform of the hugging

[05:12:33 - 05:12:40]
F so hugging F provides all the model

[05:12:36 - 05:12:41]
all the data set as free but uh provides

[05:12:40 - 05:12:43]
uh actually everything as a paid that

[05:12:41 - 05:12:44]
means you have to take their

[05:12:43 - 05:12:46]
subscription so if you're taking their

[05:12:44 - 05:12:48]
subscription that time actually you can

[05:12:46 - 05:12:50]
use their premium model apart from that

[05:12:48 - 05:12:52]
openi provides some of the model for the

[05:12:50 - 05:12:54]
fre access so that at least you can do

[05:12:52 - 05:12:55]
some experiment okay with this model but

[05:12:54 - 05:12:58]
if you want to build let's say

[05:12:55 - 05:12:59]
production grid application that time uh

[05:12:58 - 05:13:01]
they are suggesting to take their

[05:12:59 - 05:13:03]
premium model so guys through couple of

[05:13:01 - 05:13:05]
video we'll be learning about this open

[05:13:03 - 05:13:06]
and its platform so here we'll be

[05:13:05 - 05:13:08]
learning all the services from the

[05:13:06 - 05:13:11]
openai how we can use the entire

[05:13:08 - 05:13:12]
openform platform so everything I'll

[05:13:11 - 05:13:15]
show you here how we can generate open

[05:13:12 - 05:13:16]
opena API key how we can access like

[05:13:15 - 05:13:18]
different different model okay and how

[05:13:16 - 05:13:20]
we can Implement different different

[05:13:18 - 05:13:23]
application so let's open our open

[05:13:20 - 05:13:26]
platform so guys if you want to open

[05:13:23 - 05:13:28]
this open platform just search for openi

[05:13:26 - 05:13:31]
login uh so you'll get the first website

[05:13:28 - 05:13:32]
open platform so make sure you have one

[05:13:31 - 05:13:34]
account if you don't have account you

[05:13:32 - 05:13:36]
have to first of all create one account

[05:13:34 - 05:13:38]
and whenever you are creating an account

[05:13:36 - 05:13:40]
uh it will ask for your card so try to

[05:13:38 - 05:13:43]
add your C so you will get initially

[05:13:40 - 05:13:44]
actually $5 credit here okay I think $5

[05:13:43 - 05:13:47]
credit you will get then once you use

[05:13:44 - 05:13:48]
that $5 credits then what you have to do

[05:13:47 - 05:13:49]
you have to pay for the services okay

[05:13:48 - 05:13:51]
whatever Services you will be using

[05:13:49 - 05:13:53]
whatever model you'll be accessing So

[05:13:51 - 05:13:55]
based on that you have to pay now you

[05:13:53 - 05:13:56]
can ask me how much let's say money it

[05:13:55 - 05:13:58]
will take okay I'll tell you how much

[05:13:56 - 05:14:01]
money actually it will charge um it will

[05:13:58 - 05:14:03]
charge based on the token size as of now

[05:14:01 - 05:14:05]
just try to see the like uh overview of

[05:14:03 - 05:14:07]
this open then I'll tell you each and

[05:14:05 - 05:14:09]
everything so here you can see guys

[05:14:07 - 05:14:12]
after login I'm getting to window is

[05:14:09 - 05:14:14]
like chat GPT and is like API see chat

[05:14:12 - 05:14:16]
GPT is also product of a open I think

[05:14:14 - 05:14:18]
you already know right so this is my

[05:14:16 - 05:14:20]
chat GPT and this is the product of open

[05:14:18 - 05:14:23]
that means it is using GPT model you can

[05:14:20 - 05:14:25]
see if I click here it is using GPT

[05:14:23 - 05:14:27]
model OKAY GPT model so GPT has like

[05:14:25 - 05:14:30]
different different model VAR like GPT 3

[05:14:27 - 05:14:33]
is there 3.5 is there four is there even

[05:14:30 - 05:14:35]
uh recently one model has public GPT 4

[05:14:33 - 05:14:36]
and this is another like powerful model

[05:14:35 - 05:14:39]
they have published apart from that it

[05:14:36 - 05:14:41]
is also having some multimodel like uh

[05:14:39 - 05:14:43]
uh it can generate text to image like

[05:14:41 - 05:14:46]
Deli model is also there right then it

[05:14:43 - 05:14:49]
can also let's say generate like text to

[05:14:46 - 05:14:50]
text from a audio that means whp model

[05:14:49 - 05:14:52]
they are using so it is having actually

[05:14:50 - 05:14:53]
different different model I'll tell you

[05:14:52 - 05:14:57]
what are the model it is available so

[05:14:53 - 05:14:59]
first of all click on the API

[05:14:57 - 05:15:01]
part so now see this is the API

[05:14:59 - 05:15:03]
interface but as of now I'll go to the

[05:15:01 - 05:15:05]
playground see this is the playground

[05:15:03 - 05:15:07]
that means if you're opening this uh

[05:15:05 - 05:15:09]
openi for the first time so what you can

[05:15:07 - 05:15:11]
do you can test different different

[05:15:09 - 05:15:13]
model here you can see but again I'm

[05:15:11 - 05:15:15]
telling you guys you you have to first

[05:15:13 - 05:15:18]
of all create your account and make sure

[05:15:15 - 05:15:19]
this $5 is uh let's say credited in your

[05:15:18 - 05:15:21]
let's say account okay otherwise you

[05:15:19 - 05:15:23]
won't be able to use this uh playground

[05:15:21 - 05:15:24]
okay that means you want you won't be

[05:15:23 - 05:15:27]
able to access this at the model so make

[05:15:24 - 05:15:29]
sure your account is active Okay then

[05:15:27 - 05:15:30]
after that you will be using so whatever

[05:15:29 - 05:15:32]
let's say chat operation usually perform

[05:15:30 - 05:15:34]
with the chat GPT the same thing you can

[05:15:32 - 05:15:35]
perform here okay so here you can select

[05:15:34 - 05:15:37]
different different model you can see so

[05:15:35 - 05:15:41]
by default it is GPT 3.5 turbo you can

[05:15:37 - 05:15:42]
also take GPT 4 om mini GPT 3.5 turbo

[05:15:41 - 05:15:44]
16k okay that's how different different

[05:15:42 - 05:15:46]
model it is available okay so here you

[05:15:44 - 05:15:48]
can give the prompt and here you can

[05:15:46 - 05:15:49]
pass the system instruction that so I'll

[05:15:48 - 05:15:51]
tell you about that what is system

[05:15:49 - 05:15:53]
instruction so whenever let's say we are

[05:15:51 - 05:15:56]
using GPT model we are having two kinds

[05:15:53 - 05:15:58]
of let's say API the chat completion API

[05:15:56 - 05:15:59]
and other is like the completion API

[05:15:58 - 05:16:01]
okay so both has the difference I'll

[05:15:59 - 05:16:03]
tell you now here you can also perform

[05:16:01 - 05:16:05]
the assistant related task let's say uh

[05:16:03 - 05:16:07]
if you want to create your own assistant

[05:16:05 - 05:16:09]
okay you can also use this service you

[05:16:07 - 05:16:11]
can also do the text to speech

[05:16:09 - 05:16:13]
generation okay with the help of this

[05:16:11 - 05:16:15]
openi you can also perform the uh

[05:16:13 - 05:16:17]
completion operation that means sentence

[05:16:15 - 05:16:18]
completion operations so you can write

[05:16:17 - 05:16:21]
one sentence it will complete the entire

[05:16:18 - 05:16:22]
sentence all its entire story okay so

[05:16:21 - 05:16:24]
all kinds of model it is available even

[05:16:22 - 05:16:25]
it is also having Del model apart from

[05:16:24 - 05:16:27]
that actually they are also having

[05:16:25 - 05:16:29]
something called Del model Del is a text

[05:16:27 - 05:16:30]
to image generation model if you are

[05:16:29 - 05:16:32]
giving any kinds of prompt it will

[05:16:30 - 05:16:33]
generate image for you now it is in the

[05:16:32 - 05:16:35]
chat GPT also they integrated this

[05:16:33 - 05:16:37]
functionality let me show you so this is

[05:16:35 - 05:16:39]
what I will select create an image now

[05:16:37 - 05:16:41]
it is asking for a prompt okay it is

[05:16:39 - 05:16:43]
asking from a prompt so let's give a

[05:16:41 - 05:16:45]
prompt a

[05:16:43 - 05:16:48]
dog

[05:16:45 - 05:16:48]
is

[05:16:48 - 05:16:53]
flying on the sky let's see this is my

[05:16:51 - 05:16:56]
prompt let's

[05:16:53 - 05:16:57]
see now see it is generating the image

[05:16:56 - 05:16:59]
so guys as you can see this is the

[05:16:57 - 05:17:01]
result I got that means here I pass the

[05:16:59 - 05:17:03]
text prompt and it is generating the

[05:17:01 - 05:17:05]
image okay so like that they also have

[05:17:03 - 05:17:09]
one model called Deli Deli to let me

[05:17:05 - 05:17:09]
show you so Delhi

[05:17:10 - 05:17:15]
Del 2 so this is one of the model uh I

[05:17:13 - 05:17:17]
think recently they have also published

[05:17:15 - 05:17:19]
Del 3 okay Del 3 is also there so this

[05:17:17 - 05:17:20]
is actually text to image generation

[05:17:19 - 05:17:21]
model you can give different different

[05:17:20 - 05:17:23]
prompt based on that actually it will

[05:17:21 - 05:17:25]
generate a image right so guys you can

[05:17:23 - 05:17:26]
open this playground and you can test

[05:17:25 - 05:17:27]
different different model okay as part

[05:17:26 - 05:17:29]
your requirement now let's go to the

[05:17:27 - 05:17:31]
dashboard so let's say you want to

[05:17:29 - 05:17:33]
create uh like generate application

[05:17:31 - 05:17:36]
without writing code so what you can do

[05:17:33 - 05:17:37]
you can use there UI interface so from

[05:17:36 - 05:17:38]
here actually you can create different

[05:17:37 - 05:17:40]
different assistant system and all if

[05:17:38 - 05:17:42]
you want to fine tune these are the

[05:17:40 - 05:17:44]
model that mean GPT model you can also

[05:17:42 - 05:17:46]
fine tune from this these Services it is

[05:17:44 - 05:17:49]
also possible then it is also having

[05:17:46 - 05:17:51]
batches Storage storage means uh it

[05:17:49 - 05:17:52]
provides one vector database services so

[05:17:51 - 05:17:54]
you can also use the vector database

[05:17:52 - 05:17:56]
services to store your vector

[05:17:54 - 05:17:57]
representation and no need to worry uh I

[05:17:56 - 05:17:59]
will also discuss about this Vector

[05:17:57 - 05:18:01]
database why it is required and why

[05:17:59 - 05:18:03]
we'll be using Vector database with our

[05:18:01 - 05:18:06]
large language model and if you click on

[05:18:03 - 05:18:08]
the uses uh you will see like uh your

[05:18:06 - 05:18:10]
uses limit that means let's say if you

[05:18:08 - 05:18:12]
are have being uh $5 credit so how much

[05:18:10 - 05:18:15]
you have used here so everything it will

[05:18:12 - 05:18:16]
show you here now you can also generate

[05:18:15 - 05:18:18]
the API key I'll will tell you how to

[05:18:16 - 05:18:19]
generate the API ke so with the help of

[05:18:18 - 05:18:22]
this API key actually we will be

[05:18:19 - 05:18:24]
interacting with our open a platform

[05:18:22 - 05:18:26]
okay otherwise you can't use those are

[05:18:24 - 05:18:27]
the model okay without this API see all

[05:18:26 - 05:18:29]
the model actually they have hosted in

[05:18:27 - 05:18:30]
their server so you don't need to

[05:18:29 - 05:18:31]
download this model in your system

[05:18:30 - 05:18:34]
everything will be accessing through the

[05:18:31 - 05:18:35]
API okay this is the best part here now

[05:18:34 - 05:18:38]
this is the documentation guys you can

[05:18:35 - 05:18:39]
see related all the task they created

[05:18:38 - 05:18:41]
the documentation let's say if you want

[05:18:39 - 05:18:42]
to perform any kinds of task if you want

[05:18:41 - 05:18:44]
to see the models like what the model it

[05:18:42 - 05:18:46]
is having see these are the models

[05:18:44 - 05:18:49]
actually it is having so GPT 40 GPT for

[05:18:46 - 05:18:51]
mini gp355 Delhi I already told you

[05:18:49 - 05:18:53]
about Delhi TTS that means text to

[05:18:51 - 05:18:55]
speech whisper so you can see whisper is

[05:18:53 - 05:18:57]
a model it general purpose speech

[05:18:55 - 05:19:00]
recognization model it is trained on

[05:18:57 - 05:19:03]
large data set of diverse audio and um

[05:19:00 - 05:19:04]
is also multitask model that can perform

[05:19:03 - 05:19:07]
multilingual speech recognization that

[05:19:04 - 05:19:08]
means it's a speech model actually even

[05:19:07 - 05:19:09]
it can also work with different

[05:19:08 - 05:19:11]
different langu languages okay even it

[05:19:09 - 05:19:12]
is also having embedding model with the

[05:19:11 - 05:19:14]
help of embedding model we can generate

[05:19:12 - 05:19:16]
vectors and why we have to generate the

[05:19:14 - 05:19:17]
vectors I think I already told you now

[05:19:16 - 05:19:20]
in the text pre-processing and text

[05:19:17 - 05:19:21]
representation session so first of all

[05:19:20 - 05:19:25]
what we have to do we have to uh let's

[05:19:21 - 05:19:26]
say convert our uh text to uh embedding

[05:19:25 - 05:19:28]
representation for our model let's say

[05:19:26 - 05:19:29]
you want to F tune okay you want to F

[05:19:28 - 05:19:31]
tune this openi model that time what you

[05:19:29 - 05:19:33]
have to do you have to use this

[05:19:31 - 05:19:35]
embeddings okay to find you let's say

[05:19:33 - 05:19:37]
you want to create any kinds of gener

[05:19:35 - 05:19:38]
application definitely you have to first

[05:19:37 - 05:19:39]
of all generate the embeddings okay of

[05:19:38 - 05:19:41]
that particular text whatever documents

[05:19:39 - 05:19:43]
you are having so that's why embedding

[05:19:41 - 05:19:44]
models are required we'll also learning

[05:19:43 - 05:19:45]
how we can use this embedding model

[05:19:44 - 05:19:47]
whenever we'll be doing the projects

[05:19:45 - 05:19:50]
that time actually we'll be

[05:19:47 - 05:19:51]
learning now it is having also some GPT

[05:19:50 - 05:19:53]
based model you can see so these are the

[05:19:51 - 05:19:56]
GPT based model okay this is called

[05:19:53 - 05:19:58]
actually completion model uh we can use

[05:19:56 - 05:19:59]
completion API only okay to use this

[05:19:58 - 05:20:02]
model I'll tell you how to use that them

[05:19:59 - 05:20:03]
and all see everything they have given

[05:20:02 - 05:20:05]
okay everything they have given let's

[05:20:03 - 05:20:07]
say if you want to do the fine tuning so

[05:20:05 - 05:20:09]
there is a fine tuning guide they have

[05:20:07 - 05:20:10]
also given okay so all information they

[05:20:09 - 05:20:12]
have given in the documentation and this

[05:20:10 - 05:20:14]
is the one of the best resources to

[05:20:12 - 05:20:15]
learn this open if you want to let's say

[05:20:14 - 05:20:17]
learn anything just go to the

[05:20:15 - 05:20:19]
documentation they have the proper

[05:20:17 - 05:20:22]
explanation with the code sample as well

[05:20:19 - 05:20:24]
okay great now this is the API reference

[05:20:22 - 05:20:25]
now if I click on the API reference you

[05:20:24 - 05:20:27]
can see this is the API reference that

[05:20:25 - 05:20:30]
means let's say if I want to use their

[05:20:27 - 05:20:32]
uh let's say model and all how to call

[05:20:30 - 05:20:34]
call with the help of API even how to

[05:20:32 - 05:20:35]
call with the help of python C code okay

[05:20:34 - 05:20:37]
everything they have given as an example

[05:20:35 - 05:20:38]
you can see different different example

[05:20:37 - 05:20:39]
they have given but you can see there

[05:20:38 - 05:20:41]
there are so many things they have

[05:20:39 - 05:20:44]
written but I don't need all the let's

[05:20:41 - 05:20:45]
say concept here so whatever actually

[05:20:44 - 05:20:47]
let's say concept you need to master

[05:20:45 - 05:20:49]
this openi uh so I will show you each

[05:20:47 - 05:20:51]
and everything that means we'll be

[05:20:49 - 05:20:52]
learning about uh chat completion API

[05:20:51 - 05:20:54]
completion API and we'll be learning

[05:20:52 - 05:20:56]
another super important concept which is

[05:20:54 - 05:20:57]
nothing but uh function calling okay

[05:20:56 - 05:20:59]
open function calling so these are the

[05:20:57 - 05:21:01]
thing we have to learn here so yes guys

[05:20:59 - 05:21:03]
this is the overview and this is the

[05:21:01 - 05:21:05]
introduction of the openi uh I hope you

[05:21:03 - 05:21:07]
cleared now in the next video we'll be

[05:21:05 - 05:21:09]
generating One open API key okay then

[05:21:07 - 05:21:11]
after that actually will be uh doing

[05:21:09 - 05:21:12]
some handson on this opena that means

[05:21:11 - 05:21:13]
we'll be accessing different different

[05:21:12 - 05:21:15]
model with the help of API key so to

[05:21:13 - 05:21:18]
generate the opena API key so first of

[05:21:15 - 05:21:19]
all just click on the dashboard and here

[05:21:18 - 05:21:22]
left hand side you will see one option

[05:21:19 - 05:21:24]
called API key just click here and now

[05:21:22 - 05:21:25]
see I already created one API key

[05:21:24 - 05:21:27]
previously that's why it's showing but

[05:21:25 - 05:21:29]
for you it would be completely empty now

[05:21:27 - 05:21:31]
if you want to create a new API key just

[05:21:29 - 05:21:33]
click on create a new secret API key now

[05:21:31 - 05:21:35]
give the name let's say I want to give

[05:21:33 - 05:21:37]
let's say test one or anything you can

[05:21:35 - 05:21:40]
give it's up to you now what you can do

[05:21:37 - 05:21:42]
you can uh give the permission uh only

[05:21:40 - 05:21:43]
read only permission or whether actually

[05:21:42 - 05:21:45]
it's restricted okay you can give

[05:21:43 - 05:21:46]
different different permission but I

[05:21:45 - 05:21:48]
want to give permission uh for

[05:21:46 - 05:21:49]
everything let's say I want to read I

[05:21:48 - 05:21:52]
want to write everything I want to do

[05:21:49 - 05:21:55]
that's why I will be selecting all now

[05:21:52 - 05:21:57]
I'll just simply create the secret

[05:21:55 - 05:21:58]
key now see this is the secret key guys

[05:21:57 - 05:22:00]
just try to copy and try to save it

[05:21:58 - 05:22:02]
somewhere and don't share the secret key

[05:22:00 - 05:22:05]
with anyone otherwise they will uh able

[05:22:02 - 05:22:06]
to access your account okay I remove it

[05:22:05 - 05:22:08]
after the recording that's why I'm

[05:22:06 - 05:22:11]
showing you now uh just click on done

[05:22:08 - 05:22:12]
now see my your API has created that's

[05:22:11 - 05:22:13]
actually you can create different

[05:22:12 - 05:22:15]
different API key and with the help of

[05:22:13 - 05:22:17]
one API key you can also create multiple

[05:22:15 - 05:22:18]
projects so there is no issue with that

[05:22:17 - 05:22:20]
so guys I think you remember I was

[05:22:18 - 05:22:22]
talking about this playground and I told

[05:22:20 - 05:22:24]
you with the help of playground you can

[05:22:22 - 05:22:25]
do different different task and you can

[05:22:24 - 05:22:28]
use different different model okay now

[05:22:25 - 05:22:29]
see this model is having some of the

[05:22:28 - 05:22:31]
parameter okay so these are the

[05:22:29 - 05:22:32]
parameter is having so going forward

[05:22:31 - 05:22:34]
whenever we'll be accessing these are

[05:22:32 - 05:22:36]
the model through python code we'll be

[05:22:34 - 05:22:37]
also using these are the parameter right

[05:22:36 - 05:22:39]
so the first parameter you can see

[05:22:37 - 05:22:40]
called tempor

[05:22:39 - 05:22:42]
so what is temperature parameter see

[05:22:40 - 05:22:44]
temperature is a parameter if you

[05:22:42 - 05:22:45]
decrease the temperature parameter close

[05:22:44 - 05:22:48]
to zero that means you are telling your

[05:22:45 - 05:22:50]
model just try to be stick okay with the

[05:22:48 - 05:22:52]
let's say prompt whatever prompt user is

[05:22:50 - 05:22:54]
giving no need to take any kinds of risk

[05:22:52 - 05:22:57]
and don't generate any kinds of random

[05:22:54 - 05:22:58]
output if you're not sure try to give uh

[05:22:57 - 05:23:00]
I'm not sure I'm not able to generate

[05:22:58 - 05:23:02]
but don't give any kinds of random

[05:23:00 - 05:23:03]
output that means you are creating you

[05:23:02 - 05:23:06]
are giving the Restriction to the model

[05:23:03 - 05:23:08]
okay it will only work uh with the true

[05:23:06 - 05:23:09]
okay true generation okay true data

[05:23:08 - 05:23:11]
generation okay this is what actually

[05:23:09 - 05:23:13]
temperature parameter do that means you

[05:23:11 - 05:23:15]
can decrease close to zero that means if

[05:23:13 - 05:23:16]
you want to get a more stick output that

[05:23:15 - 05:23:18]
time you can give close to zero and if

[05:23:16 - 05:23:21]
it is close to one that means you are

[05:23:18 - 05:23:23]
telling your model try to take risk okay

[05:23:21 - 05:23:25]
whatever response you are generating it

[05:23:23 - 05:23:27]
doesn't matter but try to be more

[05:23:25 - 05:23:28]
creative here okay this is the idea here

[05:23:27 - 05:23:30]
there is another parameter called

[05:23:28 - 05:23:32]
maximum token maximum token means like

[05:23:30 - 05:23:33]
you are setting the maximum tokens let's

[05:23:32 - 05:23:35]
say let's say whenever you are giving

[05:23:33 - 05:23:38]
any kinds of prom to the model and model

[05:23:35 - 05:23:40]
is giving any uh let's model is giving

[05:23:38 - 05:23:41]
out output right and it is also a token

[05:23:40 - 05:23:44]
okay it is also a token and you can set

[05:23:41 - 05:23:45]
the token limit like how how many tokens

[05:23:44 - 05:23:47]
you want to get as an output so that

[05:23:45 - 05:23:49]
time actually you can set this maximum

[05:23:47 - 05:23:52]
token let's say maximum token is 256 it

[05:23:49 - 05:23:54]
will give you 256 token output okay I'll

[05:23:52 - 05:23:55]
discuss about these tokens so there is a

[05:23:54 - 05:23:58]
token counter

[05:23:55 - 05:24:00]
inside this openi with help of you can

[05:23:58 - 05:24:02]
also count the token then there is

[05:24:00 - 05:24:04]
another one called top P top p is

[05:24:02 - 05:24:06]
nothing but like how many let's say

[05:24:04 - 05:24:07]
output you want to generate from the

[05:24:06 - 05:24:09]
model how many response you want to

[05:24:07 - 05:24:10]
generate from the model model let's say

[05:24:09 - 05:24:12]
top p is equal to one your model will

[05:24:10 - 05:24:13]
give you only one response let's say top

[05:24:12 - 05:24:15]
p is equal to two your model will give

[05:24:13 - 05:24:16]
you two response okay and from the two

[05:24:15 - 05:24:18]
response you can select which one is the

[05:24:16 - 05:24:20]
best okay that's how you can play with

[05:24:18 - 05:24:21]
these are the parameter so if you want

[05:24:20 - 05:24:23]
to learn more about it you can simply

[05:24:21 - 05:24:25]
hover so they will give you the

[05:24:23 - 05:24:26]
description of this parameter and all so

[05:24:25 - 05:24:28]
these are the parameter actually we'll

[05:24:26 - 05:24:30]
be using frequently that's why I already

[05:24:28 - 05:24:31]
told you here so guys uh yes this is all

[05:24:30 - 05:24:33]
from this video so in the next video

[05:24:31 - 05:24:35]
we'll be doing the environment setup

[05:24:33 - 05:24:37]
like we'll be doing our local uh

[05:24:35 - 05:24:39]
environment setup like what the tools

[05:24:37 - 05:24:42]
and let's say service you need uh for

[05:24:39 - 05:24:43]
this uh genv project implementation

[05:24:42 - 05:24:45]
we'll be doing all the setup then after

[05:24:43 - 05:24:48]
that we'll be performing the Hands-On

[05:24:45 - 05:24:50]
okay of this open a platform uh let's

[05:24:48 - 05:24:51]
say sometimes actually we'll be using

[05:24:50 - 05:24:53]
cloud services sometimes actually we'll

[05:24:51 - 05:24:55]
be using local setup okay so that's why

[05:24:53 - 05:24:57]
for the local setup what are the tools

[05:24:55 - 05:24:59]
and Technology we need everything will

[05:24:57 - 05:25:00]
be making the setup in this video so the

[05:24:59 - 05:25:02]
first uh tools actually you need which

[05:25:00 - 05:25:04]
is nothing but anaga okay anaga

[05:25:02 - 05:25:06]
distribution so this will give you

[05:25:04 - 05:25:08]
actually python interpreter so inside

[05:25:06 - 05:25:09]
that actually we'll be uh creating the

[05:25:08 - 05:25:11]
environment will be set uping the

[05:25:09 - 05:25:13]
package okay and we'll be implementing

[05:25:11 - 05:25:15]
our genbi application so if you have

[05:25:13 - 05:25:16]
already anag in your system it's

[05:25:15 - 05:25:18]
completely fine but if you don't have

[05:25:16 - 05:25:20]
what you can do you can simply click on

[05:25:18 - 05:25:21]
free download and you can download this

[05:25:20 - 05:25:23]
particular anaga in your system so I

[05:25:21 - 05:25:25]
already install anonda so let me show

[05:25:23 - 05:25:27]
you so this is my anaga guys so if you

[05:25:25 - 05:25:28]
have installed successfully you will see

[05:25:27 - 05:25:30]
these kinds of window like anaga prompt

[05:25:28 - 05:25:32]
anaga Navigator if you're getting this

[05:25:30 - 05:25:33]
kinds of window that means uh your

[05:25:32 - 05:25:35]
installation is completed and the

[05:25:33 - 05:25:37]
installation process is very simple only

[05:25:35 - 05:25:40]
just click on next next next and install

[05:25:37 - 05:25:41]
the tool okay in your system now the

[05:25:40 - 05:25:44]
next thing you need which is nothing but

[05:25:41 - 05:25:46]
visual code Studio why we need the V

[05:25:44 - 05:25:48]
visual code Studio because uh see we'll

[05:25:46 - 05:25:49]
be writing the code okay and to write

[05:25:48 - 05:25:51]
the code I need a code editor right that

[05:25:49 - 05:25:54]
means ID integrated development

[05:25:51 - 05:25:55]
environment so either you can use pyam

[05:25:54 - 05:25:56]
either you can use visual code Studio

[05:25:55 - 05:25:58]
but personally I prefer visual code

[05:25:56 - 05:25:59]
Studio that's why I'll be using visual

[05:25:58 - 05:26:01]
code Studio in this particular course

[05:25:59 - 05:26:03]
fine so again you can install with

[05:26:01 - 05:26:04]
respect to your requirement whatever

[05:26:03 - 05:26:06]
operating system you're using you can

[05:26:04 - 05:26:08]
install this visual code Studio in your

[05:26:06 - 05:26:10]
system now the next thing we need the

[05:26:08 - 05:26:12]
git okay git is nothing but it's a let's

[05:26:10 - 05:26:13]
say client for the GitHub I think you

[05:26:12 - 05:26:15]
know if you have already familiar with

[05:26:13 - 05:26:17]
GitHub so if you want to let's say comit

[05:26:15 - 05:26:19]
any kinds of code in the GitHub what you

[05:26:17 - 05:26:21]
need you need this git client okay and

[05:26:19 - 05:26:24]
if you install the git actually will get

[05:26:21 - 05:26:26]
one B terminal which is called actually

[05:26:24 - 05:26:27]
git bash okay so sometimes actually we

[05:26:26 - 05:26:29]
need this G bash because with the help

[05:26:27 - 05:26:30]
of G bash will be executing different

[05:26:29 - 05:26:33]
different Linux command because going

[05:26:30 - 05:26:35]
forward we'll be implementing genv n2n

[05:26:33 - 05:26:37]
project so there I need this G bash to

[05:26:35 - 05:26:39]
execute some of the Linux R command Okay

[05:26:37 - 05:26:41]
so that's why make sure you have this G

[05:26:39 - 05:26:44]
bash install in your system fine and

[05:26:41 - 05:26:47]
again you can um install from here just

[05:26:44 - 05:26:48]
click on this button and it will uh

[05:26:47 - 05:26:50]
download it then you can do the next

[05:26:48 - 05:26:52]
next and you can install this G bash in

[05:26:50 - 05:26:53]
your system so as of now these three

[05:26:52 - 05:26:56]
tools actually I need for your local

[05:26:53 - 05:26:58]
setup and once uh this setup is ready

[05:26:56 - 05:27:00]
guys then I think we can start our

[05:26:58 - 05:27:03]
implementation so in the next video I'll

[05:27:00 - 05:27:04]
show you the handson on this open a that

[05:27:03 - 05:27:06]
means we'll be accessing different

[05:27:04 - 05:27:09]
different model we'll be exploring CH uh

[05:27:06 - 05:27:10]
like completion API will be exploring

[05:27:09 - 05:27:12]
completion API will be exploring

[05:27:10 - 05:27:14]
function calling of the openi okay

[05:27:12 - 05:27:15]
everything will be exploring one by one

[05:27:14 - 05:27:17]
so as I already told you openi having

[05:27:15 - 05:27:20]
two kinds of API that means if you want

[05:27:17 - 05:27:21]
to use open model uh it is having two

[05:27:20 - 05:27:23]
kinds of model one is like CH chat

[05:27:21 - 05:27:26]
completion model one is like completion

[05:27:23 - 05:27:27]
model so we'll be exploring both of them

[05:27:26 - 05:27:28]
so here you can see we are having

[05:27:27 - 05:27:30]
different different model so these are

[05:27:28 - 05:27:32]
the model actually related uh chat

[05:27:30 - 05:27:34]
completion model you can see these are

[05:27:32 - 05:27:36]
the chat completion model and apart from

[05:27:34 - 05:27:38]
that it is also having completion model

[05:27:36 - 05:27:40]
so if you go to the base model section

[05:27:38 - 05:27:42]
so I think there is a option called base

[05:27:40 - 05:27:44]
model let me find so here's the base

[05:27:42 - 05:27:46]
model guys zpt B model and this model is

[05:27:44 - 05:27:48]
nothing but it's a completion model okay

[05:27:46 - 05:27:51]
it's a completion API now what is the

[05:27:48 - 05:27:53]
difference between chat completion model

[05:27:51 - 05:27:55]
and completion model I'll tell you so

[05:27:53 - 05:27:58]
before that uh what I will do I'll just

[05:27:55 - 05:28:00]
uh open up my visual code Studio and

[05:27:58 - 05:28:02]
there I will uh do the openi let's a

[05:28:00 - 05:28:04]
package setup and we'll set our API key

[05:28:02 - 05:28:06]
and we'll start our implementation so

[05:28:04 - 05:28:07]
what I can do I can open up my local

[05:28:06 - 05:28:10]
folder and inside that you can create a

[05:28:07 - 05:28:12]
folder let's say I will create

[05:28:10 - 05:28:14]
open okay

[05:28:12 - 05:28:17]
open

[05:28:14 - 05:28:19]
demo inside that I'm going to open up my

[05:28:17 - 05:28:21]
uh visual Cod studio so this is my

[05:28:19 - 05:28:24]
visual code Studio

[05:28:21 - 05:28:24]
guys let me

[05:28:25 - 05:28:29]
Zoom then I will also open up my

[05:28:27 - 05:28:31]
terminal you can also open up your

[05:28:29 - 05:28:33]
terminal G bash okay whatever you are

[05:28:31 - 05:28:35]
using you can open it here see I have

[05:28:33 - 05:28:37]
opened up my G bash you can also open up

[05:28:35 - 05:28:38]
your anagon The Prompt whatever actually

[05:28:37 - 05:28:40]
you are using whatever teral you are

[05:28:38 - 05:28:43]
using you can open it here okay so I

[05:28:40 - 05:28:44]
have integrated my anaga with my G Bash

[05:28:43 - 05:28:46]
that's why you can see B has been

[05:28:44 - 05:28:49]
activated okay you can also integrate

[05:28:46 - 05:28:51]
anaga with your let's say G bash for

[05:28:49 - 05:28:53]
this you can simply search on Google you

[05:28:51 - 05:28:55]
will see the uh like process okay how we

[05:28:53 - 05:28:57]
can set your anaga with your G bash

[05:28:55 - 05:28:59]
otherwise you can also use your anaga

[05:28:57 - 05:29:00]
directly okay it will also work okay

[05:28:59 - 05:29:02]
anything you can use I'm using my G bash

[05:29:00 - 05:29:05]
here fine now here the first thing uh

[05:29:02 - 05:29:07]
we'll be set uping our open Package see

[05:29:05 - 05:29:09]
if you want to use openi so you have to

[05:29:07 - 05:29:11]
install one package actually so if you

[05:29:09 - 05:29:13]
go to the documentation let me show you

[05:29:11 - 05:29:15]
so this is the open a so if you go to

[05:29:13 - 05:29:16]
the quick start section so first thing

[05:29:15 - 05:29:18]
what you have to do you have to export

[05:29:16 - 05:29:20]
your open IPI key that means you have to

[05:29:18 - 05:29:22]
first of all collect your open IPI key

[05:29:20 - 05:29:23]
and you have to add it there okay so we

[05:29:22 - 05:29:25]
have we have already collected our open

[05:29:23 - 05:29:26]
IP I think you remember then second

[05:29:25 - 05:29:29]
thing what you have to do you have to

[05:29:26 - 05:29:30]
install one package called uh openi okay

[05:29:29 - 05:29:32]
with the help of openi package you can

[05:29:30 - 05:29:33]
access all the model that means you can

[05:29:32 - 05:29:35]
access all the let's say chart

[05:29:33 - 05:29:37]
completion API completion API everything

[05:29:35 - 05:29:39]
you can access here okay now see you can

[05:29:37 - 05:29:40]
access access different different model

[05:29:39 - 05:29:42]
okay you only need to give the model

[05:29:40 - 05:29:44]
name and you can access the model f so

[05:29:42 - 05:29:47]
let me first of all install this package

[05:29:44 - 05:29:49]
so I'll go to my vs code and here I'll

[05:29:47 - 05:29:53]
create a file called

[05:29:49 - 05:29:54]
requirement okay requirements. txt so

[05:29:53 - 05:29:56]
the first pack actually I'm going to

[05:29:54 - 05:29:58]
install called

[05:29:56 - 05:30:00]
openi so here I'll be installing one

[05:29:58 - 05:30:03]
specific version of the openi that's

[05:30:00 - 05:30:06]
0.28 why 0.28 because this is the stable

[05:30:03 - 05:30:07]
version so uh see openi has different

[05:30:06 - 05:30:09]
different version even currently they

[05:30:07 - 05:30:11]
have updated their package so in the

[05:30:09 - 05:30:13]
updated package what happens actually so

[05:30:11 - 05:30:14]
sometimes actually we will get the error

[05:30:13 - 05:30:15]
so that's why I'm using one specific

[05:30:14 - 05:30:18]
version you can also install the latest

[05:30:15 - 05:30:20]
version it will also work fine now the

[05:30:18 - 05:30:22]
next package actually I need pandas why

[05:30:20 - 05:30:24]
pandas because I want to list down all

[05:30:22 - 05:30:26]
the let's say open model through my code

[05:30:24 - 05:30:28]
and I want to show as a data frame

[05:30:26 - 05:30:30]
that's why I need this pandas library

[05:30:28 - 05:30:34]
then another Library I need called

[05:30:30 - 05:30:36]
python. whyb because I need to manage

[05:30:34 - 05:30:37]
that secret key okay secret API key

[05:30:36 - 05:30:40]
whatever API key you have collected from

[05:30:37 - 05:30:42]
our opening right dob so with the

[05:30:40 - 05:30:45]
python. package you can easily manage

[05:30:42 - 05:30:47]
this API that means we'll be creating a

[05:30:45 - 05:30:49]
DOT EMV

[05:30:47 - 05:30:52]
folder okay inside that we'll be writing

[05:30:49 - 05:30:55]
that open IPI key okay this is the idea

[05:30:52 - 05:30:57]
so here let me paste my open IPI key

[05:30:55 - 05:30:59]
guys so this is my open API key guys I

[05:30:57 - 05:31:02]
have already pasted and here you have to

[05:30:59 - 05:31:04]
give this particular key name and here

[05:31:02 - 05:31:06]
you have to give this key name open API

[05:31:04 - 05:31:08]
key equal to you have to pass your API

[05:31:06 - 05:31:09]
key here whatever API key you have

[05:31:08 - 05:31:12]
created okay I think remember in the

[05:31:09 - 05:31:14]
double quotation now let me save F now

[05:31:12 - 05:31:16]
let's me install this requirement so

[05:31:14 - 05:31:17]
guys before installing these are the

[05:31:16 - 05:31:19]
package first of all you have to create

[05:31:17 - 05:31:20]
a virtual environment here so to create

[05:31:19 - 05:31:24]
the virtual environment you can execute

[05:31:20 - 05:31:25]
this command cond create ipenn give the

[05:31:24 - 05:31:29]
name of the environment let's say I will

[05:31:25 - 05:31:32]
give um open

[05:31:29 - 05:31:34]
AI okay open a demo this is my

[05:31:32 - 05:31:37]
environment name and uh I have to

[05:31:34 - 05:31:41]
specify my python so here I'll be using

[05:31:37 - 05:31:43]
Python 3 point 10 and hyen Y and why

[05:31:41 - 05:31:45]
3.10 because again 3.10 is the stable

[05:31:43 - 05:31:46]
version of the Python okay that's why we

[05:31:45 - 05:31:48]
are using because it supports all the

[05:31:46 - 05:31:50]
library okay and hypen y means I want to

[05:31:48 - 05:31:53]
create I'm giving the yes permission now

[05:31:50 - 05:31:57]
see if I execute the command it will

[05:31:53 - 05:31:58]
create the 3.10 environment uh inside my

[05:31:57 - 05:32:00]
anaga then after that we'll be

[05:31:58 - 05:32:02]
activating then we'll be installing all

[05:32:00 - 05:32:03]
the requirements there this is the idea

[05:32:02 - 05:32:05]
so guys as you can see my environment is

[05:32:03 - 05:32:07]
created now I have to activate it so to

[05:32:05 - 05:32:08]
activate this is the command cond

[05:32:07 - 05:32:14]
activate

[05:32:08 - 05:32:14]
open AI demo okay it should be activate

[05:32:14 - 05:32:18]
sorry H now see my environment is

[05:32:17 - 05:32:22]
activated now I'll be installing this

[05:32:18 - 05:32:25]
package so I'll just write keep install

[05:32:22 - 05:32:28]
ienr requirement.

[05:32:25 - 05:32:29]
txt so it will install all the packets

[05:32:28 - 05:32:31]
one by one

[05:32:29 - 05:32:33]
here so as you can see my installation

[05:32:31 - 05:32:34]
is completed now let me clear my

[05:32:33 - 05:32:36]
terminal now here first of all what I

[05:32:34 - 05:32:38]
will do I'll create a jupyter notebook

[05:32:36 - 05:32:41]
file I'll just create uh click on on new

[05:32:38 - 05:32:43]
file and I'll create a file let's say

[05:32:41 - 05:32:48]
open AI

[05:32:43 - 05:32:50]
demo 1. ipy NB okay ipnb file is a

[05:32:48 - 05:32:52]
jupyter notebook file and here you need

[05:32:50 - 05:32:55]
to select the Kel I'll select my python

[05:32:52 - 05:32:58]
environment so the environment I created

[05:32:55 - 05:33:00]
uh called open demo so let me refresh

[05:32:58 - 05:33:02]
see open demo is there I'll select it

[05:33:00 - 05:33:04]
now if you want to test it just give the

[05:33:02 - 05:33:07]
any kinds of let's say code

[05:33:04 - 05:33:09]
here let's say print hello it should

[05:33:07 - 05:33:12]
execute now see guys it needs this uh

[05:33:09 - 05:33:14]
IPI Cal package to run this uh jupyter

[05:33:12 - 05:33:15]
notebook so let me install I'll click on

[05:33:14 - 05:33:18]
install so it will install all the

[05:33:15 - 05:33:20]
necessary things uh it needs to run this

[05:33:18 - 05:33:21]
jupyter notebook after that you will see

[05:33:20 - 05:33:24]
that this code would be executed here so

[05:33:21 - 05:33:26]
let's wait so as you can see all the

[05:33:24 - 05:33:28]
necessary package has installed and now

[05:33:26 - 05:33:30]
I'm able to execute my code in my

[05:33:28 - 05:33:31]
jupyter notebook fine all right now

[05:33:30 - 05:33:34]
we'll be importing some of the library

[05:33:31 - 05:33:37]
here so let me import operating system

[05:33:34 - 05:33:41]
then I need my openi

[05:33:37 - 05:33:44]
then I also need so to import theb you

[05:33:41 - 05:33:48]
have to import like that

[05:33:44 - 05:33:50]
fromb import load EnV okay load. EnV now

[05:33:48 - 05:33:52]
see if I execute it will import all the

[05:33:50 - 05:33:54]
library now if you want to check any

[05:33:52 - 05:33:57]
version of any package simply you can

[05:33:54 - 05:33:59]
write this command so P show let's say I

[05:33:57 - 05:34:02]
want to see the open version I'll give

[05:33:59 - 05:34:04]
open a here now see it will show you the

[05:34:02 - 05:34:07]
summary of the openi openi name version

[05:34:04 - 05:34:09]
summary okay homepage author everything

[05:34:07 - 05:34:10]
it will give give you okay now the first

[05:34:09 - 05:34:11]
thing what I have to do I have to set my

[05:34:10 - 05:34:13]
open API key if you check the

[05:34:11 - 05:34:15]
documentation I showed you the

[05:34:13 - 05:34:16]
documentation this one this

[05:34:15 - 05:34:18]
documentation if you check the

[05:34:16 - 05:34:19]
documentation so the first thing what

[05:34:18 - 05:34:22]
you have to do you have to set the Opia

[05:34:19 - 05:34:24]
API key okay and if you're using python

[05:34:22 - 05:34:26]
uh program so that time you can set the

[05:34:24 - 05:34:29]
open key like that so just open call

[05:34:26 - 05:34:31]
your openi package and inside openi

[05:34:29 - 05:34:35]
package we have one attribute called

[05:34:31 - 05:34:37]
openi API key okay API key so equal to

[05:34:35 - 05:34:39]
uh first of all what I have to do I have

[05:34:37 - 05:34:41]
to load my API key so to load the API

[05:34:39 - 05:34:43]
key and to load this uh API key from the

[05:34:41 - 05:34:45]
EnV folder what you have to do you have

[05:34:43 - 05:34:47]
to take the help from load EnV package

[05:34:45 - 05:34:52]
we have imported right so just try to

[05:34:47 - 05:34:58]
write load. EnV okay now after that just

[05:34:52 - 05:35:00]
write this one o dot uh G en EnV Okay g

[05:34:58 - 05:35:02]
EnV inside that you have to pass the key

[05:35:00 - 05:35:05]
name so key name is nothing but this is

[05:35:02 - 05:35:07]
my key name open a API key I'll pass it

[05:35:05 - 05:35:08]
here okay and it will give you open a

[05:35:07 - 05:35:10]
API key

[05:35:08 - 05:35:12]
I'll store it here now see if I simply

[05:35:10 - 05:35:14]
print it now see it should load the API

[05:35:12 - 05:35:17]
key now see it is loading my entire API

[05:35:14 - 05:35:19]
key fine now let me comment it as of now

[05:35:17 - 05:35:22]
I don't need to show now this open AP ke

[05:35:19 - 05:35:25]
I'll pass it here now see if I execute

[05:35:22 - 05:35:26]
this code so it has set my open API key

[05:35:25 - 05:35:28]
okay inside my environment okay you

[05:35:26 - 05:35:30]
don't need to do anything that means

[05:35:28 - 05:35:32]
openi will automatically load this API

[05:35:30 - 05:35:34]
key right now from the package itself

[05:35:32 - 05:35:36]
okay now as I already told you open is

[05:35:34 - 05:35:38]
having different different model so if I

[05:35:36 - 05:35:40]
click on the model section you you will

[05:35:38 - 05:35:41]
see different different models is there

[05:35:40 - 05:35:43]
so if you want to list down all the

[05:35:41 - 05:35:46]
models so what you can do you can use

[05:35:43 - 05:35:48]
this code snippit so open

[05:35:46 - 05:35:50]
AI

[05:35:48 - 05:35:52]
dot sorry

[05:35:50 - 05:35:56]
openi do

[05:35:52 - 05:35:59]
model do list okay it will give you the

[05:35:56 - 05:36:01]
Entre list of all the model now see if I

[05:35:59 - 05:36:03]
execute now see it is giving me all the

[05:36:01 - 05:36:06]
list of the model it is having but I

[05:36:03 - 05:36:08]
want to only see the I want to only see

[05:36:06 - 05:36:10]
the data Okay so here I'll filter out

[05:36:08 - 05:36:10]
the

[05:36:11 - 05:36:17]
data now see these are the model now if

[05:36:15 - 05:36:21]
I want to show as a data frame what I

[05:36:17 - 05:36:23]
can do I can use pd. data

[05:36:21 - 05:36:27]
frame I have to import pandas first of

[05:36:23 - 05:36:27]
all so import

[05:36:27 - 05:36:34]
pandas as

[05:36:29 - 05:36:38]
PD now PD do data frame and inside that

[05:36:34 - 05:36:41]
I'll pass this data whatever I'm getting

[05:36:38 - 05:36:43]
fine now see if I execute it will give

[05:36:41 - 05:36:47]
me as a data frame now see all the model

[05:36:43 - 05:36:48]
ID object created date as well as the

[05:36:47 - 05:36:50]
owned buy okay see everything it is

[05:36:48 - 05:36:52]
showing now see you can see different

[05:36:50 - 05:36:54]
different model now as I already told

[05:36:52 - 05:36:56]
you there are two kinds of API you will

[05:36:54 - 05:36:59]
get uh one is like uh chat completion

[05:36:56 - 05:37:00]
API other is like completion API so here

[05:36:59 - 05:37:03]
you can see we are having different

[05:37:00 - 05:37:04]
different model so if I want to use

[05:37:03 - 05:37:06]
these are the model first of all we have

[05:37:04 - 05:37:09]
to know what are the models actually uh

[05:37:06 - 05:37:10]
my uh chat completion model and what the

[05:37:09 - 05:37:12]
models actually only completion model

[05:37:10 - 05:37:14]
that means when I have to use the chat

[05:37:12 - 05:37:16]
completion API when I have to use the

[05:37:14 - 05:37:18]
completion API so for this you can

[05:37:16 - 05:37:20]
simply go to the model section now let's

[05:37:18 - 05:37:23]
say you want to use this GPT 3.5 turbo

[05:37:20 - 05:37:25]
if I click here now see this model is a

[05:37:23 - 05:37:26]
chat completion API model okay if you

[05:37:25 - 05:37:29]
want to use this model you have to use

[05:37:26 - 05:37:31]
the chat completion API and if I go to

[05:37:29 - 05:37:32]
the base model section so this is a

[05:37:31 - 05:37:34]
completion API that means you have to

[05:37:32 - 05:37:36]
use completion API for this model okay

[05:37:34 - 05:37:38]
now let me show you some example of chat

[05:37:36 - 05:37:39]
completion and completion API so first

[05:37:38 - 05:37:42]
of all let's try to see the completion

[05:37:39 - 05:37:47]
API demo okay let's say I want to use

[05:37:42 - 05:37:49]
this GPT 3.5 tarbo model GPT 3.5 TBO

[05:37:47 - 05:37:51]
model see so again if I go to the

[05:37:49 - 05:37:53]
documentation so here is the model guys

[05:37:51 - 05:37:55]
GPT 3.5 TBO I have to use chat

[05:37:53 - 05:37:57]
completion API and how to use CH chat

[05:37:55 - 05:37:59]
completion API if you click here that

[05:37:57 - 05:38:01]
means you have to use uh chat.

[05:37:59 - 05:38:04]
completion okay do create this

[05:38:01 - 05:38:07]
particular Cod cipit so let me show you

[05:38:04 - 05:38:10]
you can also write like that so here

[05:38:07 - 05:38:12]
uh I'll just call uh open

[05:38:10 - 05:38:15]
AI

[05:38:12 - 05:38:17]
dot uh chat completion there is directly

[05:38:15 - 05:38:19]
one function you will get called chat

[05:38:17 - 05:38:21]
completion then you can call this create

[05:38:19 - 05:38:23]
okay create one and inside that first of

[05:38:21 - 05:38:25]
all you have to give the model name

[05:38:23 - 05:38:28]
there's a model is equal to I want to

[05:38:25 - 05:38:31]
use which model GPT 3.5 turbo so this is

[05:38:28 - 05:38:33]
the model so you have to give the name

[05:38:31 - 05:38:33]
like

[05:38:34 - 05:38:40]
that fine okay now the second parameter

[05:38:38 - 05:38:40]
you have to pass the

[05:38:41 - 05:38:47]
masses okay and message should be a list

[05:38:44 - 05:38:48]
here now see how to write the masses so

[05:38:47 - 05:38:50]
they have already given the example that

[05:38:48 - 05:38:52]
means the first thing what you have to

[05:38:50 - 05:38:55]
give you have to give the role so Ro you

[05:38:52 - 05:38:57]
are giving system okay system you are a

[05:38:55 - 05:38:59]
helpful assistant that means you are

[05:38:57 - 05:39:01]
giving a system prompt here I think you

[05:38:59 - 05:39:02]
know like large language model is all

[05:39:01 - 05:39:06]
about prompt okay you have to give the

[05:39:02 - 05:39:08]
prompt here then you are giving the user

[05:39:06 - 05:39:10]
prompt that means what whatever user

[05:39:08 - 05:39:11]
want to ask so user will give it here so

[05:39:10 - 05:39:13]
let me show you how we can pass this

[05:39:11 - 05:39:16]
prompt so the first thing what I have to

[05:39:13 - 05:39:17]
do guys I already written so the first

[05:39:16 - 05:39:19]
thing you have to give the role as a

[05:39:17 - 05:39:21]
system that means you are so here the

[05:39:19 - 05:39:22]
first role you have to give as a system

[05:39:21 - 05:39:23]
that means you are giving the system

[05:39:22 - 05:39:25]
prompt and what is the content of the

[05:39:23 - 05:39:26]
system prompt you are a helpful

[05:39:25 - 05:39:28]
assistant you can give any kinds of

[05:39:26 - 05:39:30]
prompt here let's say you are a helpful

[05:39:28 - 05:39:33]
assistant you are helpful translator you

[05:39:30 - 05:39:34]
are a helpful let's say uh chat bot

[05:39:33 - 05:39:36]
anything you can give the prompt here so

[05:39:34 - 05:39:37]
going forward we'll be also learning

[05:39:36 - 05:39:39]
about prompt engineering there I'll try

[05:39:37 - 05:39:40]
to clarify what are the prompts actually

[05:39:39 - 05:39:42]
you are having okay different different

[05:39:40 - 05:39:44]
prompt you can set here now the second

[05:39:42 - 05:39:46]
role you are giving as a user that means

[05:39:44 - 05:39:47]
whatever user will ask okay whatever

[05:39:46 - 05:39:50]
user will ask so if you open the chat

[05:39:47 - 05:39:51]
GPT also in the chat GPT back end they

[05:39:50 - 05:39:53]
have given the system prompt as well as

[05:39:51 - 05:39:56]
the user prompt that means as the user

[05:39:53 - 05:39:57]
we give our prompt in the chat gbt but

[05:39:56 - 05:39:59]
in the back end they have given the

[05:39:57 - 05:40:00]
system prompt okay in the chat gbt that

[05:39:59 - 05:40:04]
is the idea

[05:40:00 - 05:40:06]
fine now let's give one prompt as a user

[05:40:04 - 05:40:08]
here so let's say prompt is equal to

[05:40:06 - 05:40:11]
prompt is equal to I'll give uh let's

[05:40:08 - 05:40:11]
say

[05:40:12 - 05:40:15]
hello how are

[05:40:16 - 05:40:22]
you so this prompt uh here it will come

[05:40:19 - 05:40:24]
okay as a user prompt now it will give

[05:40:22 - 05:40:24]
me one

[05:40:25 - 05:40:30]
response and that response I'll print

[05:40:27 - 05:40:30]
here

[05:40:31 - 05:40:37]
simply okay now see if I execute the

[05:40:33 - 05:40:40]
program so it will give me the response

[05:40:37 - 05:40:43]
so it is giving invalid request

[05:40:40 - 05:40:46]
at missing required parameter message

[05:40:43 - 05:40:49]
you provide message okay so let me check

[05:40:46 - 05:40:52]
so it should be messages okay not messes

[05:40:49 - 05:40:54]
now see it should work now see it is

[05:40:52 - 05:40:57]
giving me the uh response right now and

[05:40:54 - 05:41:01]
here is the response guys okay if I show

[05:40:57 - 05:41:03]
you so here is the response hello I am

[05:41:01 - 05:41:05]
here ready to assist you how I can help

[05:41:03 - 05:41:07]
you today if I want to extract this

[05:41:05 - 05:41:09]
content only that means this uh let's

[05:41:07 - 05:41:12]
say response only what I can do so

[05:41:09 - 05:41:15]
simply I can copy this example as it

[05:41:12 - 05:41:17]
is and here let me paste so here you can

[05:41:15 - 05:41:19]
see first of all I have to go to the

[05:41:17 - 05:41:21]
choices okay because it's a dictionary I

[05:41:19 - 05:41:25]
have to take the choices so let's take

[05:41:21 - 05:41:25]
Choice first of all I'll take the

[05:41:26 - 05:41:31]
choice now choice is nothing but it's a

[05:41:29 - 05:41:36]
list so I will take the

[05:41:31 - 05:41:39]
first let's say item of the list now I

[05:41:36 - 05:41:39]
have to go go inside the

[05:41:42 - 05:41:46]
masses now I need the content

[05:41:47 - 05:41:52]
only now see it will give me the content

[05:41:50 - 05:41:54]
only okay hello I'm just a computer

[05:41:52 - 05:41:55]
program so I don't have any feelings but

[05:41:54 - 05:41:57]
I'm here to ready to help you how I can

[05:41:55 - 05:41:59]
assist you because every time whenever

[05:41:57 - 05:42:01]
you will execute this uh program it will

[05:41:59 - 05:42:02]
give you different different response

[05:42:01 - 05:42:03]
okay it will generate different

[05:42:02 - 05:42:06]
different uh response for you this is

[05:42:03 - 05:42:09]
the idea fine now what is the main

[05:42:06 - 05:42:11]
benefit to use this chat completion API

[05:42:09 - 05:42:13]
that mean chat completion model see in

[05:42:11 - 05:42:15]
the chat completion model you can pass

[05:42:13 - 05:42:18]
multiple prompt okay here you can pass

[05:42:15 - 05:42:20]
multiple prompt so how let me show you

[05:42:18 - 05:42:23]
so here I have given one example so this

[05:42:20 - 05:42:25]
is the example guys see here I have

[05:42:23 - 05:42:27]
created actually three prompt hello how

[05:42:25 - 05:42:30]
are you second prompt I am uh 25 years

[05:42:27 - 05:42:33]
old I'm a programmer now third prom I've

[05:42:30 - 05:42:35]
given tell me about me that means in the

[05:42:33 - 05:42:37]
prompt itself I have given my data and

[05:42:35 - 05:42:38]
I'm asking tell me about me now this the

[05:42:37 - 05:42:41]
same way I have created my chat

[05:42:38 - 05:42:42]
completion API I have initialized my

[05:42:41 - 05:42:44]
model and in the message section right

[05:42:42 - 05:42:46]
now you can see the first role actually

[05:42:44 - 05:42:48]
have given the system role that means

[05:42:46 - 05:42:50]
you are a helpful assistant second role

[05:42:48 - 05:42:52]
I have given my first prompt third role

[05:42:50 - 05:42:55]
I have given my second prompt and fourth

[05:42:52 - 05:42:57]
role I have given my prompt three okay

[05:42:55 - 05:42:59]
that means you can pass multiple prompt

[05:42:57 - 05:43:01]
here this is the main benefit to use

[05:42:59 - 05:43:04]
this chat completion API that means in

[05:43:01 - 05:43:08]
the chat GPT also so if I go to my chat

[05:43:04 - 05:43:13]
GPT let's say here I give my data

[05:43:08 - 05:43:13]
hey I am let's I'll give the same prompt

[05:43:13 - 05:43:17]
here this is the prompt I want to

[05:43:18 - 05:43:23]
give I'm 25 years old I a

[05:43:23 - 05:43:28]
programmer now you can see memory

[05:43:25 - 05:43:30]
updated it it has memory updated right

[05:43:28 - 05:43:34]
now if

[05:43:30 - 05:43:38]
I give this prompt tell me about

[05:43:34 - 05:43:41]
me now it is telling you are 25 years

[05:43:38 - 05:43:43]
old programmer who created courses and

[05:43:41 - 05:43:46]
playlist okay see now it is giving me

[05:43:43 - 05:43:48]
the answer the related my information

[05:43:46 - 05:43:51]
because it it has remembered okay it has

[05:43:48 - 05:43:52]
remembered my previous prompt so this is

[05:43:51 - 05:43:54]
what actually they're using something

[05:43:52 - 05:43:57]
called chat completion model that means

[05:43:54 - 05:43:59]
it can understand multiple prompt okay

[05:43:57 - 05:44:01]
not one prompt it can understand

[05:43:59 - 05:44:03]
multiple prompting so here you can see I

[05:44:01 - 05:44:06]
have given one demo so I'm giving the

[05:44:03 - 05:44:08]
same thing hello how are you I'm 25

[05:44:06 - 05:44:10]
years I'm a programmer tell me about me

[05:44:08 - 05:44:12]
now see if I execute the program right

[05:44:10 - 05:44:13]
now it will able to give me the answer

[05:44:12 - 05:44:15]
see based on the information you

[05:44:13 - 05:44:16]
provided you are 25 years old programmer

[05:44:15 - 05:44:19]
is there anything specific you would

[05:44:16 - 05:44:21]
like to know or discuss I hope it is

[05:44:19 - 05:44:24]
clear now what is the use of chat

[05:44:21 - 05:44:26]
completion API and and what is the

[05:44:24 - 05:44:29]
benefit to use the chat completion API

[05:44:26 - 05:44:32]
model that means chat completion model

[05:44:29 - 05:44:34]
got it great now we'll be tweaking some

[05:44:32 - 05:44:36]
of the parameter here so the first

[05:44:34 - 05:44:38]
parameter will be tweaking which is

[05:44:36 - 05:44:40]
nothing but mix Max token okay so what

[05:44:38 - 05:44:42]
I'll do I'll copy the same example my

[05:44:40 - 05:44:42]
previous

[05:44:43 - 05:44:49]
example now instead of asking this

[05:44:45 - 05:44:51]
question I'll write what is python let's

[05:44:49 - 05:44:53]
say this is my question okay now there

[05:44:51 - 05:44:57]
is a parameter you can

[05:44:53 - 05:44:57]
set called Max token

[05:44:58 - 05:45:01]
maxcore

[05:45:02 - 05:45:08]
token let's say I want to generate only

[05:45:05 - 05:45:10]
25 tokens okay okay 25

[05:45:08 - 05:45:12]
tokens now see if I execute the program

[05:45:10 - 05:45:16]
right now it will only give me 25 tokens

[05:45:12 - 05:45:17]
output now if you want to see that you

[05:45:16 - 05:45:21]
can

[05:45:17 - 05:45:24]
copy and you can go to the open

[05:45:21 - 05:45:30]
AI

[05:45:24 - 05:45:33]
token okay tokenizer now go to the first

[05:45:30 - 05:45:36]
website now here you can simply give it

[05:45:33 - 05:45:38]
this particular let's say uh response

[05:45:36 - 05:45:40]
you have copied now you can see maximum

[05:45:38 - 05:45:42]
token 25 that means whatever token limit

[05:45:40 - 05:45:44]
you have set so it will give you that

[05:45:42 - 05:45:47]
particular token output only now if you

[05:45:44 - 05:45:49]
want to see the detailed

[05:45:47 - 05:45:51]
information you can simply print the

[05:45:49 - 05:45:55]
response instead of printing the content

[05:45:51 - 05:45:58]
now see so now if I execute this program

[05:45:55 - 05:46:00]
you'll see that my completion token 25

[05:45:58 - 05:46:04]
fine now it will charge you based on the

[05:46:00 - 05:46:06]
token limit so if can go to the openi

[05:46:04 - 05:46:08]
pricing so in the pricing section they

[05:46:06 - 05:46:10]
have given how it will charge you so so

[05:46:08 - 05:46:12]
guys as you can see this is the openi

[05:46:10 - 05:46:14]
pricing page so here they have given the

[05:46:12 - 05:46:16]
pricing as per the token limit you can

[05:46:14 - 05:46:17]
see this is the input token this is the

[05:46:16 - 05:46:20]
output token that means if your input

[05:46:17 - 05:46:22]
token is that much that means 1 million

[05:46:20 - 05:46:24]
and if your output token is let's say 1

[05:46:22 - 05:46:27]
million so you uh you will charge that

[05:46:24 - 05:46:28]
many of dollar okay that much of dollar

[05:46:27 - 05:46:31]
so you can see this different different

[05:46:28 - 05:46:33]
example so this is GPT 40 mini this is

[05:46:31 - 05:46:35]
the embedding model you can see if your

[05:46:33 - 05:46:38]
input token limit is 1 million token and

[05:46:35 - 05:46:40]
if your output token is and if your

[05:46:38 - 05:46:41]
output token is also 1 million tokens so

[05:46:40 - 05:46:45]
he will get

[05:46:41 - 05:46:47]
0.020 okay $2 only it's like very less

[05:46:45 - 05:46:48]
amount now see different different model

[05:46:47 - 05:46:50]
with respect to their different

[05:46:48 - 05:46:51]
different price price okay so you can

[05:46:50 - 05:46:54]
check all the models see Audio model as

[05:46:51 - 05:46:57]
well as the image model assistant API

[05:46:54 - 05:46:59]
okay see whatever assistant API actually

[05:46:57 - 05:47:01]
you will be using and Vector SS okay

[05:46:59 - 05:47:02]
every model they have given the pricing

[05:47:01 - 05:47:04]
okay every model they have given the

[05:47:02 - 05:47:06]
pricing so that means it will charge

[05:47:04 - 05:47:07]
based on the token limits let's say

[05:47:06 - 05:47:09]
whatever token it is giving you the

[05:47:07 - 05:47:11]
output as well as the whatever tokens

[05:47:09 - 05:47:12]
actually it is receiving as an input it

[05:47:11 - 05:47:14]
will first of all do the count operation

[05:47:12 - 05:47:16]
how it will do the count operation so

[05:47:14 - 05:47:18]
with help of this tokenizer so they have

[05:47:16 - 05:47:20]
one inbu tokenizer inside that it will

[05:47:18 - 05:47:23]
automatically make the count now you can

[05:47:20 - 05:47:25]
see I'm having total 141 character now

[05:47:23 - 05:47:27]
you can see like how many character they

[05:47:25 - 05:47:29]
are considering to calculate only one

[05:47:27 - 05:47:31]
token I think four to five okay four to

[05:47:29 - 05:47:34]
five character they considering to count

[05:47:31 - 05:47:35]
one token here okay this is the idea so

[05:47:34 - 05:47:37]
here they have written you can see a

[05:47:35 - 05:47:40]
helpful rule of thumb is is that one

[05:47:37 - 05:47:42]
token generally correspond to four

[05:47:40 - 05:47:44]
characters okay uh whether it's a four

[05:47:42 - 05:47:46]
character or sometimes it would be more

[05:47:44 - 05:47:48]
than four character of text for the

[05:47:46 - 05:47:50]
common English text okay this is called

[05:47:48 - 05:47:51]
actually one token so they have given

[05:47:50 - 05:47:55]
each and everything you can export here

[05:47:51 - 05:47:56]
now let's get back to my code editor now

[05:47:55 - 05:47:58]
I think this parameter is clear okay

[05:47:56 - 05:48:00]
what is Max tokens here now I think you

[05:47:58 - 05:48:03]
remember in the playground also I showed

[05:48:00 - 05:48:05]
you this parameter so if I go to the

[05:48:03 - 05:48:07]
playground see in the playground also I

[05:48:05 - 05:48:10]
showed you this parameter Max Tok okay

[05:48:07 - 05:48:13]
now it is I think it is

[05:48:10 - 05:48:15]
clear now I'll show you the next

[05:48:13 - 05:48:17]
parameter right now so the next

[05:48:15 - 05:48:19]
parameter is nothing but our temperature

[05:48:17 - 05:48:21]
parameter so you can see I have given

[05:48:19 - 05:48:23]
the same example but uh one parameter

[05:48:21 - 05:48:25]
I'm using called

[05:48:23 - 05:48:27]
temperature and I already told you what

[05:48:25 - 05:48:29]
is temperature parameter means uh it

[05:48:27 - 05:48:31]
will give the randomness okay Randomness

[05:48:29 - 05:48:33]
to the response like how much Randomness

[05:48:31 - 05:48:35]
you need let's say if it is close to

[05:48:33 - 05:48:37]
zero your model would be more stick to

[05:48:35 - 05:48:38]
the let's say prompt you have given

[05:48:37 - 05:48:41]
and if it is close to one that means it

[05:48:38 - 05:48:42]
will try to take some risk and it will

[05:48:41 - 05:48:44]
generate some random output as well now

[05:48:42 - 05:48:47]
let's say here I have given 0.6 that

[05:48:44 - 05:48:50]
means I'm telling my model uh try to be

[05:48:47 - 05:48:52]
actually balanced okay balance with the

[05:48:50 - 05:48:55]
prompt user is giving try to give some

[05:48:52 - 05:48:57]
creativity some somehow even U also try

[05:48:55 - 05:48:59]
to be strict with the prompt user has

[05:48:57 - 05:49:01]
given now see if I execute the program

[05:48:59 - 05:49:04]
now see now the response actually I'm

[05:49:01 - 05:49:05]
getting this is the uh this little bit

[05:49:04 - 05:49:07]
different response from the previous

[05:49:05 - 05:49:09]
response you can see

[05:49:07 - 05:49:10]
so here is the response I was getting

[05:49:09 - 05:49:12]
python is a high level inter programar

[05:49:10 - 05:49:14]
Simplicity and visibility it supp

[05:49:12 - 05:49:15]
multiple paradigms okay now see this is

[05:49:14 - 05:49:17]
the another response actually I'm

[05:49:15 - 05:49:19]
getting okay that's how you can increase

[05:49:17 - 05:49:20]
and decrease this parameter size but

[05:49:19 - 05:49:24]
what I saw like people are using this

[05:49:20 - 05:49:25]
parameter around 0.5 to 0.6 to 7 like

[05:49:24 - 05:49:27]
that okay no need to decrease and no

[05:49:25 - 05:49:28]
need to increase much but if you

[05:49:27 - 05:49:30]
sometimes need it you can increase

[05:49:28 - 05:49:32]
otherwise you can decrease okay it's up

[05:49:30 - 05:49:34]
to you now there is another one that n

[05:49:32 - 05:49:36]
parameter uh n parameter means it will

[05:49:34 - 05:49:38]
give you like how many response you need

[05:49:36 - 05:49:40]
from the model let's say if n is equal

[05:49:38 - 05:49:43]
to two it will give me two response now

[05:49:40 - 05:49:44]
if I if I execute the program see it has

[05:49:43 - 05:49:47]
given me two response so this is one

[05:49:44 - 05:49:49]
response and this is another response

[05:49:47 - 05:49:51]
now if it is three it will give you

[05:49:49 - 05:49:51]
three

[05:49:53 - 05:50:01]
response see one response two response

[05:49:58 - 05:50:03]
and if I open in a text editor two

[05:50:01 - 05:50:05]
response uh this is one this is two and

[05:50:03 - 05:50:07]
this three okay that's how you can get

[05:50:05 - 05:50:09]
multiple responses if you want so this

[05:50:07 - 05:50:10]
is called actually n parameter like

[05:50:09 - 05:50:13]
number of response you want to get here

[05:50:10 - 05:50:14]
great so yes these are the parameter you

[05:50:13 - 05:50:16]
can play with guys because these are the

[05:50:14 - 05:50:18]
parameter we'll be using frequently now

[05:50:16 - 05:50:19]
see uh with the help of chat completion

[05:50:18 - 05:50:21]
model you can perform different

[05:50:19 - 05:50:23]
different tasks so let me show you so

[05:50:21 - 05:50:24]
you can give different different prompt

[05:50:23 - 05:50:27]
so let's say here I have given a prompt

[05:50:24 - 05:50:29]
give me a sentiment of this sentence

[05:50:27 - 05:50:30]
okay this movie is amazing now I think

[05:50:29 - 05:50:32]
you know this sentiment would be

[05:50:30 - 05:50:35]
positive now let's see whether my model

[05:50:32 - 05:50:37]
is giving me right answer or not now see

[05:50:35 - 05:50:39]
this sentiment of uh of the sentence

[05:50:37 - 05:50:41]
this movie is amazing it's a positive

[05:50:39 - 05:50:43]
that means it's working fine nowart from

[05:50:41 - 05:50:45]
that you can also give any other

[05:50:43 - 05:50:47]
prompt let's say I'm given give me the

[05:50:45 - 05:50:50]
Hindi translation of this sentence this

[05:50:47 - 05:50:52]
movie is amazing now see it should give

[05:50:50 - 05:50:54]
me the Hindi translation see so whatever

[05:50:52 - 05:50:56]
things we used to perform in the chat JP

[05:50:54 - 05:50:58]
now okay that means we can perform

[05:50:56 - 05:51:01]
multiple task I want to do language

[05:50:58 - 05:51:02]
translation uh then sentiment analysis

[05:51:01 - 05:51:04]
anything I can perform here the same

[05:51:02 - 05:51:07]
thing you can also do here okay because

[05:51:04 - 05:51:08]
it is using the same model only okay and

[05:51:07 - 05:51:10]
we able to access those model with the

[05:51:08 - 05:51:12]
help of API key that means whenever you

[05:51:10 - 05:51:15]
are uh sending this

[05:51:12 - 05:51:17]
request uh it is first of all calling

[05:51:15 - 05:51:18]
that API and API is actually hitting the

[05:51:17 - 05:51:20]
model and model is giving me the

[05:51:18 - 05:51:22]
response and this response actually we

[05:51:20 - 05:51:24]
able to see this is the idea only I hope

[05:51:22 - 05:51:25]
you're clear now let me show you another

[05:51:24 - 05:51:27]
prompt let's say detect the language of

[05:51:25 - 05:51:30]
this sentence this movie is amazing so

[05:51:27 - 05:51:32]
the language should be English see it is

[05:51:30 - 05:51:34]
the English uh language okay now you can

[05:51:32 - 05:51:36]
also generate code okay you can also

[05:51:34 - 05:51:38]
generate code uh with these are the

[05:51:36 - 05:51:40]
model so I've given a prompt give me a

[05:51:38 - 05:51:41]
python code to add two numbers now let

[05:51:40 - 05:51:45]
me

[05:51:41 - 05:51:48]
see see this is the code I have given to

[05:51:45 - 05:51:50]
add so here I got the code to add two

[05:51:48 - 05:51:51]
numbers in Python okay so that's how

[05:51:50 - 05:51:53]
actually we can create different

[05:51:51 - 05:51:55]
different application with these at the

[05:51:53 - 05:51:57]
large language model fine so yes guys

[05:51:55 - 05:51:58]
this is all about our chat completion

[05:51:57 - 05:52:01]
API now let's try to export the

[05:51:58 - 05:52:02]
completion API as well so as I already

[05:52:01 - 05:52:05]
told you so here is the definition of

[05:52:02 - 05:52:07]
completion API guys you can see uh hooks

[05:52:05 - 05:52:09]
you up with text comp comption from a

[05:52:07 - 05:52:10]
single prompt that means it can only

[05:52:09 - 05:52:12]
support single prompt you can only pass

[05:52:10 - 05:52:14]
one prompt here in the other hand

[05:52:12 - 05:52:16]
actually in the chat completion you can

[05:52:14 - 05:52:19]
give multiple prompt to keep the

[05:52:16 - 05:52:21]
conversation uh flow intact okay as I

[05:52:19 - 05:52:23]
already told you you can give multiple

[05:52:21 - 05:52:25]
prompt and that prompt actually this

[05:52:23 - 05:52:27]
model can remember but in the completion

[05:52:25 - 05:52:29]
API you can only pass the one prompt

[05:52:27 - 05:52:31]
here okay this is the idea in completion

[05:52:29 - 05:52:34]
API you can pass only one prompt now if

[05:52:31 - 05:52:36]
I show you some completion model model

[05:52:34 - 05:52:39]
section and let's say this is the GPT

[05:52:36 - 05:52:40]
base so this is use actually completion

[05:52:39 - 05:52:43]
API and these are the model are

[05:52:40 - 05:52:45]
available related completion API okay

[05:52:43 - 05:52:48]
now let me use this Babs 002 model and

[05:52:45 - 05:52:50]
let me show you one example see if you

[05:52:48 - 05:52:52]
want to use completion API that time you

[05:52:50 - 05:52:54]
have to call this

[05:52:52 - 05:52:58]
completion

[05:52:54 - 05:53:00]
open Dot completion okay open.

[05:52:58 - 05:53:02]
completion. create not chat completion

[05:53:00 - 05:53:04]
you have to call completion only and

[05:53:02 - 05:53:07]
inside that you have to give the model

[05:53:04 - 05:53:09]
first of all which model you want to use

[05:53:07 - 05:53:13]
let say I want to use this Babas model

[05:53:09 - 05:53:18]
that babz model okay and it will take

[05:53:13 - 05:53:20]
the prompt so let me Define an prompt

[05:53:18 - 05:53:23]
here let's say this is the prompt okay

[05:53:20 - 05:53:27]
what is python this prompt I'll pass it

[05:53:23 - 05:53:27]
here now I'll

[05:53:28 - 05:53:33]
print the

[05:53:30 - 05:53:36]
response okay now if I

[05:53:33 - 05:53:37]
execute now see it is giving you the

[05:53:36 - 05:53:39]
response okay it is giving you the

[05:53:37 - 05:53:42]
response so that's how actually you can

[05:53:39 - 05:53:44]
give uh actually only single prompt here

[05:53:42 - 05:53:49]
and whatever let's say parameter you saw

[05:53:44 - 05:53:51]
temperature then maximum token then n

[05:53:49 - 05:53:53]
parameter you can also give the same

[05:53:51 - 05:53:56]
parameter in the completion API as well

[05:53:53 - 05:53:58]
okay it will also work but uh see we'll

[05:53:56 - 05:54:00]
be using the chat completion API a lot

[05:53:58 - 05:54:02]
we'll be using chat completion Model A

[05:54:00 - 05:54:05]
lot going forward okay because I have

[05:54:02 - 05:54:07]
seen like people are using this chat

[05:54:05 - 05:54:09]
completion Model A lot instead of

[05:54:07 - 05:54:11]
completion API because here we can pass

[05:54:09 - 05:54:13]
multiple prompt okay this is the main

[05:54:11 - 05:54:15]
advantage okay I hope it is clear so yes

[05:54:13 - 05:54:17]
guys uh this is all about our chat

[05:54:15 - 05:54:20]
completion API as well as the completion

[05:54:17 - 05:54:23]
API and this is all about a Hands-On

[05:54:20 - 05:54:24]
part on the open a platform okay because

[05:54:23 - 05:54:26]
see going forward we'll be using these

[05:54:24 - 05:54:27]
are the concept only to implement any

[05:54:26 - 05:54:29]
kinds of project even I will also

[05:54:27 - 05:54:30]
Implement some of the project I'll tell

[05:54:29 - 05:54:31]
you how we can Implement different

[05:54:30 - 05:54:33]
different projects with the help of

[05:54:31 - 05:54:35]
openi that time also you will see I'll

[05:54:33 - 05:54:37]
be using these are the concept only okay

[05:54:35 - 05:54:39]
now in the next video we'll be learning

[05:54:37 - 05:54:40]
about another super important concept

[05:54:39 - 05:54:42]
inside openi called function calling

[05:54:40 - 05:54:43]
okay again it's the very powerful

[05:54:42 - 05:54:45]
concept inside openi so we'll be

[05:54:43 - 05:54:47]
learning that function calling see first

[05:54:45 - 05:54:48]
of all you have to understand what is

[05:54:47 - 05:54:50]
function calling and what is the use of

[05:54:48 - 05:54:52]
the function calling so for this I will

[05:54:50 - 05:54:56]
go to my Blackboard and there I'll try

[05:54:52 - 05:54:58]
to clarify okay see function calling

[05:54:56 - 05:55:01]
helps the open a model to interact with

[05:54:58 - 05:55:03]
different third partyy API let's say

[05:55:01 - 05:55:04]
here you are having one API let's say

[05:55:03 - 05:55:08]
here you are having one

[05:55:04 - 05:55:10]
API okay let's say you are using uh one

[05:55:08 - 05:55:13]
databases okay

[05:55:10 - 05:55:15]
databases so let's with the help of API

[05:55:13 - 05:55:16]
you are hitting the database and

[05:55:15 - 05:55:18]
database is giving you some kinds of

[05:55:16 - 05:55:20]
response which is nothing but a just on

[05:55:18 - 05:55:23]
response because most of the time

[05:55:20 - 05:55:24]
whenever you will use API right API to

[05:55:23 - 05:55:26]
hit any kinds of website or database you

[05:55:24 - 05:55:30]
will get the juston output let's this is

[05:55:26 - 05:55:31]
a weather okay weather data database and

[05:55:30 - 05:55:33]
with the help of wether API you are

[05:55:31 - 05:55:34]
hitting this website and it is giving

[05:55:33 - 05:55:36]
you the Jon response that means wether

[05:55:34 - 05:55:38]
related data now what you can do with

[05:55:36 - 05:55:40]
the help of function

[05:55:38 - 05:55:43]
calling okay with the help of function

[05:55:40 - 05:55:46]
calling inside open

[05:55:43 - 05:55:50]
a you can use open a

[05:55:46 - 05:55:53]
API open AI API okay to interact with

[05:55:50 - 05:55:56]
this model because let's say this is my

[05:55:53 - 05:55:58]
large language model OKAY openi model

[05:55:56 - 05:56:00]
now with the help of open API key what I

[05:55:58 - 05:56:03]
can do I can interact with this model

[05:56:00 - 05:56:05]
that means with help of function calling

[05:56:03 - 05:56:09]
what it can perform okay it can perform

[05:56:05 - 05:56:10]
the Comm communication with this data

[05:56:09 - 05:56:13]
communication with this data that means

[05:56:10 - 05:56:14]
this model can directly communicate with

[05:56:13 - 05:56:16]
this

[05:56:14 - 05:56:18]
data that means whatever response you

[05:56:16 - 05:56:21]
are getting whatever response you are

[05:56:18 - 05:56:22]
getting from this database or let's API

[05:56:21 - 05:56:25]
you can directly communicate okay you

[05:56:22 - 05:56:26]
can directly communicate communicate uh

[05:56:25 - 05:56:28]
with the help of your large language

[05:56:26 - 05:56:30]
model okay this is the main power

[05:56:28 - 05:56:33]
actually this function calling will

[05:56:30 - 05:56:35]
provides okay that means you don't need

[05:56:33 - 05:56:36]
to manually extract this information and

[05:56:35 - 05:56:38]
manually

[05:56:36 - 05:56:40]
let's say feed inside your model you

[05:56:38 - 05:56:42]
don't need to do like that you'll be

[05:56:40 - 05:56:44]
using function calling and what your

[05:56:42 - 05:56:45]
model will try to do it will directly

[05:56:44 - 05:56:47]
let's say communicate with this

[05:56:45 - 05:56:48]
particular response whatever just on

[05:56:47 - 05:56:50]
whatever response you are getting it

[05:56:48 - 05:56:52]
will directly do the communication okay

[05:56:50 - 05:56:55]
so that's why with of function calling

[05:56:52 - 05:56:57]
my large language model will be capable

[05:56:55 - 05:56:59]
enough to communicate with any kinds of

[05:56:57 - 05:57:01]
third party API okay third party API

[05:56:59 - 05:57:03]
this is the main benefit to use this one

[05:57:01 - 05:57:05]
and without this function calling uh

[05:57:03 - 05:57:06]
what you have to do you have to manually

[05:57:05 - 05:57:08]
extract the data and you have to

[05:57:06 - 05:57:10]
manually fine tune this model OKAY

[05:57:08 - 05:57:12]
manually fine tune this model and again

[05:57:10 - 05:57:14]
it's a very hetic task like because

[05:57:12 - 05:57:16]
again it's a large language model and

[05:57:14 - 05:57:18]
you can't do the fine tune okay easily

[05:57:16 - 05:57:21]
okay and again it is having lots of cost

[05:57:18 - 05:57:22]
involvement so that's why open uh this

[05:57:21 - 05:57:25]
function calling helps us to do this

[05:57:22 - 05:57:26]
communication that means instead of like

[05:57:25 - 05:57:29]
feding the data in my model directly

[05:57:26 - 05:57:32]
function qu calling will try to uh make

[05:57:29 - 05:57:35]
the communication between my response of

[05:57:32 - 05:57:36]
like API response I'm getting and this

[05:57:35 - 05:57:39]
particular model okay this model will

[05:57:36 - 05:57:41]
try to communicate with my output okay

[05:57:39 - 05:57:42]
it can be any kinds of API it can be not

[05:57:41 - 05:57:45]
only weather API it can be any kinds of

[05:57:42 - 05:57:46]
API any heart party data okay so that's

[05:57:45 - 05:57:48]
why openi supports actually different

[05:57:46 - 05:57:51]
different uh third party actually

[05:57:48 - 05:57:52]
integration you can U connect like

[05:57:51 - 05:57:53]
different different platform you can

[05:57:52 - 05:57:55]
connect let's say slack you can connect

[05:57:53 - 05:57:57]
let's say different different uh uh

[05:57:55 - 05:57:58]
website you can connect different

[05:57:57 - 05:58:00]
different database okay directly you can

[05:57:58 - 05:58:01]
connect and it can directly to the

[05:58:00 - 05:58:03]
communication with the help of function

[05:58:01 - 05:58:04]
calling okay now let me show you one

[05:58:03 - 05:58:06]
example I think then this part would be

[05:58:04 - 05:58:08]
more clear so what I'll do I'll go to my

[05:58:06 - 05:58:10]
code editor and here I already created

[05:58:08 - 05:58:11]
one file you can see now we'll be

[05:58:10 - 05:58:13]
exploring the function calling here

[05:58:11 - 05:58:15]
again what I will do I'll import all of

[05:58:13 - 05:58:15]
the

[05:58:16 - 05:58:24]
lid then I'll select my cardal and I'll

[05:58:20 - 05:58:24]
set my environment

[05:58:25 - 05:58:28]
variable

[05:58:28 - 05:58:33]
H now I can use the same example from

[05:58:32 - 05:58:38]
here just to test whether everything is

[05:58:33 - 05:58:38]
working fine or not I can

[05:58:41 - 05:58:45]
copy see everything is working fine okay

[05:58:43 - 05:58:49]
there is no issue instead of printing

[05:58:45 - 05:58:49]
all the response I can only print the

[05:58:49 - 05:58:53]
content so as I already told you uh it

[05:58:52 - 05:58:55]
can actually communicate with any kinds

[05:58:53 - 05:58:57]
of third party API so as a third partyy

[05:58:55 - 05:59:01]
API what I will do I will use one API

[05:58:57 - 05:59:03]
here so called rapid API okay rapid API

[05:59:01 - 05:59:05]
inside rapid API you are having

[05:59:03 - 05:59:06]
different different API whether it's a

[05:59:05 - 05:59:08]
weather API okay and you API it is

[05:59:06 - 05:59:10]
available so this is the link so let me

[05:59:08 - 05:59:13]
open this link guys I will search on

[05:59:10 - 05:59:15]
Google so this is the rapid open.com and

[05:59:13 - 05:59:16]
make sure you have created One account

[05:59:15 - 05:59:18]
so for me I already created One account

[05:59:16 - 05:59:20]
okay for you also you have to create one

[05:59:18 - 05:59:22]
account now here what you have to do you

[05:59:20 - 05:59:26]
have to search for the API now simply

[05:59:22 - 05:59:28]
left hand side you can click on view all

[05:59:26 - 05:59:32]
categories now I need actually wether

[05:59:28 - 05:59:34]
API so I'll simply search

[05:59:32 - 05:59:36]
here

[05:59:34 - 05:59:38]
wether now see different different

[05:59:36 - 05:59:40]
weather API is coming but I need this AI

[05:59:38 - 05:59:43]
weather by Metro Source okay this this

[05:59:40 - 05:59:44]
one I'll click here now see initially if

[05:59:43 - 05:59:46]
you're doing it for the first time you

[05:59:44 - 05:59:48]
will see one button here subscribe okay

[05:59:46 - 05:59:49]
subscribe to the API you have to do the

[05:59:48 - 05:59:51]
subscription that means you have to take

[05:59:49 - 05:59:53]
the basic plan that free plan okay you

[05:59:51 - 05:59:55]
can also take that premium subscription

[05:59:53 - 05:59:56]
but you can take that free plan free

[05:59:55 - 05:59:58]
plan actually will give you some of the

[05:59:56 - 06:00:00]
a request you can hit right now I

[05:59:58 - 06:00:02]
already do the subscription that's why

[06:00:00 - 06:00:03]
it's showing me test endpoint now simply

[06:00:02 - 06:00:05]
what you need to do you need to copy

[06:00:03 - 06:00:07]
this code snippit copy this code snippit

[06:00:05 - 06:00:09]
and with the help of that I have written

[06:00:07 - 06:00:10]
a function let me show you so this is

[06:00:09 - 06:00:14]
the function I have

[06:00:10 - 06:00:16]
written so the function name is uh get

[06:00:14 - 06:00:18]
current weather okay so it will take the

[06:00:16 - 06:00:20]
location and it will return you the

[06:00:18 - 06:00:21]
current weather in that particular

[06:00:20 - 06:00:23]
location okay see this is the U that

[06:00:21 - 06:00:25]
means the same code now here see the

[06:00:23 - 06:00:27]
same code actually have copy pasted same

[06:00:25 - 06:00:29]
code I have copy pasted you can see you

[06:00:27 - 06:00:32]
can see the same code I have copy pasted

[06:00:29 - 06:00:34]
and this is my API key rapid API key and

[06:00:32 - 06:00:36]
this is my rapid API host and don't

[06:00:34 - 06:00:38]
share with anyone otherwise they will

[06:00:36 - 06:00:40]
also able to access your account okay

[06:00:38 - 06:00:41]
I'll delete it after the recording now

[06:00:40 - 06:00:43]
with the help of request package I'm

[06:00:41 - 06:00:44]
sending the request and it will give you

[06:00:43 - 06:00:46]
the response and that response actually

[06:00:44 - 06:00:48]
I'm doing the returning and as a Json

[06:00:46 - 06:00:49]
format because I already told you now

[06:00:48 - 06:00:51]
there any kinds of API will give you as

[06:00:49 - 06:00:53]
a Json response and that particular Json

[06:00:51 - 06:00:54]
response I want to uh do the

[06:00:53 - 06:00:57]
communication with my large language

[06:00:54 - 06:00:58]
model okay this is the idea now I think

[06:00:57 - 06:00:59]
yeah everything is fine now let me

[06:00:58 - 06:01:01]
execute this

[06:00:59 - 06:01:04]
function now if you want to test what I

[06:01:01 - 06:01:06]
can do I can call this

[06:01:04 - 06:01:09]
function inside that I can give any

[06:01:06 - 06:01:13]
location let's say I will give

[06:01:09 - 06:01:13]
Delhi and it will give me

[06:01:16 - 06:01:24]
response now see the place ID uh area

[06:01:21 - 06:01:26]
India latitude longitude okay see all

[06:01:24 - 06:01:28]
the information it is giving me okay all

[06:01:26 - 06:01:29]
the information it is giving me uh

[06:01:28 - 06:01:31]
related Deli you can give any kinds of

[06:01:29 - 06:01:33]
place okay it's up to you you can give

[06:01:31 - 06:01:36]
Bangalore Delhi Mumbai okay anything you

[06:01:33 - 06:01:38]
can pass here now if I show you the

[06:01:36 - 06:01:39]
response so this is the response okay

[06:01:38 - 06:01:42]
this is the response I'm getting as it

[06:01:39 - 06:01:44]
just on fine now what I will do I'll

[06:01:42 - 06:01:45]
just connect my large language model

[06:01:44 - 06:01:47]
with this response okay with the help of

[06:01:45 - 06:01:50]
function calling for this you need to

[06:01:47 - 06:01:52]
create a functions see this is the

[06:01:50 - 06:01:55]
function format you have to follow it's

[06:01:52 - 06:01:57]
a uh it's actually you can see again

[06:01:55 - 06:01:59]
it's a kinds of Json format only so you

[06:01:57 - 06:02:01]
can see I have written a list inside

[06:01:59 - 06:02:02]
that I have mention a dictionary only

[06:02:01 - 06:02:06]
okay so this is called actually function

[06:02:02 - 06:02:08]
again if you go to the documentation

[06:02:06 - 06:02:10]
if I go to the documentation let's say

[06:02:08 - 06:02:15]
documentation so they have one function

[06:02:10 - 06:02:15]
calling you can also start here function

[06:02:17 - 06:02:22]
calling see whatever things I explained

[06:02:20 - 06:02:24]
they have written here also now see this

[06:02:22 - 06:02:25]
is the format you have to follow okay

[06:02:24 - 06:02:26]
this is the format you have to follow

[06:02:25 - 06:02:29]
that's how you can write the function

[06:02:26 - 06:02:30]
calling here so I already simplified

[06:02:29 - 06:02:33]
this thing and I written a function okay

[06:02:30 - 06:02:34]
so similar like format you can also

[06:02:33 - 06:02:36]
follow now first thing you have to give

[06:02:34 - 06:02:38]
the name so current

[06:02:36 - 06:02:40]
get current weather so I have written my

[06:02:38 - 06:02:42]
function name here you can see this the

[06:02:40 - 06:02:44]
function name get current weather that

[06:02:42 - 06:02:46]
means this will hit that particular

[06:02:44 - 06:02:48]
function because this is my third party

[06:02:46 - 06:02:50]
API okay you can also consider database

[06:02:48 - 06:02:52]
here but as of now I'm considering the

[06:02:50 - 06:02:54]
function now this is the description get

[06:02:52 - 06:02:56]
the current weather in given location

[06:02:54 - 06:02:58]
parameter object properties location

[06:02:56 - 06:02:59]
string and the final thing required

[06:02:58 - 06:03:01]
location that means it needs the

[06:02:59 - 06:03:03]
location okay if I if it needs to give

[06:03:01 - 06:03:04]
any kinds of output first of all it need

[06:03:03 - 06:03:07]
the location because my function takes

[06:03:04 - 06:03:10]
the location out input okay I hope it is

[06:03:07 - 06:03:12]
clear now let me initialize my

[06:03:10 - 06:03:14]
functions now I think remember whenever

[06:03:12 - 06:03:16]
I was using this chat completion API

[06:03:14 - 06:03:18]
okay chat completion model that means I

[06:03:16 - 06:03:19]
can give multiple prompt I can add

[06:03:18 - 06:03:23]
multiple prompt okay in that particular

[06:03:19 - 06:03:24]
let's say um message section so that

[06:03:23 - 06:03:26]
concept actually will try to utilize

[06:03:24 - 06:03:28]
here see here I have given an example

[06:03:26 - 06:03:30]
let's say this is uh here I'm using chat

[06:03:28 - 06:03:32]
completion model and I have to prepare

[06:03:30 - 06:03:33]
the message function I think remember

[06:03:32 - 06:03:36]
this message function inside that I can

[06:03:33 - 06:03:38]
give multiple Ro right that is multiple

[06:03:36 - 06:03:39]
prompt so what I'm doing here I'm

[06:03:38 - 06:03:42]
appending one prompt here you can see

[06:03:39 - 06:03:44]
user masses masses. append because it's

[06:03:42 - 06:03:46]
a list I can append roll user content

[06:03:44 - 06:03:47]
user message okay now it will add this

[06:03:46 - 06:03:49]
particular prompt inside my message now

[06:03:47 - 06:03:52]
see if I

[06:03:49 - 06:03:54]
execute now if I show you the now see if

[06:03:52 - 06:03:55]
you want to see the output see this is

[06:03:54 - 06:03:58]
the output hello how I can assist you

[06:03:55 - 06:04:00]
now if you want to see the message only

[06:03:58 - 06:04:02]
now see in the masses one prompt has

[06:04:00 - 06:04:04]
been added okay this is the user prompt

[06:04:02 - 06:04:06]
has been added that's how I can also add

[06:04:04 - 06:04:08]
multiple prompt again what I can do I

[06:04:06 - 06:04:10]
can do the append

[06:04:08 - 06:04:12]
operation see again I have taken another

[06:04:10 - 06:04:14]
user message what is the temperature of

[06:04:12 - 06:04:17]
Del now I'm appending in the message now

[06:04:14 - 06:04:19]
roll user content user because this is a

[06:04:17 - 06:04:21]
user okay user message only now again

[06:04:19 - 06:04:22]
I'm adding the message and I'm also

[06:04:21 - 06:04:24]
adding the function the function calling

[06:04:22 - 06:04:26]
I have defined now here this particular

[06:04:24 - 06:04:27]
function calling so with the help of

[06:04:26 - 06:04:30]
this function it will try to understand

[06:04:27 - 06:04:32]
okay I need to execute this get current

[06:04:30 - 06:04:33]
weather okay this particular function

[06:04:32 - 06:04:35]
and this particular function will return

[06:04:33 - 06:04:37]
return the Json output that means the

[06:04:35 - 06:04:38]
data data related by that and it will

[06:04:37 - 06:04:40]
automatically connect the large language

[06:04:38 - 06:04:42]
model in that particular data see the

[06:04:40 - 06:04:43]
same diagram I showed you now here it

[06:04:42 - 06:04:45]
will give you the response and my large

[06:04:43 - 06:04:49]
language model will connect through

[06:04:45 - 06:04:53]
function calling okay now let me show

[06:04:49 - 06:04:53]
you so if I execute

[06:04:53 - 06:04:57]
it now if I show you the masses now see

[06:04:55 - 06:05:00]
two masses has been added two prompt has

[06:04:57 - 06:05:02]
been added hi there now second prompt

[06:05:00 - 06:05:03]
what is the temperature of Del you can

[06:05:02 - 06:05:05]
also ignore this prompt I've just only

[06:05:03 - 06:05:07]
given because I just wanted to show you

[06:05:05 - 06:05:10]
okay whether you can add any new prompt

[06:05:07 - 06:05:12]
or not okay this is the idea now if you

[06:05:10 - 06:05:13]
see the completion that means the

[06:05:12 - 06:05:16]
response see this is the response you

[06:05:13 - 06:05:18]
got see as of now it is only calling the

[06:05:16 - 06:05:20]
function you can see it is only calling

[06:05:18 - 06:05:22]
the gate weather function okay and here

[06:05:20 - 06:05:23]
you have given the location of Dilly you

[06:05:22 - 06:05:25]
can see it is automatically extracting

[06:05:23 - 06:05:28]
the location from your prompt okay you

[06:05:25 - 06:05:30]
can see location D you have given okay

[06:05:28 - 06:05:33]
now if you want to get the information

[06:05:30 - 06:05:34]
what you can do now if you want to get

[06:05:33 - 06:05:35]
the actual information what you can do

[06:05:34 - 06:05:37]
let me show you let's say say you want

[06:05:35 - 06:05:39]
to see the masses you can also see the

[06:05:37 - 06:05:42]
masses this is the massage it is calling

[06:05:39 - 06:05:45]
my function and this is my location now

[06:05:42 - 06:05:45]
this is the

[06:05:48 - 06:05:52]
response okay this is the

[06:05:52 - 06:05:57]
response now if you only want to extract

[06:05:55 - 06:06:00]
let's say the function name what you can

[06:05:57 - 06:06:02]
do you can extract like that so it is

[06:06:00 - 06:06:07]
inside function called name okay and it

[06:06:02 - 06:06:09]
is my get current weather function

[06:06:07 - 06:06:10]
and if you want to see the location so

[06:06:09 - 06:06:12]
what you can do insert function called

[06:06:10 - 06:06:14]
insert argument location you can see

[06:06:12 - 06:06:17]
argument location I'm extracting the

[06:06:14 - 06:06:19]
Delhi here see this is my location okay

[06:06:17 - 06:06:23]
now this response actually I'm getting I

[06:06:19 - 06:06:25]
need to pass to my large language model

[06:06:23 - 06:06:27]
for this you can execute this code uh

[06:06:25 - 06:06:28]
message. append response the response

[06:06:27 - 06:06:30]
actually I'm getting I'm again adding to

[06:06:28 - 06:06:32]
the message that means as a prompt okay

[06:06:30 - 06:06:36]
as a prompt actually I'm adding I think

[06:06:32 - 06:06:39]
remember here now um here I showed you

[06:06:36 - 06:06:41]
you can give multiple prompt this prompt

[06:06:39 - 06:06:43]
this prompt that means I was providing

[06:06:41 - 06:06:44]
the data Based on data I was asking the

[06:06:43 - 06:06:46]
question the similar things I'm doing

[06:06:44 - 06:06:48]
the response actually I'm getting this

[06:06:46 - 06:06:50]
response entire response I'm getting now

[06:06:48 - 06:06:52]
this is I'm passing as a prompt okay as

[06:06:50 - 06:06:53]
a prompt data and on top of this font

[06:06:52 - 06:06:55]
I'll be asking the question okay with

[06:06:53 - 06:06:56]
the help of function calling see the

[06:06:55 - 06:06:58]
same thing I'm doing appending the

[06:06:56 - 06:07:01]
response message.

[06:06:58 - 06:07:04]
append now I'm appending the role as a

[06:07:01 - 06:07:05]
function name function content location

[06:07:04 - 06:07:08]
okay this thing actually I'm passing one

[06:07:05 - 06:07:10]
by one if I show you the entire masses

[06:07:08 - 06:07:13]
see this is my entire masses right now

[06:07:10 - 06:07:15]
now I can initialize my gbt 3.5 tarbo

[06:07:13 - 06:07:17]
model inside that I'm passing my message

[06:07:15 - 06:07:21]
as well as the function calling now it

[06:07:17 - 06:07:24]
will give you the accurate response see

[06:07:21 - 06:07:25]
the prompt you have given um the current

[06:07:24 - 06:07:27]
here is the prompt you have given I

[06:07:25 - 06:07:27]
think

[06:07:29 - 06:07:33]
remember what is the temperature of

[06:07:31 - 06:07:35]
Dilly now see this is the temperature of

[06:07:33 - 06:07:40]
Dilly right now okay and it is coming

[06:07:35 - 06:07:41]
like that because it's a 32 uh 32¬∞ cius

[06:07:40 - 06:07:43]
so degree is a special character that's

[06:07:41 - 06:07:44]
why it's coming like that okay you can

[06:07:43 - 06:07:45]
convert to special uh see you can

[06:07:44 - 06:07:48]
convert this UN code to special

[06:07:45 - 06:07:49]
character okay it is also possible now

[06:07:48 - 06:07:51]
see here I have executed actually line

[06:07:49 - 06:07:53]
by line that's why you can see you can

[06:07:51 - 06:07:55]
also execute as a snippet of the code it

[06:07:53 - 06:07:57]
will give you the complete response now

[06:07:55 - 06:07:59]
see instead of giving DHI I can give

[06:07:57 - 06:08:03]
let's say

[06:07:59 - 06:08:03]
Mumbai now let's see the

[06:08:04 - 06:08:07]
Mumbai temp

[06:08:13 - 06:08:17]
see uh it is not able to fetching the

[06:08:15 - 06:08:18]
Mumbai temperature currently so what I

[06:08:17 - 06:08:21]
can do I can give any other location

[06:08:18 - 06:08:25]
let's say I give U as of now I can

[06:08:21 - 06:08:27]
comment this two line it's not

[06:08:25 - 06:08:30]
required I'll give let's say

[06:08:27 - 06:08:32]
Bangalore now see this is the current

[06:08:30 - 06:08:35]
temperature of the Bangalore okay so

[06:08:32 - 06:08:37]
that's how actually you can uh uh uh

[06:08:35 - 06:08:38]
give any kinds of information any kinds

[06:08:37 - 06:08:39]
of API you can connect with your large

[06:08:38 - 06:08:41]
language model with the help of this

[06:08:39 - 06:08:43]
function calling technique and it's like

[06:08:41 - 06:08:45]
very powerful technique guys trust me

[06:08:43 - 06:08:47]
it's like very powerful technique okay

[06:08:45 - 06:08:49]
if you're uh interested learning more

[06:08:47 - 06:08:50]
about it like what are the things you

[06:08:49 - 06:08:51]
can connect you can go to their

[06:08:50 - 06:08:52]
documentation okay they have written

[06:08:51 - 06:08:55]
each and everything what are the things

[06:08:52 - 06:08:57]
you can connect with it here right okay

[06:08:55 - 06:09:00]
so yes guys this is all about from this

[06:08:57 - 06:09:01]
video I I hope you liked it now in the

[06:09:00 - 06:09:03]
next video we'll be implementing one

[06:09:01 - 06:09:05]
projects whatever concept you have

[06:09:03 - 06:09:07]
learned so far uh the project name is

[06:09:05 - 06:09:09]
telegram bot okay telegram bot with the

[06:09:07 - 06:09:10]
help of openi that means we'll be

[06:09:09 - 06:09:13]
creating a chat bot and we'll be

[06:09:10 - 06:09:14]
integrating with the telegram okay so

[06:09:13 - 06:09:16]
all the fundamentals we have already

[06:09:14 - 06:09:19]
discussed now it's time to implement one

[06:09:16 - 06:09:21]
projects uh with the help of openi so in

[06:09:19 - 06:09:22]
this video I'll show you how we can

[06:09:21 - 06:09:25]
Implement one telegram chatbot with the

[06:09:22 - 06:09:27]
help of open that means uh here we'll be

[06:09:25 - 06:09:28]
using one chat completion model that

[06:09:27 - 06:09:31]
means one large language model we'll be

[06:09:28 - 06:09:32]
using called GPT 3.5 uh and with the

[06:09:31 - 06:09:34]
help of that actually we'll be

[06:09:32 - 06:09:35]
implementing one chatboard and we'll be

[06:09:34 - 06:09:38]
integrating this chatboard with the

[06:09:35 - 06:09:40]
telegram platform okay so make sure you

[06:09:38 - 06:09:42]
have the telegram guys uh it can be a

[06:09:40 - 06:09:44]
smartphone telegram application or it

[06:09:42 - 06:09:46]
can be your desktop application as well

[06:09:44 - 06:09:48]
anything you can keep both will work

[06:09:46 - 06:09:49]
okay so here I'm going to use my desktop

[06:09:48 - 06:09:51]
telegram you can also use your

[06:09:49 - 06:09:53]
smartphone telegram it will also work

[06:09:51 - 06:09:54]
fine so before starting the

[06:09:53 - 06:09:56]
implementation guys first of all let me

[06:09:54 - 06:09:58]
show you the architecture diagram like

[06:09:56 - 06:09:59]
how we'll be implementing the entire

[06:09:58 - 06:10:01]
projects then after that we'll be doing

[06:09:59 - 06:10:04]
the setup and we'll be starting the

[06:10:01 - 06:10:07]
implementation so guys let's say uh this

[06:10:04 - 06:10:07]
is the user that means

[06:10:10 - 06:10:17]
you so you will be asking one

[06:10:14 - 06:10:21]
query okay you'll be asking one query

[06:10:17 - 06:10:21]
and this query will go to the front

[06:10:23 - 06:10:28]
end okay front end of our application so

[06:10:26 - 06:10:31]
here front end wise we'll be using

[06:10:28 - 06:10:31]
something called

[06:10:31 - 06:10:40]
telegram fine then what will happen uh

[06:10:35 - 06:10:40]
this s will go to the back

[06:10:41 - 06:10:45]
end back end means our

[06:10:48 - 06:10:57]
openi openi API okay open a API then

[06:10:53 - 06:10:57]
this API will access the large language

[06:10:57 - 06:11:01]
model that means here will be using

[06:11:02 - 06:11:08]
GPT 3.5 okay you can also use any other

[06:11:05 - 06:11:08]
model like

[06:11:09 - 06:11:16]
GPT GPT uh 4 you can also use GPT 4 or

[06:11:14 - 06:11:18]
it's up to you okay I I I think I showed

[06:11:16 - 06:11:20]
you how to like select different

[06:11:18 - 06:11:21]
different model there is a model list so

[06:11:20 - 06:11:23]
if you click there you will see the

[06:11:21 - 06:11:27]
model ID so that particular ID you have

[06:11:23 - 06:11:28]
to write there okay and this model is I

[06:11:27 - 06:11:30]
think you already know this is a chat

[06:11:28 - 06:11:33]
completion model okay why that

[06:11:30 - 06:11:34]
completion model because it can take the

[06:11:33 - 06:11:36]
instruction that means multiple

[06:11:34 - 06:11:38]
instruction you can give multiple prompt

[06:11:36 - 06:11:39]
you can give okay you can also create

[06:11:38 - 06:11:42]
with the help of completion model like

[06:11:39 - 06:11:44]
the babz one okay I already showed you

[06:11:42 - 06:11:45]
uh which will also work but what I feel

[06:11:44 - 06:11:48]
like this chat completion model will be

[06:11:45 - 06:11:51]
more powerful okay this is the idea here

[06:11:48 - 06:11:54]
now it will happen this uh uh large

[06:11:51 - 06:11:54]
language model will give the

[06:11:54 - 06:11:58]
response so where so where it will give

[06:11:57 - 06:12:02]
the response it will give the response

[06:11:58 - 06:12:06]
to the backend API that means your openi

[06:12:02 - 06:12:08]
API and openi API will send the uh let's

[06:12:06 - 06:12:13]
say response to the front end okay front

[06:12:08 - 06:12:15]
end means our telegram okay and from

[06:12:13 - 06:12:17]
telegram actually user will again get

[06:12:15 - 06:12:17]
the

[06:12:18 - 06:12:23]
response response let's this is the

[06:12:20 - 06:12:25]
response and this is the

[06:12:23 - 06:12:27]
question okay so that's how actually

[06:12:25 - 06:12:30]
we'll be implementing the entire

[06:12:27 - 06:12:32]
projects okay uh this is our actually

[06:12:30 - 06:12:34]
high level architecture of our project

[06:12:32 - 06:12:37]
now what I will do uh first of all uh I

[06:12:34 - 06:12:39]
just need to get my open API key and I

[06:12:37 - 06:12:41]
already told you how to get the open API

[06:12:39 - 06:12:44]
key so make sure you already created

[06:12:41 - 06:12:46]
your open API key and you keep it with

[06:12:44 - 06:12:48]
you now in my computer I'll just create

[06:12:46 - 06:12:51]
a folder here and I'm going to name it

[06:12:48 - 06:12:51]
as uh

[06:12:53 - 06:12:59]
telegram chatbot okay telegram chatbot

[06:12:57 - 06:13:02]
and inside that I'm going to open up my

[06:12:59 - 06:13:02]
visual code Studio

[06:13:05 - 06:13:09]
H then I'm also going to open up my

[06:13:08 - 06:13:12]
terminal

[06:13:09 - 06:13:14]
here you can also open up your um

[06:13:12 - 06:13:17]
command prompt then you can also open up

[06:13:14 - 06:13:18]
your anagon prom it's up to you now here

[06:13:17 - 06:13:20]
the first thing what I have to do I have

[06:13:18 - 06:13:22]
to create one virtual environment so to

[06:13:20 - 06:13:26]
create the virtual environment just

[06:13:22 - 06:13:28]
write cond create tyen in uh give the

[06:13:26 - 06:13:29]
name of the environment let's say this

[06:13:28 - 06:13:30]
is

[06:13:29 - 06:13:35]
my

[06:13:30 - 06:13:37]
t Okay telegram so I'll just write tbot

[06:13:35 - 06:13:38]
uh specify the python version let's say

[06:13:37 - 06:13:42]
python is equal to

[06:13:38 - 06:13:45]
3 let's say 8 okay I'll use it

[06:13:42 - 06:13:47]
3.8 uh you can also use 3.9 but let's

[06:13:45 - 06:13:52]
use 3.8 then H can

[06:13:47 - 06:13:52]
bu um yeah now let's create the

[06:13:59 - 06:14:04]
environment so my environment is created

[06:14:02 - 06:14:07]
now let me activate just write cond

[06:14:04 - 06:14:07]
activate

[06:14:09 - 06:14:15]
teleport now let me

[06:14:12 - 06:14:17]
clear now uh what I will do I'll just

[06:14:15 - 06:14:20]
create a requirement. txt

[06:14:17 - 06:14:20]
file

[06:14:20 - 06:14:26]
requirements.txt

[06:14:22 - 06:14:27]
so inside that I need to mention all the

[06:14:26 - 06:14:31]
let's say library I need to implement

[06:14:27 - 06:14:33]
this project so here you can see um

[06:14:31 - 06:14:36]
front end wise actually uh I'll be using

[06:14:33 - 06:14:38]
telegram okay and to integrate my

[06:14:36 - 06:14:40]
chatbot with my telegram I need a python

[06:14:38 - 06:14:42]
package that means this package will

[06:14:40 - 06:14:44]
communicate with my telegram so inside

[06:14:42 - 06:14:46]
telegram will be generating one uh let's

[06:14:44 - 06:14:48]
say API token so with the help of API

[06:14:46 - 06:14:51]
token we'll be communicating with our

[06:14:48 - 06:14:52]
telegram app right so for this actually

[06:14:51 - 06:14:54]
we need one python package so let me

[06:14:52 - 06:14:56]
show you this package actually the

[06:14:54 - 06:14:57]
package actually I'm going to use so

[06:14:56 - 06:14:59]
guys as you can see this is the package

[06:14:57 - 06:15:01]
actually we'll be using uh the package

[06:14:59 - 06:15:05]
name is AOG so as you can see a is a

[06:15:01 - 06:15:08]
modern and fully ason chromos uh asnr

[06:15:05 - 06:15:11]
framework for telegram B API and this is

[06:15:08 - 06:15:12]
the complete documentation of this AI

[06:15:11 - 06:15:15]
even they have also given the sample

[06:15:12 - 06:15:16]
code like how we can connect with theam

[06:15:15 - 06:15:18]
and all okay they have discussed each

[06:15:16 - 06:15:20]
and everything uh but you can see they

[06:15:18 - 06:15:23]
have written actually too much line of

[06:15:20 - 06:15:24]
code but uh that many line of code

[06:15:23 - 06:15:27]
actually is not required so what I've

[06:15:24 - 06:15:29]
done I just uh made it uh like simple

[06:15:27 - 06:15:31]
and I created one Basics template for

[06:15:29 - 06:15:33]
you if if you want to connect with your

[06:15:31 - 06:15:35]
telegram okay so how you can connect for

[06:15:33 - 06:15:37]
this uh what kinds of code you have use

[06:15:35 - 06:15:39]
I already prepared one for snippet okay

[06:15:37 - 06:15:40]
I'll share with you so first of all let

[06:15:39 - 06:15:43]
me mention this package name inside my

[06:15:40 - 06:15:45]
requirements so so the first package I'm

[06:15:43 - 06:15:49]
going to add called

[06:15:45 - 06:15:51]
a fine now the second package I need

[06:15:49 - 06:15:53]
open and I'm going to use the same

[06:15:51 - 06:15:56]
version of the openi I already used in

[06:15:53 - 06:16:00]
My openi Demo then I need another

[06:15:56 - 06:16:02]
package called python uhv why python.

[06:16:00 - 06:16:05]
EnV because I already showed you if you

[06:16:02 - 06:16:08]
want to manage the secret key so you can

[06:16:05 - 06:16:10]
use this uh python. to load that secret

[06:16:08 - 06:16:12]
key from the environment that means EnV

[06:16:10 - 06:16:15]
file okay this is the idea now let me

[06:16:12 - 06:16:17]
save now what I will do simply I'll

[06:16:15 - 06:16:20]
install everything in my uh environment

[06:16:17 - 06:16:25]
so for this just write this command so P

[06:16:20 - 06:16:25]
install tyen at requirement.

[06:16:33 - 06:16:38]
txd so guys you can see my installation

[06:16:35 - 06:16:41]
is completed now let me clear my

[06:16:38 - 06:16:44]
terminal and now first of all we'll be

[06:16:41 - 06:16:46]
testing our uh this one telegram whether

[06:16:44 - 06:16:48]
we are able to make the connection

[06:16:46 - 06:16:51]
without telegram or not so for this I'm

[06:16:48 - 06:16:53]
going to create a folder here called

[06:16:51 - 06:16:55]
resarch inside that I'm going to create

[06:16:53 - 06:16:58]
a file I'm going to name it as eobot

[06:16:55 - 06:17:00]
eore bot so here we'll be creating one

[06:16:58 - 06:17:03]
uh Eco actually Eco functionality that

[06:17:00 - 06:17:05]
means if you're sending any message okay

[06:17:03 - 06:17:08]
to the let's say chat that means to your

[06:17:05 - 06:17:09]
telegram chatbot it will give you the

[06:17:08 - 06:17:11]
same message okay this is called

[06:17:09 - 06:17:12]
actually eobot that means whatever

[06:17:11 - 06:17:14]
message actually will be giving as an

[06:17:12 - 06:17:17]
input that message actually will be

[06:17:14 - 06:17:18]
getting as an output okay so that means

[06:17:17 - 06:17:20]
I just wanted to experiment whether I'm

[06:17:18 - 06:17:22]
able to successfully connect with my

[06:17:20 - 06:17:24]
telam or not okay this is the idea here

[06:17:22 - 06:17:27]
but before that I just need to create

[06:17:24 - 06:17:29]
this EnV

[06:17:27 - 06:17:32]
file now inside that first of all you

[06:17:29 - 06:17:35]
have to uh write your open API key so

[06:17:32 - 06:17:36]
let me just write my open API key so

[06:17:35 - 06:17:38]
this is my open API key I think you

[06:17:36 - 06:17:41]
remember I already created this API key

[06:17:38 - 06:17:43]
okay now let me save now just open up

[06:17:41 - 06:17:45]
your telegram app so here I'm using my

[06:17:43 - 06:17:48]
desktop telegram so you can see this is

[06:17:45 - 06:17:50]
my desktop telegram to search for

[06:17:48 - 06:17:52]
BFA so after searching BFA you will see

[06:17:50 - 06:17:54]
different different B further but you

[06:17:52 - 06:17:55]
have to take the verified one you can

[06:17:54 - 06:17:58]
see this is the verified one now just

[06:17:55 - 06:18:00]
try to open it up see I already opened

[06:17:58 - 06:18:02]
now see uh previously I already created

[06:18:00 - 06:18:05]
some of the bot with the help of Bot F

[06:18:02 - 06:18:06]
that's why it's coming um that's why

[06:18:05 - 06:18:09]
here you can see some of the uh like

[06:18:06 - 06:18:10]
older masses but if you're opening for

[06:18:09 - 06:18:12]
the first time you won't be seeing any

[06:18:10 - 06:18:13]
kinds of masses okay you will see a

[06:18:12 - 06:18:15]
start button you just click on the start

[06:18:13 - 06:18:17]
button okay then it will give you the

[06:18:15 - 06:18:20]
suggestion okay what you want to do here

[06:18:17 - 06:18:22]
so here I want to create a okay I think

[06:18:20 - 06:18:25]
my screen is

[06:18:22 - 06:18:27]
visible okay so here I want to uh let's

[06:18:25 - 06:18:29]
say create a new uh actually telegram

[06:18:27 - 06:18:32]
bot so for this what you can do you can

[06:18:29 - 06:18:35]
write this command new Slash new okay

[06:18:32 - 06:18:38]
new bot you can see new bot just select

[06:18:35 - 06:18:41]
this one now see now it will ask you all

[06:18:38 - 06:18:43]
right a new bot how are we going to call

[06:18:41 - 06:18:45]
okay please choose a name for your Bot

[06:18:43 - 06:18:47]
now you can give any kinds of name here

[06:18:45 - 06:18:52]
so let's say I will give

[06:18:47 - 06:18:52]
U my

[06:18:52 - 06:19:00]
live okay my live

[06:18:57 - 06:19:02]
bot let's say 24 let's say this is my

[06:19:00 - 06:19:04]
bot name I want to give now if I hit

[06:19:02 - 06:19:07]
enter see it's telling good now let's

[06:19:04 - 06:19:10]
choose the username for your Bot it must

[06:19:07 - 06:19:12]
end with bot like uh this is example ter

[06:19:10 - 06:19:14]
bot or terore bot okay so you have to

[06:19:12 - 06:19:16]
give a username and that username should

[06:19:14 - 06:19:19]
contain underscore bot okay at the last

[06:19:16 - 06:19:21]
so I'll give the same name let's say my

[06:19:19 - 06:19:23]
live

[06:19:21 - 06:19:27]
bot okay

[06:19:23 - 06:19:28]
24ore bot now if I hit enter now see my

[06:19:27 - 06:19:31]
bot is created now it is telling

[06:19:28 - 06:19:33]
congratulations on your new bot you will

[06:19:31 - 06:19:34]
find your Bot here but before that what

[06:19:33 - 06:19:37]
you have to do you have to collect this

[06:19:34 - 06:19:40]
user uh you can see uh use token so let

[06:19:37 - 06:19:43]
me collect this use token I'll

[06:19:40 - 06:19:44]
copy okay and I'll open up my visual

[06:19:43 - 06:19:47]
code Studio inside environment what I

[06:19:44 - 06:19:47]
will

[06:19:47 - 06:19:53]
do so here I'm going to paste it as of

[06:19:50 - 06:19:55]
now and you need to also give the key

[06:19:53 - 06:19:58]
name that means this is my

[06:19:55 - 06:20:01]
telegram bot token okay now I'll be

[06:19:58 - 06:20:03]
mentioning inside my string so here we

[06:20:01 - 06:20:05]
have collected two secret key one is my

[06:20:03 - 06:20:07]
open API key another one is telegram bot

[06:20:05 - 06:20:09]
token so with the help of telegram bot

[06:20:07 - 06:20:10]
token we'll be authenticating with our

[06:20:09 - 06:20:11]
bot actually we have created here you

[06:20:10 - 06:20:13]
can see this is my bot if I click on the

[06:20:11 - 06:20:16]
URL right now see this is my bot now if

[06:20:13 - 06:20:17]
I click on the start now see there uh

[06:20:16 - 06:20:19]
you won't be seeing anything because

[06:20:17 - 06:20:22]
this is not connected yet now see if I

[06:20:19 - 06:20:24]
send any message here so you won't be

[06:20:22 - 06:20:26]
getting any kinds of response because as

[06:20:24 - 06:20:28]
of now we haven't made the connection so

[06:20:26 - 06:20:29]
here first of all we have to make the

[06:20:28 - 06:20:30]
connection and how to make the

[06:20:29 - 06:20:32]
connection with the help of this

[06:20:30 - 06:20:35]
telegram bot token okay and this open

[06:20:32 - 06:20:37]
API key we need to access our GPT model

[06:20:35 - 06:20:38]
because this is my main large language

[06:20:37 - 06:20:39]
model right with the help of that

[06:20:38 - 06:20:42]
actually we'll be getting the actual

[06:20:39 - 06:20:45]
response this is the idea here fine now

[06:20:42 - 06:20:47]
in the eobot uh I'll be writing some of

[06:20:45 - 06:20:49]
the code to connect with my telegram

[06:20:47 - 06:20:51]
okay so as I already showed you so this

[06:20:49 - 06:20:52]
is the AOG documentation and they have

[06:20:51 - 06:20:54]
given the code snippet you can use to

[06:20:52 - 06:20:56]
connect with the telegram right but I

[06:20:54 - 06:20:58]
already told you this uh that much of

[06:20:56 - 06:21:00]
actually code is not required so I just

[06:20:58 - 06:21:02]
created a Basics template let me show

[06:21:00 - 06:21:03]
you so here first of all let me import

[06:21:02 - 06:21:05]
some required Library so you can see I

[06:21:03 - 06:21:08]
have imported some library but here it

[06:21:05 - 06:21:10]
is coming this yellow mark because I

[06:21:08 - 06:21:11]
haven't selected my current environment

[06:21:10 - 06:21:13]
right so right hand side below you can

[06:21:11 - 06:21:15]
see there is one option so my base

[06:21:13 - 06:21:16]
environment is selected now I have to

[06:21:15 - 06:21:18]
select my own environment which is

[06:21:16 - 06:21:20]
nothing but telegram B okay now see this

[06:21:18 - 06:21:22]
arror would be disappeared now see these

[06:21:20 - 06:21:24]
are the package you have to import like

[06:21:22 - 06:21:27]
login aam from aam you have to import

[06:21:24 - 06:21:28]
bot dispatcher execute executor and

[06:21:27 - 06:21:30]
types okay if you see the documentation

[06:21:28 - 06:21:32]
also they are importing the same thing

[06:21:30 - 06:21:34]
see they're importing the same thing as

[06:21:32 - 06:21:36]
well fine but as I told you they have

[06:21:34 - 06:21:38]
written so many line of code I just

[06:21:36 - 06:21:40]
simplified the code okay that's why um

[06:21:38 - 06:21:41]
my code might be a little bit different

[06:21:40 - 06:21:44]
um okay from the documentation this is

[06:21:41 - 06:21:47]
the idea now I'm loading because with

[06:21:44 - 06:21:49]
help ofb I'm I'm going to load by okay

[06:21:47 - 06:21:51]
that means my secret okay inside uh

[06:21:49 - 06:21:52]
inside my environment now operating

[06:21:51 - 06:21:54]
system I need because with the help of

[06:21:52 - 06:21:56]
operating system I'll be loading now O.G

[06:21:54 - 06:21:58]
I think you remember previously you also

[06:21:56 - 06:22:01]
did the same thing and why logging is

[06:21:58 - 06:22:02]
required because if you see the aam uh

[06:22:01 - 06:22:05]
if you see the aam they are also using

[06:22:02 - 06:22:07]
login okay so you have to uh write the

[06:22:05 - 06:22:09]
login okay login here see basic config

[06:22:07 - 06:22:11]
loging so by default it will take the

[06:22:09 - 06:22:13]
log because it will let's log all the

[06:22:11 - 06:22:15]
information in the back end okay because

[06:22:13 - 06:22:16]
see this is their implementation they're

[06:22:15 - 06:22:18]
suggesting to use these are the let's

[06:22:16 - 06:22:21]
say Cod cipit okay that's why I'm using

[06:22:18 - 06:22:22]
it's not my implementation so whenever

[06:22:21 - 06:22:25]
you are using any kinds of let's say

[06:22:22 - 06:22:26]
framework or Library first of all try to

[06:22:25 - 06:22:28]
check their documentation whatever

[06:22:26 - 06:22:30]
things they are suggesting based on that

[06:22:28 - 06:22:32]
you have to write the code okay no need

[06:22:30 - 06:22:33]
to do any modification at the very first

[06:22:32 - 06:22:35]
if you understand their implementation

[06:22:33 - 06:22:37]
then you can do the modification but the

[06:22:35 - 06:22:40]
core implementation you have to always

[06:22:37 - 06:22:41]
keep as same okay this is the idea here

[06:22:40 - 06:22:45]
now the first thing what I have to do

[06:22:41 - 06:22:47]
guys I have to set my I have to set my I

[06:22:45 - 06:22:51]
have to load my API key right so for

[06:22:47 - 06:22:53]
this I can use this load EnV now simply

[06:22:51 - 06:22:57]
o

[06:22:53 - 06:22:58]
dog uh EnV inside that I can pass my key

[06:22:57 - 06:23:01]
name let's say I want to load my

[06:22:58 - 06:23:03]
telegram bot token I'll pass the key

[06:23:01 - 06:23:05]
name here fine so it will return return

[06:23:03 - 06:23:09]
me my telegram bot token

[06:23:05 - 06:23:11]
now if I print this one my telegram bot

[06:23:09 - 06:23:13]
token now see if I execute the file

[06:23:11 - 06:23:16]
right now it will print the bot token so

[06:23:13 - 06:23:18]
let me show you so python let's say my

[06:23:16 - 06:23:21]
it is inside my resarch folder resarch I

[06:23:18 - 06:23:25]
want to execute this eobot okay

[06:23:21 - 06:23:28]
sorry uh eobot

[06:23:25 - 06:23:30]
dop so guys uh you can see it is showing

[06:23:28 - 06:23:32]
me one error it is telling from aam

[06:23:30 - 06:23:35]
import bar dispatcher executor types

[06:23:32 - 06:23:38]
import error cannot import the executor

[06:23:35 - 06:23:40]
from a okay so it is uh throwing me one

[06:23:38 - 06:23:42]
error so to solve this error what you

[06:23:40 - 06:23:44]
have to do so you have to create

[06:23:42 - 06:23:47]
actually uh python uh let's say

[06:23:44 - 06:23:49]
interpreter 3.7 that means python

[06:23:47 - 06:23:50]
environment you need uh 3.7 so let's

[06:23:49 - 06:23:53]
create one another environment so I'll

[06:23:50 - 06:23:53]
just write Conta

[06:23:54 - 06:24:01]
create typen in uh let's give the name

[06:23:58 - 06:24:01]
let's say

[06:24:02 - 06:24:10]
mybot python is equal to 3. uh 7

[06:24:07 - 06:24:10]
actually I want to use typ and

[06:24:16 - 06:24:23]
while okay now let me activate Honda

[06:24:20 - 06:24:26]
activate

[06:24:23 - 06:24:29]
mybot now let me clear and let me

[06:24:26 - 06:24:32]
install the requirements right now so P

[06:24:29 - 06:24:35]
install ienr

[06:24:32 - 06:24:36]
requirement. dxt see it has installed

[06:24:35 - 06:24:38]
all the packages in my environment okay

[06:24:36 - 06:24:40]
so I already installed that's why it's

[06:24:38 - 06:24:41]
telling requirement is already satisfied

[06:24:40 - 06:24:43]
but for you it will take some time okay

[06:24:41 - 06:24:45]
so once it is done now let's clear my

[06:24:43 - 06:24:49]
terminal and now if you execute the

[06:24:45 - 06:24:51]
command uh this command python research

[06:24:49 - 06:24:53]
E.P that means if you execute this Eco

[06:24:51 - 06:24:57]
bot right now now see it should work now

[06:24:53 - 06:24:58]
see it is printing my uh API token okay

[06:24:57 - 06:25:00]
it is printing my API token right now

[06:24:58 - 06:25:02]
telegram B token fine that means it is

[06:25:00 - 06:25:04]
working now now let me comment this line

[06:25:02 - 06:25:06]
it's not required now what you have to

[06:25:04 - 06:25:09]
do you have to first of all initialize

[06:25:06 - 06:25:11]
the login so that's how actually you can

[06:25:09 - 06:25:14]
initialize the login so you just need to

[06:25:11 - 06:25:16]
write login. basic config Lael is equal

[06:25:14 - 06:25:18]
to loging doino okay because if you

[06:25:16 - 06:25:19]
check the documentation they suggesting

[06:25:18 - 06:25:21]
like that okay you have to configure the

[06:25:19 - 06:25:23]
loging like that okay after that you

[06:25:21 - 06:25:25]
have to initialize the bot and

[06:25:23 - 06:25:27]
dispatcher so this is the bot and

[06:25:25 - 06:25:31]
dispatcher so inside that you have to

[06:25:27 - 06:25:33]
pass the API token okay now see what

[06:25:31 - 06:25:35]
will happen you can see from AIG I

[06:25:33 - 06:25:37]
imported bot right because I want to

[06:25:35 - 06:25:39]
Conn connect with my telegram bot the

[06:25:37 - 06:25:41]
bot actually have created now if I want

[06:25:39 - 06:25:44]
to connect what I need I need the API

[06:25:41 - 06:25:46]
token tegram bot API token yes or no

[06:25:44 - 06:25:48]
right so here you can see I'm passing

[06:25:46 - 06:25:51]
this bot token inside a token actually

[06:25:48 - 06:25:52]
attribute so what will happen this bot

[06:25:51 - 06:25:54]
will be initialized that means it will

[06:25:52 - 06:25:56]
authenticate with my credential if the

[06:25:54 - 06:25:58]
authentication is correct that means

[06:25:56 - 06:26:00]
this uh statement would be true okay if

[06:25:58 - 06:26:02]
it is true that means my dispatcher will

[06:26:00 - 06:26:04]
be connected okay dispatcher means let's

[06:26:02 - 06:26:07]
say the synchronization that means

[06:26:04 - 06:26:09]
whatever message I want to pass okay so

[06:26:07 - 06:26:11]
it will go to my telegram B okay this is

[06:26:09 - 06:26:12]
called actually synchronization so it

[06:26:11 - 06:26:14]
will be connected okay it should be

[06:26:12 - 06:26:15]
connected that means this is the

[06:26:14 - 06:26:18]
authentication code okay with your

[06:26:15 - 06:26:21]
telegram I hope it's is clear now fine

[06:26:18 - 06:26:22]
then after that I think you saw they

[06:26:21 - 06:26:24]
they have written different different

[06:26:22 - 06:26:26]
function with the help of asence and Aid

[06:26:24 - 06:26:28]
keyword okay asence and Aid keyword so

[06:26:26 - 06:26:30]
what is the use of asence and Aid uh see

[06:26:28 - 06:26:31]
uh this is the concept of python if you

[06:26:30 - 06:26:34]
don't know about python so what you can

[06:26:31 - 06:26:36]
do you can check out our YouTube channel

[06:26:34 - 06:26:38]
okay okay so there actually I already uh

[06:26:36 - 06:26:39]
let me show you so guys you can see this

[06:26:38 - 06:26:42]
is our YouTube channel so there I

[06:26:39 - 06:26:44]
already created uh like python playlist

[06:26:42 - 06:26:45]
so there I already covered each and

[06:26:44 - 06:26:48]
every topic okay you need you need to

[06:26:45 - 06:26:49]
master inside python so there I already

[06:26:48 - 06:26:51]
explained what is asence and Aid okay so

[06:26:49 - 06:26:53]
you can check those video so let me tell

[06:26:51 - 06:26:55]
you as a high level what is Asin and AIT

[06:26:53 - 06:26:58]
see what this Asin and AIT will do it

[06:26:55 - 06:27:00]
will keep on sensing okay it will keep

[06:26:58 - 06:27:02]
on sensing your update that means if you

[06:27:00 - 06:27:03]
uh update anything okay if you update

[06:27:02 - 06:27:05]
anything in the code base it will

[06:27:03 - 06:27:07]
automatically get that update okay that

[06:27:05 - 06:27:09]
means what happens actually let's say

[06:27:07 - 06:27:11]
whenever U you update anything in your

[06:27:09 - 06:27:12]
code so you don't need to send the

[06:27:11 - 06:27:14]
request okay you don't need to save and

[06:27:12 - 06:27:16]
send the request it will automatically

[06:27:14 - 06:27:18]
sense that it will automatically sense

[06:27:16 - 06:27:20]
that and it will send the update okay so

[06:27:18 - 06:27:22]
this is the work of asence and a and if

[06:27:20 - 06:27:25]
you want to use AI you have to use this

[06:27:22 - 06:27:27]
particular keyword okay ass and Abit

[06:27:25 - 06:27:30]
with a function so I already created two

[06:27:27 - 06:27:32]
function let me show you so I'll tell

[06:27:30 - 06:27:34]
you what this function will do so this

[06:27:32 - 06:27:37]
is the first function guys so the

[06:27:34 - 06:27:40]
function name I have given command start

[06:27:37 - 06:27:42]
handle okay I think you saw whenever I

[06:27:40 - 06:27:44]
started my telegram board okay whenever

[06:27:42 - 06:27:46]
I started my telegram bot so there was a

[06:27:44 - 06:27:48]
start button see I given SL start

[06:27:46 - 06:27:50]
whenever I will give the SL start my bot

[06:27:48 - 06:27:53]
will start okay my bot will start see if

[06:27:50 - 06:27:57]
I show you the bot father if I give SL

[06:27:53 - 06:27:58]
start see bot father started and it has

[06:27:57 - 06:28:00]
given me all the suggestion actually I

[06:27:58 - 06:28:02]
can perform here so this kinds of

[06:28:00 - 06:28:04]
functionality I want to implement even

[06:28:02 - 06:28:05]
and if I want to implement so for this I

[06:28:04 - 06:28:07]
have to create a function and with the

[06:28:05 - 06:28:09]
help of asence and a keyword I have to

[06:28:07 - 06:28:11]
give here inside the function now you

[06:28:09 - 06:28:13]
have to create a decorator uh your

[06:28:11 - 06:28:14]
dispatcher decorator now inside that

[06:28:13 - 06:28:16]
there is a function called message

[06:28:14 - 06:28:17]
Handler inside that you have to pass the

[06:28:16 - 06:28:19]
command like what kinds of command you

[06:28:17 - 06:28:23]
want to pass let's see if I give SL help

[06:28:19 - 06:28:26]
as as well in my bot father slel so it

[06:28:23 - 06:28:27]
will give me the uh menu okay what are

[06:28:26 - 06:28:29]
the things I can perform with the help

[06:28:27 - 06:28:31]
of Bot father that means if anyone using

[06:28:29 - 06:28:33]
my bot for the first time they can get

[06:28:31 - 06:28:36]
the information with the help of start

[06:28:33 - 06:28:38]
and help okay SL so I I want to give two

[06:28:36 - 06:28:40]
commands SL start and SL help if if you

[06:28:38 - 06:28:42]
are passing this one so what your Bot

[06:28:40 - 06:28:45]
will do so what your Bot will do your

[06:28:42 - 06:28:47]
Bot will reply hi I'm a eobot powered by

[06:28:45 - 06:28:49]
AOG so this message actually it will

[06:28:47 - 06:28:50]
give now here you can give any kinds of

[06:28:49 - 06:28:52]
messes okay you can give any kinds of

[06:28:50 - 06:28:54]
message I have given this message now

[06:28:52 - 06:28:56]
let me show you how it will work so for

[06:28:54 - 06:28:58]
this what I have to do I have to start

[06:28:56 - 06:29:01]
my bot so for this this is the syntax

[06:28:58 - 06:29:03]
you have to write so inside this keyword

[06:29:01 - 06:29:05]
you have to write executor start pulling

[06:29:03 - 06:29:06]
then you have to give the dispatcher

[06:29:05 - 06:29:08]
object and as well as the you have to

[06:29:06 - 06:29:10]
give one parameter skip updates is equal

[06:29:08 - 06:29:12]
to true what is Skip update is equal to

[06:29:10 - 06:29:13]
true I'll tell you later on as of now

[06:29:12 - 06:29:15]
just try to remember this parameter you

[06:29:13 - 06:29:16]
have to give okay if you check the

[06:29:15 - 06:29:19]
documentation they are also giving the

[06:29:16 - 06:29:24]
same thing now let me save and now see

[06:29:19 - 06:29:24]
if I execute my program my

[06:29:26 - 06:29:33]
eobot see so it has connected now see it

[06:29:30 - 06:29:35]
has start pulling now if I go to my bot

[06:29:33 - 06:29:38]
let's say this is my bot now see if I

[06:29:35 - 06:29:41]
give let's say SL start

[06:29:38 - 06:29:43]
here so it has given me hi I'm eobot

[06:29:41 - 06:29:46]
Power by aam now if I give let's say

[06:29:43 - 06:29:47]
slash help it will give you the same

[06:29:46 - 06:29:49]
thing because you have mentioned two

[06:29:47 - 06:29:51]
command there I think remember you have

[06:29:49 - 06:29:53]
mentioned two command never from that if

[06:29:51 - 06:29:56]
you give any commment let's say slash

[06:29:53 - 06:29:58]
hello it's not working if you give any

[06:29:56 - 06:30:01]
other message also it's not working okay

[06:29:58 - 06:30:03]
that means it will only work whenever it

[06:30:01 - 06:30:05]
will get this two command and here you

[06:30:03 - 06:30:08]
can pass any sub masses okay I have

[06:30:05 - 06:30:10]
given powered by aam or anything you can

[06:30:08 - 06:30:12]
let's say powered by buy here you can

[06:30:10 - 06:30:14]
give my name so once you changed

[06:30:12 - 06:30:17]
anything just try to reexecute the code

[06:30:14 - 06:30:20]
so I'll just stop the execution with the

[06:30:17 - 06:30:23]
help of contrl C now if I reexecute

[06:30:20 - 06:30:26]
now again I will go to my Telegram and

[06:30:23 - 06:30:29]
now if I give let's say slash help now

[06:30:26 - 06:30:31]
see it will give me hi ma'am eobot

[06:30:29 - 06:30:34]
powered by buy okay I hope it is clear

[06:30:31 - 06:30:35]
now but see it is not able to handle my

[06:30:34 - 06:30:37]
casual response okay let's say if I'm

[06:30:35 - 06:30:40]
giving any other message let's say hi

[06:30:37 - 06:30:41]
hello okay hi hello whatever it's not

[06:30:40 - 06:30:43]
giving me the response because I have to

[06:30:41 - 06:30:44]
create another function for this let me

[06:30:43 - 06:30:46]
show you so here I will create a

[06:30:44 - 06:30:48]
function called Eco that means it will

[06:30:46 - 06:30:50]
give me the same message again and again

[06:30:48 - 06:30:52]
okay so this is the E Eco function and

[06:30:50 - 06:30:54]
see I'm using the same syntax only

[06:30:52 - 06:30:56]
message hander now see here I'm not

[06:30:54 - 06:30:57]
providing any kind of command I'm not

[06:30:56 - 06:30:58]
providing any kind of command because

[06:30:57 - 06:31:00]
see whenever I'm giving my casual

[06:30:58 - 06:31:01]
message this is not a command Okay so

[06:31:00 - 06:31:03]
that's why you don't need to mention the

[06:31:01 - 06:31:05]
command that means whatever message user

[06:31:03 - 06:31:07]
will give that message actually it will

[06:31:05 - 06:31:09]
send okay it will show you as an output

[06:31:07 - 06:31:11]
you can see with the help of AIT now let

[06:31:09 - 06:31:14]
me save and again I have to re-execute

[06:31:11 - 06:31:14]
let me stop the

[06:31:14 - 06:31:20]
execution now reexecute my code now if I

[06:31:18 - 06:31:23]
go to my telegram now let's say if I

[06:31:20 - 06:31:25]
just write High it will give me high if

[06:31:23 - 06:31:28]
I write hello it will give me hello if I

[06:31:25 - 06:31:30]
write let's say I am buy it will also

[06:31:28 - 06:31:32]
give me I'm buy because it's a EOB bot

[06:31:30 - 06:31:35]
we have created that means I'm

[06:31:32 - 06:31:36]
successfully able to connect with my bot

[06:31:35 - 06:31:37]
the bot actually I have created in my

[06:31:36 - 06:31:40]
telegram that means telegram collection

[06:31:37 - 06:31:42]
is completed okay telegram connection is

[06:31:40 - 06:31:43]
completed there is no issue that means

[06:31:42 - 06:31:46]
we are able to communicate with the

[06:31:43 - 06:31:47]
front end now we have to make another

[06:31:46 - 06:31:50]
functionality that means back end API

[06:31:47 - 06:31:52]
that means we will be using open API uh

[06:31:50 - 06:31:53]
to uh let's say process the response

[06:31:52 - 06:31:56]
sorry process the question whatever user

[06:31:53 - 06:31:58]
is asking we'll be taking the help from

[06:31:56 - 06:31:59]
the llm llm will give the response and

[06:31:58 - 06:32:01]
this response I'll will be sending to

[06:31:59 - 06:32:03]
the front end again okay so now let's

[06:32:01 - 06:32:04]
create our actual application so what I

[06:32:03 - 06:32:07]
will do

[06:32:04 - 06:32:10]
uh outside of resarch I'll create a file

[06:32:07 - 06:32:14]
I'll name it as let's say main

[06:32:10 - 06:32:16]
dot uh Pi okay main. Pi inside that I'll

[06:32:14 - 06:32:19]
be writing all the code so what I can do

[06:32:16 - 06:32:20]
I can import all the necessary Library

[06:32:19 - 06:32:23]
again you can see have imported all the

[06:32:20 - 06:32:25]
library even I also imported here as

[06:32:23 - 06:32:26]
well okay apart from that I'm also

[06:32:25 - 06:32:28]
importing openi as well as the system

[06:32:26 - 06:32:30]
package okay this is the idea now see

[06:32:28 - 06:32:33]
this application I'll be creating little

[06:32:30 - 06:32:36]
bit advanc because if I show you my chat

[06:32:33 - 06:32:38]
jpt now so let's say this is my chat GPT

[06:32:36 - 06:32:41]
let's say if I give any message to the

[06:32:38 - 06:32:49]
chat gbt let's say

[06:32:41 - 06:32:49]
I need a python code to add two

[06:32:52 - 06:32:57]
numbers sorry I think my prompt is

[06:32:54 - 06:33:01]
incorrect it should be

[06:32:57 - 06:33:04]
add again I can give the prompt I need a

[06:33:01 - 06:33:07]
python code to add two numbers okay now

[06:33:04 - 06:33:09]
I think it is perfect now see it is

[06:33:07 - 06:33:11]
giving me the code okay but see it is

[06:33:09 - 06:33:12]
giving me with the function but I don't

[06:33:11 - 06:33:15]
need the function what I can give I can

[06:33:12 - 06:33:19]
give uh

[06:33:15 - 06:33:20]
without functions okay now see I just

[06:33:19 - 06:33:22]
given without function it will

[06:33:20 - 06:33:24]
automatically remember I'm asking this

[06:33:22 - 06:33:25]
particular response okay it has

[06:33:24 - 06:33:28]
remembered okay it has remembered my

[06:33:25 - 06:33:30]
previous input so this is actually using

[06:33:28 - 06:33:31]
one memory okay temporary memory so I

[06:33:30 - 06:33:34]
also want to implement this kinds of

[06:33:31 - 06:33:36]
temporary memory inside my chart B so

[06:33:34 - 06:33:38]
for this what I will do I'll just write

[06:33:36 - 06:33:40]
a class here I'll just name it as

[06:33:38 - 06:33:42]
reference okay

[06:33:40 - 06:33:46]
reference so inside that what what I

[06:33:42 - 06:33:48]
will do I'll just write a Constructor

[06:33:46 - 06:33:51]
and this will and it will return

[06:33:48 - 06:33:54]
actually none okay so inside that I'll

[06:33:51 - 06:33:57]
just write self dot response and it

[06:33:54 - 06:33:58]
should be empty initially okay that

[06:33:57 - 06:34:00]
means as of now let's consider this is

[06:33:58 - 06:34:02]
my empty memory okay this is my empty

[06:34:00 - 06:34:06]
memory that means whatever question I'll

[06:34:02 - 06:34:07]
be asking as a uh like as a temporary

[06:34:06 - 06:34:09]
memory that question actually I'll be

[06:34:07 - 06:34:11]
saving here so that if I want to ask any

[06:34:09 - 06:34:13]
new question my previous question my

[06:34:11 - 06:34:14]
model will try to understand okay it

[06:34:13 - 06:34:17]
will try to remember now here you can

[06:34:14 - 06:34:18]
also pass the doc string so let's say

[06:34:17 - 06:34:21]
this is

[06:34:18 - 06:34:23]
my uh class I have written to store

[06:34:21 - 06:34:26]
previously response from the chat GPT

[06:34:23 - 06:34:30]
API okay you can also give open

[06:34:26 - 06:34:32]
API opena API okay this is the idea now

[06:34:30 - 06:34:37]
let me uh load my open API key as well

[06:34:32 - 06:34:39]
as my uh um this uh telegram bot token

[06:34:37 - 06:34:41]
so first of all I will load my open IP

[06:34:39 - 06:34:45]
key and I'm setting my open I key then I

[06:34:41 - 06:34:45]
will also load the telegram bot

[06:34:46 - 06:34:50]
token okay this is my telegram bot token

[06:34:48 - 06:34:54]
fine then let's initialize this

[06:34:50 - 06:34:57]
reference class so here I can initialize

[06:34:54 - 06:35:01]
I'll just write reference is equal to my

[06:34:57 - 06:35:03]
reference then I'm going to uh Define my

[06:35:01 - 06:35:06]
model name let say which model I want to

[06:35:03 - 06:35:09]
use so

[06:35:06 - 06:35:13]
model underscore name is equal to let's

[06:35:09 - 06:35:15]
say I want to use GPT 3.5 tar model if

[06:35:13 - 06:35:18]
you go to the openi

[06:35:15 - 06:35:21]
platform okay if you go to the

[06:35:18 - 06:35:21]
openi openi

[06:35:23 - 06:35:27]
models see here is the different

[06:35:25 - 06:35:31]
different model and I want to use

[06:35:27 - 06:35:33]
this uh 3.5 series actually CBO model

[06:35:31 - 06:35:35]
okay this model actually I'm using right

[06:35:33 - 06:35:37]
now fine now same way I have to

[06:35:35 - 06:35:39]
initialize my dispatcher as well as the

[06:35:37 - 06:35:42]
bot because it will

[06:35:39 - 06:35:45]
authenticate uh with my

[06:35:42 - 06:35:47]
telegram the same code guys from my

[06:35:45 - 06:35:49]
previous uh let's say uh file and copy

[06:35:47 - 06:35:51]
pasting okay I think you

[06:35:49 - 06:35:53]
remember so we are initializing our bot

[06:35:51 - 06:35:55]
and dispatcher so here the first thing I

[06:35:53 - 06:35:57]
want to create a function so this

[06:35:55 - 06:36:00]
function actually will do the welcome

[06:35:57 - 06:36:02]
okay so if you give let's say start uh

[06:36:00 - 06:36:03]
start command it will welcome you so

[06:36:02 - 06:36:05]
this is the function I've written guys

[06:36:03 - 06:36:08]
you can see simple function using using

[06:36:05 - 06:36:09]
the same concept okay same concept so

[06:36:08 - 06:36:12]
this is the function dispatcher message

[06:36:09 - 06:36:13]
Handler and here is the command only

[06:36:12 - 06:36:16]
start okay if you give start command it

[06:36:13 - 06:36:18]
will give you hi I'm a tbot created by

[06:36:16 - 06:36:19]
buy how I can assist you okay this is

[06:36:18 - 06:36:21]
the message actually it will show you

[06:36:19 - 06:36:23]
that's it now if you want to

[06:36:21 - 06:36:27]
execute you can simply

[06:36:23 - 06:36:30]
copy this line and here you can past

[06:36:27 - 06:36:31]
it that's it okay now it's a dispatcher

[06:36:30 - 06:36:35]
object

[06:36:31 - 06:36:37]
DP previously WR as a short form but now

[06:36:35 - 06:36:40]
what I did I just written full full name

[06:36:37 - 06:36:43]
okay this is the idea now let me execute

[06:36:40 - 06:36:45]
and let me show you so I'll open up my

[06:36:43 - 06:36:48]
terminal let me stop the

[06:36:45 - 06:36:49]
execution now let's say if I execute the

[06:36:48 - 06:36:53]
file right now now I need to execute my

[06:36:49 - 06:36:56]
main. Pi file so

[06:36:53 - 06:37:00]
clear

[06:36:56 - 06:37:00]
python main.

[06:37:00 - 06:37:06]
by now see if I open up my bot and if I

[06:37:04 - 06:37:09]
give SL start right

[06:37:06 - 06:37:10]
now so it is giving hi I a Teleport

[06:37:09 - 06:37:12]
created by papy how I can assist you

[06:37:10 - 06:37:14]
that means it is working fine now let me

[06:37:12 - 06:37:18]
stop the

[06:37:14 - 06:37:20]
execution H great now I also want to

[06:37:18 - 06:37:22]
create a help our function that means I

[06:37:20 - 06:37:25]
showed you now if I go to my B father

[06:37:22 - 06:37:26]
and if I give SL help so it will give me

[06:37:25 - 06:37:28]
all the Manu actually I want to part

[06:37:26 - 06:37:30]
from here so I also want to give one

[06:37:28 - 06:37:32]
manual function in my bot so for this I

[06:37:30 - 06:37:35]
have created a function and I named it

[06:37:32 - 06:37:37]
as a help

[06:37:35 - 06:37:39]
see this is the function so it will take

[06:37:37 - 06:37:41]
the help command after that it will show

[06:37:39 - 06:37:43]
you this message hi there I'm a CH GPT

[06:37:41 - 06:37:46]
telegram or I can write I a telegram

[06:37:43 - 06:37:47]
board okay created byy please follow

[06:37:46 - 06:37:49]
this command start to start the

[06:37:47 - 06:37:52]
conversation clear to clear the past

[06:37:49 - 06:37:54]
conversation and help to get the help

[06:37:52 - 06:37:57]
menu okay I hope this helps now it will

[06:37:54 - 06:37:59]
give you this uh this actually menu okay

[06:37:57 - 06:38:01]
now see here I've written clear SL clear

[06:37:59 - 06:38:03]
to pre like clear the previous

[06:38:01 - 06:38:04]
conversation now let's say uh if you're

[06:38:03 - 06:38:06]
saving any conversation and if you want

[06:38:04 - 06:38:08]
to clear it so you can use the clear

[06:38:06 - 06:38:11]
function for this so what I will do I'll

[06:38:08 - 06:38:13]
just write a function named

[06:38:11 - 06:38:15]
clear so here I can

[06:38:13 - 06:38:18]
write so it will just do the clear

[06:38:15 - 06:38:20]
operation on the previous conversation

[06:38:18 - 06:38:22]
see I think you remember we initialized

[06:38:20 - 06:38:24]
our reference here so inside reference

[06:38:22 - 06:38:26]
we're having one variable class variable

[06:38:24 - 06:38:28]
called reference so here I'm doing the

[06:38:26 - 06:38:30]
clear operation see reference. reference

[06:38:28 - 06:38:31]
I'm making as empty that means whenever

[06:38:30 - 06:38:33]
I I will save something okay inside the

[06:38:31 - 06:38:35]
variable and if I call the Clear C past

[06:38:33 - 06:38:37]
function it will clear that particular

[06:38:35 - 06:38:38]
response okay this is the idea if you go

[06:38:37 - 06:38:41]
to the chat GPT as well and if you write

[06:38:38 - 06:38:43]
forget my past prompt it will forget

[06:38:41 - 06:38:44]
that okay it will remove that memory so

[06:38:43 - 06:38:46]
same way I'm creating the same

[06:38:44 - 06:38:50]
functionality here and to execute this

[06:38:46 - 06:38:53]
clear past so I will pass one command so

[06:38:50 - 06:38:54]
I'll just write clear this command clear

[06:38:53 - 06:38:56]
so it will automatically do the clear

[06:38:54 - 06:38:58]
operations so for this I will be writing

[06:38:56 - 06:39:01]
another function

[06:38:58 - 06:39:03]
here so function name is clear and it

[06:39:01 - 06:39:04]
will take the clear command and it will

[06:39:03 - 06:39:06]
call this particular function you can

[06:39:04 - 06:39:08]
see clear past okay then it will give

[06:39:06 - 06:39:09]
you message I have cleared the past

[06:39:08 - 06:39:12]
conversation as the context okay this is

[06:39:09 - 06:39:14]
the idea now I have to write my main

[06:39:12 - 06:39:17]
code that means my uh main brain

[06:39:14 - 06:39:20]
functionality of my application so for

[06:39:17 - 06:39:22]
this I already prepared the open code

[06:39:20 - 06:39:24]
see this is the openi code and this is

[06:39:22 - 06:39:26]
nothing new guys this is nothing new

[06:39:24 - 06:39:28]
just try to see here I'm using chat

[06:39:26 - 06:39:30]
completion API okay now let me check

[06:39:28 - 06:39:32]
everything is fine or not now you can

[06:39:30 - 06:39:34]
see guys everything is fine uh so I'm

[06:39:32 - 06:39:35]
creating the chat completion API

[06:39:34 - 06:39:37]
and role assistant content I'm giving

[06:39:35 - 06:39:40]
because you can see reference. response

[06:39:37 - 06:39:43]
first of all it will check this response

[06:39:40 - 06:39:45]
okay this response if there is any

[06:39:43 - 06:39:48]
response or not okay if not that means

[06:39:45 - 06:39:49]
it will act like a you are using for the

[06:39:48 - 06:39:53]
first time that means there is no

[06:39:49 - 06:39:55]
previous context but if you are starting

[06:39:53 - 06:39:58]
for the second time let's say I think

[06:39:55 - 06:40:00]
remember here in the chat GPT I have

[06:39:58 - 06:40:01]
given a prompt I need a python code to

[06:40:00 - 06:40:03]
add two numbers that means one response

[06:40:01 - 06:40:05]
it will remember and when whenever I'm

[06:40:03 - 06:40:07]
asking the second second question it

[06:40:05 - 06:40:08]
will refer my previous let's say

[06:40:07 - 06:40:10]
question I have asked okay the same

[06:40:08 - 06:40:11]
thing actually happening here that means

[06:40:10 - 06:40:13]
it will first of all check whether you

[06:40:11 - 06:40:14]
are having previous response or not if

[06:40:13 - 06:40:17]
not that means it's a completely new

[06:40:14 - 06:40:20]
rule otherwise uh it will refer my

[06:40:17 - 06:40:22]
previous let's say response okay now

[06:40:20 - 06:40:23]
this is the user message then it will

[06:40:22 - 06:40:26]
give you the response this response

[06:40:23 - 06:40:29]
actually I'm uh only getting the content

[06:40:26 - 06:40:31]
and I'm printing in the terminal and I'm

[06:40:29 - 06:40:32]
also printing in my user interface that

[06:40:31 - 06:40:35]
means in my Telegram and it is also

[06:40:32 - 06:40:36]
updating the response okay you can see

[06:40:35 - 06:40:39]
this reference response is also getting

[06:40:36 - 06:40:41]
updated okay now if you call this clear

[06:40:39 - 06:40:42]
P it will also do the clear operation

[06:40:41 - 06:40:44]
it's a simple code I have written now

[06:40:42 - 06:40:46]
let me show you how it will work so I'll

[06:40:44 - 06:40:48]
open up my terminal now let me execute

[06:40:46 - 06:40:48]
my

[06:40:49 - 06:40:56]
app now if I open my bot let's say if I

[06:40:54 - 06:40:59]
just write

[06:40:56 - 06:41:02]
uh uh Slash start I think this command I

[06:40:59 - 06:41:05]
already showed you now SL start SL help

[06:41:02 - 06:41:07]
it is working F sorry SL

[06:41:05 - 06:41:10]
start okay now see if I give any casual

[06:41:07 - 06:41:10]
message let's say

[06:41:10 - 06:41:16]
hi see it is giving me hello how I can

[06:41:13 - 06:41:19]
assist you let's say if I give

[06:41:16 - 06:41:23]
hello how are you doing today let's say

[06:41:19 - 06:41:23]
I'll ask what

[06:41:23 - 06:41:26]
is

[06:41:26 - 06:41:30]
python this is telling python is a high

[06:41:28 - 06:41:32]
level programming language okay now I

[06:41:30 - 06:41:35]
can also give the same promt let's say

[06:41:32 - 06:41:35]
give me

[06:41:35 - 06:41:39]
a

[06:41:36 - 06:41:41]
python

[06:41:39 - 06:41:46]
code to

[06:41:41 - 06:41:49]
add sorry code to add two

[06:41:46 - 06:41:51]
numbers see this is the code I got now

[06:41:49 - 06:41:55]
I'll ask give

[06:41:51 - 06:41:55]
me as a

[06:41:58 - 06:42:02]
function now see that means it is

[06:42:00 - 06:42:05]
remembering my previous context now if I

[06:42:02 - 06:42:06]
give slash clear

[06:42:05 - 06:42:10]
I have cleared all the past conversation

[06:42:06 - 06:42:14]
okay now if I give the same message give

[06:42:10 - 06:42:16]
me as a function now see here it is

[06:42:14 - 06:42:18]
giving me the function okay it is giving

[06:42:16 - 06:42:20]
me the function but not these kinds of

[06:42:18 - 06:42:23]
function that means my previous uh let's

[06:42:20 - 06:42:25]
say question function okay that's why I

[06:42:23 - 06:42:28]
uh created this clear okay clear

[06:42:25 - 06:42:29]
functionality as well okay now you can

[06:42:28 - 06:42:31]
ask any kinds of question okay whatever

[06:42:29 - 06:42:32]
question you can ask in your chat JB the

[06:42:31 - 06:42:35]
same question you can also ask here okay

[06:42:32 - 06:42:36]
there no issue so that means we have

[06:42:35 - 06:42:38]
created one beautiful application now

[06:42:36 - 06:42:40]
one thing I want to show you this is

[06:42:38 - 06:42:42]
keep update is equal to True let's say

[06:42:40 - 06:42:45]
if it is true what will happen let's say

[06:42:42 - 06:42:49]
if my application is offline right now

[06:42:45 - 06:42:51]
let's say I'll stop the execution let's

[06:42:49 - 06:42:52]
say it offline now if I give any message

[06:42:51 - 06:42:54]
let's say

[06:42:52 - 06:42:56]
hello now see it is offline okay it's

[06:42:54 - 06:42:58]
not giving you any response but if it is

[06:42:56 - 06:43:00]
online let's say if I execute the

[06:42:58 - 06:43:01]
program right now now let's say my

[06:43:00 - 06:43:03]
application is

[06:43:01 - 06:43:05]
online okay now see still it is not

[06:43:03 - 06:43:07]
giving me the response still it is not

[06:43:05 - 06:43:08]
giving me the response because let's say

[06:43:07 - 06:43:10]
sometimes it's possible your application

[06:43:08 - 06:43:12]
will go offline and if user is giving

[06:43:10 - 06:43:14]
any question when it is online again it

[06:43:12 - 06:43:16]
should return the answer right but it's

[06:43:14 - 06:43:19]
not giving so for this what I can do I

[06:43:16 - 06:43:21]
can stop the

[06:43:19 - 06:43:24]
execution and this parameter I can make

[06:43:21 - 06:43:24]
it as

[06:43:24 - 06:43:30]
false okay now let's save my application

[06:43:27 - 06:43:30]
is offline let's say

[06:43:31 - 06:43:38]
hello now if if I reexecute my

[06:43:36 - 06:43:41]
program see it will automatically take

[06:43:38 - 06:43:43]
the hello okay hello message whatever

[06:43:41 - 06:43:45]
you asked during offline now see it is

[06:43:43 - 06:43:47]
giving you the response okay so this is

[06:43:45 - 06:43:49]
one of the amazing parameter you can

[06:43:47 - 06:43:51]
play with if you want to let's say keep

[06:43:49 - 06:43:52]
your application offline but if you want

[06:43:51 - 06:43:54]
to reply it okay when you are online you

[06:43:52 - 06:43:57]
can update this particular parameter

[06:43:54 - 06:43:59]
fine so yes guys this is the um like

[06:43:57 - 06:44:01]
chat bot we have implemented uh you can

[06:43:59 - 06:44:03]
also share this uh bot with your friends

[06:44:01 - 06:44:05]
and family so what you need to do you

[06:44:03 - 06:44:06]
just only give uh need to give the

[06:44:05 - 06:44:08]
username let's say this is your username

[06:44:06 - 06:44:10]
of your Bot now if they startch with

[06:44:08 - 06:44:12]
this username they will be able to

[06:44:10 - 06:44:13]
access your Bot okay and if they're

[06:44:12 - 06:44:15]
asking any question they will also get

[06:44:13 - 06:44:17]
the response okay that's how just try to

[06:44:15 - 06:44:18]
ask your friend to use your chat bot

[06:44:17 - 06:44:20]
okay you have developed with the help of

[06:44:18 - 06:44:22]
open so in this video actually I will

[06:44:20 - 06:44:25]
show you like how you can f tune your uh

[06:44:22 - 06:44:27]
gpt3 model okay with your custom data so

[06:44:25 - 06:44:29]
basically what I'm going to do here so

[06:44:27 - 06:44:31]
basically here we'll be funing add

[06:44:29 - 06:44:34]
classifier okay to distinguish between

[06:44:31 - 06:44:35]
two sports like basball and hockey so

[06:44:34 - 06:44:38]
basically we are going to perform one

[06:44:35 - 06:44:41]
classification task here okay so here I

[06:44:38 - 06:44:43]
will uh like take one sports data and

[06:44:41 - 06:44:46]
with the sport data okay I will uh train

[06:44:43 - 06:44:48]
my uh gpt3 model which is nothing but

[06:44:46 - 06:44:51]
Ada okay adaa classifier I think you

[06:44:48 - 06:44:52]
already know it has various model okay

[06:44:51 - 06:44:55]
if you click on the model so ad is one

[06:44:52 - 06:44:59]
of the one of them okay so uh let's

[06:44:55 - 06:44:59]
install first of all open AI

[06:45:03 - 06:45:06]
and uh here you don't have to worry

[06:45:04 - 06:45:09]
about your system configuration because

[06:45:06 - 06:45:11]
here you are using uh open API okay so

[06:45:09 - 06:45:13]
all the training and all the you can say

[06:45:11 - 06:45:15]
computation everything will be performed

[06:45:13 - 06:45:18]
on the uh on their website itself okay

[06:45:15 - 06:45:20]
on their uh you can say engine itself

[06:45:18 - 06:45:22]
okay so you don't have to worry about so

[06:45:20 - 06:45:24]
you just need the API key and just try

[06:45:22 - 06:45:26]
to open up your Google collab okay and

[06:45:24 - 06:45:28]
try to start the training that's it so

[06:45:26 - 06:45:30]
because see uh it has like millions of

[06:45:28 - 06:45:32]
parameters so it's not possible to train

[06:45:30 - 06:45:35]
in our system okay so that's why they

[06:45:32 - 06:45:37]
have proposed uh API okay gp3 API

[06:45:35 - 06:45:40]
instead of giving the raw model to us

[06:45:37 - 06:45:42]
okay then uh this command actually you

[06:45:40 - 06:45:44]
can actually upgrade your openi so let's

[06:45:42 - 06:45:44]
upgrade it

[06:45:45 - 06:45:50]
also and here I will uh import my data

[06:45:48 - 06:45:52]
so this data actually is already

[06:45:50 - 06:45:54]
available inside psyit learn data set

[06:45:52 - 06:45:58]
okay like 20 News Group data set the

[06:45:54 - 06:45:59]
name of the data set is okay so here

[06:45:58 - 06:46:03]
here you have two categories one is like

[06:45:59 - 06:46:03]
baseball and hockey

[06:46:04 - 06:46:08]
now if you want to see the example the

[06:46:06 - 06:46:11]
first example so this is the data

[06:46:08 - 06:46:14]
basically it kinds of email okay and

[06:46:11 - 06:46:16]
here you have the news sports data okay

[06:46:14 - 06:46:19]
uh if you want to see the label Target

[06:46:16 - 06:46:22]
so you have uh sports baseball and hocky

[06:46:19 - 06:46:24]
okay now if you want to see the first

[06:46:22 - 06:46:26]
one see the first example I shown here

[06:46:24 - 06:46:28]
first data set with respect to that I'm

[06:46:26 - 06:46:31]
showing my um first Target okay which is

[06:46:28 - 06:46:33]
nothing but it's a b baseball okay now

[06:46:31 - 06:46:38]
if you want to also see the

[06:46:33 - 06:46:42]
count so you have total example uh

[06:46:38 - 06:46:45]
1,197 uh baseball has 597 okay example

[06:46:42 - 06:46:48]
and hcky has 6 600 so basically this

[06:46:45 - 06:46:49]
data is not imbalanced so it's fine now

[06:46:48 - 06:46:52]
inside data preparation first of all we

[06:46:49 - 06:46:53]
need to prepare the data so what kinds

[06:46:52 - 06:46:56]
of preparation we need to do here if you

[06:46:53 - 06:46:59]
see uh if I show you the target so it

[06:46:56 - 06:47:01]
has actually uh r. sport. baseball okay

[06:46:59 - 06:47:02]
so this is the additional information I

[06:47:01 - 06:47:03]
don't need okay so I need to suppress

[06:47:02 - 06:47:06]
that

[06:47:03 - 06:47:08]
so if you just run this

[06:47:06 - 06:47:10]
code so basically what it will do it

[06:47:08 - 06:47:12]
will take all the data okay and it will

[06:47:10 - 06:47:14]
create two columns one is like prompt

[06:47:12 - 06:47:17]
and completion okay so why I'm creating

[06:47:14 - 06:47:21]
prompt and completion because if you uh

[06:47:17 - 06:47:24]
go to documentation of U open a so here

[06:47:21 - 06:47:26]
is a uh uh section called fine tunes

[06:47:24 - 06:47:28]
okay just click on fine tunes so they

[06:47:26 - 06:47:32]
have given like how you can find Tunes

[06:47:28 - 06:47:35]
okay uh gpt3 model so here uh one thing

[06:47:32 - 06:47:35]
they have mentioned data

[06:47:37 - 06:47:43]
preparation I think uh here F tune guide

[06:47:41 - 06:47:45]
and if you just go

[06:47:43 - 06:47:47]
below prepare your data set okay so if

[06:47:45 - 06:47:50]
you just read read it okay if you just

[06:47:47 - 06:47:53]
read this uh okay entirely so you will

[06:47:50 - 06:47:55]
get to know you need prompt and

[06:47:53 - 06:47:58]
completion okay so that's why I have

[06:47:55 - 06:48:00]
given this name prompt and completion so

[06:47:58 - 06:48:01]
prompt is nothing but your data okay

[06:48:00 - 06:48:03]
your input data and completion is

[06:48:01 - 06:48:05]
nothing but your level okay so that's

[06:48:03 - 06:48:08]
actually you need to prepare the data so

[06:48:05 - 06:48:10]
once it is done now um you need to

[06:48:08 - 06:48:13]
convert them uh a file format called

[06:48:10 - 06:48:15]
jonl okay so this is the command just

[06:48:13 - 06:48:15]
run

[06:48:15 - 06:48:22]
it okay now let me show you what is jonl

[06:48:19 - 06:48:25]
okay so if you just refresh here and let

[06:48:22 - 06:48:29]
me download

[06:48:25 - 06:48:29]
it now if I open

[06:48:30 - 06:48:34]
it okay so this is the same data format

[06:48:33 - 06:48:39]
okay like this is your

[06:48:34 - 06:48:39]
prompt and at the last you have the

[06:48:42 - 06:48:46]
completion see this is the completion

[06:48:44 - 06:48:49]
okay and if you see this is the same

[06:48:46 - 06:48:51]
format if I come here this is the same

[06:48:49 - 06:48:54]
format okay so that that is why you need

[06:48:51 - 06:48:57]
to uh you can say convert your entire

[06:48:54 - 06:49:00]
data frame to jonl format okay is done

[06:48:57 - 06:49:03]
now openai has a data preparation Tool

[06:49:00 - 06:49:05]
uh so if you just call open a and from

[06:49:03 - 06:49:08]
Tool itself you just call prepared data

[06:49:05 - 06:49:09]
okay so it will actually uh uh I mean

[06:49:08 - 06:49:12]
prepare your data first of all it will

[06:49:09 - 06:49:15]
take this jonl okay see I'm just passing

[06:49:12 - 06:49:17]
Sports to jonl hypen Q it will take this

[06:49:15 - 06:49:19]
one and will do some analyzing okay if

[06:49:17 - 06:49:21]
something is okay wrong with your data

[06:49:19 - 06:49:25]
set it will throw error otherwise it

[06:49:21 - 06:49:26]
will actually uh uh fix it okay so see I

[06:49:25 - 06:49:28]
have run this command so it has

[06:49:26 - 06:49:31]
generated two file which is nothing but

[06:49:28 - 06:49:33]
isort to prepare train Zess validation

[06:49:31 - 06:49:35]
Zess okay so it is also it will also do

[06:49:33 - 06:49:37]
like Trend split okay you don't have to

[06:49:35 - 06:49:39]
do it separately okay so this thing

[06:49:37 - 06:49:41]
actually you need to run and here also

[06:49:39 - 06:49:43]
they have written okay they have their

[06:49:41 - 06:49:47]
own data preparation tool you need to

[06:49:43 - 06:49:49]
execute so whenever it is done now uh

[06:49:47 - 06:49:51]
this is the section actually you can uh

[06:49:49 - 06:49:53]
execute okay to F tune your uh you can

[06:49:51 - 06:49:55]
say model okay this is the training

[06:49:53 - 06:49:56]
command actually so here you need to

[06:49:55 - 06:49:59]
change this API key because this is my

[06:49:56 - 06:50:01]
older API key so I will what I will do I

[06:49:59 - 06:50:03]
will change it uh with with the newer

[06:50:01 - 06:50:06]
one

[06:50:03 - 06:50:09]
you can also read it from uh secret

[06:50:06 - 06:50:11]
okay uh but I will uh give it here just

[06:50:09 - 06:50:14]
for

[06:50:11 - 06:50:16]
Simplicity now here API find Tunes

[06:50:14 - 06:50:18]
create okay now here actually you need

[06:50:16 - 06:50:20]
to give your data path okay so this is

[06:50:18 - 06:50:22]
my train data path and this is my

[06:50:20 - 06:50:24]
validation data path but here one issue

[06:50:22 - 06:50:26]
actually I was having so I was uh trying

[06:50:24 - 06:50:28]
to actually uh execute this command

[06:50:26 - 06:50:31]
because here if you see if I show you my

[06:50:28 - 06:50:33]
model okay so find TS here I have like

[06:50:31 - 06:50:35]
already trained to model models okay

[06:50:33 - 06:50:37]
with the same data so here actually you

[06:50:35 - 06:50:39]
can't give the same ID again and again

[06:50:37 - 06:50:41]
okay if you give this same name so it

[06:50:39 - 06:50:43]
will create the same ID again and again

[06:50:41 - 06:50:46]
okay and it will give you uh error like

[06:50:43 - 06:50:49]
just give a new ID okay so that's why uh

[06:50:46 - 06:50:51]
if you have done training one time okay

[06:50:49 - 06:50:53]
you just change the data name otherwise

[06:50:51 - 06:50:55]
it's fine okay if you're doing it for

[06:50:53 - 06:50:57]
first time it's fine just keep it as it

[06:50:55 - 06:50:59]
is otherwise what you can do just rename

[06:50:57 - 06:51:04]
this name with a unique name so I'll

[06:50:59 - 06:51:04]
just rename so I'll just give Sports uh

[06:51:06 - 06:51:12]
222 okay because this name is already

[06:51:09 - 06:51:15]
present in my model so I that's why I'm

[06:51:12 - 06:51:18]
changing the name sport

[06:51:15 - 06:51:20]
222 okay similar wise just change it

[06:51:18 - 06:51:24]
also here Sports

[06:51:20 - 06:51:26]
22 this is your validation okay and

[06:51:24 - 06:51:28]
computation metrix uh okay everything

[06:51:26 - 06:51:30]
you providing and at the last you're

[06:51:28 - 06:51:33]
selecting the add model OKAY epox is not

[06:51:30 - 06:51:34]
required so it will basically

[06:51:33 - 06:51:36]
uh okay automatically observe whenever

[06:51:34 - 06:51:38]
your loss is not decreasing or accur is

[06:51:36 - 06:51:40]
not increasing it will stop the

[06:51:38 - 06:51:44]
execution okay so now everything is

[06:51:40 - 06:51:46]
prepared now just click on this one so

[06:51:44 - 06:51:50]
it will take the data and it will start

[06:51:46 - 06:51:50]
you can say training your okay it's

[06:51:52 - 06:51:59]
telling okay it's telling this data is

[06:51:54 - 06:51:59]
missing so let me do LS

[06:52:03 - 06:52:07]
okay so here one mistake I have done

[06:52:05 - 06:52:10]
here I have given one okay one won't be

[06:52:07 - 06:52:12]
there so just remove the

[06:52:10 - 06:52:15]
one and now I think everything is fine

[06:52:12 - 06:52:15]
now let me execute

[06:52:19 - 06:52:24]
again so guys uh actually uh training

[06:52:22 - 06:52:25]
takes a lots of time so uh what I'm

[06:52:24 - 06:52:27]
going to do I'm going to show you my

[06:52:25 - 06:52:29]
previous notebook okay I did the

[06:52:27 - 06:52:30]
training so basically whenever you will

[06:52:29 - 06:52:32]
click on the command so actually it will

[06:52:30 - 06:52:34]
start the training and it will start the

[06:52:32 - 06:52:37]
epox okay see this is the epox actually

[06:52:34 - 06:52:38]
it will be running okay and once uh your

[06:52:37 - 06:52:40]
training is completed it will save your

[06:52:38 - 06:52:42]
model okay it will save your model so

[06:52:40 - 06:52:44]
where you will get the model just come

[06:52:42 - 06:52:45]
here okay come here and here you need to

[06:52:44 - 06:52:48]
refresh this page

[06:52:45 - 06:52:50]
okay so if you just refresh this page

[06:52:48 - 06:52:52]
now if you just click on the model and

[06:52:50 - 06:52:54]
at the last there there would be a

[06:52:52 - 06:52:55]
section called fine tunes okay inside

[06:52:54 - 06:52:58]
fine tunes actually you will get your

[06:52:55 - 06:53:00]
model okay see I train add a model okay

[06:52:58 - 06:53:01]
and this is the ID okay it is the ID and

[06:53:00 - 06:53:03]
basically this is the date actually when

[06:53:01 - 06:53:05]
I train this model model okay so this

[06:53:03 - 06:53:06]
model actually you have to use okay

[06:53:05 - 06:53:08]
whenever you'll be doing the inferencing

[06:53:06 - 06:53:10]
so now how you can do the inferencing so

[06:53:08 - 06:53:14]
this is the code so basically you can

[06:53:10 - 06:53:16]
also uh like uh see the evolution Matrix

[06:53:14 - 06:53:19]
okay performance Matrix actually you can

[06:53:16 - 06:53:22]
U see okay uh you can also save it as a

[06:53:19 - 06:53:25]
result. CSV okay and here you can also

[06:53:22 - 06:53:29]
plot this uh accuracy score okay this is

[06:53:25 - 06:53:31]
the accuracy score and uh this is my

[06:53:29 - 06:53:35]
data okay this data set actually I'm

[06:53:31 - 06:53:36]
like taking one prompt okay and here

[06:53:35 - 06:53:38]
actually I'm doing the generation okay

[06:53:36 - 06:53:41]
basically I'm loading my model so why do

[06:53:38 - 06:53:43]
you need to give your model so let me

[06:53:41 - 06:53:46]
show

[06:53:43 - 06:53:47]
you yeah so here actually you need to

[06:53:46 - 06:53:49]
provide your model name okay the model

[06:53:47 - 06:53:53]
name actually you'll be training okay

[06:53:49 - 06:53:54]
here see I I have took this model okay

[06:53:53 - 06:53:57]
uh so this name actually you need to

[06:53:54 - 06:53:59]
copy and you need to paste it here okay

[06:53:57 - 06:54:01]
and it will load the model from the

[06:53:59 - 06:54:02]
opener itself okay and it will like uh

[06:54:01 - 06:54:04]
do the inference

[06:54:02 - 06:54:06]
see this is the score of your hockey and

[06:54:04 - 06:54:08]
baseball and after that if you want to

[06:54:06 - 06:54:11]
see okay this is the baseball and hockey

[06:54:08 - 06:54:14]
so that's actually you can uh okay see

[06:54:11 - 06:54:16]
see the example okay U like uh do the

[06:54:14 - 06:54:18]
inferencing so yes guys I think you got

[06:54:16 - 06:54:21]
it like how you can uh find tune your

[06:54:18 - 06:54:23]
openi uh like gpt3 model okay with your

[06:54:21 - 06:54:26]
custom data set and if you want to learn

[06:54:23 - 06:54:28]
more about fine tuning I will Su just

[06:54:26 - 06:54:29]
try to explore this U documentation it

[06:54:28 - 06:54:31]
is pretty good documentation just try to

[06:54:29 - 06:54:33]
read everything not only like uh

[06:54:31 - 06:54:35]
classific you can also do it from

[06:54:33 - 06:54:36]
summarization and other task okay for

[06:54:35 - 06:54:38]
that actually you need to prepare the

[06:54:36 - 06:54:40]
data like you need to learn how to

[06:54:38 - 06:54:42]
prepare the data okay so yes guys I

[06:54:40 - 06:54:44]
think you got it uhu this was all about

[06:54:42 - 06:54:46]
from this video and yeah that's it

[06:54:44 - 06:54:48]
actually you need to learn about open a

[06:54:46 - 06:54:50]
and uh like gpt3 okay so once you are

[06:54:48 - 06:54:53]
comfortable with this API I think you

[06:54:50 - 06:54:55]
can do anything okay so as I already

[06:54:53 - 06:54:56]
showed you the opena platform even I

[06:54:55 - 06:54:58]
already use different different model

[06:54:56 - 06:55:00]
Even in our previous video we also

[06:54:58 - 06:55:03]
implemented one projects called telegram

[06:55:00 - 06:55:06]
chatbot so here we'll be exploring

[06:55:03 - 06:55:08]
another actually variant of the model so

[06:55:06 - 06:55:09]
the model name is whisper so I think I

[06:55:08 - 06:55:11]
showed you the whisper let's say

[06:55:09 - 06:55:13]
introduction what is this whisper model

[06:55:11 - 06:55:16]
so let me show you again so if I go back

[06:55:13 - 06:55:19]
to my uh let's say openi platform so

[06:55:16 - 06:55:20]
here if you go to the model section and

[06:55:19 - 06:55:22]
uh if you just go below this is the

[06:55:20 - 06:55:24]
whisper model guys so let me open it up

[06:55:22 - 06:55:26]
so you can see whisper is a general

[06:55:24 - 06:55:29]
purpose speech recognization model it is

[06:55:26 - 06:55:32]
trained on a large data set of diverse

[06:55:29 - 06:55:34]
audio and it is also multitask model

[06:55:32 - 06:55:35]
that can perform multilingual speech

[06:55:34 - 06:55:37]
recognization as well as the speech

[06:55:35 - 06:55:40]
translation and language identification

[06:55:37 - 06:55:42]
okay so this is actually a speech based

[06:55:40 - 06:55:44]
model that means you can uh give any

[06:55:42 - 06:55:45]
kinds of speech or audio so it will give

[06:55:44 - 06:55:48]
you the transcript of that particular

[06:55:45 - 06:55:52]
audio so here uh what we'll be doing let

[06:55:48 - 06:55:53]
me show you the Entre diagram see here

[06:55:52 - 06:55:56]
we'll be implementing one audio

[06:55:53 - 06:55:59]
transcript translation let's say uh here

[06:55:56 - 06:56:02]
here I will pass one audio

[06:55:59 - 06:56:06]
file okay it can be MP3

[06:56:02 - 06:56:06]
or any other format you can

[06:56:06 - 06:56:11]
pass uh I'll will pass to the whisper

[06:56:14 - 06:56:22]
model okay and Whisper model will return

[06:56:18 - 06:56:22]
return uh transcript of this

[06:56:24 - 06:56:33]
audio okay transcript that means it is a

[06:56:30 - 06:56:36]
text the enter audio text actually it

[06:56:33 - 06:56:38]
will return then what I will do I will

[06:56:36 - 06:56:40]
use one um actually chat completion

[06:56:38 - 06:56:41]
model that means here I can use any

[06:56:40 - 06:56:47]
kinds of model let's say here you will

[06:56:41 - 06:56:47]
be using GPT okay gpt3 so I'll pass this

[06:56:53 - 06:57:01]
transcript to the gpt3 and here I will

[06:56:56 - 06:57:01]
provide a prompt uh Translate

[06:57:04 - 06:57:09]
okay translate so here as an input you

[06:57:07 - 06:57:12]
will pass one

[06:57:09 - 06:57:14]
language okay you'll pass one language

[06:57:12 - 06:57:16]
and it will give you the um like

[06:57:14 - 06:57:19]
translated

[06:57:16 - 06:57:21]
text okay translated text okay so this

[06:57:19 - 06:57:24]
is the entire actually high level

[06:57:21 - 06:57:26]
diagram so for this I'll open up my uh

[06:57:24 - 06:57:30]
local folder and here I'm going to open

[06:57:26 - 06:57:30]
up my uh visual code

[06:57:30 - 06:57:37]
Studio so this this is my visual code

[06:57:34 - 06:57:39]
Studio then I'm also going to open up my

[06:57:37 - 06:57:39]
terminal

[06:57:40 - 06:57:44]
here okay I think you remember

[06:57:42 - 06:57:46]
previously we created one environment

[06:57:44 - 06:57:47]
like openi demo so let me activate the

[06:57:46 - 06:57:49]
environment instead of creating again

[06:57:47 - 06:57:53]
and again so what I can do I can just

[06:57:49 - 06:57:55]
write P activate open AI demo okay so

[06:57:53 - 06:57:57]
this environment I'm going to use

[06:57:55 - 06:57:58]
because inside that openi is already

[06:57:57 - 06:58:02]
installed there

[06:57:58 - 06:58:05]
right fine now here I'm going to create

[06:58:02 - 06:58:05]
a requirement

[06:58:05 - 06:58:10]
file so here the first requirement you

[06:58:08 - 06:58:12]
need the openi I think openi is already

[06:58:10 - 06:58:14]
installed but here I'm adding because I

[06:58:12 - 06:58:16]
want to share this uh material with you

[06:58:14 - 06:58:18]
so later on whenever you want to install

[06:58:16 - 06:58:22]
it you can check the requirement. txt

[06:58:18 - 06:58:24]
file then I also need python. EnV uh I

[06:58:22 - 06:58:26]
think uh you know why python. because

[06:58:24 - 06:58:29]
we'll be managing the credential right

[06:58:26 - 06:58:31]
that means we'll be creating a EnV file

[06:58:29 - 06:58:34]
and inside that I'm going to mention my

[06:58:31 - 06:58:36]
uh open API key I think you remember we

[06:58:34 - 06:58:38]
already created One open API key so this

[06:58:36 - 06:58:41]
is my open API key okay let me save it

[06:58:38 - 06:58:43]
here fine now see here I'm going to

[06:58:41 - 06:58:47]
create a user interface that means see

[06:58:43 - 06:58:49]
this audio file uh user can upload user

[06:58:47 - 06:58:52]
can

[06:58:49 - 06:58:54]
upload this audio file for this I need a

[06:58:52 - 06:58:56]
web interface okay web application so to

[06:58:54 - 06:58:59]
create the web application I'm going to

[06:58:56 - 06:59:01]
use one uh framework called flask so

[06:58:59 - 06:59:02]
flask is a framework inside python with

[06:59:01 - 06:59:05]
the help of that you can create the web

[06:59:02 - 06:59:08]
application okay so let me also install

[06:59:05 - 06:59:08]
the flask

[06:59:10 - 06:59:14]
here okay

[06:59:12 - 06:59:16]
flask now simply what you have to do

[06:59:14 - 06:59:23]
open up your terminal and write this

[06:59:16 - 06:59:23]
command P install hyen requirement.

[06:59:23 - 06:59:27]
dxt for me it is already satisfied but

[06:59:26 - 06:59:29]
for you it will take some time to

[06:59:27 - 06:59:33]
install all the packet fine now the

[06:59:29 - 06:59:35]
first thing uh I'll show you the demo

[06:59:33 - 06:59:38]
like how we can use the whispar model so

[06:59:35 - 06:59:40]
first of all let me import openi and it

[06:59:38 - 06:59:42]
is showing this warning because I have

[06:59:40 - 06:59:44]
to select my environment I have created

[06:59:42 - 06:59:46]
openi

[06:59:44 - 06:59:48]
demo then I also need to import

[06:59:46 - 06:59:54]
operating system because I want to load

[06:59:48 - 07:00:00]
my EnV then EnV as well so from EnV

[06:59:54 - 07:00:00]
import load EnV F first of all I load my

[07:00:00 - 07:00:05]
EnV so here is my open API

[07:00:06 - 07:00:13]
key w.

[07:00:10 - 07:00:16]
gmv then I need to add this API key

[07:00:13 - 07:00:18]
inside my open API key so

[07:00:16 - 07:00:23]
open. API

[07:00:18 - 07:00:25]
key is equal to my open API key fine H I

[07:00:23 - 07:00:28]
think my authentication is completed now

[07:00:25 - 07:00:30]
now what I will do I'll just uh open up

[07:00:28 - 07:00:32]
one audio file so let me show you I have

[07:00:30 - 07:00:34]
one audio file with me so this is the

[07:00:32 - 07:00:36]
audio file guys let me play so this

[07:00:34 - 07:00:39]
audio actually I have

[07:00:36 - 07:00:41]
recorded python is a high level

[07:00:39 - 07:00:44]
interpreted general purpose programming

[07:00:41 - 07:00:48]
language it is very easy to learn and

[07:00:44 - 07:00:50]
you can use Python Programming in data

[07:00:48 - 07:00:52]
science fine so this is the audio file

[07:00:50 - 07:00:54]
actually I have recorded so I just need

[07:00:52 - 07:00:57]
to open this file so to open this file I

[07:00:54 - 07:01:01]
think you can use this U open and inside

[07:00:57 - 07:01:03]
that you can pass this uh name so

[07:01:01 - 07:01:03]
recording

[07:01:04 - 07:01:12]
dot MP3 okay MP3 and again it's a binary

[07:01:09 - 07:01:15]
file so you have to give the mode uh RB

[07:01:12 - 07:01:18]
read binary fine so it will give you one

[07:01:15 - 07:01:20]
uh object let's say

[07:01:18 - 07:01:23]
audio underscore

[07:01:20 - 07:01:26]
file okay so I have successfully uh

[07:01:23 - 07:01:28]
loaded this file now if you want to get

[07:01:26 - 07:01:30]
the transcripts what you can do you can

[07:01:28 - 07:01:32]
use this open uh sorry open a whispar

[07:01:30 - 07:01:34]
model so I'll just write open a

[07:01:32 - 07:01:37]
do audio this is Audio model I think I

[07:01:34 - 07:01:40]
told you so you have to call one F

[07:01:37 - 07:01:42]
function called Translate Okay translate

[07:01:40 - 07:01:44]
and inside that first of all you have to

[07:01:42 - 07:01:47]
mention the model name so I want to use

[07:01:44 - 07:01:48]
whispar one model so it is having

[07:01:47 - 07:01:50]
different different model I want to use

[07:01:48 - 07:01:54]
whar B model then you have to pass the

[07:01:50 - 07:01:57]
audio file so audio file now here uh it

[07:01:54 - 07:01:57]
will give me the

[07:01:59 - 07:02:03]
output now let me print the output

[07:02:05 - 07:02:08]
H now let me show

[07:02:12 - 07:02:16]
you so guys here is the text I'm getting

[07:02:14 - 07:02:17]
python is a high level interpreted

[07:02:16 - 07:02:19]
general purpose programming language it

[07:02:17 - 07:02:21]
is very easy to learn and you can use

[07:02:19 - 07:02:24]
Python Programming in data science that

[07:02:21 - 07:02:25]
means uh whatever uh things you can uh

[07:02:24 - 07:02:27]
actually hear in the audio the same

[07:02:25 - 07:02:29]
thing you can see as a text so it is

[07:02:27 - 07:02:31]
like very powerful model it will give

[07:02:29 - 07:02:33]
you the accurate result always okay you

[07:02:31 - 07:02:34]
can try with different different audio I

[07:02:33 - 07:02:36]
think you will get it now what I have to

[07:02:34 - 07:02:38]
do I have to translate okay I have to

[07:02:36 - 07:02:40]
translate this transcript uh in a

[07:02:38 - 07:02:43]
different language okay for this I'll be

[07:02:40 - 07:02:45]
using uh gpt3 or GPT 4 model whatever

[07:02:43 - 07:02:46]
you can use here okay and we'll be

[07:02:45 - 07:02:48]
creating one user application so that

[07:02:46 - 07:02:49]
user can upload this audio there okay

[07:02:48 - 07:02:51]
this is what actually will be

[07:02:49 - 07:02:53]
implementing so for this what I can do I

[07:02:51 - 07:02:55]
can create another file here I'll just

[07:02:53 - 07:02:59]
name it as

[07:02:55 - 07:03:01]
app.py H now I'll copy paste the same

[07:02:59 - 07:03:03]
code this code actually I'll just try to

[07:03:01 - 07:03:05]
copy request here because here we are

[07:03:03 - 07:03:06]
authenticating with our openi only fine

[07:03:05 - 07:03:08]
now apart from that I also need to

[07:03:06 - 07:03:10]
import another package called flask okay

[07:03:08 - 07:03:12]
uh because with the help of flask will

[07:03:10 - 07:03:14]
be creating this uh user application

[07:03:12 - 07:03:16]
okay that is why I'm importing flask so

[07:03:14 - 07:03:18]
you can see from flask I'm importing

[07:03:16 - 07:03:20]
flask request so redirect URL this is

[07:03:18 - 07:03:22]
not required as of now just un ify

[07:03:20 - 07:03:24]
render template okay so with the help of

[07:03:22 - 07:03:26]
that actually we'll be rendering our web

[07:03:24 - 07:03:28]
webp for this you need a basic HTML file

[07:03:26 - 07:03:30]
I'll tell you how we can create a HTML

[07:03:28 - 07:03:31]
file you can also get different

[07:03:30 - 07:03:34]
different template you can also use that

[07:03:31 - 07:03:35]
fun fine now the next thing I'll be

[07:03:34 - 07:03:37]
initializing my flask to initialize the

[07:03:35 - 07:03:39]
flask just write this code this is the

[07:03:37 - 07:03:41]
code guys flask u in the parenthesis you

[07:03:39 - 07:03:43]
have to give underscore name now you can

[07:03:41 - 07:03:45]
ask me how to initialize the flash go to

[07:03:43 - 07:03:47]
the flash documentation you can see that

[07:03:45 - 07:03:48]
okay you can see the code the basic

[07:03:47 - 07:03:49]
template they have already given so

[07:03:48 - 07:03:52]
first of all here I'll just add one

[07:03:49 - 07:03:54]
configuration so have. config that means

[07:03:52 - 07:03:57]
whatever audio actually user will upload

[07:03:54 - 07:04:00]
so this will save so this will save

[07:03:57 - 07:04:02]
actually first of all let me just write

[07:04:00 - 07:04:04]
upload unders

[07:04:02 - 07:04:07]
folder this will save inside a folder

[07:04:04 - 07:04:07]
name static static okay now let's create

[07:04:07 - 07:04:10]
this

[07:04:07 - 07:04:12]
folder left hand side I'll create a

[07:04:10 - 07:04:14]
folder name static okay inside that this

[07:04:12 - 07:04:17]
audio will be saved fine this is the

[07:04:14 - 07:04:20]
idea now let me create a route so I'll

[07:04:17 - 07:04:23]
just give at theate app. Route so as you

[07:04:20 - 07:04:24]
can see this is my route so it will look

[07:04:23 - 07:04:26]
for actually two kinds of let's say

[07:04:24 - 07:04:28]
request one is like get request and is

[07:04:26 - 07:04:31]
like post request okay if it is matching

[07:04:28 - 07:04:32]
what will happen this will execute this

[07:04:31 - 07:04:34]
function so here I'm going to create a

[07:04:32 - 07:04:37]
function called main okay so this will

[07:04:34 - 07:04:39]
execute this main function so inside

[07:04:37 - 07:04:42]
main function the first thing I have to

[07:04:39 - 07:04:47]
check uh whether it's a post request or

[07:04:42 - 07:04:50]
not so if uh request okay if request.

[07:04:47 - 07:04:52]
method is equal to is equal to if it is

[07:04:50 - 07:04:54]
post okay if it is a post request that

[07:04:52 - 07:04:56]
means if you upload if you upload one

[07:04:54 - 07:04:57]
audio file and if you click on the

[07:04:56 - 07:05:00]
button that that means it would be a

[07:04:57 - 07:05:02]
post request okay that is the idea if it

[07:05:00 - 07:05:04]
is a post request so what I will do

[07:05:02 - 07:05:07]
first of all I will get the

[07:05:04 - 07:05:09]
language okay I'll get the language that

[07:05:07 - 07:05:12]
means user will also pass the language

[07:05:09 - 07:05:14]
like uh in which language he or she

[07:05:12 - 07:05:15]
wants to translate this uh let's say

[07:05:14 - 07:05:18]
transcript okay that's why I also need

[07:05:15 - 07:05:20]
to take the language input so here I'll

[07:05:18 - 07:05:22]
take the input I'll just write request

[07:05:20 - 07:05:24]
do

[07:05:22 - 07:05:26]
form uh so from the form itself I'll

[07:05:24 - 07:05:28]
take the language now how I'll get the

[07:05:26 - 07:05:31]
language because for this I'm going to

[07:05:28 - 07:05:33]
create a HTML file so let me create a

[07:05:31 - 07:05:34]
folder here first first of all if you're

[07:05:33 - 07:05:36]
using flask you need to create this

[07:05:34 - 07:05:39]
folder guys called

[07:05:36 - 07:05:41]
templates okay templates inside that I

[07:05:39 - 07:05:43]
will be creating a sorry it should be

[07:05:41 - 07:05:46]
templates

[07:05:43 - 07:05:47]
not spelling is not correct H now it is

[07:05:46 - 07:05:54]
fine now inside that I'm going to create

[07:05:47 - 07:05:56]
a HTML file called index do HTML

[07:05:54 - 07:06:01]
okay now here I have written one very

[07:05:56 - 07:06:03]
simple HTML code it will only uh accept

[07:06:01 - 07:06:06]
the audio file see here I've given the

[07:06:03 - 07:06:08]
title and this is like very basic uh CSS

[07:06:06 - 07:06:10]
code I have added here just to like show

[07:06:08 - 07:06:12]
my front end little bit actually

[07:06:10 - 07:06:14]
beautiful that's why now see it will uh

[07:06:12 - 07:06:16]
user can upload one audio file okay you

[07:06:14 - 07:06:18]
can see user can upload one audio file

[07:06:16 - 07:06:20]
uh input type is file and user will also

[07:06:18 - 07:06:23]
able to give the language input that

[07:06:20 - 07:06:25]
means in which language he or she wants

[07:06:23 - 07:06:27]
to translate that transcript okay then

[07:06:25 - 07:06:29]
there would be a button called upload so

[07:06:27 - 07:06:31]
whenever uh they will upload so what

[07:06:29 - 07:06:33]
will happen it will hit the post request

[07:06:31 - 07:06:35]
okay it will hit the post request and

[07:06:33 - 07:06:37]
that time my you can see method is equal

[07:06:35 - 07:06:39]
to post that time it will hit this route

[07:06:37 - 07:06:41]
okay it will hit this route and I will

[07:06:39 - 07:06:43]
then I'll be able to get the language

[07:06:41 - 07:06:44]
and whatever audio actually is

[07:06:43 - 07:06:46]
submitting everything I will get okay

[07:06:44 - 07:06:48]
from the back end this is the idea only

[07:06:46 - 07:06:50]
fine so this is a simple HTML code and

[07:06:48 - 07:06:52]
now you can ask me why to get these

[07:06:50 - 07:06:55]
kinds of HTML code there is a one

[07:06:52 - 07:06:57]
beautiful website you can follow called

[07:06:55 - 07:06:59]
bootstrap okay

[07:06:57 - 07:07:02]
bootstrap so here you will get all kinds

[07:06:59 - 07:07:04]
of FD HTML CSS template you can go to

[07:07:02 - 07:07:06]
the example section and see different

[07:07:04 - 07:07:08]
different actually template you are

[07:07:06 - 07:07:10]
having you can uh get their HTML and CSS

[07:07:08 - 07:07:13]
code even you can also SE let's see you

[07:07:10 - 07:07:15]
need a file uploader button okay file

[07:07:13 - 07:07:17]
upload see different different codes in

[07:07:15 - 07:07:20]
if they have already given okay that's

[07:07:17 - 07:07:22]
how actually you can also get the code

[07:07:20 - 07:07:24]
you can also get the code okay so I just

[07:07:22 - 07:07:26]
referred this website and I uh actually

[07:07:24 - 07:07:28]
let's say collected this HTML and CSS

[07:07:26 - 07:07:30]
code and I modified okay with respect to

[07:07:28 - 07:07:32]
my requirement this is the idea now I

[07:07:30 - 07:07:34]
think everything is fine now what I will

[07:07:32 - 07:07:37]
do I'll go back to my app app.py and I'm

[07:07:34 - 07:07:39]
getting the language then I also need

[07:07:37 - 07:07:41]
the file okay so to get the file I'll

[07:07:39 - 07:07:44]
store inside a file and I'll just write

[07:07:41 - 07:07:47]
uh request.

[07:07:44 - 07:07:49]
form uh request dot not form do files

[07:07:47 - 07:07:52]
actually because it's a file type input

[07:07:49 - 07:07:53]
right so it should be a file you can see

[07:07:52 - 07:07:55]
here I have mentioned it should be a

[07:07:53 - 07:07:58]
file okay it should be a file type

[07:07:55 - 07:07:59]
should be a file now once I get the file

[07:07:58 - 07:08:02]
uh first of all I will check whether

[07:07:59 - 07:08:03]
this file is available or not if file

[07:08:02 - 07:08:06]
is equal to True okay if this is not

[07:08:03 - 07:08:07]
false that means user has uploaded the

[07:08:06 - 07:08:10]
file that time what I will do I'll just

[07:08:07 - 07:08:12]
simply save this file where I will save

[07:08:10 - 07:08:14]
I'll save inside my static folder so

[07:08:12 - 07:08:16]
this is the code I think you remember we

[07:08:14 - 07:08:18]
said the configuration okay static okay

[07:08:16 - 07:08:21]
upload file static so it will save the

[07:08:18 - 07:08:22]
inside stratic folder and to save this

[07:08:21 - 07:08:25]
file I need a file name so let's create

[07:08:22 - 07:08:27]
a file name here I'll just write file

[07:08:25 - 07:08:29]
name is equal to file do file name okay

[07:08:27 - 07:08:30]
it will give you the file name now after

[07:08:29 - 07:08:32]
that you can easily save this file

[07:08:30 - 07:08:34]
inside stratic folder

[07:08:32 - 07:08:36]
then I will load my

[07:08:34 - 07:08:38]
audio so to load the Audio I think you

[07:08:36 - 07:08:43]
remember I was using this code

[07:08:38 - 07:08:43]
snippit so I can use the same code

[07:08:43 - 07:08:50]
here H now see this recording. MP3 would

[07:08:48 - 07:08:53]
be available inside static folder so I

[07:08:50 - 07:08:53]
need to also give the path of the

[07:08:54 - 07:09:01]
static okay stratic / recording. MP3 now

[07:08:58 - 07:09:05]
the same code I'll be writing here

[07:09:01 - 07:09:08]
I'll copy and here I'm going to paste

[07:09:05 - 07:09:11]
it so this will give me the output that

[07:09:08 - 07:09:14]
means the transcript here I can mention

[07:09:11 - 07:09:15]
it as transcript okay transcript now

[07:09:14 - 07:09:16]
what I have to do I have to translate

[07:09:15 - 07:09:18]
this transcript to the another language

[07:09:16 - 07:09:20]
for this I already told you here we'll

[07:09:18 - 07:09:24]
be using something called gpt3 or four

[07:09:20 - 07:09:26]
model okay so let me initialize my GPT

[07:09:24 - 07:09:29]
model so I think remember how we can

[07:09:26 - 07:09:32]
initialize it uh we can use chat

[07:09:29 - 07:09:33]
completion API so here is the Cod s it

[07:09:32 - 07:09:35]
guys so here I'm using chat completion

[07:09:33 - 07:09:38]
API inside that I'm mentioning I want to

[07:09:35 - 07:09:40]
use GPT for model OKAY GPT for model and

[07:09:38 - 07:09:42]
this is the message I have given role

[07:09:40 - 07:09:45]
you can see RO system content uh you

[07:09:42 - 07:09:47]
will be provided with a sentence in the

[07:09:45 - 07:09:49]
English and your task is to translate is

[07:09:47 - 07:09:51]
to language that means whatever language

[07:09:49 - 07:09:54]
user is giving that in that particular

[07:09:51 - 07:09:57]
language then role so let me bring it

[07:09:54 - 07:09:58]
here I can see R user content

[07:09:57 - 07:10:00]
transcript. text that means whatever

[07:09:58 - 07:10:01]
text actually I'm getting after doing

[07:10:00 - 07:10:04]
the let's say

[07:10:01 - 07:10:06]
I mean audio to text I'm just passing it

[07:10:04 - 07:10:07]
here and here is my prompt okay here is

[07:10:06 - 07:10:08]
my prompt I have given to my large

[07:10:07 - 07:10:09]
language model and this is the

[07:10:08 - 07:10:11]
temperature parameter and this is the

[07:10:09 - 07:10:13]
max tokens okay I already explained this

[07:10:11 - 07:10:15]
parameter okay why it is required now

[07:10:13 - 07:10:18]
simply what I will do I'll just try to

[07:10:15 - 07:10:21]
return return this response but I just

[07:10:18 - 07:10:23]
try to return with the Jony why justy

[07:10:21 - 07:10:26]
because whatever let's say response you

[07:10:23 - 07:10:28]
want to render in the HML P it should be

[07:10:26 - 07:10:30]
Json format okay that's why I have to do

[07:10:28 - 07:10:33]
the jsonify so inside that I will be

[07:10:30 - 07:10:33]
passing my response

[07:10:33 - 07:10:36]
okay and this on ify I already imported

[07:10:34 - 07:10:38]
I think you remember from here then if

[07:10:36 - 07:10:40]
it is not a post request okay if it is

[07:10:38 - 07:10:41]
not a post request that means if it is a

[07:10:40 - 07:10:42]
get request what will happen it will

[07:10:41 - 07:10:45]
only

[07:10:42 - 07:10:47]
render okay it will only render my

[07:10:45 - 07:10:50]
index.html okay this index.html that

[07:10:47 - 07:10:52]
means my uh web app okay my web app menu

[07:10:50 - 07:10:53]
it will open in front of the user this

[07:10:52 - 07:10:56]
is the

[07:10:53 - 07:10:57]
idea and to render it I'm using render

[07:10:56 - 07:10:59]
template function you can see I've

[07:10:57 - 07:11:02]
already imported it here now if I want

[07:10:59 - 07:11:03]
to execute my application so you can

[07:11:02 - 07:11:05]
execute it here for this you have to

[07:11:03 - 07:11:07]
give the app host and app Port see

[07:11:05 - 07:11:09]
app.run host 00 that means I want to run

[07:11:07 - 07:11:10]
in my local host and debug is equal to r

[07:11:09 - 07:11:12]
that means if you change anything it

[07:11:10 - 07:11:14]
will automatically update the changes

[07:11:12 - 07:11:16]
and this is the Port Port number 8080

[07:11:14 - 07:11:19]
now let me execute and show you this

[07:11:16 - 07:11:22]
application so I'll open up my terminal

[07:11:19 - 07:11:24]
and now if I execute let's say python

[07:11:22 - 07:11:27]
app.py now it is running on my Local

[07:11:24 - 07:11:29]
Host now let's go to the Google and

[07:11:27 - 07:11:30]
search for local host port number 8080

[07:11:29 - 07:11:32]
now see if I search so guys you can see

[07:11:30 - 07:11:33]
this is my my interface okay interface

[07:11:32 - 07:11:36]
of my application now here you can

[07:11:33 - 07:11:38]
upload any kinds of uh audio file now

[07:11:36 - 07:11:40]
let's upload so let's say I want to

[07:11:38 - 07:11:44]
upload my this audio Now language let's

[07:11:40 - 07:11:48]
say I want to translate in a Hindi okay

[07:11:44 - 07:11:48]
Hindi now let's upload

[07:11:49 - 07:11:54]
it now see guys this is the response I

[07:11:52 - 07:11:56]
got and this is my response you can see

[07:11:54 - 07:11:59]
this is the Hindi translation okay this

[07:11:56 - 07:12:01]
is the Hindi translation whatever

[07:11:59 - 07:12:02]
actually I had in my audio now you can

[07:12:01 - 07:12:05]
Al give any other language let's say

[07:12:02 - 07:12:08]
again I will pass my audio let's say I

[07:12:05 - 07:12:11]
want to translate uh in the let's say I

[07:12:08 - 07:12:12]
want to translate in Bangla okay Bengali

[07:12:11 - 07:12:14]
now I'll

[07:12:12 - 07:12:17]
upload see this is the Bengali

[07:12:14 - 07:12:20]
translation I'm getting okay now you can

[07:12:17 - 07:12:21]
also extract the content only uh instead

[07:12:20 - 07:12:22]
of like let's say getting all the

[07:12:21 - 07:12:24]
response but I have printed all the

[07:12:22 - 07:12:25]
response I just wanted to show you each

[07:12:24 - 07:12:27]
and everything whatever things it is

[07:12:25 - 07:12:29]
returning okay I already showed you how

[07:12:27 - 07:12:31]
we can extract out this content okay

[07:12:29 - 07:12:33]
from my previous I think session I think

[07:12:31 - 07:12:35]
remember fine so yes guys that's how

[07:12:33 - 07:12:38]
actually we can implement this project

[07:12:35 - 07:12:39]
and we can use the whispar model okay

[07:12:38 - 07:12:40]
now what you can do you can improve this

[07:12:39 - 07:12:42]
project you can add some more

[07:12:40 - 07:12:43]
functionality let's say you want to

[07:12:42 - 07:12:45]
again convert this text to audio you can

[07:12:43 - 07:12:47]
also do it for this just go to the

[07:12:45 - 07:12:49]
whisper documentation and try to check

[07:12:47 - 07:12:50]
there okay so I hope guys you like this

[07:12:49 - 07:12:52]
project so if you have like this project

[07:12:50 - 07:12:53]
guys so please try to subscribe to the

[07:12:52 - 07:12:55]
channel and share this video with your

[07:12:53 - 07:12:57]
friends and family so I already showed

[07:12:55 - 07:12:59]
you openi is having different different

[07:12:57 - 07:13:00]
actually large language model uh like

[07:12:59 - 07:13:02]
different different kinds of large

[07:13:00 - 07:13:04]
language model like uh language model

[07:13:02 - 07:13:05]
multi model OKAY image model like

[07:13:04 - 07:13:08]
different different model actually it is

[07:13:05 - 07:13:10]
having so we'll be using another model

[07:13:08 - 07:13:11]
uh this is called actually Deli so Deli

[07:13:10 - 07:13:13]
is having different different like

[07:13:11 - 07:13:15]
version like Del 2 is there Del 3 is

[07:13:13 - 07:13:17]
there so we can use openi API to access

[07:13:15 - 07:13:19]
this model okay so let me show you this

[07:13:17 - 07:13:21]
Deli model so guys if you go to the

[07:13:19 - 07:13:23]
openi documentation so here you will see

[07:13:21 - 07:13:25]
this Deli model let me show you so this

[07:13:23 - 07:13:26]
is the deli model so as you can see Deli

[07:13:25 - 07:13:29]
is having different kinds of uh let's

[07:13:26 - 07:13:30]
say version like Del 3 then Del 2 okay

[07:13:29 - 07:13:32]
so different different version it is

[07:13:30 - 07:13:33]
having and Deli is one of the model

[07:13:32 - 07:13:35]
actually it can create actually

[07:13:33 - 07:13:37]
realistic image from a prompt let's say

[07:13:35 - 07:13:39]
here you will be passing one uh like

[07:13:37 - 07:13:40]
text prompt and with the help of this

[07:13:39 - 07:13:42]
prompt actually it will generate the

[07:13:40 - 07:13:43]
image okay the prompt you will be asking

[07:13:42 - 07:13:45]
the same kinds of image actually it'll

[07:13:43 - 07:13:47]
try to generate and this would be

[07:13:45 - 07:13:49]
realistic image okay now let's see how

[07:13:47 - 07:13:52]
we can use openi API to access this Del

[07:13:49 - 07:13:54]
model and let's build one uh image

[07:13:52 - 07:13:57]
generator application so what I will do

[07:13:54 - 07:13:59]
guys I have uh used the same template as

[07:13:57 - 07:14:00]
I already used in my previous project

[07:13:59 - 07:14:02]
implementation I think remember we are

[07:14:00 - 07:14:04]
using FL there so I use the same

[07:14:02 - 07:14:06]
template and I just did little bit

[07:14:04 - 07:14:09]
modification here so the modification I

[07:14:06 - 07:14:12]
have done uh the entire HTML code okay

[07:14:09 - 07:14:14]
I've done the modification uh let me

[07:14:12 - 07:14:16]
show you the application like how it

[07:14:14 - 07:14:18]
will look

[07:14:16 - 07:14:23]
like let me

[07:14:18 - 07:14:27]
clear now if I open up my app.py

[07:14:23 - 07:14:30]
again so let me go to Google and Local

[07:14:27 - 07:14:31]
Host port number 8080 so guys you can

[07:14:30 - 07:14:33]
see this is the interface of of my

[07:14:31 - 07:14:36]
application so to build this interface I

[07:14:33 - 07:14:37]
have actually collected this HTML and

[07:14:36 - 07:14:39]
CSS code from the bootstrap website I

[07:14:37 - 07:14:41]
think I showed you that bootstrap

[07:14:39 - 07:14:43]
website right so you don't need to do

[07:14:41 - 07:14:44]
anything only you can change the title

[07:14:43 - 07:14:46]
and all okay everything you can keep it

[07:14:44 - 07:14:49]
as default because you can use this uh

[07:14:46 - 07:14:50]
HTML and CSS code uh as a template okay

[07:14:49 - 07:14:52]
let's say you want to build any other

[07:14:50 - 07:14:53]
application with the same template you

[07:14:52 - 07:14:55]
can use this code as it is okay if

[07:14:53 - 07:14:57]
you're not familiar with HTML CSS code

[07:14:55 - 07:14:58]
it's completely fine you can copy paste

[07:14:57 - 07:14:59]
from different different website okay

[07:14:58 - 07:15:01]
now the second changes I have done I

[07:14:59 - 07:15:04]
have created two route one is my default

[07:15:01 - 07:15:05]
route that means if user is hitting my

[07:15:04 - 07:15:07]
uh let's say default route that means

[07:15:05 - 07:15:10]
port number 8080 so he will get this

[07:15:07 - 07:15:11]
kinds of landing page okay and to render

[07:15:10 - 07:15:14]
the landing page actually I'm using

[07:15:11 - 07:15:16]
render template index.html okay and

[07:15:14 - 07:15:18]
whenever user is giving any kinds of

[07:15:16 - 07:15:20]
prompt and there submitting okay

[07:15:18 - 07:15:22]
submitting button so it will hit this

[07:15:20 - 07:15:24]
route and it will generate and it will

[07:15:22 - 07:15:25]
execute this function and this function

[07:15:24 - 07:15:27]
will take the prompt whatever prompt

[07:15:25 - 07:15:29]
actually user is giving here I think you

[07:15:27 - 07:15:32]
can see okay and this prompt will go to

[07:15:29 - 07:15:33]
the open AI Del model you can see to use

[07:15:32 - 07:15:37]
the open Del model you have to use this

[07:15:33 - 07:15:39]
Cod spp it open. im. create okay inside

[07:15:37 - 07:15:40]
that just try to mention the prompt

[07:15:39 - 07:15:42]
number of image you want to generate

[07:15:40 - 07:15:44]
just give the number of image and the

[07:15:42 - 07:15:46]
size of the image okay everything you

[07:15:44 - 07:15:48]
can set here now I'm printing the

[07:15:46 - 07:15:50]
response as well as that and here you

[07:15:48 - 07:15:51]
can see I'm also rendering on my user

[07:15:50 - 07:15:54]
interface okay and again I'm running on

[07:15:51 - 07:15:55]
Local Host and port number 8080 and

[07:15:54 - 07:15:57]
debug is equal to True means if you're

[07:15:55 - 07:15:59]
changing anything this will reflect

[07:15:57 - 07:16:00]
automatically fine so this is the simple

[07:15:59 - 07:16:02]
modification I have done guys otherwise

[07:16:00 - 07:16:03]
everything I kept default okay

[07:16:02 - 07:16:04]
everything I kept default whatever

[07:16:03 - 07:16:06]
things we have implemented in our

[07:16:04 - 07:16:08]
previous project so yes guys I think you

[07:16:06 - 07:16:10]
got it uh using openi is like very easy

[07:16:08 - 07:16:12]
only you just need to know how we can

[07:16:10 - 07:16:14]
access different different model rest of

[07:16:12 - 07:16:15]
the things you can take care okay let's

[07:16:14 - 07:16:16]
say if you want to create any kinds of

[07:16:15 - 07:16:18]
application you have to design how

[07:16:16 - 07:16:20]
you'll be creating okay otherwise the

[07:16:18 - 07:16:22]
fundamental will remain same now let me

[07:16:20 - 07:16:24]
show you the demo guys so what I can do

[07:16:22 - 07:16:31]
I can give a prompt here let's say I'll

[07:16:24 - 07:16:33]
give a dog is flying and smoking

[07:16:31 - 07:16:34]
let's say this is my prompt I have given

[07:16:33 - 07:16:37]
let's see whether it is able to generate

[07:16:34 - 07:16:39]
the image or not you can give the same

[07:16:37 - 07:16:41]
prompt in the chat GPT

[07:16:39 - 07:16:45]
also let me show you chat GPT is also

[07:16:41 - 07:16:47]
using uh this kinds of image model

[07:16:45 - 07:16:50]
recently they have published one model

[07:16:47 - 07:16:52]
called GPT 40 okay GPT 40 so this model

[07:16:50 - 07:16:55]
is able to actually create these kinds

[07:16:52 - 07:16:57]
of image okay uh from your prompt now

[07:16:55 - 07:16:58]
let me pass this prompt a dog is flying

[07:16:57 - 07:17:01]
and is

[07:16:58 - 07:17:04]
smoking see it is uh generating

[07:17:01 - 07:17:05]
two response and let me see my see this

[07:17:04 - 07:17:07]
one actually it has generated okay this

[07:17:05 - 07:17:09]
is a curon version even you can also

[07:17:07 - 07:17:11]
generate the realistic one let me show

[07:17:09 - 07:17:13]
you another prompt so guys uh this is

[07:17:11 - 07:17:15]
the prompt I have prepared you can see

[07:17:13 - 07:17:17]
uh dream like a beautiful girl uh

[07:17:15 - 07:17:20]
playing the Festival of Color drapped in

[07:17:17 - 07:17:22]
the traditional Indian uh throwing the

[07:17:20 - 07:17:24]
colors okay now let me send and let me

[07:17:22 - 07:17:26]
see the response and if I go to the chat

[07:17:24 - 07:17:28]
jbt see this is the CH jpt response fine

[07:17:26 - 07:17:31]
see uh this is the output actually we

[07:17:28 - 07:17:32]
got okay it's amazing you can see so you

[07:17:31 - 07:17:33]
can give different different prom like

[07:17:32 - 07:17:35]
that and you can generate image and you

[07:17:33 - 07:17:38]
can also control like how many image you

[07:17:35 - 07:17:39]
need so here I mentioned I think you saw

[07:17:38 - 07:17:41]
only five images that's why it's giving

[07:17:39 - 07:17:42]
five images okay and you can also

[07:17:41 - 07:17:44]
mention the size everything you can

[07:17:42 - 07:17:46]
mention so yes guys uh this is the

[07:17:44 - 07:17:49]
application we have developed I hope you

[07:17:46 - 07:17:51]
liked it and now uh what you can do you

[07:17:49 - 07:17:53]
can improve this application you can add

[07:17:51 - 07:17:55]
some more functionality see I think the

[07:17:53 - 07:17:57]
previous application we created that uh

[07:17:55 - 07:17:59]
whispar model what you can do you can

[07:17:57 - 07:18:01]
integrate like both application in one

[07:17:59 - 07:18:03]
place okay and you can create a complete

[07:18:01 - 07:18:04]
platform okay that thing I think you can

[07:18:03 - 07:18:06]
perform okay this would be a good

[07:18:04 - 07:18:08]
project for you so yes guys this is all

[07:18:06 - 07:18:09]
about from my side please subscribe to

[07:18:08 - 07:18:11]
the channel and share this video with

[07:18:09 - 07:18:13]
your friends and family and please

[07:18:11 - 07:18:15]
support the channel guys uh if you

[07:18:13 - 07:18:17]
support the channel so definitely uh

[07:18:15 - 07:18:19]
we'll be bringing up these kinds of

[07:18:17 - 07:18:20]
content okay for you and you can let us

[07:18:19 - 07:18:23]
know what kinds of content you you want

[07:18:20 - 07:18:25]
okay from my end I'll try to provide so

[07:18:23 - 07:18:27]
I think as of now we have worked with

[07:18:25 - 07:18:29]
the large language model I have showed

[07:18:27 - 07:18:31]
you the hugging face platform even we

[07:18:29 - 07:18:33]
have also worked with the openi platform

[07:18:31 - 07:18:35]
there we use different different large

[07:18:33 - 07:18:36]
language model and whenever I was using

[07:18:35 - 07:18:38]
these kinds of large language model I

[07:18:36 - 07:18:41]
think you noticed I was passing the

[07:18:38 - 07:18:43]
prompt okay uh again uh if I'm talking

[07:18:41 - 07:18:44]
about chat GPT Google but whatever

[07:18:43 - 07:18:46]
application you can see in the field of

[07:18:44 - 07:18:48]
geni all the application takes the

[07:18:46 - 07:18:50]
prompt as an input okay based on the

[07:18:48 - 07:18:52]
prompt it will decide what kinds of

[07:18:50 - 07:18:54]
output it should generate okay that

[07:18:52 - 07:18:56]
means prompt is everything inside large

[07:18:54 - 07:18:57]
language model okay whatever let's say

[07:18:56 - 07:18:59]
large language model you are using

[07:18:57 - 07:19:01]
whatever generative model you are using

[07:18:59 - 07:19:03]
prompt is everything here okay you have

[07:19:01 - 07:19:05]
to give a proper prompt to get a proper

[07:19:03 - 07:19:07]
answer otherwise you will be getting

[07:19:05 - 07:19:09]
random kinds of answer from your large

[07:19:07 - 07:19:11]
language model okay so that's why there

[07:19:09 - 07:19:13]
is a separate concept inside genbi

[07:19:11 - 07:19:14]
called prompt engineering why prompt

[07:19:13 - 07:19:16]
engineering because whenever you are

[07:19:14 - 07:19:19]
writing these kinds of prompt you have

[07:19:16 - 07:19:21]
to know some uh technique okay how we

[07:19:19 - 07:19:23]
can design this prompt efficiently so

[07:19:21 - 07:19:25]
that I can get the output I can get the

[07:19:23 - 07:19:27]
effective output I can get the let's say

[07:19:25 - 07:19:28]
useful output from my large language

[07:19:27 - 07:19:30]
model okay otherwise what is the use of

[07:19:28 - 07:19:34]
large language model if it is giving you

[07:19:30 - 07:19:35]
a random kinds of output fine so that's

[07:19:34 - 07:19:37]
why we'll be learning about this prompt

[07:19:35 - 07:19:39]
engineering and make sure you are

[07:19:37 - 07:19:40]
watching this video till the end because

[07:19:39 - 07:19:42]
in this video we'll be covering each and

[07:19:40 - 07:19:44]
everything you need to master about

[07:19:42 - 07:19:46]
prompt

[07:19:44 - 07:19:47]
engineering so guys uh as you can see

[07:19:46 - 07:19:49]
what is prompt engineering prompt

[07:19:47 - 07:19:50]
engineering is nothing but so prompt

[07:19:49 - 07:19:52]
engineering is nothing but prompt

[07:19:50 - 07:19:54]
engineering is the process of

[07:19:52 - 07:19:57]
structuring uh an instruction that can

[07:19:54 - 07:19:59]
be interpreted and understood by by a

[07:19:57 - 07:20:01]
generative AI model that means I already

[07:19:59 - 07:20:03]
told you now in said generative prompt

[07:20:01 - 07:20:04]
is everything and whatever prompt

[07:20:03 - 07:20:06]
actually you are giving to the

[07:20:04 - 07:20:08]
generative EI model or your large

[07:20:06 - 07:20:10]
language model okay this should be well

[07:20:08 - 07:20:12]
structured okay this should be well

[07:20:10 - 07:20:13]
structured and well organized okay

[07:20:12 - 07:20:16]
otherwise what will happen your model

[07:20:13 - 07:20:17]
will give random kinds of output okay

[07:20:16 - 07:20:19]
that is why here I have written the

[07:20:17 - 07:20:21]
definition what is prompt engineering

[07:20:19 - 07:20:23]
exactly okay I hope it is clear now now

[07:20:21 - 07:20:25]
as a generative engineer you should have

[07:20:23 - 07:20:26]
some responsibility whenever you will be

[07:20:25 - 07:20:28]
working with the large language model

[07:20:26 - 07:20:29]
whenever you'll be preparing the prompt

[07:20:28 - 07:20:32]
and all see here have listed down some

[07:20:29 - 07:20:35]
of the points write uh refine and

[07:20:32 - 07:20:37]
optimize prompts perfect the interaction

[07:20:35 - 07:20:40]
between humans and AI that means you

[07:20:37 - 07:20:42]
always need to make sure whether your

[07:20:40 - 07:20:44]
prompt is perfect or not okay to

[07:20:42 - 07:20:46]
communicate between human and AI that

[07:20:44 - 07:20:48]
means you will be communicating with

[07:20:46 - 07:20:49]
your AI assistant let's say whatever

[07:20:48 - 07:20:51]
let's say application you are having

[07:20:49 - 07:20:53]
with the help of large language model

[07:20:51 - 07:20:55]
okay there is a a good interaction on

[07:20:53 - 07:20:56]
not okay The Prompt actually you have

[07:20:55 - 07:20:58]
given you have to always make sure

[07:20:56 - 07:20:59]
continuously monitor those prompt you

[07:20:58 - 07:21:01]
have to continuously monitor those

[07:20:59 - 07:21:03]
prompt whether this prompt is perfect or

[07:21:01 - 07:21:06]
not and is there any change in the model

[07:21:03 - 07:21:07]
or not then maintain and up up toate the

[07:21:06 - 07:21:10]
prompt that means if let's say model

[07:21:07 - 07:21:12]
model got updated let's say they again

[07:21:10 - 07:21:14]
did the fine tune that particular model

[07:21:12 - 07:21:15]
and if let's say previous prompt is not

[07:21:14 - 07:21:17]
working better in that case what you can

[07:21:15 - 07:21:19]
do you can maintain and update that

[07:21:17 - 07:21:20]
particular promt for that large language

[07:21:19 - 07:21:22]
model so these are the key

[07:21:20 - 07:21:24]
responsibility you should have as a

[07:21:22 - 07:21:26]
generative engineer now let's try to

[07:21:24 - 07:21:28]
understand why prompt engineering okay

[07:21:26 - 07:21:29]
so for this I'm going to show you one

[07:21:28 - 07:21:31]
demo I think this demo will give you the

[07:21:29 - 07:21:33]
clearcut idea why prompt engineering is

[07:21:31 - 07:21:36]
super important if you want to work with

[07:21:33 - 07:21:38]
the genbi so here you can see I have

[07:21:36 - 07:21:39]
written a prompt uh you can see this is

[07:21:38 - 07:21:41]
a prompt I have written correct my

[07:21:39 - 07:21:44]
paragraph today was the great day in the

[07:21:41 - 07:21:47]
world for me I went Disneyland with my

[07:21:44 - 07:21:48]
mom it could have been better if it

[07:21:47 - 07:21:50]
wasn't raining you can see some of the

[07:21:48 - 07:21:53]
spelling mistake is there that means

[07:21:50 - 07:21:55]
grammatical mistakes are there in this

[07:21:53 - 07:21:57]
paragraph I have written so I will do

[07:21:55 - 07:21:58]
I'll give this prom to my let's say

[07:21:57 - 07:22:01]
large language model so large language

[07:21:58 - 07:22:03]
model wise here I'm going to use ch GPT

[07:22:01 - 07:22:04]
okay you can also use Google b or any

[07:22:03 - 07:22:06]
other actually let's say model it's

[07:22:04 - 07:22:07]
completely fine but just to show you the

[07:22:06 - 07:22:10]
demo actually I'm going to use the chat

[07:22:07 - 07:22:11]
GPT platform later on whenever let's say

[07:22:10 - 07:22:12]
we'll be implementing different

[07:22:11 - 07:22:14]
different let's say application with the

[07:22:12 - 07:22:16]
help of large language model that time

[07:22:14 - 07:22:18]
actually we'll be using this prompt with

[07:22:16 - 07:22:19]
the help of python code okay as of now

[07:22:18 - 07:22:22]
just to show you the demo I'm going to

[07:22:19 - 07:22:24]
use the chat GPT application so guys as

[07:22:22 - 07:22:26]
you can see I'm inside my chat GPT now

[07:22:24 - 07:22:29]
let's say if I give this prompt uh to my

[07:22:26 - 07:22:31]
chat GPT now let's say if I send it here

[07:22:29 - 07:22:33]
see what will happen

[07:22:31 - 07:22:35]
see it has given me straightforward

[07:22:33 - 07:22:37]
results without let's say explaining

[07:22:35 - 07:22:39]
this uh like paragraph I have given

[07:22:37 - 07:22:40]
without let's say asking me any kinds of

[07:22:39 - 07:22:43]
question it has given me straightforward

[07:22:40 - 07:22:45]
answer so here is my uh paragraph and

[07:22:43 - 07:22:47]
here is the correct okay correct of my

[07:22:45 - 07:22:49]
paragraph correct version of my

[07:22:47 - 07:22:51]
paragraph today was uh today was a great

[07:22:49 - 07:22:54]
day for me I went to Disneyland with my

[07:22:51 - 07:22:56]
mom and it could have been better uh if

[07:22:54 - 07:22:58]
it wasn't raining okay you can see so

[07:22:56 - 07:23:00]
here you can see this uh grammatical

[07:22:58 - 07:23:02]
mistake I did it is resolved okay by my

[07:23:00 - 07:23:03]
large language model now let's say you

[07:23:02 - 07:23:05]
are learning about English language you

[07:23:03 - 07:23:06]
are learning about grammar you are

[07:23:05 - 07:23:08]
learning about let's say spelling and

[07:23:06 - 07:23:10]
everything like that means the complete

[07:23:08 - 07:23:13]
let's say English guidance you want okay

[07:23:10 - 07:23:14]
from your Mentor but as a mentor wise

[07:23:13 - 07:23:16]
what you want to use you want to use the

[07:23:14 - 07:23:18]
chat GPT let's say your large language

[07:23:16 - 07:23:19]
model that time instead of giving these

[07:23:18 - 07:23:21]
kinds of prompt to the large language

[07:23:19 - 07:23:23]
model what you can give so instead of

[07:23:21 - 07:23:25]
giving the prompt like that you can

[07:23:23 - 07:23:26]
design your own prompt in an effective

[07:23:25 - 07:23:28]
way so let me show you another example

[07:23:26 - 07:23:30]
so guys as you can see this is the next

[07:23:28 - 07:23:32]
prompt I have designed so here is the

[07:23:30 - 07:23:35]
problem guys I want you to act as a

[07:23:32 - 07:23:37]
spoken English teacher I will speak to

[07:23:35 - 07:23:39]
you in English and you will also reply

[07:23:37 - 07:23:42]
to me in English to practice my spoken

[07:23:39 - 07:23:45]
English I want you to keep your reply NE

[07:23:42 - 07:23:47]
uh limiting the reply to 100 words I

[07:23:45 - 07:23:50]
want you to strictly correct my grammar

[07:23:47 - 07:23:53]
mistakes and and typos I want you to ask

[07:23:50 - 07:23:55]
me questions in your reply now let's

[07:23:53 - 07:23:58]
start practicing you could ask me a

[07:23:55 - 07:24:00]
question first remember I want you to

[07:23:58 - 07:24:03]
strictly correct my grammar and mistakes

[07:24:00 - 07:24:04]
uh typos and factual errors okay so this

[07:24:03 - 07:24:06]
is the prompt I have designed okay see

[07:24:04 - 07:24:07]
previously The Prompt I have given it

[07:24:06 - 07:24:09]
was like very straightforward prompt I

[07:24:07 - 07:24:12]
had given right but now what I did I

[07:24:09 - 07:24:14]
just designed one very powerful prompt

[07:24:12 - 07:24:15]
here now see what should be the response

[07:24:14 - 07:24:17]
from my large language model right now

[07:24:15 - 07:24:18]
so let me give this prompt to my large

[07:24:17 - 07:24:22]
language model this is the prompt guys

[07:24:18 - 07:24:22]
the same prompt I have given now let me

[07:24:24 - 07:24:29]
send now see it is giving me great let's

[07:24:26 - 07:24:31]
start with a question what is the most

[07:24:29 - 07:24:35]
interesting place you have ever visited

[07:24:31 - 07:24:37]
and why did you uh did you find it uh so

[07:24:35 - 07:24:40]
fascinating okay now let me give the

[07:24:37 - 07:24:44]
answer let's say the most interesting

[07:24:40 - 07:24:47]
place I visited India

[07:24:44 - 07:24:49]
because I

[07:24:47 - 07:24:54]
loved

[07:24:49 - 07:24:57]
Indian okay Indian

[07:24:54 - 07:24:59]
food Indian food okay now you can also

[07:24:57 - 07:25:02]
do some grammatical mistake let's say

[07:24:59 - 07:25:03]
here I'll just write like that okay now

[07:25:02 - 07:25:05]
let's say this is my response I have

[07:25:03 - 07:25:08]
given to my uh model right now see my

[07:25:05 - 07:25:10]
model will try to correct first of all

[07:25:08 - 07:25:12]
you can see here is the correct version

[07:25:10 - 07:25:15]
the most interesting place I have

[07:25:12 - 07:25:17]
visited in India because I love the

[07:25:15 - 07:25:19]
Indian food now see the reply you have

[07:25:17 - 07:25:21]
given so there actually lots of spelling

[07:25:19 - 07:25:22]
mistakes were there there are lots of

[07:25:21 - 07:25:24]
actually grammatical mistakes were there

[07:25:22 - 07:25:26]
now it has corrected everything now as a

[07:25:24 - 07:25:28]
learn that you can easily get to know

[07:25:26 - 07:25:31]
okay so that's how actually you have to

[07:25:28 - 07:25:32]
uh write this particular sentence okay

[07:25:31 - 07:25:34]
now you don't need any kinds of actual

[07:25:32 - 07:25:36]
actually English teacher okay with the

[07:25:34 - 07:25:38]
help of this kinds of large language

[07:25:36 - 07:25:41]
model you can easily learn this kinds of

[07:25:38 - 07:25:43]
syntax yes or no fine now again it is

[07:25:41 - 07:25:45]
you can see it is asking me one question

[07:25:43 - 07:25:48]
can you tell me more about your favorite

[07:25:45 - 07:25:49]
Indian dish that means now this

[07:25:48 - 07:25:51]
conversation is like more interactive

[07:25:49 - 07:25:54]
it's not like straightforward answer it

[07:25:51 - 07:25:56]
is giving me it is like more interactive

[07:25:54 - 07:25:59]
the way actually human communicate with

[07:25:56 - 07:26:02]
each other yes or no now yes I can give

[07:25:59 - 07:26:06]
another response so here I can give

[07:26:02 - 07:26:09]
um I loved CH

[07:26:06 - 07:26:11]
uh V okay now let's see the output so

[07:26:09 - 07:26:15]
here is the correct version I love CH V

[07:26:11 - 07:26:16]
what do you like most about CH V okay so

[07:26:15 - 07:26:20]
here I can

[07:26:16 - 07:26:22]
write the Puri now see this is the

[07:26:20 - 07:26:25]
correct version I like the Puri uh what

[07:26:22 - 07:26:27]
do you enjoy about the Puri okay now see

[07:26:25 - 07:26:30]
this conversation is more interactive

[07:26:27 - 07:26:32]
now you can um just keep on replying uh

[07:26:30 - 07:26:33]
to the question actually uh this model

[07:26:32 - 07:26:35]
is asking that's actually you'll be

[07:26:33 - 07:26:36]
learning about the correct let's say

[07:26:35 - 07:26:39]
grammar correct let's say spelling and

[07:26:36 - 07:26:43]
all yes or no now see with the help of

[07:26:39 - 07:26:44]
just only one simple prom design I got

[07:26:43 - 07:26:46]
like very interactive output from my

[07:26:44 - 07:26:47]
large language model okay this is called

[07:26:46 - 07:26:49]
actually prompt engineering and that's

[07:26:47 - 07:26:51]
why it's useful okay that's why it is

[07:26:49 - 07:26:53]
important because sometimes whenever

[07:26:51 - 07:26:55]
you'll be creating any kinds of

[07:26:53 - 07:26:57]
application any kinds of LM PR

[07:26:55 - 07:27:00]
application that time you have to design

[07:26:57 - 07:27:02]
The Prompt in such a way so that it can

[07:27:00 - 07:27:03]
give the correct answer to the audience

[07:27:02 - 07:27:05]
even it can it can be more interactive

[07:27:03 - 07:27:07]
to the audience that means those who are

[07:27:05 - 07:27:09]
using your application so they should

[07:27:07 - 07:27:11]
enjoy your application yes or no so guys

[07:27:09 - 07:27:13]
that is why it's like very interesting

[07:27:11 - 07:27:14]
concept and it's like very important

[07:27:13 - 07:27:16]
concept inside gener B you have to

[07:27:14 - 07:27:18]
master now see to master the prompt

[07:27:16 - 07:27:21]
engineering the first thing you should

[07:27:18 - 07:27:22]
know about the Linguistics okay what is

[07:27:21 - 07:27:25]
linguistics Linguistics is nothing but

[07:27:22 - 07:27:27]
it's a study of language that means

[07:27:25 - 07:27:28]
whenever let's say you are uh studying

[07:27:27 - 07:27:30]
any kinds of language let's say English

[07:27:28 - 07:27:32]
Language inside English language you are

[07:27:30 - 07:27:33]
having some kinds of uh let's say

[07:27:32 - 07:27:36]
Linguistics okay what kinds of

[07:27:33 - 07:27:38]
linguistics you can see uh phonetics is

[07:27:36 - 07:27:42]
there so phonetics means the study of

[07:27:38 - 07:27:43]
how speech sounds are produced and

[07:27:42 - 07:27:46]
perceived okay then there is another one

[07:27:43 - 07:27:48]
called phology the study of sounds

[07:27:46 - 07:27:50]
pattern and changes that means whenever

[07:27:48 - 07:27:54]
we are speaking any kinds of let's say

[07:27:50 - 07:27:55]
language like how these sounds look like

[07:27:54 - 07:27:56]
okay how this sounds look like how

[07:27:55 - 07:27:58]
you're pronouncing this particular word

[07:27:56 - 07:28:00]
and all this is called actually

[07:27:58 - 07:28:02]
phonetics and phology

[07:28:00 - 07:28:04]
got it then there is another one called

[07:28:02 - 07:28:06]
morphology the study of word structure

[07:28:04 - 07:28:07]
then there there is another one called

[07:28:06 - 07:28:09]
syntax that means the study of the

[07:28:07 - 07:28:11]
sentence structure that means whatever

[07:28:09 - 07:28:13]
grammar you usually learn inside English

[07:28:11 - 07:28:14]
then you have also having the semantics

[07:28:13 - 07:28:16]
that means the study of the linguistic

[07:28:14 - 07:28:18]
meaning then the next one is pragmatics

[07:28:16 - 07:28:20]
the study of how language is used in the

[07:28:18 - 07:28:23]
context then historical the study of

[07:28:20 - 07:28:25]
language change then so on okay you can

[07:28:23 - 07:28:27]
see these are the actually Linguistics

[07:28:25 - 07:28:29]
are available to study about the

[07:28:27 - 07:28:30]
language okay and if you have good

[07:28:29 - 07:28:32]
knowledge if you have good knowledge on

[07:28:30 - 07:28:34]
these kinds of let's say Linguistics

[07:28:32 - 07:28:36]
definitely you can design a very good

[07:28:34 - 07:28:38]
promt for the large language model so

[07:28:36 - 07:28:40]
that's why I have written here

[07:28:38 - 07:28:41]
Linguistics are the key to the prompt

[07:28:40 - 07:28:43]
engineering that means if you are having

[07:28:41 - 07:28:45]
good knowledge about linguistic

[07:28:43 - 07:28:48]
definitely you can design a good prompt

[07:28:45 - 07:28:50]
for the large language model now we have

[07:28:48 - 07:28:52]
already studied about like large

[07:28:50 - 07:28:53]
language model or our generative a model

[07:28:52 - 07:28:55]
right so there are different kinds of

[07:28:53 - 07:28:58]
generative AI models are available like

[07:28:55 - 07:29:02]
GPT Bart then Lambda Palm Bloom Lama

[07:28:58 - 07:29:04]
cloudy okay then uh Nemo llm okay

[07:29:02 - 07:29:05]
generate so these are the actually apart

[07:29:04 - 07:29:06]
from that like there are so many large

[07:29:05 - 07:29:08]
language models are available I think I

[07:29:06 - 07:29:10]
showed you one GitHub right I think you

[07:29:08 - 07:29:11]
remember open llm GitHub there I think

[07:29:10 - 07:29:13]
you saw thousands of large language

[07:29:11 - 07:29:15]
model were there and these are the

[07:29:13 - 07:29:16]
provider and brander okay like those who

[07:29:15 - 07:29:18]
are created this these are the actually

[07:29:16 - 07:29:21]
large language model see all kinds of

[07:29:18 - 07:29:23]
large language model over the internet

[07:29:21 - 07:29:24]
all the large language model accept this

[07:29:23 - 07:29:26]
prompt okay that means you have to give

[07:29:24 - 07:29:28]
the promt there if you want to use this

[07:29:26 - 07:29:29]
kinds of large language model okay

[07:29:28 - 07:29:31]
because this large language model is

[07:29:29 - 07:29:35]
already trained with huge amount of data

[07:29:31 - 07:29:36]
huge amount of unstructured data even

[07:29:35 - 07:29:38]
they also did something called

[07:29:36 - 07:29:40]
supervised fine tuning they also applied

[07:29:38 - 07:29:42]
something called reinforcement learning

[07:29:40 - 07:29:45]
technique to improve the quality of the

[07:29:42 - 07:29:46]
model that means this model is also

[07:29:45 - 07:29:48]
trained with the instruction lots of

[07:29:46 - 07:29:50]
instruction that means they did the chat

[07:29:48 - 07:29:52]
operation with this model I think I

[07:29:50 - 07:29:54]
showed you one uh in one video one of my

[07:29:52 - 07:29:56]
video I already explained how chat GPT

[07:29:54 - 07:29:58]
train okay so that's why whenever they

[07:29:56 - 07:29:59]
train with this kinds of instruction

[07:29:58 - 07:30:01]
data that means they are passing the

[07:29:59 - 07:30:03]
prompt and whenever you want to use this

[07:30:01 - 07:30:05]
particular model you also need to

[07:30:03 - 07:30:07]
provide the prompt I think now it is

[07:30:05 - 07:30:08]
clear why this prompt engineering is

[07:30:07 - 07:30:10]
super important and whenever you want to

[07:30:08 - 07:30:12]
use any kinds of large language model

[07:30:10 - 07:30:13]
why you have to use the prompt

[07:30:12 - 07:30:15]
engineering technique that means why you

[07:30:13 - 07:30:17]
have to give the correct prompt always

[07:30:15 - 07:30:19]
to the large language model now let's

[07:30:17 - 07:30:20]
learn about some best practices to

[07:30:19 - 07:30:23]
design a prompt see if you want to

[07:30:20 - 07:30:25]
design some best prompt for the large

[07:30:23 - 07:30:27]
language model you have to keep some of

[07:30:25 - 07:30:29]
the point in your mind let's say the

[07:30:27 - 07:30:30]
first thing clear instruction definitely

[07:30:29 - 07:30:33]
you have to give the clear instruction

[07:30:30 - 07:30:35]
to the large language model then adopt a

[07:30:33 - 07:30:37]
Persona then specify the format avoid

[07:30:35 - 07:30:38]
leading the answer and limit the scope

[07:30:37 - 07:30:40]
okay so these are the thing actually you

[07:30:38 - 07:30:42]
have to always remember now let's open

[07:30:40 - 07:30:44]
our CH gbt and let's try to see some of

[07:30:42 - 07:30:45]
the best practices okay we can perform

[07:30:44 - 07:30:47]
whenever we're giving any kind of prompt

[07:30:45 - 07:30:49]
to the large language model so guys

[07:30:47 - 07:30:53]
let's say if I give a prompt here let's

[07:30:49 - 07:30:53]
say I'll give when is

[07:30:54 - 07:30:57]
the

[07:30:58 - 07:31:02]
election okay when is the election let's

[07:31:00 - 07:31:04]
say this is my prompt okay now see if I

[07:31:02 - 07:31:06]
pass this prompt to my large language

[07:31:04 - 07:31:08]
model let's see the output it depends on

[07:31:06 - 07:31:11]
which election you are referring see

[07:31:08 - 07:31:13]
election can uh be vary by the country

[07:31:11 - 07:31:16]
definitely because it's the correct one

[07:31:13 - 07:31:17]
now you are asking what is the election

[07:31:16 - 07:31:19]
but you are not clarifying okay you are

[07:31:17 - 07:31:21]
not clarifying in which country you are

[07:31:19 - 07:31:23]
referring okay that means you have to

[07:31:21 - 07:31:25]
always pass a clear prompt okay clear

[07:31:23 - 07:31:27]
instruction to the large language model

[07:31:25 - 07:31:30]
now see I can give this prompt like that

[07:31:27 - 07:31:33]
when is the

[07:31:30 - 07:31:33]
next

[07:31:34 - 07:31:40]
president

[07:31:36 - 07:31:43]
election in USA okay now see this prompt

[07:31:40 - 07:31:47]
is clear and it is like well organized

[07:31:43 - 07:31:47]
for my large language model now see if I

[07:31:47 - 07:31:51]
pass now see this is the answer the next

[07:31:49 - 07:31:56]
US president election election is

[07:31:51 - 07:31:58]
scheduled for the November 5th uh 2024

[07:31:56 - 07:32:00]
okay now I'm getting the correct answer

[07:31:58 - 07:32:01]
from my large language model but

[07:32:00 - 07:32:03]
whenever you are not giving any kinds of

[07:32:01 - 07:32:04]
clear let's say clear let's instruction

[07:32:03 - 07:32:07]
to the model it will give you

[07:32:04 - 07:32:08]
unnecessary output and again it's a

[07:32:07 - 07:32:11]
chargeable because whenever you are

[07:32:08 - 07:32:13]
using Char GPT or let's say uh any kinds

[07:32:11 - 07:32:14]
of let's say commercial large language

[07:32:13 - 07:32:16]
model It is charging based on the token

[07:32:14 - 07:32:18]
input and output token I already showed

[07:32:16 - 07:32:20]
you okay how it will count the token and

[07:32:18 - 07:32:21]
how it will charge so whenever you are

[07:32:20 - 07:32:23]
getting these kinds of unnecessary

[07:32:21 - 07:32:25]
output that means unnecessary you are

[07:32:23 - 07:32:26]
spending your money yes or no okay so

[07:32:25 - 07:32:27]
that's why whenever you are using these

[07:32:26 - 07:32:30]
kinds of commercial large language model

[07:32:27 - 07:32:32]
make sure you have the proper promp

[07:32:30 - 07:32:34]
so that in just one prompt you will get

[07:32:32 - 07:32:35]
the actual output you are looking for

[07:32:34 - 07:32:37]
okay this is what actually you have to

[07:32:35 - 07:32:41]
always remembered now let me give you

[07:32:37 - 07:32:44]
another example I'll just write write a

[07:32:41 - 07:32:44]
code to

[07:32:45 - 07:32:51]
filter

[07:32:47 - 07:32:53]
out the ages from data so let's say this

[07:32:51 - 07:32:55]
is my prompt I have

[07:32:53 - 07:32:58]
given now

[07:32:55 - 07:33:00]
see my llm model has given me this this

[07:32:58 - 07:33:02]
is the output but let's say you are

[07:33:00 - 07:33:04]
looking for Java code you are looking

[07:33:02 - 07:33:06]
for Java code but it has given you the

[07:33:04 - 07:33:09]
python code again what you have given

[07:33:06 - 07:33:11]
you have given actually uncleared

[07:33:09 - 07:33:13]
instruction to the model yes or no right

[07:33:11 - 07:33:14]
so you have to give the clear

[07:33:13 - 07:33:17]
instruction always now you can write

[07:33:14 - 07:33:17]
this prompt like

[07:33:17 - 07:33:23]
that uh write

[07:33:20 - 07:33:26]
a Java code okay to filter out edges

[07:33:23 - 07:33:27]
from the data now see now it is the

[07:33:26 - 07:33:30]
clear instruction to my large language

[07:33:27 - 07:33:32]
model now I will get the Java code now

[07:33:30 - 07:33:33]
let's see the next one like the add of

[07:33:32 - 07:33:35]
the Persona okay like uh what is the

[07:33:33 - 07:33:37]
Persona exactly whenever you are giving

[07:33:35 - 07:33:39]
any kinds of let's instruction to the

[07:33:37 - 07:33:40]
model uh what kinds of persona you have

[07:33:39 - 07:33:42]
to add up there let's say this is one

[07:33:40 - 07:33:44]
prompt I'm giving to my large language

[07:33:42 - 07:33:47]
model write a poem for a sister's High

[07:33:44 - 07:33:49]
School uh graduation that will be read

[07:33:47 - 07:33:50]
out to the uh to family and close

[07:33:49 - 07:33:52]
friends okay let's say this is my

[07:33:50 - 07:33:54]
instruction I have given to my large

[07:33:52 - 07:33:57]
language model now see uh here is the

[07:33:54 - 07:33:59]
response I will

[07:33:57 - 07:34:01]
get so here is the response I got that

[07:33:59 - 07:34:03]
that means this is my poem now if you

[07:34:01 - 07:34:06]
read this poem actually this is not

[07:34:03 - 07:34:08]
actually much interesting the poem

[07:34:06 - 07:34:10]
actually I was looking for now what you

[07:34:08 - 07:34:12]
can do you can actually uh give the

[07:34:10 - 07:34:14]
Persona okay you can give the Persona

[07:34:12 - 07:34:15]
whenever you are giving the prompt so

[07:34:14 - 07:34:17]
now let me show you another prompt I

[07:34:15 - 07:34:20]
have design for this so This Is The

[07:34:17 - 07:34:23]
Prompt guys now here I'm writing write a

[07:34:20 - 07:34:26]
poem as Helena Helena is a 25 years old

[07:34:23 - 07:34:30]
and amazing writer her writing style

[07:34:26 - 07:34:33]
similar to the famous uh 21st century

[07:34:30 - 07:34:35]
poet uh rupik cor so I think you know

[07:34:33 - 07:34:38]
about rupik cor you can also search

[07:34:35 - 07:34:40]
about rupik see she is the actually

[07:34:38 - 07:34:43]
Canadian poet and illustrator okay you

[07:34:40 - 07:34:45]
can read about her now see write as a

[07:34:43 - 07:34:49]
Helena writing as a Helena write a poem

[07:34:45 - 07:34:50]
for her uh 18 years old old sister to

[07:34:49 - 07:34:52]
celebrate her sister's High School

[07:34:50 - 07:34:55]
graduation this will be read out to the

[07:34:52 - 07:34:57]
friends and family at the uh Gathering

[07:34:55 - 07:34:59]
okay now see this is the prompt actually

[07:34:57 - 07:35:01]
have given now see if I send it uh if I

[07:34:59 - 07:35:03]
this prompt right now now see the

[07:35:01 - 07:35:05]
response actually I got here now if you

[07:35:03 - 07:35:07]
read this poem actually it is too good

[07:35:05 - 07:35:09]
it is too good than my previous response

[07:35:07 - 07:35:11]
I got okay so that's how actually you

[07:35:09 - 07:35:13]
have to adapt the Persona always you

[07:35:11 - 07:35:15]
have to adapt the Persona what kinds of

[07:35:13 - 07:35:17]
things you are looking for now see this

[07:35:15 - 07:35:19]
large language model is already know

[07:35:17 - 07:35:21]
about rupic cor okay because it is

[07:35:19 - 07:35:25]
already trained it is already trained uh

[07:35:21 - 07:35:27]
let's say around 2022 data okay till

[07:35:25 - 07:35:28]
2022 data it has already return and in

[07:35:27 - 07:35:32]
that data actually rupik or poem was

[07:35:28 - 07:35:34]
there okay that's why you that's why so

[07:35:32 - 07:35:37]
that's why this model is already known

[07:35:34 - 07:35:40]
about rupic cord and it is trying to get

[07:35:37 - 07:35:43]
the similar kinds of let's say

[07:35:40 - 07:35:46]
poetry okay whatever let's say poem

[07:35:43 - 07:35:48]
actually rupik used to write okay the

[07:35:46 - 07:35:51]
same actually syntax context actually is

[07:35:48 - 07:35:53]
trying to Let's gain now the next thing

[07:35:51 - 07:35:55]
you can also specify the format let's

[07:35:53 - 07:35:57]
say what kinds of format you want as a

[07:35:55 - 07:35:58]
output let's say what I will do I will

[07:35:57 - 07:36:01]
give you one example for the

[07:35:58 - 07:36:03]
summarization let's copy one English

[07:36:01 - 07:36:04]
story here so let's say this is one

[07:36:03 - 07:36:07]
English story I'll just try to copy the

[07:36:04 - 07:36:07]
entire

[07:36:07 - 07:36:16]
story and here I'll go to my chat GPT

[07:36:10 - 07:36:16]
and I'll just write uh please

[07:36:17 - 07:36:22]
summarize this

[07:36:20 - 07:36:24]
story okay summarize this story now I

[07:36:22 - 07:36:28]
can pass the entire story

[07:36:24 - 07:36:30]
here now see I can send it now see it is

[07:36:28 - 07:36:32]
giving me the summary but see this

[07:36:30 - 07:36:34]
summary again it's a paragraph okay it's

[07:36:32 - 07:36:38]
a paragraph now I can also specify the

[07:36:34 - 07:36:38]
format let's say I'll give I

[07:36:39 - 07:36:43]
want I think I can copy the same

[07:36:48 - 07:36:53]
instruction now here just try to modify

[07:36:51 - 07:36:59]
please summarize this

[07:36:53 - 07:36:59]
story in bullet point okay

[07:36:59 - 07:37:04]
bullet point now see I'm specifying the

[07:37:01 - 07:37:05]
format now see if I pass this now see it

[07:37:04 - 07:37:07]
will give me inside the bullet point

[07:37:05 - 07:37:10]
okay now see it's like more readable now

[07:37:07 - 07:37:12]
it's more readable it is giving me uh

[07:37:10 - 07:37:14]
some actually important uh important

[07:37:12 - 07:37:16]
actually summary of this entire story it

[07:37:14 - 07:37:17]
is trying to return me okay so that's

[07:37:16 - 07:37:20]
how you can provide any kinds of format

[07:37:17 - 07:37:22]
you need let's say you need a data and

[07:37:20 - 07:37:25]
you need a juston format data you can

[07:37:22 - 07:37:26]
also provide I need a juston format data

[07:37:25 - 07:37:28]
okay you can pass the prompt and it will

[07:37:26 - 07:37:29]
give you that so that's how actually

[07:37:28 - 07:37:31]
whenever you are designing your prom you

[07:37:29 - 07:37:33]
have to always keep these are the point

[07:37:31 - 07:37:35]
in your mind okay the point actually I

[07:37:33 - 07:37:37]
listed down in my presentation I think

[07:37:35 - 07:37:40]
you saw that right now there are some

[07:37:37 - 07:37:42]
types of prompt are available uh so the

[07:37:40 - 07:37:44]
first type you can consider zero short

[07:37:42 - 07:37:46]
prompting and the second type actually

[07:37:44 - 07:37:49]
few short prompting apart from that

[07:37:46 - 07:37:50]
actually there are like some types of

[07:37:49 - 07:37:52]
prompts are available like emotional

[07:37:50 - 07:37:53]
prompting and all right but this is not

[07:37:52 - 07:37:54]
actually required but if you want to

[07:37:53 - 07:37:57]
create any large language powered

[07:37:54 - 07:37:59]
application so this two prompt actually

[07:37:57 - 07:38:01]
very famous so I have seen like people

[07:37:59 - 07:38:03]
are using this to prompt a lot like few

[07:38:01 - 07:38:05]
shot prompting and zero shot prompting

[07:38:03 - 07:38:07]
so let's explore this zero shot and few

[07:38:05 - 07:38:10]
shot prompting uh in the example so

[07:38:07 - 07:38:11]
again I will go to my CH gbt now first

[07:38:10 - 07:38:12]
of all let's write the zero shot

[07:38:11 - 07:38:15]
prompting zero shot prompting means you

[07:38:12 - 07:38:16]
are only asking the instruction because

[07:38:15 - 07:38:18]
the see this Char GPT is already trained

[07:38:16 - 07:38:21]
with huge amount of data so this Char

[07:38:18 - 07:38:23]
GPT has already like lots of knowledge

[07:38:21 - 07:38:24]
about let's say the data over the

[07:38:23 - 07:38:26]
whatever data they have trained now

[07:38:24 - 07:38:31]
let's say I will ask one question when

[07:38:26 - 07:38:31]
is the Christmas in

[07:38:31 - 07:38:38]
America now see Christmas United States

[07:38:34 - 07:38:40]
celebrated on December uh 25th each each

[07:38:38 - 07:38:41]
year okay now it is giving me the answer

[07:38:40 - 07:38:43]
so this is called actually zero shot

[07:38:41 - 07:38:44]
prompting that means you have only give

[07:38:43 - 07:38:45]
one prompt okay one prompt that means

[07:38:44 - 07:38:48]
the instruction you have given the

[07:38:45 - 07:38:52]
question you have given okay but let's

[07:38:48 - 07:38:54]
say if I ask these kinds of

[07:38:52 - 07:38:56]
question now let's see if I ask this

[07:38:54 - 07:38:59]
kind some question what

[07:38:56 - 07:39:03]
is BU

[07:38:59 - 07:39:03]
favorite types

[07:39:03 - 07:39:09]
of food okay let's say this is the

[07:39:06 - 07:39:11]
question I have given now see it will

[07:39:09 - 07:39:12]
give you I don't have the information

[07:39:11 - 07:39:14]
about buy favorite types of food could

[07:39:12 - 07:39:18]
you please provide more details clarify

[07:39:14 - 07:39:19]
who is buy okay now see here actually uh

[07:39:18 - 07:39:21]
zero short prompting is not working so

[07:39:19 - 07:39:23]
here you have to pass the few short

[07:39:21 - 07:39:25]
prompting that time okay now see here

[07:39:23 - 07:39:30]
I'll give a prompt now I'll just write

[07:39:25 - 07:39:35]
buies buy is a

[07:39:30 - 07:39:38]
data scientist and his favorite types

[07:39:35 - 07:39:43]
of food are or you can write uh food

[07:39:38 - 07:39:47]
includes let's say burgers burgers

[07:39:43 - 07:39:47]
Pizza okay and

[07:39:47 - 07:39:52]
chicken now I can pass this prom to my

[07:39:50 - 07:39:54]
large language model now it will learn

[07:39:52 - 07:39:56]
about me okay because I have given a few

[07:39:54 - 07:39:58]
short prompt here okay now see got it

[07:39:56 - 07:40:00]
puppy uh s types of foods are Burger

[07:39:58 - 07:40:02]
pizza chicken and if you need any more

[07:40:00 - 07:40:04]
details or have a questions just let me

[07:40:02 - 07:40:06]
know now here I can give another prompt

[07:40:04 - 07:40:07]
what is the or I can write what

[07:40:06 - 07:40:09]
restaurant now let's say this is the

[07:40:07 - 07:40:13]
prompt I have given what restaurant

[07:40:09 - 07:40:14]
should I take buy uh to in Dubai this

[07:40:13 - 07:40:16]
weekend okay now see if I

[07:40:14 - 07:40:19]
pass now see it will suggest me some

[07:40:16 - 07:40:22]
restaurant Dubai has fantastic range of

[07:40:19 - 07:40:24]
restaurant that CS a vity of test since

[07:40:22 - 07:40:27]
buy like barers piz and chicken here is

[07:40:24 - 07:40:28]
the few recommendation so here is the

[07:40:27 - 07:40:29]
restaurant now see this is called

[07:40:28 - 07:40:32]
actually few short from that means you

[07:40:29 - 07:40:34]
are also giving some few short prom that

[07:40:32 - 07:40:36]
means some some let's say information

[07:40:34 - 07:40:38]
information about the question you are

[07:40:36 - 07:40:39]
asking okay this is called actually F

[07:40:38 - 07:40:42]
short prompting so these are the thing

[07:40:39 - 07:40:44]
guys you have to master so uh see this

[07:40:42 - 07:40:45]
prompt engineering will come

[07:40:44 - 07:40:47]
automatically whenever you will be

[07:40:45 - 07:40:48]
writing these kinds of prompt so unless

[07:40:47 - 07:40:50]
and until you are not writing you are

[07:40:48 - 07:40:51]
not experimenting you won't be able to

[07:40:50 - 07:40:53]
understand okay which prompt will give

[07:40:51 - 07:40:55]
you what kinds of output so try to

[07:40:53 - 07:40:56]
practice a lot okay you have the chat

[07:40:55 - 07:40:58]
gbt you can give different different

[07:40:56 - 07:41:00]
prompts and you can get the response

[07:40:58 - 07:41:01]
from the chat gbt and the prompt

[07:41:00 - 07:41:03]
actually you're giving to the CH the

[07:41:01 - 07:41:05]
same prompt you can use to any kinds of

[07:41:03 - 07:41:07]
large language model OKAY in future

[07:41:05 - 07:41:09]
you'll be using whether it's a let's G

[07:41:07 - 07:41:11]
whether it's let's Mistral Falcon

[07:41:09 - 07:41:13]
whatever let's say your model are using

[07:41:11 - 07:41:16]
you can use it as it is fine now there

[07:41:13 - 07:41:17]
is another concept inside actually

[07:41:16 - 07:41:19]
generative AI model called AI

[07:41:17 - 07:41:21]
hallucination now what is an AI

[07:41:19 - 07:41:23]
hallucination see AI Hallucination is

[07:41:21 - 07:41:25]
when a large language model generates

[07:41:23 - 07:41:26]
false information that means let's say

[07:41:25 - 07:41:29]
you are giving a prompt and that model

[07:41:26 - 07:41:31]
is giving you the false information

[07:41:29 - 07:41:33]
okay so this is called actually AI

[07:41:31 - 07:41:34]
hallucination that means the prompt you

[07:41:33 - 07:41:36]
are asking the information you're asking

[07:41:34 - 07:41:38]
this information is not available to the

[07:41:36 - 07:41:40]
large language model okay so that time

[07:41:38 - 07:41:42]
what we have to do if we are getting

[07:41:40 - 07:41:43]
this kinds of alation so that time we

[07:41:42 - 07:41:44]
can use something called rag concept

[07:41:43 - 07:41:46]
that means retrieval augmented

[07:41:44 - 07:41:47]
generation that means we can connect our

[07:41:46 - 07:41:50]
external data source to my large

[07:41:47 - 07:41:52]
language model okay and from that data

[07:41:50 - 07:41:54]
sources my model can learn okay this is

[07:41:52 - 07:41:56]
the information uh you are looking for

[07:41:54 - 07:41:57]
and if rag is not working that time what

[07:41:56 - 07:41:59]
we can perform we can perform something

[07:41:57 - 07:42:00]
called fine tuning of a large language

[07:41:59 - 07:42:02]
mod model I think I showed you now we

[07:42:00 - 07:42:04]
can perform fine tuning with the help of

[07:42:02 - 07:42:06]
hugging face okay so I'll also show you

[07:42:04 - 07:42:07]
how we can fine tune different kinds of

[07:42:06 - 07:42:09]
large language model on top of our

[07:42:07 - 07:42:11]
custom data we can also perform F tune

[07:42:09 - 07:42:14]
operation but fine tune is a costly task

[07:42:11 - 07:42:16]
because here you need a good system like

[07:42:14 - 07:42:18]
lots of lots of data okay so again it's

[07:42:16 - 07:42:20]
like very costly task but rag

[07:42:18 - 07:42:21]
application is a very easy kinds of task

[07:42:20 - 07:42:22]
see here you don't need lots of cost

[07:42:21 - 07:42:24]
here you don't need lots of

[07:42:22 - 07:42:26]
computational power okay so both we'll

[07:42:24 - 07:42:28]
be exploring one by one like what is uh

[07:42:26 - 07:42:30]
rag concept and what is let's say fine

[07:42:28 - 07:42:32]
tuning concept will be exploring okay so

[07:42:30 - 07:42:34]
yes guys this is all about our prompt

[07:42:32 - 07:42:36]
engineering now I think you got it why

[07:42:34 - 07:42:37]
prompt engineering is super important

[07:42:36 - 07:42:39]
and how you can Master this kinds of

[07:42:37 - 07:42:41]
prompt engineering technique okay it's

[07:42:39 - 07:42:43]
nothing but it just a way of let's say

[07:42:41 - 07:42:44]
communicating with your large language

[07:42:43 - 07:42:45]
model the input you are giving to the

[07:42:44 - 07:42:47]
large language model this is called

[07:42:45 - 07:42:48]
actually prompt okay and the way you are

[07:42:47 - 07:42:49]
designing this particular prompt this is

[07:42:48 - 07:42:52]
called prompt engineering okay I hope it

[07:42:49 - 07:42:53]
is clear now see if you want to learn if

[07:42:52 - 07:42:54]
you want to master Genera VII if you

[07:42:53 - 07:42:56]
want to work with the large language

[07:42:54 - 07:42:58]
model so this is super important concept

[07:42:56 - 07:43:00]
you have to first of all master and uh

[07:42:58 - 07:43:01]
this this is called actually Vector

[07:43:00 - 07:43:02]
database because see whatever let's say

[07:43:01 - 07:43:04]
data you will be using whatever

[07:43:02 - 07:43:06]
documents you will be using let's say to

[07:43:04 - 07:43:07]
work with your large language model so

[07:43:06 - 07:43:09]
first of all what you have to do you

[07:43:07 - 07:43:10]
have to convert the documents to the

[07:43:09 - 07:43:11]
embedding representation I think I

[07:43:10 - 07:43:13]
already explained like what is

[07:43:11 - 07:43:15]
embeddings right so my model can take

[07:43:13 - 07:43:17]
the English input directly so for this I

[07:43:15 - 07:43:19]
have to uh create some number okay that

[07:43:17 - 07:43:20]
means I have to generate the embeddings

[07:43:19 - 07:43:22]
I have to generate some vector and after

[07:43:20 - 07:43:24]
generating these kinds of embedding and

[07:43:22 - 07:43:26]
Vector uh we have to store these are the

[07:43:24 - 07:43:28]
vector to a databases uh because I have

[07:43:26 - 07:43:30]
to connect my large language model with

[07:43:28 - 07:43:32]
these kinds of databases okay so this is

[07:43:30 - 07:43:34]
called actually Vector databases okay I

[07:43:32 - 07:43:35]
hope it is clear now so no need to worry

[07:43:34 - 07:43:36]
I will give you the entire idea of this

[07:43:35 - 07:43:38]
Vector database like what Vector

[07:43:36 - 07:43:40]
database is even I will also show you

[07:43:38 - 07:43:41]
the different different practical uh

[07:43:40 - 07:43:43]
with different different Vector

[07:43:41 - 07:43:45]
databases so here we'll be covering

[07:43:43 - 07:43:46]
almost all the famous Vector databases

[07:43:45 - 07:43:47]
whatever let's say people are using

[07:43:46 - 07:43:50]
broadly in the market we'll be covering

[07:43:47 - 07:43:52]
all of them no need to worry and guys to

[07:43:50 - 07:43:54]
show you this Vector database demo I'll

[07:43:52 - 07:43:56]
be using one framework called langen so

[07:43:54 - 07:43:57]
langen is a genbi framework with the

[07:43:56 - 07:43:59]
help of langen actually we can build

[07:43:57 - 07:44:00]
different different genbi based

[07:43:59 - 07:44:02]
application because inside langin

[07:44:00 - 07:44:04]
actually all kinds of vector database

[07:44:02 - 07:44:06]
functionality are already available okay

[07:44:04 - 07:44:08]
so that's why I'm going to use langen uh

[07:44:06 - 07:44:10]
throughout the entire let's say series

[07:44:08 - 07:44:11]
of this Vector database but if you're

[07:44:10 - 07:44:13]
not familiar with langin no need to

[07:44:11 - 07:44:15]
worry go through this tutorial and try

[07:44:13 - 07:44:16]
to implement whatever things I'm

[07:44:15 - 07:44:18]
implementing so after this Vector

[07:44:16 - 07:44:20]
database series I will start the

[07:44:18 - 07:44:22]
complete langen series as well so there

[07:44:20 - 07:44:24]
actually we'll be uh starting from very

[07:44:22 - 07:44:25]
basics of the lch even we'll be covering

[07:44:24 - 07:44:27]
till Advanced part of the lch okay we'll

[07:44:25 - 07:44:30]
be learning each and everything as of

[07:44:27 - 07:44:31]
now let's say as a code wise just try to

[07:44:30 - 07:44:32]
understand okay what are the

[07:44:31 - 07:44:34]
functionality actually I'm using from

[07:44:32 - 07:44:36]
the Lang chin and try to implement with

[07:44:34 - 07:44:37]
me and make sure whenever I'll be

[07:44:36 - 07:44:39]
installing any kinds of package on my

[07:44:37 - 07:44:41]
collab notebook try to see the version

[07:44:39 - 07:44:43]
okay try to see the version of that

[07:44:41 - 07:44:44]
package because uh today actually I'm

[07:44:43 - 07:44:46]
creating the video I know that because

[07:44:44 - 07:44:47]
this is a completely research field so

[07:44:46 - 07:44:49]
some of the functionality they will

[07:44:47 - 07:44:51]
change in their package and then you

[07:44:49 - 07:44:52]
will uh get some issue okay you might

[07:44:51 - 07:44:54]
get some issue you might get some error

[07:44:52 - 07:44:56]
so make sure whatever let's say version

[07:44:54 - 07:44:58]
I'm installing on my notebook try to

[07:44:56 - 07:44:59]
also install the same version and if I'm

[07:44:58 - 07:45:01]
not mentioning the version okay with the

[07:44:59 - 07:45:03]
package what you can do so whenever I

[07:45:01 - 07:45:05]
will show you the installation uh Below

[07:45:03 - 07:45:06]
in the console you will see the version

[07:45:05 - 07:45:08]
okay like what is the L chain version

[07:45:06 - 07:45:10]
what is the openi version what is the

[07:45:08 - 07:45:11]
let's say Vector database version okay

[07:45:10 - 07:45:13]
just try to see the version try to just

[07:45:11 - 07:45:15]
note it down and try to install the same

[07:45:13 - 07:45:17]
version it will work because see it's a

[07:45:15 - 07:45:19]
completely resource field every day they

[07:45:17 - 07:45:21]
are updating their package and all so I

[07:45:19 - 07:45:22]
know that if you're learning something

[07:45:21 - 07:45:23]
today so tomorrow actually they will

[07:45:22 - 07:45:25]
update that package and you might get

[07:45:23 - 07:45:26]
some issue okay so that's why I'm

[07:45:25 - 07:45:29]
telling you guys always try to use one a

[07:45:26 - 07:45:30]
specific version okay uh if you're using

[07:45:29 - 07:45:32]
a specific version so you won't be

[07:45:30 - 07:45:34]
having any kinds of issue because you

[07:45:32 - 07:45:35]
know that this version will work fine

[07:45:34 - 07:45:37]
okay the code you have implemented so

[07:45:35 - 07:45:39]
that's why just try to see the version

[07:45:37 - 07:45:40]
whatever version I'm installing uh see

[07:45:39 - 07:45:42]
the console console of that collab

[07:45:40 - 07:45:43]
notebook there actually you will see all

[07:45:42 - 07:45:45]
the version has been written okay for

[07:45:43 - 07:45:47]
all the package so note it down and try

[07:45:45 - 07:45:49]
to install the same version now let's

[07:45:47 - 07:45:51]
try to see what the topic actually we be

[07:45:49 - 07:45:53]
covering uh through this Vector database

[07:45:51 - 07:45:54]
Series so guys as you can see uh here

[07:45:53 - 07:45:56]
first of all we'll be learning about

[07:45:54 - 07:45:57]
Vector database like the in detail

[07:45:56 - 07:45:59]
explanation of the vector database what

[07:45:57 - 07:46:00]
is Vector database how it is work work

[07:45:59 - 07:46:01]
and all everything we'll be learning

[07:46:00 - 07:46:03]
then we'll see that why we need the

[07:46:01 - 07:46:05]
vector database how Vector database

[07:46:03 - 07:46:07]
Works use cases of the vector database

[07:46:05 - 07:46:08]
then some weedly used Vector database

[07:46:07 - 07:46:10]
we'll be also learning then at the last

[07:46:08 - 07:46:11]
of the series actually we'll be also

[07:46:10 - 07:46:13]
doing the Practical demo with the help

[07:46:11 - 07:46:14]
of python and langen as I already told

[07:46:13 - 07:46:16]
you we'll be using langen framework to

[07:46:14 - 07:46:18]
work with the vector database okay now

[07:46:16 - 07:46:20]
let's try to see what is Vector database

[07:46:18 - 07:46:21]
is see Vector database nothing but a

[07:46:20 - 07:46:24]
vector database is a database used for

[07:46:21 - 07:46:26]
storing High dimensional Vector such as

[07:46:24 - 07:46:28]
uh word embeddings or image embeddings

[07:46:26 - 07:46:31]
so I think you already know that uh we

[07:46:28 - 07:46:33]
are lots of unstructured data and higher

[07:46:31 - 07:46:36]
dimensional data like documents image

[07:46:33 - 07:46:38]
PDF okay then we are also having audios

[07:46:36 - 07:46:39]
videos and so on right so this is called

[07:46:38 - 07:46:42]
actually unstructured High dimensional

[07:46:39 - 07:46:43]
data so what we have to do inside Vector

[07:46:42 - 07:46:45]
database concept we just need to first

[07:46:43 - 07:46:46]
of all convert desert the higher

[07:46:45 - 07:46:48]
dimensional documents to the higher

[07:46:46 - 07:46:49]
dimensional Vector you can see we are

[07:46:48 - 07:46:51]
converting this documents to a vector

[07:46:49 - 07:46:53]
representation and this Vector actually

[07:46:51 - 07:46:55]
we restoring to the database and this is

[07:46:53 - 07:46:56]
called actually Vector database okay

[07:46:55 - 07:46:58]
that is why here I have written a vector

[07:46:56 - 07:47:00]
database is a database used for storing

[07:46:58 - 07:47:01]
High dimensional Vector such as word

[07:47:00 - 07:47:02]
embeddings as well as the image

[07:47:01 - 07:47:04]
embeddings because I think you already

[07:47:02 - 07:47:06]
know that inside generative VI we are

[07:47:04 - 07:47:08]
having textual data as well as the image

[07:47:06 - 07:47:10]
kinds of data that means video data

[07:47:08 - 07:47:11]
audio data and so on right so that is

[07:47:10 - 07:47:12]
why you can consider any kinds of data

[07:47:11 - 07:47:14]
and whenever you're considering any

[07:47:12 - 07:47:15]
kinds of data it will have some

[07:47:14 - 07:47:17]
embeddings and that particular embedding

[07:47:15 - 07:47:19]
you have to save to the vector database

[07:47:17 - 07:47:21]
so this is the introduction of vector

[07:47:19 - 07:47:23]
database I think it is clear now you can

[07:47:21 - 07:47:25]
ask me like why we need these kinds of

[07:47:23 - 07:47:27]
vector database because we have lots of

[07:47:25 - 07:47:29]
existing database are available in the

[07:47:27 - 07:47:31]
market now uh to give you the answer

[07:47:29 - 07:47:32]
actually uh I want to show you one

[07:47:31 - 07:47:34]
example so first of all let's see like

[07:47:32 - 07:47:37]
uh why we need these kinds of vector

[07:47:34 - 07:47:40]
database uh because if you see over like

[07:47:37 - 07:47:42]
80 to 85% data out there is unstructured

[07:47:40 - 07:47:44]
data like we have images we have videos

[07:47:42 - 07:47:46]
we have text and we have audios okay so

[07:47:44 - 07:47:48]
these are the data actually unstructured

[07:47:46 - 07:47:50]
data so we can't uh easily store these

[07:47:48 - 07:47:52]
kinds of unstructured data to the

[07:47:50 - 07:47:54]
relational database or let's say our

[07:47:52 - 07:47:56]
traditional database like we have my SQL

[07:47:54 - 07:47:59]
then we have postre SQL then we have uh

[07:47:56 - 07:48:00]
sqlite so these are actually relational

[07:47:59 - 07:48:02]
database and these are actually

[07:48:00 - 07:48:03]
traditional database so we can directly

[07:48:02 - 07:48:05]
store these are the data so we can

[07:48:03 - 07:48:07]
directly store our unstructured data

[07:48:05 - 07:48:09]
through these kinds of relational or

[07:48:07 - 07:48:10]
traditional database okay why we can't

[07:48:09 - 07:48:12]
store I will uh show you one example it

[07:48:10 - 07:48:14]
would be very much clear so guys to give

[07:48:12 - 07:48:16]
you one example let's take one image

[07:48:14 - 07:48:18]
data as an example so let's say I want

[07:48:16 - 07:48:20]
to store uh these kinds of dog images to

[07:48:18 - 07:48:22]
our relational or our traditional

[07:48:20 - 07:48:24]
database so if I want to store it I can

[07:48:22 - 07:48:26]
directly store these are the data to our

[07:48:24 - 07:48:28]
uh relational database okay so if I want

[07:48:26 - 07:48:30]
to store it so what I need to do I need

[07:48:28 - 07:48:33]
to create some of the schema let's say I

[07:48:30 - 07:48:36]
have some schema here I have some table

[07:48:33 - 07:48:37]
so in this table let's say I have one

[07:48:36 - 07:48:40]
column called

[07:48:37 - 07:48:44]
animal okay

[07:48:40 - 07:48:47]
animal then I have another column called

[07:48:44 - 07:48:48]
color okay then I have another column

[07:48:47 - 07:48:51]
called

[07:48:48 - 07:48:53]
Tags so basically you need to manually

[07:48:51 - 07:48:55]
label them uh to store these are the

[07:48:53 - 07:48:57]
images okay if you want to identify a

[07:48:55 - 07:48:58]
similar kinds of images if you want to

[07:48:57 - 07:49:00]
apply the query on top of that then then

[07:48:58 - 07:49:02]
you need to uh create this kinds of

[07:49:00 - 07:49:04]
schema manually now here uh you just

[07:49:02 - 07:49:07]
need to set those parameter manually

[07:49:04 - 07:49:10]
let's say animal wise it's a

[07:49:07 - 07:49:13]
dog okay it's a dog then color-wise

[07:49:10 - 07:49:14]
let's say it's black or let's say I can

[07:49:13 - 07:49:17]
and color-wise you can give any color

[07:49:14 - 07:49:20]
let's say golden okay this is the golden

[07:49:17 - 07:49:23]
uh dog golden dog then we have let's say

[07:49:20 - 07:49:25]
black dog as well okay black dog you can

[07:49:23 - 07:49:26]
give anything based on your image

[07:49:25 - 07:49:28]
actually you are trying to store then

[07:49:26 - 07:49:31]
you also need to assign some of the T

[07:49:28 - 07:49:31]
let's say this is very

[07:49:32 - 07:49:38]
cute um let's say this dog has black

[07:49:36 - 07:49:41]
eyes Okay black

[07:49:38 - 07:49:43]
eyes so these are the tags actually

[07:49:41 - 07:49:45]
we'll be assigning uh manually so what

[07:49:43 - 07:49:47]
happens actually so whenever you assign

[07:49:45 - 07:49:49]
these kinds of schema manually so what

[07:49:47 - 07:49:51]
happens let's say you want to uh query

[07:49:49 - 07:49:52]
uh the similar images okay from the

[07:49:51 - 07:49:54]
database so you just give these are the

[07:49:52 - 07:49:57]
parameters so it will return these are

[07:49:54 - 07:49:58]
the image for you okay based on the tags

[07:49:57 - 07:50:00]
actually you have written based on the

[07:49:58 - 07:50:02]
schema you have prepared right but again

[07:50:00 - 07:50:04]
it's a manual thing okay it's not a

[07:50:02 - 07:50:06]
efficient way to uh store our data and

[07:50:04 - 07:50:09]
it's not a efficient way to like query

[07:50:06 - 07:50:10]
out our data because let's say I want

[07:50:09 - 07:50:12]
similar kinds of image so I need to

[07:50:10 - 07:50:15]
assign these at the labels manually and

[07:50:12 - 07:50:17]
it's like very uh hard task for us right

[07:50:15 - 07:50:19]
so that's why actually we can't use our

[07:50:17 - 07:50:21]
traditional or let's say relational

[07:50:19 - 07:50:23]
database for these kinds of unstructured

[07:50:21 - 07:50:24]
data we can easily use this kinds of

[07:50:23 - 07:50:26]
relational database for the structured

[07:50:24 - 07:50:29]
data let's say we have CSV data we have

[07:50:26 - 07:50:30]
uh Excel data but for this kinds of

[07:50:29 - 07:50:32]
unstructured data it's like very much

[07:50:30 - 07:50:34]
difficult to store these kinds of data

[07:50:32 - 07:50:36]
right you can store them uh there is no

[07:50:34 - 07:50:38]
issue but uh the thing is like whenever

[07:50:36 - 07:50:40]
you will be quing out uh from your

[07:50:38 - 07:50:42]
database let's say you want similar

[07:50:40 - 07:50:44]
kinds of dog images at the time it would

[07:50:42 - 07:50:46]
be very much difficult because if I

[07:50:44 - 07:50:49]
let's say convert this image to Bas 64

[07:50:46 - 07:50:51]
string so using B 64 string I can easily

[07:50:49 - 07:50:53]
store the data to the relational

[07:50:51 - 07:50:55]
database but I'm talking about whenever

[07:50:53 - 07:50:56]
let's say you are applying query on top

[07:50:55 - 07:50:58]
of that let's say you want similar kinds

[07:50:56 - 07:51:00]
of dog images from this database at that

[07:50:58 - 07:51:02]
time it would be very much difficult for

[07:51:00 - 07:51:04]
you to quering out because because it

[07:51:02 - 07:51:06]
doesn't know like whether this best 64

[07:51:04 - 07:51:07]
string is a dog image or let's say it's

[07:51:06 - 07:51:09]
a cat image or let's say it's a horse

[07:51:07 - 07:51:11]
image okay it doesn't know so there is

[07:51:09 - 07:51:13]
only one option to uh filter out these

[07:51:11 - 07:51:15]
kinds of images uh the thing is like you

[07:51:13 - 07:51:17]
need to create one manual schema like

[07:51:15 - 07:51:19]
these kinds of tags you need to generate

[07:51:17 - 07:51:20]
you need to label out these are the

[07:51:19 - 07:51:22]
images uh using that actually you can

[07:51:20 - 07:51:24]
filter out these kinds of data but again

[07:51:22 - 07:51:25]
it would be very hard approach uh as I

[07:51:24 - 07:51:28]
already told you because you need to

[07:51:25 - 07:51:30]
apply manual observation here now guys I

[07:51:28 - 07:51:31]
I think you already got the idea like

[07:51:30 - 07:51:33]
why it is difficult to store these kinds

[07:51:31 - 07:51:35]
of unstructured data to the uh

[07:51:33 - 07:51:37]
relational database because as you can

[07:51:35 - 07:51:39]
see image is nothing but it's a pixel

[07:51:37 - 07:51:41]
and your relational database doesn't

[07:51:39 - 07:51:43]
ever know like how to query out similar

[07:51:41 - 07:51:45]
kinds of images using these kinds of

[07:51:43 - 07:51:47]
pixel right so guys this is the one

[07:51:45 - 07:51:49]
major problem uh with these kinds of

[07:51:47 - 07:51:51]
relational database uh whenever we are

[07:51:49 - 07:51:53]
using unstructured kinds of data so guys

[07:51:51 - 07:51:55]
whenever I'm talking about unstructured

[07:51:53 - 07:51:57]
data it is not only image data so it can

[07:51:55 - 07:51:59]
be video data it can be Text data and it

[07:51:57 - 07:52:01]
can be audio data as well so guys to

[07:51:59 - 07:52:02]
overcome this issue uh there is a

[07:52:01 - 07:52:03]
concept introduced called Vector

[07:52:02 - 07:52:05]
embedding so let's say we have

[07:52:03 - 07:52:07]
unstructured data let's say we have

[07:52:05 - 07:52:09]
image we have a text and we have audios

[07:52:07 - 07:52:11]
and it can be also videos so first of

[07:52:09 - 07:52:13]
all what we need to do we need to apply

[07:52:11 - 07:52:14]
something called embedding model okay so

[07:52:13 - 07:52:16]
embedding model is nothing but it's a

[07:52:14 - 07:52:18]
neural network based model it's a deep

[07:52:16 - 07:52:19]
learning model so using this embedding

[07:52:18 - 07:52:21]
model first of all you will be

[07:52:19 - 07:52:22]
generating some of the embeddings or

[07:52:21 - 07:52:25]
let's say vectors okay let's say this is

[07:52:22 - 07:52:27]
my image we have applied embedding model

[07:52:25 - 07:52:28]
embedding model will give you vectors

[07:52:27 - 07:52:30]
okay like this is the represent ation of

[07:52:28 - 07:52:32]
the image okay this is the numerical

[07:52:30 - 07:52:34]
representation of this image it can be

[07:52:32 - 07:52:36]
also applied to the text data so you see

[07:52:34 - 07:52:38]
here I'm giving the text Data uh and

[07:52:36 - 07:52:40]
this is my embedding model and it is

[07:52:38 - 07:52:43]
returning these kinds of vector again uh

[07:52:40 - 07:52:45]
you can also put audio data so it will

[07:52:43 - 07:52:47]
convert to the numerical representation

[07:52:45 - 07:52:49]
and this is the representation of the

[07:52:47 - 07:52:50]
audio so here if you see embedding model

[07:52:49 - 07:52:52]
is nothing but it's a neural network

[07:52:50 - 07:52:54]
based model here you can use any kinds

[07:52:52 - 07:52:55]
of embedding model let's say we have

[07:52:54 - 07:52:57]
what toake then we have Transformer

[07:52:55 - 07:52:58]
based embedding model as well right so

[07:52:57 - 07:52:59]
these are the things actually you can

[07:52:58 - 07:53:01]
use so if you're already familiar with

[07:52:59 - 07:53:02]
NLP that means natural language

[07:53:01 - 07:53:04]
processing I think you have heard of

[07:53:02 - 07:53:06]
like what to V then you have heard of

[07:53:04 - 07:53:09]
like Transformer embeddings okay and uh

[07:53:06 - 07:53:11]
nowadays actually we have large language

[07:53:09 - 07:53:14]
model based embeddings like we have open

[07:53:11 - 07:53:16]
a embeddings we have uh lots of Open

[07:53:14 - 07:53:18]
Source llm based embeddings as well we

[07:53:16 - 07:53:19]
have hugging face embeddings as well so

[07:53:18 - 07:53:20]
using these kinds of embedding model we

[07:53:19 - 07:53:22]
can easily generate these kinds of

[07:53:20 - 07:53:24]
vectors and we can store them in a

[07:53:22 - 07:53:25]
vector database so guys this is the

[07:53:24 - 07:53:27]
entire idea uh on top of this

[07:53:25 - 07:53:29]
unstructured data like how we can store

[07:53:27 - 07:53:31]
these kinds of un structured data to the

[07:53:29 - 07:53:32]
vector database so first of all uh what

[07:53:31 - 07:53:34]
we are doing we are just trying to

[07:53:32 - 07:53:37]
convert these are the unstructured data

[07:53:34 - 07:53:38]
uh to the vectors Vector representation

[07:53:37 - 07:53:41]
then we are uh storing these are the

[07:53:38 - 07:53:42]
vectors okay to the vector database so

[07:53:41 - 07:53:44]
guys here is an example you can see so

[07:53:42 - 07:53:46]
let's say we have a text unstructured

[07:53:44 - 07:53:48]
data and here you can use any kinds of

[07:53:46 - 07:53:50]
embedding model so in this case actually

[07:53:48 - 07:53:52]
I have referred this uh open a embedding

[07:53:50 - 07:53:55]
model so it is already trained on GPT

[07:53:52 - 07:53:56]
model okay gpt3 and four model and if

[07:53:55 - 07:53:58]
you put these kinds of unstructured data

[07:53:56 - 07:54:00]
to the embedding model it will you these

[07:53:58 - 07:54:02]
kinds of vector okay this kinds of

[07:54:00 - 07:54:04]
vector representation of all the text

[07:54:02 - 07:54:05]
actually you have in the documents then

[07:54:04 - 07:54:07]
once you got this Vector actually this

[07:54:05 - 07:54:10]
Vector embedding then you will be using

[07:54:07 - 07:54:12]
some uh uh Vector database it can be

[07:54:10 - 07:54:14]
anything any database you can use so

[07:54:12 - 07:54:16]
here you can store one by one these are

[07:54:14 - 07:54:17]
the data okay so this is the complete

[07:54:16 - 07:54:19]
idea of this Vector database like uh

[07:54:17 - 07:54:21]
instead of directly storing our Text

[07:54:19 - 07:54:23]
data to the database first of all what

[07:54:21 - 07:54:25]
we are doing we are taking help from the

[07:54:23 - 07:54:26]
embedding model uh and using the

[07:54:25 - 07:54:27]
embedding model we are trying to

[07:54:26 - 07:54:29]
generating these kinds of vector

[07:54:27 - 07:54:31]
embeddings then restoring this kinds of

[07:54:29 - 07:54:32]
vector embeddings to the vector database

[07:54:31 - 07:54:34]
and guys this kinds of vector database

[07:54:32 - 07:54:36]
has one beautiful function called

[07:54:34 - 07:54:37]
similarity SE so using this similarity

[07:54:36 - 07:54:40]
sech functionality it can return return

[07:54:37 - 07:54:41]
you similar kinds of vector represented

[07:54:40 - 07:54:43]
in the vector database okay I will show

[07:54:41 - 07:54:45]
you this similarity search as an example

[07:54:43 - 07:54:47]
like how it is uh doing actually simil

[07:54:45 - 07:54:49]
search now guys you got to know like

[07:54:47 - 07:54:51]
what is embedding uh but you don't know

[07:54:49 - 07:54:53]
like how these embeddings are generated

[07:54:51 - 07:54:54]
so to give you one example I will open

[07:54:53 - 07:54:56]
my whiteboard and there I will try to

[07:54:54 - 07:54:58]
make you understand so guys I'm inside

[07:54:56 - 07:55:00]
my whiteboard and here first first of

[07:54:58 - 07:55:04]
all what I will do uh I will take one

[07:55:00 - 07:55:05]
pan and here I'll be using U

[07:55:04 - 07:55:08]
unstructured

[07:55:05 - 07:55:08]
data unst

[07:55:09 - 07:55:15]
structure unstructured data as a text

[07:55:13 - 07:55:19]
Data here I'll be using Text data to

[07:55:15 - 07:55:21]
give you the example so so first of all

[07:55:19 - 07:55:24]
what I will do uh let's create one table

[07:55:21 - 07:55:26]
here so let me create one table uh so

[07:55:24 - 07:55:28]
guys let's say I have taken one table

[07:55:26 - 07:55:30]
here so here uh we are using one

[07:55:28 - 07:55:32]
embedding model so let's say we are

[07:55:30 - 07:55:32]
using

[07:55:34 - 07:55:39]
one embedding

[07:55:36 - 07:55:41]
model to convert our uh text to numbers

[07:55:39 - 07:55:43]
so here you can use any kinds of

[07:55:41 - 07:55:45]
embedding model you can use open a based

[07:55:43 - 07:55:47]
you can use uh what to F you can use

[07:55:45 - 07:55:50]
like uh large language model based you

[07:55:47 - 07:55:53]
can use anything here okay now whenever

[07:55:50 - 07:55:55]
uh let's say I have some wordss here so

[07:55:53 - 07:56:00]
let's say I have something called

[07:55:55 - 07:56:02]
King then I have something called Queen

[07:56:00 - 07:56:05]
then I have something called

[07:56:02 - 07:56:08]
men and I have something called

[07:56:05 - 07:56:11]
women then I have some uh let's say

[07:56:08 - 07:56:13]
monkey so let's say I have five words

[07:56:11 - 07:56:15]
here now what this uh embedding model

[07:56:13 - 07:56:17]
will do it will try to uh generate some

[07:56:15 - 07:56:20]
of the features on top of the words okay

[07:56:17 - 07:56:23]
let's say this is my feature

[07:56:20 - 07:56:25]
column features column okay so what

[07:56:23 - 07:56:29]
kinds of features actually uh it will

[07:56:25 - 07:56:30]
generate let's say it can generate um

[07:56:29 - 07:56:32]
it can generate anything let's say it

[07:56:30 - 07:56:32]
can generate

[07:56:33 - 07:56:36]
gender it can generate

[07:56:37 - 07:56:41]
wealth it can generate

[07:56:39 - 07:56:43]
power because this is a neural network

[07:56:41 - 07:56:44]
based model we can't say like what are

[07:56:43 - 07:56:47]
the features actually uh it will

[07:56:44 - 07:56:49]
generate because U it it will generate

[07:56:47 - 07:56:50]
these are the features based on the back

[07:56:49 - 07:56:52]
propagation so it will calculate the

[07:56:50 - 07:56:54]
loss and all based on that actually it

[07:56:52 - 07:56:56]
will try to uh find out the best

[07:56:54 - 07:56:58]
possible features okay for these kinds

[07:56:56 - 07:56:59]
of work so here I'm just giving my

[07:56:58 - 07:57:02]
example that's why I'm taking these are

[07:56:59 - 07:57:03]
the features okay but it might not like

[07:57:02 - 07:57:05]
generate these are the features but to

[07:57:03 - 07:57:06]
give you one example I will be using

[07:57:05 - 07:57:10]
these are the features now let's say it

[07:57:06 - 07:57:12]
will uh generate

[07:57:10 - 07:57:15]
weight and it can also generate

[07:57:12 - 07:57:16]
something called speak okay now what

[07:57:15 - 07:57:18]
happens actually based on the features

[07:57:16 - 07:57:20]
actually it will assign some of the

[07:57:18 - 07:57:23]
value let's say let's say here uh my

[07:57:20 - 07:57:25]
first word is King okay now King has

[07:57:23 - 07:57:27]
gender or not yeah King has gender and

[07:57:25 - 07:57:31]
the gender is like male so it would be

[07:57:27 - 07:57:33]
one and for Queen uh yeah Queen has also

[07:57:31 - 07:57:35]
gender so it would be zero because Queen

[07:57:33 - 07:57:39]
is a female so similar wise man man has

[07:57:35 - 07:57:41]
a gender so it will have one and women

[07:57:39 - 07:57:43]
also has gender so it would be zero

[07:57:41 - 07:57:45]
because it's a female and monkey uh

[07:57:43 - 07:57:48]
let's say it's a male monkey so I'll

[07:57:45 - 07:57:50]
assign at one okay now it will come to

[07:57:48 - 07:57:52]
the next features called wealth okay now

[07:57:50 - 07:57:54]
here and here you can see King has

[07:57:52 - 07:57:55]
wealth right because he's the king and

[07:57:54 - 07:57:58]
he has lots of wealth so it would be

[07:57:55 - 07:58:01]
let's say one I'll assign it as one uh

[07:57:58 - 07:58:03]
Queen will also have wealth because

[07:58:01 - 07:58:05]
Queen is also part of King and uh man

[07:58:03 - 07:58:07]
will also have wealth but it would be

[07:58:05 - 07:58:08]
less than king and queen so let's uh

[07:58:07 - 07:58:11]
assign as

[07:58:08 - 07:58:14]
0.5 and women will have also wealth but

[07:58:11 - 07:58:16]
less than man so here I can give 0.3

[07:58:14 - 07:58:18]
monkey doesn't have any wealth so I'll

[07:58:16 - 07:58:21]
give as zero okay now King has power so

[07:58:18 - 07:58:24]
I'll give one Queen has also power but

[07:58:21 - 07:58:27]
less than King so I'll give 0.7 man has

[07:58:24 - 07:58:30]
also power let's say man has power but

[07:58:27 - 07:58:32]
it's less than King so I'll give as 0.5

[07:58:30 - 07:58:34]
women has also power but it's less than

[07:58:32 - 07:58:36]
man so it would be 0.2 and monkey uh

[07:58:34 - 07:58:39]
doesn't have any power so I'll give as

[07:58:36 - 07:58:40]
zero now weight yeah King has also

[07:58:39 - 07:58:43]
weight so I'll give

[07:58:40 - 07:58:46]
0.8 and let's say king is little bit

[07:58:43 - 07:58:49]
obese uh Queen has also weight so I'll

[07:58:46 - 07:58:53]
give as 0.5 because let's say queen is

[07:58:49 - 07:58:54]
Slim and all man has also weight so I'll

[07:58:53 - 07:58:57]
uh give it as

[07:58:54 - 07:58:59]
0.7 women has also we I'll give 0 point

[07:58:57 - 07:59:02]
um

[07:58:59 - 07:59:04]
uh 0.5 weight is fine I think monkey

[07:59:02 - 07:59:06]
also has weight let's say 0.3 now King

[07:59:04 - 07:59:09]
can speak so I'll give one Queen can

[07:59:06 - 07:59:12]
also skip speak I'll give one man can

[07:59:09 - 07:59:15]
also speak I will give one women can

[07:59:12 - 07:59:17]
also skip uh speak I'll give one and

[07:59:15 - 07:59:20]
monkey doesn't uh speak okay so I'll

[07:59:17 - 07:59:21]
give as zero okay now see guys

[07:59:20 - 07:59:24]
beautifully it has generated these are

[07:59:21 - 07:59:26]
the vectors okay uh by generating these

[07:59:24 - 07:59:28]
are the features

[07:59:26 - 07:59:31]
now let's see if I want to represent

[07:59:28 - 07:59:34]
King okay if I want to represent King so

[07:59:31 - 07:59:36]
what would be my king Vector so here

[07:59:34 - 07:59:40]
this is your king Vector so King Vector

[07:59:36 - 07:59:44]
is nothing but 1 1 1

[07:59:40 - 07:59:47]
0.8 uh one so this is the king Vector

[07:59:44 - 07:59:47]
now if I want to represent

[07:59:47 - 07:59:55]
Queen so this is my queen

[07:59:50 - 07:59:56]
Vector so Queen Vector would be 0 1 uh

[07:59:55 - 07:59:58]
then

[07:59:56 - 08:00:01]
0.7 0.5

[07:59:58 - 08:00:06]
and one okay now if I want to represent

[08:00:01 - 08:00:08]
man so this is the man Vector so one

[08:00:06 - 08:00:11]
0.5

[08:00:08 - 08:00:14]
0.7 and 1 okay now let's say if I want

[08:00:11 - 08:00:16]
to represent

[08:00:14 - 08:00:18]
women okay I think you are getting it

[08:00:16 - 08:00:20]
like how uh we have generated these are

[08:00:18 - 08:00:27]
the vector now this is the vector of the

[08:00:20 - 08:00:31]
women so 0o uh 0.3 0 0.3 and 0.2 0.5 and

[08:00:27 - 08:00:32]
1 okay now let's take one 2D Dimension

[08:00:31 - 08:00:34]
okay and plot these are the vector and

[08:00:32 - 08:00:37]
try to understand like what will happen

[08:00:34 - 08:00:39]
so let's say here I will take one two

[08:00:37 - 08:00:42]
dimensional uh space so let's say this

[08:00:39 - 08:00:42]
is

[08:00:43 - 08:00:47]
my two dimensional space okay so this is

[08:00:45 - 08:00:50]
my

[08:00:47 - 08:00:53]
X and this is my

[08:00:50 - 08:00:55]
y so if you plot all the vector here

[08:00:53 - 08:00:58]
okay if you plot all the vector here you

[08:00:55 - 08:01:03]
will see King

[08:00:58 - 08:01:07]
and uh queen king and queen will

[08:01:03 - 08:01:09]
appear uh to the similar so here let's

[08:01:07 - 08:01:12]
say this is my

[08:01:09 - 08:01:14]
king and this is my queen okay so what

[08:01:12 - 08:01:15]
will happen uh whenever you will plot

[08:01:14 - 08:01:17]
these are the vector to the two

[08:01:15 - 08:01:18]
dimensional space or let's say three

[08:01:17 - 08:01:21]
dimensional or any Dimension okay you

[08:01:18 - 08:01:22]
will see king and queen will appear uh

[08:01:21 - 08:01:25]
like very close together because if you

[08:01:22 - 08:01:27]
see here okay if you see here as per the

[08:01:25 - 08:01:28]
features if you calculate the number if

[08:01:27 - 08:01:31]
you calculate distance between these are

[08:01:28 - 08:01:33]
the vector you will see this distance

[08:01:31 - 08:01:35]
would be like very less okay that's why

[08:01:33 - 08:01:39]
king and queen would be appearing very

[08:01:35 - 08:01:43]
closely together and here man and women

[08:01:39 - 08:01:46]
let's say this is my man man vector and

[08:01:43 - 08:01:48]
this is my women okay this is my woman

[08:01:46 - 08:01:50]
so these two Vector would be uh

[08:01:48 - 08:01:52]
appearing closely and here if you see

[08:01:50 - 08:01:56]
here uh there is another Vector called

[08:01:52 - 08:01:58]
monkey okay monkey will

[08:01:56 - 08:02:00]
appear uh completely

[08:01:58 - 08:02:01]
different from these are the vector

[08:02:00 - 08:02:03]
because monkey is a different different

[08:02:01 - 08:02:07]
entity here so let's say this is my

[08:02:03 - 08:02:09]
monkey okay now if I show you see so it

[08:02:07 - 08:02:12]
has buil one cluster so this this is one

[08:02:09 - 08:02:14]
cluster this is another

[08:02:12 - 08:02:17]
cluster and this is another cluster okay

[08:02:14 - 08:02:20]
now if you see here uh using this

[08:02:17 - 08:02:22]
concept called Vector embeddings uh we

[08:02:20 - 08:02:24]
are easily getting these are the

[08:02:22 - 08:02:27]
similarity score okay similarity Vector

[08:02:24 - 08:02:29]
so now if I want to extract any kind of

[08:02:27 - 08:02:30]
vector okay let let's say I want Queen

[08:02:29 - 08:02:32]
okay I want Queen so it will go to the

[08:02:30 - 08:02:34]
this cluster and will return this vector

[08:02:32 - 08:02:36]
and let's say not only Queen let's say

[08:02:34 - 08:02:37]
it would be let's say I want something

[08:02:36 - 08:02:40]
called Princess okay I want something

[08:02:37 - 08:02:42]
called Princess Vector so what what will

[08:02:40 - 08:02:44]
happen it will come in this cluster

[08:02:42 - 08:02:46]
because if you calculate the vectors

[08:02:44 - 08:02:47]
okay of the princess you will see it

[08:02:46 - 08:02:49]
will have these are the features okay it

[08:02:47 - 08:02:52]
will have these are the features related

[08:02:49 - 08:02:54]
to the king and queen okay so now this

[08:02:52 - 08:02:56]
princess will appear here so that's how

[08:02:54 - 08:02:58]
actually this uh embedding model Works

[08:02:56 - 08:02:59]
actually so it will first of all assign

[08:02:58 - 08:03:01]
some of the features based on that it

[08:02:59 - 08:03:03]
will generate these are the vectors and

[08:03:01 - 08:03:05]
it will plot these are the vectors to

[08:03:03 - 08:03:06]
the H High dimensional space so here in

[08:03:05 - 08:03:09]
this case I have taken two dimensional

[08:03:06 - 08:03:11]
space but it might be 3 4 five and so on

[08:03:09 - 08:03:13]
okay based on your dimension of the data

[08:03:11 - 08:03:15]
so whenever I'm using unstructured data

[08:03:13 - 08:03:18]
whenever I'm using U real world data so

[08:03:15 - 08:03:19]
Dimension might be vary okay it might be

[08:03:18 - 08:03:20]
Millions Dimension it might be thousand

[08:03:19 - 08:03:22]
Dimension we can't say like whatever

[08:03:20 - 08:03:25]
Dimension it will have but as a

[08:03:22 - 08:03:27]
visualization we can only show 2D u

[08:03:25 - 08:03:28]
space here okay so this is the complete

[08:03:27 - 08:03:30]
idea guys I think you got it like how

[08:03:28 - 08:03:31]
this embeddings mod model are working

[08:03:30 - 08:03:34]
okay and how it is generating these

[08:03:31 - 08:03:36]
kinds of uh Vector okay now here in this

[08:03:34 - 08:03:39]
case actually you have lots of embedding

[08:03:36 - 08:03:42]
models so we have open AI open AI

[08:03:39 - 08:03:42]
embedding

[08:03:42 - 08:03:49]
model and this model is trained on GPT

[08:03:46 - 08:03:51]
okay GPT model I think you have heard of

[08:03:49 - 08:03:54]
GPT model then we have something called

[08:03:51 - 08:03:54]
hugging

[08:03:54 - 08:03:59]
face hugging face embedding as well

[08:04:00 - 08:04:05]
okay hang face embeding so uh it is

[08:04:03 - 08:04:06]
already trained on let's say lots of

[08:04:05 - 08:04:09]
Open

[08:04:06 - 08:04:12]
Source open source llm okay that means

[08:04:09 - 08:04:16]
large language model then uh we also

[08:04:12 - 08:04:16]
have uh something called uh

[08:04:17 - 08:04:20]
LMA okay Lama to

[08:04:21 - 08:04:26]
embedding I'll be discussing like what

[08:04:23 - 08:04:27]
is Lama 2 and all okay uh as a open

[08:04:26 - 08:04:28]
source model then we have something

[08:04:27 - 08:04:31]
called

[08:04:28 - 08:04:34]
Google uh Google

[08:04:31 - 08:04:36]
Palm

[08:04:34 - 08:04:38]
embedding so these are the open source

[08:04:36 - 08:04:39]
embedding you can directly use so this

[08:04:38 - 08:04:42]
is from

[08:04:39 - 08:04:43]
Facebook Facebook research okay and this

[08:04:42 - 08:04:46]
is from Google

[08:04:43 - 08:04:48]
research okay and this one is paid

[08:04:46 - 08:04:50]
because if you are using open AI uh

[08:04:48 - 08:04:53]
embedding an open model so you need to

[08:04:50 - 08:04:55]
pay this is completely FID and these are

[08:04:53 - 08:04:57]
the things are uh free okay these are

[08:04:55 - 08:04:59]
the things are open source and free but

[08:04:57 - 08:05:02]
to get the Lama to access actually you

[08:04:59 - 08:05:03]
need to uh like uh uh send some

[08:05:02 - 08:05:05]
information then they will give you the

[08:05:03 - 08:05:06]
access I'll tell you like how to take

[08:05:05 - 08:05:08]
this Lama to access and all okay

[08:05:06 - 08:05:09]
everything I'll be discussing about

[08:05:08 - 08:05:10]
don't worry about like just try to stay

[08:05:09 - 08:05:12]
with the video I'll be discussing each

[08:05:10 - 08:05:14]
and everything so guys I hope you got

[08:05:12 - 08:05:16]
the entire idea like how this uh

[08:05:14 - 08:05:18]
embeddings models works okay and how it

[08:05:16 - 08:05:20]
generate these kinds of embeddings as a

[08:05:18 - 08:05:22]
vector right so guys here I kept uh

[08:05:20 - 08:05:24]
another example uh if you just see this

[08:05:22 - 08:05:27]
example uh your concept would be very

[08:05:24 - 08:05:29]
much Clear see here I have uh this kind

[08:05:27 - 08:05:31]
of work okay and we are using these

[08:05:29 - 08:05:33]
kinds of embedding model and we are

[08:05:31 - 08:05:36]
generating these kinds of vectors and if

[08:05:33 - 08:05:37]
we plot these are the vectors to the 2D

[08:05:36 - 08:05:39]
Dimension so it will look like that so

[08:05:37 - 08:05:40]
let's say we have this three word we

[08:05:39 - 08:05:41]
have this three word and we have this

[08:05:40 - 08:05:43]
three word and we are getting different

[08:05:41 - 08:05:45]
different vector and this is the cluster

[08:05:43 - 08:05:48]
okay this is the cluster of each of the

[08:05:45 - 08:05:50]
words if you see here King man uh women

[08:05:48 - 08:05:53]
is appearing in the same cluster then

[08:05:50 - 08:05:55]
apple banana orange is appearing uh to

[08:05:53 - 08:05:57]
the another cluster and football Golf

[08:05:55 - 08:05:59]
and Tennis it's appearing uh in the

[08:05:57 - 08:06:03]
another cluster because uh this is

[08:05:59 - 08:06:04]
related uh to person okay person and

[08:06:03 - 08:06:06]
this is related to fruits and this is

[08:06:04 - 08:06:08]
related to sports okay that's why this

[08:06:06 - 08:06:10]
cluster is different now I think you got

[08:06:08 - 08:06:11]
it the vector embeddings like how this

[08:06:10 - 08:06:13]
Vector embeddings looks like and how it

[08:06:11 - 08:06:16]
is generating okay I have given you the

[08:06:13 - 08:06:18]
entire idea but uh one issue actually uh

[08:06:16 - 08:06:20]
with this Vector embeddings uh which is

[08:06:18 - 08:06:22]
nothing but uh whenever you are uh like

[08:06:20 - 08:06:23]
getting any similar kinds of vector it

[08:06:22 - 08:06:25]
is applying something called distance

[08:06:23 - 08:06:27]
formula I think you have heard of like

[08:06:25 - 08:06:29]
distance formula we have ukle distance

[08:06:27 - 08:06:32]
okay we have Manhattan distance or let

[08:06:29 - 08:06:34]
say we have something called cosine

[08:06:32 - 08:06:36]
similarity score as well okay so using

[08:06:34 - 08:06:38]
these are the equation actually it Tred

[08:06:36 - 08:06:39]
to calculate the similar kinds of vector

[08:06:38 - 08:06:42]
but again if you see here it would be

[08:06:39 - 08:06:44]
very much time-taking because uh it will

[08:06:42 - 08:06:45]
calculate uh with respect to one by one

[08:06:44 - 08:06:48]
all the vector then it will give you uh

[08:06:45 - 08:06:50]
the similar kinds of vector so uh the

[08:06:48 - 08:06:53]
main problem is like the time if you're

[08:06:50 - 08:06:54]
using uh this thing directly so it will

[08:06:53 - 08:06:56]
take lots of time to give you the

[08:06:54 - 08:06:58]
similar kinds of vector so to overcome

[08:06:56 - 08:07:00]
this issue actually they propos

[08:06:58 - 08:07:02]
something called indexes in the vector

[08:07:00 - 08:07:04]
database okay like we call it as Vector

[08:07:02 - 08:07:05]
indexes so what is Vector indexes so

[08:07:04 - 08:07:06]
let's say whenever we are having this

[08:07:05 - 08:07:08]
kinds of unstructured data we are

[08:07:06 - 08:07:09]
applying this kinds of embedding model

[08:07:08 - 08:07:11]
and it is generating this kinds of

[08:07:09 - 08:07:13]
embedding okay so on top of this

[08:07:11 - 08:07:15]
embedding uh where uh what is trying to

[08:07:13 - 08:07:17]
do it is trying to add some kinds of

[08:07:15 - 08:07:19]
indexes okay so this indexes is nothing

[08:07:17 - 08:07:21]
but it's a data structure it's one kinds

[08:07:19 - 08:07:22]
of data structure actually so what it

[08:07:21 - 08:07:24]
will do it will find out similar kinds

[08:07:22 - 08:07:25]
of vector and it will assign some of the

[08:07:24 - 08:07:27]
indexes okay and it will make some

[08:07:25 - 08:07:29]
cluster kinds of thing so when let's say

[08:07:27 - 08:07:31]
you have any new data first of all it

[08:07:29 - 08:07:34]
will see like which uh indexes actually

[08:07:31 - 08:07:36]
lies this data so in that index only it

[08:07:34 - 08:07:38]
will search that query so uh to

[08:07:36 - 08:07:40]
understand this let's say this is my U

[08:07:38 - 08:07:42]
example so first of all let's say it has

[08:07:40 - 08:07:44]
assigned these kinds of indexes now you

[08:07:42 - 08:07:46]
have one new data now first of all it

[08:07:44 - 08:07:48]
will see like which cluster actually

[08:07:46 - 08:07:50]
this this is lies okay so it will go to

[08:07:48 - 08:07:51]
that cluster then it will return the

[08:07:50 - 08:07:53]
similar kinds of vector with respect to

[08:07:51 - 08:07:55]
the uh new data you are giving okay

[08:07:53 - 08:07:57]
instead of searching to all of the

[08:07:55 - 08:07:59]
Clusters so this is the idea of this

[08:07:57 - 08:08:02]
indexes uh in this Vector database now

[08:07:59 - 08:08:04]
uh using uh this indexes uh to our

[08:08:02 - 08:08:05]
Vector database it's like very fast now

[08:08:04 - 08:08:08]
whenever you are asking any kinds of

[08:08:05 - 08:08:10]
query to the vector database and it is

[08:08:08 - 08:08:12]
returning any kinds of vector so this

[08:08:10 - 08:08:13]
process time would be very fast now guys

[08:08:12 - 08:08:16]
I hope you got the entire idea like what

[08:08:13 - 08:08:18]
is uh Vector database and all about and

[08:08:16 - 08:08:19]
what is embeddings and all about now you

[08:08:18 - 08:08:21]
can tell a vector database indexes and

[08:08:19 - 08:08:24]
store Vector embeddings for first

[08:08:21 - 08:08:26]
retrieval and similarity SE uh so we

[08:08:24 - 08:08:27]
used to use our traditional database to

[08:08:26 - 08:08:29]
directly store our data but uh in the

[08:08:27 - 08:08:31]
vector database first of all we try to

[08:08:29 - 08:08:33]
convert as Vector then we try to store

[08:08:31 - 08:08:36]
them to the vector database okay this is

[08:08:33 - 08:08:39]
the complete idea now guys let's uh

[08:08:36 - 08:08:41]
discuss some use cases like U why this

[08:08:39 - 08:08:43]
Vector database is useful like what are

[08:08:41 - 08:08:45]
the use cases are there so as you can

[08:08:43 - 08:08:47]
see uh it will help you the longterm

[08:08:45 - 08:08:49]
memory for the large language model

[08:08:47 - 08:08:51]
because it is uh storing all of the data

[08:08:49 - 08:08:52]
as a vector to the vector database so

[08:08:51 - 08:08:53]
whenever you are connecting these kinds

[08:08:52 - 08:08:56]
of large language model to the vector

[08:08:53 - 08:08:58]
database so it can be uh used as a

[08:08:56 - 08:08:59]
memory okay memory of your large

[08:08:58 - 08:09:02]
language model like long long-term

[08:08:59 - 08:09:03]
memory and it can also perform something

[08:09:02 - 08:09:04]
called semantic search I already told

[08:09:03 - 08:09:07]
you how to perform the semantic search

[08:09:04 - 08:09:09]
using the formula and using the indexes

[08:09:07 - 08:09:10]
and all so s based on the meaning of the

[08:09:09 - 08:09:12]
context let's say if you're giving

[08:09:10 - 08:09:15]
something called let's say king and

[08:09:12 - 08:09:16]
queen so it will uh not only consider

[08:09:15 - 08:09:18]
the text you are giving it will also

[08:09:16 - 08:09:19]
consider the context like what is King

[08:09:18 - 08:09:21]
what are the features of King what is

[08:09:19 - 08:09:23]
the features of Queen based on that it

[08:09:21 - 08:09:25]
will uh give you the S uh similar kinds

[08:09:23 - 08:09:26]
of vector okay as a output then it can

[08:09:25 - 08:09:29]
also perform something called similarity

[08:09:26 - 08:09:31]
S as a already told you like on the text

[08:09:29 - 08:09:33]
data image data video data or let's say

[08:09:31 - 08:09:35]
audio data let's say I have one image

[08:09:33 - 08:09:36]
let's a dog image I will tell hey just

[08:09:35 - 08:09:38]
give me some dog images okay similar

[08:09:36 - 08:09:40]
kinds of dog images so it will uh first

[08:09:38 - 08:09:42]
of all try to see the like vector okay

[08:09:40 - 08:09:44]
similar kinds of vector and it will

[08:09:42 - 08:09:46]
return uh the similar kinds of like

[08:09:44 - 08:09:48]
representation of the dog to you okay so

[08:09:46 - 08:09:50]
we call it as similar uh similar SE then

[08:09:48 - 08:09:52]
it can be also used uh in the field of

[08:09:50 - 08:09:54]
recommendation system uh because as as

[08:09:52 - 08:09:57]
you already saw like if you if you're

[08:09:54 - 08:09:58]
having these kinds of vector together

[08:09:57 - 08:09:59]
and it it can perform similar SE let's

[08:09:58 - 08:10:01]
say I want to build something called

[08:09:59 - 08:10:02]
recommendation system so let's say I'm

[08:10:01 - 08:10:05]
asking

[08:10:02 - 08:10:07]
for like food related content so it will

[08:10:05 - 08:10:09]
uh suggest me food related content only

[08:10:07 - 08:10:11]
okay using these kinds of similar SE and

[08:10:09 - 08:10:13]
all so guys this is the entire idea of

[08:10:11 - 08:10:15]
this Vector database and this is are the

[08:10:13 - 08:10:18]
use cases actually uh you can consider

[08:10:15 - 08:10:20]
okay inside this Vector database so guys

[08:10:18 - 08:10:21]
I think uh so far everything is clear

[08:10:20 - 08:10:23]
now let's try to see some weedly used

[08:10:21 - 08:10:26]
Vector database so you can see we are

[08:10:23 - 08:10:28]
having chroma DB we8 then F so F has

[08:10:26 - 08:10:31]
implemented by Facebook AI then we are

[08:10:28 - 08:10:34]
also having pine cone then Neo 4G neo4j

[08:10:31 - 08:10:36]
is a graph based Vector database okay so

[08:10:34 - 08:10:38]
uh these are actually very common Vector

[08:10:36 - 08:10:39]
database people are using in the market

[08:10:38 - 08:10:41]
and it's like very famous Vector

[08:10:39 - 08:10:43]
database okay in the market right now so

[08:10:41 - 08:10:45]
here we'll be exploring all of them one

[08:10:43 - 08:10:47]
by one so in the next video we'll try to

[08:10:45 - 08:10:48]
see how we can use chroma DB and chroma

[08:10:47 - 08:10:51]
DB is a local Vector database and this

[08:10:48 - 08:10:53]
Pine con wave Neo 4G it's a cloudbase

[08:10:51 - 08:10:55]
vector database okay and here is another

[08:10:53 - 08:10:57]
Vector database you can see f f is also

[08:10:55 - 08:10:59]
a local Vector database that means if

[08:10:57 - 08:11:01]
you want to let's say store your data as

[08:10:59 - 08:11:03]
a locally so what you can do you can use

[08:11:01 - 08:11:05]
chroma DB or F and if you want to store

[08:11:03 - 08:11:07]
them in the cloud you can use pine con

[08:11:05 - 08:11:09]
weate or NE 4J okay now in this video

[08:11:07 - 08:11:11]
actually we'll start with uh one

[08:11:09 - 08:11:13]
practical uh demo that means we'll be

[08:11:11 - 08:11:15]
learning one amazing Vector database

[08:11:13 - 08:11:17]
local Vector database called chroma DB

[08:11:15 - 08:11:19]
you can see chroma DB is a local Vector

[08:11:17 - 08:11:21]
database so they're also bringing the

[08:11:19 - 08:11:23]
hosted version of the Chad DB so you can

[08:11:21 - 08:11:25]
see it is still under development so

[08:11:23 - 08:11:26]
once it is done you will be also able to

[08:11:25 - 08:11:29]
let's say use this chroma DB in the

[08:11:26 - 08:11:31]
Cloud Server as well so as of now if you

[08:11:29 - 08:11:33]
want to store your let's say uh

[08:11:31 - 08:11:34]
embeddings in the local okay that means

[08:11:33 - 08:11:36]
if you want to set up everything in the

[08:11:34 - 08:11:37]
local you can use chroma DB Vector

[08:11:36 - 08:11:39]
database for this so this is the

[08:11:37 - 08:11:41]
documentation of chroma DB guys you can

[08:11:39 - 08:11:42]
see this is the official documentation

[08:11:41 - 08:11:44]
so they have given each and every

[08:11:42 - 08:11:45]
guideline so you can follow this

[08:11:44 - 08:11:48]
documentation like how we can set up and

[08:11:45 - 08:11:50]
all okay so what I will show you guys uh

[08:11:48 - 08:11:51]
I will show you one uh complete

[08:11:50 - 08:11:53]
practical that means we'll be uh

[08:11:51 - 08:11:55]
experimenting this chroma DB on the

[08:11:53 - 08:11:57]
collab notebook okay so guys let's open

[08:11:55 - 08:11:59]
up my collab notebook and let's see how

[08:11:57 - 08:12:01]
we can use this chrom ADB Vector

[08:11:59 - 08:12:03]
database so guys as you can see my

[08:12:01 - 08:12:05]
notebook is connected now if you want to

[08:12:03 - 08:12:06]
test it whether it's working or not just

[08:12:05 - 08:12:07]
write one message here so I'll just

[08:12:06 - 08:12:15]
write

[08:12:07 - 08:12:17]
print uh okay so it should uh yeah so

[08:12:15 - 08:12:20]
it's working fine okay so now the first

[08:12:17 - 08:12:22]
thing I'll be installing some of the uh

[08:12:20 - 08:12:24]
like required packages like uh I need to

[08:12:22 - 08:12:26]
install the chroma DB and all so there

[08:12:24 - 08:12:27]
is the guide actually they have given

[08:12:26 - 08:12:31]
like you need to use peep install the

[08:12:27 - 08:12:32]
chroma DV and how to like uh uh set the

[08:12:31 - 08:12:34]
client and all everything they have

[08:12:32 - 08:12:36]
given okay so first of all what I will

[08:12:34 - 08:12:38]
do I will just set up this chroma DB so

[08:12:36 - 08:12:40]
to set up the chroma DB you will need

[08:12:38 - 08:12:42]
some more required package okay some

[08:12:40 - 08:12:45]
some more dependency I'll tell you like

[08:12:42 - 08:12:46]
what are things you need so just right

[08:12:45 - 08:12:48]
peip

[08:12:46 - 08:12:51]
uh hypen

[08:12:48 - 08:12:53]
Q uh

[08:12:51 - 08:12:56]
install uh first of all I need something

[08:12:53 - 08:12:59]
called chroma DB so I'll copy the name

[08:12:56 - 08:12:59]
from here

[08:13:01 - 08:13:06]
proma DB then I need something called

[08:13:04 - 08:13:09]
open AI because I'm going to use open Ai

[08:13:06 - 08:13:11]
embeddings and open AI like you can say

[08:13:09 - 08:13:14]
LM model okay that means GPT 3.5 turbo

[08:13:11 - 08:13:16]
model so that's why I need openi and I

[08:13:14 - 08:13:18]
also need something called Lang chain

[08:13:16 - 08:13:20]
because I told you I'll be using Lang

[08:13:18 - 08:13:22]
Chen here Lang Chen and there is another

[08:13:20 - 08:13:26]
dependency unit something called tick

[08:13:22 - 08:13:28]
token okay tick token so if we are using

[08:13:26 - 08:13:30]
open AI embedding so you need this

[08:13:28 - 08:13:31]
package actually Tik token now yeah I

[08:13:30 - 08:13:34]
think these are the things actually I

[08:13:31 - 08:13:37]
need now let me install it and guys you

[08:13:34 - 08:13:39]
need openi account for this video

[08:13:37 - 08:13:41]
actually uh so just try to create an

[08:13:39 - 08:13:42]
account here uh otherwise uh you won't

[08:13:41 - 08:13:45]
be able to do it because you need the

[08:13:42 - 08:13:47]
open API key okay to run this uh like

[08:13:45 - 08:13:47]
you can say

[08:13:49 - 08:13:54]
notebook so guys installation is done

[08:13:52 - 08:13:56]
now if you want to see let's say any uh

[08:13:54 - 08:13:58]
version of any package so what you can

[08:13:56 - 08:14:00]
do let's say I want to see the chroma DB

[08:13:58 - 08:14:03]
version so I'll just copy the name and

[08:14:00 - 08:14:06]
here you can just write Peep

[08:14:03 - 08:14:10]
Show um pep

[08:14:06 - 08:14:11]
show and just uh give the name of the

[08:14:10 - 08:14:14]
package now if you execute it will show

[08:14:11 - 08:14:16]
you the version and every uh information

[08:14:14 - 08:14:16]
about this

[08:14:19 - 08:14:24]
package see guys uh name is chroma and

[08:14:22 - 08:14:27]
this is the specific version and uh this

[08:14:24 - 08:14:29]
is the entire summary of your uh like

[08:14:27 - 08:14:31]
chroma DB package okay so that's how you

[08:14:29 - 08:14:33]
can see for all the packages okay you

[08:14:31 - 08:14:36]
have installed now uh here first of all

[08:14:33 - 08:14:38]
I need to uh download uh some data uh

[08:14:36 - 08:14:40]
because here I'm I'm showing you Vector

[08:14:38 - 08:14:41]
database example and there actually I

[08:14:40 - 08:14:44]
need the data okay to show you like how

[08:14:41 - 08:14:46]
to store and all so uh for this actually

[08:14:44 - 08:14:48]
what I will do so there is a actually

[08:14:46 - 08:14:50]
this Dropbox links actually you can see

[08:14:48 - 08:14:52]
this is the Dropbox links and inside

[08:14:50 - 08:14:54]
that actually you have some article data

[08:14:52 - 08:14:56]
if you see Google article is there then

[08:14:54 - 08:14:58]
you have some AI startup article Amazon

[08:14:56 - 08:15:00]
article then you have databas article

[08:14:58 - 08:15:01]
chat jpt article so we have different

[08:15:00 - 08:15:05]
different articles here okay and this is

[08:15:01 - 08:15:06]
a txt data txt format data now if I open

[08:15:05 - 08:15:10]
any kinds of txt file see this is the

[08:15:06 - 08:15:12]
article related to this uh default okay

[08:15:10 - 08:15:14]
generative VI so they have written all

[08:15:12 - 08:15:16]
the article and all okay so I'll be

[08:15:14 - 08:15:17]
using this kinds of data um you can use

[08:15:16 - 08:15:19]
any kinds of data it's up to you but

[08:15:17 - 08:15:21]
this is the open source data actually I

[08:15:19 - 08:15:22]
got uh from the internet and this is the

[08:15:21 - 08:15:24]
link of the data so to download this

[08:15:22 - 08:15:26]
data first of all I will copy this link

[08:15:24 - 08:15:28]
and here I'll be using something called

[08:15:26 - 08:15:32]
W gate to download this data so I'll

[08:15:28 - 08:15:34]
just write w w gate so Wate is a Linux

[08:15:32 - 08:15:35]
command and here we are using Google

[08:15:34 - 08:15:38]
collab and Google collab is running on

[08:15:35 - 08:15:40]
the uh Linux operating system okay so it

[08:15:38 - 08:15:41]
is running on the Linux kernel so that's

[08:15:40 - 08:15:44]
why you can execute any kinds of Linux

[08:15:41 - 08:15:47]
command here so here I'll just write w k

[08:15:44 - 08:15:50]
um hypen q and here I'll just paste this

[08:15:47 - 08:15:53]
link okay I'll paste this entire link

[08:15:50 - 08:15:56]
now once it will download uh let me show

[08:15:53 - 08:15:58]
you how it will download so if I execute

[08:15:56 - 08:15:58]
this cell

[08:16:01 - 08:16:04]
left hand side you will see it will

[08:16:02 - 08:16:06]
download that zip file okay see new

[08:16:04 - 08:16:08]
article. zip file this ZIP file has been

[08:16:06 - 08:16:11]
downloaded now I also need to unzip this

[08:16:08 - 08:16:11]
ZIP file so I'll just write

[08:16:12 - 08:16:19]
unzip hen q and this is the name I'll

[08:16:16 - 08:16:19]
just copy the

[08:16:25 - 08:16:30]
name I'll just copy the name and here

[08:16:28 - 08:16:34]
I'll just uh tell the directory like

[08:16:30 - 08:16:37]
where uh you need to um I mean unzip it

[08:16:34 - 08:16:41]
so I'll give the same name

[08:16:37 - 08:16:42]
so this is the name new uh underscore

[08:16:41 - 08:16:44]
articles okay so it will create one

[08:16:42 - 08:16:46]
folder new UN articles and inside that

[08:16:44 - 08:16:48]
it will uh unzip everything okay now if

[08:16:46 - 08:16:48]
I show

[08:16:49 - 08:16:54]
you it's done now if I refresh the page

[08:16:52 - 08:16:56]
I think inside new articles uh now see

[08:16:54 - 08:16:58]
guys all the articles are present okay

[08:16:56 - 08:17:00]
now let's if you want to open it you can

[08:16:58 - 08:17:03]
also open and see so this is the article

[08:17:00 - 08:17:05]
and all about so now let me close this

[08:17:03 - 08:17:08]
thing so we have successfully uh

[08:17:05 - 08:17:10]
downloaded our data now what I need to

[08:17:08 - 08:17:12]
do I need to uh first of all create one

[08:17:10 - 08:17:14]
openi API key and uh I'll be setting up

[08:17:12 - 08:17:16]
my environment okay uh so for this

[08:17:14 - 08:17:19]
actually what I need to do I'll uh first

[08:17:16 - 08:17:21]
of all open up my openi account so you

[08:17:19 - 08:17:24]
just also open up your openi account

[08:17:21 - 08:17:26]
just say uh just search like open.com

[08:17:24 - 08:17:28]
and here just try to loging with your

[08:17:26 - 08:17:30]
account account so let me quickly log

[08:17:28 - 08:17:31]
with my account so guys as you can see

[08:17:30 - 08:17:34]
this is my account now here I'll just

[08:17:31 - 08:17:36]
click on this personal my U this uh this

[08:17:34 - 08:17:38]
is my profile I'll click here and here

[08:17:36 - 08:17:40]
you'll get one option called view API

[08:17:38 - 08:17:42]
Keys okay now I'll click here and here

[08:17:40 - 08:17:44]
you will see uh API Keys option okay now

[08:17:42 - 08:17:46]
see previously I created some of the API

[08:17:44 - 08:17:47]
Keys that's why uh you can see here but

[08:17:46 - 08:17:49]
for you it might be completely empty

[08:17:47 - 08:17:51]
it's completely fine so you'll get one

[08:17:49 - 08:17:52]
option called create a new secret key

[08:17:51 - 08:17:55]
okay just click here and just give the

[08:17:52 - 08:17:59]
name so in this case I'm using um Vector

[08:17:55 - 08:18:00]
DV so Vector DV I'll just name it okay

[08:17:59 - 08:18:03]
you can give any name I'm just giving

[08:18:00 - 08:18:06]
Vector DV and create the

[08:18:03 - 08:18:08]
keys now you need to solve one puzzle

[08:18:06 - 08:18:10]
here uh it will verify whether it's uh

[08:18:08 - 08:18:12]
whether you are a human or not okay so

[08:18:10 - 08:18:13]
I'll just click here now it's telling

[08:18:12 - 08:18:15]
just try to move this object uh with

[08:18:13 - 08:18:18]
respect to this hand Direction so let me

[08:18:15 - 08:18:18]
move it and

[08:18:24 - 08:18:29]
submit I think uh yeah attemp is

[08:18:27 - 08:18:33]
complete now uh I will get my secret key

[08:18:29 - 08:18:34]
yeah now I'll copy this key and here uh

[08:18:33 - 08:18:39]
I'll paste it okay as of now I'll paste

[08:18:34 - 08:18:39]
it and I'll just

[08:18:39 - 08:18:45]
uh give a comment here uh setting

[08:18:46 - 08:18:51]
up um setting up

[08:18:54 - 08:18:57]
environment and don't share this key

[08:18:56 - 08:18:59]
with any one guys otherwise they will

[08:18:57 - 08:19:02]
also able to access your uh like you can

[08:18:59 - 08:19:03]
open AI account I will be removing this

[08:19:02 - 08:19:05]
keys after this recording so that's why

[08:19:03 - 08:19:09]
I'm showing now here first of all I will

[08:19:05 - 08:19:10]
import operating system package called W

[08:19:09 - 08:19:13]
and here I'll set the environment so

[08:19:10 - 08:19:16]
I'll just write o dot

[08:19:13 - 08:19:19]
environment

[08:19:16 - 08:19:22]
Environ okay and here you just need to

[08:19:19 - 08:19:25]
give the keys like uh which name you

[08:19:22 - 08:19:29]
need to save it so I'll just give uh

[08:19:25 - 08:19:32]
open AI underscore

[08:19:29 - 08:19:36]
API underscore

[08:19:32 - 08:19:38]
key and equal to I'll set my API key

[08:19:36 - 08:19:42]
here so this is my API key I'll copy or

[08:19:38 - 08:19:43]
I'll cut it and here I'll set it yeah

[08:19:42 - 08:19:47]
that's

[08:19:43 - 08:19:49]
it okay now I can remove this uh cell

[08:19:47 - 08:19:49]
now let me

[08:19:50 - 08:19:55]
execute done now I need to import some

[08:19:52 - 08:19:57]
of the necessary Library so

[08:19:55 - 08:20:00]
import so so first of all I need to

[08:19:57 - 08:20:02]
import something called uh chroma okay

[08:20:00 - 08:20:05]
so if you're using langen so langen

[08:20:02 - 08:20:09]
already has this chroma API because I

[08:20:05 - 08:20:10]
already told you uh the integration so

[08:20:09 - 08:20:13]
it is the integration with the langin as

[08:20:10 - 08:20:15]
well as the LMA index so instead of uh

[08:20:13 - 08:20:20]
like importing directly like

[08:20:15 - 08:20:23]
import uh import coma okay import

[08:20:20 - 08:20:25]
chroma import chroma we have to uh

[08:20:23 - 08:20:27]
import it uh like from The Lang chain

[08:20:25 - 08:20:28]
itself because here I'm going to use

[08:20:27 - 08:20:30]
langen framework okay to build my

[08:20:28 - 08:20:32]
application that's why I need to call it

[08:20:30 - 08:20:34]
from the langen but let's see if you're

[08:20:32 - 08:20:35]
using it for any other uh like task

[08:20:34 - 08:20:37]
parpose let's say you are not creating

[08:20:35 - 08:20:39]
any generative VI application let's say

[08:20:37 - 08:20:40]
you are doing some different thing okay

[08:20:39 - 08:20:42]
different application at that time you

[08:20:40 - 08:20:43]
can directly import it and all the

[08:20:42 - 08:20:44]
functionality will remain same only all

[08:20:43 - 08:20:46]
the code will remain same only you just

[08:20:44 - 08:20:49]
need to change the import okay at that

[08:20:46 - 08:20:50]
time so here I'll be using Lang change

[08:20:49 - 08:20:55]
so I need to import it from the Lang

[08:20:50 - 08:20:58]
itself so how to import it so just write

[08:20:55 - 08:20:58]
from l

[08:20:58 - 08:21:04]
do Vector store so there is

[08:21:01 - 08:21:06]
a uh function you will get called vector

[08:21:04 - 08:21:10]
vector

[08:21:06 - 08:21:12]
stores import so I'll import my chroma

[08:21:10 - 08:21:16]
so I'll just write chroma then I also

[08:21:12 - 08:21:18]
need to import uh open a embedding

[08:21:16 - 08:21:20]
because I think you remember let me open

[08:21:18 - 08:21:22]
my board uh I think you remember first

[08:21:20 - 08:21:25]
of all what I need to do let's say I

[08:21:22 - 08:21:27]
have my unstructured data so let's say

[08:21:25 - 08:21:29]
this is my

[08:21:27 - 08:21:31]
data so the first place what I need to

[08:21:29 - 08:21:34]
do I need to use something called uh

[08:21:31 - 08:21:34]
embedding

[08:21:35 - 08:21:39]
model

[08:21:37 - 08:21:41]
embedding model so this model might be

[08:21:39 - 08:21:43]
anything so in this case I'm going to

[08:21:41 - 08:21:47]
use uh open

[08:21:43 - 08:21:47]
AI open a embedding

[08:21:48 - 08:21:52]
model open a embedding model I'll be

[08:21:50 - 08:21:55]
using so you can use any model here okay

[08:21:52 - 08:21:58]
then after that it will return me uh my

[08:21:55 - 08:21:58]
U vector

[08:22:02 - 08:22:08]
embedding Vector embeddings okay and

[08:22:05 - 08:22:13]
that Vector embeddings I will

[08:22:08 - 08:22:16]
store inside my Vector database

[08:22:13 - 08:22:19]
okay Vector DB so in this case I'll be

[08:22:16 - 08:22:21]
using something called chroma chroma

[08:22:19 - 08:22:24]
DB chromat okay so this is the complete

[08:22:21 - 08:22:26]
idea so first of all I need to import

[08:22:24 - 08:22:27]
this uh embedding model as well so here

[08:22:26 - 08:22:29]
I'm I'm going to use opena embedding so

[08:22:27 - 08:22:32]
I can directly import opena embedding so

[08:22:29 - 08:22:35]
let me do it so here I'll just write

[08:22:32 - 08:22:35]
from

[08:22:36 - 08:22:40]
lanen do

[08:22:38 - 08:22:43]
embeddings uh

[08:22:40 - 08:22:47]
import open

[08:22:43 - 08:22:49]
AI embeddings open eddings okay then I

[08:22:47 - 08:22:51]
also need to import open AI because I'm

[08:22:49 - 08:22:54]
going to use openi large language model

[08:22:51 - 08:22:58]
so again I'll just write

[08:22:54 - 08:22:58]
from Lang chain

[08:22:59 - 08:23:04]
uh llms that means large language model

[08:23:02 - 08:23:07]
I need

[08:23:04 - 08:23:09]
open then uh I need to load my data as

[08:23:07 - 08:23:11]
you can see this is my data and it is uh

[08:23:09 - 08:23:13]
present inside a directory okay and

[08:23:11 - 08:23:15]
again this data format is a txt data

[08:23:13 - 08:23:18]
okay if you see it's a txt data so for

[08:23:15 - 08:23:22]
this I again need two libraries so I'll

[08:23:18 - 08:23:23]
just write from Lang chain so guys I'm

[08:23:22 - 08:23:25]
expecting you are already familiar with

[08:23:23 - 08:23:27]
this Lang chain because if you check our

[08:23:25 - 08:23:28]
YouTube channel so we have already

[08:23:27 - 08:23:30]
covered this Lang chain tutorial and all

[08:23:28 - 08:23:32]
okay so you can go with uh that tutorial

[08:23:30 - 08:23:35]
and you can learn the Lang chain so here

[08:23:32 - 08:23:38]
from Lang chain U there is a uh class

[08:23:35 - 08:23:39]
called document loader so just write

[08:23:38 - 08:23:42]
document

[08:23:39 - 08:23:44]
loaders okay so first of all I will be

[08:23:42 - 08:23:48]
import something called directory loader

[08:23:44 - 08:23:50]
okay directory directory loaded because

[08:23:48 - 08:23:51]
uh my data set is present inside the

[08:23:50 - 08:23:53]
directory that's why I need this

[08:23:51 - 08:23:55]
directory loaded then I also need to

[08:23:53 - 08:23:57]
load my text loader because it's a txt

[08:23:55 - 08:24:01]
data right so I'll import the same thing

[08:23:57 - 08:24:05]
only uh sorry it should be uh data

[08:24:01 - 08:24:05]
loader I think uh document loader

[08:24:07 - 08:24:16]
document it's a document

[08:24:10 - 08:24:16]
loaded okay now it should be uh text

[08:24:19 - 08:24:25]
loader text loader okay uh yes so as of

[08:24:23 - 08:24:26]
now I need these are the libraries uh

[08:24:25 - 08:24:28]
and if I need anything I will be

[08:24:26 - 08:24:30]
importing later on so let me just

[08:24:28 - 08:24:34]
quickly import them now we'll be loading

[08:24:30 - 08:24:37]
the documents so load uh data so guys uh

[08:24:34 - 08:24:39]
to load the data just write uh directory

[08:24:37 - 08:24:41]
loader directory loader and inside that

[08:24:39 - 08:24:44]
you just need to mention the directory

[08:24:41 - 08:24:48]
so here this is the directory I'll just

[08:24:44 - 08:24:48]
copy uh the

[08:24:49 - 08:24:55]
name copy path and I can give it here so

[08:24:53 - 08:24:58]
this is the directory and inside that

[08:24:55 - 08:25:00]
actually I have but txt data okay I have

[08:24:58 - 08:25:02]
if you see I have txt data so I only

[08:25:00 - 08:25:03]
want to load the txt file so if I let's

[08:25:02 - 08:25:05]
say I have some many other file okay I

[08:25:03 - 08:25:07]
will be ignoring so for this there is a

[08:25:05 - 08:25:11]
parameter you you can give called Globe

[08:25:07 - 08:25:14]
okay just write Globe equal to so it

[08:25:11 - 08:25:17]
should be txt

[08:25:14 - 08:25:23]
file so all the file just load is means

[08:25:17 - 08:25:23]
all the file okay it should be Dot dxt

[08:25:27 - 08:25:34]
then you also need to define the loader

[08:25:29 - 08:25:34]
class okay so just write

[08:25:34 - 08:25:39]
loader loader class and and should be my

[08:25:37 - 08:25:41]
text loader because uh all the file are

[08:25:39 - 08:25:44]
txt format okay that's why you need to

[08:25:41 - 08:25:46]
give this uh text loader okay now it

[08:25:44 - 08:25:49]
will load up your data and I'll be

[08:25:46 - 08:25:50]
storing this data inside a variable

[08:25:49 - 08:25:53]
called

[08:25:50 - 08:25:56]
loader so this is my uh object of my

[08:25:53 - 08:25:58]
data loader now let me uh execute it now

[08:25:56 - 08:26:00]
to load the data you need to call one

[08:25:58 - 08:26:04]
function

[08:26:00 - 08:26:06]
called uh loaded. load okay if you call

[08:26:04 - 08:26:07]
this function it will load the data and

[08:26:06 - 08:26:10]
this data will store it in a variable

[08:26:07 - 08:26:10]
called

[08:26:11 - 08:26:19]
document okay and see guys it will uh

[08:26:15 - 08:26:22]
load all the data inside this

[08:26:19 - 08:26:24]
document see guys this is the all of the

[08:26:22 - 08:26:26]
text actually you can see here so it has

[08:26:24 - 08:26:27]
loaded all the txt file one by one and

[08:26:26 - 08:26:30]
it has has extracted a data and this is

[08:26:27 - 08:26:33]
your entire data as you can see so let

[08:26:30 - 08:26:35]
me show you see guys and this is a

[08:26:33 - 08:26:37]
document object okay this is a document

[08:26:35 - 08:26:39]
object now uh we have successfully

[08:26:37 - 08:26:41]
loaded our data now guys before

[08:26:39 - 08:26:43]
converting this data set to the

[08:26:41 - 08:26:44]
embedding and storing uh it to my chroma

[08:26:43 - 08:26:46]
DV first of all I need to apply

[08:26:44 - 08:26:49]
something called text Splitter on top of

[08:26:46 - 08:26:51]
it basically I need to convert my entire

[08:26:49 - 08:26:53]
uh data as a chunks because as you can

[08:26:51 - 08:26:55]
see this is my complete Corpus okay see

[08:26:53 - 08:26:56]
this is my complete Corpus if I show you

[08:26:55 - 08:26:58]
so if I show you the see this is the

[08:26:56 - 08:27:01]
complete uh data okay this is the

[08:26:58 - 08:27:03]
complete Data Corpus but this data is

[08:27:01 - 08:27:06]
like very huge okay I can't like you can

[08:27:03 - 08:27:07]
say directly convert it to Vector okay

[08:27:06 - 08:27:10]
so if I'm converting so what will happen

[08:27:07 - 08:27:13]
Okay let me explain so what is the use

[08:27:10 - 08:27:15]
of this chunks okay so see so whenever

[08:27:13 - 08:27:18]
you are using any llm model okay

[08:27:15 - 08:27:21]
whenever you are using any llm model so

[08:27:18 - 08:27:23]
it has one input size okay it has

[08:27:21 - 08:27:27]
one

[08:27:23 - 08:27:29]
input input size as well as each has one

[08:27:27 - 08:27:31]
output

[08:27:29 - 08:27:34]
size okay output

[08:27:31 - 08:27:36]
size so whenever you are giving

[08:27:34 - 08:27:38]
something as a input to the llm okay you

[08:27:36 - 08:27:39]
need to always take care about the input

[08:27:38 - 08:27:41]
okay so I'll tell you like where you

[08:27:39 - 08:27:43]
need to check the input size and all so

[08:27:41 - 08:27:48]
in this case let's say I'm using open

[08:27:43 - 08:27:49]
AI open AI llm okay open LM so open LM

[08:27:48 - 08:27:53]
wise I'll be using something called

[08:27:49 - 08:27:55]
GPT 3.5 turbo so there there is a model

[08:27:53 - 08:27:58]
you will get from openi called GPT 3.5

[08:27:55 - 08:28:00]
TBO TBO and it has actually one specific

[08:27:58 - 08:28:03]
input length so that input length

[08:28:00 - 08:28:05]
actually you need to uh see so if you

[08:28:03 - 08:28:08]
want to check the input L just uh search

[08:28:05 - 08:28:11]
like open model

[08:28:08 - 08:28:11]
open

[08:28:11 - 08:28:16]
models so this is the link just open it

[08:28:14 - 08:28:19]
up and here you will see all the models

[08:28:16 - 08:28:23]
are available inside open so we have gbt

[08:28:19 - 08:28:25]
4 gbt 3.5 GPT based Deli okay gpt3

[08:28:23 - 08:28:27]
Legacy so these are the model actually

[08:28:25 - 08:28:30]
and and uh here I'm going to use uh this

[08:28:27 - 08:28:31]
GPT 3.5 Series so I'll just click here

[08:28:30 - 08:28:33]
now here if you see the first model is

[08:28:31 - 08:28:35]
GPT 3.5 turbo and this is the

[08:28:33 - 08:28:36]
description about the model OKAY like uh

[08:28:35 - 08:28:39]
what are the things they are doing and

[08:28:36 - 08:28:42]
all and this is the Max uh token length

[08:28:39 - 08:28:43]
as you can see so it can take a input

[08:28:42 - 08:28:48]
around

[08:28:43 - 08:28:51]
4,000 97 tokens okay at a time and this

[08:28:48 - 08:28:53]
is the training data okay like up to uh

[08:28:51 - 08:28:55]
September 2021 they have trainer data

[08:28:53 - 08:28:57]
okay so this is the input length Okay

[08:28:55 - 08:29:00]
but if you check if you check your uh

[08:28:57 - 08:29:03]
input here uh if I open my data if you

[08:29:00 - 08:29:05]
see this input length actually will be

[08:29:03 - 08:29:07]
more than this 4,000 token because here

[08:29:05 - 08:29:08]
if you see I have loaded the entire

[08:29:07 - 08:29:10]
documents I have loaded the entire

[08:29:08 - 08:29:12]
documents all the articles I have loaded

[08:29:10 - 08:29:14]
okay so there is a possibility uh this

[08:29:12 - 08:29:16]
input size would be more than 4,000

[08:29:14 - 08:29:18]
tokens okay and if I'm converting all

[08:29:16 - 08:29:21]
the Corpus as my uh vector embeddings

[08:29:18 - 08:29:23]
and I storing to the vector database so

[08:29:21 - 08:29:26]
it will create issue okay so again uh

[08:29:23 - 08:29:27]
during storing it will create issue and

[08:29:26 - 08:29:29]
and whenever you will be giving this

[08:29:27 - 08:29:31]
data to your llm model again it will be

[08:29:29 - 08:29:33]
creating issue and you will also get

[08:29:31 - 08:29:34]
some memory error and all okay so it's

[08:29:33 - 08:29:37]
better to split our data as a chunks

[08:29:34 - 08:29:40]
okay now what is Chunks so let me first

[08:29:37 - 08:29:42]
of all tell you chunks is nothing but

[08:29:40 - 08:29:44]
here I have already written chunks is a

[08:29:42 - 08:29:46]
size of the maximum number of the

[08:29:44 - 08:29:48]
character that uh a chunks can contain

[08:29:46 - 08:29:50]
okay and there is another concept called

[08:29:48 - 08:29:52]
chunks overlap okay so chks overlap is

[08:29:50 - 08:29:54]
nothing but this is the number of

[08:29:52 - 08:29:57]
character that should be overlap between

[08:29:54 - 08:29:59]
two uh adjust chunks okay so let's say

[08:29:57 - 08:30:01]
so to explain this one let's say I will

[08:29:59 - 08:30:03]
take one text

[08:30:01 - 08:30:05]
here so let's say this is my entire

[08:30:03 - 08:30:07]
Corpus okay now first of all I need to

[08:30:05 - 08:30:09]
convert it to chunks okay chunks means

[08:30:07 - 08:30:13]
I'll be taking uh some of the Chun size

[08:30:09 - 08:30:16]
okay let's say if I am writing

[08:30:13 - 08:30:20]
chunk

[08:30:16 - 08:30:22]
size is equal to let's say 500 so it

[08:30:20 - 08:30:25]
will take uh let's say I'll take a new

[08:30:22 - 08:30:29]
color so it will start from here and it

[08:30:25 - 08:30:30]
will uh go and it will count like 500

[08:30:29 - 08:30:32]
character okay it will count 500

[08:30:30 - 08:30:34]
character so let's say this is uh this

[08:30:32 - 08:30:36]
will end here okay this will end here

[08:30:34 - 08:30:37]
and this should be one chunks okay this

[08:30:36 - 08:30:40]
should

[08:30:37 - 08:30:42]
be this should be one chunks okay so

[08:30:40 - 08:30:45]
again it will start from here again it

[08:30:42 - 08:30:48]
will count let's say 500 word uh sorry

[08:30:45 - 08:30:50]
500 character uh and we call it as a

[08:30:48 - 08:30:51]
token okay so let's say this is uh here

[08:30:50 - 08:30:53]
it will end so this should be another

[08:30:51 - 08:30:55]
chance okay so let's say this is another

[08:30:53 - 08:30:58]
chance this is another chance now again

[08:30:55 - 08:31:00]
let's say it will start from here it

[08:30:58 - 08:31:01]
will start from here again it will count

[08:31:00 - 08:31:03]
let's say it will end here this is

[08:31:01 - 08:31:06]
another chance let's say again it will

[08:31:03 - 08:31:08]
start from here and it let's say it will

[08:31:06 - 08:31:10]
end here okay I'm taking it randomly

[08:31:08 - 08:31:11]
just try to consider so this is another

[08:31:10 - 08:31:13]
chance and it will start from here it

[08:31:11 - 08:31:16]
will end here okay now how many chunks

[08:31:13 - 08:31:20]
we have got so one chunks two chunks

[08:31:16 - 08:31:22]
three four and five okay so here I got

[08:31:20 - 08:31:25]
five chunks okay five

[08:31:22 - 08:31:28]
chunks five chunks of the data see now

[08:31:25 - 08:31:31]
if if you count this input length okay

[08:31:28 - 08:31:32]
now it should be less than it should be

[08:31:31 - 08:31:36]
less

[08:31:32 - 08:31:37]
than less than my 4,000 uh I think uh

[08:31:36 - 08:31:39]
what is the

[08:31:37 - 08:31:42]
number it should be

[08:31:39 - 08:31:46]
4,000 97 okay

[08:31:42 - 08:31:46]
4,997 okay now my

[08:31:47 - 08:31:54]
input now my input uh size is less than

[08:31:51 - 08:31:56]
4,097 okay so this is the idea of

[08:31:54 - 08:31:58]
creating this chunks okay instead of

[08:31:56 - 08:32:00]
converting my entire Corpus to the

[08:31:58 - 08:32:02]
vector first of all I need to create as

[08:32:00 - 08:32:04]
the chunks okay then I need to convert

[08:32:02 - 08:32:05]
it to Vector embedding then I will be

[08:32:04 - 08:32:08]
storing and that embedding I will feed

[08:32:05 - 08:32:09]
my llm model okay and there is another

[08:32:08 - 08:32:11]
concept called chunks overlap okay so

[08:32:09 - 08:32:13]
what is Chunks overlap so if you set

[08:32:11 - 08:32:14]
this chunks overlap let's say I will set

[08:32:13 - 08:32:18]
this chunks

[08:32:14 - 08:32:18]
overlap chunks uncore

[08:32:18 - 08:32:24]
overlap overlap let's say I have set as

[08:32:22 - 08:32:26]
20 so what it will do so whenever uh

[08:32:24 - 08:32:29]
first of all I will

[08:32:26 - 08:32:31]
gra these are the chunks okay now let's

[08:32:29 - 08:32:32]
create a new chunks again so let's say

[08:32:31 - 08:32:34]
whenever it will create a chunks let's

[08:32:32 - 08:32:36]
say it will start from here and Chun

[08:32:34 - 08:32:38]
size is 500 so let's say it will end

[08:32:36 - 08:32:40]
here now you have mentioned chunks

[08:32:38 - 08:32:42]
overlap is equal to 20 now what you will

[08:32:40 - 08:32:44]
do instead of starting from here it will

[08:32:42 - 08:32:46]
go back and it will count 20 character

[08:32:44 - 08:32:49]
okay it will count 20 character let's

[08:32:46 - 08:32:51]
say this is my 20 character okay now it

[08:32:49 - 08:32:54]
will create the chks form here now again

[08:32:51 - 08:32:57]
it will count and let's say your 5 500

[08:32:54 - 08:32:59]
character will end here so this is my

[08:32:57 - 08:33:00]
another chunks okay so basically chunks

[08:32:59 - 08:33:02]
overlap means like how much overlapping

[08:33:00 - 08:33:04]
you are needed from your previous chunks

[08:33:02 - 08:33:06]
okay so that that is called chunks

[08:33:04 - 08:33:07]
overlap so it helps you like to

[08:33:06 - 08:33:10]
understand your context of that text

[08:33:07 - 08:33:11]
okay U instead of using only Chang size

[08:33:10 - 08:33:13]
you can also use chunks overlap so that

[08:33:11 - 08:33:15]
it can also got to know like what was

[08:33:13 - 08:33:17]
the previous context okay whenever it

[08:33:15 - 08:33:19]
will let's say see I'm giving this

[08:33:17 - 08:33:22]
chunks by chunks let's say this is my

[08:33:19 - 08:33:24]
chunk one the Chun two and Chun three so

[08:33:22 - 08:33:26]
okay so instead of giving directly the

[08:33:24 - 08:33:28]
chunks if I'm also mention s overlap

[08:33:26 - 08:33:30]
what will happen your llm model llm

[08:33:28 - 08:33:31]
model automatically will get to know

[08:33:30 - 08:33:34]
okay so this is the context actually so

[08:33:31 - 08:33:36]
this this sentence okay this sentence

[08:33:34 - 08:33:37]
and this sentence so after this sentence

[08:33:36 - 08:33:39]
actually this sentence is coming okay so

[08:33:37 - 08:33:41]
that's why this Chun SI this chunks

[08:33:39 - 08:33:42]
overlaps actually helps us okay this

[08:33:41 - 08:33:44]
Chun overlap actually help us to

[08:33:42 - 08:33:46]
understand the context of the uh entire

[08:33:44 - 08:33:47]
story okay so that's why we'll be using

[08:33:46 - 08:33:49]
this two concept called Chun size and

[08:33:47 - 08:33:51]
chunks overlap okay now I think this

[08:33:49 - 08:33:54]
thing is clear now let me show you how

[08:33:51 - 08:33:55]
to do it using Code so I'll come here

[08:33:54 - 08:33:57]
now here first of all you need to to

[08:33:55 - 08:34:00]
import uh something called recursive

[08:33:57 - 08:34:04]
character text splitter okay so from

[08:34:00 - 08:34:08]
langen from langen uh dot text splitter

[08:34:04 - 08:34:11]
textor uh splitter

[08:34:08 - 08:34:13]
input recursive so recursive character

[08:34:11 - 08:34:15]
text splitter okay so this is the uh

[08:34:13 - 08:34:18]
class actually we'll be using to convert

[08:34:15 - 08:34:20]
my entire Corpus as a chunks okay now

[08:34:18 - 08:34:22]
I'll just call this

[08:34:20 - 08:34:23]
class and inside that you need to

[08:34:22 - 08:34:26]
mention two parameter I think I already

[08:34:23 - 08:34:28]
explained one is the your chunk

[08:34:26 - 08:34:32]
underscore

[08:34:28 - 08:34:34]
size okay CH size so let's define as

[08:34:32 - 08:34:37]
1,000 okay I am considering 1,000

[08:34:34 - 08:34:39]
character uh as my one chunk okay you

[08:34:37 - 08:34:41]
can give any number so it's a hyper

[08:34:39 - 08:34:43]
parameter tuning you can uh set any

[08:34:41 - 08:34:45]
number here but I I saw like people are

[08:34:43 - 08:34:49]
starting with 1,000 here okay and there

[08:34:45 - 08:34:52]
is another parameter will give called

[08:34:49 - 08:34:54]
chunk underscore overlap so chunk

[08:34:52 - 08:34:57]
overlap I will give let's say 200 okay

[08:34:54 - 08:34:58]
so again it's a hyper tuning now guys I

[08:34:57 - 08:35:01]
have created this object now I will save

[08:34:58 - 08:35:03]
this object so I'll just uh create a

[08:35:01 - 08:35:05]
variable called text

[08:35:03 - 08:35:07]
splitter now guys finally I will convert

[08:35:05 - 08:35:11]
my entire Corpus to my chunks so I'll

[08:35:07 - 08:35:13]
just call this object and here you need

[08:35:11 - 08:35:15]
to call

[08:35:13 - 08:35:17]
split

[08:35:15 - 08:35:20]
dot

[08:35:17 - 08:35:23]
split _

[08:35:20 - 08:35:25]
documents and this is my Ed

[08:35:23 - 08:35:29]
documents okay this is my raw documents

[08:35:25 - 08:35:32]
so I'll give it here and I'll store in a

[08:35:29 - 08:35:33]
document variable okay or I can store it

[08:35:32 - 08:35:36]
I think in a text variable I think it

[08:35:33 - 08:35:39]
should be fine so let's make it as

[08:35:36 - 08:35:42]
separate now uh let me

[08:35:39 - 08:35:44]
execute it's done now if I show you my

[08:35:42 - 08:35:46]
text guys so you will able to see it has

[08:35:44 - 08:35:48]
converted to chunks and how many chunks

[08:35:46 - 08:35:52]
it has converted I will also show you

[08:35:48 - 08:35:55]
see guys uh so if I just go up so guys

[08:35:52 - 08:35:58]
see this is my first chunks okay and it

[08:35:55 - 08:36:00]
is ending here then again it is another

[08:35:58 - 08:36:02]
chunks okay then it is ending here then

[08:36:00 - 08:36:05]
again this is another chunks and it is

[08:36:02 - 08:36:06]
ending here and from uh and if you see

[08:36:05 - 08:36:08]
in each chunks actually you have

[08:36:06 - 08:36:10]
thousand character okay th character and

[08:36:08 - 08:36:12]
here if you see the chunks overlap so if

[08:36:10 - 08:36:14]
you read this text carefully so you will

[08:36:12 - 08:36:16]
see some of the sentence are coming okay

[08:36:14 - 08:36:17]
in this uh new chunks as well okay

[08:36:16 - 08:36:20]
because we have set this chunks overlap

[08:36:17 - 08:36:23]
as uh 200 okay so see this is my entire

[08:36:20 - 08:36:24]
chunks now if you want to see the length

[08:36:23 - 08:36:26]
like how many chunks it has created so

[08:36:24 - 08:36:29]
just print the length

[08:36:26 - 08:36:29]
so I'll just read as my

[08:36:30 - 08:36:36]
text so it has created 23 uh3 chunks

[08:36:33 - 08:36:38]
okay all together now uh it's fine now

[08:36:36 - 08:36:40]
if you want to see any chunks specific

[08:36:38 - 08:36:43]
chunks you just give the index let's say

[08:36:40 - 08:36:45]
I want to see the number one

[08:36:43 - 08:36:47]
chunks this is the number one chunks and

[08:36:45 - 08:36:50]
I can also

[08:36:47 - 08:36:52]
print number

[08:36:50 - 08:36:56]
two now uh we have successfully

[08:36:52 - 08:36:58]
converted our uh like Corpus to chunks

[08:36:56 - 08:37:00]
now what I will do I will uh create my

[08:36:58 - 08:37:04]
uh DB object okay like vector DB object

[08:37:00 - 08:37:05]
so just write the comment

[08:37:04 - 08:37:08]
here

[08:37:05 - 08:37:10]
creating DB

[08:37:08 - 08:37:12]
object so as I already told you chroma

[08:37:10 - 08:37:13]
DB is nothing but it's a local database

[08:37:12 - 08:37:16]
so first of all you need to create a

[08:37:13 - 08:37:19]
local uh like DB here okay local DB so

[08:37:16 - 08:37:23]
you need to specify the name uh so here

[08:37:19 - 08:37:25]
I already prepared uh this code so here

[08:37:23 - 08:37:27]
uh you need to first of all create one

[08:37:25 - 08:37:29]
par directory and the name can be

[08:37:27 - 08:37:32]
anything so here in this case I'm giving

[08:37:29 - 08:37:35]
as DV that means database and uh you

[08:37:32 - 08:37:37]
need to specify the embedding first of

[08:37:35 - 08:37:39]
all okay like I think you know why we

[08:37:37 - 08:37:40]
need the embedding because uh first of

[08:37:39 - 08:37:43]
all I need to convert my text to

[08:37:40 - 08:37:45]
embeddings okay that means Vector then I

[08:37:43 - 08:37:47]
will store this uh Vector okay to my

[08:37:45 - 08:37:49]
Vector database which is nothing by my

[08:37:47 - 08:37:51]
Comm so in this case I'm using something

[08:37:49 - 08:37:53]
called uh open a embedding I think you

[08:37:51 - 08:37:57]
remember here we imported so open a

[08:37:53 - 08:37:57]
embedding so I'll just uh call it

[08:37:58 - 08:38:04]
it open a embeddings and by default if

[08:38:02 - 08:38:07]
you execute uh this code so let me show

[08:38:04 - 08:38:07]
you which embeddings model it is

[08:38:10 - 08:38:15]
using so it is using something called

[08:38:12 - 08:38:16]
text embedding add a model OKAY 002 this

[08:38:15 - 08:38:20]
is the model now you can search also

[08:38:16 - 08:38:22]
here uh so if you check here so it has

[08:38:20 - 08:38:24]
this model called text embedding um add

[08:38:22 - 08:38:28]
002 this is the model it has also

[08:38:24 - 08:38:30]
another version text uh add a 01 okay

[08:38:28 - 08:38:32]
now we have successfully uh loaded our

[08:38:30 - 08:38:34]
embedding model now what I need to do I

[08:38:32 - 08:38:37]
need to create my Vector uh instance

[08:38:34 - 08:38:39]
okay uh I need to like create my Vector

[08:38:37 - 08:38:42]
uh database instance so to create it so

[08:38:39 - 08:38:44]
this is the code for it it's a simple

[08:38:42 - 08:38:46]
code only so first of all I have created

[08:38:44 - 08:38:47]
one variable called Vector DB and here

[08:38:46 - 08:38:49]
I'm just calling my chroma I think you

[08:38:47 - 08:38:52]
remember we imported chroma from my Lang

[08:38:49 - 08:38:54]
chain I'm just calling this chroma so

[08:38:52 - 08:38:56]
inside chroma you have one function

[08:38:54 - 08:38:59]
called from uh documents okay from

[08:38:56 - 08:39:00]
documents now here you just need to give

[08:38:59 - 08:39:02]
the data like you just need to give your

[08:39:00 - 08:39:03]
text like you just need to give your

[08:39:02 - 08:39:05]
chunks like which uh chunks actually

[08:39:03 - 08:39:08]
want to convert as a vector so in this

[08:39:05 - 08:39:10]
case this is my chunks called text as

[08:39:08 - 08:39:11]
you can see this is my text I'll just

[08:39:10 - 08:39:14]
copy the

[08:39:11 - 08:39:16]
name and here I'll just name it text

[08:39:14 - 08:39:17]
okay and it will also take the embedding

[08:39:16 - 08:39:19]
model okay so this is the embedding

[08:39:17 - 08:39:20]
model I want to use so in this case you

[08:39:19 - 08:39:22]
can use any embedding model you just

[08:39:20 - 08:39:23]
need to import it here okay so here I'm

[08:39:22 - 08:39:25]
using openi based embedding model so

[08:39:23 - 08:39:27]
that's why I have initialized it here so

[08:39:25 - 08:39:29]
here I'm giving the Ming model and here

[08:39:27 - 08:39:32]
you also need to give the proc directory

[08:39:29 - 08:39:34]
like where it will save after let's say

[08:39:32 - 08:39:36]
converting to vectors where it will save

[08:39:34 - 08:39:38]
so it will save inside this DB folder

[08:39:36 - 08:39:40]
okay so here I'm giving the directory so

[08:39:38 - 08:39:42]
these three parameter users only need to

[08:39:40 - 08:39:44]
give here okay that's it and if you're

[08:39:42 - 08:39:46]
not giving any embedding model uh inside

[08:39:44 - 08:39:48]
chroma it will automatically take Opia

[08:39:46 - 08:39:50]
embedding model okay I think they have

[08:39:48 - 08:39:54]
already uh written here if you see here

[08:39:50 - 08:39:55]
uh embeddings so they're automatically I

[08:39:54 - 08:39:57]
think taking uh some embedding model

[08:39:55 - 08:39:59]
using open API key and all okay so they

[08:39:57 - 08:40:00]
have already mentioned here like it will

[08:39:59 - 08:40:02]
automatically load but it's better

[08:40:00 - 08:40:05]
practice to mention okay always better

[08:40:02 - 08:40:07]
practice to mention here that's it now

[08:40:05 - 08:40:11]
if I execute it uh so first of all what

[08:40:07 - 08:40:11]
you'll do I'll just remove this

[08:40:12 - 08:40:17]
directory now see it is converting

[08:40:14 - 08:40:19]
everything uh to the uh vectors okay all

[08:40:17 - 08:40:22]
the text has been converted to vectors

[08:40:19 - 08:40:24]
now I need to uh save it to my disk okay

[08:40:22 - 08:40:26]
now see it has uh converted everything

[08:40:24 - 08:40:28]
to the Vector now I need to save it to

[08:40:26 - 08:40:31]
the database okay now this is the code

[08:40:28 - 08:40:34]
for it just write Vector DV persist and

[08:40:31 - 08:40:35]
Vector DV uh is equal to none now if I

[08:40:34 - 08:40:37]
execute it now you'll see it will create

[08:40:35 - 08:40:40]
One DB Here Local

[08:40:37 - 08:40:42]
DB now if I

[08:40:40 - 08:40:44]
refresh see guys DV has been created now

[08:40:42 - 08:40:48]
inside that it has saved all the

[08:40:44 - 08:40:50]
vector now see it's a binary format you

[08:40:48 - 08:40:52]
can't see the vector here so that is the

[08:40:50 - 08:40:53]
issue with this local DB but whenever

[08:40:52 - 08:40:55]
I'll will be showing you like pine cone

[08:40:53 - 08:40:57]
and wave you will able to see the vector

[08:40:55 - 08:40:59]
like how it it has generated the vector

[08:40:57 - 08:41:00]
okay how it has generated the embedding

[08:40:59 - 08:41:03]
everything you can see in the cloud okay

[08:41:00 - 08:41:05]
you can like see all the list of the

[08:41:03 - 08:41:08]
vector there okay so that was the beauty

[08:41:05 - 08:41:10]
of this Cloud uh uh Vector database but

[08:41:08 - 08:41:12]
again it's a local one okay so that's

[08:41:10 - 08:41:14]
why it's a binary presentation here so

[08:41:12 - 08:41:16]
yes guys we are successfully able to

[08:41:14 - 08:41:19]
save our Vector here okay

[08:41:16 - 08:41:21]
now uh let's say you want to uh load it

[08:41:19 - 08:41:23]
so how to load it so this is the code

[08:41:21 - 08:41:26]
for

[08:41:23 - 08:41:28]
it so here you just need to mention

[08:41:26 - 08:41:29]
chroma okay just call the chroma and

[08:41:28 - 08:41:31]
here you just to mention the the

[08:41:29 - 08:41:34]
directory you have your data so this is

[08:41:31 - 08:41:36]
my database DB so here I'm giving the

[08:41:34 - 08:41:38]
par directory which is nothing but DB in

[08:41:36 - 08:41:39]
this case and here you also need to give

[08:41:38 - 08:41:41]
the embedding okay so this is the

[08:41:39 - 08:41:43]
embedding I'm using uh now here I'm

[08:41:41 - 08:41:44]
giving my Pur directory so in this case

[08:41:43 - 08:41:47]
it's DV okay now it will automatically

[08:41:44 - 08:41:48]
load this vector and everything okay

[08:41:47 - 08:41:50]
from this DV itself because it's a

[08:41:48 - 08:41:52]
binary presentation I already told you

[08:41:50 - 08:41:56]
okay and as well as I'm also giving my

[08:41:52 - 08:41:57]
embedding model now let me load it

[08:41:56 - 08:41:59]
now I think you remember I told you

[08:41:57 - 08:42:02]
something called similarity s okay now

[08:41:59 - 08:42:04]
once we have loaded this uh Vector uh to

[08:42:02 - 08:42:06]
my uh Vector database now you can apply

[08:42:04 - 08:42:09]
similarity s on top of it okay we call

[08:42:06 - 08:42:11]
it as uh retriever okay retriever so now

[08:42:09 - 08:42:13]
let's show you the demo of the retriever

[08:42:11 - 08:42:18]
so I'll just comment it out make

[08:42:13 - 08:42:21]
retriever okay so uh to retrieve any uh

[08:42:18 - 08:42:23]
specific information with respect to the

[08:42:21 - 08:42:25]
question you are asking you need to set

[08:42:23 - 08:42:27]
this parameter called Vector as R okay

[08:42:25 - 08:42:29]
Vector DB so this is my object Vector DV

[08:42:27 - 08:42:32]
as rer and this is my rer object now let

[08:42:29 - 08:42:34]
me execute now here I'll just call this

[08:42:32 - 08:42:38]
R

[08:42:34 - 08:42:40]
object and uh here there is a parameter

[08:42:38 - 08:42:44]
called

[08:42:40 - 08:42:46]
get retrieve documents okay that means

[08:42:44 - 08:42:48]
that means I'm trying to tell my uh

[08:42:46 - 08:42:50]
Vector database uh whatever question I'm

[08:42:48 - 08:42:53]
asking try to uh give the similar kinds

[08:42:50 - 08:42:55]
of uh you can say data okay with respect

[08:42:53 - 08:42:58]
to the question I'm asking so here I'll

[08:42:55 - 08:43:00]
ask one question let's say here I have

[08:42:58 - 08:43:02]
Microsoft articles as well I think if

[08:43:00 - 08:43:04]
you see here I think Microsoft yeah

[08:43:02 - 08:43:07]
Microsoft articles is also there so I

[08:43:04 - 08:43:11]
can ask one question just like how

[08:43:07 - 08:43:11]
much micro how much

[08:43:11 - 08:43:16]
money did uh Microsoft

[08:43:18 - 08:43:23]
race okay so let's say this is my

[08:43:20 - 08:43:28]
question now uh by

[08:43:23 - 08:43:28]
default uh I'll store it in a

[08:43:28 - 08:43:35]
docs so by default it will return for uh

[08:43:33 - 08:43:37]
relevant uh answer okay four relevant

[08:43:35 - 08:43:40]
answer if I print it

[08:43:37 - 08:43:41]
see it will return return you four uh

[08:43:40 - 08:43:44]
similarity answer okay

[08:43:41 - 08:43:46]
for most similar answer okay like

[08:43:44 - 08:43:48]
whatever Vector are closed I think I was

[08:43:46 - 08:43:50]
explaining in the theory so it is the

[08:43:48 - 08:43:53]
most uh relevant and most similar answer

[08:43:50 - 08:43:55]
okay four most similar answer so if I

[08:43:53 - 08:43:58]
show you the length

[08:43:55 - 08:44:00]
so you can also set this parameter like

[08:43:58 - 08:44:04]
how many relevant information you

[08:44:00 - 08:44:06]
want see it is uh rning me four so let's

[08:44:04 - 08:44:07]
say you only want let's say two relevant

[08:44:06 - 08:44:09]
answer okay so in this case you can set

[08:44:07 - 08:44:12]
this parameter Vector DB as retrieve

[08:44:09 - 08:44:14]
search keyword as K2 okay K me like how

[08:44:12 - 08:44:18]
many answer you want okay so let's say I

[08:44:14 - 08:44:18]
have given two now if I execute

[08:44:19 - 08:44:24]
it okay done

[08:44:22 - 08:44:26]
now if you want to see like search types

[08:44:24 - 08:44:27]
so so it's a similarity Matrix I think

[08:44:26 - 08:44:29]
they're using similarity equation

[08:44:27 - 08:44:32]
they're using cosine similarity to

[08:44:29 - 08:44:34]
calculate this uh answer okay like the

[08:44:32 - 08:44:35]
question you are asking basically it

[08:44:34 - 08:44:37]
will match with the vector like what are

[08:44:35 - 08:44:38]
the closest Vector okay it will come so

[08:44:37 - 08:44:40]
it will return you so they're

[08:44:38 - 08:44:42]
considering this similarity uh coine

[08:44:40 - 08:44:43]
similarity Matrix I think they are okay

[08:44:42 - 08:44:46]
qu similarity

[08:44:43 - 08:44:48]
equation and this parameter will give

[08:44:46 - 08:44:49]
you like number of um return actually it

[08:44:48 - 08:44:52]
will

[08:44:49 - 08:44:55]
provide so uh it will only provide two

[08:44:52 - 08:44:58]
uh answer okay two answer now if I again

[08:44:55 - 08:44:58]
execute this

[08:45:01 - 08:45:07]
code now see guys now length is two okay

[08:45:04 - 08:45:08]
it is only returning two answer okay so

[08:45:07 - 08:45:11]
using this parameter you can set like

[08:45:08 - 08:45:14]
how many uh like answer or how many uh

[08:45:11 - 08:45:16]
similar answer you want okay from your

[08:45:14 - 08:45:19]
uh database okay now see guys it has

[08:45:16 - 08:45:21]
written two or let's say four similar

[08:45:19 - 08:45:23]
answer but I want a specific output

[08:45:21 - 08:45:26]
let's say the question I asked okay

[08:45:23 - 08:45:27]
let's say if I print my document so it's

[08:45:26 - 08:45:30]
a different kinds of answer actually it

[08:45:27 - 08:45:31]
will return okay but it's not

[08:45:30 - 08:45:33]
understandable actually it's like U it

[08:45:31 - 08:45:36]
is giving like lots of answer and all

[08:45:33 - 08:45:38]
okay it's giving lots of text but I want

[08:45:36 - 08:45:40]
like a relevant answer like I just asked

[08:45:38 - 08:45:42]
like how much money did Microsoft raise

[08:45:40 - 08:45:44]
so it should give me like that is the

[08:45:42 - 08:45:45]
money Microsoft raise okay so it should

[08:45:44 - 08:45:47]
give me that kinds of answer but it is

[08:45:45 - 08:45:50]
returning this kinds of document okay

[08:45:47 - 08:45:53]
these kinds of chunks so uh to get a

[08:45:50 - 08:45:55]
specific output okay from your uh data

[08:45:53 - 08:45:59]
you can take a help from the L M so what

[08:45:55 - 08:46:01]
you can do let me show you the diagram

[08:45:59 - 08:46:02]
so let's say this is my this is my

[08:46:01 - 08:46:08]
Vector

[08:46:02 - 08:46:12]
DB Vector DB okay now we have stored our

[08:46:08 - 08:46:12]
uh Vector embedding here Vector

[08:46:12 - 08:46:17]
embedding we have stored here okay now

[08:46:15 - 08:46:20]
you are uh

[08:46:17 - 08:46:22]
giving uh any kinds of query let's say

[08:46:20 - 08:46:26]
this is your query so here in this case

[08:46:22 - 08:46:26]
let's say you ask like how much

[08:46:29 - 08:46:34]
money uh

[08:46:31 - 08:46:36]
Microsoft raise right so this is your

[08:46:34 - 08:46:39]
question so it is returning let's say

[08:46:36 - 08:46:43]
four or let's say two

[08:46:39 - 08:46:45]
output output documents okay but this

[08:46:43 - 08:46:47]
for output documents is not readable

[08:46:45 - 08:46:49]
okay I am not getting my specific answer

[08:46:47 - 08:46:51]
so what I can do I can integrate LM

[08:46:49 - 08:46:52]
model so let's say I will initialize my

[08:46:51 - 08:46:53]
large language model here which is

[08:46:52 - 08:46:56]
nothing but

[08:46:53 - 08:47:00]
GPT T point

[08:46:56 - 08:47:02]
five turbo in this case Okay turbo so

[08:47:00 - 08:47:04]
I'll give this answer to my llm model

[08:47:02 - 08:47:06]
okay I'll give this answer to my llm

[08:47:04 - 08:47:08]
model and llm model will analyze this

[08:47:06 - 08:47:10]
answer it will also Analyze This quy

[08:47:08 - 08:47:12]
okay it will also analyze this quy with

[08:47:10 - 08:47:15]
respect to that it will give me the

[08:47:12 - 08:47:17]
authentic output okay the correct

[08:47:15 - 08:47:19]
output correct meaningful

[08:47:17 - 08:47:21]
output okay that is the power of L&M I

[08:47:19 - 08:47:23]
think you know why it is powerful and

[08:47:21 - 08:47:25]
all okay because it is it has strained

[08:47:23 - 08:47:27]
with huge amount of un instruction data

[08:47:25 - 08:47:29]
so it can perform all kinds of task okay

[08:47:27 - 08:47:32]
that's why uh we will be using llm okay

[08:47:29 - 08:47:33]
to retrieve our specific answer with

[08:47:32 - 08:47:35]
respect to the specific question I'm

[08:47:33 - 08:47:38]
asking okay so this is the idea so now

[08:47:35 - 08:47:41]
to do it actually uh first of all I need

[08:47:38 - 08:47:43]
to make one chain okay so let me just

[08:47:41 - 08:47:47]
comment it out I think you know what is

[08:47:43 - 08:47:48]
chain in uh Lang chain okay so I'm not

[08:47:47 - 08:47:50]
going to explain because I think you

[08:47:48 - 08:47:53]
already learned this uh chain in Lang

[08:47:50 - 08:47:55]
chain okay why we use uh chain and all

[08:47:53 - 08:47:58]
so first of all I need to something

[08:47:55 - 08:48:03]
called retrieval QA chain okay so I'll

[08:47:58 - 08:48:03]
just write from Lang

[08:48:03 - 08:48:10]
chain from Lang chain do

[08:48:07 - 08:48:10]
chains

[08:48:10 - 08:48:15]
input

[08:48:12 - 08:48:17]
retrieval so whenever you are using uh

[08:48:15 - 08:48:19]
Vector database okay it is returning

[08:48:17 - 08:48:21]
retrieval output right like related

[08:48:19 - 08:48:22]
output so you need to use this retrieval

[08:48:21 - 08:48:25]
qway that means retrieval question

[08:48:22 - 08:48:28]
answering chain okay so it will help you

[08:48:25 - 08:48:30]
to ask the question okay to the data

[08:48:28 - 08:48:32]
actually you have stored in your DB okay

[08:48:30 - 08:48:34]
so that's why this chain is required Ral

[08:48:32 - 08:48:36]
question answering so I'll import this

[08:48:34 - 08:48:39]
chain now here first of all you need to

[08:48:36 - 08:48:41]
make one chain so I have already make

[08:48:39 - 08:48:43]
made one chain here so this is the chain

[08:48:41 - 08:48:45]
so I'm just calling retrial Q chain and

[08:48:43 - 08:48:47]
there is a function called from chain

[08:48:45 - 08:48:48]
type so here you need to specify the llm

[08:48:47 - 08:48:52]
model so here in this case I'm using

[08:48:48 - 08:48:54]
open AI llm model okay so let's let me

[08:48:52 - 08:48:57]
show you how it will give you the model

[08:48:54 - 08:49:00]
so if you just run it in a new

[08:48:57 - 08:49:03]
cell now if you print this

[08:49:00 - 08:49:06]
llm so this is nothing but your GPT 3.5

[08:49:03 - 08:49:07]
turbo yeah so it's not giving the name

[08:49:06 - 08:49:10]
but if you see the documentation by

[08:49:07 - 08:49:12]
default whenever you call open a so it

[08:49:10 - 08:49:15]
will give you something called gbt 3.5

[08:49:12 - 08:49:17]
turbo okay this model actually uh if I

[08:49:15 - 08:49:20]
gbt 3.5 so this model actually it will

[08:49:17 - 08:49:21]
return okay so I'll be using this llm

[08:49:20 - 08:49:23]
and here I'm giving this llm model and

[08:49:21 - 08:49:25]
chain type is tough okay I think you

[08:49:23 - 08:49:27]
already know what is chain type and all

[08:49:25 - 08:49:28]
and retriever so you need need to give

[08:49:27 - 08:49:30]
the retriever object here okay this is

[08:49:28 - 08:49:32]
the retriever object so basically

[08:49:30 - 08:49:34]
whatever question uh you are asking okay

[08:49:32 - 08:49:36]
whatever question you are asking uh it

[08:49:34 - 08:49:38]
will return you from this retriever

[08:49:36 - 08:49:40]
right because you have given this

[08:49:38 - 08:49:42]
retriever here okay so that's why you

[08:49:40 - 08:49:44]
need to give this R object here and you

[08:49:42 - 08:49:45]
also need to give the return Source

[08:49:44 - 08:49:48]
documents okay return Source documents

[08:49:45 - 08:49:52]
means U it will return the source also

[08:49:48 - 08:49:54]
like see we have lots of uh we have lots

[08:49:52 - 08:49:56]
of data here if I show you we have lots

[08:49:54 - 08:49:58]
of article here okay now which article

[08:49:56 - 08:49:59]
it is referring to give the answer okay

[08:49:58 - 08:50:00]
it will also give you as a reference

[08:49:59 - 08:50:03]
that article okay so this is the idea of

[08:50:00 - 08:50:03]
this now if I

[08:50:04 - 08:50:11]
execute now let's ask one

[08:50:07 - 08:50:13]
question and print this response okay so

[08:50:11 - 08:50:15]
here I'm calling my qn and this is the

[08:50:13 - 08:50:18]
query same query I'm asking how much did

[08:50:15 - 08:50:20]
Microsoft raise uh the money okay so

[08:50:18 - 08:50:22]
this is the quy I'm giving my inside my

[08:50:20 - 08:50:25]
chain and this is the response of the

[08:50:22 - 08:50:27]
llm now if I print this

[08:50:25 - 08:50:31]
see guys this is the query now it's sing

[08:50:27 - 08:50:33]
around $ 10 billion okay U raas like

[08:50:31 - 08:50:36]
this Microsoft and uh this is the source

[08:50:33 - 08:50:38]
document okay but it's not readable so

[08:50:36 - 08:50:41]
what you can do actually uh you can

[08:50:38 - 08:50:44]
write one function here process LM

[08:50:41 - 08:50:46]
output or process llm response so this

[08:50:44 - 08:50:47]
is the function you can write so

[08:50:46 - 08:50:49]
whatever response it will give it will

[08:50:47 - 08:50:51]
process only like it will give you the

[08:50:49 - 08:50:54]
result source and the answer okay now if

[08:50:51 - 08:50:56]
I execute now if I call this function

[08:50:54 - 08:50:59]
here

[08:50:56 - 08:51:03]
now I'll just remove this response here

[08:50:59 - 08:51:06]
okay now I think it should give me the

[08:51:03 - 08:51:09]
uh yeah so now you can see this is the

[08:51:06 - 08:51:11]
clear output now around $10 billion and

[08:51:09 - 08:51:13]
these are the source actually it has

[08:51:11 - 08:51:16]
referred this two file as a source now

[08:51:13 - 08:51:18]
see guys uh we are able to successfully

[08:51:16 - 08:51:20]
uh store our Vector to the vector

[08:51:18 - 08:51:22]
database and we are also able to make

[08:51:20 - 08:51:24]
the query on top of that and we we also

[08:51:22 - 08:51:27]
saw that like how we can found a similar

[08:51:24 - 08:51:29]
uh of you can output okay using this

[08:51:27 - 08:51:31]
retrieve okay using this retrieve option

[08:51:29 - 08:51:33]
okay so you can ask any different

[08:51:31 - 08:51:35]
question also so let's say I will ask

[08:51:33 - 08:51:39]
another question

[08:51:35 - 08:51:42]
here so uh what is the news about Pand

[08:51:39 - 08:51:44]
so there is again another Pand articles

[08:51:42 - 08:51:46]
you will see inside the data now again

[08:51:44 - 08:51:48]
I'm giving inside my chain and it is

[08:51:46 - 08:51:50]
giving the response and I'm just

[08:51:48 - 08:51:52]
processing the

[08:51:50 - 08:51:55]
response now see Pand is a startup that

[08:51:52 - 08:51:58]
has raised $3 billion uh in a series B

[08:51:55 - 08:52:00]
round and bringing its total raised okay

[08:51:58 - 08:52:02]
so this is the complete answer and this

[08:52:00 - 08:52:05]
is the source it is giving okay I think

[08:52:02 - 08:52:05]
I don't need to print

[08:52:10 - 08:52:15]
this yeah so this is the source so yes

[08:52:13 - 08:52:17]
guys that's how actually you can uh do

[08:52:15 - 08:52:19]
it and one thing I also want to show you

[08:52:17 - 08:52:23]
like how to let's say you want to delete

[08:52:19 - 08:52:23]
this database so how to do it

[08:52:25 - 08:52:31]
so deleting DB so it's like very easy

[08:52:28 - 08:52:34]
first of all you can make a z file okay

[08:52:31 - 08:52:36]
of your existing DB so that later on if

[08:52:34 - 08:52:37]
you want to retri it you can retri it

[08:52:36 - 08:52:39]
okay so first of all I'm making it a z

[08:52:37 - 08:52:40]
file then I'm I'll be deleting it so

[08:52:39 - 08:52:43]
first of all I'll make a z

[08:52:40 - 08:52:45]
file now see guys if I refresh so first

[08:52:43 - 08:52:46]
of all it will make a z file of this DB

[08:52:45 - 08:52:50]
okay now I'll be deleting so this is the

[08:52:46 - 08:52:50]
deleting code so it will clean up

[08:52:51 - 08:52:56]
everything now if I refresh now see uh

[08:52:54 - 08:52:59]
database has been deleted okay now let's

[08:52:56 - 08:53:02]
say uh you want to um get your previous

[08:52:59 - 08:53:04]
DB okay like you had let's say specific

[08:53:02 - 08:53:06]
some specific or let's say important

[08:53:04 - 08:53:10]
Vector there you want to uh get back so

[08:53:06 - 08:53:10]
what you can do you can unzip that zip

[08:53:10 - 08:53:13]
file okay so this is the zip file you

[08:53:12 - 08:53:15]
can unzip now again your database will

[08:53:13 - 08:53:17]
come now what you need to do you need to

[08:53:15 - 08:53:18]
restart the run time okay so just click

[08:53:17 - 08:53:20]
here and there is option called restart

[08:53:18 - 08:53:23]
on time if you restart on time again you

[08:53:20 - 08:53:25]
can able to use your DV same wise okay

[08:53:23 - 08:53:27]
like we already imported out DB right

[08:53:25 - 08:53:29]
here so here that's how you can uh load

[08:53:27 - 08:53:31]
your DB again okay so this is the

[08:53:29 - 08:53:32]
functionality actually chroma DB

[08:53:31 - 08:53:33]
provides okay uh if you see the

[08:53:32 - 08:53:34]
documentation they have written

[08:53:33 - 08:53:36]
everything even they have also given the

[08:53:34 - 08:53:39]
stter notebook and all okay so guys I

[08:53:36 - 08:53:40]
think as of now you got the entire idea

[08:53:39 - 08:53:42]
about the chroma DB like how we can use

[08:53:40 - 08:53:44]
chromat Vector database and how we can

[08:53:42 - 08:53:46]
connect the large language model and how

[08:53:44 - 08:53:48]
we can perform this uh let's say Vector

[08:53:46 - 08:53:50]
sarce operation right so one thing I

[08:53:48 - 08:53:53]
just wanted to show you see if you click

[08:53:50 - 08:53:53]
on the integration see this chroma DV is

[08:53:53 - 08:53:55]
having like different different

[08:53:53 - 08:53:57]
integration that means you can use

[08:53:55 - 08:53:59]
chroma with openi Google gini CAD

[08:53:57 - 08:54:02]
hugging face okay instructor hugging

[08:53:59 - 08:54:04]
face embedding server G roof flow okay

[08:54:02 - 08:54:06]
Allama embeddings everything you can use

[08:54:04 - 08:54:08]
okay everything you can use with this

[08:54:06 - 08:54:10]
chrom RB now you can see some framework

[08:54:08 - 08:54:12]
integration like it can also support

[08:54:10 - 08:54:15]
Lang chin llama index then brain tast

[08:54:12 - 08:54:17]
open uh llm uh llm tree okay then uh

[08:54:15 - 08:54:19]
stream lead highest stack open lead so

[08:54:17 - 08:54:21]
these are the framework also you can

[08:54:19 - 08:54:23]
connect okay that means it has actually

[08:54:21 - 08:54:24]
all the integration uh if you're using

[08:54:23 - 08:54:25]
different different framework different

[08:54:24 - 08:54:27]
different let's say large language model

[08:54:25 - 08:54:29]
different different platform everything

[08:54:27 - 08:54:30]
it can support okay so as of now we saw

[08:54:29 - 08:54:32]
like how we can use with the help of

[08:54:30 - 08:54:33]
Lang chain going forward we will be also

[08:54:32 - 08:54:36]
learning how we can use with the help of

[08:54:33 - 08:54:37]
llama index and so on right so yes guys

[08:54:36 - 08:54:38]
this is all about from this video in the

[08:54:37 - 08:54:41]
next video we'll be learning another

[08:54:38 - 08:54:42]
amazing uh Vector database called uh

[08:54:41 - 08:54:44]
Pine con and pine con is a cloudbased

[08:54:42 - 08:54:46]
vector database that means we can store

[08:54:44 - 08:54:47]
our embeddings in the cloud platform as

[08:54:46 - 08:54:49]
I already told you Pine con is a

[08:54:47 - 08:54:51]
cloud-based Vector DB that means you can

[08:54:49 - 08:54:53]
store your embeddings to the cloud so if

[08:54:51 - 08:54:55]
you want to use pine cor so search for

[08:54:53 - 08:54:57]
actually pine cone in the Google so Pine

[08:54:55 - 08:54:58]
con so you will get the first website

[08:54:57 - 08:55:00]
just try to open it up and make sure you

[08:54:58 - 08:55:02]
create one account okay you just need to

[08:55:00 - 08:55:03]
create one account inside this website

[08:55:02 - 08:55:05]
so for this you just do the sign up

[08:55:03 - 08:55:07]
operation so with the help of your

[08:55:05 - 08:55:08]
Google account you can create one

[08:55:07 - 08:55:10]
account so once you have the account

[08:55:08 - 08:55:11]
just try to do the login so I already

[08:55:10 - 08:55:13]
have the account so I'll just try to do

[08:55:11 - 08:55:14]
the login here so once you have logged

[08:55:13 - 08:55:16]
in guys you will get this kinds of

[08:55:14 - 08:55:18]
dashboard so guys now let's try to see

[08:55:16 - 08:55:20]
how we can use this Pine con Vector

[08:55:18 - 08:55:21]
database to instore our embeddings so

[08:55:20 - 08:55:24]
guys what I've done I already recorded

[08:55:21 - 08:55:25]
one video previously on this Pine con

[08:55:24 - 08:55:27]
that detailed video how to use this Pine

[08:55:25 - 08:55:29]
con and all so I'll add this video here

[08:55:27 - 08:55:31]
so this video will give you the entire

[08:55:29 - 08:55:33]
idea how we can use this Pine con with

[08:55:31 - 08:55:35]
the Lang Channel all so guys as you can

[08:55:33 - 08:55:36]
see recently they have updated their

[08:55:35 - 08:55:38]
dashboard but previously uh it was

[08:55:36 - 08:55:39]
actually different kinds of dashboard

[08:55:38 - 08:55:42]
but see functionality wise it is same

[08:55:39 - 08:55:43]
you have to use as it is but somehow

[08:55:42 - 08:55:45]
actually they have updated some kinds of

[08:55:43 - 08:55:47]
actually dashboard you can see uh

[08:55:45 - 08:55:49]
previously this index was like out that

[08:55:47 - 08:55:51]
means there was a option called index

[08:55:49 - 08:55:52]
directly create index option was there

[08:55:51 - 08:55:54]
but they have actually created this

[08:55:52 - 08:55:56]
index now inside databases okay see ins

[08:55:54 - 08:55:58]
databases now there is a index option so

[08:55:56 - 08:55:59]
guys this Pine con is not a free Vector

[08:55:58 - 08:56:00]
database for this actually you have to

[08:55:59 - 08:56:02]
take the subscription but if you

[08:56:00 - 08:56:04]
creating let's say new account for the

[08:56:02 - 08:56:06]
first time here you will get actually

[08:56:04 - 08:56:07]
free actually some storage that means 2

[08:56:06 - 08:56:09]
GB storage you will get that means you

[08:56:07 - 08:56:11]
can only create one index there that

[08:56:09 - 08:56:13]
means one cluster you can create so if I

[08:56:11 - 08:56:15]
click on the create index you will see I

[08:56:13 - 08:56:17]
can only create one index and and

[08:56:15 - 08:56:18]
whenever you are creating uh free index

[08:56:17 - 08:56:20]
make sure you are selecting Google Cloud

[08:56:18 - 08:56:22]
okay not any other Cloud otherwise

[08:56:20 - 08:56:24]
actually it will ask for the charge see

[08:56:22 - 08:56:26]
I already occupied my let's say free

[08:56:24 - 08:56:28]
plan now if I click here see it will ask

[08:56:26 - 08:56:29]
for the upgrade that means I have to

[08:56:28 - 08:56:31]
upgrade with their let's say

[08:56:29 - 08:56:33]
subscription I already utilized the free

[08:56:31 - 08:56:35]
plan but for you actually will see the

[08:56:33 - 08:56:36]
free plan option is there because you

[08:56:35 - 08:56:38]
have created the new account but for me

[08:56:36 - 08:56:40]
I already use this uh account okay

[08:56:38 - 08:56:42]
that's why uh it is showing I don't have

[08:56:40 - 08:56:43]
any free plan right now fine so make

[08:56:42 - 08:56:47]
sure guys you just try to create on new

[08:56:43 - 08:56:48]
account and try to use this Pine con and

[08:56:47 - 08:56:50]
to create the API key guys just click on

[08:56:48 - 08:56:52]
the API key and here you can create the

[08:56:50 - 08:56:54]
API key okay and this API keyy will help

[08:56:52 - 08:56:56]
you to connect with your uh this Pine

[08:56:54 - 08:56:58]
con server okay from your python code

[08:56:56 - 08:57:01]
now let's try to see how we can use this

[08:56:58 - 08:57:03]
Pine con uh Vector database with our

[08:57:01 - 08:57:05]
Lang Chen and guys one thing uh whenever

[08:57:03 - 08:57:07]
you're installing Pine con client make

[08:57:05 - 08:57:10]
sure you're installing 2.2.4 okay this

[08:57:07 - 08:57:11]
particular version because uh whenever

[08:57:10 - 08:57:13]
uh I was using this pine cone that time

[08:57:11 - 08:57:15]
actually this version was the stable

[08:57:13 - 08:57:17]
version and try to use this version guys

[08:57:15 - 08:57:18]
because this version will help you a lot

[08:57:17 - 08:57:20]
because it is like it is having like

[08:57:18 - 08:57:22]
very easy syntax to store the embeddings

[08:57:20 - 08:57:25]
to the Pine gon server so make sure

[08:57:22 - 08:57:26]
you're installing this 2.2 four version

[08:57:25 - 08:57:28]
so let's try to see how we can use this

[08:57:26 - 08:57:31]
fine gun right now first of all you need

[08:57:28 - 08:57:33]
to install uh some required packages so

[08:57:31 - 08:57:37]
just let

[08:57:33 - 08:57:37]
me write down the comments

[08:57:37 - 08:57:41]
here

[08:57:38 - 08:57:43]
so I'll installing these are the

[08:57:41 - 08:57:46]
packages so I'll be installing something

[08:57:43 - 08:57:48]
called langen then uh Pine con client

[08:57:46 - 08:57:50]
okay so if you want to so if you want to

[08:57:48 - 08:57:52]
use this Pine con uh Vector DV so you

[08:57:50 - 08:57:54]
need to install this package called Pine

[08:57:52 - 08:57:56]
con client and this is the python

[08:57:54 - 08:57:58]
package and it will help you to connect

[08:57:56 - 08:58:00]
with this Pine con okay then I also need

[08:57:58 - 08:58:02]
P PDF Li because uh here I'm going to

[08:58:00 - 08:58:05]
load PDF data so previously I showed

[08:58:02 - 08:58:06]
like how to load txt data now I will

[08:58:05 - 08:58:08]
show you like how to load PDF data so

[08:58:06 - 08:58:10]
I'll show you like all kinds of data

[08:58:08 - 08:58:11]
like how to load and all okay so that's

[08:58:10 - 08:58:14]
why I need uh to install these are the

[08:58:11 - 08:58:14]
packages so let me

[08:58:16 - 08:58:20]
install so guys as you can see my

[08:58:18 - 08:58:23]
installation is done now I'll take some

[08:58:20 - 08:58:26]
new cell and here I also need open Ai

[08:58:23 - 08:58:28]
and T token okay I think you already saw

[08:58:26 - 08:58:30]
from my previous demo so openi is also

[08:58:28 - 08:58:32]
needed because I'm going to use open

[08:58:30 - 08:58:33]
embedding and as well as this tick token

[08:58:32 - 08:58:37]
uh because I'm going to use open

[08:58:33 - 08:58:37]
embedding so Tik token is the dependency

[08:58:39 - 08:58:45]
there now installation is done now let's

[08:58:41 - 08:58:45]
import some of the Liberties

[08:58:52 - 08:58:56]
here so here I'm going to import these

[08:58:54 - 08:58:57]
are the libraries and I think you are

[08:58:56 - 08:59:00]
already familiar with these are the

[08:58:57 - 08:59:02]
libraries why I'm loading and all I also

[08:59:00 - 08:59:04]
need something called operating system

[08:59:02 - 08:59:07]
so I need this Pi PDF reader loader

[08:59:04 - 08:59:08]
because here I'm going to read like PDF

[08:59:07 - 08:59:10]
data so for this actually I need to load

[08:59:08 - 08:59:12]
this one from documents loader but

[08:59:10 - 08:59:13]
previously I was loading like text

[08:59:12 - 08:59:16]
loader okay so this is the difference

[08:59:13 - 08:59:18]
then recursive character text splitter

[08:59:16 - 08:59:20]
means like you want to make uh your data

[08:59:18 - 08:59:22]
as a chunks because I told you why this

[08:59:20 - 08:59:24]
chunks is required and all so that's why

[08:59:22 - 08:59:26]
this is needed and open embedding I will

[08:59:24 - 08:59:28]
be using and open llm model that means

[08:59:26 - 08:59:32]
GP 3.5 turbo so for this actually I'm

[08:59:28 - 08:59:34]
using this open llm then uh from uh Lang

[08:59:32 - 08:59:37]
chin I'm also going U and here from

[08:59:34 - 08:59:38]
langin I'm also importing like vector

[08:59:37 - 08:59:40]
restore which is nothing but my Pine con

[08:59:38 - 08:59:43]
but previously I was loading my chroma

[08:59:40 - 08:59:46]
DB and uh retrieve retrieval QA means

[08:59:43 - 08:59:48]
like you can also make some uh question

[08:59:46 - 08:59:49]
answer okay on top of your uh data uh

[08:59:48 - 08:59:51]
you have stored in the vector database I

[08:59:49 - 08:59:53]
think I was discussing okay with the

[08:59:51 - 08:59:54]
help of this chain then you can also

[08:59:53 - 08:59:56]
import something called prompt template

[08:59:54 - 08:59:58]
uh basically you can uh give your custom

[08:59:56 - 09:00:00]
prompt here so this is also possible

[08:59:58 - 09:00:03]
okay I'll show you one demo here so

[09:00:00 - 09:00:03]
let's import this at the

[09:00:05 - 09:00:10]
library so first of all here what I will

[09:00:07 - 09:00:10]
do I will create one

[09:00:10 - 09:00:16]
folder uh so let me first of all give

[09:00:13 - 09:00:16]
one title like load

[09:00:17 - 09:00:23]
data so first of all I'm going to create

[09:00:20 - 09:00:25]
one folder here um called PDFs so inside

[09:00:23 - 09:00:27]
that I will download some of the PDFs I

[09:00:25 - 09:00:29]
have in my Google Drive so this is the

[09:00:27 - 09:00:31]
code to download anything from the

[09:00:29 - 09:00:33]
Google Drive so here if you see in

[09:00:31 - 09:00:36]
Google Drive you will see this ID okay

[09:00:33 - 09:00:38]
of any kinds of file otherwise you can U

[09:00:36 - 09:00:40]
download it and manually upload it

[09:00:38 - 09:00:42]
inside okay it is also fine but I'm just

[09:00:40 - 09:00:45]
downloading so I have one uh yellow V7

[09:00:42 - 09:00:47]
paper in my Google Drive and also I

[09:00:45 - 09:00:49]
downloaded one uh resume okay like uh

[09:00:47 - 09:00:51]
from Google itself I've downloaded one

[09:00:49 - 09:00:54]
resume uh so called so the name of the

[09:00:51 - 09:00:55]
resume is like richel G CV okay so this

[09:00:54 - 09:00:58]
is the resume I have downloaded so this

[09:00:55 - 09:01:00]
two file I'm going to download uh inside

[09:00:58 - 09:01:02]
my PDF

[09:01:00 - 09:01:03]
folder and with the help of this G down

[09:01:02 - 09:01:05]
package you can download anything from

[09:01:03 - 09:01:07]
the Google Drive now if I refresh and if

[09:01:05 - 09:01:10]
I show you my PDF so see these are my

[09:01:07 - 09:01:13]
data are available inside that okay now

[09:01:10 - 09:01:15]
what I will do first of all I need to

[09:01:13 - 09:01:18]
extract the text from the PDF so for

[09:01:15 - 09:01:22]
this uh let me give one title

[09:01:18 - 09:01:24]
here so how to extract the text from the

[09:01:22 - 09:01:26]
PDF so this is the code you need to take

[09:01:24 - 09:01:28]
the help from P PDF uh directory loaded

[09:01:26 - 09:01:30]
and here you just need to provide the

[09:01:28 - 09:01:32]
path of the PDF file you have so this is

[09:01:30 - 09:01:34]
my path like PDF so here I'm giving the

[09:01:32 - 09:01:35]
path and once uh you have given the path

[09:01:34 - 09:01:37]
you just need to call this load function

[09:01:35 - 09:01:39]
and it will automatically load the data

[09:01:37 - 09:01:41]
so let me show

[09:01:39 - 09:01:45]
you so it has loaded my data now if I

[09:01:41 - 09:01:48]
print my data you will able to see my

[09:01:45 - 09:01:51]
data see guys all of the data has been

[09:01:48 - 09:01:53]
extracted okay now what I need to do I

[09:01:51 - 09:01:57]
need to uh convert it to chunks because

[09:01:53 - 09:02:00]
I can't um directly convert it to my

[09:01:57 - 09:02:02]
Vector because uh input size might be

[09:02:00 - 09:02:03]
vary because I told you uh whenever you

[09:02:02 - 09:02:05]
are using a large language model so it

[09:02:03 - 09:02:07]
has one input size okay so you always

[09:02:05 - 09:02:08]
need to take care the input size so

[09:02:07 - 09:02:11]
that's why uh we need to create as a

[09:02:08 - 09:02:12]
chunks so uh to create the Chun so this

[09:02:11 - 09:02:14]
is the code I think you remember so I'll

[09:02:12 - 09:02:16]
be just calling this recursive character

[09:02:14 - 09:02:19]
text splitter and here you need to give

[09:02:16 - 09:02:20]
Chun size and chunks overlap okay I I

[09:02:19 - 09:02:22]
think I have already discussed what is

[09:02:20 - 09:02:25]
Chun size and Chun overlap then uh

[09:02:22 - 09:02:27]
simply I'll just uh execute it then I

[09:02:25 - 09:02:31]
will apply on top of my

[09:02:27 - 09:02:34]
data okay so this is my entire data and

[09:02:31 - 09:02:35]
here I'm passing this in my text lior

[09:02:34 - 09:02:39]
object okay now it will give me that

[09:02:35 - 09:02:43]
text chunks now let me execute and show

[09:02:39 - 09:02:45]
you so guys uh this is my text

[09:02:43 - 09:02:48]
chunks okay see uh this is another

[09:02:45 - 09:02:52]
chunks this is another chunks so let me

[09:02:48 - 09:02:55]
see like uh how many chunks I got here

[09:02:52 - 09:02:55]
so length

[09:02:55 - 09:03:01]
takech chunks so I got around 168 chunks

[09:02:59 - 09:03:03]
here okay now if you want to see any

[09:03:01 - 09:03:06]
specific Chun so you can also print

[09:03:03 - 09:03:10]
let's say I want to see number

[09:03:06 - 09:03:10]
one you can also print for

[09:03:11 - 09:03:16]
other this is number two okay now here

[09:03:14 - 09:03:17]
if you read it carefully you'll able to

[09:03:16 - 09:03:19]
see like also some chunks overlap is

[09:03:17 - 09:03:22]
also there like some uh text is coming

[09:03:19 - 09:03:25]
from the previous chunks also okay now

[09:03:22 - 09:03:28]
guys uh you can also print like third

[09:03:25 - 09:03:28]
one as

[09:03:30 - 09:03:36]
well now guys uh first of all I need to

[09:03:33 - 09:03:38]
download the embedding so download the

[09:03:36 - 09:03:40]
embedding first of all you need to set

[09:03:38 - 09:03:42]
up the environment uh you need to first

[09:03:40 - 09:03:45]
of all what you need to do you need to

[09:03:42 - 09:03:47]
set up your openi API key okay so I

[09:03:45 - 09:03:49]
think you remember uh I can use my

[09:03:47 - 09:03:51]
previous notebook so in my previous

[09:03:49 - 09:03:53]
notebook I already created this API key

[09:03:51 - 09:03:55]
and I already set up my environment I'll

[09:03:53 - 09:03:58]
just copy copy this code and here I will

[09:03:55 - 09:04:02]
paste it okay now I'll set my OPI open

[09:03:58 - 09:04:04]
API key so let me set it here now first

[09:04:02 - 09:04:06]
of all I need to download the embeddings

[09:04:04 - 09:04:07]
so this is the code for it so it will

[09:04:06 - 09:04:10]
give you the

[09:04:07 - 09:04:13]
embeddings like open embeddings now

[09:04:10 - 09:04:16]
first of all let me test one uh thing

[09:04:13 - 09:04:19]
here so what I can do uh I'll just call

[09:04:16 - 09:04:21]
my embedding like I just want to show

[09:04:19 - 09:04:23]
you like uh what is the length of the

[09:04:21 - 09:04:24]
vector it will generate okay so I'll

[09:04:23 - 09:04:26]
just call

[09:04:24 - 09:04:29]
embedding do

[09:04:26 - 09:04:31]
embed embed query and here if you pass

[09:04:29 - 09:04:32]
any word let's say I will give hello

[09:04:31 - 09:04:34]
okay now if I

[09:04:32 - 09:04:37]
execute

[09:04:34 - 09:04:39]
uh you will able to see the vector okay

[09:04:37 - 09:04:41]
see this is the representation of the

[09:04:39 - 09:04:42]
hello okay and this is the uh Vector

[09:04:41 - 09:04:44]
okay this is the vector representation

[09:04:42 - 09:04:46]
numerical representation so I'll store

[09:04:44 - 09:04:52]
it

[09:04:46 - 09:04:52]
uh u in a variable called r

[09:04:55 - 09:05:02]
okay now if I uh show you the length of

[09:04:58 - 09:05:02]
this results so let me see the vector

[09:05:03 - 09:05:09]
length yeah so uh by default actually if

[09:05:07 - 09:05:12]
you're using open AI embedding so the

[09:05:09 - 09:05:15]
each Vector length would be uh

[09:05:12 - 09:05:17]
1,5 36 let's say if I give any any word

[09:05:15 - 09:05:20]
here let's say I'll give uh something

[09:05:17 - 09:05:22]
called uh good okay let's say good if I

[09:05:20 - 09:05:25]
give good so you will see uh the length

[09:05:22 - 09:05:29]
would be same okay now if I give let's

[09:05:25 - 09:05:31]
say anything like uh I can give hello or

[09:05:29 - 09:05:35]
let's say how are you how are

[09:05:31 - 09:05:37]
you so again the length would be

[09:05:35 - 09:05:39]
same see length would be same so

[09:05:37 - 09:05:41]
basically what is happening I think I

[09:05:39 - 09:05:44]
was discussing uh this thing in my

[09:05:41 - 09:05:47]
uh uh theoretical lecture so whenever it

[09:05:44 - 09:05:49]
is uh like trying to generate this kinds

[09:05:47 - 09:05:51]
of vectors okay so it was following this

[09:05:49 - 09:05:53]
approach basically it was creating some

[09:05:51 - 09:05:54]
features okay so with the help of the

[09:05:53 - 09:05:56]
features actually it was uh generating

[09:05:54 - 09:05:58]
these kinds of vector so basically what

[09:05:56 - 09:06:00]
is happening so the sentence you have

[09:05:58 - 09:06:02]
given so uh this sentence is

[09:06:00 - 09:06:03]
representing uh in this Dimension

[09:06:02 - 09:06:07]
actually

[09:06:03 - 09:06:09]
1,5 and3 uh 36 okay this is the

[09:06:07 - 09:06:12]
dimension of the sentence okay and it is

[09:06:09 - 09:06:14]
representing in that here I was

[09:06:12 - 09:06:16]
referring this uh word by word but you

[09:06:14 - 09:06:19]
can refer as a sentence by sentence so

[09:06:16 - 09:06:22]
basically this uh King is uh appearing

[09:06:19 - 09:06:24]
in this Dimension actually 1 2 3 4 5 6

[09:06:22 - 09:06:26]
okay six feature we have cre so this was

[09:06:24 - 09:06:28]
the six Dimension okay six Dimension uh

[09:06:26 - 09:06:30]
this six uh this King was representing

[09:06:28 - 09:06:32]
there okay but whenever I'm uh using

[09:06:30 - 09:06:34]
open AI so I have written like how are

[09:06:32 - 09:06:36]
you there okay how are you is

[09:06:34 - 09:06:41]
representing with the help of

[09:06:36 - 09:06:43]
1,590 um sorry 1,536 Vector okay that is

[09:06:41 - 09:06:44]
the this is the dimension okay if you if

[09:06:43 - 09:06:46]
I plot it okay so this should be the

[09:06:44 - 09:06:48]
dimension and this is the representation

[09:06:46 - 09:06:49]
of the how are you okay I think you are

[09:06:48 - 09:06:51]
getting like how it is generating this

[09:06:49 - 09:06:52]
vector and all okay so if you give any

[09:06:51 - 09:06:55]
sentence here so this should be the

[09:06:52 - 09:06:57]
length so now now I need to store uh

[09:06:55 - 09:07:00]
these are the vectors okay like uh I

[09:06:57 - 09:07:02]
will apply this vectors embedding on top

[09:07:00 - 09:07:04]
of my data I have uh created the chunks

[09:07:02 - 09:07:06]
then I will store it on uh in my Pine

[09:07:04 - 09:07:08]
con Vector database so for this first of

[09:07:06 - 09:07:12]
all I need to initialize the pine cone

[09:07:08 - 09:07:12]
so let me initialize

[09:07:12 - 09:07:19]
it so uh for this first of all what you

[09:07:15 - 09:07:21]
need to do you need to collect uh uh

[09:07:19 - 09:07:23]
some uh pine cone

[09:07:21 - 09:07:25]
credential so you need to collect like

[09:07:23 - 09:07:27]
Pine con API key and pine con

[09:07:25 - 09:07:28]
environment okay so how to collect it so

[09:07:27 - 09:07:32]
just go to Pine

[09:07:28 - 09:07:33]
con and this is my uh dashboard and here

[09:07:32 - 09:07:36]
I already told you how to collect this

[09:07:33 - 09:07:38]
API key just create a API key and try to

[09:07:36 - 09:07:40]
just copy and here just replace your

[09:07:38 - 09:07:43]
value okay no need to use my value

[09:07:40 - 09:07:45]
because I'll be removing my keys so you

[09:07:43 - 09:07:47]
need to use uh your value okay so just

[09:07:45 - 09:07:49]
try to replace this value okay then you

[09:07:47 - 09:07:51]
need to uh also collect something called

[09:07:49 - 09:07:55]
uh Pine con API environment okay so how

[09:07:51 - 09:07:56]
to collect it so here if I go go to now

[09:07:55 - 09:07:57]
just click on index so here you just

[09:07:56 - 09:07:59]
need to create one index here so first

[09:07:57 - 09:08:01]
of all it would be empty and here you

[09:07:59 - 09:08:04]
just only can create one index because

[09:08:01 - 09:08:06]
it's a free uh one I am using okay now

[09:08:04 - 09:08:08]
I'll just click on create index and need

[09:08:06 - 09:08:10]
to give the name so here I'm using let's

[09:08:08 - 09:08:13]
say this is my test uh or you can give

[09:08:10 - 09:08:15]
any name I'm I'll give test test index

[09:08:13 - 09:08:17]
and here you just need to specify the

[09:08:15 - 09:08:18]
dimension of the vector okay now here I

[09:08:17 - 09:08:20]
already showed you so this is the

[09:08:18 - 09:08:23]
dimension of my each Vector okay so this

[09:08:20 - 09:08:25]
is the dimension I'll copy this value

[09:08:23 - 09:08:27]
and here I'll just write it and you can

[09:08:25 - 09:08:29]
also select the metrics like what kinds

[09:08:27 - 09:08:32]
of metric you want to use to retrieve

[09:08:29 - 09:08:34]
your similar kinds of vector okay so by

[09:08:32 - 09:08:37]
default it is cosine you can also use

[09:08:34 - 09:08:38]
ukian and Dot product but uh cosine is a

[09:08:37 - 09:08:41]
little bit fast okay because if it

[09:08:38 - 09:08:43]
calculating cosine distance okay so uh

[09:08:41 - 09:08:45]
uh it will be like little bit fast okay

[09:08:43 - 09:08:46]
to calculate because I already I was

[09:08:45 - 09:08:49]
already discussing right if I show you

[09:08:46 - 09:08:51]
that uh graph so see if I want to

[09:08:49 - 09:08:53]
calculate cosine similarity within this

[09:08:51 - 09:08:54]
two Vector so it will just create one

[09:08:53 - 09:08:56]
angle here and it will give me the

[09:08:54 - 09:08:58]
cosine similarity score but if I'm using

[09:08:56 - 09:09:00]
nule distance so it will just calculate

[09:08:58 - 09:09:02]
with respect to all the data points I

[09:09:00 - 09:09:04]
have here okay so that's why cosine is

[09:09:02 - 09:09:08]
uh first of in this case okay so I'll be

[09:09:04 - 09:09:10]
using cosine metric now here uh this is

[09:09:08 - 09:09:11]
the default pod you need to select and

[09:09:10 - 09:09:14]
this is the free plan I already told you

[09:09:11 - 09:09:14]
now I'll just create the

[09:09:15 - 09:09:20]
index now see guys it is initializing so

[09:09:17 - 09:09:21]
you need to wait for some times once uh

[09:09:20 - 09:09:23]
it is done so it will give you this uh

[09:09:21 - 09:09:25]
green status okay now see guys has

[09:09:23 - 09:09:26]
created now here you will see the

[09:09:25 - 09:09:29]
environment name okay and this is the

[09:09:26 - 09:09:31]
gcp provider so basically this uh uh

[09:09:29 - 09:09:34]
cluster has been created in the gcp

[09:09:31 - 09:09:37]
cloud and this is the region and this is

[09:09:34 - 09:09:39]
the uh uh environment name so this

[09:09:37 - 09:09:40]
parameter you can set if you're taking

[09:09:39 - 09:09:42]
their paid subscription but by default

[09:09:40 - 09:09:43]
if you're using three one so they will

[09:09:42 - 09:09:45]
assign these kinds of provider and

[09:09:43 - 09:09:47]
region okay now I'll copy this

[09:09:45 - 09:09:48]
environment name and here I'll just need

[09:09:47 - 09:09:49]
to replace okay so for me I have already

[09:09:48 - 09:09:52]
replaced which is nothing but gcp

[09:09:49 - 09:09:55]
starter okay now let me just quickly set

[09:09:52 - 09:09:57]
this uh uh environment variables okay

[09:09:55 - 09:09:59]
inside my environment now here I will

[09:09:57 - 09:10:00]
initialize my pine cone so if you visit

[09:09:59 - 09:10:02]
pine cone documentation so they have

[09:10:00 - 09:10:04]
given this code like that's how you need

[09:10:02 - 09:10:07]
to initialize Pine con so here you just

[09:10:04 - 09:10:08]
need to provide this API key so here is

[09:10:07 - 09:10:11]
my API key it will read from my

[09:10:08 - 09:10:12]
environment and here is my Pine con API

[09:10:11 - 09:10:14]
environment so this is the environment

[09:10:12 - 09:10:15]
so it will automatically read it and it

[09:10:14 - 09:10:17]
will initialize that okay and here you

[09:10:15 - 09:10:19]
also need to provide the index name so

[09:10:17 - 09:10:21]
this is my index index name we have

[09:10:19 - 09:10:22]
created called test but if you creating

[09:10:21 - 09:10:24]
any other name you can give the same

[09:10:22 - 09:10:29]
name here now let let me just quickly

[09:10:24 - 09:10:29]
initialize this pine cone yeah so it has

[09:10:29 - 09:10:34]
initialized now what I need to do I need

[09:10:31 - 09:10:37]
to create embeddings from my chunks so

[09:10:34 - 09:10:37]
let me first of all

[09:10:37 - 09:10:42]
comment so to create the embeddings from

[09:10:40 - 09:10:45]
the Chun so this is the particular code

[09:10:42 - 09:10:47]
you need to execute so first of all uh

[09:10:45 - 09:10:49]
here whatever embedding I'll be

[09:10:47 - 09:10:50]
generating okay so I'll store it my pine

[09:10:49 - 09:10:53]
cone that's why I'm just writing writing

[09:10:50 - 09:10:55]
pine cone from text okay and here I just

[09:10:53 - 09:10:56]
written one list comprehension okay I

[09:10:55 - 09:10:59]
think you know list comprehension in

[09:10:56 - 09:11:00]
Python okay so basically the chunks uh

[09:10:59 - 09:11:02]
text chunks I have so I'm just reading

[09:11:00 - 09:11:05]
one by one then I'm just reading the

[09:11:02 - 09:11:06]
page content okay then uh this is my

[09:11:05 - 09:11:08]
embedding object I think you remember so

[09:11:06 - 09:11:10]
this is my embedding object and I'm also

[09:11:08 - 09:11:12]
passing my embedding okay embedding

[09:11:10 - 09:11:13]
objects and also I'm giving my index

[09:11:12 - 09:11:15]
name okay that means this is the index

[09:11:13 - 09:11:16]
name so this pine cone client will

[09:11:15 - 09:11:19]
automatically take it and it will

[09:11:16 - 09:11:20]
automatically uh convert your chunks to

[09:11:19 - 09:11:22]
embedding with the help of this

[09:11:20 - 09:11:24]
embedding objects and it will rest

[09:11:22 - 09:11:25]
inside this index name that means my

[09:11:24 - 09:11:28]
this index okay inside this index it

[09:11:25 - 09:11:29]
will store all of my Vector okay and it

[09:11:28 - 09:11:32]
will give you one object called docar

[09:11:29 - 09:11:34]
okay now let me just quickly uh execute

[09:11:32 - 09:11:37]
and show you what will

[09:11:34 - 09:11:39]
happen see guys it is taking all of my

[09:11:37 - 09:11:41]
chunks one by one and it has converted

[09:11:39 - 09:11:43]
to vectors and it has stored inside the

[09:11:41 - 09:11:46]
pine con uh cluster now if I go to my

[09:11:43 - 09:11:48]
Pine con cluster and here if I refresh

[09:11:46 - 09:11:51]
this

[09:11:48 - 09:11:53]
page so guys as you can see I refreshed

[09:11:51 - 09:11:55]
my page and now I able to see all of the

[09:11:53 - 09:11:58]
vector here if you see if you just click

[09:11:55 - 09:12:00]
on browsers so here is the vector okay

[09:11:58 - 09:12:03]
and first of all it will show you like

[09:12:00 - 09:12:04]
top uh like 50 Vector here if you see

[09:12:03 - 09:12:07]
this is the representation so this is

[09:12:04 - 09:12:09]
the text and on top of that actually

[09:12:07 - 09:12:11]
this is my Vector okay I'm getting so

[09:12:09 - 09:12:13]
you can also copy the vector and you can

[09:12:11 - 09:12:15]
also see okay and the length of the

[09:12:13 - 09:12:17]
vector is uh this one actually I think

[09:12:15 - 09:12:20]
you remember um

[09:12:17 - 09:12:22]
1,536 okay this is the length and this

[09:12:20 - 09:12:24]
is the beauty of this Cloud uh Vector DB

[09:12:22 - 09:12:26]
you can see your vector here like how

[09:12:24 - 09:12:28]
this Vector has been created and what is

[09:12:26 - 09:12:30]
the text with respect to that and you

[09:12:28 - 09:12:32]
can also see the scores okay like what

[09:12:30 - 09:12:34]
is the scores uh uh with respect to

[09:12:32 - 09:12:36]
these vectors like this is the distance

[09:12:34 - 09:12:37]
actually okay that's how it create the

[09:12:36 - 09:12:39]
index okay I think I was also talking

[09:12:37 - 09:12:41]
about like index in Vector database

[09:12:39 - 09:12:44]
right indexes in Vector database this is

[09:12:41 - 09:12:46]
the score okay using this score actually

[09:12:44 - 09:12:48]
it try to figure out the similar kinds

[09:12:46 - 09:12:49]
of vector whenever you start any quity

[09:12:48 - 09:12:52]
right so this is the beauty of this

[09:12:49 - 09:12:55]
vector and I love this uh pine cone one

[09:12:52 - 09:12:56]
because it looks look very uh easy and

[09:12:55 - 09:12:58]
it's like very beautiful interface it

[09:12:56 - 09:13:00]
provides okay and you can also see the

[09:12:58 - 09:13:01]
second page and you can see all kinds of

[09:13:00 - 09:13:04]
vector here even you can also change the

[09:13:01 - 09:13:07]
parameter let's say I want to see top

[09:13:04 - 09:13:10]
100 Vector here so if I just U search

[09:13:07 - 09:13:12]
the query so it will give me all all the

[09:13:10 - 09:13:14]
100 okay 100 Vector here okay so yes

[09:13:12 - 09:13:16]
guys and you can also see the Matrix

[09:13:14 - 09:13:18]
like how many times you are raising the

[09:13:16 - 09:13:20]
request and all so it will give you all

[09:13:18 - 09:13:23]
kinds of log here like if any request is

[09:13:20 - 09:13:25]
failed so it will give the logs and

[09:13:23 - 09:13:29]
everything it will give you okay so yes

[09:13:25 - 09:13:31]
so this is the simple uh interface of my

[09:13:29 - 09:13:37]
this pine cone and Vector counts

[09:13:31 - 09:13:39]
is U 68 because if I show you uh if I

[09:13:37 - 09:13:42]
show you my uh chunks okay my chunk size

[09:13:39 - 09:13:45]
was 168 so that's why you you are able

[09:13:42 - 09:13:47]
to see this uh Vector count is 68

[09:13:45 - 09:13:48]
because I have 168 chunks so with

[09:13:47 - 09:13:51]
respect to that this Vector has been

[09:13:48 - 09:13:53]
created okay so yes case this is all

[09:13:51 - 09:13:56]
about my pine cone one now we are able

[09:13:53 - 09:13:57]
to successfully store our uh data here

[09:13:56 - 09:14:00]
and this is the cosine and this is the

[09:13:57 - 09:14:02]
dimension and all kinds of host and

[09:14:00 - 09:14:05]
provider you can see here now let me uh

[09:14:02 - 09:14:08]
show you like how to query out on top of

[09:14:05 - 09:14:09]
your vector and all so for this uh what

[09:14:08 - 09:14:11]
you can do you can use something called

[09:14:09 - 09:14:13]
similarity sear but before that let's

[09:14:11 - 09:14:15]
see if you have already one class T here

[09:14:13 - 09:14:17]
okay um so what you can do you can load

[09:14:15 - 09:14:20]
this class T directly instead of storing

[09:14:17 - 09:14:22]
that uh Vector again and again so this

[09:14:20 - 09:14:24]
is the code for it so let's say I have

[09:14:22 - 09:14:25]
already one cluster so you just need to

[09:14:24 - 09:14:28]
give the index name which is nothing but

[09:14:25 - 09:14:29]
let's say test and here you also need to

[09:14:28 - 09:14:31]
give the embedding like here I'm using

[09:14:29 - 09:14:32]
open embedding so here I'm giving the

[09:14:31 - 09:14:35]
embedding objects now if you execute it

[09:14:32 - 09:14:36]
will automatically load this uh index

[09:14:35 - 09:14:37]
okay it will automatically load these

[09:14:36 - 09:14:39]
are the vector here now see it has

[09:14:37 - 09:14:41]
loaded this

[09:14:39 - 09:14:45]
Vector now on top of that you can

[09:14:41 - 09:14:48]
perform similarity score uh

[09:14:45 - 09:14:51]
operation now here let's say I will ask

[09:14:48 - 09:14:53]
one query let's say I have one yolow V7

[09:14:51 - 09:14:55]
paper here I think you saw that so here

[09:14:53 - 09:14:57]
I'm raising one query like YOLO V7 outp

[09:14:55 - 09:15:00]
part from which model OKAY like we have

[09:14:57 - 09:15:02]
lots of YOLO model right so from them

[09:15:00 - 09:15:04]
actually YOLO V7 performs actually which

[09:15:02 - 09:15:08]
model so this is the query I'm asking so

[09:15:04 - 09:15:10]
now this query I will give it to my uh

[09:15:08 - 09:15:13]
docar this doers this is the object okay

[09:15:10 - 09:15:15]
basically it will it will have all the

[09:15:13 - 09:15:17]
like you can say Vector objects and all

[09:15:15 - 09:15:19]
okay so here I'm going U so here

[09:15:17 - 09:15:21]
actually I can directly ask the quy so

[09:15:19 - 09:15:23]
it has one uh function called similarity

[09:15:21 - 09:15:25]
SS okay so inside that you just need to

[09:15:23 - 09:15:26]
pass the query and you need to set the K

[09:15:25 - 09:15:28]
okay I think you know what is K so K

[09:15:26 - 09:15:30]
means like how many output you want to

[09:15:28 - 09:15:32]
get okay from your uh search results

[09:15:30 - 09:15:35]
okay so it will give me three results

[09:15:32 - 09:15:36]
okay now if I execute and show you uh

[09:15:35 - 09:15:39]
query is not defined because I haven't

[09:15:36 - 09:15:43]
executed now let me show

[09:15:39 - 09:15:47]
you see so it will give me a top uh

[09:15:43 - 09:15:49]
similar uh three output see this is the

[09:15:47 - 09:15:51]
three output it has given but again it's

[09:15:49 - 09:15:54]
not readable so what you can do you can

[09:15:51 - 09:15:57]
take the help from llm so llm if you

[09:15:54 - 09:15:59]
give this query and this output to the

[09:15:57 - 09:16:01]
llm llm will try to understand this

[09:15:59 - 09:16:04]
query and the output and it will give

[09:16:01 - 09:16:07]
you the best uh uh answer okay from

[09:16:04 - 09:16:09]
them so here let's ask uh this query to

[09:16:07 - 09:16:10]
my llm so I'll first of all initialize

[09:16:09 - 09:16:13]
my

[09:16:10 - 09:16:15]
llm and here I'll be using retrieval

[09:16:13 - 09:16:17]
question answer from langen I think you

[09:16:15 - 09:16:19]
remember I was also using and CH type is

[09:16:17 - 09:16:22]
stuff and here I'm just giving this ret

[09:16:19 - 09:16:25]
objects as my doc s okay and as ret okay

[09:16:22 - 09:16:27]
okay you need to give it like that then

[09:16:25 - 09:16:29]
it will consider you are uh it will you

[09:16:27 - 09:16:31]
want to ask any kinds of question okay

[09:16:29 - 09:16:35]
and you want to get the answer now let

[09:16:31 - 09:16:40]
me initialize this uh question answer uh

[09:16:35 - 09:16:40]
object now you can ask the query

[09:16:40 - 09:16:46]
here so I'll ask the same

[09:16:43 - 09:16:49]
query so this is my

[09:16:46 - 09:16:53]
query and I will ask it to

[09:16:49 - 09:16:55]
my uh llm model so I'll just initialize

[09:16:53 - 09:16:58]
keyway run and if I give the query so it

[09:16:55 - 09:16:58]
will give me the

[09:16:58 - 09:17:08]
answer see guys YOLO V7 per outperforms

[09:17:02 - 09:17:10]
YOLO V5 uh L6 YOLO X YOLO ex okay so

[09:17:08 - 09:17:11]
these are the model actually uh it

[09:17:10 - 09:17:13]
outperforms okay see it is giving the

[09:17:11 - 09:17:14]
correct answer now I'm not getting these

[09:17:13 - 09:17:18]
kinds of answer okay I'm getting my

[09:17:14 - 09:17:20]
relevant answer now I have one uh uh

[09:17:18 - 09:17:23]
resume I think you know okay I have one

[09:17:20 - 09:17:25]
resume also uh Richard uh

[09:17:23 - 09:17:28]
G uh CV so let's ask some query from

[09:17:25 - 09:17:30]
this uh resume also so here is one

[09:17:28 - 09:17:32]
question I prepared called Richard green

[09:17:30 - 09:17:36]
uh experience okay like what is what is

[09:17:32 - 09:17:37]
our experience okay so uh see it will uh

[09:17:36 - 09:17:41]
automatically give you that experience

[09:17:37 - 09:17:41]
as well this is the power of

[09:17:43 - 09:17:49]
llm see it's giving richel green has a

[09:17:46 - 09:17:50]
PHD in English from the University of uh

[09:17:49 - 09:17:53]
uh it is giving like some more

[09:17:50 - 09:17:54]
information about uh richel green but is

[09:17:53 - 09:17:57]
pretty good right um yeah so you can ask

[09:17:54 - 09:17:59]
any kinds of questions so you can um

[09:17:57 - 09:18:01]
also create one while loop here so let

[09:17:59 - 09:18:02]
me show you how to create while loop so

[09:18:01 - 09:18:05]
this is the while loop I have created

[09:18:02 - 09:18:07]
and here I'm taking the user uh uh

[09:18:05 - 09:18:09]
prompt so here you need to import one

[09:18:07 - 09:18:11]
Library called

[09:18:09 - 09:18:14]
CIS basically whenever you are uh you

[09:18:11 - 09:18:17]
want to exit so you can exit it also so

[09:18:14 - 09:18:19]
this is like uh input I'm taking from

[09:18:17 - 09:18:22]
the user and if user is giving like exit

[09:18:19 - 09:18:23]
so it will exit Okay this code would be

[09:18:22 - 09:18:25]
exit

[09:18:23 - 09:18:26]
and if it is not then it will ask take

[09:18:25 - 09:18:29]
the query and it will return you the

[09:18:26 - 09:18:33]
answer okay now let me show

[09:18:29 - 09:18:35]
you so if I ask like what is

[09:18:33 - 09:18:37]
uh

[09:18:35 - 09:18:39]
YOLO

[09:18:37 - 09:18:42]
V7 now if I press enter so it will give

[09:18:39 - 09:18:44]
me the answer see yellow V7 is a real

[09:18:42 - 09:18:47]
time object detection which surpassed

[09:18:44 - 09:18:48]
all known object detection in Bon speed

[09:18:47 - 09:18:51]
and accuracy okay it's giving the

[09:18:48 - 09:18:52]
correct answer now let's ask any query

[09:18:51 - 09:18:56]
uh

[09:18:52 - 09:18:56]
tell me

[09:18:57 - 09:19:03]
about tell me about

[09:19:00 - 09:19:06]
uh

[09:19:03 - 09:19:06]
recel

[09:19:07 - 09:19:12]
green yeah I

[09:19:09 - 09:19:15]
think recel spelling is not correct I

[09:19:12 - 09:19:15]
think it should be now let me

[09:19:15 - 09:19:20]
ask see uh it's giving the correct

[09:19:18 - 09:19:23]
answer okay now if I press let's say

[09:19:20 - 09:19:25]
exit now it should exit the

[09:19:23 - 09:19:28]
yeah okay guys I think you saw the

[09:19:25 - 09:19:30]
entire uh like demo how we can use the

[09:19:28 - 09:19:32]
pine con and you got the clearcut idea

[09:19:30 - 09:19:34]
now in the next video we'll be learning

[09:19:32 - 09:19:36]
another amazing Vector database called

[09:19:34 - 09:19:38]
webat webit is also a like you can say

[09:19:36 - 09:19:39]
cloud-based Vector database there also

[09:19:38 - 09:19:41]
you can create a cluster and you can

[09:19:39 - 09:19:43]
store your embeddings so if you search

[09:19:41 - 09:19:45]
web in Google uh you will get this

[09:19:43 - 09:19:47]
documentation so here they have already

[09:19:45 - 09:19:48]
mentioned like how to connect this we8

[09:19:47 - 09:19:50]
with the Lang CH and all everything they

[09:19:48 - 09:19:52]
have given all the integration and all

[09:19:50 - 09:19:54]
how to install okay how to configure

[09:19:52 - 09:19:55]
everything they have given so guys what

[09:19:54 - 09:19:56]
I've done I prepared one notebook this

[09:19:55 - 09:19:58]
notebook will give you the entire

[09:19:56 - 09:20:00]
understanding like how we can use this

[09:19:58 - 09:20:03]
Webb Vector database now this is the

[09:20:00 - 09:20:04]
official website of the webat web iio so

[09:20:03 - 09:20:06]
here you need to create one account

[09:20:04 - 09:20:07]
first of all make sure you have created

[09:20:06 - 09:20:09]
the account and after creating the

[09:20:07 - 09:20:10]
account actually you will get uh free

[09:20:09 - 09:20:12]
credits with the free credits you can

[09:20:10 - 09:20:14]
only create one cluster the same way you

[09:20:12 - 09:20:15]
would do it for the pine con as well

[09:20:14 - 09:20:17]
right and again it's a paid one guys you

[09:20:15 - 09:20:19]
have to pay if you want to use there

[09:20:17 - 09:20:21]
let's say Advance let's say I mean

[09:20:19 - 09:20:22]
functionality you have to pay for that

[09:20:21 - 09:20:24]
so here we'll be only exploring the

[09:20:22 - 09:20:25]
let's say free one the free Ty one

[09:20:24 - 09:20:26]
because free TI one is enough for

[09:20:25 - 09:20:28]
landing fine later on if you need it you

[09:20:26 - 09:20:29]
can also upgrade your subscription so if

[09:20:28 - 09:20:32]
you want to create the account just

[09:20:29 - 09:20:33]
click on try now button so you will see

[09:20:32 - 09:20:35]
uh they will ask for the email and

[09:20:33 - 09:20:37]
password with that actually you can

[09:20:35 - 09:20:39]
create your account and you can log with

[09:20:37 - 09:20:41]
this uh web so guys now let's try to see

[09:20:39 - 09:20:42]
the Practical how we can use this web at

[09:20:41 - 09:20:45]
Vector database so here first of all you

[09:20:42 - 09:20:46]
need to install some of the libraries so

[09:20:45 - 09:20:48]
these are the libraries are common so

[09:20:46 - 09:20:50]
here so guys here now I'm using

[09:20:48 - 09:20:52]
something called wave so this is the

[09:20:50 - 09:20:53]
like python package like wave client so

[09:20:52 - 09:20:57]
you need to install this package to

[09:20:53 - 09:21:01]
connect with your O Okay o um cloud data

[09:20:57 - 09:21:01]
database now let me just quickly set up

[09:21:05 - 09:21:09]
them uh now guys what to do uh you need

[09:21:07 - 09:21:11]
to collect some of the credential so

[09:21:09 - 09:21:13]
these are the credential are required so

[09:21:11 - 09:21:16]
first of all I need my openi API key

[09:21:13 - 09:21:18]
then I need my wave API key and wave at

[09:21:16 - 09:21:20]
cluster okay cluster URL so this three

[09:21:18 - 09:21:22]
thing actually I need so I think we

[09:21:20 - 09:21:26]
already created my open API key just try

[09:21:22 - 09:21:30]
to copy from my previous notebook so

[09:21:26 - 09:21:30]
here is my API key so I'll just

[09:21:30 - 09:21:36]
copy and here I will just try to paste

[09:21:34 - 09:21:39]
it okay now let's see like how we can

[09:21:36 - 09:21:42]
collect this W API key so for this just

[09:21:39 - 09:21:45]
uh visit your U so for this just visit

[09:21:42 - 09:21:47]
your uh weat dashboard and here just try

[09:21:45 - 09:21:49]
to create one cluster just click on

[09:21:47 - 09:21:49]
create

[09:21:49 - 09:21:53]
cluster okay you need to give the

[09:21:51 - 09:21:56]
cluster name so let's give any name so

[09:21:53 - 09:21:59]
I'll give a test okay so you can give

[09:21:56 - 09:22:01]
any name so everything will remain uh

[09:21:59 - 09:22:04]
same because this is a free free one and

[09:22:01 - 09:22:06]
it will expire in 21 days because this

[09:22:04 - 09:22:08]
is the free version free tire I'm using

[09:22:06 - 09:22:09]
okay but if you want to use for your

[09:22:08 - 09:22:11]
production grade application so at the

[09:22:09 - 09:22:15]
time you can take the subscription okay

[09:22:11 - 09:22:15]
now just try to Cate the

[09:22:18 - 09:22:21]
cluster so it will take some time once

[09:22:20 - 09:22:24]
it is ready so it will give you the

[09:22:21 - 09:22:26]
status message

[09:22:24 - 09:22:28]
and guys if you see web also support

[09:22:26 - 09:22:32]
these kinds of client like python client

[09:22:28 - 09:22:34]
Java client CLI uh typescript then go so

[09:22:32 - 09:22:36]
it has actually multiple client support

[09:22:34 - 09:22:38]
so like those who are working in Java

[09:22:36 - 09:22:41]
and all so you can also use it now guys

[09:22:38 - 09:22:44]
see my web at cluster is ready now if I

[09:22:41 - 09:22:47]
click on detail now here it should give

[09:22:44 - 09:22:51]
me that uh detail of my cluster now here

[09:22:47 - 09:22:53]
first of all I need to uh copy this uh

[09:22:51 - 09:22:56]
uh cluster URL okay just copy this clust

[09:22:53 - 09:22:59]
URL here from here you can also copy now

[09:22:56 - 09:23:01]
let's go back to my wave and here you

[09:22:59 - 09:23:01]
need to paste

[09:23:04 - 09:23:11]
it oh sorry uh this is my API so I need

[09:23:07 - 09:23:15]
to paste it here this is my cluster URL

[09:23:11 - 09:23:18]
okay now I also need to copy the API so

[09:23:15 - 09:23:20]
here is the API option just click here

[09:23:18 - 09:23:22]
and this is the API key just try to copy

[09:23:20 - 09:23:23]
and don't share uh I'll delete it after

[09:23:22 - 09:23:27]
this this recording so that's why I'm

[09:23:23 - 09:23:29]
sharing and I'll just uh past it here

[09:23:27 - 09:23:32]
okay now I got my three credential now

[09:23:29 - 09:23:32]
let me execute

[09:23:34 - 09:23:40]
them okay so first of all I need to read

[09:23:37 - 09:23:40]
my data so let me read the

[09:23:42 - 09:23:48]
data so here first of all uh so here

[09:23:46 - 09:23:51]
first of all I will create One Directory

[09:23:48 - 09:23:54]
called uh MK

[09:23:51 - 09:23:54]
DRS

[09:24:00 - 09:24:05]
data okay now data folder has been

[09:24:03 - 09:24:07]
created now inside that I will upload

[09:24:05 - 09:24:09]
one uh so inside that I will upload one

[09:24:07 - 09:24:12]
PDF file I have here so this is the

[09:24:09 - 09:24:14]
Yello paper actually YOLO related

[09:24:12 - 09:24:16]
content so you can download any kinds of

[09:24:14 - 09:24:18]
PDF and you can upload here no issue

[09:24:16 - 09:24:22]
with that you can either use text Data

[09:24:18 - 09:24:22]
okay doc data it's up to you

[09:24:25 - 09:24:30]
uh so guys as you can see uh my PDF has

[09:24:27 - 09:24:33]
been uploaded here now what I will do uh

[09:24:30 - 09:24:36]
I'll just try to load this PDF okay and

[09:24:33 - 09:24:38]
uh I'll just extract that text from it

[09:24:36 - 09:24:39]
so let me show you like how this PDF

[09:24:38 - 09:24:42]
will look like so guys see this is the

[09:24:39 - 09:24:45]
yellow uh like presentation okay so I

[09:24:42 - 09:24:47]
have downloaded as PDF I'll just execute

[09:24:45 - 09:24:49]
this particular code so here I'm giving

[09:24:47 - 09:24:51]
the data directory and I'm telling just

[09:24:49 - 09:24:54]
load the PDF file okay then I'm loading

[09:24:51 - 09:24:54]
the data now let me load

[09:24:55 - 09:24:59]
so it's giving one error it's telling

[09:24:57 - 09:25:00]
unstructured package not found uh please

[09:24:59 - 09:25:02]
install it with people install on

[09:25:00 - 09:25:04]
instruct okay so what is happening

[09:25:02 - 09:25:07]
actually so if you see here I have

[09:25:04 - 09:25:09]
downloaded this uh Google uh like you

[09:25:07 - 09:25:11]
can say uh slide Okay Google slide as

[09:25:09 - 09:25:13]
PDF that's why it is considering as

[09:25:11 - 09:25:15]
unstructured PDF okay so that that's why

[09:25:13 - 09:25:18]
we need to install uh one package called

[09:25:15 - 09:25:20]
unstructured unstructured PDF so let me

[09:25:18 - 09:25:22]
install it so this is the command to

[09:25:20 - 09:25:26]
install but if you're having like like

[09:25:22 - 09:25:28]
uh PDF like very simple PDF so you don't

[09:25:26 - 09:25:30]
need to install it okay so this is for

[09:25:28 - 09:25:33]
like unstructured PDF so if you have any

[09:25:30 - 09:25:33]
complex PDF so you need to install this

[09:25:34 - 09:25:40]
package so previously I was using like

[09:25:37 - 09:25:43]
uh ppad and all okay that's why it was a

[09:25:40 - 09:25:45]
uh simple uh PDF but now I'm using like

[09:25:43 - 09:25:47]
Google slide PDF that's why it's giving

[09:25:45 - 09:25:49]
this

[09:25:47 - 09:25:50]
ad and it's pretty good like it will

[09:25:49 - 09:25:52]
tell you like what are the package you

[09:25:50 - 09:25:54]
need to install and all so it will give

[09:25:52 - 09:25:57]
you the message as

[09:25:54 - 09:25:58]
well so guys it's done now it's telling

[09:25:57 - 09:26:01]
just restart the run time so let's

[09:25:58 - 09:26:01]
restart our run

[09:26:04 - 09:26:10]
time okay now let me uh execute

[09:26:10 - 09:26:15]
Discord now it is extracting all the

[09:26:12 - 09:26:15]
text from this

[09:26:16 - 09:26:20]
PDF you can also upload multiple PDF

[09:26:19 - 09:26:22]
here uh it's up to you but I have

[09:26:20 - 09:26:25]
already added one PDF I just want to to

[09:26:22 - 09:26:28]
show you the quick demo done now let me

[09:26:25 - 09:26:28]
show you the

[09:26:32 - 09:26:37]
data so guys this is the entire data I

[09:26:35 - 09:26:39]
got from my PDF okay now I need to apply

[09:26:37 - 09:26:43]
something called text splitting I think

[09:26:39 - 09:26:47]
you remember I need to convert it to

[09:26:43 - 09:26:47]
chunks so let's convert

[09:26:47 - 09:26:52]
it so Rec character text is spitter okay

[09:26:50 - 09:26:54]
I'm importing from langin and this is

[09:26:52 - 09:26:56]
the Chun size and chunks overlap you can

[09:26:54 - 09:26:58]
give any number here so let me just do

[09:26:56 - 09:27:02]
do it

[09:26:58 - 09:27:02]
quickly now I got my

[09:27:02 - 09:27:08]
chunks okay see this is my chunks and

[09:27:05 - 09:27:08]
also let me see the

[09:27:08 - 09:27:12]
length see all the things are common

[09:27:11 - 09:27:14]
only we are just changing the data uh

[09:27:12 - 09:27:17]
database client okay like I'm using

[09:27:14 - 09:27:19]
chroma DB M code and weave so just

[09:27:17 - 09:27:20]
client is changing but steps are same I

[09:27:19 - 09:27:23]
think you are

[09:27:20 - 09:27:27]
getting now I need to convert to

[09:27:23 - 09:27:31]
embeddings so let me just comment it

[09:27:27 - 09:27:33]
out so here I'm going to use open a

[09:27:31 - 09:27:35]
embedding P embedding and here you need

[09:27:33 - 09:27:37]
to pass the op API key uh if you're not

[09:27:35 - 09:27:39]
passing it's fine you need to add inside

[09:27:37 - 09:27:41]
the environment variable so previously

[09:27:39 - 09:27:43]
we added if you see here environment

[09:27:41 - 09:27:44]
variable but here I'm not adding

[09:27:43 - 09:27:46]
environment variable if you're not

[09:27:44 - 09:27:47]
adding inside environment variable you

[09:27:46 - 09:27:49]
can directly pass them okay that will

[09:27:47 - 09:27:49]
also

[09:27:51 - 09:27:55]
work okay it's giving error open a is

[09:27:53 - 09:27:57]
not defined because we have restarted

[09:27:55 - 09:27:59]
the run time so I need to execute this

[09:27:57 - 09:27:59]
cell

[09:28:00 - 09:28:05]
again H now I think it should

[09:28:06 - 09:28:15]
work now here I'll be uh initializing my

[09:28:11 - 09:28:17]
we Vector database so if you visit we

[09:28:15 - 09:28:19]
documentation uh there's the

[09:28:17 - 09:28:21]
documentation and here they have given

[09:28:19 - 09:28:24]
the installation guideline then

[09:28:21 - 09:28:26]
configuration then what is the schema

[09:28:24 - 09:28:28]
libraries everything they have explained

[09:28:26 - 09:28:30]
okay so you can visit the documentation

[09:28:28 - 09:28:33]
and uh you can get all the information

[09:28:30 - 09:28:35]
but here I already uh gone through the

[09:28:33 - 09:28:37]
documentation and I uh prepared this

[09:28:35 - 09:28:39]
notebook so this is the code actually

[09:28:37 - 09:28:42]
you need to write to initialize your web

[09:28:39 - 09:28:43]
actually uh that's why actually I like

[09:28:42 - 09:28:46]
Pine con one because pine cone looks

[09:28:43 - 09:28:48]
easy uh okay to me because what I feel

[09:28:46 - 09:28:51]
like Pine con is like more easy and it's

[09:28:48 - 09:28:53]
like more uh easy to understand and uh

[09:28:51 - 09:28:54]
like more clear but if you're using web

[09:28:53 - 09:28:57]
so you need to write some extra Cod it

[09:28:54 - 09:28:58]
okay uh but it's completely fine okay no

[09:28:57 - 09:29:00]
issue you can use it I I will share my

[09:28:58 - 09:29:02]
notebook you can use this notebook as it

[09:29:00 - 09:29:04]
is so here I'm just first of all

[09:29:02 - 09:29:07]
importing weat from langen you can also

[09:29:04 - 09:29:08]
import directly it is also fine now here

[09:29:07 - 09:29:10]
you just uh so first of all you just

[09:29:08 - 09:29:12]
need to connect with your wave cluster

[09:29:10 - 09:29:13]
okay this cluster we have created here I

[09:29:12 - 09:29:15]
think you remember this is the cluster

[09:29:13 - 09:29:17]
to connect with the cluster you need to

[09:29:15 - 09:29:19]
give the API key W API key and I think

[09:29:17 - 09:29:22]
you know we already collected the oi o

[09:29:19 - 09:29:24]
API key here and we stored in the video

[09:29:22 - 09:29:27]
able okay then I also need collected the

[09:29:24 - 09:29:28]
cluster URL okay both I have collected

[09:29:27 - 09:29:30]
now cluster URL you also need to give

[09:29:28 - 09:29:31]
then you need to initialize the client

[09:29:30 - 09:29:34]
and inside that you need to give the

[09:29:31 - 09:29:36]
cluster URL and as well as the open API

[09:29:34 - 09:29:38]
key also because uh using the open API

[09:29:36 - 09:29:40]
key it will use the open embedding okay

[09:29:38 - 09:29:43]
whenever it will convert your um data to

[09:29:40 - 09:29:45]
Vector embedding so it will use that

[09:29:43 - 09:29:48]
open a embedding okay so that's why you

[09:29:45 - 09:29:49]
need to give the open API key here now I

[09:29:48 - 09:29:51]
also need to give something called uh

[09:29:49 - 09:29:52]
authentication configuration so this is

[09:29:51 - 09:29:54]
the Authentication configuration which

[09:29:52 - 09:29:56]
is nothing but my API key wave API key

[09:29:54 - 09:29:58]
and this is the startup period these are

[09:29:56 - 09:30:00]
some default parameter you need to give

[09:29:58 - 09:30:02]
and let's

[09:30:00 - 09:30:04]
execute okay now if you want to check it

[09:30:02 - 09:30:06]
whether this client is ready or not so

[09:30:04 - 09:30:08]
this is the code for it so is ready so

[09:30:06 - 09:30:10]
now it is true that means my client is

[09:30:08 - 09:30:13]
ready now it is connected with my wave

[09:30:10 - 09:30:15]
client now wave is telling you need to

[09:30:13 - 09:30:18]
uh prepare something called schema okay

[09:30:15 - 09:30:21]
here uh they have given uh one client

[09:30:18 - 09:30:22]
schema so if you visit this client

[09:30:21 - 09:30:24]
libraries Okay so so here if you see

[09:30:22 - 09:30:27]
example client schema so you Al also

[09:30:24 - 09:30:29]
need to Define some schema here schem is

[09:30:27 - 09:30:31]
nothing but it just a it kinds of

[09:30:29 - 09:30:33]
configuration it will take okay as input

[09:30:31 - 09:30:35]
like you can uh change the configuration

[09:30:33 - 09:30:36]
with the help of code so that's why

[09:30:35 - 09:30:38]
these are the things they are giving but

[09:30:36 - 09:30:41]
if you're not able to get it okay it's

[09:30:38 - 09:30:43]
completely fine so you just need to give

[09:30:41 - 09:30:46]
this schema and it will common for every

[09:30:43 - 09:30:48]
U experiment you'll be doing so this is

[09:30:46 - 09:30:50]
the complete schema guys okay so client

[09:30:48 - 09:30:52]
schema detail U first of all if it has

[09:30:50 - 09:30:55]
any schema it will delete then it will

[09:30:52 - 09:30:57]
add this schema so here uh you can give

[09:30:55 - 09:31:00]
any name okay so I have given chatbot

[09:30:57 - 09:31:03]
here then U here you can give an

[09:31:00 - 09:31:05]
description then uh what the vector

[09:31:03 - 09:31:07]
actually model you are using you can

[09:31:05 - 09:31:09]
give the name here so in openi actually

[09:31:07 - 09:31:11]
you have Adam model okay so here I'm

[09:31:09 - 09:31:13]
using Adam model I think you remember if

[09:31:11 - 09:31:15]
I print my

[09:31:13 - 09:31:16]
embedding so here I was using something

[09:31:15 - 09:31:19]
called Adam

[09:31:16 - 09:31:20]
model okay as you can see here I was

[09:31:19 - 09:31:22]
using something called text Adda

[09:31:20 - 09:31:24]
embedding add model that's why you can

[09:31:22 - 09:31:25]
also give the name and these are some

[09:31:24 - 09:31:27]
description you can give and after that

[09:31:25 - 09:31:29]
you can create this schema and you can

[09:31:27 - 09:31:31]
uh create your client okay now this is

[09:31:29 - 09:31:32]
the code so you can execute and this

[09:31:31 - 09:31:34]
thing is not required in Pine con so

[09:31:32 - 09:31:36]
Pine con can handle these other the

[09:31:34 - 09:31:38]
thing automatically but in weave you

[09:31:36 - 09:31:40]
need to uh provide that's why I

[09:31:38 - 09:31:42]
personally like like Pine con okay now

[09:31:40 - 09:31:45]
once it is done you need to initialize

[09:31:42 - 09:31:47]
the uh vectory store okay now this code

[09:31:45 - 09:31:48]
will initialize the vector so what it

[09:31:47 - 09:31:50]
will do basically it will take your

[09:31:48 - 09:31:54]
documents okay I think you remember we

[09:31:50 - 09:31:56]
have um we have uh created the documents

[09:31:54 - 09:31:58]
okay uh we have created a cluster and

[09:31:56 - 09:31:59]
from this cluster uh with the help of

[09:31:58 - 09:32:02]
this embedding we are just trying to

[09:31:59 - 09:32:04]
generating the vector and storing inside

[09:32:02 - 09:32:06]
the wave okay now let me St uh execute

[09:32:04 - 09:32:09]
and show

[09:32:06 - 09:32:11]
you now see guys now if I go to my wave8

[09:32:09 - 09:32:14]
and

[09:32:11 - 09:32:15]
refresh now it hasn't updated yet so

[09:32:14 - 09:32:17]
after some times you will see it will

[09:32:15 - 09:32:20]
update like how many embeddings had

[09:32:17 - 09:32:22]
generated okay then uh how many times

[09:32:20 - 09:32:25]
you have uh you can say did the request

[09:32:22 - 09:32:27]
everything it will show you here okay so

[09:32:25 - 09:32:29]
all the information actually it will

[09:32:27 - 09:32:30]
give you and these are the and Guys

[09:32:29 - 09:32:32]
these are the embedding model are

[09:32:30 - 09:32:34]
available by default with this we so you

[09:32:32 - 09:32:37]
can use any of them it's completely fine

[09:32:34 - 09:32:39]
but we are using this Adda model uh open

[09:32:37 - 09:32:42]
a generative model okay so yeah so guys

[09:32:39 - 09:32:44]
usually it takes some time around uh

[09:32:42 - 09:32:45]
like uh 5 to 6 minutes after that you

[09:32:44 - 09:32:48]
will able to see all the update here so

[09:32:45 - 09:32:50]
in between what I can do I can show you

[09:32:48 - 09:32:52]
the other step now we have successfully

[09:32:50 - 09:32:54]
stored our embeddings now now let me

[09:32:52 - 09:32:57]
just do the similarity measurement that

[09:32:54 - 09:32:57]
means similarity

[09:32:59 - 09:33:03]
charts so here first of all I will ask

[09:33:02 - 09:33:05]
one

[09:33:03 - 09:33:07]
query called what is YOLO because this

[09:33:05 - 09:33:10]
is the yellow related content and here

[09:33:07 - 09:33:12]
I'm initializing this similarity SAR

[09:33:10 - 09:33:14]
okay because Vector store is it this is

[09:33:12 - 09:33:16]
my object and on top of that I'm just

[09:33:14 - 09:33:19]
writing similarity search here I'm

[09:33:16 - 09:33:20]
giving the quy and top K that means how

[09:33:19 - 09:33:23]
many output you want to get so here I'm

[09:33:20 - 09:33:25]
given 20 you can give any number now it

[09:33:23 - 09:33:29]
will return like 20 results okay 20

[09:33:25 - 09:33:33]
similar kinds of uh

[09:33:29 - 09:33:36]
results see okay but um I can't actually

[09:33:33 - 09:33:39]
take the answer so what I can give I can

[09:33:36 - 09:33:42]
give one chain with the help of Lang

[09:33:39 - 09:33:43]
chain so here uh there is another

[09:33:42 - 09:33:45]
parameter called question answering okay

[09:33:43 - 09:33:48]
load QA CH you can also use this chain

[09:33:45 - 09:33:50]
otherwise you can also use retrieve uh

[09:33:48 - 09:33:53]
qn okay that that is also fine now here

[09:33:50 - 09:33:53]
I'm going to use open LM

[09:33:54 - 09:33:58]
now I'll Define my

[09:33:56 - 09:34:02]
chain and here I need to pass my open

[09:33:58 - 09:34:04]
API key and uh this is the CH typ and

[09:34:02 - 09:34:06]
temperature means like uh if temperature

[09:34:04 - 09:34:07]
is zero so your model would be like more

[09:34:06 - 09:34:11]
uh you can

[09:34:07 - 09:34:13]
say stick to the U answer like it won't

[09:34:11 - 09:34:15]
be giving any Randomness and if you're

[09:34:13 - 09:34:17]
changing the temperature to close to one

[09:34:15 - 09:34:19]
so it will uh give some random output as

[09:34:17 - 09:34:21]
well okay so this parameter you can

[09:34:19 - 09:34:23]
change I think if you have learned like

[09:34:21 - 09:34:24]
llm so I you know this parameter and all

[09:34:23 - 09:34:27]
okay so these are like Basics thing okay

[09:34:24 - 09:34:30]
in llm now let me Define my

[09:34:27 - 09:34:33]
chain now here I will ask this

[09:34:30 - 09:34:35]
query so chain. run input documents so

[09:34:33 - 09:34:37]
this is my documents this is my entire

[09:34:35 - 09:34:40]
documents I'm giving okay the documents

[09:34:37 - 09:34:42]
I have and uh see this is the documents

[09:34:40 - 09:34:44]
that means I got all the answer right uh

[09:34:42 - 09:34:46]
20 answer and from this 20 answer I want

[09:34:44 - 09:34:47]
my query that means the query I'm asking

[09:34:46 - 09:34:50]
which is nothing but what is yellow so

[09:34:47 - 09:34:53]
now with the help of U my llm I will get

[09:34:50 - 09:34:55]
my authentic answer see see is an

[09:34:53 - 09:34:58]
algorithm for object detection that is

[09:34:55 - 09:34:59]
uh uh that is uh unified real time and

[09:34:58 - 09:35:01]
has higher accuracy it is presented by

[09:34:59 - 09:35:03]
shivang Shing and this is the date of

[09:35:01 - 09:35:05]
the publication okay so yes I'm getting

[09:35:03 - 09:35:07]
my output and all so now you can ask any

[09:35:05 - 09:35:08]
kinds of question about yolow and all

[09:35:07 - 09:35:10]
okay I think you got it like I already

[09:35:08 - 09:35:11]
showed you multiple time you can either

[09:35:10 - 09:35:13]
create one while loop and you can ask

[09:35:11 - 09:35:15]
many question here all right guys I

[09:35:13 - 09:35:18]
think everything is clear now how we can

[09:35:15 - 09:35:19]
use this weate uh like vector database

[09:35:18 - 09:35:21]
so we have learned different different

[09:35:19 - 09:35:24]
Vector database guys so far now we'll be

[09:35:21 - 09:35:26]
using all of them to implement different

[09:35:24 - 09:35:27]
different like gni application if you

[09:35:26 - 09:35:29]
don't know about Lang chain Lang chain

[09:35:27 - 09:35:31]
is a genv framework with the help of

[09:35:29 - 09:35:33]
that we can Implement any kinds of

[09:35:31 - 09:35:35]
generative AI based application with the

[09:35:33 - 09:35:37]
help of large language model so I think

[09:35:35 - 09:35:39]
you already used something called py and

[09:35:37 - 09:35:41]
tensor flow whenever you used to learn

[09:35:39 - 09:35:42]
deep learning right so inside deep

[09:35:41 - 09:35:44]
learning we used to implement uh

[09:35:42 - 09:35:46]
computer vision project NLP project so

[09:35:44 - 09:35:49]
there we used to use these kinds of

[09:35:46 - 09:35:50]
framework like P and tensorflow so both

[09:35:49 - 09:35:51]
are actually deep learning based

[09:35:50 - 09:35:54]
framework so with the help of that you

[09:35:51 - 09:35:56]
can create a neural network right that

[09:35:54 - 09:35:58]
means all the functionality this

[09:35:56 - 09:36:00]
framework provides to implement any

[09:35:58 - 09:36:02]
kinds of neural network to let's say

[09:36:00 - 09:36:04]
work with your data to load your image

[09:36:02 - 09:36:05]
everything you can perform there so

[09:36:04 - 09:36:08]
similar wise if you want to work in the

[09:36:05 - 09:36:10]
field of genbi so inside gen if you want

[09:36:08 - 09:36:12]
to work with the large language model

[09:36:10 - 09:36:13]
and all so you have to use this Lang

[09:36:12 - 09:36:15]
chain framework because Lang chain is

[09:36:13 - 09:36:17]
having all kinds of integration all

[09:36:15 - 09:36:18]
kinds of functionality okay so only you

[09:36:17 - 09:36:20]
just need to learn how we can use this

[09:36:18 - 09:36:22]
Lang chain properly and with the help of

[09:36:20 - 09:36:23]
that how we can access different

[09:36:22 - 09:36:25]
different large language model and how

[09:36:23 - 09:36:27]
we can build different different kinds

[09:36:25 - 09:36:29]
of application I think you saw the chat

[09:36:27 - 09:36:31]
GPT right chat GPT like it's a very

[09:36:29 - 09:36:32]
powerful application so if you let's say

[09:36:31 - 09:36:34]
give any kinds of prompt that particular

[09:36:32 - 09:36:36]
prompt actually it will try to remember

[09:36:34 - 09:36:38]
Okay then if you are asking the next

[09:36:36 - 09:36:39]
prompt it will also try to remember that

[09:36:38 - 09:36:41]
prompt because it is using something

[09:36:39 - 09:36:45]
called memory okay memory inside chat

[09:36:41 - 09:36:46]
GPT and how this memory is utilizing so

[09:36:45 - 09:36:49]
this concept is already available inside

[09:36:46 - 09:36:51]
langin langin is also having the memory

[09:36:49 - 09:36:53]
functionality so if you use this langin

[09:36:51 - 09:36:55]
to implement this kinds of project so

[09:36:53 - 09:36:57]
you can also create a memory okay memory

[09:36:55 - 09:36:59]
for that application so that if user is

[09:36:57 - 09:37:01]
giving any kinds of prompt this prompt

[09:36:59 - 09:37:03]
would be also remembered by your

[09:37:01 - 09:37:04]
application so not only that actually it

[09:37:03 - 09:37:06]
is it provides actually lots of

[09:37:04 - 09:37:08]
functionality guys unless and until you

[09:37:06 - 09:37:09]
are not learning about langin so you

[09:37:08 - 09:37:11]
won't be able to understand so what I

[09:37:09 - 09:37:14]
will do guys uh let's uh quickly start

[09:37:11 - 09:37:16]
our uh this practical demo of langin

[09:37:14 - 09:37:18]
because langin is all about practical

[09:37:16 - 09:37:19]
here nothing theory is there so I

[09:37:18 - 09:37:21]
already prepared one amazing notebook

[09:37:19 - 09:37:23]
for you so there I will show you the

[09:37:21 - 09:37:25]
entire Lang chain demo so guys as you

[09:37:23 - 09:37:26]
can see this is the collab notebook I

[09:37:25 - 09:37:28]
prepared so first of all let's connect

[09:37:26 - 09:37:31]
this

[09:37:28 - 09:37:33]
notebook and make sure you select GPU

[09:37:31 - 09:37:35]
because going forward actually we'll be

[09:37:33 - 09:37:37]
using uh some open source large language

[09:37:35 - 09:37:40]
model from the hugging fa itself and to

[09:37:37 - 09:37:41]
use that one you need a GPU based

[09:37:40 - 09:37:43]
machine okay so make sure you selected

[09:37:41 - 09:37:45]
the GPU if you're selecting CPU it's

[09:37:43 - 09:37:47]
completely fine it will also work but

[09:37:45 - 09:37:49]
the execution time would be little bit

[09:37:47 - 09:37:51]
High okay that is the thing now let me

[09:37:49 - 09:37:53]
cancel H now if you want to see the

[09:37:51 - 09:37:55]
official GitHub of langen guys this is

[09:37:53 - 09:37:58]
uh so you can see this is the official

[09:37:55 - 09:38:00]
uh GitHub of the langen okay see it's

[09:37:58 - 09:38:03]
like very active resarch the last comit

[09:38:00 - 09:38:06]
was 3 hours ago only okay now you can

[09:38:03 - 09:38:09]
see um they have given all the let's say

[09:38:06 - 09:38:10]
uh tutorial how we can install and how

[09:38:09 - 09:38:12]
we can access uh let's say different

[09:38:10 - 09:38:14]
different Services of the Lang chain

[09:38:12 - 09:38:16]
everything they have given apart from

[09:38:14 - 09:38:18]
that see uh they are having actually a

[09:38:16 - 09:38:20]
very huge community that means uh these

[09:38:18 - 09:38:22]
are the communities supporting this

[09:38:20 - 09:38:25]
Library a lot that means if anything is

[09:38:22 - 09:38:27]
going wrong in this Library they uh

[09:38:25 - 09:38:29]
let's instantly solving that uh let's

[09:38:27 - 09:38:31]
issue even they're also upgrading this

[09:38:29 - 09:38:32]
framework day by day now apart from that

[09:38:31 - 09:38:34]
it is also having one beautiful

[09:38:32 - 09:38:36]
documentation so let me show you guys

[09:38:34 - 09:38:37]
this is the documentation link if you

[09:38:36 - 09:38:39]
just search Lang chain documentation on

[09:38:37 - 09:38:41]
Google you will see this documentation

[09:38:39 - 09:38:43]
now see this is the entire documentation

[09:38:41 - 09:38:45]
they are having okay now see different

[09:38:43 - 09:38:46]
different uh things they have developed

[09:38:45 - 09:38:48]
they have also develop ecosystem like

[09:38:46 - 09:38:49]
Lang speth Lang graph we'll be we'll be

[09:38:48 - 09:38:51]
also discussing about Lang spe and Lang

[09:38:49 - 09:38:52]
graph no need to worry first of all

[09:38:51 - 09:38:54]
let's try to understand the fundamental

[09:38:52 - 09:38:56]
of langen like how we can install the

[09:38:54 - 09:38:59]
langen how we can integrate with

[09:38:56 - 09:39:00]
different different let's say platform

[09:38:59 - 09:39:01]
like you can see it is having different

[09:39:00 - 09:39:03]
different integration let me show you so

[09:39:01 - 09:39:05]
if I open the third party integration

[09:39:03 - 09:39:08]
see it supports anthropic then AWS

[09:39:05 - 09:39:11]
Google hugging face Microsoft op and

[09:39:08 - 09:39:12]
many more okay many more see all the

[09:39:11 - 09:39:14]
different different Cloud jni servic it

[09:39:12 - 09:39:15]
is also support all the different

[09:39:14 - 09:39:17]
different let's say lar large language

[09:39:15 - 09:39:18]
model platform it is support even you

[09:39:17 - 09:39:20]
can also integrate with hugging face

[09:39:18 - 09:39:22]
that means whatever hugging face model I

[09:39:20 - 09:39:24]
think I showed you now I think remember

[09:39:22 - 09:39:26]
all kinds of Open Source large language

[09:39:24 - 09:39:28]
model is available inside hugging F you

[09:39:26 - 09:39:31]
can also easily use these are the model

[09:39:28 - 09:39:32]
with the help of langin and always try

[09:39:31 - 09:39:34]
to remember guys langin doesn't have any

[09:39:32 - 09:39:37]
kinds of large language model OKAY

[09:39:34 - 09:39:39]
langin is just a framework it's just a

[09:39:37 - 09:39:40]
framework to work with the Genera VI

[09:39:39 - 09:39:42]
based application with the help of large

[09:39:40 - 09:39:44]
language model large language model wise

[09:39:42 - 09:39:46]
it will connect with different different

[09:39:44 - 09:39:49]
platform let's say hugging face let's

[09:39:46 - 09:39:50]
say open AI let's say AWS let's say you

[09:39:49 - 09:39:52]
can see different different integation

[09:39:50 - 09:39:53]
it is there let's say Microsoft okay so

[09:39:52 - 09:39:56]
those who actually provides these kinds

[09:39:53 - 09:39:58]
of large language model okay so it can

[09:39:56 - 09:39:59]
connect with those platform this is the

[09:39:58 - 09:40:01]
idea only got it so it's just a

[09:39:59 - 09:40:02]
framework you can see they have also

[09:40:01 - 09:40:04]
written Lang chain is a framework for

[09:40:02 - 09:40:05]
developing application powered by large

[09:40:04 - 09:40:08]
language model

[09:40:05 - 09:40:10]
llm okay I hope it is clear now see uh

[09:40:08 - 09:40:12]
they have written so many things so what

[09:40:10 - 09:40:14]
I did guys I just prepared one amazing

[09:40:12 - 09:40:15]
notebook so this notebook will give you

[09:40:14 - 09:40:17]
the comprehensive idea how we can

[09:40:15 - 09:40:19]
install and how we can use this langen I

[09:40:17 - 09:40:21]
think this is enough for you okay to

[09:40:19 - 09:40:22]
learn about langen now see this is the

[09:40:21 - 09:40:24]
overview so these are the things

[09:40:22 - 09:40:26]
actually be covering inside langin like

[09:40:24 - 09:40:28]
installation we'll be learning about how

[09:40:26 - 09:40:29]
we can like access different different

[09:40:28 - 09:40:31]
large language model we'll be learning

[09:40:29 - 09:40:34]
about prom template chains agents and

[09:40:31 - 09:40:35]
Tool memory document loader and indexes

[09:40:34 - 09:40:36]
okay so these are the thing we'll be

[09:40:35 - 09:40:38]
learning apart from that we'll be

[09:40:36 - 09:40:39]
learning some more advanc let's say

[09:40:38 - 09:40:41]
technique like we'll be learning about

[09:40:39 - 09:40:42]
ecosystem like Lang speed Lang graph

[09:40:41 - 09:40:45]
okay these are the thing also we'll be

[09:40:42 - 09:40:46]
trying to cover now let's see how we can

[09:40:45 - 09:40:48]
install the Lang chain so this is the

[09:40:46 - 09:40:50]
command guys to install the Lang chin

[09:40:48 - 09:40:51]
just right P install Lang chain and with

[09:40:50 - 09:40:53]
that you need to install another package

[09:40:51 - 09:40:56]
called langin Community now let me

[09:40:53 - 09:40:56]
install the

[09:41:02 - 09:41:07]
langen okay so after installing I just

[09:41:05 - 09:41:09]
need to set up some environment like I

[09:41:07 - 09:41:11]
need to set up my open API key as well

[09:41:09 - 09:41:14]
as the hugging face API token okay why

[09:41:11 - 09:41:16]
because here I'll show you how we can uh

[09:41:14 - 09:41:18]
use open okay open language model if you

[09:41:16 - 09:41:20]
want to use let's any kind of commercial

[09:41:18 - 09:41:21]
model how we can access it even I will

[09:41:20 - 09:41:23]
also show you how we can access any

[09:41:21 - 09:41:25]
kinds of Open Source large language

[09:41:23 - 09:41:27]
model from the hugging face uh let's say

[09:41:25 - 09:41:29]
Hub okay so for this I need to collect

[09:41:27 - 09:41:31]
this authentication API I think you know

[09:41:29 - 09:41:33]
we have already generated One open API

[09:41:31 - 09:41:34]
key so see here I have already written

[09:41:33 - 09:41:36]
my open API key so you can also write

[09:41:34 - 09:41:38]
your open API key and you need to also

[09:41:36 - 09:41:39]
give the hugging face API token and

[09:41:38 - 09:41:41]
where you will get the hugging face API

[09:41:39 - 09:41:44]
token go to the hugging face platform

[09:41:41 - 09:41:45]
click on the profile go to the settings

[09:41:44 - 09:41:47]
now left hand side you will see access

[09:41:45 - 09:41:49]
tokens now you need to create a token

[09:41:47 - 09:41:50]
for me I already created the token guys

[09:41:49 - 09:41:52]
you can see Lang chain now if you want

[09:41:50 - 09:41:54]
to create just create a token give the

[09:41:52 - 09:41:56]
name let's say I will I'll give test

[09:41:54 - 09:41:59]
okay after that give the read permission

[09:41:56 - 09:42:01]
and create the token now copy this token

[09:41:59 - 09:42:03]
and try to mention it here okay I hope

[09:42:01 - 09:42:04]
it is clear now let me delete I think I

[09:42:03 - 09:42:07]
already created so I don't need it I

[09:42:04 - 09:42:09]
will delete it okay this token so my

[09:42:07 - 09:42:10]
token name is langen you can give any

[09:42:09 - 09:42:12]
kinds of name it's up to you now let me

[09:42:10 - 09:42:14]
set these are the token inside my

[09:42:12 - 09:42:15]
environment okay it is giving one error

[09:42:14 - 09:42:17]
because I have to initialize the

[09:42:15 - 09:42:19]
operating system package first of all

[09:42:17 - 09:42:20]
then let me set inside my environment

[09:42:19 - 09:42:22]
variable okay now what will happen

[09:42:20 - 09:42:23]
whenever you will using Lang chain now

[09:42:22 - 09:42:26]
it will automatically load these are the

[09:42:23 - 09:42:27]
API key from the environment itself okay

[09:42:26 - 09:42:30]
you don't need to manually set that this

[09:42:27 - 09:42:31]
is the idea now we'll be learning about

[09:42:30 - 09:42:32]
how we can use any kinds of large

[09:42:31 - 09:42:35]
language model with the help of Lang

[09:42:32 - 09:42:36]
chin so I think we saw we are having

[09:42:35 - 09:42:37]
like two kinds of large language model

[09:42:36 - 09:42:39]
one is like commercial model one is like

[09:42:37 - 09:42:41]
open source large language model OKAY

[09:42:39 - 09:42:43]
commercial wise we already saw the

[09:42:41 - 09:42:45]
entire openi platform we are having gbt

[09:42:43 - 09:42:46]
based model and the open source wise we

[09:42:45 - 09:42:48]
are having this hugging face model that

[09:42:46 - 09:42:50]
means we are having let's say llama

[09:42:48 - 09:42:52]
model we are having mral model falcon

[09:42:50 - 09:42:54]
model like different different models

[09:42:52 - 09:42:56]
are available okay in the hugging face

[09:42:54 - 09:42:57]
Hub if you see okay there are thousands

[09:42:56 - 09:43:00]
of like lar langage models are available

[09:42:57 - 09:43:03]
I think I showed you one platform open

[09:43:00 - 09:43:07]
llm okay it should be open llm GitHub

[09:43:03 - 09:43:09]
Now list of all the open llm see all

[09:43:07 - 09:43:10]
kinds of large language model you can

[09:43:09 - 09:43:13]
see and these are actually open source

[09:43:10 - 09:43:14]
large language model fine now first of

[09:43:13 - 09:43:17]
all let's try to see how we can access

[09:43:14 - 09:43:19]
actually open large language model see

[09:43:17 - 09:43:22]
whenever I think I showed you the open

[09:43:19 - 09:43:24]
platform and I showed you the demo of

[09:43:22 - 09:43:26]
the let's say model like if I want to

[09:43:24 - 09:43:28]
access this model if I want to give any

[09:43:26 - 09:43:29]
kinds of prompt so how we can do it see

[09:43:28 - 09:43:31]
this open ey is already integrated

[09:43:29 - 09:43:33]
inside Lang chin so I think I showed you

[09:43:31 - 09:43:35]
the integration now so this open source

[09:43:33 - 09:43:38]
integration just open it up now see open

[09:43:35 - 09:43:40]
is already integrated with uh Lang chain

[09:43:38 - 09:43:42]
so you don't need to manually so here

[09:43:40 - 09:43:44]
you don't need to manually uh use the

[09:43:42 - 09:43:46]
openi platform like the way we used

[09:43:44 - 09:43:48]
previously like chat completion API

[09:43:46 - 09:43:50]
completion API no you don't need to use

[09:43:48 - 09:43:53]
like that see it's the very simple first

[09:43:50 - 09:43:53]
of all install the open

[09:43:56 - 09:44:03]
a then just import from langin large

[09:44:01 - 09:44:04]
language model I want to use openi okay

[09:44:03 - 09:44:06]
openi platform that means open large

[09:44:04 - 09:44:08]
language model just try to import this

[09:44:06 - 09:44:10]
particular class now here just try to

[09:44:08 - 09:44:12]
set the temperature

[09:44:10 - 09:44:13]
parameter okay temperature parameter now

[09:44:12 - 09:44:15]
what is temperature parameter I think

[09:44:13 - 09:44:18]
you remember temperature parameter it's

[09:44:15 - 09:44:20]
just a creative actually parameter like

[09:44:18 - 09:44:21]
how much creative you want to be your

[09:44:20 - 09:44:22]
lar langage model you can see if it is

[09:44:21 - 09:44:25]
zero close to zero that means

[09:44:22 - 09:44:27]
temperature uh it means model is very

[09:44:25 - 09:44:28]
safe and it is not taking any bits that

[09:44:27 - 09:44:30]
means it won't be taking any risk okay

[09:44:28 - 09:44:32]
it will stick to the output and if it is

[09:44:30 - 09:44:33]
close to one that means this will be

[09:44:32 - 09:44:36]
taking risk it might generate wrong

[09:44:33 - 09:44:37]
output but it's like very creative okay

[09:44:36 - 09:44:40]
I think I already explained this part

[09:44:37 - 09:44:41]
now let me initialize my open a rer now

[09:44:40 - 09:44:43]
see I have already initialized my open a

[09:44:41 - 09:44:45]
raer now see this is my large language

[09:44:43 - 09:44:46]
model so guys whenever you initialize

[09:44:45 - 09:44:49]
this rapper by default actually it will

[09:44:46 - 09:44:51]
utilize one model called GPT 3.5 turbo

[09:44:49 - 09:44:52]
model okay but if you want to use any

[09:44:51 - 09:44:54]
other model you can give the model

[09:44:52 - 09:44:55]
parameter here there is a model

[09:44:54 - 09:44:57]
parameter with the help of that you can

[09:44:55 - 09:44:59]
also give any other model name okay

[09:44:57 - 09:45:01]
later on I'll show you how we can change

[09:44:59 - 09:45:03]
the model as of now let's take the

[09:45:01 - 09:45:05]
default model only now let's say this is

[09:45:03 - 09:45:07]
my prompt you can see what would be a

[09:45:05 - 09:45:09]
good company name for a uh for a company

[09:45:07 - 09:45:11]
that makes colorful socks okay this is

[09:45:09 - 09:45:13]
the let's say my prompt I'm giving to my

[09:45:11 - 09:45:16]
large language model now let me

[09:45:13 - 09:45:18]
initialize this prompt now see if I want

[09:45:16 - 09:45:20]
to let's say generate output gener the

[09:45:18 - 09:45:22]
response I need to call the predict

[09:45:20 - 09:45:25]
function lm. predict inside that I need

[09:45:22 - 09:45:29]
to give my prompt now see it will give

[09:45:25 - 09:45:32]
me the answer now rainbow trades are

[09:45:29 - 09:45:33]
vibrant socks uh company okay so this is

[09:45:32 - 09:45:35]
this is suggesting the name of the

[09:45:33 - 09:45:37]
company okay that makes colorful socks

[09:45:35 - 09:45:39]
it's great now you can also directly

[09:45:37 - 09:45:40]
pass this text to the large language

[09:45:39 - 09:45:42]
model rapper so instead of calling the

[09:45:40 - 09:45:44]
predict you can also give like that it

[09:45:42 - 09:45:46]
will also work so these are some

[09:45:44 - 09:45:47]
actually way we can uh give the input to

[09:45:46 - 09:45:50]
the large language model now see it is

[09:45:47 - 09:45:52]
also giving me the name now you can see

[09:45:50 - 09:45:54]
uh uh now you can see it has given me

[09:45:52 - 09:45:56]
this name okay this is the response now

[09:45:54 - 09:45:58]
I can also use something called invok

[09:45:56 - 09:46:01]
function okay inside invok function also

[09:45:58 - 09:46:01]
you can give the input it will also

[09:46:04 - 09:46:09]
work see invok has given some more

[09:46:07 - 09:46:10]
detail output you can see it has

[09:46:09 - 09:46:13]
suggested me different different

[09:46:10 - 09:46:14]
actually company I can uh use this name

[09:46:13 - 09:46:17]
uh that makes actually colorful socks

[09:46:14 - 09:46:19]
okay it's pretty good now let me show

[09:46:17 - 09:46:21]
you the second example so I have written

[09:46:19 - 09:46:22]
the same code guys you can see now here

[09:46:21 - 09:46:24]
I've given another prompt I want to open

[09:46:22 - 09:46:28]
a restaurant for a Chinese food suggest

[09:46:24 - 09:46:31]
me a fancy name for this so now let me

[09:46:28 - 09:46:35]
give so it is suest me Imperial

[09:46:31 - 09:46:39]
Dragon Palace okay great now I can give

[09:46:35 - 09:46:44]
the input like that also inside LM

[09:46:39 - 09:46:46]
object now dragon fire dining okay great

[09:46:44 - 09:46:47]
name now let me show you the hugging

[09:46:46 - 09:46:49]
face okay hugging face model because see

[09:46:47 - 09:46:51]
at the end openi is a chargeable that

[09:46:49 - 09:46:54]
means if you're sending any request to

[09:46:51 - 09:46:56]
the open open AI okay that is open AI

[09:46:54 - 09:46:58]
model it will charge you based on the

[09:46:56 - 09:47:00]
token so it's a at then there is a cost

[09:46:58 - 09:47:02]
involvement but let's say you don't want

[09:47:00 - 09:47:04]
to spend the money you don't want to use

[09:47:02 - 09:47:06]
this kinds of paid model you can also

[09:47:04 - 09:47:08]
use open source large language model

[09:47:06 - 09:47:09]
with the help of uh Lang chain it is

[09:47:08 - 09:47:11]
also possible for this what you have to

[09:47:09 - 09:47:13]
do you have to use hugging face up okay

[09:47:11 - 09:47:15]
because inside hugging face I showed you

[09:47:13 - 09:47:17]
we are having lacks of model we are

[09:47:15 - 09:47:19]
having lacks of model and all the models

[09:47:17 - 09:47:21]
are open source okay all the models are

[09:47:19 - 09:47:22]
open source and these are like Lar

[09:47:21 - 09:47:23]
language model from the different

[09:47:22 - 09:47:28]
different organization you can see from

[09:47:23 - 09:47:29]
meta from Google okay from open uh then

[09:47:28 - 09:47:32]
we are also having see openi also having

[09:47:29 - 09:47:33]
some kinds of actually free model they

[09:47:32 - 09:47:35]
are published in the hugging face you

[09:47:33 - 09:47:36]
can also use them m is also there

[09:47:35 - 09:47:38]
different different model see that many

[09:47:36 - 09:47:40]
of models are available inside hugging

[09:47:38 - 09:47:41]
face it's like very hug model now even I

[09:47:40 - 09:47:42]
also showed you different different task

[09:47:41 - 09:47:45]
you can select based on that also you

[09:47:42 - 09:47:46]
can also select the model it's up to you

[09:47:45 - 09:47:48]
now let me show you how we can uh

[09:47:46 - 09:47:49]
integrate hugging face platform and how

[09:47:48 - 09:47:51]
we can access hugging face large

[09:47:49 - 09:47:53]
language model also for this you have to

[09:47:51 - 09:47:55]
install one Library called hugging face

[09:47:53 - 09:47:56]
Hub so let me install hugging face Hub

[09:47:55 - 09:47:58]
because the models are available it is

[09:47:56 - 09:47:59]
present inside hugging face Hub because

[09:47:58 - 09:48:01]
I already told you now the model they

[09:47:59 - 09:48:02]
have published it is called Hub okay Hub

[09:48:01 - 09:48:04]
inside Hub actually this models are

[09:48:02 - 09:48:06]
present now see I installed the hugging

[09:48:04 - 09:48:08]
face up now let me import hugging face

[09:48:06 - 09:48:10]
up from Lang chain now see uh this is

[09:48:08 - 09:48:13]
the model actually I want to use so I've

[09:48:10 - 09:48:15]
already provided the link let me open so

[09:48:13 - 09:48:17]
this is called actually flant T5 model

[09:48:15 - 09:48:18]
this is from Google and this is one of

[09:48:17 - 09:48:19]
the large language model guys you can

[09:48:18 - 09:48:21]
see if you are interested you can go

[09:48:19 - 09:48:22]
through the documentation okay what can

[09:48:21 - 09:48:23]
this model can perform and all

[09:48:22 - 09:48:25]
everything they have given they have

[09:48:23 - 09:48:28]
also given the paper link of the model

[09:48:25 - 09:48:31]
now if I go to my notebook now see here

[09:48:28 - 09:48:32]
I'm using the large model see this is

[09:48:31 - 09:48:34]
the extra large model and it's like very

[09:48:32 - 09:48:36]
huge I don't want to load this model I

[09:48:34 - 09:48:38]
want to use some smaller model because

[09:48:36 - 09:48:39]
here I I want to show you the quick demo

[09:48:38 - 09:48:42]
that's why so I'm using this model

[09:48:39 - 09:48:44]
actually T5 large model let me show you

[09:48:42 - 09:48:46]
so this is the model the same model only

[09:48:44 - 09:48:48]
but this is the small variant this is

[09:48:46 - 09:48:49]
the small variant and this is the X

[09:48:48 - 09:48:51]
large variant like this is like more

[09:48:49 - 09:48:55]
bigger than this one okay I hope it is

[09:48:51 - 09:48:56]
clear now see if I want to load the llm

[09:48:55 - 09:48:57]
object right now that means large

[09:48:56 - 09:48:59]
language model idty to use hugging for

[09:48:57 - 09:49:00]
from Lang chin inside that I have to

[09:48:59 - 09:49:02]
give the repo ID that means the model

[09:49:00 - 09:49:04]
you want to use just copy the repo ID

[09:49:02 - 09:49:06]
and pass it here and you have to give

[09:49:04 - 09:49:08]
some arguments okay you have to give

[09:49:06 - 09:49:09]
some model arguments that means the same

[09:49:08 - 09:49:11]
parameter I think remember temperature

[09:49:09 - 09:49:12]
what temperature will do I think I

[09:49:11 - 09:49:14]
already showed you this is the creative

[09:49:12 - 09:49:16]
parameter and the max length I think you

[09:49:14 - 09:49:18]
remember inside open I also used to pass

[09:49:16 - 09:49:20]
the max length that means how many let's

[09:49:18 - 09:49:22]
say output token you want to get from

[09:49:20 - 09:49:24]
your large language model so here I have

[09:49:22 - 09:49:25]
given 64 okay you can increase and

[09:49:24 - 09:49:27]
decrease as per your requirement you can

[09:49:25 - 09:49:29]
also remove this one okay it's

[09:49:27 - 09:49:31]
completely fine because at then it won't

[09:49:29 - 09:49:33]
be charging you okay it's a PRD model so

[09:49:31 - 09:49:35]
you can use as many of length you can

[09:49:33 - 09:49:37]
okay now see this large language model

[09:49:35 - 09:49:38]
we are using this is not like very good

[09:49:37 - 09:49:40]
large language model but somehow

[09:49:38 - 09:49:42]
actually just to test actually I'm using

[09:49:40 - 09:49:43]
it going forward we'll be using very

[09:49:42 - 09:49:45]
powerful large language model like we'll

[09:49:43 - 09:49:47]
be using Lama model mol model falcon

[09:49:45 - 09:49:48]
model OKAY Jimma model we'll be using

[09:49:47 - 09:49:50]
different different model but this is

[09:49:48 - 09:49:52]
like very basic SL language model

[09:49:50 - 09:49:53]
actually I just wanted to show you as of

[09:49:52 - 09:49:56]
now now this is the prompt I have given

[09:49:53 - 09:49:58]
translate English to German this

[09:49:56 - 09:50:00]
particular sentence okay now see how old

[09:49:58 - 09:50:01]
are you this sentence I want to do the

[09:50:00 - 09:50:03]
translate operation English to German

[09:50:01 - 09:50:05]
and for this I'm going to use this model

[09:50:03 - 09:50:08]
okay now let me execute and let me show

[09:50:05 - 09:50:11]
you the magic see this is the output I

[09:50:08 - 09:50:13]
got this is the German translation of

[09:50:11 - 09:50:14]
how are you and this model actually it

[09:50:13 - 09:50:16]
is trying to access with the help of

[09:50:14 - 09:50:18]
hugging face API okay hugging face API

[09:50:16 - 09:50:20]
that means the token you collected and

[09:50:18 - 09:50:22]
anything you just set inside in enir

[09:50:20 - 09:50:23]
variable with the help of that it is

[09:50:22 - 09:50:26]
sending the request to the hugging face

[09:50:23 - 09:50:27]
hugging face is returning the answer

[09:50:26 - 09:50:29]
okay we are accessing through API

[09:50:27 - 09:50:30]
request right now going forward we'll be

[09:50:29 - 09:50:32]
also learning how we can download the

[09:50:30 - 09:50:34]
model as well and we'll be loading that

[09:50:32 - 09:50:36]
model with the help of langen and we can

[09:50:34 - 09:50:38]
create a llm rapper and we can do the

[09:50:36 - 09:50:39]
application building okay so I'll also

[09:50:38 - 09:50:40]
show you this part no need to worry as

[09:50:39 - 09:50:42]
of now I'm showing you the API access

[09:50:40 - 09:50:44]
okay if I want only want to perform the

[09:50:42 - 09:50:47]
inference operation how we can perform

[09:50:44 - 09:50:49]
it that is the idea now again I've given

[09:50:47 - 09:50:50]
the second example the same example I

[09:50:49 - 09:50:52]
want to open a Resturant for Chinese

[09:50:50 - 09:50:54]
suest me a fancy name for this again I

[09:50:52 - 09:50:56]
initialized my LM rapper with the help

[09:50:54 - 09:50:58]
of my huging f model now if I give this

[09:50:56 - 09:51:00]
prompt to my large language model see it

[09:50:58 - 09:51:02]
is giving me Chinese Resturant so this

[09:51:00 - 09:51:04]
is not actually creative Rim because I

[09:51:02 - 09:51:07]
told you I'm using very basic SL

[09:51:04 - 09:51:09]
language model that's why okay so yes

[09:51:07 - 09:51:11]
guys this is the introduction of Lang

[09:51:09 - 09:51:13]
Chen I think you got it what is uh Lang

[09:51:11 - 09:51:15]
Chen is and how we can use Lang Chen

[09:51:13 - 09:51:17]
exactly okay and it's like very easy to

[09:51:15 - 09:51:19]
use very easy to use it will trust me

[09:51:17 - 09:51:20]
guys it will make your task very easy if

[09:51:19 - 09:51:23]
you're using Lang chain it will make

[09:51:20 - 09:51:24]
your task very easy okay now in the next

[09:51:23 - 09:51:26]
video we'll be learning about something

[09:51:24 - 09:51:28]
called prompt template okay like how we

[09:51:26 - 09:51:30]
can create different different prompt

[09:51:28 - 09:51:32]
template and how we can pass to the

[09:51:30 - 09:51:34]
let's say large language model okay with

[09:51:32 - 09:51:36]
the help of langin so previously I think

[09:51:34 - 09:51:38]
I showed you how we can use this uh

[09:51:36 - 09:51:41]
langin to access different different

[09:51:38 - 09:51:43]
large language model and whenever I was

[09:51:41 - 09:51:45]
accessing this large language model that

[09:51:43 - 09:51:47]
means uh whenever I was let's say

[09:51:45 - 09:51:49]
sending my prompt to the large language

[09:51:47 - 09:51:50]
model you can see I was giving the

[09:51:49 - 09:51:52]
complete prompt okay this is the the

[09:51:50 - 09:51:53]
complete promt actually I was to pass

[09:51:52 - 09:51:55]
let's say this is the prompt I want to

[09:51:53 - 09:51:57]
open a restaurant for Chinese food suest

[09:51:55 - 09:52:00]
me a fancy name for this now let's say

[09:51:57 - 09:52:02]
if user needs to change this food okay

[09:52:00 - 09:52:05]
food let's say category let's say uh he

[09:52:02 - 09:52:08]
wants to let's say put Indian food here

[09:52:05 - 09:52:09]
so what he has to write again he he has

[09:52:08 - 09:52:12]
to write the complete prompt yes or no

[09:52:09 - 09:52:15]
that means if I show you let's I can

[09:52:12 - 09:52:17]
copy and I can paste it here let's I

[09:52:15 - 09:52:18]
will comment this line now let's say

[09:52:17 - 09:52:21]
here instead of Chinese food I will give

[09:52:18 - 09:52:23]
Indian food

[09:52:21 - 09:52:25]
okay Indian food now if I execute see it

[09:52:23 - 09:52:27]
is giving me Indian Resturant now let's

[09:52:25 - 09:52:29]
say if I want to give any other food

[09:52:27 - 09:52:30]
let's say I want to give Korean food I

[09:52:29 - 09:52:32]
want to give let's say Pakistani food I

[09:52:30 - 09:52:33]
want to give let's say I want to give

[09:52:32 - 09:52:36]
let's say Italian food so I have to

[09:52:33 - 09:52:37]
every time write the entire prompt okay

[09:52:36 - 09:52:39]
but let's say you are creating a

[09:52:37 - 09:52:41]
complete application you are creating a

[09:52:39 - 09:52:42]
complete let's say web application or

[09:52:41 - 09:52:44]
let's say stream late application or any

[09:52:42 - 09:52:46]
kinds of application there you don't

[09:52:44 - 09:52:49]
want to pass this entire prompt again

[09:52:46 - 09:52:51]
and again because if user let's say

[09:52:49 - 09:52:53]
needs to pass this prompt entirely again

[09:52:51 - 09:52:55]
and again so it would be little bit

[09:52:53 - 09:52:56]
actually let's say hard for the user yes

[09:52:55 - 09:52:59]
or no now see instead of passing the

[09:52:56 - 09:53:01]
entire promt you can see we can only

[09:52:59 - 09:53:03]
change this uh food category okay the

[09:53:01 - 09:53:05]
food category will only change otherwise

[09:53:03 - 09:53:07]
see this promp will remain same now

[09:53:05 - 09:53:09]
every time so that time actually I can

[09:53:07 - 09:53:10]
do the slight modification here that

[09:53:09 - 09:53:13]
means I can create a template of the

[09:53:10 - 09:53:15]
prompt and user will only select that

[09:53:13 - 09:53:17]
part he needs to change here okay this

[09:53:15 - 09:53:20]
is the idea now let me show you how it

[09:53:17 - 09:53:21]
can be done so for this actually be

[09:53:20 - 09:53:24]
using something called prom template

[09:53:21 - 09:53:26]
okay now inside Lang chain we are having

[09:53:24 - 09:53:27]
uh inside Lang chain prompts we having

[09:53:26 - 09:53:29]
something called prom template now here

[09:53:27 - 09:53:30]
I've created a promp template and here

[09:53:29 - 09:53:33]
I've given the input variables is equal

[09:53:30 - 09:53:35]
to kuin now this is the same prompt I

[09:53:33 - 09:53:36]
have written you can see I want to open

[09:53:35 - 09:53:38]
a student for now you can see in the

[09:53:36 - 09:53:41]
bracket I've written kuin okay now this

[09:53:38 - 09:53:43]
is going to be the input only and rest

[09:53:41 - 09:53:45]
of the let's say prompt will remain same

[09:53:43 - 09:53:47]
okay as per the prompt you have written

[09:53:45 - 09:53:49]
previously so me a fancy F this okay now

[09:53:47 - 09:53:51]
here is the prompt template I'm creating

[09:53:49 - 09:53:53]
I'm just doing the format oper

[09:53:51 - 09:53:54]
and kuin is equal to Italian that means

[09:53:53 - 09:53:56]
user will only give the food category

[09:53:54 - 09:53:58]
right now let's say Italian Indian

[09:53:56 - 09:54:00]
Pakistani okay or let's say Bangladeshi

[09:53:58 - 09:54:01]
anything they can put here it's up to

[09:54:00 - 09:54:03]
them now user don't have to write the

[09:54:01 - 09:54:06]
entire prompt user will only change the

[09:54:03 - 09:54:08]
food category here got it so this is

[09:54:06 - 09:54:10]
called actually promt template so

[09:54:08 - 09:54:11]
whenever we'll be creating any kinds of

[09:54:10 - 09:54:12]
let's say large language Prov

[09:54:11 - 09:54:14]
application whenever will be creating

[09:54:12 - 09:54:16]
any kind of GNA application we always

[09:54:14 - 09:54:17]
need to take care this particular prompt

[09:54:16 - 09:54:19]
let's say I don't need to pass the

[09:54:17 - 09:54:21]
entire prompt instead of that what I can

[09:54:19 - 09:54:23]
give I can only give the prompt which is

[09:54:21 - 09:54:26]
required to get my output okay this is

[09:54:23 - 09:54:27]
the idea now see if I execute this line

[09:54:26 - 09:54:29]
now see it is creating my complete

[09:54:27 - 09:54:31]
prompt that means user is giving Italian

[09:54:29 - 09:54:33]
food now see in the cuisine section it

[09:54:31 - 09:54:35]
will come the it now you can see in the

[09:54:33 - 09:54:37]
cuisine section it will replace with the

[09:54:35 - 09:54:40]
Italian now if I give let's say

[09:54:37 - 09:54:42]
Indian now see here it uh Indian will

[09:54:40 - 09:54:45]
come okay I think you got it now there

[09:54:42 - 09:54:47]
is another way you can uh Define this

[09:54:45 - 09:54:50]
prom template now you can write uh prom

[09:54:47 - 09:54:51]
template doore template now now this is

[09:54:50 - 09:54:54]
another prompt I have given what is the

[09:54:51 - 09:54:56]
good name for the company that makes now

[09:54:54 - 09:54:57]
you can see product should be the input

[09:54:56 - 09:55:00]
now here you can pass the product name

[09:54:57 - 09:55:02]
like that prom. format product is equal

[09:55:00 - 09:55:04]
to colorful socks or any other name

[09:55:02 - 09:55:07]
let's say cakes or let's say biscuits

[09:55:04 - 09:55:09]
anything you can give here if I execute

[09:55:07 - 09:55:11]
see in the product this uh input would

[09:55:09 - 09:55:14]
be replaced okay so this is called

[09:55:11 - 09:55:15]
actually prom template inside langin and

[09:55:14 - 09:55:17]
this is like very powerful concept guys

[09:55:15 - 09:55:19]
because going forward whenever you'll be

[09:55:17 - 09:55:21]
implementing application this concept

[09:55:19 - 09:55:22]
will help you a lot got it so yes this

[09:55:21 - 09:55:24]
is what I just wanted to show you in the

[09:55:22 - 09:55:26]
next video we'll be learning about

[09:55:24 - 09:55:28]
chains inside uh uh langin and with the

[09:55:26 - 09:55:30]
help of chain actually we'll be inting

[09:55:28 - 09:55:32]
this prom template as well as the large

[09:55:30 - 09:55:34]
language model and we'll be again doing

[09:55:32 - 09:55:36]
the inference operation and what is the

[09:55:34 - 09:55:38]
use of promp template I already explain

[09:55:36 - 09:55:39]
now see if I want to use this prompt

[09:55:38 - 09:55:42]
template with my large language model so

[09:55:39 - 09:55:43]
what I have to do I have to combine my

[09:55:42 - 09:55:44]
large language model as well as the

[09:55:43 - 09:55:45]
prompt template I have created okay for

[09:55:44 - 09:55:48]
this we'll be using something called

[09:55:45 - 09:55:50]
chin you can see combine llms and prompt

[09:55:48 - 09:55:52]
in a multi-steps workflows okay to

[09:55:50 - 09:55:54]
create a multi-state workflows I have to

[09:55:52 - 09:55:56]
create a change now let me show you one

[09:55:54 - 09:55:57]
example I think then this part would be

[09:55:56 - 09:55:59]
clear let's say first of all I will

[09:55:57 - 09:56:02]
initialize my large langage model rapper

[09:55:59 - 09:56:04]
and here I'm using open AI model now see

[09:56:02 - 09:56:05]
previously I think you remember we

[09:56:04 - 09:56:08]
learned this prom template that means if

[09:56:05 - 09:56:10]
I want to let's say give any kinds of

[09:56:08 - 09:56:12]
prompt but I don't need to uh pass the

[09:56:10 - 09:56:14]
entire prompt only I want to pass some

[09:56:12 - 09:56:17]
specific let's say U point of that

[09:56:14 - 09:56:19]
particular prompt you can see here only

[09:56:17 - 09:56:21]
I want to change the product name so for

[09:56:19 - 09:56:22]
this I created a prompt template and the

[09:56:21 - 09:56:24]
product name I've given the colorful

[09:56:22 - 09:56:26]
socks okay this is my entire prompt you

[09:56:24 - 09:56:28]
can see now it will create my entire

[09:56:26 - 09:56:30]
prompt so which is the good name for the

[09:56:28 - 09:56:31]
company that makes colorful socks that

[09:56:30 - 09:56:33]
means whatever input you are giving it

[09:56:31 - 09:56:35]
will replace it here fine now as of now

[09:56:33 - 09:56:36]
let me comment this line let's say this

[09:56:35 - 09:56:38]
is the prompt I have created this is the

[09:56:36 - 09:56:41]
entire prompt I have created I think you

[09:56:38 - 09:56:42]
would remember now if I want to use this

[09:56:41 - 09:56:44]
prompt The Prompt template I have

[09:56:42 - 09:56:46]
created with my large language model I

[09:56:44 - 09:56:49]
have to use something called LM Chen and

[09:56:46 - 09:56:51]
how to import LM CH so from Lang Chen do

[09:56:49 - 09:56:52]
CH import l M chain now the first

[09:56:51 - 09:56:54]
parameter you have to give the large

[09:56:52 - 09:56:55]
language model the large language model

[09:56:54 - 09:56:57]
you have defined which is nothing but

[09:56:55 - 09:56:59]
open open E large language model you can

[09:56:57 - 09:57:00]
also use open source large language

[09:56:59 - 09:57:01]
model you can use hugging face large

[09:57:00 - 09:57:03]
language model as well the way I showed

[09:57:01 - 09:57:05]
you then you have to give the prompt

[09:57:03 - 09:57:06]
template the second parameter you can

[09:57:05 - 09:57:08]
see prompt is equal to prompt that means

[09:57:06 - 09:57:10]
the prompt template I have created this

[09:57:08 - 09:57:12]
object actually I'm passing here then

[09:57:10 - 09:57:14]
just try to call this function chain.

[09:57:12 - 09:57:15]
run and inside that give the input let's

[09:57:14 - 09:57:17]
say whatever input you used to give like

[09:57:15 - 09:57:19]
that instead of giving you have to give

[09:57:17 - 09:57:22]
chain. run and give the input let's say

[09:57:19 - 09:57:24]
colorful soof now if I execute see it

[09:57:22 - 09:57:26]
will give me the output see Rainbow

[09:57:24 - 09:57:28]
traits or chroma shocks I think okay

[09:57:26 - 09:57:30]
chroma shocks actually it is giving me

[09:57:28 - 09:57:33]
the output that means now we are able to

[09:57:30 - 09:57:35]
use our prom template as well as the uh

[09:57:33 - 09:57:37]
let's say llm okay and for this we are

[09:57:35 - 09:57:39]
using something called LM CH that means

[09:57:37 - 09:57:40]
first of all it is creating the entire

[09:57:39 - 09:57:42]
prom template first of all it is

[09:57:40 - 09:57:44]
creating the entire prom template that

[09:57:42 - 09:57:47]
means this entire prom

[09:57:44 - 09:57:48]
template if I show

[09:57:47 - 09:57:50]
you that means it is first of all

[09:57:48 - 09:57:52]
creating the entire prom template and

[09:57:50 - 09:57:53]
this prompt actually is passing to the

[09:57:52 - 09:57:55]
large language model and how things are

[09:57:53 - 09:57:58]
happening with the help of llm chain

[09:57:55 - 09:58:00]
okay that's why here I have written um

[09:57:58 - 09:58:02]
with multi-step workflows that means it

[09:58:00 - 09:58:04]
is creating a workflow in the back end

[09:58:02 - 09:58:05]
it is creating a pipeline so first of

[09:58:04 - 09:58:07]
all it will create the prompt then this

[09:58:05 - 09:58:09]
prompt would be passed to the large

[09:58:07 - 09:58:11]
language model and this things are

[09:58:09 - 09:58:13]
handling by the llm chain I think you

[09:58:11 - 09:58:15]
know what is chain now chain is chain

[09:58:13 - 09:58:17]
means like one let chain would be

[09:58:15 - 09:58:19]
connected with another one okay that

[09:58:17 - 09:58:22]
means complete pipeline complete workf

[09:58:19 - 09:58:24]
flows sequence of you can say chains

[09:58:22 - 09:58:27]
okay so I think now you got it what

[09:58:24 - 09:58:28]
chain exactly inside uh Lang chain now

[09:58:27 - 09:58:30]
let me show you another example example

[09:58:28 - 09:58:32]
two so again I'll initialize my large

[09:58:30 - 09:58:33]
language model and see now here I'm

[09:58:32 - 09:58:34]
using the second approach I think

[09:58:33 - 09:58:36]
remember we can also create the prom

[09:58:34 - 09:58:38]
template like that so let's say here

[09:58:36 - 09:58:39]
input variable is nothing but my cuin

[09:58:38 - 09:58:41]
that means kin will only change and rest

[09:58:39 - 09:58:43]
of the prompt will remain same okay now

[09:58:41 - 09:58:45]
this is my prompt template now if I want

[09:58:43 - 09:58:46]
to pass this prom template to my large

[09:58:45 - 09:58:48]
language model what I will do I'll use

[09:58:46 - 09:58:50]
the llm chain inside llm chain I'll

[09:58:48 - 09:58:51]
first of all give the llm then I will

[09:58:50 - 09:58:53]
pass my prom template the prom template

[09:58:51 - 09:58:56]
I have created now you can see I'm

[09:58:53 - 09:58:57]
calling chain. run and here I'm giving

[09:58:56 - 09:58:59]
the input let's say Mexican I want to

[09:58:57 - 09:59:01]
see the Mexican now here you can see I

[09:58:59 - 09:59:02]
have given Mexican as an input that

[09:59:01 - 09:59:04]
means I want to open a resturent for the

[09:59:02 - 09:59:06]
Mexican food now if I execute so it

[09:59:04 - 09:59:08]
should suggest me some fancy name for

[09:59:06 - 09:59:11]
this see this is the name it has me L

[09:59:08 - 09:59:13]
sober D Mexico okay the flavor of Mexico

[09:59:11 - 09:59:15]
now if you want to see internally how it

[09:59:13 - 09:59:17]
is like creating the entire PR for this

[09:59:15 - 09:59:19]
you can activate one parameter called

[09:59:17 - 09:59:20]
varos isal to true now see if I again

[09:59:19 - 09:59:22]
execute

[09:59:20 - 09:59:24]
it will show you internally first of all

[09:59:22 - 09:59:26]
it will create the complete prom

[09:59:24 - 09:59:28]
template that means here you have given

[09:59:26 - 09:59:30]
Mexican so it will first of all create

[09:59:28 - 09:59:32]
the complete prom template with the help

[09:59:30 - 09:59:33]
of Mexican this prom template will be

[09:59:32 - 09:59:34]
passed to my large language model and

[09:59:33 - 09:59:37]
large language model will give you the

[09:59:34 - 09:59:39]
output got it so this is the work of

[09:59:37 - 09:59:40]
chains now this is called actually

[09:59:39 - 09:59:43]
single chains now let's see if you want

[09:59:40 - 09:59:44]
to create a multiple chain that means

[09:59:43 - 09:59:46]
let's say you want to create a chain and

[09:59:44 - 09:59:48]
this chain output you want to again pass

[09:59:46 - 09:59:50]
to another chain okay for this you can

[09:59:48 - 09:59:52]
use something called multiple chain okay

[09:59:50 - 09:59:53]
multi chain and to use the multi chain

[09:59:52 - 09:59:55]
you have to use something called sequ

[09:59:53 - 09:59:57]
Simple sequence chain so there is

[09:59:55 - 09:59:59]
another class inside Lang chain chain

[09:59:57 - 10:00:00]
called Simple sequential chain we'll be

[09:59:59 - 10:00:01]
using this one let me show you one

[10:00:00 - 10:00:04]
example let's say this is my large

[10:00:01 - 10:00:05]
language model I have defined and this

[10:00:04 - 10:00:07]
is the prompt I have created the first

[10:00:05 - 10:00:10]
prompt you can see the same prompt I

[10:00:07 - 10:00:13]
want to open a Resturant for the kisin

[10:00:10 - 10:00:16]
food suest me a fancy name for this so

[10:00:13 - 10:00:18]
it will take the cuine input and this is

[10:00:16 - 10:00:20]
the LM chain I have created okay I think

[10:00:18 - 10:00:21]
you remember this is the LM chain

[10:00:20 - 10:00:24]
that means this is my LM rapper and this

[10:00:21 - 10:00:26]
is my prom template okay now what I want

[10:00:24 - 10:00:28]
whatever let's say Resturant name

[10:00:26 - 10:00:30]
actually it will suggest okay whatever

[10:00:28 - 10:00:31]
student name this prompt will suest that

[10:00:30 - 10:00:33]
means this large language model will

[10:00:31 - 10:00:34]
suggest this name again I want to pass

[10:00:33 - 10:00:36]
to another prompt template for this I

[10:00:34 - 10:00:38]
created another prompt template prompt

[10:00:36 - 10:00:39]
template now input variable is restorent

[10:00:38 - 10:00:40]
name that means this prompt will give

[10:00:39 - 10:00:42]
you the restorant name yes or no because

[10:00:40 - 10:00:45]
here you have given kuin fo suggest me a

[10:00:42 - 10:00:46]
fancy name for this okay now it will

[10:00:45 - 10:00:48]
give you resturent name and this

[10:00:46 - 10:00:50]
resturent name I want to utilize and

[10:00:48 - 10:00:52]
here I written another prompt s just me

[10:00:50 - 10:00:53]
some menu item for this restaurant name

[10:00:52 - 10:00:55]
that means let's say You have given

[10:00:53 - 10:00:58]
Indian Indian let's say food now it will

[10:00:55 - 10:00:59]
give you some Indian restaurant name and

[10:00:58 - 10:01:02]
this Indian resturent name here I will

[10:00:59 - 10:01:04]
pass and it will give me some menu item

[10:01:02 - 10:01:05]
for the Indian resturent name okay I

[10:01:04 - 10:01:07]
think you got it how it is

[10:01:05 - 10:01:08]
interconnected with each other this is

[10:01:07 - 10:01:10]
called actually multiple chain okay now

[10:01:08 - 10:01:12]
see here Ive created another chain now

[10:01:10 - 10:01:13]
if I you want to use this both chain I

[10:01:12 - 10:01:15]
have to use something called Simple

[10:01:13 - 10:01:17]
sequential chin now there are some

[10:01:15 - 10:01:19]
limitation inside simple sequential chin

[10:01:17 - 10:01:21]
I'll tell you what is the limitation as

[10:01:19 - 10:01:22]
of now let me show you the let's say

[10:01:21 - 10:01:24]
example so you can see I have

[10:01:22 - 10:01:26]
initialized the simple sequential chain

[10:01:24 - 10:01:28]
inside that chain is equal to first of

[10:01:26 - 10:01:29]
all I will give my name chain you can

[10:01:28 - 10:01:31]
see first of all I'll will give my name

[10:01:29 - 10:01:33]
chain that means it will give me the

[10:01:31 - 10:01:35]
restaurant name okay then I will give my

[10:01:33 - 10:01:36]
food item chain that means this

[10:01:35 - 10:01:38]
particular chain that means whatever

[10:01:36 - 10:01:39]
Resturant name I will be getting from

[10:01:38 - 10:01:41]
this chain I want to pass to the next

[10:01:39 - 10:01:43]
chain okay which is nothing but my suest

[10:01:41 - 10:01:46]
me some menu items for the resturant

[10:01:43 - 10:01:48]
name okay now uh here is the final code

[10:01:46 - 10:01:49]
chain. run here I've given the Indian

[10:01:48 - 10:01:52]
that means first of all it will go in

[10:01:49 - 10:01:53]
inside that and it will give the output

[10:01:52 - 10:01:55]
and this output will go in the next next

[10:01:53 - 10:01:58]
CH okay now it will give me the output

[10:01:55 - 10:01:58]
let me show

[10:02:00 - 10:02:06]
you now see I have given Indian now see

[10:02:03 - 10:02:07]
this is the Indian menu I got that means

[10:02:06 - 10:02:09]
what is happening first of all it is

[10:02:07 - 10:02:11]
executing this promp template then it is

[10:02:09 - 10:02:13]
executing this prompt template okay and

[10:02:11 - 10:02:14]
how it is handling it is handling by the

[10:02:13 - 10:02:16]
simple sequential prom template that

[10:02:14 - 10:02:18]
means it is following the sequence first

[10:02:16 - 10:02:20]
of all this sequence will execute then

[10:02:18 - 10:02:22]
this sequence will execute that's how

[10:02:20 - 10:02:24]
you can create multiple prompt not only

[10:02:22 - 10:02:26]
two prompt you can create 3 four 5 six

[10:02:24 - 10:02:28]
and so on if you need any kinds of let's

[10:02:26 - 10:02:30]
say application uh this is like

[10:02:28 - 10:02:32]
interconnected with let's say previous

[10:02:30 - 10:02:34]
prompt okay you can create these kinds

[10:02:32 - 10:02:37]
of sequential prompt now I think you got

[10:02:34 - 10:02:39]
the idea how CH GPT works okay how CH

[10:02:37 - 10:02:41]
GPT Works let's say how uh let's say if

[10:02:39 - 10:02:43]
if you giving any kinds of input how it

[10:02:41 - 10:02:44]
is connected with the previous prompt as

[10:02:43 - 10:02:47]
well okay they're also using something

[10:02:44 - 10:02:49]
called this sequential chain in the back

[10:02:47 - 10:02:52]
end okay chain method they're also using

[10:02:49 - 10:02:54]
I think it is clear now now the

[10:02:52 - 10:02:56]
limitation of simple sequential chain is

[10:02:54 - 10:02:58]
it is it is only showing you the last

[10:02:56 - 10:03:01]
output last last chain output you can

[10:02:58 - 10:03:03]
see only the menu item but if I want to

[10:03:01 - 10:03:04]
also see the previous chain output what

[10:03:03 - 10:03:06]
is the output it is giving for this you

[10:03:04 - 10:03:08]
have to use something called sequential

[10:03:06 - 10:03:10]
chain only okay sequ sequential chain

[10:03:08 - 10:03:12]
not the simple sequential chain okay

[10:03:10 - 10:03:13]
this is the difference only now let me

[10:03:12 - 10:03:16]
show you one example let's say I've

[10:03:13 - 10:03:18]
given the same example so I want to open

[10:03:16 - 10:03:20]
a stent who in name okay here have to

[10:03:18 - 10:03:23]
pass and here creating the

[10:03:20 - 10:03:25]
llm chain okay now this is the another

[10:03:23 - 10:03:27]
chain I created guys you can see so

[10:03:25 - 10:03:29]
whatever let's say uh Resturant name

[10:03:27 - 10:03:31]
actually I will get from my first CH you

[10:03:29 - 10:03:33]
can see output key it will return you

[10:03:31 - 10:03:34]
the resturant name so it should be the

[10:03:33 - 10:03:36]
input for the next CH which is nothing

[10:03:34 - 10:03:38]
but my uh menu okay menu of the

[10:03:36 - 10:03:40]
resturant name here You' given the input

[10:03:38 - 10:03:41]
is equal to Resturant name and this is

[10:03:40 - 10:03:43]
the template suggest me the menu of the

[10:03:41 - 10:03:46]
item for Resturant name and this is my

[10:03:43 - 10:03:48]
second actually chain I have created and

[10:03:46 - 10:03:50]
what would the output of this chain the

[10:03:48 - 10:03:51]
output would be menu item that means

[10:03:50 - 10:03:53]
whatever menu actually it will suggest

[10:03:51 - 10:03:55]
you now here I have initialized my

[10:03:53 - 10:03:57]
sequential chain now inside sequential

[10:03:55 - 10:03:58]
chain I have to pass my chain first of

[10:03:57 - 10:04:00]
all I have to give my name chain that

[10:03:58 - 10:04:02]
means the first chain I have created

[10:04:00 - 10:04:03]
then I have to give the second chain now

[10:04:02 - 10:04:05]
here you have to specify the input

[10:04:03 - 10:04:07]
variable what is the input variable I

[10:04:05 - 10:04:08]
think you saw the first input variable

[10:04:07 - 10:04:10]
is nothing but kuin okay kin should be

[10:04:08 - 10:04:12]
my input variable and what be the output

[10:04:10 - 10:04:14]
variable output variable would be the

[10:04:12 - 10:04:15]
resturant name as well as the menu item

[10:04:14 - 10:04:17]
okay resturent name as well as the menu

[10:04:15 - 10:04:19]
item that means both it will show me now

[10:04:17 - 10:04:21]
let me execute and let me show you see

[10:04:19 - 10:04:23]
now I'll call my chain and here I'll

[10:04:21 - 10:04:25]
give the input only which is nothing but

[10:04:23 - 10:04:26]
Indian that means cuine name now see it

[10:04:25 - 10:04:28]
will give you the

[10:04:26 - 10:04:30]
output see first of all it will give you

[10:04:28 - 10:04:33]
the cuine then the resturent name as

[10:04:30 - 10:04:35]
well as the menu item that means this

[10:04:33 - 10:04:37]
prompt it is giving you the output this

[10:04:35 - 10:04:39]
prompt it is giving you the output even

[10:04:37 - 10:04:40]
the menu item it is also giving you the

[10:04:39 - 10:04:42]
output that means complete output you

[10:04:40 - 10:04:44]
can see here so which is not available

[10:04:42 - 10:04:45]
inside my simple sequential chin okay

[10:04:44 - 10:04:47]
this is the difference only I think you

[10:04:45 - 10:04:49]
got it right now got it so yes that's

[10:04:47 - 10:04:52]
how actually we can use chin to

[10:04:49 - 10:04:55]
interconnect my prom template with my

[10:04:52 - 10:04:56]
large language model and we can uh

[10:04:55 - 10:04:58]
easily get any kinds of response from my

[10:04:56 - 10:05:00]
llm okay now in the next video we'll be

[10:04:58 - 10:05:02]
learning about something called agents

[10:05:00 - 10:05:05]
and Tool inside uh langin so what is

[10:05:02 - 10:05:09]
agents and Tool exactly uh let me show

[10:05:05 - 10:05:11]
you see agents and tools is a actually

[10:05:09 - 10:05:13]
very powerful concept inside Lang chain

[10:05:11 - 10:05:15]
so it will help you to let's say plug in

[10:05:13 - 10:05:18]
with different kinds of let's say tool

[10:05:15 - 10:05:20]
let's say if I give you one example um

[10:05:18 - 10:05:24]
let's say I have traveled from Dubai to

[10:05:20 - 10:05:26]
Canada I type this in chat gbt now give

[10:05:24 - 10:05:29]
me to flight option from Dubai to Canada

[10:05:26 - 10:05:33]
on September 1 20124 now CH gbt will not

[10:05:29 - 10:05:35]
be able to uh give the answer because it

[10:05:33 - 10:05:39]
has actually knowledge till September

[10:05:35 - 10:05:41]
2021 that means after 2021 if you asking

[10:05:39 - 10:05:43]
anything to the chat gbt it won't be

[10:05:41 - 10:05:46]
able to give the answer because it

[10:05:43 - 10:05:49]
doesn't have like the new information

[10:05:46 - 10:05:53]
new information regarding uh 2024 but

[10:05:49 - 10:05:55]
chat GPT plus has uh xandia uh plugin if

[10:05:53 - 10:05:58]
we enable this plugin it will go to the

[10:05:55 - 10:06:00]
xandia plugin and uh it will try to pull

[10:05:58 - 10:06:02]
the information about flights and it

[10:06:00 - 10:06:04]
will show the information that means if

[10:06:02 - 10:06:07]
it is not able to give the answer

[10:06:04 - 10:06:09]
related 20124 what it will do it will

[10:06:07 - 10:06:12]
try to connect some third party plugins

[10:06:09 - 10:06:13]
third partyy API okay and from there

[10:06:12 - 10:06:14]
actually it will pull the information

[10:06:13 - 10:06:16]
and it will show you let me show you one

[10:06:14 - 10:06:19]
example let's say this is my chat GPT

[10:06:16 - 10:06:22]
now here if I give this prompt what was

[10:06:19 - 10:06:25]
the G uh GDP of Canada in 2024 now see

[10:06:22 - 10:06:27]
if I give this to the chat gbt see chat

[10:06:25 - 10:06:29]
gbt searing Canada gbt see it is already

[10:06:27 - 10:06:32]
searcing okay it is already searching in

[10:06:29 - 10:06:33]
the third party API now see in 2024 now

[10:06:32 - 10:06:37]
you can see it has given me the answer

[10:06:33 - 10:06:40]
in 2024 what was the uh G GDP okay in

[10:06:37 - 10:06:43]
that Canada that means it doesn't have

[10:06:40 - 10:06:46]
the information about let's say 2024 uh

[10:06:43 - 10:06:48]
what Wass the Canada JDP but it was

[10:06:46 - 10:06:50]
searching okay it was searching in the

[10:06:48 - 10:06:52]
third party API that me it has some

[10:06:50 - 10:06:54]
plugins inside that okay so it is

[10:06:52 - 10:06:57]
happening with the help of this agents

[10:06:54 - 10:06:58]
only agents and Tool okay with the help

[10:06:57 - 10:07:01]
of agents and Tool they are doing these

[10:06:58 - 10:07:03]
kinds of task now let me show you how

[10:07:01 - 10:07:05]
you can also perform this agents and

[10:07:03 - 10:07:07]
Tool operation inside langin let's you

[10:07:05 - 10:07:09]
want to create an application and this

[10:07:07 - 10:07:11]
application will also uh be able to give

[10:07:09 - 10:07:13]
the answer from the newest actually

[10:07:11 - 10:07:15]
let's say uh information okay over the

[10:07:13 - 10:07:16]
Internet for this you can connect

[10:07:15 - 10:07:18]
actually different different tools

[10:07:16 - 10:07:20]
different different plugins you can

[10:07:18 - 10:07:21]
connect SARP apic this is the SARP API

[10:07:20 - 10:07:23]
SARP API is a Google search actually

[10:07:21 - 10:07:25]
let's say API you can also directly

[10:07:23 - 10:07:27]
search from the Google even you can also

[10:07:25 - 10:07:29]
connect the Wikipedia okay let me show

[10:07:27 - 10:07:30]
you one Wikipedia example even you can

[10:07:29 - 10:07:32]
also connect different different

[10:07:30 - 10:07:34]
actually third party plugins okay there

[10:07:32 - 10:07:35]
are so many third partyy plugins if you

[10:07:34 - 10:07:36]
search on Google you will see different

[10:07:35 - 10:07:39]
different third party plugins they are

[10:07:36 - 10:07:40]
using okay you can also connected

[10:07:39 - 10:07:42]
weather okay weather API to get the

[10:07:40 - 10:07:45]
let's say recent weather it is also

[10:07:42 - 10:07:47]
possible now see first of all I will be

[10:07:45 - 10:07:49]
installing Wikipedia just to show you

[10:07:47 - 10:07:50]
the demo of the Wikipedia now you can

[10:07:49 - 10:07:52]
see I'm importing this Agents from the

[10:07:50 - 10:07:55]
Lang chin I'm importing agents type then

[10:07:52 - 10:07:56]
initialize agents and load tools and all

[10:07:55 - 10:07:58]
then I'm also importing my openi that

[10:07:56 - 10:08:00]
means I want to use openi large language

[10:07:58 - 10:08:02]
model as of now now this is my let's say

[10:08:00 - 10:08:04]
llm rapper okay now if you want to

[10:08:02 - 10:08:05]
define the agents so you have to Define

[10:08:04 - 10:08:07]
like that guys first of all call this

[10:08:05 - 10:08:09]
load tools and inside that first of all

[10:08:07 - 10:08:11]
mention which let's say plugins you want

[10:08:09 - 10:08:13]
to use I want to use Wikipedia plugins

[10:08:11 - 10:08:15]
that means whatever things actually I'll

[10:08:13 - 10:08:17]
be searcing if it is not available

[10:08:15 - 10:08:18]
inside my chart GPT CH GPT let's say

[10:08:17 - 10:08:20]
knowledge base it will go to the

[10:08:18 - 10:08:21]
Wikipedia okay it will hit the Wikipedia

[10:08:20 - 10:08:23]
and from Wikipedia actually it will get

[10:08:21 - 10:08:25]
the response then it will also use

[10:08:23 - 10:08:28]
something called llm math tool and why

[10:08:25 - 10:08:30]
llm math tool because let's say if you

[10:08:28 - 10:08:33]
are asking something related JDP or

[10:08:30 - 10:08:35]
let's say uh any any kinds of number any

[10:08:33 - 10:08:36]
any kind of numerical representation so

[10:08:35 - 10:08:37]
for this actually this llm math is

[10:08:36 - 10:08:39]
required okay they're suggesting if you

[10:08:37 - 10:08:41]
go to the documentation you will see

[10:08:39 - 10:08:42]
that then I'm also passing my llm rapper

[10:08:41 - 10:08:44]
this particular object okay now it will

[10:08:42 - 10:08:45]
give me the tool now here I have to

[10:08:44 - 10:08:47]
initialize the agents first of all give

[10:08:45 - 10:08:49]
the tool the tool you have created then

[10:08:47 - 10:08:50]
give the llm the llm you have created as

[10:08:49 - 10:08:52]
well as the agent type so this is the

[10:08:50 - 10:08:53]
agent type you can give and verbos is

[10:08:52 - 10:08:54]
equal to True means it will also show

[10:08:53 - 10:08:56]
you the output okay like what it is

[10:08:54 - 10:08:58]
executing in the back end now just

[10:08:56 - 10:09:01]
simply search agent. run what was the

[10:08:58 - 10:09:04]
JDP of us in 2024 let's say this is my

[10:09:01 - 10:09:07]
question 2024 JDP I want to ask okay now

[10:09:04 - 10:09:10]
see if I execute this program now see uh

[10:09:07 - 10:09:11]
it has actually connected with my uh

[10:09:10 - 10:09:13]
Wikipedia and it has fced the

[10:09:11 - 10:09:15]
information and this is the final

[10:09:13 - 10:09:20]
results as you can see the JDP of us in

[10:09:15 - 10:09:24]
2024 was 28 trillion uh

[10:09:20 - 10:09:26]
28269 trillion okay it's great that

[10:09:24 - 10:09:29]
means it is also able to get the current

[10:09:26 - 10:09:30]
information okay newest information over

[10:09:29 - 10:09:32]
from the internet itself and this is

[10:09:30 - 10:09:34]
like very powerful tool guys trust me if

[10:09:32 - 10:09:36]
you want to implement any kinds of let's

[10:09:34 - 10:09:37]
say LM powered application and you want

[10:09:36 - 10:09:39]
to integrate this kinds of functionality

[10:09:37 - 10:09:41]
you can use this uh agents okay because

[10:09:39 - 10:09:44]
Char gbt is also using agents in the

[10:09:41 - 10:09:46]
back end it is clear okay now in the

[10:09:44 - 10:09:48]
next video we'll be also learning about

[10:09:46 - 10:09:49]
memory let's say I told you not CH GPT

[10:09:48 - 10:09:51]
can also remember the previous context

[10:09:49 - 10:09:53]
let's say if I give one let's say

[10:09:51 - 10:09:55]
message here give

[10:09:53 - 10:10:00]
me a

[10:09:55 - 10:10:03]
code to add two numbers in

[10:10:00 - 10:10:06]
Python let this is the prompt I have

[10:10:03 - 10:10:08]
given now see it has given me the code

[10:10:06 - 10:10:09]
now see it has given me one function but

[10:10:08 - 10:10:10]
I don't need the function I'll just

[10:10:09 - 10:10:13]
write

[10:10:10 - 10:10:13]
without

[10:10:14 - 10:10:18]
function now see it has automatically

[10:10:16 - 10:10:19]
remembered my previous uh prompt I have

[10:10:18 - 10:10:21]
given and now see

[10:10:19 - 10:10:23]
beautifully it has given me the second

[10:10:21 - 10:10:25]
response that means it is it is having

[10:10:23 - 10:10:26]
some memory okay buffer memory in the

[10:10:25 - 10:10:28]
back end with the help of that actually

[10:10:26 - 10:10:29]
it is trying to remember my previous

[10:10:28 - 10:10:31]
context so we'll be learning this part

[10:10:29 - 10:10:34]
in the memory part I think I already

[10:10:31 - 10:10:36]
showed you one demo of the chat GPT uh

[10:10:34 - 10:10:37]
chat GPT can remember my previous uh

[10:10:36 - 10:10:39]
let's say prompt that means whatever

[10:10:37 - 10:10:42]
previous prompt you are giving it can

[10:10:39 - 10:10:43]
remember that context right so how they

[10:10:42 - 10:10:44]
remembering the previous let's say

[10:10:43 - 10:10:46]
prompt and context because they're using

[10:10:44 - 10:10:48]
something called memory okay memory in

[10:10:46 - 10:10:50]
their application now with the help of

[10:10:48 - 10:10:52]
Lang you can create this memory so

[10:10:50 - 10:10:54]
whenever you want to create any kinds of

[10:10:52 - 10:10:55]
genbi application so definitely you

[10:10:54 - 10:10:57]
should integrate the memory with that

[10:10:55 - 10:10:59]
because people will be asking the

[10:10:57 - 10:11:00]
question and your application should

[10:10:59 - 10:11:02]
remember that particular context okay

[10:11:00 - 10:11:04]
this is the important things now let me

[10:11:02 - 10:11:06]
show you one demo of the memory so here

[10:11:04 - 10:11:08]
I've already written chatbot application

[10:11:06 - 10:11:10]
like chat gbt uh you will notice it will

[10:11:08 - 10:11:11]
remember the past information and how

[10:11:10 - 10:11:13]
they're remembering the past information

[10:11:11 - 10:11:15]
they're using memory so let me first of

[10:11:13 - 10:11:18]
all initialize my llm rapper I'm using

[10:11:15 - 10:11:20]
the open llm here now first of all let

[10:11:18 - 10:11:21]
me show you if you are not using like

[10:11:20 - 10:11:23]
memory okay memory let's say

[10:11:21 - 10:11:24]
functionality from the Lin what will

[10:11:23 - 10:11:26]
happen let's say here I created a pom

[10:11:24 - 10:11:28]
template the same prom plate I want to

[10:11:26 - 10:11:31]
open a restorant for the kuin food s me

[10:11:28 - 10:11:33]
a fancy name for this now see if I

[10:11:31 - 10:11:34]
create this prom template and if I give

[10:11:33 - 10:11:36]
this prom template what I have to do I

[10:11:34 - 10:11:37]
have to use llm chain here I'm passing

[10:11:36 - 10:11:39]
the LM and here I'm giving the prom

[10:11:37 - 10:11:41]
template okay now this is the let's say

[10:11:39 - 10:11:44]
input I've given Mexican so it will give

[10:11:41 - 10:11:45]
me the output the resturent name so guys

[10:11:44 - 10:11:48]
you can see it has suggested me

[10:11:45 - 10:11:50]
different different restaurant name now

[10:11:48 - 10:11:52]
if I give Indian

[10:11:50 - 10:11:55]
also see it has also given me Indian

[10:11:52 - 10:11:57]
press random now if I show you the chain

[10:11:55 - 10:11:59]
memory that means whether it has saved

[10:11:57 - 10:12:01]
anything or not so I'll just write

[10:11:59 - 10:12:03]
chain. memory see it is non type that

[10:12:01 - 10:12:04]
means it hasn't saved my previous

[10:12:03 - 10:12:07]
information whatever let's say question

[10:12:04 - 10:12:09]
I have asked it hasn't save any kinds of

[10:12:07 - 10:12:11]
information okay you can see it's a non-

[10:12:09 - 10:12:13]
type completely it's a non- type now if

[10:12:11 - 10:12:15]
I want to add the memory functionality

[10:12:13 - 10:12:16]
what I can do I can use actually three

[10:12:15 - 10:12:18]
kinds of memory inside Lang chain I'll

[10:12:16 - 10:12:20]
discuss all of them one by one first of

[10:12:18 - 10:12:23]
all let's try to see conversation buffer

[10:12:20 - 10:12:25]
memory okay so just try to import Lang

[10:12:23 - 10:12:27]
chain. memory import conversation buffer

[10:12:25 - 10:12:29]
memory okay now see this memory will try

[10:12:27 - 10:12:30]
to remember the previous conversation

[10:12:29 - 10:12:32]
now first of all create a memory object

[10:12:30 - 10:12:33]
you can see conversation B memory memory

[10:12:32 - 10:12:35]
object now same thing you have to

[10:12:33 - 10:12:37]
initialize only another parameter you

[10:12:35 - 10:12:40]
have to pass memory is equal to memory

[10:12:37 - 10:12:44]
okay now again I'm giving Mexican

[10:12:40 - 10:12:48]
food now I have given let's say Arabic

[10:12:44 - 10:12:51]
food okay now if I show you my chain.

[10:12:48 - 10:12:53]
memory. buffard you will see that it has

[10:12:51 - 10:12:56]
remembered my previous context so human

[10:12:53 - 10:12:57]
has given Mexican then AI has replied

[10:12:56 - 10:13:00]
again human has given the let's say

[10:12:57 - 10:13:01]
Arabic input then again my agent has

[10:13:00 - 10:13:03]
replied that means it is trying to

[10:13:01 - 10:13:06]
remember my previous conversation

[10:13:03 - 10:13:08]
amazing right now one issue actually

[10:13:06 - 10:13:10]
will get with this conversation B memory

[10:13:08 - 10:13:11]
it can remember all the input it will be

[10:13:10 - 10:13:14]
giving let's say whatever input it will

[10:13:11 - 10:13:16]
be giving all the input actually it will

[10:13:14 - 10:13:18]
try to remember so whenever it is trying

[10:13:16 - 10:13:20]
to remember all the input that means uh

[10:13:18 - 10:13:22]
it is occupying your memory space so I

[10:13:20 - 10:13:25]
don't need to remember all the let's say

[10:13:22 - 10:13:27]
context of the user I can only remember

[10:13:25 - 10:13:28]
let's say 5 to 10 let's say context it

[10:13:27 - 10:13:29]
would be enough for me because if you go

[10:13:28 - 10:13:32]
to the chat jpt also it can only

[10:13:29 - 10:13:34]
remember five to let's say six uh let's

[10:13:32 - 10:13:36]
say context five to six conversation

[10:13:34 - 10:13:38]
okay apart from that whatever things it

[10:13:36 - 10:13:40]
will say previously it will delete okay

[10:13:38 - 10:13:42]
so for this actually we can use another

[10:13:40 - 10:13:43]
actually memory called conversation

[10:13:42 - 10:13:45]
chain okay now here I have already

[10:13:43 - 10:13:47]
written conversation buffer memory goes

[10:13:45 - 10:13:49]
growing endlessly that means it can save

[10:13:47 - 10:13:51]
all the information and if I want to set

[10:13:49 - 10:13:53]
only let's say five conversation or

[10:13:51 - 10:13:54]
let's say or 10 to 20 conversation that

[10:13:53 - 10:13:56]
time I'll will be using conversation

[10:13:54 - 10:13:57]
chin now here is the example of

[10:13:56 - 10:13:59]
conversation chin first of all you have

[10:13:57 - 10:14:01]
to define the conversation CH and inside

[10:13:59 - 10:14:03]
that you have to pass the your llm

[10:14:01 - 10:14:04]
rapper now let me show you the template

[10:14:03 - 10:14:06]
now see this is the template actually it

[10:14:04 - 10:14:07]
will give you okay now you can see

[10:14:06 - 10:14:08]
current conversation there is no

[10:14:07 - 10:14:10]
conversation that's why it's empty now

[10:14:08 - 10:14:12]
let me do some conversation so here I

[10:14:10 - 10:14:14]
have given the first conversation who

[10:14:12 - 10:14:16]
own the first Cricket World Cup let's

[10:14:14 - 10:14:18]
say this is my first

[10:14:16 - 10:14:19]
conversation so this is the output I'm

[10:14:18 - 10:14:21]
getting you can see see the first

[10:14:19 - 10:14:25]
Cricket World Cup own by the India in

[10:14:21 - 10:14:28]
2000 uh sorry in uh 1983 okay now here I

[10:14:25 - 10:14:31]
will give another let's say uh prompt

[10:14:28 - 10:14:33]
how much is 5 5 + 5 see this is the

[10:14:31 - 10:14:35]
irrelevant question I'm asking now this

[10:14:33 - 10:14:38]
5 + 5 is equal to 10 now again I'm

[10:14:35 - 10:14:41]
asking who was the captain of the

[10:14:38 - 10:14:43]
winning team now it will refer my this

[10:14:41 - 10:14:45]
this actually prompt okay this context

[10:14:43 - 10:14:47]
now see the captain of the winning team

[10:14:45 - 10:14:50]
in India was Kil Dev do you have any

[10:14:47 - 10:14:51]
other question see amazingly it has

[10:14:50 - 10:14:53]
remembered my previous previous let's

[10:14:51 - 10:14:55]
say conversation okay that's how also

[10:14:53 - 10:14:56]
chgb is working I think the same example

[10:14:55 - 10:14:58]
I have given you you can also ask this

[10:14:56 - 10:15:00]
question like uh this add number code

[10:14:58 - 10:15:03]
question you will also see the same

[10:15:00 - 10:15:06]
output okay now if I show you the uh my

[10:15:03 - 10:15:09]
buffer memory right now so this was my

[10:15:06 - 10:15:11]
input then this was my like uh model

[10:15:09 - 10:15:13]
output again I asked this question again

[10:15:11 - 10:15:14]
this was the output again I asked this

[10:15:13 - 10:15:16]
question this is the output okay that's

[10:15:14 - 10:15:18]
how actually you can say five to 10

[10:15:16 - 10:15:19]
conversation here okay five to 10

[10:15:18 - 10:15:21]
conversation here after that it will

[10:15:19 - 10:15:23]
remove everything okay now you can also

[10:15:21 - 10:15:25]
set the window size like how many

[10:15:23 - 10:15:27]
conversation you want to save you also

[10:15:25 - 10:15:27]
have one parameter to set for this you

[10:15:27 - 10:15:29]
have to use something called

[10:15:27 - 10:15:32]
conversation buffer memory window sorry

[10:15:29 - 10:15:34]
conversation buffer window memory now

[10:15:32 - 10:15:35]
just try to define the memory inside

[10:15:34 - 10:15:36]
that just mention this parameter K is

[10:15:35 - 10:15:38]
equal to one that means it will only

[10:15:36 - 10:15:41]
remember one conversation okay now just

[10:15:38 - 10:15:43]
try to uh refine this conversation chain

[10:15:41 - 10:15:44]
inside that mention your llm as well as

[10:15:43 - 10:15:46]
the memory now if I again do the

[10:15:44 - 10:15:49]
conversation who won the first Cricket

[10:15:46 - 10:15:51]
World Cup now I'll again Ask how how

[10:15:49 - 10:15:53]
much is 5 + 5 now it is giving me the

[10:15:51 - 10:15:55]
output now again if I ask who was the

[10:15:53 - 10:15:57]
captain of the winning team now see it

[10:15:55 - 10:15:59]
is telling I don't have an information

[10:15:57 - 10:16:00]
context answer this question okay

[10:15:59 - 10:16:02]
because I have only given K is equal to

[10:16:00 - 10:16:04]
one that means it is only saving my one

[10:16:02 - 10:16:07]
information okay now if I give there's a

[10:16:04 - 10:16:09]
k is equal to three now it will remember

[10:16:07 - 10:16:11]
my three previous three conversation let

[10:16:09 - 10:16:13]
me show you now again if I ask this

[10:16:11 - 10:16:15]
question who was the captain of winning

[10:16:13 - 10:16:18]
team now see guys it is giving me the

[10:16:15 - 10:16:19]
output okay now if I show you the

[10:16:18 - 10:16:22]
conversation now you can see it is

[10:16:19 - 10:16:23]
remembering my previous context got it

[10:16:22 - 10:16:25]
so that's how whenever you are creating

[10:16:23 - 10:16:27]
any kinds of application guys try to use

[10:16:25 - 10:16:29]
this uh memory okay memory inside your

[10:16:27 - 10:16:31]
application this will make your

[10:16:29 - 10:16:32]
application very powerful and now I

[10:16:31 - 10:16:35]
think you are getting the logic behind

[10:16:32 - 10:16:36]
chat GPT how chat GPT is working it's

[10:16:35 - 10:16:38]
just a application guys always try to

[10:16:36 - 10:16:40]
remember chat GPT is an application

[10:16:38 - 10:16:41]
inside that they're using large language

[10:16:40 - 10:16:43]
model which is nothing but GPT series

[10:16:41 - 10:16:45]
okay and whatever functionality they

[10:16:43 - 10:16:47]
have created this memory functionality

[10:16:45 - 10:16:49]
then chain functionality prompt template

[10:16:47 - 10:16:51]
functionality they're using these kinds

[10:16:49 - 10:16:52]
of framework langen framework or Lama

[10:16:51 - 10:16:53]
index framework there is another

[10:16:52 - 10:16:54]
framework called Lama Index this is the

[10:16:53 - 10:16:57]
alternative framework of langen we'll be

[10:16:54 - 10:16:58]
also discussing this part as well fine

[10:16:57 - 10:17:00]
okay great now in the next video we'll

[10:16:58 - 10:17:02]
be learning about documents loader let's

[10:17:00 - 10:17:04]
say uh whenever you want to build any

[10:17:02 - 10:17:05]
kinds of rag based application retrieval

[10:17:04 - 10:17:07]
augmented generation let's say you have

[10:17:05 - 10:17:08]
some custom documents and if you want to

[10:17:07 - 10:17:10]
load these documents and you want to

[10:17:08 - 10:17:12]
connect with your let's say uh large

[10:17:10 - 10:17:13]
language model that time you have to

[10:17:12 - 10:17:14]
load your documents okay whatever

[10:17:13 - 10:17:17]
documents you are having whether it's a

[10:17:14 - 10:17:19]
PDF documents documents documents or let

[10:17:17 - 10:17:21]
a THD documents even you can also load

[10:17:19 - 10:17:23]
the website also just on any kinds of

[10:17:21 - 10:17:25]
file format you can open any kinds of

[10:17:23 - 10:17:27]
website you can integrate here okay so L

[10:17:25 - 10:17:29]
chain is very powerful guys you'll be

[10:17:27 - 10:17:30]
loving a lot trust me guys so in the

[10:17:29 - 10:17:32]
next video we'll be learning how we can

[10:17:30 - 10:17:33]
load the documents then after learning

[10:17:32 - 10:17:34]
this Lang chain we'll be also

[10:17:33 - 10:17:35]
implementing different different

[10:17:34 - 10:17:37]
projects so that this concept would be

[10:17:35 - 10:17:38]
clear how we can load our custom

[10:17:37 - 10:17:40]
documents how we can create a rag based

[10:17:38 - 10:17:41]
application okay how we can create a

[10:17:40 - 10:17:43]
chatboard different different things

[10:17:41 - 10:17:45]
we'll be learning so if you go to the

[10:17:43 - 10:17:46]
langen documentation you will see we can

[10:17:45 - 10:17:48]
also load different different documents

[10:17:46 - 10:17:50]
with the help of langen so you can load

[10:17:48 - 10:17:53]
let's say custom documents let's say any

[10:17:50 - 10:17:55]
any kinds of file format CSV then file

[10:17:53 - 10:17:58]
directory HTML Json markdown okay

[10:17:55 - 10:17:59]
Microsoft Office PDF Tex 3 okay any

[10:17:58 - 10:18:01]
kinds of documents you can load with the

[10:17:59 - 10:18:03]
help of this Lang chin even you can also

[10:18:01 - 10:18:04]
connect different different let's say

[10:18:03 - 10:18:07]
platform you can also connect slack you

[10:18:04 - 10:18:08]
can also connect let's say uh Discord

[10:18:07 - 10:18:10]
and from there also you can extract the

[10:18:08 - 10:18:11]
data it's like very powerful guys you

[10:18:10 - 10:18:13]
can go through the documentation you

[10:18:11 - 10:18:14]
will get each and every IDE even they

[10:18:13 - 10:18:16]
have also given the cod in it okay how

[10:18:14 - 10:18:17]
we can let's say connect uh with

[10:18:16 - 10:18:18]
different different let's say document

[10:18:17 - 10:18:21]
format and how we can load the documents

[10:18:18 - 10:18:23]
fine see always try to remember whatever

[10:18:21 - 10:18:25]
let's say data we are loading inside

[10:18:23 - 10:18:27]
langen it would be considered as a

[10:18:25 - 10:18:29]
document let me show you one example so

[10:18:27 - 10:18:31]
here let's say I want to load one PDF uh

[10:18:29 - 10:18:32]
documents let's say PDF I want to load

[10:18:31 - 10:18:35]
let's say I'm having one PDF let me show

[10:18:32 - 10:18:37]
you so this is my resarch paper guys I

[10:18:35 - 10:18:39]
so this is my research paper guys I

[10:18:37 - 10:18:41]
published uh some years back you can see

[10:18:39 - 10:18:43]
I'm the author so this is the author

[10:18:41 - 10:18:45]
okay I'm the author now you can see this

[10:18:43 - 10:18:47]
paper is about actually uh development

[10:18:45 - 10:18:50]
of multiple combined regression method

[10:18:47 - 10:18:53]
for the uh rainfall measurement okay and

[10:18:50 - 10:18:55]
this paper is already published uh in

[10:18:53 - 10:18:56]
the research gate let me show you if you

[10:18:55 - 10:18:58]
go to my LinkedIn profile this is my

[10:18:56 - 10:19:00]
LinkedIn profile you can connect me on

[10:18:58 - 10:19:01]
LinkedIn guys you can follow me so if

[10:19:00 - 10:19:03]
you have any question you can ask me

[10:19:01 - 10:19:07]
there I'll try to reply now see if I

[10:19:03 - 10:19:08]
show you uh this particular publication

[10:19:07 - 10:19:10]
so see this is this is what I've already

[10:19:08 - 10:19:12]
added now if I open this publication see

[10:19:10 - 10:19:14]
this is the publication and this is in

[10:19:12 - 10:19:16]
research gate okay even if you open the

[10:19:14 - 10:19:18]
Google Scholar also you will get it

[10:19:16 - 10:19:19]
there so this PDF actually I have downlo

[10:19:18 - 10:19:21]
downloed this paper PDF I have

[10:19:19 - 10:19:23]
downloaded now what I will do I'll just

[10:19:21 - 10:19:25]
try to load the documents okay whatever

[10:19:23 - 10:19:27]
let's information I'm having in this

[10:19:25 - 10:19:29]
let's say uh PDF I want to extract these

[10:19:27 - 10:19:30]
are the information for this I'll be

[10:19:29 - 10:19:32]
using langen so let me show you first of

[10:19:30 - 10:19:34]
all I need to install one package called

[10:19:32 - 10:19:38]
P

[10:19:34 - 10:19:41]
PDF now let me upload that PDF here so

[10:19:38 - 10:19:44]
my paper I'll upload it here now see it

[10:19:41 - 10:19:47]
is getting uploaded you can use any

[10:19:44 - 10:19:50]
kinds of documents guys docs dxt csb

[10:19:47 - 10:19:51]
just on anything and again visit the

[10:19:50 - 10:19:53]
documentation you will get all the codes

[10:19:51 - 10:19:55]
let's say you want to use Jon so this

[10:19:53 - 10:19:57]
the Json okay Json loader you have to

[10:19:55 - 10:19:59]
use let's say you want to load csb you

[10:19:57 - 10:20:00]
have to use CSV loader for this okay now

[10:19:59 - 10:20:02]
I'll be loading something called PDF

[10:20:00 - 10:20:04]
that's why I'll be using PDF loader okay

[10:20:02 - 10:20:06]
now see this is updated now I'm

[10:20:04 - 10:20:08]
importing this PDF loader from Lang you

[10:20:06 - 10:20:09]
can see document loader PDF loader now

[10:20:08 - 10:20:12]
here you have to give the location of

[10:20:09 - 10:20:15]
the file let's say this is my

[10:20:12 - 10:20:16]
location okay now you have to call load

[10:20:15 - 10:20:17]
loaded. load now see it will

[10:20:16 - 10:20:20]
automatically extract all the

[10:20:17 - 10:20:22]
information and this uh data would be

[10:20:20 - 10:20:25]
considered as a document let me show

[10:20:22 - 10:20:28]
you always try to remember inside Lang

[10:20:25 - 10:20:30]
chain inside geni all the data would be

[10:20:28 - 10:20:32]
considered as a

[10:20:30 - 10:20:34]
documents okay that's why I think you

[10:20:32 - 10:20:35]
remember in the vector database session

[10:20:34 - 10:20:37]
I was talking about documents okay

[10:20:35 - 10:20:39]
chunking documents these are the thing

[10:20:37 - 10:20:41]
okay now I think you got it now see it

[10:20:39 - 10:20:43]
has extracted all the pages now see this

[10:20:41 - 10:20:45]
is considering as a document this is the

[10:20:43 - 10:20:48]
type of documents right now and all the

[10:20:45 - 10:20:51]
information present inside my paper

[10:20:48 - 10:20:53]
it now we can use this data to implement

[10:20:51 - 10:20:55]
any kinds of rag based application that

[10:20:53 - 10:20:56]
means with help of vector database I can

[10:20:55 - 10:20:58]
store these are the data with help of

[10:20:56 - 10:21:00]
embeddings and I can connect my large

[10:20:58 - 10:21:02]
language model and I can ask some

[10:21:00 - 10:21:04]
information there okay don't need to

[10:21:02 - 10:21:05]
worry I'll be explaining this rag

[10:21:04 - 10:21:07]
concept and all okay why rag is

[10:21:05 - 10:21:08]
important why we have to create the rag

[10:21:07 - 10:21:10]
even we'll be also learning about fine

[10:21:08 - 10:21:11]
tuning okay how we can let's say take

[10:21:10 - 10:21:13]
our custom data and we can perform the

[10:21:11 - 10:21:17]
fine tuning as of now we have learned

[10:21:13 - 10:21:18]
the fundamentals of langin and I think I

[10:21:17 - 10:21:20]
covered almost everything about the L

[10:21:18 - 10:21:22]
chin whatever things you need to work

[10:21:20 - 10:21:24]
with the Lang chin but I will show you

[10:21:22 - 10:21:26]
some more advanced concept of the Lang

[10:21:24 - 10:21:28]
chin this will also help you okay so so

[10:21:26 - 10:21:29]
far I think we have covered so many

[10:21:28 - 10:21:31]
things inside Lang chain we have uh

[10:21:29 - 10:21:33]
learned the entire fundamental concept

[10:21:31 - 10:21:36]
of the Lang chain so one thing I wanted

[10:21:33 - 10:21:39]
to tell you see Lang chain also can work

[10:21:36 - 10:21:40]
with this one your pandas data frame

[10:21:39 - 10:21:43]
that means directly pandas data frame

[10:21:40 - 10:21:45]
you can pass to the large language model

[10:21:43 - 10:21:47]
and you can ask some question there okay

[10:21:45 - 10:21:49]
it is also possible for this uh you can

[10:21:47 - 10:21:50]
use your large language model any kinds

[10:21:49 - 10:21:51]
of large language model and with the

[10:21:50 - 10:21:53]
help of langin framework you can perform

[10:21:51 - 10:21:54]
these kinds of operation let me show you

[10:21:53 - 10:21:56]
so first of all I have to install some

[10:21:54 - 10:21:58]
of the library so here you can see I'm

[10:21:56 - 10:21:59]
installing langin and langin

[10:21:58 - 10:22:02]
experimental why langin experimental

[10:21:59 - 10:22:03]
because this Panda's data frame actually

[10:22:02 - 10:22:05]
agents will be using now this is

[10:22:03 - 10:22:06]
available inside Lang and experimental

[10:22:05 - 10:22:09]
okay that's why I have to import all of

[10:22:06 - 10:22:10]
them so let me import and I'm going to

[10:22:09 - 10:22:13]
use open large language model that's why

[10:22:10 - 10:22:15]
I'm using open here now I'm going to

[10:22:13 - 10:22:17]
import some of the required liabilities

[10:22:15 - 10:22:19]
I need now you can see from Lang chain

[10:22:17 - 10:22:21]
experimental agents A toolkits I'm

[10:22:19 - 10:22:22]
importing create pandas data frame

[10:22:21 - 10:22:24]
agents okay you can go to the

[10:22:22 - 10:22:26]
documentation you can see pandas data

[10:22:24 - 10:22:27]
frame documentation inside langin and

[10:22:26 - 10:22:30]
they are also loading in that way okay

[10:22:27 - 10:22:31]
and they are giving u a data set okay

[10:22:30 - 10:22:33]
any kinds of data set they're loading

[10:22:31 - 10:22:36]
with the help of pandas and they are

[10:22:33 - 10:22:37]
performing lots of operation okay see

[10:22:36 - 10:22:39]
you can use different different large

[10:22:37 - 10:22:41]
language model and you can perform chat

[10:22:39 - 10:22:43]
operation okay with this uh data frame

[10:22:41 - 10:22:45]
let me show you so let me import the

[10:22:43 - 10:22:49]
library first of all I'll import the

[10:22:45 - 10:22:50]
pandas as well I'll set my open API key

[10:22:49 - 10:22:53]
then this is the data I want to load

[10:22:50 - 10:22:55]
let's say this is the csb data Titanic

[10:22:53 - 10:22:57]
csb data it is available in this

[10:22:55 - 10:22:59]
GitHub if I show you the live GitHub

[10:22:57 - 10:23:01]
link so this so this is the data guys it

[10:22:59 - 10:23:04]
is already available so let me first of

[10:23:01 - 10:23:06]
all load this data with the help of

[10:23:04 - 10:23:08]
pandas so here is the data guys I think

[10:23:06 - 10:23:10]
you already familiar with this Titanic

[10:23:08 - 10:23:12]
data now first of all we'll be

[10:23:10 - 10:23:15]
performing this chat operation with the

[10:23:12 - 10:23:17]
single data frame so I'll initialize my

[10:23:15 - 10:23:18]
large language model now create a agents

[10:23:17 - 10:23:20]
to create agents just call this create

[10:23:18 - 10:23:23]
fond as data frame agents this class

[10:23:20 - 10:23:24]
inside that give the llm data frame

[10:23:23 - 10:23:26]
varos is equal to two means it will show

[10:23:24 - 10:23:28]
you the entire let's say execution

[10:23:26 - 10:23:29]
details and here you have to give

[10:23:28 - 10:23:31]
another parameter called allow dangerous

[10:23:29 - 10:23:33]
code is equal to true now I'll create

[10:23:31 - 10:23:35]
the agents now here I can ask the

[10:23:33 - 10:23:38]
question right now I'll ask how many

[10:23:35 - 10:23:40]
rows are there in the let's say data

[10:23:38 - 10:23:42]
frame now see it will count and it will

[10:23:40 - 10:23:45]
automatically give me the answer see

[10:23:42 - 10:23:47]
around uh uh 891 okay rows are available

[10:23:45 - 10:23:51]
I will give another question how many

[10:23:47 - 10:23:53]
people have more than 23 Ed see

[10:23:51 - 10:23:55]
amazingly your model will try to um go

[10:23:53 - 10:23:58]
through that data frame and it will give

[10:23:55 - 10:24:00]
you the answer see for

[10:23:58 - 10:24:03]
468 now I can also work with multi dat

[10:24:00 - 10:24:05]
Fame so for this what I can do I can

[10:24:03 - 10:24:08]
copy this data uh in another variable

[10:24:05 - 10:24:10]
called df1 see I'm copying this DF only

[10:24:08 - 10:24:14]
and I'm creating another df1 here this

[10:24:10 - 10:24:16]
is the data now what I will do I'll just

[10:24:14 - 10:24:18]
fill the uh nonone value okay which is

[10:24:16 - 10:24:20]
present inside H because H is having

[10:24:18 - 10:24:22]
some non value I'm just fing now again

[10:24:20 - 10:24:23]
I'm creating the agenty you can see now

[10:24:22 - 10:24:27]
here you can see I'm giving multi data

[10:24:23 - 10:24:29]
frame DF and df1 okay now let me create

[10:24:27 - 10:24:32]
that agents now I'll ask one question

[10:24:29 - 10:24:35]
how many rows in the ages columns are

[10:24:32 - 10:24:37]
different okay now let me show

[10:24:35 - 10:24:41]
you because I already filled the

[10:24:37 - 10:24:43]
information now around 177 rows were

[10:24:41 - 10:24:45]
have the N value now you can see rows

[10:24:43 - 10:24:47]
have different values in the agge column

[10:24:45 - 10:24:48]
I think you got it now I'll create

[10:24:47 - 10:24:51]
another data frame called df2

[10:24:48 - 10:24:53]
and now I will just multiply two with

[10:24:51 - 10:24:56]
the age whatever age I'm having I'm just

[10:24:53 - 10:24:57]
multiplying two now this is the results

[10:24:56 - 10:24:59]
now I'll create another agents and it

[10:24:57 - 10:25:01]
will have three different data frame

[10:24:59 - 10:25:04]
okay now let me create the agents now we

[10:25:01 - 10:25:05]
ask one question are uh the three of The

[10:25:04 - 10:25:09]
Columns same in the all the data frames

[10:25:05 - 10:25:10]
are not definitely it should be same for

[10:25:09 - 10:25:12]
all the data frame because I because I

[10:25:10 - 10:25:13]
have just copy pasted the same data

[10:25:12 - 10:25:15]
frame again and again three times so so

[10:25:13 - 10:25:17]
here all the column name should be same

[10:25:15 - 10:25:19]
if I show you the output C uh so see

[10:25:17 - 10:25:21]
guys I'm getting the output agent stop

[10:25:19 - 10:25:22]
due to the iteration limit or time limit

[10:25:21 - 10:25:26]
because I'm executing multiple time now

[10:25:22 - 10:25:28]
that's why I just uh uh use the limit

[10:25:26 - 10:25:29]
okay that means my limit has been done

[10:25:28 - 10:25:31]
uh so what you can do you can restart

[10:25:29 - 10:25:33]
the run time again you can execute the

[10:25:31 - 10:25:35]
entire code you will see that all the

[10:25:33 - 10:25:36]
column should be same okay in three

[10:25:35 - 10:25:38]
different data frame okay you'll get

[10:25:36 - 10:25:39]
this kinds of output now you can ask any

[10:25:38 - 10:25:41]
kinds of question okay about this data

[10:25:39 - 10:25:43]
frame so this is called actually multi

[10:25:41 - 10:25:45]
data frame agents inside Lang chain and

[10:25:43 - 10:25:46]
this like again very powerful concept if

[10:25:45 - 10:25:47]
you want to work with the data frame and

[10:25:46 - 10:25:49]
all going forward we'll be also

[10:25:47 - 10:25:51]
implementing some projects with that

[10:25:49 - 10:25:53]
okay this concept will help you a lot so

[10:25:51 - 10:25:55]
as of now I think I showed you lots of

[10:25:53 - 10:25:57]
example lots of demo of the langen like

[10:25:55 - 10:25:59]
what are the things we can perform even

[10:25:57 - 10:26:01]
I also told you we can also let's say

[10:25:59 - 10:26:02]
access different different uh open

[10:26:01 - 10:26:04]
source large language model from the

[10:26:02 - 10:26:06]
hugging F itself okay so this would be

[10:26:04 - 10:26:08]
the dedicated video about this Lang

[10:26:06 - 10:26:10]
chain integration with the hugging F so

[10:26:08 - 10:26:12]
there I will see that how we can access

[10:26:10 - 10:26:13]
different different model uh with two

[10:26:12 - 10:26:14]
kinds of method like one method I will

[10:26:13 - 10:26:17]
show you how we can access through the

[10:26:14 - 10:26:19]
API request other method I will tell you

[10:26:17 - 10:26:20]
how we can download the the model okay

[10:26:19 - 10:26:22]
uh in our Google collab and how we can

[10:26:20 - 10:26:24]
use this particular model okay this is

[10:26:22 - 10:26:26]
the idea so first of all let me install

[10:26:24 - 10:26:27]
some required package so you can see I'm

[10:26:26 - 10:26:29]
installing Lang chain Lang chain

[10:26:27 - 10:26:31]
Community hugging face up Transformer

[10:26:29 - 10:26:33]
why Transformer because I want to use

[10:26:31 - 10:26:33]
hugging face platform I want to download

[10:26:33 - 10:26:35]
the hugging face model that's why

[10:26:33 - 10:26:37]
Transformer is required I think so I

[10:26:35 - 10:26:39]
think I already taught you about the

[10:26:37 - 10:26:40]
hugging face like how to use hugging

[10:26:39 - 10:26:42]
face and what is Transformer Library

[10:26:40 - 10:26:43]
everything I already discussed and these

[10:26:42 - 10:26:45]
are some actually dependency package you

[10:26:43 - 10:26:47]
need to also install with the hugging

[10:26:45 - 10:26:50]
face that means your Transformer now let

[10:26:47 - 10:26:50]
me install all the one by

[10:26:51 - 10:26:54]
one so guys as you can see my

[10:26:53 - 10:26:56]
installation is completed now let's

[10:26:54 - 10:26:57]
import some of the library you can see

[10:26:56 - 10:27:00]
I'm importing prom template hugging face

[10:26:57 - 10:27:01]
up llm chain from the Lang chain itself

[10:27:00 - 10:27:02]
now first thing what you have to do you

[10:27:01 - 10:27:03]
have to setting up the environment for

[10:27:02 - 10:27:05]
this you have to set the hugging face

[10:27:03 - 10:27:07]
API token and how to get the hug API

[10:27:05 - 10:27:10]
token I think I already explained go to

[10:27:07 - 10:27:12]
the settings and left hand side you will

[10:27:10 - 10:27:13]
see access token option so you can

[10:27:12 - 10:27:15]
create a new token here I already showed

[10:27:13 - 10:27:16]
you how to create a token okay so I'm

[10:27:15 - 10:27:19]
not going to show you again so now let

[10:27:16 - 10:27:21]
me set my token

[10:27:19 - 10:27:22]
now we'll be learning the first approach

[10:27:21 - 10:27:24]
like access the hosted model on hugging

[10:27:22 - 10:27:26]
face through API request okay now see

[10:27:24 - 10:27:28]
here we'll be accessing one text to text

[10:27:26 - 10:27:29]
generation model so first of all let's

[10:27:28 - 10:27:31]
create a prom template so here's the

[10:27:29 - 10:27:33]
prom template I have prepared what is

[10:27:31 - 10:27:34]
the good name for a company that makes

[10:27:33 - 10:27:37]
product so product should be my input

[10:27:34 - 10:27:38]
here now here I'm creating the LM chain

[10:27:37 - 10:27:40]
I'm giving my large language model and

[10:27:38 - 10:27:42]
you can see I'm using Hing face up and

[10:27:40 - 10:27:44]
I'm giving this model ID that means I

[10:27:42 - 10:27:47]
will be using this model so this is the

[10:27:44 - 10:27:49]
flan T5 model uh this is from Google

[10:27:47 - 10:27:51]
actually so we'll be using this model

[10:27:49 - 10:27:52]
here so let me load this model and here

[10:27:51 - 10:27:54]
is the model arguments that means

[10:27:52 - 10:27:56]
temperature and max length parameter and

[10:27:54 - 10:27:57]
here I'm giving the prompt okay the prom

[10:27:56 - 10:27:59]
template I have created now let me

[10:27:57 - 10:28:00]
create the chain object now here you can

[10:27:59 - 10:28:02]
give the output let's say I give

[10:28:00 - 10:28:04]
colorful socks let's see whether it is

[10:28:02 - 10:28:06]
able to give the response or not see it

[10:28:04 - 10:28:08]
has given me sock Mania okay this should

[10:28:06 - 10:28:10]
be the name now let me show you another

[10:28:08 - 10:28:11]
prompt you can see I have written

[10:28:10 - 10:28:12]
another prompt can you tell me about

[10:28:11 - 10:28:14]
famous footballer so it will take the

[10:28:12 - 10:28:17]
famous footballer name and it will um

[10:28:14 - 10:28:20]
tell you about him so let me show you so

[10:28:17 - 10:28:21]
again I'll create the chin and see the

[10:28:20 - 10:28:23]
same code actually I'm using now if I

[10:28:21 - 10:28:23]
give

[10:28:24 - 10:28:28]
Messi now you can see guys it is giving

[10:28:26 - 10:28:30]
me the response Messi is a footballer

[10:28:28 - 10:28:32]
who plays for Argentina great now you

[10:28:30 - 10:28:34]
can give another prompt let's say uh can

[10:28:32 - 10:28:36]
you tell me food items for the cuisin

[10:28:34 - 10:28:38]
restaurant so kuin should be the input

[10:28:36 - 10:28:41]
let's create and I'm using the same code

[10:28:38 - 10:28:44]
snippit now let me initialize the chain

[10:28:41 - 10:28:47]
and let me give the input let's say

[10:28:44 - 10:28:48]
Indian now see it is giving me uh

[10:28:47 - 10:28:51]
vegetable

[10:28:48 - 10:28:52]
okay can you tell me the food items yeah

[10:28:51 - 10:28:55]
vegetable is fine now if I again execute

[10:28:52 - 10:28:56]
let's see okay vegetable it is giving

[10:28:55 - 10:28:58]
because I told you now this model is not

[10:28:56 - 10:29:00]
good now guys let's see how we can use

[10:28:58 - 10:29:01]
any other model see again I have

[10:29:00 - 10:29:03]
prepared one prom template and again I'm

[10:29:01 - 10:29:05]
using the same thing can you please tell

[10:29:03 - 10:29:08]
me about famous footballer now instead

[10:29:05 - 10:29:09]
of this T5 model I'm using Falcon 7B so

[10:29:08 - 10:29:11]
this is one of the large language model

[10:29:09 - 10:29:12]
it is already available in the hugging P

[10:29:11 - 10:29:14]
okay you can see so this is the

[10:29:12 - 10:29:15]
organization they publish this Falcon

[10:29:14 - 10:29:18]
and Falcon is having different different

[10:29:15 - 10:29:19]
variant Falcon 7B 13B okay that's how is

[10:29:18 - 10:29:21]
having different different variant and

[10:29:19 - 10:29:22]
this is one of the like great uh large

[10:29:21 - 10:29:25]
language model you can use now let me

[10:29:22 - 10:29:27]
show you one demo now let's load it and

[10:29:25 - 10:29:31]
see I'm using the same

[10:29:27 - 10:29:32]
codit and I'm sending the request see

[10:29:31 - 10:29:35]
this model actually I'm not downloading

[10:29:32 - 10:29:37]
in my machine so it is using the API to

[10:29:35 - 10:29:38]
access the model and it is giving me the

[10:29:37 - 10:29:40]
response and that response actually I

[10:29:38 - 10:29:42]
can see okay now see this is the

[10:29:40 - 10:29:43]
response I got and it's like very detail

[10:29:42 - 10:29:45]
response I got okay than your previous

[10:29:43 - 10:29:46]
response now let's see the approach too

[10:29:45 - 10:29:48]
like how we can download this model

[10:29:46 - 10:29:50]
locally and how we can create a pipeline

[10:29:48 - 10:29:51]
that means that hugging face pipeline I

[10:29:50 - 10:29:53]
think remember right for this let's

[10:29:51 - 10:29:54]
import hugging pH pipeline from Lang

[10:29:53 - 10:29:56]
chin then I'm also importing some

[10:29:54 - 10:29:58]
additional Library like Auto tokenizer

[10:29:56 - 10:29:59]
auto auto model for casual LM then

[10:29:58 - 10:30:00]
pipeline okay these are the thing I'm

[10:29:59 - 10:30:02]
importing because I think you remember

[10:30:00 - 10:30:05]
how to create the pipeline so let me

[10:30:02 - 10:30:07]
import them now see I'm using this flant

[10:30:05 - 10:30:09]
T5 model again so let's initialize the

[10:30:07 - 10:30:10]
model and first of all I have to create

[10:30:09 - 10:30:12]
the tokenizer if I want to download the

[10:30:10 - 10:30:14]
model I have to create the tokenizer I

[10:30:12 - 10:30:15]
think you know that right tokenizer will

[10:30:14 - 10:30:18]
pre-process your input that means it

[10:30:15 - 10:30:19]
will process input it will create them

[10:30:18 - 10:30:22]
Bings and then it will pass to the model

[10:30:19 - 10:30:23]
now and now here I'm going to initialize

[10:30:22 - 10:30:26]
my model you can see I'm giving the

[10:30:23 - 10:30:27]
model ID then device map is equal Auto

[10:30:26 - 10:30:29]
that means it will load the model inside

[10:30:27 - 10:30:32]
my

[10:30:29 - 10:30:33]
GPU and make sure whenever you are like

[10:30:32 - 10:30:35]
downloading the model locally you are

[10:30:33 - 10:30:36]
using GPU based machine okay good

[10:30:35 - 10:30:39]
configuration machine otherwise

[10:30:36 - 10:30:40]
execution time would be very like slow

[10:30:39 - 10:30:42]
okay but if you're accessing through API

[10:30:40 - 10:30:44]
you don't need a GPU based machine now

[10:30:42 - 10:30:46]
let's create a pipeline you can see it's

[10:30:44 - 10:30:47]
a text text to text generation model so

[10:30:46 - 10:30:49]
here I've given text to text generation

[10:30:47 - 10:30:50]
model tokenizer and max length now let

[10:30:49 - 10:30:53]
me create the

[10:30:50 - 10:30:56]
pipeline now I'm going to initialize my

[10:30:53 - 10:30:58]
llm rapper so I think remember we called

[10:30:56 - 10:30:59]
this hugging face pipeline from langin

[10:30:58 - 10:31:02]
now so here you can see I have

[10:30:59 - 10:31:03]
initialized my llm wrapper and pipeline

[10:31:02 - 10:31:06]
the pipeline object I'm getting I'm

[10:31:03 - 10:31:08]
passing inside this H pipeline now this

[10:31:06 - 10:31:10]
is going to be my Raper now again I'm

[10:31:08 - 10:31:11]
going to create the prom template and

[10:31:10 - 10:31:14]
this is the example I have taken the

[10:31:11 - 10:31:17]
same uh like a company okay company

[10:31:14 - 10:31:19]
example now let me pass to the LM chain

[10:31:17 - 10:31:21]
and as well as my prompt see I'm passing

[10:31:19 - 10:31:23]
my large language model as well as my

[10:31:21 - 10:31:25]
prompt and now see the model actually

[10:31:23 - 10:31:28]
I'm passing the this model actually have

[10:31:25 - 10:31:30]
downloaded okay llm local local LM not

[10:31:28 - 10:31:33]
the API one okay so both way you can use

[10:31:30 - 10:31:37]
this hugging face now let me show you

[10:31:33 - 10:31:38]
the results see socks Mania now let me

[10:31:37 - 10:31:41]
prepare another prompt can you tell me

[10:31:38 - 10:31:43]
about famous footballer now let me

[10:31:41 - 10:31:45]
initialize the chain now let me ask

[10:31:43 - 10:31:45]
about

[10:31:45 - 10:31:50]
Messi see Messi is a footballer who

[10:31:47 - 10:31:53]
place for the Argentina okay so that's

[10:31:50 - 10:31:54]
why guys we can access uh hugging fish

[10:31:53 - 10:31:56]
model open source langage model with the

[10:31:54 - 10:31:58]
help of langen and going forward we'll

[10:31:56 - 10:31:59]
be using this concept guys and with this

[10:31:58 - 10:32:01]
concept we'll be implementing so many

[10:31:59 - 10:32:04]
application so this project we'll be

[10:32:01 - 10:32:05]
implementing uh with the help of

[10:32:04 - 10:32:07]
whatever things we have learned so far

[10:32:05 - 10:32:09]
let's say Lang chain large language

[10:32:07 - 10:32:12]
model Vector database okay even we'll be

[10:32:09 - 10:32:14]
also implementing one front end uh

[10:32:12 - 10:32:17]
application of this project that means

[10:32:14 - 10:32:19]
uh user will get one user interface and

[10:32:17 - 10:32:21]
their uh us user will upload the data

[10:32:19 - 10:32:23]
and they will get the results okay so

[10:32:21 - 10:32:24]
these kinds of things actually will be

[10:32:23 - 10:32:26]
also implementing that means I'm going

[10:32:24 - 10:32:27]
to show you the complete project

[10:32:26 - 10:32:30]
structure here that means we'll be doing

[10:32:27 - 10:32:32]
modular coding here but before that I'll

[10:32:30 - 10:32:34]
show you the notebook experiment uh like

[10:32:32 - 10:32:35]
how uh we can implement this project

[10:32:34 - 10:32:37]
through the jupyter notebook then I'll

[10:32:35 - 10:32:40]
try to convert this jupyter notebook to

[10:32:37 - 10:32:42]
the end to end manner okay so uh I think

[10:32:40 - 10:32:43]
you saw the name interview question

[10:32:42 - 10:32:45]
Creator I think you are already getting

[10:32:43 - 10:32:47]
what is the project about interview

[10:32:45 - 10:32:48]
question Creator means let's say you are

[10:32:47 - 10:32:50]
having one PDF documents or let's say

[10:32:48 - 10:32:53]
any kinds of documents whether it's a

[10:32:50 - 10:32:55]
doc uh docs documents PDF documents TT

[10:32:53 - 10:32:57]
documents or whether it's a books okay

[10:32:55 - 10:33:00]
so what you have to do you just need to

[10:32:57 - 10:33:02]
upload that let's say PDF uh to this

[10:33:00 - 10:33:04]
application and this application will

[10:33:02 - 10:33:07]
automatically generate the questions

[10:33:04 - 10:33:09]
okay question as well as the answer okay

[10:33:07 - 10:33:11]
uh of the topic actually will be giving

[10:33:09 - 10:33:13]
let's say you have uploaded one python

[10:33:11 - 10:33:15]
PDF here so this application will

[10:33:13 - 10:33:18]
generate some python questions interview

[10:33:15 - 10:33:20]
questions uh as well as the answer okay

[10:33:18 - 10:33:22]
and that question and answer you can use

[10:33:20 - 10:33:23]
let's say for your candidate or let's

[10:33:22 - 10:33:24]
say you are a teacher you are a teacher

[10:33:23 - 10:33:27]
and you want to generate interview

[10:33:24 - 10:33:28]
questions or let's say uh exam questions

[10:33:27 - 10:33:30]
what you can do you can use this

[10:33:28 - 10:33:32]
application to generate these kinds of

[10:33:30 - 10:33:33]
question and answer so it would be very

[10:33:32 - 10:33:35]
easy for you to generate these kinds of

[10:33:33 - 10:33:37]
question otherwise you have to manually

[10:33:35 - 10:33:39]
find the questions manually let's say

[10:33:37 - 10:33:40]
prepare the answer so it will take time

[10:33:39 - 10:33:42]
but if you're creating these kinds of

[10:33:40 - 10:33:44]
application it will help you a lot okay

[10:33:42 - 10:33:46]
to automate your process again it seems

[10:33:44 - 10:33:47]
like a simple project but whenever you

[10:33:46 - 10:33:49]
will be implementing you will get the

[10:33:47 - 10:33:51]
compx City and this is like very

[10:33:49 - 10:33:53]
interesting project because uh this is

[10:33:51 - 10:33:55]
the first project I will be implementing

[10:33:53 - 10:33:57]
after learning Lin going forward will be

[10:33:55 - 10:33:58]
also implementing some Advanced projects

[10:33:57 - 10:34:00]
like we'll be implementing medical

[10:33:58 - 10:34:01]
chatboard source code analysis okay so

[10:34:00 - 10:34:03]
these are the thing we'll be also

[10:34:01 - 10:34:05]
implementing so instead of talking too

[10:34:03 - 10:34:07]
much guys let's start the implementation

[10:34:05 - 10:34:10]
but before that uh I will show you the

[10:34:07 - 10:34:12]
let's say the requirements actually I

[10:34:10 - 10:34:13]
need to implement this project and I'll

[10:34:12 - 10:34:15]
will also show you the project

[10:34:13 - 10:34:19]
architecture so guys to implement this

[10:34:15 - 10:34:19]
project uh I need some requ

[10:34:22 - 10:34:27]
requirements okay I need some

[10:34:24 - 10:34:30]
requirements so here we'll be using

[10:34:27 - 10:34:31]
langin to implement the entire let's say

[10:34:30 - 10:34:33]
uh

[10:34:31 - 10:34:34]
project and why langin I think you know

[10:34:33 - 10:34:37]
because langin having all the

[10:34:34 - 10:34:39]
functionality right let's say you want

[10:34:37 - 10:34:41]
to integrate Vector database you want to

[10:34:39 - 10:34:44]
integrate large language model okay

[10:34:41 - 10:34:45]
everything is available here so that's

[10:34:44 - 10:34:47]
why we'll be using the complete Lang

[10:34:45 - 10:34:50]
chain here and large language model wise

[10:34:47 - 10:34:52]
we'll be using open model open we'll be

[10:34:50 - 10:34:55]
using

[10:34:52 - 10:34:57]
GPT 3.5 okay this model actually will be

[10:34:55 - 10:34:58]
using going forward we'll be also

[10:34:57 - 10:34:59]
learning how we can use open source

[10:34:58 - 10:35:00]
starge language model with the help of

[10:34:59 - 10:35:03]
that I will also show you how we can

[10:35:00 - 10:35:06]
create the application now third I need

[10:35:03 - 10:35:09]
uh Vector

[10:35:06 - 10:35:13]
database Vector DB so here we'll be

[10:35:09 - 10:35:15]
using F okay so FS is another actually

[10:35:13 - 10:35:17]
Vector database I think I haven't

[10:35:15 - 10:35:19]
covered in my Vector database series uh

[10:35:17 - 10:35:21]
so that's why I thought let's also show

[10:35:19 - 10:35:23]
you this F in this video so that you

[10:35:21 - 10:35:25]
will be also learning about F so F has

[10:35:23 - 10:35:27]
implemented by Facebook Ai and this is

[10:35:25 - 10:35:30]
one of the vector database this is the

[10:35:27 - 10:35:33]
local Vector database actually local

[10:35:30 - 10:35:35]
Vector database so you have to set up

[10:35:33 - 10:35:37]
everything in local machine going

[10:35:35 - 10:35:40]
forward we'll be also using pine con we

[10:35:37 - 10:35:42]
okay no need to worry then to implement

[10:35:40 - 10:35:44]
the entire let's say front end part part

[10:35:42 - 10:35:45]
of our application that means we'll be

[10:35:44 - 10:35:48]
creating the user interface with the

[10:35:45 - 10:35:50]
help of fast API fast API I think you

[10:35:48 - 10:35:52]
know what is fast API fast API is a

[10:35:50 - 10:35:55]
python framework with the help of fast

[10:35:52 - 10:35:56]
API we can create a uh user interface

[10:35:55 - 10:36:00]
web application apart from first API we

[10:35:56 - 10:36:01]
are having let's stream lead flask Jango

[10:36:00 - 10:36:03]
okay Falcone so these are the thing you

[10:36:01 - 10:36:05]
can also use we'll be exploring one by

[10:36:03 - 10:36:07]
one all of them I think we saw the flask

[10:36:05 - 10:36:10]
previously I think remember flask I

[10:36:07 - 10:36:12]
think we I showed you we created some of

[10:36:10 - 10:36:15]
the application with the help of open uh

[10:36:12 - 10:36:16]
we'll be also using stream lit streamlit

[10:36:15 - 10:36:17]
is very easy if you're using a stream

[10:36:16 - 10:36:20]
lit you don't need to write it in kinds

[10:36:17 - 10:36:22]
of HTML and CSS code so guys yes as of

[10:36:20 - 10:36:24]
now these are the requirements uh are

[10:36:22 - 10:36:26]
needed uh if I need it later on I'll

[10:36:24 - 10:36:28]
tell you okay now let me show you the

[10:36:26 - 10:36:31]
project uh diagram okay the project

[10:36:28 - 10:36:34]
let's say structure uh that means the

[10:36:31 - 10:36:38]
high level architecture so here uh first

[10:36:34 - 10:36:40]
of all user will let me just draw it

[10:36:38 - 10:36:42]
here first of all user will upload one

[10:36:40 - 10:36:44]
PDF

[10:36:42 - 10:36:46]
documents okay let's say this the PDF

[10:36:44 - 10:36:49]
documents so what I have to do I have to

[10:36:46 - 10:36:49]
extract that data

[10:36:51 - 10:36:56]
extract docs so why I have written docs

[10:36:54 - 10:36:59]
because I think you already know if I

[10:36:56 - 10:37:01]
I'm using langin and if I'm let's say

[10:36:59 - 10:37:03]
extracting uh any kinds of data from any

[10:37:01 - 10:37:05]
kinds of PDF or any kinds of let's say

[10:37:03 - 10:37:07]
um I mean file format it would be

[10:37:05 - 10:37:09]
considered as a documents I think I

[10:37:07 - 10:37:11]
already covered multiple time like Lang

[10:37:09 - 10:37:13]
chain data loader even I also showed you

[10:37:11 - 10:37:14]
inside Vector database session so guys

[10:37:13 - 10:37:16]
uh Vector database session is very much

[10:37:14 - 10:37:18]
required here because inside Vector

[10:37:16 - 10:37:20]
database session explained each and

[10:37:18 - 10:37:22]
everything you need to know to implement

[10:37:20 - 10:37:24]
any kinds of project okay how to connect

[10:37:22 - 10:37:25]
llm what is documents what is Chun what

[10:37:24 - 10:37:27]
is Chun overlap everything I have

[10:37:25 - 10:37:29]
discussed there so please go ahead and

[10:37:27 - 10:37:31]
try to watch that uh let's say session

[10:37:29 - 10:37:32]
first of all then you'll be able to

[10:37:31 - 10:37:34]
understand okay what is happening here

[10:37:32 - 10:37:36]
because here I'm not going to uh explain

[10:37:34 - 10:37:38]
in detail everything we are implementing

[10:37:36 - 10:37:40]
the project only and we are using our

[10:37:38 - 10:37:43]
previous concept okay this is the idea

[10:37:40 - 10:37:45]
so make sure you uh complete that Vector

[10:37:43 - 10:37:47]
database series first of all fine so we

[10:37:45 - 10:37:49]
are uh we'll be extracting the document

[10:37:47 - 10:37:51]
from the PDF then we have to create a

[10:37:49 - 10:37:53]
chunks and what is Chunks I think I

[10:37:51 - 10:37:56]
already told you why chuning is required

[10:37:53 - 10:37:58]
because llm is having one kinds of input

[10:37:56 - 10:38:00]
limit okay so that's why actually we

[10:37:58 - 10:38:03]
have to create a

[10:38:00 - 10:38:07]
chunks okay chunks then what we'll be

[10:38:03 - 10:38:07]
doing uh we'll be using one embedding

[10:38:08 - 10:38:11]
model what is embedding model I think

[10:38:10 - 10:38:14]
you already know I already explain

[10:38:11 - 10:38:16]
inside my Vector database uh session

[10:38:14 - 10:38:18]
embedding model will help you to

[10:38:16 - 10:38:20]
generate the vector embedding okay

[10:38:18 - 10:38:21]
because I have to convert this chunks to

[10:38:20 - 10:38:23]
the vector embedding so this will give

[10:38:21 - 10:38:28]
me something called Vector

[10:38:23 - 10:38:31]
embedding okay uh

[10:38:28 - 10:38:31]
Vector

[10:38:31 - 10:38:37]
embedding okay embedding and with this

[10:38:34 - 10:38:39]
Vector embedding we'll be creating One

[10:38:37 - 10:38:43]
centic

[10:38:39 - 10:38:47]
S I already explain what is santic

[10:38:43 - 10:38:47]
s santic

[10:38:47 - 10:38:52]
search because uh I think you know the

[10:38:50 - 10:38:55]
power of vector DB it will give you one

[10:38:52 - 10:38:57]
CTIC s kinds of functionality now uh

[10:38:55 - 10:39:02]
what I have to do I have to store this

[10:38:57 - 10:39:05]
uh Vector to a vector

[10:39:02 - 10:39:08]
database Vector

[10:39:05 - 10:39:11]
database because if I want to perform

[10:39:08 - 10:39:13]
the centic source operation I have to uh

[10:39:11 - 10:39:16]
use the vector database okay I think you

[10:39:13 - 10:39:18]
already know now guys you can see my

[10:39:16 - 10:39:20]
knowledge base has been created so this

[10:39:18 - 10:39:23]
is called actually knowledge base right

[10:39:20 - 10:39:25]
now okay knowledge base because it is

[10:39:23 - 10:39:27]
having the entire information about my

[10:39:25 - 10:39:31]
data now I'll be connecting my large

[10:39:27 - 10:39:33]
language model here so let's say um this

[10:39:31 - 10:39:38]
is my large language

[10:39:33 - 10:39:41]
model um llm that means that GPT

[10:39:38 - 10:39:44]
3.5 okay so this large language model

[10:39:41 - 10:39:48]
I'll be connecting

[10:39:44 - 10:39:51]
here with my Vector database

[10:39:48 - 10:39:55]
okay and here I will set a

[10:39:51 - 10:39:57]
prompt um I'll just set a prompt here so

[10:39:55 - 10:39:59]
in inside this prompt actually I'll be

[10:39:57 - 10:40:01]
writing what kinds of let's say task it

[10:39:59 - 10:40:04]
has to perform so here I'll be writing

[10:40:01 - 10:40:07]
you are a uh expert uh uh interview

[10:40:04 - 10:40:08]
question Creator so what you have to do

[10:40:07 - 10:40:10]
whatever let's say data user will give

[10:40:08 - 10:40:12]
you you have to create a interview

[10:40:10 - 10:40:14]
questions okay or let's say 10 questions

[10:40:12 - 10:40:16]
20 questions you have to create it okay

[10:40:14 - 10:40:17]
this is the idea so this kinds of prompt

[10:40:16 - 10:40:19]
actually I'll pass to the

[10:40:17 - 10:40:22]
large language model so I think you

[10:40:19 - 10:40:24]
already know prompt is everything if I

[10:40:22 - 10:40:26]
if I'm using any kinds of llm right so

[10:40:24 - 10:40:28]
with the help of prompt we can uh

[10:40:26 - 10:40:30]
achieve our task this is the main idea

[10:40:28 - 10:40:32]
so this llm will go to the vector

[10:40:30 - 10:40:33]
database that time and because Vector

[10:40:32 - 10:40:36]
database having all the information

[10:40:33 - 10:40:38]
about the PDF and it will create okay it

[10:40:36 - 10:40:40]
will create what it will create you uh

[10:40:38 - 10:40:44]
interview questions so it will

[10:40:40 - 10:40:44]
return interview

[10:40:44 - 10:40:48]
questions interview

[10:40:50 - 10:40:57]
questions

[10:40:53 - 10:40:59]
okay fine now what I told you I'm not

[10:40:57 - 10:41:01]
going to take only the interview

[10:40:59 - 10:41:03]
question I will also um going to take

[10:41:01 - 10:41:05]
the interview question answer as well

[10:41:03 - 10:41:07]
from the large language model so again

[10:41:05 - 10:41:09]
what I will do whatever questions

[10:41:07 - 10:41:10]
actually I'm getting again I'll pass

[10:41:09 - 10:41:12]
okay again I'll pass to my large

[10:41:10 - 10:41:14]
language

[10:41:12 - 10:41:16]
model again I'll pass to my large

[10:41:14 - 10:41:18]
language model and I will tell you tell

[10:41:16 - 10:41:20]
my large language model model also

[10:41:18 - 10:41:22]
provide the answer the questions you

[10:41:20 - 10:41:24]
have generated so it will give me the

[10:41:22 - 10:41:24]
answer that

[10:41:26 - 10:41:32]
time so it will give

[10:41:29 - 10:41:32]
me

[10:41:33 - 10:41:40]
questions answer okay as well so this is

[10:41:38 - 10:41:42]
going to be my complete project

[10:41:40 - 10:41:44]
architecture okay so based on this

[10:41:42 - 10:41:46]
architecture we'll be developing the

[10:41:44 - 10:41:48]
entire projects fine so first of all

[10:41:46 - 10:41:50]
Let's uh do everything in my jupyter

[10:41:48 - 10:41:53]
notebook then once jupyter notebook is

[10:41:50 - 10:41:54]
working fine then I'll uh show you the

[10:41:53 - 10:41:57]
uh let's say modular coding

[10:41:54 - 10:41:59]
implementation as well so for for this

[10:41:57 - 10:42:02]
guys what I will do I will open up my

[10:41:59 - 10:42:04]
local folder and here I already created

[10:42:02 - 10:42:07]
one folder here Mt folder inside that

[10:42:04 - 10:42:09]
I'm going to open up my terminal okay so

[10:42:07 - 10:42:11]
in case if you're using anaga G bash

[10:42:09 - 10:42:13]
whatever terminal you are using you can

[10:42:11 - 10:42:15]
open it up now here I'm also going to

[10:42:13 - 10:42:17]
open up my visual code Studio so let me

[10:42:15 - 10:42:19]
open up my visual code Studio

[10:42:17 - 10:42:21]
now here the first thing uh what I have

[10:42:19 - 10:42:23]
to do I have to create one virtual

[10:42:21 - 10:42:25]
environment I think I already told you

[10:42:23 - 10:42:26]
um you just need to create a virtual

[10:42:25 - 10:42:28]
environment every time whenever you are

[10:42:26 - 10:42:29]
creating different different projects so

[10:42:28 - 10:42:31]
to create the virtual environment you

[10:42:29 - 10:42:32]
have to execute some of the command so

[10:42:31 - 10:42:34]
let me share the command with you as

[10:42:32 - 10:42:36]
well so here I'm going to create a file

[10:42:34 - 10:42:36]
called

[10:42:36 - 10:42:41]
readme MD so this is the markdown file

[10:42:39 - 10:42:44]
inside that I can mention all the

[10:42:41 - 10:42:46]
command and this file uh uh will help

[10:42:44 - 10:42:48]
you to render actually these kinds of

[10:42:46 - 10:42:50]
message in the GitHub so let's say

[10:42:48 - 10:42:52]
whenever you will be uploading this code

[10:42:50 - 10:42:53]
to the GitHub that time you'll see that

[10:42:52 - 10:42:56]
in the GitHub description that means

[10:42:53 - 10:42:57]
your project description uh all the

[10:42:56 - 10:42:59]
details has been written okay let me

[10:42:57 - 10:43:02]
show you one example so guys uh this is

[10:42:59 - 10:43:04]
my GitHub profile you can follow me here

[10:43:02 - 10:43:07]
also because here I have created lots of

[10:43:04 - 10:43:08]
repository that might help you a lot so

[10:43:07 - 10:43:10]
let me show you my repository guys one

[10:43:08 - 10:43:14]
of the project actually I implemented

[10:43:10 - 10:43:16]
previously so let's say uh this project

[10:43:14 - 10:43:18]
okay um MLS production ready machine

[10:43:16 - 10:43:20]
learning project so this is the project

[10:43:18 - 10:43:23]
actually I created now if you open this

[10:43:20 - 10:43:24]
project and if you go to the read me

[10:43:23 - 10:43:27]
section you will see that the complete

[10:43:24 - 10:43:28]
details about my project okay see the

[10:43:27 - 10:43:31]
complete details about my projects like

[10:43:28 - 10:43:32]
how we can set up what is the workflow

[10:43:31 - 10:43:34]
what are the command you have to execute

[10:43:32 - 10:43:35]
okay everything I have set here so how

[10:43:34 - 10:43:38]
it is rendering it is rendering because

[10:43:35 - 10:43:40]
of this rme file you can see readme.md

[10:43:38 - 10:43:43]
file okay so that's why we are creating

[10:43:40 - 10:43:45]
this rme file here because whatever

[10:43:43 - 10:43:46]
things you will be writing here it will

[10:43:45 - 10:43:49]
render in the GitHub later on and this

[10:43:46 - 10:43:51]
is the idea yeah so here uh some of the

[10:43:49 - 10:43:53]
common command you have to execute every

[10:43:51 - 10:43:55]
time let me show you all the all the

[10:43:53 - 10:43:56]
command so see guys these are the

[10:43:55 - 10:43:58]
command you have to execute first of all

[10:43:56 - 10:44:00]
you have to create the environment after

[10:43:58 - 10:44:01]
that you have to activate it after that

[10:44:00 - 10:44:02]
you have to install the requirements to

[10:44:01 - 10:44:04]
install the requirements you have to

[10:44:02 - 10:44:07]
execute this command okay be install

[10:44:04 - 10:44:08]
hypen requirement. txt so let's create a

[10:44:07 - 10:44:11]
file here uh I'll name it as

[10:44:08 - 10:44:14]
requirement. txl copy and let me create

[10:44:11 - 10:44:15]
the file as well okay now first of all

[10:44:14 - 10:44:18]
create the environment so copy this

[10:44:15 - 10:44:20]
command and open up your terminal and

[10:44:18 - 10:44:22]
execute it here okay execute it here for

[10:44:20 - 10:44:24]
me I already created the environment

[10:44:22 - 10:44:25]
what I'll do I'll just try to activate

[10:44:24 - 10:44:27]
it but for you you just need to create

[10:44:25 - 10:44:29]
the environment so for me let me

[10:44:27 - 10:44:31]
activate so this is the environment I

[10:44:29 - 10:44:33]
created already interview you can see

[10:44:31 - 10:44:36]
fine now inside interview I have to

[10:44:33 - 10:44:37]
install some of the required package the

[10:44:36 - 10:44:41]
package actually I need I think I showed

[10:44:37 - 10:44:42]
you the Lang genen open AI then uh

[10:44:41 - 10:44:44]
Vector database fast API okay everything

[10:44:42 - 10:44:46]
I have to install here so I already

[10:44:44 - 10:44:48]
listed down all the required package you

[10:44:46 - 10:44:51]
need

[10:44:48 - 10:44:53]
h Huh so these are the package guys you

[10:44:51 - 10:44:55]
need okay you need to install so you can

[10:44:53 - 10:44:57]
see lch lch Community langen code so

[10:44:55 - 10:44:58]
these are the actually dependency

[10:44:57 - 10:45:00]
package if you want to use langen so you

[10:44:58 - 10:45:02]
have to install it and again we are

[10:45:00 - 10:45:05]
doing local setup guys that's why some

[10:45:02 - 10:45:06]
additional package you can see otherwise

[10:45:05 - 10:45:08]
what will happen actually you might get

[10:45:06 - 10:45:10]
issue installation issue that's why I

[10:45:08 - 10:45:12]
have added everything now open i p pdfi

[10:45:10 - 10:45:13]
p PDF because user will upload PDF

[10:45:12 - 10:45:16]
documents here as of now we are

[10:45:13 - 10:45:17]
considering PDF documents fine and Tik

[10:45:16 - 10:45:20]
Tok and Tik Tok is the dependency of

[10:45:17 - 10:45:22]
open then then you can see I files fast

[10:45:20 - 10:45:24]
API uh uvon so these are the dependency

[10:45:22 - 10:45:25]
of fast API uh I'll tell you whenever

[10:45:24 - 10:45:27]
we'll be using these are the package

[10:45:25 - 10:45:28]
that time I'll explain okay as of now

[10:45:27 - 10:45:30]
just consider these are the package

[10:45:28 - 10:45:32]
actually I need to implement the entire

[10:45:30 - 10:45:34]
projects okay now you can see we'll be

[10:45:32 - 10:45:37]
using F and to install the F you have to

[10:45:34 - 10:45:39]
um execute this command F CPU then

[10:45:37 - 10:45:41]
python. EnV because I have to manage my

[10:45:39 - 10:45:43]
uh secret credential okay now let me

[10:45:41 - 10:45:44]
save everything and you have to install

[10:45:43 - 10:45:46]
it to install it this is the command

[10:45:44 - 10:45:49]
guys I already shared so copy the

[10:45:46 - 10:45:51]
command and let's execute it here for me

[10:45:49 - 10:45:52]
I already installed all the package

[10:45:51 - 10:45:54]
that's why Stelling requirement is

[10:45:52 - 10:45:56]
already satisfied but for you it will

[10:45:54 - 10:45:59]
take some time okay now let me

[10:45:56 - 10:46:00]
clear all right now first thing I'm

[10:45:59 - 10:46:02]
going to create a folder here called

[10:46:00 - 10:46:07]
resource inside resarch I'm going to

[10:46:02 - 10:46:07]
create a notebook I'm going to as

[10:46:07 - 10:46:13]
experiment I'm going to name it as

[10:46:09 - 10:46:14]
experiment do ipy NB because this is The

[10:46:13 - 10:46:17]
jupyter Notebook file I want to create

[10:46:14 - 10:46:19]
okay that's why it's ipb file now let me

[10:46:17 - 10:46:21]
select the cardal so the environment I

[10:46:19 - 10:46:23]
created this in interview okay I'll

[10:46:21 - 10:46:25]
select it up now here first of all let's

[10:46:23 - 10:46:31]
import some Library I need the operating

[10:46:25 - 10:46:31]
system then I also need EnV so fromb

[10:46:32 - 10:46:37]
import load

[10:46:34 - 10:46:39]
EnV now let me execute so it's working

[10:46:37 - 10:46:41]
fine so I think remember I have to

[10:46:39 - 10:46:43]
create a EnV file here inside that I

[10:46:41 - 10:46:45]
have to mention my open API key so let

[10:46:43 - 10:46:47]
me do it so guys as you can see I have

[10:46:45 - 10:46:49]
created this EnV file inside that I

[10:46:47 - 10:46:51]
mention my open a IPI key okay so for

[10:46:49 - 10:46:52]
you you have to do the same thing now

[10:46:51 - 10:46:56]
let's load this open II key so to load

[10:46:52 - 10:46:59]
it I'll call this load EnV after that

[10:46:56 - 10:46:59]
simply I'll call the

[10:46:59 - 10:47:03]
key open API

[10:47:03 - 10:47:11]
key and I'm going to use os.

[10:47:08 - 10:47:13]
gmv inside that I'm going to pass my key

[10:47:11 - 10:47:16]
okay so this will give you open a key

[10:47:13 - 10:47:18]
let me show you see okay it is printing

[10:47:16 - 10:47:20]
the open a a ke now let me comment as of

[10:47:18 - 10:47:22]
now I don't need to print it fine and

[10:47:20 - 10:47:24]
now what I have to do I have to set this

[10:47:22 - 10:47:25]
hop AP key as an environment variable so

[10:47:24 - 10:47:28]
for this you have to execute this line

[10:47:25 - 10:47:30]
of code so it will set this open a key

[10:47:28 - 10:47:31]
as an environment variable so that open

[10:47:30 - 10:47:33]
a package will load okay from the

[10:47:31 - 10:47:34]
environment itself I think I already

[10:47:33 - 10:47:36]
explained previously this part okay how

[10:47:34 - 10:47:37]
to do it and all now the first thing

[10:47:36 - 10:47:39]
what I have to do guys I have to load

[10:47:37 - 10:47:40]
the data but I don't have any data here

[10:47:39 - 10:47:42]
so let me show you some of the PDF

[10:47:40 - 10:47:44]
actually I'm having so guys as you can

[10:47:42 - 10:47:46]
see in the data folder I'm having

[10:47:44 - 10:47:48]
actually two PDF one is like HGD PDF one

[10:47:46 - 10:47:50]
is like starts PDF let me show you let

[10:47:48 - 10:47:53]
me open the PDF and let me show you so

[10:47:50 - 10:47:54]
if I go to the data folder so this is

[10:47:53 - 10:47:56]
the PDF guys I downloaded from the

[10:47:54 - 10:47:59]
internet uh so the PDF name is

[10:47:56 - 10:48:00]
sustainable development goals okay so

[10:47:59 - 10:48:02]
about this topic actually they have

[10:48:00 - 10:48:04]
written this PDF you can see what is

[10:48:02 - 10:48:05]
sustainable let's say development and

[10:48:04 - 10:48:07]
all they have written this particular

[10:48:05 - 10:48:09]
let's a PDF so this is uh one PDF

[10:48:07 - 10:48:10]
actually we'll be using to generate the

[10:48:09 - 10:48:12]
interview questions let's say you want

[10:48:10 - 10:48:14]
to generate interview question based on

[10:48:12 - 10:48:16]
this topic okay so you can use this PDF

[10:48:14 - 10:48:17]
not only this PDF guys you can use any

[10:48:16 - 10:48:19]
kinds of PDF whether it's a python book

[10:48:17 - 10:48:21]
any kinds of physics chemistry English

[10:48:19 - 10:48:23]
anything you can use here it's up to you

[10:48:21 - 10:48:25]
so this is the PDF guys actually I'm

[10:48:23 - 10:48:27]
having now the next PDF let me show you

[10:48:25 - 10:48:30]
so this is the statistics PDF so this is

[10:48:27 - 10:48:32]
the topic of importance and the use of

[10:48:30 - 10:48:34]
correlation in statistics and again you

[10:48:32 - 10:48:36]
can see correlation topic has been

[10:48:34 - 10:48:38]
written so we'll be also generating some

[10:48:36 - 10:48:39]
interview questions based on the

[10:48:38 - 10:48:41]
statistics okay that means the

[10:48:39 - 10:48:44]
correlation so this two PDF actually I

[10:48:41 - 10:48:46]
just downloaded from the internet okay

[10:48:44 - 10:48:49]
now let's load the data here so I'm

[10:48:46 - 10:48:51]
going to to open up my notebook so to

[10:48:49 - 10:48:53]
load the data you have to I think

[10:48:51 - 10:48:57]
remember you have to uh import one let's

[10:48:53 - 10:49:00]
say uh function from the langin so let's

[10:48:57 - 10:49:05]
import it from langin dot documents

[10:49:00 - 10:49:07]
loader okay documents loader input

[10:49:05 - 10:49:10]
uh input Pi

[10:49:07 - 10:49:12]
PDF uh Pi PDF loader I think yeah this

[10:49:10 - 10:49:15]
one p PDF loader because it's a PDF

[10:49:12 - 10:49:16]
document right now let me import it now

[10:49:15 - 10:49:19]
one thing I want to show you so let's

[10:49:16 - 10:49:21]
say if I show you my uh project working

[10:49:19 - 10:49:22]
directory right now so let's say PWD

[10:49:21 - 10:49:25]
this is the command to check my project

[10:49:22 - 10:49:27]
working directory now you can see that

[10:49:25 - 10:49:30]
I'm inside my resarch folder okay you

[10:49:27 - 10:49:31]
can see I'm inside my resarch folder so

[10:49:30 - 10:49:33]
because this experiment. ipnb is

[10:49:31 - 10:49:35]
available inside my resarch folder but

[10:49:33 - 10:49:37]
where is my data located data located

[10:49:35 - 10:49:39]
outside of the research folder yes or no

[10:49:37 - 10:49:41]
because outside of the resarch folder

[10:49:39 - 10:49:44]
data is available okay now if I want to

[10:49:41 - 10:49:46]
go back if I want to go back uh to my

[10:49:44 - 10:49:47]
root project directory that means Lang

[10:49:46 - 10:49:50]
chain project what I have to do I have

[10:49:47 - 10:49:51]
to execute one command uh this command

[10:49:50 - 10:49:54]
is

[10:49:51 - 10:49:56]
CD dot dot okay CD dot dot is the

[10:49:54 - 10:49:58]
command so this will actually go back

[10:49:56 - 10:50:00]
one folder back let me show you so now

[10:49:58 - 10:50:02]
see if I execute the command now if I

[10:50:00 - 10:50:03]
again check the project working

[10:50:02 - 10:50:05]
directory now you can see that I'm

[10:50:03 - 10:50:08]
inside my root directory that means this

[10:50:05 - 10:50:09]
directory okay Lang chain project now I

[10:50:08 - 10:50:11]
can easily access my data right now okay

[10:50:09 - 10:50:13]
this is the idea so make sure you always

[10:50:11 - 10:50:16]
check the path project working directory

[10:50:13 - 10:50:18]
okay if you're working with let's say uh

[10:50:16 - 10:50:20]
jupyter notebook uh in a specific folder

[10:50:18 - 10:50:23]
okay this is the requirement now let me

[10:50:20 - 10:50:26]
Define the file path file _ path is

[10:50:23 - 10:50:28]
equal to so my file is present inside my

[10:50:26 - 10:50:31]
data folder okay data and let's say as

[10:50:28 - 10:50:35]
of now I want to load this hd.pdf so H

[10:50:31 - 10:50:38]
sorry it should be S DG okay sustainable

[10:50:35 - 10:50:41]
uh Development Goal this PDF I want to

[10:50:38 - 10:50:44]
load PDF okay and to load it I'll be

[10:50:41 - 10:50:47]
using pi PDF loader inside that I'm

[10:50:44 - 10:50:50]
going to pass my file path okay and it

[10:50:47 - 10:50:53]
will give you uh loader loader

[10:50:50 - 10:50:56]
object now I'm going to load the data so

[10:50:53 - 10:50:59]
I'll just write data is equal to loader

[10:50:56 - 10:51:01]
loader do

[10:50:59 - 10:51:03]
load that's it now see if I execute it

[10:51:01 - 10:51:06]
should load the data now if I show you

[10:51:03 - 10:51:08]
the data see so the complete documents

[10:51:06 - 10:51:10]
it uh so guys you can see it has

[10:51:08 - 10:51:13]
extracted all the data from the PDF

[10:51:10 - 10:51:15]
itself and it is having around uh 24

[10:51:13 - 10:51:17]
pages you can see it has started from

[10:51:15 - 10:51:20]
zero till three that means 24 pages

[10:51:17 - 10:51:22]
actually it is having this PDF if I open

[10:51:20 - 10:51:24]
this PDF you'll see that 24 pages it is

[10:51:22 - 10:51:26]
having and all the pce content it has

[10:51:24 - 10:51:28]
extracted and some of the places you can

[10:51:26 - 10:51:29]
see p content is equal to empty because

[10:51:28 - 10:51:31]
in this page actually there is no

[10:51:29 - 10:51:33]
content that's so it's empty and

[10:51:31 - 10:51:34]
whatever actually documents I'm having

[10:51:33 - 10:51:36]
it has extracted okay one by one

[10:51:34 - 10:51:39]
everything now if I want to uh show you

[10:51:36 - 10:51:41]
the length you can see 24 pages are

[10:51:39 - 10:51:44]
available okay in the PDF now what I

[10:51:41 - 10:51:46]
have to do see it's a separate separate

[10:51:44 - 10:51:48]
pH content now I'm having now I want to

[10:51:46 - 10:51:51]
let's say uh store all the data in just

[10:51:48 - 10:51:53]
one variable so for this what I will do

[10:51:51 - 10:51:56]
uh I'll just take a variable here so

[10:51:53 - 10:51:57]
let's say variable name is question

[10:51:56 - 10:52:00]
undor

[10:51:57 - 10:52:02]
gen you can give any variable name and

[10:52:00 - 10:52:04]
subtitute it should be initially empty

[10:52:02 - 10:52:05]
string now I'll just write a fold Loop

[10:52:04 - 10:52:10]
so for

[10:52:05 - 10:52:11]
page in let's say data let's say the

[10:52:10 - 10:52:14]
complete data I'm having so it will give

[10:52:11 - 10:52:17]
me all the page one by one and I just

[10:52:14 - 10:52:20]
need to extract the content so question

[10:52:17 - 10:52:22]
gen uh plus and equal I'll just I'll be

[10:52:20 - 10:52:25]
just adding okay in this variable okay

[10:52:22 - 10:52:28]
this is the idea I'll just write P

[10:52:25 - 10:52:28]
dopor

[10:52:29 - 10:52:33]
content okay so it will give me uh all

[10:52:32 - 10:52:35]
the content one by one and it will save

[10:52:33 - 10:52:37]
inside this question gen variable now

[10:52:35 - 10:52:40]
let me show you now if I print my

[10:52:37 - 10:52:43]
question gen now see all the data I am

[10:52:40 - 10:52:45]
extracted okay see now it is in one

[10:52:43 - 10:52:47]
place only this is the idea now see this

[10:52:45 - 10:52:50]
part actually have completed that means

[10:52:47 - 10:52:51]
whatever PDF I uploaded I extracted the

[10:52:50 - 10:52:53]
entire documents okay now what I have to

[10:52:51 - 10:52:54]
do I have to um do the chunking

[10:52:53 - 10:52:57]
operation that means I have to create a

[10:52:54 - 10:52:59]
chunks um for my large language model uh

[10:52:57 - 10:53:00]
because if I want to let's say generate

[10:52:59 - 10:53:01]
the embeddings before that I have to do

[10:53:00 - 10:53:03]
the chunking operation I already

[10:53:01 - 10:53:05]
explained this part I think remember so

[10:53:03 - 10:53:07]
to perform the chunking we'll be using

[10:53:05 - 10:53:12]
one package so it is available inside

[10:53:07 - 10:53:16]
langen so len. text splitter so we'll be

[10:53:12 - 10:53:19]
using uh one text Splitter Splitter here

[10:53:16 - 10:53:20]
called token text splitter okay so

[10:53:19 - 10:53:23]
previously I think we used something

[10:53:20 - 10:53:25]
called character text splitter then

[10:53:23 - 10:53:26]
recursive text splitter I think remember

[10:53:25 - 10:53:31]
we use

[10:53:26 - 10:53:34]
character okay character text

[10:53:31 - 10:53:35]
splitter okay splitter so with the help

[10:53:34 - 10:53:37]
of that we can perform the chunking

[10:53:35 - 10:53:40]
operation I think remember then we have

[10:53:37 - 10:53:43]
also have something called recursive uh

[10:53:40 - 10:53:44]
recursive okay text is splitter so again

[10:53:43 - 10:53:45]
this is another method to perform the

[10:53:44 - 10:53:47]
chunking operation and now we'll be

[10:53:45 - 10:53:49]
using something single token text

[10:53:47 - 10:53:51]
spitter token text spitter now what is

[10:53:49 - 10:53:54]
the difference between token Tex spitter

[10:53:51 - 10:53:56]
and character and recursive see let's

[10:53:54 - 10:53:57]
say this my entire documents so I think

[10:53:56 - 10:53:59]
remember we used to perform something

[10:53:57 - 10:54:05]
called

[10:53:59 - 10:54:08]
chunk size okay CH size let's say uh

[10:54:05 - 10:54:12]
let's say uh five okay 500 and there is

[10:54:08 - 10:54:15]
another parameter called s _

[10:54:12 - 10:54:17]
overlap let's say it's 100 okay now how

[10:54:15 - 10:54:18]
it will the chunks I think remember

[10:54:17 - 10:54:20]
first of all it will start from the

[10:54:18 - 10:54:23]
first and it will count 500 wat let's

[10:54:20 - 10:54:26]
say 500 wats ends here so this is our

[10:54:23 - 10:54:28]
first chunks okay and to start the

[10:54:26 - 10:54:30]
second chunk first of all it will apply

[10:54:28 - 10:54:33]
the chunk overlap let's say 1001 back

[10:54:30 - 10:54:35]
actually it will go so it will count uh

[10:54:33 - 10:54:38]
1001 let's say this is the 100 W start

[10:54:35 - 10:54:40]
from here so it will start the second

[10:54:38 - 10:54:44]
chunks from here and again it will count

[10:54:40 - 10:54:47]
till 500 wat let's say 500 wat ends here

[10:54:44 - 10:54:48]
okay so this is my second chunk okay so

[10:54:47 - 10:54:51]
that's actually it will perform the

[10:54:48 - 10:54:54]
chunking operation now you can see uh

[10:54:51 - 10:54:56]
there is a chunk overlap you got so this

[10:54:54 - 10:54:58]
is called actually overlap okay this is

[10:54:56 - 10:55:01]
called overlap and with this overlap

[10:54:58 - 10:55:03]
actually my uh model will understand

[10:55:01 - 10:55:05]
after this first chance this Chance is

[10:55:03 - 10:55:07]
coming because you can see it is getting

[10:55:05 - 10:55:09]
overlap now this is the actually manual

[10:55:07 - 10:55:11]
manual approach actually we can consider

[10:55:09 - 10:55:14]
this is the manual approach we can

[10:55:11 - 10:55:18]
consider to get the context context of

[10:55:14 - 10:55:20]
my first SS and second chunks okay and

[10:55:18 - 10:55:23]
so on like whatever chunks actually are

[10:55:20 - 10:55:24]
defining here but uh this is actually

[10:55:23 - 10:55:26]
what we do in the character Tex spitter

[10:55:24 - 10:55:27]
or recursive text splitter but what

[10:55:26 - 10:55:30]
about token text splitter see token text

[10:55:27 - 10:55:32]
spitter what it will do instead of using

[10:55:30 - 10:55:33]
Okay instead of using actually this

[10:55:32 - 10:55:35]
manual approach it will use one large

[10:55:33 - 10:55:37]
language model it will use one large

[10:55:35 - 10:55:38]
language model in case actually we'll be

[10:55:37 - 10:55:44]
using something called

[10:55:38 - 10:55:47]
GPT 3.5 okay so this GPT 3.5 will decide

[10:55:44 - 10:55:49]
okay uh like uh how to create the chunk

[10:55:47 - 10:55:51]
how to perform the overlapping and it

[10:55:49 - 10:55:53]
will automatically remember let's say

[10:55:51 - 10:55:55]
after this first chunks this second

[10:55:53 - 10:55:57]
chunks is coming after second chunks

[10:55:55 - 10:55:59]
this third chunks is coming after third

[10:55:57 - 10:56:01]
chunks this fourth chunks is coming okay

[10:55:59 - 10:56:03]
your large language model will try to

[10:56:01 - 10:56:05]
remember this part okay and this is like

[10:56:03 - 10:56:07]
more powerful method than your previous

[10:56:05 - 10:56:10]
one Whatever let's say method you used

[10:56:07 - 10:56:13]
previously because now LM is like

[10:56:10 - 10:56:15]
remembering everything the context okay

[10:56:13 - 10:56:17]
that's the idea so let's try to explore

[10:56:15 - 10:56:19]
this uh one this token text is printer

[10:56:17 - 10:56:21]
so for this I'm going to open up my

[10:56:19 - 10:56:24]
notebook so I already imported now let

[10:56:21 - 10:56:26]
me execute now see uh this is the synex

[10:56:24 - 10:56:28]
to use the token text sper so I think

[10:56:26 - 10:56:29]
you remember previously we didn't use

[10:56:28 - 10:56:31]
any kinds of model name whenever we used

[10:56:29 - 10:56:32]
to perform the let's say chunking

[10:56:31 - 10:56:35]
operation now you can see I'm using the

[10:56:32 - 10:56:37]
model name I'm using GPT 3.5 turbo that

[10:56:35 - 10:56:40]
means my model will try to decide okay

[10:56:37 - 10:56:42]
how to remember the context now you can

[10:56:40 - 10:56:44]
see this is the Chang size Chang size

[10:56:42 - 10:56:46]
I'm expecting 10,000 okay 10,000

[10:56:44 - 10:56:49]
actually what would be consider as one

[10:56:46 - 10:56:50]
chunks and chunks overlap should be 200

[10:56:49 - 10:56:52]
okay as of now let's say this is the

[10:56:50 - 10:56:54]
things I'm just showing you just to show

[10:56:52 - 10:56:55]
you okay how it will work it just

[10:56:54 - 10:56:57]
experiment okay I'm just showing you how

[10:56:55 - 10:56:59]
we will try to create the chunk now

[10:56:57 - 10:57:02]
let's define the splitter okay this is

[10:56:59 - 10:57:04]
my splitter now inside that I'm going to

[10:57:02 - 10:57:06]
pass my entire documents so you can see

[10:57:04 - 10:57:08]
the entire questions and documents

[10:57:06 - 10:57:10]
actually I'm having I'm passing to my

[10:57:08 - 10:57:12]
splitter okay splitter objects you can

[10:57:10 - 10:57:14]
see speed text it will give me chunk

[10:57:12 - 10:57:15]
question gen that means the uh chunking

[10:57:14 - 10:57:17]
okay it will give you the chunking

[10:57:15 - 10:57:19]
result let me show you so here is the

[10:57:17 - 10:57:22]
chunk I

[10:57:19 - 10:57:23]
got see this is the chunk I got now how

[10:57:22 - 10:57:25]
many chunk it has written for this you

[10:57:23 - 10:57:27]
can use length function you can check

[10:57:25 - 10:57:30]
see it has only given me one chunk

[10:57:27 - 10:57:34]
because why the PDF you can see this PDF

[10:57:30 - 10:57:36]
is DG so if you count all the words it

[10:57:34 - 10:57:38]
won't be actually 10,000 words okay it

[10:57:36 - 10:57:40]
won't be 10,000 words it is less than

[10:57:38 - 10:57:42]
10,000 wordss that's why here I given

[10:57:40 - 10:57:45]
chunk size is equal to 10,000 it is only

[10:57:42 - 10:57:46]
considering uh one okay one chunk the

[10:57:45 - 10:57:49]
entire documents because I told you if

[10:57:46 - 10:57:51]
you count the all the let's say what

[10:57:49 - 10:57:53]
okay in this do let's say PDF it won't

[10:57:51 - 10:57:55]
be 10,000 okay because it's a like hug

[10:57:53 - 10:57:57]
size I have given here just to show you

[10:57:55 - 10:57:59]
okay how chunking will happen now let's

[10:57:57 - 10:58:00]
perform our actual chunking for this

[10:57:59 - 10:58:03]
what I have to do I have to first of all

[10:58:00 - 10:58:05]
convert this uh this actually data to

[10:58:03 - 10:58:07]
the document format because you can see

[10:58:05 - 10:58:09]
now it's a list format okay if I show

[10:58:07 - 10:58:11]
the

[10:58:09 - 10:58:17]
type okay if I show you the

[10:58:11 - 10:58:17]
type of this one CH question

[10:58:20 - 10:58:24]
now it's a list inside that if I just

[10:58:22 - 10:58:26]
extract the first element it would be a

[10:58:24 - 10:58:28]
string see it's a string but I have to

[10:58:26 - 10:58:30]
convert to the documentary presentation

[10:58:28 - 10:58:35]
so for this what I will do I'll import

[10:58:30 - 10:58:36]
one uh class from lanin called doc

[10:58:35 - 10:58:38]
documents import documents okay with the

[10:58:36 - 10:58:39]
help of documents we can easily convert

[10:58:38 - 10:58:42]
any kind of string to document

[10:58:39 - 10:58:46]
representation okay now let me show

[10:58:42 - 10:58:48]
you see now whatever let's say

[10:58:46 - 10:58:52]
um data you got that means your uh this

[10:58:48 - 10:58:54]
one chunk question gen so I'm applying

[10:58:52 - 10:58:56]
on for Loop that means it will give me

[10:58:54 - 10:58:58]
all the let's say data one by one and

[10:58:56 - 10:58:59]
I'm converting to the documents you can

[10:58:58 - 10:59:02]
see okay and I'm storing in this

[10:58:59 - 10:59:05]
particular variable now if I execute now

[10:59:02 - 10:59:06]
see I got the documents and it is format

[10:59:05 - 10:59:09]
of documents right now okay now if I

[10:59:06 - 10:59:09]
show you the

[10:59:09 - 10:59:16]
type type of document question in it

[10:59:13 - 10:59:17]
should be a langin code document BAS

[10:59:16 - 10:59:19]
document documents okay it's a now

[10:59:17 - 10:59:22]
document format because if I want to

[10:59:19 - 10:59:23]
apply the splitter so first of all you

[10:59:22 - 10:59:24]
have to convert everything to the

[10:59:23 - 10:59:26]
document this is the recommended way

[10:59:24 - 10:59:28]
okay if you're also giving the let's say

[10:59:26 - 10:59:29]
string directly it's completely fine but

[10:59:28 - 10:59:30]
this is the recommended way first of all

[10:59:29 - 10:59:32]
convert everything to the document

[10:59:30 - 10:59:34]
format then try to use the splitter that

[10:59:32 - 10:59:36]
means the chunking operation now I'll do

[10:59:34 - 10:59:39]
the chunking again see again token Tex

[10:59:36 - 10:59:41]
splitter again I'm using gbt 3.5 TBO

[10:59:39 - 10:59:43]
model now I have given the Chun size is

[10:59:41 - 10:59:44]
equal to 1,000 that means 1,000 mod I

[10:59:43 - 10:59:46]
want to consider as one chunks and

[10:59:44 - 10:59:49]
chunks overlap is equal to

[10:59:46 - 10:59:52]
uh 100 okay now let me

[10:59:49 - 10:59:55]
execute now let me give my documents now

[10:59:52 - 10:59:57]
you can see do document question gen

[10:59:55 - 10:59:59]
okay I'm passing it to my uh splitter

[10:59:57 - 11:00:01]
okay splitter object right now now it

[10:59:59 - 11:00:04]
will give me the chunk now let me show

[11:00:01 - 11:00:06]
you now see I'll get multiple chunk here

[11:00:04 - 11:00:08]
so I got here four chunks okay four

[11:00:06 - 11:00:10]
chunks actually I got from the entire

[11:00:08 - 11:00:13]
PDF now if I show you the

[11:00:10 - 11:00:15]
length see four chunks I got fine I

[11:00:13 - 11:00:18]
think it is clear now so guys as you can

[11:00:15 - 11:00:20]
see we successfully uh created the

[11:00:18 - 11:00:22]
chunks now the next thing what I have to

[11:00:20 - 11:00:24]
do uh first of all I will generate the

[11:00:22 - 11:00:26]
questions uh like whatever let's say

[11:00:24 - 11:00:27]
chunk I have created I will pass to my

[11:00:26 - 11:00:29]
large language model and I will generate

[11:00:27 - 11:00:30]
the questions okay interview questions

[11:00:29 - 11:00:32]
based on the prompt actually I'll be

[11:00:30 - 11:00:34]
providing I think

[11:00:32 - 11:00:35]
remember I think you remember uh we'll

[11:00:34 - 11:00:37]
be passing one prompt to the large

[11:00:35 - 11:00:39]
language model okay so with the help of

[11:00:37 - 11:00:42]
this prompt actually I'll tell my large

[11:00:39 - 11:00:44]
language model um I need a uh interview

[11:00:42 - 11:00:45]
questions okay let's say the documents I

[11:00:44 - 11:00:47]
have given based on that it should

[11:00:45 - 11:00:48]
provide provide me some interview

[11:00:47 - 11:00:50]
questions that's what actually I need to

[11:00:48 - 11:00:51]
perform so for this I don't need to

[11:00:50 - 11:00:53]
convert this documents to the embeding

[11:00:51 - 11:00:55]
representation because as of now we are

[11:00:53 - 11:00:56]
only passing the let's say uh documents

[11:00:55 - 11:00:58]
to my large language model large

[11:00:56 - 11:01:00]
language model will give me the

[11:00:58 - 11:01:01]
questions but later on whenever let's

[11:01:00 - 11:01:03]
say I'll be doing the answer generation

[11:01:01 - 11:01:05]
okay the complete answer generation that

[11:01:03 - 11:01:07]
time actually I I need to pass the

[11:01:05 - 11:01:08]
entire documents okay and it will create

[11:01:07 - 11:01:11]
the vector embeddings and it will store

[11:01:08 - 11:01:12]
to the vector database okay and uh

[11:01:11 - 11:01:14]
Vector database I'll will connect my

[11:01:12 - 11:01:16]
large language model and large language

[11:01:14 - 11:01:17]
model will refer this interre inform to

[11:01:16 - 11:01:19]
give me the answer as well okay this is

[11:01:17 - 11:01:21]
the idea so let's define my large

[11:01:19 - 11:01:22]
language model right now so here I

[11:01:21 - 11:01:24]
already told you I'm going to use

[11:01:22 - 11:01:27]
something called open uh large langage

[11:01:24 - 11:01:29]
model that mean GPT 3.5 okay this model

[11:01:27 - 11:01:30]
and to use it I can use this class

[11:01:29 - 11:01:32]
actually chat openi you can also

[11:01:30 - 11:01:34]
directly import openi it is completely

[11:01:32 - 11:01:36]
fine but we can also import like that

[11:01:34 - 11:01:38]
okay both way you can import and if I'm

[11:01:36 - 11:01:40]
importing like that so here I can also

[11:01:38 - 11:01:42]
give my model name that means which

[11:01:40 - 11:01:44]
specific model I want to use whether I

[11:01:42 - 11:01:46]
want to use let's say gbt 4 model 3.5

[11:01:44 - 11:01:49]
model you can use so let me show you so

[11:01:46 - 11:01:50]
this is the Cod nibit so chat open

[11:01:49 - 11:01:52]
inside that you can give the model name

[11:01:50 - 11:01:54]
let's say I want to use GPT 3.5 TBO

[11:01:52 - 11:01:57]
model and this is the temperature

[11:01:54 - 11:01:59]
parameter you can also give max length

[11:01:57 - 11:02:01]
parameter and so on so temperature

[11:01:59 - 11:02:02]
parameter is a creativity parameter I

[11:02:01 - 11:02:03]
already explained okay what is the

[11:02:02 - 11:02:05]
temperature parameter now let me Define

[11:02:03 - 11:02:07]
my

[11:02:05 - 11:02:09]
llm now here I already created one

[11:02:07 - 11:02:11]
prompt guys promt template let me show

[11:02:09 - 11:02:13]
you so this is the prompt I have created

[11:02:11 - 11:02:14]
guys you can see you are an expert at

[11:02:13 - 11:02:17]
creating question based on the coding

[11:02:14 - 11:02:19]
material and document mentation see uh

[11:02:17 - 11:02:21]
whenever I designed this prompt actually

[11:02:19 - 11:02:23]
I was uh like generating coding related

[11:02:21 - 11:02:26]
questions and now I'm using any other

[11:02:23 - 11:02:27]
documents you can see um that means the

[11:02:26 - 11:02:29]
uh this one sustainable development goal

[11:02:27 - 11:02:31]
and statistics one so if you're using

[11:02:29 - 11:02:33]
statistics one that time you need to

[11:02:31 - 11:02:35]
give statistics material if you're doing

[11:02:33 - 11:02:37]
uh sustainable development goal you have

[11:02:35 - 11:02:38]
to give sustainable development goal

[11:02:37 - 11:02:40]
here that means whatever subject you are

[11:02:38 - 11:02:41]
referring you have to give the prompt

[11:02:40 - 11:02:42]
with respect to that because it's a

[11:02:41 - 11:02:44]
changeable prompt is changeable okay you

[11:02:42 - 11:02:46]
have to change every time based on your

[11:02:44 - 11:02:48]
requirement now your is to prepare a

[11:02:46 - 11:02:51]
coder for a programmer for their exams

[11:02:48 - 11:02:52]
and their coding test you do this by

[11:02:51 - 11:02:54]
asking the questions about the text

[11:02:52 - 11:02:56]
below that means whatever let's say data

[11:02:54 - 11:02:57]
user will provide that means this chunks

[11:02:56 - 11:02:59]
okay based on that it will create

[11:02:57 - 11:03:01]
interview questions that will prepare

[11:02:59 - 11:03:04]
for the coder um programmer for their

[11:03:01 - 11:03:06]
exam test okay make sure not lose any

[11:03:04 - 11:03:08]
important information okay this is the

[11:03:06 - 11:03:10]
prompt actually I have created and I

[11:03:08 - 11:03:12]
already told you like how we can design

[11:03:10 - 11:03:14]
a efficient prompt what is the art of

[11:03:12 - 11:03:16]
let's say design a prompt I already took

[11:03:14 - 11:03:18]
on session uh on the prompt engineering

[11:03:16 - 11:03:20]
that uh session you can refer okay so

[11:03:18 - 11:03:22]
that's how always you have to prepare a

[11:03:20 - 11:03:23]
uh good prompt whenever you are

[11:03:22 - 11:03:24]
preparing good prompt that means you

[11:03:23 - 11:03:27]
will get a good response from the large

[11:03:24 - 11:03:29]
language model this is the idea now let

[11:03:27 - 11:03:30]
me Define The Prompt now to use this

[11:03:29 - 11:03:32]
prompt I think I already told you one

[11:03:30 - 11:03:33]
concept called prompt template you have

[11:03:32 - 11:03:35]
to use something called promp template

[11:03:33 - 11:03:36]
from the langen so let me show you so

[11:03:35 - 11:03:39]
this is the Cod

[11:03:36 - 11:03:40]
cipit prom template okay so here I'm

[11:03:39 - 11:03:42]
passing the prom template the prom

[11:03:40 - 11:03:44]
template I've created and this is the

[11:03:42 - 11:03:46]
input variable is text that means user

[11:03:44 - 11:03:48]
will give this data okay this is the

[11:03:46 - 11:03:50]
input variable I think it is clear now

[11:03:48 - 11:03:53]
let me execute the prompt okay now this

[11:03:50 - 11:03:56]
is my template right now uh we can do

[11:03:53 - 11:03:59]
another actually uh very important let's

[11:03:56 - 11:04:00]
say technique here uh see if you're not

[11:03:59 - 11:04:02]
doing it it's completely fine it will

[11:04:00 - 11:04:04]
work but I was going through some of the

[11:04:02 - 11:04:06]
research paper research article and I

[11:04:04 - 11:04:07]
got to know people are using something

[11:04:06 - 11:04:09]
called second layer verification that

[11:04:07 - 11:04:11]
means they are doing refine template

[11:04:09 - 11:04:13]
refine prom template so what is refine

[11:04:11 - 11:04:15]
prom template let me show you I created

[11:04:13 - 11:04:17]
one prom template see this is the prom

[11:04:15 - 11:04:18]
template I again created that means

[11:04:17 - 11:04:20]
whatever questions actually your model

[11:04:18 - 11:04:21]
will generate from the first prompt you

[11:04:20 - 11:04:23]
have to give those question to the

[11:04:21 - 11:04:25]
second prompt that means it will refine

[11:04:23 - 11:04:26]
that particular question let's say if

[11:04:25 - 11:04:28]
there are some issue with the question

[11:04:26 - 11:04:30]
if let's say this question is irrelevant

[11:04:28 - 11:04:32]
based on the topic you are asking again

[11:04:30 - 11:04:33]
this refine prompt template will try to

[11:04:32 - 11:04:36]
refine and again it will give you some

[11:04:33 - 11:04:37]
new questions okay on top of it so here

[11:04:36 - 11:04:39]
you can see I've written the same prompt

[11:04:37 - 11:04:41]
again but one more additional

[11:04:39 - 11:04:42]
information I have added we have

[11:04:41 - 11:04:45]
received some practical questions to

[11:04:42 - 11:04:46]
certain context that means it will give

[11:04:45 - 11:04:48]
me some questions okay this question

[11:04:46 - 11:04:50]
actually I have to give to my second

[11:04:48 - 11:04:52]
prompt and second prompt we try to check

[11:04:50 - 11:04:54]
we have the option to refine the

[11:04:52 - 11:04:55]
existing questions or add new one only

[11:04:54 - 11:04:58]
if necessary with some more context

[11:04:55 - 11:05:00]
below that means if some issue is there

[11:04:58 - 11:05:01]
if let's say it is irrelevant that time

[11:05:00 - 11:05:03]
what it will do it'll try to rectify

[11:05:01 - 11:05:04]
that question okay this is the idea give

[11:05:03 - 11:05:07]
the new context refine original

[11:05:04 - 11:05:08]
questions in English if context is not

[11:05:07 - 11:05:10]
helpful please provide the original

[11:05:08 - 11:05:12]
questions this is the idea so this will

[11:05:10 - 11:05:14]
actually refine from template you are

[11:05:12 - 11:05:16]
refining the questions here that is the

[11:05:14 - 11:05:18]
idea only and this will like very

[11:05:16 - 11:05:19]
powerful method guys if you are using

[11:05:18 - 11:05:21]
you will see that your result would be

[11:05:19 - 11:05:23]
pretty good if you're not using it it's

[11:05:21 - 11:05:25]
completely fine no need to worry but I'm

[11:05:23 - 11:05:27]
showing you uh because see we are

[11:05:25 - 11:05:29]
creating in Advan application and in

[11:05:27 - 11:05:30]
Advan application we have to take care

[11:05:29 - 11:05:33]
these are the part okay this is

[11:05:30 - 11:05:34]
important let's also Define this refine

[11:05:33 - 11:05:35]
prom template again I'm going to use

[11:05:34 - 11:05:37]
prom template inside that I'm going to

[11:05:35 - 11:05:40]
pass the input variable now input

[11:05:37 - 11:05:42]
variable is two one is the this existing

[11:05:40 - 11:05:44]
answer the existing answer I will get

[11:05:42 - 11:05:46]
and the text that means the again you

[11:05:44 - 11:05:48]
have to give the entire text that means

[11:05:46 - 11:05:50]
the chunks okay so this two input now

[11:05:48 - 11:05:52]
you have to give you can see text and

[11:05:50 - 11:05:53]
existing answer and it will give me the

[11:05:52 - 11:05:56]
refine prom

[11:05:53 - 11:05:58]
template fine now I'll generate the

[11:05:56 - 11:06:00]
questions for this I need to integrate

[11:05:58 - 11:06:02]
my large language model as well as the

[11:06:00 - 11:06:05]
prom template for this I'm going to use

[11:06:02 - 11:06:07]
one function from Lang chain called load

[11:06:05 - 11:06:09]
summarize chain okay previously I think

[11:06:07 - 11:06:11]
I showed you we can use chain okay only

[11:06:09 - 11:06:12]
chain we can use now there is another

[11:06:11 - 11:06:14]
chain actually called load summarized

[11:06:12 - 11:06:15]
chain because inside Lang chain you are

[11:06:14 - 11:06:17]
getting different different chains okay

[11:06:15 - 11:06:19]
okay we are using this particular chain

[11:06:17 - 11:06:23]
actually load summarize chain now we'll

[11:06:19 - 11:06:24]
be creating my entire CH see this is the

[11:06:23 - 11:06:26]
entire chain first of all you have to

[11:06:24 - 11:06:29]
give the large language model OKAY the

[11:06:26 - 11:06:31]
LM we have defined GPT 3.5 then chain

[11:06:29 - 11:06:33]
type is equal to refine because we have

[11:06:31 - 11:06:35]
reped one refine PR template okay that's

[11:06:33 - 11:06:37]
why it's a refine varos true that means

[11:06:35 - 11:06:39]
it will show you the execution um all

[11:06:37 - 11:06:40]
the let's say logs then here I'm giving

[11:06:39 - 11:06:42]
the question prompt first of all the

[11:06:40 - 11:06:43]
prompt I have defined at the very first

[11:06:42 - 11:06:46]
okay this is the this is the question

[11:06:43 - 11:06:49]
prompt okay because it's a chain it will

[11:06:46 - 11:06:50]
execute after uh one one after another

[11:06:49 - 11:06:52]
okay first of all it will execute and

[11:06:50 - 11:06:53]
whatever question actually I'll getting

[11:06:52 - 11:06:55]
I'll pass to the Define PR template okay

[11:06:53 - 11:06:57]
you can see refine prom template okay

[11:06:55 - 11:07:01]
now this is going to be my chain right

[11:06:57 - 11:07:03]
now now simply I'm going to pass

[11:07:01 - 11:07:05]
the document question that means that

[11:07:03 - 11:07:07]
means this one I have to pass this one

[11:07:05 - 11:07:09]
that means the entire document okay this

[11:07:07 - 11:07:11]
document I have to pass right now to my

[11:07:09 - 11:07:13]
large language model and it will give me

[11:07:11 - 11:07:14]
the questions okay it will give me the

[11:07:13 - 11:07:16]
questions and these questions I'm

[11:07:14 - 11:07:19]
printing let me show

[11:07:16 - 11:07:21]
you see it is generating and it is

[11:07:19 - 11:07:23]
giving all the information because you

[11:07:21 - 11:07:25]
have defined barbas is equal to true now

[11:07:23 - 11:07:26]
see these are the questions I got I got

[11:07:25 - 11:07:29]
10 questions now if you got if you want

[11:07:26 - 11:07:31]
to get 100 questions you can Define here

[11:07:29 - 11:07:33]
you can Define inside the prompt I need

[11:07:31 - 11:07:34]
100 questions okay you have to generate

[11:07:33 - 11:07:36]
100 question it will generate 100

[11:07:34 - 11:07:38]
question by default it generating 10

[11:07:36 - 11:07:40]
questions now if you if I want to show

[11:07:38 - 11:07:42]
you I will open in a text editor see all

[11:07:40 - 11:07:44]
the 10 questions I got here but apart

[11:07:42 - 11:07:45]
from that I'm getting some more

[11:07:44 - 11:07:47]
additional information I don't need I

[11:07:45 - 11:07:49]
only need the questions you can see 1 to

[11:07:47 - 11:07:50]
10 questions it is giving me what is the

[11:07:49 - 11:07:52]
main goal of the sustainable development

[11:07:50 - 11:07:54]
goals method what are the some key

[11:07:52 - 11:07:55]
achievements in the see that means if

[11:07:54 - 11:07:57]
you read this questions it's pretty good

[11:07:55 - 11:08:01]
now as a human if if I tell you just

[11:07:57 - 11:08:03]
prepare the question for me I think uh

[11:08:01 - 11:08:04]
you'll be thinking in that way okay this

[11:08:03 - 11:08:06]
is the idea that means my answer is

[11:08:04 - 11:08:08]
pretty good guys and why I got the

[11:08:06 - 11:08:09]
pretty good answer because I use the

[11:08:08 - 11:08:11]
refine prom template okay so this is

[11:08:09 - 11:08:14]
another powerful concept you can use

[11:08:11 - 11:08:15]
okay so now we'll be creating the next

[11:08:14 - 11:08:17]
part that means we'll be using the

[11:08:15 - 11:08:18]
embedding model we'll be generating the

[11:08:17 - 11:08:21]
vector embedding and we'll be storing to

[11:08:18 - 11:08:22]
the vector database okay because I also

[11:08:21 - 11:08:24]
need to generate the answer right now

[11:08:22 - 11:08:26]
fine so this is what I have to perform

[11:08:24 - 11:08:28]
so let's do it so for this first of all

[11:08:26 - 11:08:31]
I have to Define one embedding model so

[11:08:28 - 11:08:34]
here I'll be using opena embedding model

[11:08:31 - 11:08:36]
so for this you can import from the Lang

[11:08:34 - 11:08:37]
chain embeddings open I need open

[11:08:36 - 11:08:40]
embedding model okay so let me

[11:08:37 - 11:08:42]
initialize so here I'm going to use open

[11:08:40 - 11:08:44]
embedding model so if you go to the open

[11:08:42 - 11:08:45]
website and if you go to the model

[11:08:44 - 11:08:47]
section you'll see that open also

[11:08:45 - 11:08:49]
provides lots of embedding model okay so

[11:08:47 - 11:08:51]
you can use any of them now I also need

[11:08:49 - 11:08:52]
to initialize my Vector database so here

[11:08:51 - 11:08:54]
I'm going to use f Vector database I

[11:08:52 - 11:08:57]
already told you so it is available

[11:08:54 - 11:08:59]
inside lanin lanin Vector restore F you

[11:08:57 - 11:09:01]
can also use chrom RB Pine con web it's

[11:08:59 - 11:09:03]
up to you but I'm going to use the F

[11:09:01 - 11:09:06]
because I need to show you the f as well

[11:09:03 - 11:09:08]
okay and F is very like Fast um I mean

[11:09:06 - 11:09:11]
than your chroma DB okay you'll see that

[11:09:08 - 11:09:13]
it's like very fast quite fast now let's

[11:09:11 - 11:09:14]
initialize my Vector store see that's

[11:09:13 - 11:09:16]
how you have to initialize the vector

[11:09:14 - 11:09:17]
store F from documents and you have to

[11:09:16 - 11:09:18]
give the documents here like which

[11:09:17 - 11:09:20]
document you want to create the

[11:09:18 - 11:09:22]
embedding I think remember we created a

[11:09:20 - 11:09:26]
chunks this chunks I think

[11:09:22 - 11:09:27]
remember document and Sur this chunks I

[11:09:26 - 11:09:29]
have to pass and I have to create the

[11:09:27 - 11:09:30]
embedding okay and I have to give the

[11:09:29 - 11:09:32]
embedding model this the embedding model

[11:09:30 - 11:09:32]
I'm passing so this will give you the

[11:09:32 - 11:09:35]
vector

[11:09:32 - 11:09:36]
store and it will save locally guys okay

[11:09:35 - 11:09:39]
it will save locally you won't be able

[11:09:36 - 11:09:41]
to see that okay it will save in memory

[11:09:39 - 11:09:43]
actually and if you want to see that you

[11:09:41 - 11:09:45]
can store in the cloud based uh I mean

[11:09:43 - 11:09:46]
you can use the cloud Vector d in the

[11:09:45 - 11:09:48]
cloud you can sa I think I showed you

[11:09:46 - 11:09:50]
the pine cone there you can see the

[11:09:48 - 11:09:53]
visualization of your vector okay it's

[11:09:50 - 11:09:54]
possible now let me again initialize my

[11:09:53 - 11:09:57]
large language model you can see again

[11:09:54 - 11:09:59]
I'm using gbd 3.5 turbo large language

[11:09:57 - 11:10:01]
model to generate my answer because you

[11:09:59 - 11:10:03]
can see I told you now the question I'm

[11:10:01 - 11:10:04]
getting I'll again pass to my large

[11:10:03 - 11:10:05]
language model large language model will

[11:10:04 - 11:10:08]
give me the answer okay that's why I'm

[11:10:05 - 11:10:12]
initializing my llm now previously

[11:10:08 - 11:10:14]
I um got some questions I think remember

[11:10:12 - 11:10:17]
so this is the questions I got okay

[11:10:14 - 11:10:19]
these are the question questions I got

[11:10:17 - 11:10:21]
uh if I show you uh beautifully so what

[11:10:19 - 11:10:26]
I can do I can split with the help of

[11:10:21 - 11:10:29]
Slash in so it will give me line by line

[11:10:26 - 11:10:32]
everything now this is the question list

[11:10:29 - 11:10:34]
see so this 10 question I got now I have

[11:10:32 - 11:10:36]
to generate the answer of this 10

[11:10:34 - 11:10:38]
question okay with the help of large

[11:10:36 - 11:10:41]
language model now for this let's create

[11:10:38 - 11:10:43]
a retrial QA okay question answer let's

[11:10:41 - 11:10:44]
a chain because inside chain we are

[11:10:43 - 11:10:45]
having different different chains I

[11:10:44 - 11:10:48]
think I told you now I'm using retriable

[11:10:45 - 11:10:51]
Q CH this CH I already used in my Vector

[11:10:48 - 11:10:55]
DV I think you remember let's create it

[11:10:51 - 11:10:56]
now let's initialize my qn so here you

[11:10:55 - 11:10:57]
have to give the large language model

[11:10:56 - 11:10:59]
first of all now you have to give the

[11:10:57 - 11:11:01]
chain type is equal to stop because it's

[11:10:59 - 11:11:03]
a qn okay now you have to give the

[11:11:01 - 11:11:05]
object that means your vector store that

[11:11:03 - 11:11:06]
means you are connecting with your large

[11:11:05 - 11:11:08]
language model right now see llm you are

[11:11:06 - 11:11:09]
connecting with the vector store okay

[11:11:08 - 11:11:11]
for this you have to write this code

[11:11:09 - 11:11:14]
Vector store as reter that's it now this

[11:11:11 - 11:11:16]
is going to give you one chain now we

[11:11:14 - 11:11:18]
can give the let's say question and you

[11:11:16 - 11:11:21]
can get the answer for this I written a

[11:11:18 - 11:11:22]
full loop here see what I'm doing

[11:11:21 - 11:11:24]
whatever question list actually I'm

[11:11:22 - 11:11:26]
having I'm looping through it that means

[11:11:24 - 11:11:28]
I'm taking all the question one by one

[11:11:26 - 11:11:29]
okay you can see then I'm printing it

[11:11:28 - 11:11:31]
then I'm generating the answer you can

[11:11:29 - 11:11:32]
see I'm calling this chain run question

[11:11:31 - 11:11:34]
that means I'm giving the question it

[11:11:32 - 11:11:36]
will give me the answer this answer

[11:11:34 - 11:11:37]
actually I'm also printing after that

[11:11:36 - 11:11:39]
I'm opening a txt file inside that I'm

[11:11:37 - 11:11:40]
just saving it okay inside that I'm just

[11:11:39 - 11:11:42]
saving it that's it as of now inside a

[11:11:40 - 11:11:44]
txt file I'm saving it going forward

[11:11:42 - 11:11:45]
inside a CSV file I I have to save it

[11:11:44 - 11:11:47]
okay this is the idea

[11:11:45 - 11:11:49]
now let me execute see first of all this

[11:11:47 - 11:11:51]
is the first question it is generating

[11:11:49 - 11:11:52]
the answer see this is the answer okay

[11:11:51 - 11:11:56]
second question it is generating the

[11:11:52 - 11:11:59]
answer third question answer fourth

[11:11:56 - 11:12:00]
question answer so that's how it will

[11:11:59 - 11:12:03]
generate for all the questions let me

[11:12:00 - 11:12:05]
show you see beautifully it is

[11:12:03 - 11:12:06]
generating so we have created one

[11:12:05 - 11:12:08]
amazing application guys now we have to

[11:12:06 - 11:12:10]
convert it the modular coding there the

[11:12:08 - 11:12:12]
idea now see all the answer I got and if

[11:12:10 - 11:12:13]
you read the answer guys if you open

[11:12:12 - 11:12:14]
your text editor and if you read the

[11:12:13 - 11:12:16]
answer it's pretty good it's pretty good

[11:12:14 - 11:12:19]
if you see that question and answer is

[11:12:16 - 11:12:21]
pretty good now you can use as it is as

[11:12:19 - 11:12:23]
it is for any kinds of exam any kinds of

[11:12:21 - 11:12:26]
interview you can prepare it's amazing

[11:12:23 - 11:12:28]
right okay so this is the entire

[11:12:26 - 11:12:30]
actually let's say notebook experiment

[11:12:28 - 11:12:32]
of our project now let's try to convert

[11:12:30 - 11:12:34]
everything in a modular coding modular

[11:12:32 - 11:12:35]
coding is I just need to write

[11:12:34 - 11:12:38]
everything in a function that is the

[11:12:35 - 11:12:39]
idea only okay I'll refer the same

[11:12:38 - 11:12:42]
notebook only I'll copy paste the same

[11:12:39 - 11:12:43]
code code but I'll write everything in a

[11:12:42 - 11:12:45]
function okay there is nothing new I'll

[11:12:43 - 11:12:47]
be doing so let's start the modular

[11:12:45 - 11:12:48]
coding so guys now let's start the

[11:12:47 - 11:12:50]
modular coding but before that let me

[11:12:48 - 11:12:52]
show you this answer. now see inside

[11:12:50 - 11:12:54]
answer. it has saved everything all the

[11:12:52 - 11:12:56]
question and answer but again it's not

[11:12:54 - 11:12:58]
readable so next time what I will do

[11:12:56 - 11:13:00]
I'll save everything in a CSV file uh in

[11:12:58 - 11:13:01]
one column I will add the question in

[11:13:00 - 11:13:03]
another column I add the answer okay

[11:13:01 - 11:13:07]
that would be more readable so what I'll

[11:13:03 - 11:13:08]
do guys now let me close everything so

[11:13:07 - 11:13:11]
left hand side I'm going to create a

[11:13:08 - 11:13:12]
folder and I'm going to name it it SRC

[11:13:11 - 11:13:15]
okay

[11:13:12 - 11:13:16]
SRC because this is going to be my

[11:13:15 - 11:13:19]
Source folder inside that I'm going to

[11:13:16 - 11:13:21]
write some helper related function that

[11:13:19 - 11:13:23]
means if you open up any kinds of let's

[11:13:21 - 11:13:25]
say um I mean real time implementation

[11:13:23 - 11:13:27]
of any kinds of package or any kinds of

[11:13:25 - 11:13:30]
project inside python let's say if I

[11:13:27 - 11:13:32]
open this one gas

[11:13:30 - 11:13:35]
GitHub you will see that they have also

[11:13:32 - 11:13:38]
created this kinds of folder

[11:13:35 - 11:13:40]
structure see this is the kasas now

[11:13:38 - 11:13:43]
kasas is also using see it is having one

[11:13:40 - 11:13:45]
root folder caras inside that they're

[11:13:43 - 11:13:47]
also having the source SRC and inside

[11:13:45 - 11:13:50]
SRC they have created all the let's say

[11:13:47 - 11:13:51]
utility related functionality that means

[11:13:50 - 11:13:53]
whatever functionality they need let's

[11:13:51 - 11:13:55]
activation function application back end

[11:13:53 - 11:13:56]
call backs they're writing everything

[11:13:55 - 11:13:58]
here and they're integrating in the

[11:13:56 - 11:14:00]
endpoint okay it is also having some

[11:13:58 - 11:14:02]
endpoint see API gen this is the

[11:14:00 - 11:14:04]
endpoint and they're importing it here

[11:14:02 - 11:14:06]
if you open it any kinds of endpoint

[11:14:04 - 11:14:07]
they're importing it here okay this is

[11:14:06 - 11:14:09]
called actually modular approach that

[11:14:07 - 11:14:10]
means instead of writing everything in

[11:14:09 - 11:14:12]
just one file we have to create a

[11:14:10 - 11:14:14]
separate separate file separate separate

[11:14:12 - 11:14:15]
function and whenever I need it I'll

[11:14:14 - 11:14:17]
just call it okay from that particular

[11:14:15 - 11:14:20]
let's say uh helper function this is the

[11:14:17 - 11:14:22]
idea so inside SRC I'm going to create a

[11:14:20 - 11:14:24]
file called underscore uncore

[11:14:22 - 11:14:25]
init

[11:14:24 - 11:14:28]
uncore

[11:14:25 - 11:14:29]
dop okay this is the Constructor file

[11:14:28 - 11:14:31]
because this folder would be considered

[11:14:29 - 11:14:33]
as my local package right now see this

[11:14:31 - 11:14:36]
is the modular concept guys this modular

[11:14:33 - 11:14:38]
concept I already explained u in my

[11:14:36 - 11:14:40]
python session okay so I think you know

[11:14:38 - 11:14:41]
so guys this is our YouTube channel so

[11:14:40 - 11:14:43]
here if you go to the playlist section I

[11:14:41 - 11:14:45]
already created complete python course

[11:14:43 - 11:14:47]
so here I already explained about

[11:14:45 - 11:14:50]
modular coding everything what is this

[11:14:47 - 11:14:52]
Constructor file what is modular coding

[11:14:50 - 11:14:53]
how we can write an any function in any

[11:14:52 - 11:14:55]
other file how we can import it in the

[11:14:53 - 11:14:57]
endpoint everything I have explained

[11:14:55 - 11:14:59]
just try to go ahead and watch that one

[11:14:57 - 11:15:00]
because modular concept is required here

[11:14:59 - 11:15:01]
okay I'm expecting you are already

[11:15:00 - 11:15:04]
familiar with this kind of python

[11:15:01 - 11:15:06]
concept fine so you can uh also see the

[11:15:04 - 11:15:08]
master op actually playlist so there

[11:15:06 - 11:15:10]
also I have covered lots of advanced

[11:15:08 - 11:15:11]
topic related python so that's why I'm

[11:15:10 - 11:15:13]
creating this Constructor file because

[11:15:11 - 11:15:15]
this folder would be considered as my

[11:15:13 - 11:15:16]
local package right now okay and inside

[11:15:15 - 11:15:19]
that I'm going to create

[11:15:16 - 11:15:22]
a uh file called

[11:15:19 - 11:15:26]
helper do PI and I'm going to create

[11:15:22 - 11:15:28]
another file called prom. Pi okay prom.

[11:15:26 - 11:15:30]
Pi so inside prom. Pi I'm going to

[11:15:28 - 11:15:32]
mention my prompt so let me show you so

[11:15:30 - 11:15:33]
the prompt actually I showed you in my

[11:15:32 - 11:15:35]
jupyter notebook so here I'm going to

[11:15:33 - 11:15:37]
just Define see this is my promp

[11:15:35 - 11:15:39]
template first prom template and this is

[11:15:37 - 11:15:40]
my defined promp template nothing new

[11:15:39 - 11:15:43]
guys I'm just copy pasting from my

[11:15:40 - 11:15:45]
notebook only see the same prompt I just

[11:15:43 - 11:15:48]
copy pasted because because prompt is a

[11:15:45 - 11:15:50]
changeable okay it's a changeable it's a

[11:15:48 - 11:15:51]
static one people can change any time so

[11:15:50 - 11:15:53]
that's why I have written inside prompt

[11:15:51 - 11:15:55]
prompt let's say file so user will open

[11:15:53 - 11:15:57]
the prom file and there actually they

[11:15:55 - 11:15:58]
will change so that they they don't need

[11:15:57 - 11:15:59]
to open the actual code code

[11:15:58 - 11:16:01]
implementation and inside that they

[11:15:59 - 11:16:03]
don't need to change okay I don't need

[11:16:01 - 11:16:06]
to hard code these other the value

[11:16:03 - 11:16:08]
that's why I kept this separate entity I

[11:16:06 - 11:16:11]
I hope it is clear now now let me close

[11:16:08 - 11:16:13]
it now inside help. Pi see whatever code

[11:16:11 - 11:16:15]
I have written so far that means I

[11:16:13 - 11:16:17]
loaded my documents I perform the

[11:16:15 - 11:16:20]
chunking operation then I created the

[11:16:17 - 11:16:21]
questions okay these are the thing I'll

[11:16:20 - 11:16:22]
be writing inside a function only so

[11:16:21 - 11:16:26]
inside

[11:16:22 - 11:16:29]
helper I created two function first of

[11:16:26 - 11:16:30]
all you have to import all the required

[11:16:29 - 11:16:32]
package you need I think remember these

[11:16:30 - 11:16:34]
are the packes actually I need I loaded

[11:16:32 - 11:16:36]
in my notebook then I need to load my

[11:16:34 - 11:16:38]
what I need to load my open and I have

[11:16:36 - 11:16:40]
to set as environment variable I think

[11:16:38 - 11:16:43]
you know got it right now the first

[11:16:40 - 11:16:46]
function I have written called file

[11:16:43 - 11:16:48]
processing same thing guys if I show you

[11:16:46 - 11:16:50]
the same thing I'm performing here first

[11:16:48 - 11:16:52]
of all I'm loading my documents I'm

[11:16:50 - 11:16:54]
adding all the let's say um I mean

[11:16:52 - 11:16:57]
content inside one variable I was

[11:16:54 - 11:16:58]
performing this one um I mean chunking

[11:16:57 - 11:17:02]
operation first of all I was doing with

[11:16:58 - 11:17:04]
the help of 1,000 token then next time I

[11:17:02 - 11:17:06]
was doing with the help of uh sorry

[11:17:04 - 11:17:08]
first of all I was doing the 10,000 okay

[11:17:06 - 11:17:10]
10,000 chunk that means one uh chunk I

[11:17:08 - 11:17:12]
want I want to consider as 10,000 then I

[11:17:10 - 11:17:15]
was doing for the 1,000 that means the

[11:17:12 - 11:17:17]
same experiment I did here remember same

[11:17:15 - 11:17:19]
experiment see same experiment I just

[11:17:17 - 11:17:21]
written inside a function only that's it

[11:17:19 - 11:17:22]
that is the difference only this so This

[11:17:21 - 11:17:24]
is called actually modular approach you

[11:17:22 - 11:17:26]
can also create a python class but as of

[11:17:24 - 11:17:28]
now it's a very let's say a small

[11:17:26 - 11:17:30]
implementation that's why python class

[11:17:28 - 11:17:32]
is not required but if you see the

[11:17:30 - 11:17:33]
actually very big implementation any ml

[11:17:32 - 11:17:35]
project or deep learning project you

[11:17:33 - 11:17:37]
will see that there I written a lots of

[11:17:35 - 11:17:40]
class let me show you so inside US Visa

[11:17:37 - 11:17:41]
if I open the components let let's say

[11:17:40 - 11:17:43]
data in this you can see I have written

[11:17:41 - 11:17:45]
a class that time okay so class is

[11:17:43 - 11:17:47]
recorded because you can see lots of

[11:17:45 - 11:17:48]
function I have to handle and whenever

[11:17:47 - 11:17:50]
you are having lots of function lots of

[11:17:48 - 11:17:51]
method that time you can write a class

[11:17:50 - 11:17:54]
but here I don't I don't have actually

[11:17:51 - 11:17:56]
lots of method I only have one to two

[11:17:54 - 11:17:58]
method okay that that's why I've just

[11:17:56 - 11:17:59]
written directly a function not a class

[11:17:58 - 11:18:01]
okay this is the idea so that's how you

[11:17:59 - 11:18:03]
have to design your own project whether

[11:18:01 - 11:18:05]
your project size is very huge or not if

[11:18:03 - 11:18:06]
it is us try to maintain the class

[11:18:05 - 11:18:08]
otherwise try to maintain the function

[11:18:06 - 11:18:10]
this is the difference only so if you

[11:18:08 - 11:18:12]
see any kinds of jni project so most of

[11:18:10 - 11:18:14]
the time actually we create let's say

[11:18:12 - 11:18:16]
inference on top of large language model

[11:18:14 - 11:18:19]
create a rag application on top of large

[11:18:16 - 11:18:21]
language model okay that's why the code

[11:18:19 - 11:18:23]
implementation is not big that much of

[11:18:21 - 11:18:24]
but whenever actually I'm creating ml

[11:18:23 - 11:18:26]
project DL project there actually we are

[11:18:24 - 11:18:28]
training our custom model that time

[11:18:26 - 11:18:30]
actually uh lots of method we have to

[11:18:28 - 11:18:31]
handle very big code base we have to

[11:18:30 - 11:18:33]
handle okay that's how we need class

[11:18:31 - 11:18:35]
concept this is the idea now you can see

[11:18:33 - 11:18:36]
guys I will get my object okay object

[11:18:35 - 11:18:38]
related my chunking you can see it will

[11:18:36 - 11:18:40]
gen give me document question gen that

[11:18:38 - 11:18:42]
means after performing the chunking and

[11:18:40 - 11:18:43]
document answers then okay both actually

[11:18:42 - 11:18:45]
it will

[11:18:43 - 11:18:47]
provide so questions in is nothing but

[11:18:45 - 11:18:49]
uh you can see I'm converting to the

[11:18:47 - 11:18:50]
documents this question whatever

[11:18:49 - 11:18:52]
questions actually I was getting so this

[11:18:50 - 11:18:53]
is the document question that means

[11:18:52 - 11:18:55]
after uh converting to the documents

[11:18:53 - 11:18:57]
whatever documents I'm getting this is

[11:18:55 - 11:18:58]
my document questions Z and after doing

[11:18:57 - 11:19:00]
the chunking this is my document

[11:18:58 - 11:19:01]
answerers gen so this question

[11:19:00 - 11:19:03]
generation and this document I need for

[11:19:01 - 11:19:05]
the answer generation okay the same

[11:19:03 - 11:19:09]
thing I perform in by notebook I think

[11:19:05 - 11:19:12]
remember see uh first of all I was using

[11:19:09 - 11:19:14]
document uh question gen just to

[11:19:12 - 11:19:17]
generate the question okay then I will

[11:19:14 - 11:19:18]
was using document answer gen just to

[11:19:17 - 11:19:20]
generate my answer okay I hope it is

[11:19:18 - 11:19:21]
clear so this function I have created

[11:19:20 - 11:19:25]
guys now the next function I have

[11:19:21 - 11:19:26]
created my LM pipeline that means I will

[11:19:25 - 11:19:28]
be using my large language model I'll be

[11:19:26 - 11:19:30]
creating the vector embeddings okay so

[11:19:28 - 11:19:32]
everything will happen inside this

[11:19:30 - 11:19:34]
function right now llm pipeline first of

[11:19:32 - 11:19:35]
all I'm calling the file uh file

[11:19:34 - 11:19:37]
processing that means this function

[11:19:35 - 11:19:39]
inside that whatever file user is giving

[11:19:37 - 11:19:40]
this file would be process and it will

[11:19:39 - 11:19:42]
give me document questions in and

[11:19:40 - 11:19:44]
document answers in I'm creating my

[11:19:42 - 11:19:45]
large language model creating the prompt

[11:19:44 - 11:19:47]
both prompt actually that means my

[11:19:45 - 11:19:49]
prompt question as well as the refined

[11:19:47 - 11:19:50]
prompt okay both I'm creating then I'm

[11:19:49 - 11:19:53]
first of all creating load summarization

[11:19:50 - 11:19:54]
I think remember load summarization I

[11:19:53 - 11:19:56]
was

[11:19:54 - 11:19:58]
creating okay this one so it will give

[11:19:56 - 11:20:00]
me the question it will give you the

[11:19:58 - 11:20:03]
question and I was creating the vector

[11:20:00 - 11:20:05]
embedding after that Vector embedding

[11:20:03 - 11:20:08]
then I was uh creating the vector index

[11:20:05 - 11:20:10]
you can see Vector index then I was uh I

[11:20:08 - 11:20:11]
was creating the retal keyway that time

[11:20:10 - 11:20:13]
okay it will generate you the answer

[11:20:11 - 11:20:14]
that means question answer that means

[11:20:13 - 11:20:16]
here you will get answer question

[11:20:14 - 11:20:19]
generation and filtered question list

[11:20:16 - 11:20:21]
okay both actually will get so this two

[11:20:19 - 11:20:23]
function I prepared here now let me save

[11:20:21 - 11:20:25]
now let me create the endpoint so here

[11:20:23 - 11:20:27]
what I will do I'll create a file I'll

[11:20:25 - 11:20:30]
name it as app.py

[11:20:27 - 11:20:31]
okay now this is going to be a Endo so

[11:20:30 - 11:20:34]
inside that I'm going to call this

[11:20:31 - 11:20:35]
function actually this llm pipeline

[11:20:34 - 11:20:37]
because inside llm pipeline I'm calling

[11:20:35 - 11:20:39]
my file preprocessing that's why I don't

[11:20:37 - 11:20:41]
need to call separately so let me open

[11:20:39 - 11:20:43]
it up but before that let me initialize

[11:20:41 - 11:20:44]
my first API related code so if you go

[11:20:43 - 11:20:47]
to the first API documentation guys you

[11:20:44 - 11:20:48]
will see this is the U start our code

[11:20:47 - 11:20:50]
that means this is the demo code they

[11:20:48 - 11:20:51]
will also give you so these are the

[11:20:50 - 11:20:53]
library you have to import one by one

[11:20:51 - 11:20:55]
okay then you have to initialize the

[11:20:53 - 11:20:56]
fast API so how to initialize the fast

[11:20:55 - 11:20:58]
API guys so that's how you can

[11:20:56 - 11:21:01]
initialize the fast

[11:20:58 - 11:21:03]
API okay see this is the code to install

[11:21:01 - 11:21:05]
the first API now here you have to

[11:21:03 - 11:21:06]
create two folder static and templates

[11:21:05 - 11:21:08]
inside that you have to create the uh

[11:21:06 - 11:21:10]
index.html file so inside template

[11:21:08 - 11:21:12]
folder you have to create a index.html

[11:21:10 - 11:21:14]
file because index.html file would be

[11:21:12 - 11:21:16]
your homepage okay that means the user

[11:21:14 - 11:21:17]
interface so you need some HTML code let

[11:21:16 - 11:21:19]
me show you I already created so guys as

[11:21:17 - 11:21:22]
you can see I already created one

[11:21:19 - 11:21:24]
template folder inside that I created a

[11:21:22 - 11:21:26]
uh HTML file okay now see inside that I

[11:21:24 - 11:21:27]
have written already HTML code okay that

[11:21:26 - 11:21:29]
means my front end part of my

[11:21:27 - 11:21:30]
application and how I created again I

[11:21:29 - 11:21:32]
referred that boot strapo side I think

[11:21:30 - 11:21:34]
you remember I previously I also used

[11:21:32 - 11:21:36]
the boot website if you don't know about

[11:21:34 - 11:21:38]
HTML code it's completely fine you can

[11:21:36 - 11:21:40]
skip this part you can use let's say any

[11:21:38 - 11:21:42]
other framework let's say stream later

[11:21:40 - 11:21:44]
on uh and see this HTML creation would

[11:21:42 - 11:21:45]
be done by the front end developer as of

[11:21:44 - 11:21:47]
now just to beautify this project I

[11:21:45 - 11:21:49]
created HTML okay from my end that's the

[11:21:47 - 11:21:50]
idea and there is another folder I

[11:21:49 - 11:21:52]
created called startic inside instatic I

[11:21:50 - 11:21:54]
created two folders called docs and

[11:21:52 - 11:21:56]
output see whatever documents user will

[11:21:54 - 11:21:58]
upload that PDF it will save inside

[11:21:56 - 11:21:59]
documents folder and whatever output you

[11:21:58 - 11:22:01]
will get from the let's say application

[11:21:59 - 11:22:03]
that means the question and answer in a

[11:22:01 - 11:22:05]
csb format because you can see I

[11:22:03 - 11:22:07]
imported the csb it will save inside

[11:22:05 - 11:22:09]
output folder and from output folder

[11:22:07 - 11:22:11]
actually I will get that particular

[11:22:09 - 11:22:13]
let's say csb output okay and inside

[11:22:11 - 11:22:15]
documents it will store the PDF this the

[11:22:13 - 11:22:16]
idea now this is the first API code guys

[11:22:15 - 11:22:19]
first API will handle each and

[11:22:16 - 11:22:20]
everything now I also need to import my

[11:22:19 - 11:22:23]
this one that means my LM pipeline let's

[11:22:20 - 11:22:25]
import so it is available inside uh I'll

[11:22:23 - 11:22:27]
call it from let's say

[11:22:25 - 11:22:32]
SRC

[11:22:27 - 11:22:35]
SRC uh dot let's say helper

[11:22:32 - 11:22:37]
import LM pipeline see it is inside

[11:22:35 - 11:22:39]
helper I need to import llm pipeline

[11:22:37 - 11:22:41]
because inside helper I have this LM

[11:22:39 - 11:22:43]
pipeline okay now see if you I'm

[11:22:41 - 11:22:45]
importing like that from SRC helper

[11:22:43 - 11:22:47]
import LM pipeline that means SRC is now

[11:22:45 - 11:22:49]
considering my local package and if I

[11:22:47 - 11:22:51]
want to use SRC as my local package what

[11:22:49 - 11:22:54]
I have to do I have to create one file

[11:22:51 - 11:22:56]
called setup.py okay setup. Pi so this

[11:22:54 - 11:22:58]
is the modular coding concept guys again

[11:22:56 - 11:23:00]
inside setup. Pi you have to write some

[11:22:58 - 11:23:03]
setup related code let me show

[11:23:00 - 11:23:04]
you so this is the code guys setup tool

[11:23:03 - 11:23:07]
first of all give the project name

[11:23:04 - 11:23:08]
version author name author email package

[11:23:07 - 11:23:11]
and install requires that means this

[11:23:08 - 11:23:13]
find package will try to find okay

[11:23:11 - 11:23:14]
wherever this Constructor file is

[11:23:13 - 11:23:15]
available this folder would be

[11:23:14 - 11:23:17]
considered as my local package now you

[11:23:15 - 11:23:19]
can see Constructor file is only present

[11:23:17 - 11:23:20]
inside SRC that means SRC would be

[11:23:19 - 11:23:24]
considered as my local package now see

[11:23:20 - 11:23:27]
if I show you pep list P list inside my

[11:23:24 - 11:23:29]
environment see SRC is not mentioned SRC

[11:23:27 - 11:23:31]
is not a package okay see SRC is not a

[11:23:29 - 11:23:33]
package but whenever I will install it

[11:23:31 - 11:23:35]
whenever I will set install this setup

[11:23:33 - 11:23:36]
you will see that this SRC would be

[11:23:35 - 11:23:38]
considered as my local package that

[11:23:36 - 11:23:39]
means there would be a package name

[11:23:38 - 11:23:41]
called genv project you can give any

[11:23:39 - 11:23:43]
name I've given genv project now let me

[11:23:41 - 11:23:44]
save and to install it in the

[11:23:43 - 11:23:48]
requirements you have to add one more

[11:23:44 - 11:23:50]
line called hypen space dot okay so this

[11:23:48 - 11:23:51]
hypen space dot will look for the

[11:23:50 - 11:23:53]
setup.py and it will install this

[11:23:51 - 11:23:55]
package okay let me show you now if I

[11:23:53 - 11:23:59]
again run let's

[11:23:55 - 11:23:59]
say pep

[11:24:00 - 11:24:06]
install henard requirement. txt see this

[11:24:05 - 11:24:09]
would be installed as my local package

[11:24:06 - 11:24:11]
right now done okay now see uh some egg

[11:24:09 - 11:24:13]
info file would be created okay whenever

[11:24:11 - 11:24:15]
this egg info file is created that means

[11:24:13 - 11:24:17]
this setup is successful now if I again

[11:24:15 - 11:24:19]
open up my

[11:24:17 - 11:24:22]
environment there's a pep

[11:24:19 - 11:24:25]
list now see uh there is a package it

[11:24:22 - 11:24:28]
has created gen project okay now see it

[11:24:25 - 11:24:29]
is my local package right now that means

[11:24:28 - 11:24:31]
this SRC would be considered as my local

[11:24:29 - 11:24:33]
package now I won't be getting any kinds

[11:24:31 - 11:24:34]
of error right now if I'm importing like

[11:24:33 - 11:24:36]
that okay so this is called actually

[11:24:34 - 11:24:38]
modular approach I think you got it so

[11:24:36 - 11:24:40]
here first of all user will upload one

[11:24:38 - 11:24:42]
PDF for this I have written a function

[11:24:40 - 11:24:45]
with the help of first API so this is

[11:24:42 - 11:24:46]
the function uh there is a route called

[11:24:45 - 11:24:49]
upload user will upload one let's say

[11:24:46 - 11:24:51]
file and uh this file would be saved

[11:24:49 - 11:24:54]
inside my documents uh inside Statics

[11:24:51 - 11:24:56]
documents okay it will save now there is

[11:24:54 - 11:24:59]
another uh function I will create called

[11:24:56 - 11:25:01]
get csb that means the complete results

[11:24:59 - 11:25:03]
okay I want to save as a CSV file so

[11:25:01 - 11:25:05]
this uh function will help me to do that

[11:25:03 - 11:25:07]
that means the file actually I'll be

[11:25:05 - 11:25:09]
receiving here this file I'll give where

[11:25:07 - 11:25:11]
in the llm pipeline and LM pipeline what

[11:25:09 - 11:25:13]
it will do it will pre-process it will

[11:25:11 - 11:25:16]
create the let's say prompt and

[11:25:13 - 11:25:18]
everything then it will give me the um

[11:25:16 - 11:25:19]
that me chain entire chain okay and that

[11:25:18 - 11:25:20]
chain actually I'll utilize here you can

[11:25:19 - 11:25:22]
see so you can see I'm getting the

[11:25:20 - 11:25:24]
entire chain and whatever question list

[11:25:22 - 11:25:26]
actually I'm having okay question list

[11:25:24 - 11:25:27]
I'll pass the question inside my chain

[11:25:26 - 11:25:29]
and it will give me all the answer and

[11:25:27 - 11:25:32]
this answer actually I'll save inside my

[11:25:29 - 11:25:33]
CSV file you can see right row okay CSV

[11:25:32 - 11:25:36]
writer right row and with for this

[11:25:33 - 11:25:38]
actually I'm using CSV package you can

[11:25:36 - 11:25:39]
see csb package very simple code guys

[11:25:38 - 11:25:41]
only have written inside a function only

[11:25:39 - 11:25:43]
you just need to go through this code

[11:25:41 - 11:25:44]
you will able to understand okay then I

[11:25:43 - 11:25:47]
need another function guys called

[11:25:44 - 11:25:48]
chat so this particular function what it

[11:25:47 - 11:25:50]
will do it will load the output file

[11:25:48 - 11:25:52]
that means the CSV file okay and it will

[11:25:50 - 11:25:54]
show it will return you okay it will

[11:25:52 - 11:25:56]
return that means you can also see the

[11:25:54 - 11:25:58]
complete PDF okay in the UI let me show

[11:25:56 - 11:26:00]
you how this application will look like

[11:25:58 - 11:26:01]
so now let me execute my first API code

[11:26:00 - 11:26:04]
see this is the first API code even on

[11:26:01 - 11:26:06]
run app this is the local host and this

[11:26:04 - 11:26:08]
is the port number 8080 okay now let me

[11:26:06 - 11:26:10]
save and now let me execute so I'll open

[11:26:08 - 11:26:10]
up my

[11:26:12 - 11:26:16]
terminal so python app.py

[11:26:16 - 11:26:20]
now see it is running let's me give the

[11:26:19 - 11:26:22]
allow permission now I'll go to my

[11:26:20 - 11:26:24]
Google

[11:26:22 - 11:26:27]
Chrome and here I'll search for local

[11:26:24 - 11:26:29]
host 080 see this is the user interface

[11:26:27 - 11:26:33]
guys okay now here you can upload a file

[11:26:29 - 11:26:37]
first of all let's say I'll upload this

[11:26:33 - 11:26:40]
file inside data let's say I will upload

[11:26:37 - 11:26:41]
this uh sdg first of all this

[11:26:40 - 11:26:43]
sustainable go

[11:26:41 - 11:26:48]
development and here I'll generate the

[11:26:43 - 11:26:48]
question and answer let's see

[11:26:50 - 11:26:55]
see it is generating this is the user

[11:26:53 - 11:26:58]
interface we created basic user

[11:26:55 - 11:27:00]
interface now see it's loading and how

[11:26:58 - 11:27:02]
this uh I mean uh loading is happening

[11:27:00 - 11:27:05]
animation is happening because I written

[11:27:02 - 11:27:07]
everything inside HTML

[11:27:05 - 11:27:09]
code so guys you can see I got the

[11:27:07 - 11:27:11]
output now left hand side you can see it

[11:27:09 - 11:27:13]
has rendered my entire PDF okay the PDF

[11:27:11 - 11:27:15]
I uploaded and right side it has given

[11:27:13 - 11:27:17]
me that uh CSV downloader now see if I

[11:27:15 - 11:27:21]
click here it will download the CSV file

[11:27:17 - 11:27:23]
see Q CSV now let's open the CSV uh how

[11:27:21 - 11:27:25]
I can open let's open it here so I'll

[11:27:23 - 11:27:27]
open it see this is the csb I don't have

[11:27:25 - 11:27:29]
Excel right now guys in my system that's

[11:27:27 - 11:27:31]
why I've open in a b code you can see

[11:27:29 - 11:27:33]
this is the question this side and that

[11:27:31 - 11:27:35]
side actually I have the answer you can

[11:27:33 - 11:27:38]
open in Excel viewer you see that it's a

[11:27:35 - 11:27:39]
beautiful format I have just stored okay

[11:27:38 - 11:27:41]
so that's how actually things are

[11:27:39 - 11:27:43]
happening okay now I think you got it

[11:27:41 - 11:27:45]
why we have written Des are the function

[11:27:43 - 11:27:47]
so this function will help you to render

[11:27:45 - 11:27:49]
your PDF documents as well as the it

[11:27:47 - 11:27:51]
will give you the download option okay

[11:27:49 - 11:27:52]
to download this particular PDF now

[11:27:51 - 11:27:54]
let's upload another PDF let's say I

[11:27:52 - 11:27:57]
will upload this Statistics one right

[11:27:54 - 11:27:57]
now now let's generate

[11:28:05 - 11:28:10]
again so guys as you can see I got the

[11:28:07 - 11:28:13]
results and this is my pdfi uploaded and

[11:28:10 - 11:28:15]
let's download the Qs B well see this is

[11:28:13 - 11:28:17]
the correlation answer and question I

[11:28:15 - 11:28:19]
got fine so yes guys this is the project

[11:28:17 - 11:28:21]
actually I hope you liked it and this is

[11:28:19 - 11:28:22]
like very interesting project guys if

[11:28:21 - 11:28:23]
you develop it I will feel like it's

[11:28:22 - 11:28:25]
like very interesting going forward

[11:28:23 - 11:28:26]
we'll be also implementing lots of

[11:28:25 - 11:28:28]
project no need to worry so in the next

[11:28:26 - 11:28:30]
video we'll be implementing another

[11:28:28 - 11:28:32]
Amazing Project very interesting project

[11:28:30 - 11:28:34]
called uh chatbot for any website that

[11:28:32 - 11:28:36]
means let's say I think you saw website

[11:28:34 - 11:28:38]
chatbot if you go go for any kinds of

[11:28:36 - 11:28:41]
website nowadays they're having their

[11:28:38 - 11:28:43]
chatbot integration with that okay so if

[11:28:41 - 11:28:45]
you ask let's say some question related

[11:28:43 - 11:28:46]
about the said about their let's say

[11:28:45 - 11:28:48]
product and service it will able to give

[11:28:46 - 11:28:50]
the answer so that means they're

[11:28:48 - 11:28:52]
replacing the human behind it previously

[11:28:50 - 11:28:53]
they used to let's say use one human

[11:28:52 - 11:28:56]
they used to receive the chat they used

[11:28:53 - 11:28:57]
to give the reply but nowaday they have

[11:28:56 - 11:28:59]
uh added the chat uh chatbot there

[11:28:57 - 11:29:01]
chatbot can handle all the answer if you

[11:28:59 - 11:29:03]
go to any of the website you will see

[11:29:01 - 11:29:06]
that so we'll be implementing these

[11:29:03 - 11:29:08]
kinds of application that means uh the

[11:29:06 - 11:29:10]
custom website chatboard it will only

[11:29:08 - 11:29:13]
work based on our website data not any

[11:29:10 - 11:29:14]
other let's say uh I mean question and

[11:29:13 - 11:29:16]
all fine this is what actually we'll be

[11:29:14 - 11:29:18]
implementing and this is kinds of rag

[11:29:16 - 11:29:19]
based application we'll be creating okay

[11:29:18 - 11:29:21]
that means we are using our custom data

[11:29:19 - 11:29:22]
on top of that we are adding about let's

[11:29:21 - 11:29:24]
say a large language model large

[11:29:22 - 11:29:27]
language model will try to refer that

[11:29:24 - 11:29:29]
data to provide you the answer fine so

[11:29:27 - 11:29:31]
in this implementation also I'm going to

[11:29:29 - 11:29:33]
use Lang chain large language model even

[11:29:31 - 11:29:34]
we'll be also using something called

[11:29:33 - 11:29:36]
Vector database okay with the help of

[11:29:34 - 11:29:39]
that actually we'll be implementing this

[11:29:36 - 11:29:40]
entire application but see this

[11:29:39 - 11:29:42]
application would be little bit Advanced

[11:29:40 - 11:29:43]
because here we'll be creating something

[11:29:42 - 11:29:45]
called rag based system okay like r

[11:29:43 - 11:29:47]
augmented generation this is the basic

[11:29:45 - 11:29:49]
rag so here we'll be using our custom

[11:29:47 - 11:29:51]
data so custom data wise actually we

[11:29:49 - 11:29:53]
we're going to use our website data that

[11:29:51 - 11:29:56]
means we'll be giving some website okay

[11:29:53 - 11:29:58]
website URL so U my langen will

[11:29:56 - 11:30:00]
automatically uh fix the information

[11:29:58 - 11:30:02]
from the website itself and this data

[11:30:00 - 11:30:03]
actually I'll give to my large language

[11:30:02 - 11:30:05]
model that means my llm would be

[11:30:03 - 11:30:06]
connected with this data and if you're

[11:30:05 - 11:30:08]
asking something related about this

[11:30:06 - 11:30:10]
website okay it will give you the answer

[11:30:08 - 11:30:11]
related that okay so this is the

[11:30:10 - 11:30:13]
application we be implementing so first

[11:30:11 - 11:30:14]
of all let me show you the architecture

[11:30:13 - 11:30:16]
like we are going to develop this

[11:30:14 - 11:30:17]
project then I think this part will be

[11:30:16 - 11:30:19]
clear so before showing you the

[11:30:17 - 11:30:22]
architecture diagram guys let me show

[11:30:19 - 11:30:24]
you one thing so let's say if I want to

[11:30:22 - 11:30:28]
open any kinds of website let's say I'll

[11:30:24 - 11:30:30]
open this open.com okay this one open

[11:30:28 - 11:30:33]
ai.com

[11:30:30 - 11:30:36]
so this is the open.com website now see

[11:30:33 - 11:30:38]
if I want to like see the if I want to

[11:30:36 - 11:30:40]
see the let's say XML page of this

[11:30:38 - 11:30:43]
website so what I can do I can give this

[11:30:40 - 11:30:45]
particular let's say uh U route here so

[11:30:43 - 11:30:45]
slash

[11:30:46 - 11:30:51]
sitemap um sitemap.xml so if you open

[11:30:49 - 11:30:54]
any website and if you give SL

[11:30:51 - 11:30:56]
sitemap.xml it will show you the entire

[11:30:54 - 11:30:58]
structure of the website let me show you

[11:30:56 - 11:31:00]
so guys here you can see uh this is the

[11:30:58 - 11:31:03]
page actually I got now see inside

[11:31:00 - 11:31:05]
opi.com okay inside open.com whatever

[11:31:03 - 11:31:07]
let's say content you are having

[11:31:05 - 11:31:09]
whatever content whatever sub Pages you

[11:31:07 - 11:31:10]
are having all the information is coming

[11:31:09 - 11:31:12]
here you can see if you just see it

[11:31:10 - 11:31:14]
carefully so it is having different

[11:31:12 - 11:31:15]
different URL okay different different

[11:31:14 - 11:31:17]
URL for the different different tab

[11:31:15 - 11:31:20]
let's say research for research actually

[11:31:17 - 11:31:23]
it is having one URL for GPT 4 40 it is

[11:31:20 - 11:31:25]
having one URL for safy company see

[11:31:23 - 11:31:26]
company I think I saw here so see this

[11:31:25 - 11:31:29]
is the company one okay this is the

[11:31:26 - 11:31:31]
company one you can see okay company one

[11:31:29 - 11:31:33]
so I think I showed you the company so

[11:31:31 - 11:31:34]
see this is the company URL so that

[11:31:33 - 11:31:36]
means it is having all the information

[11:31:34 - 11:31:38]
all the data whatever data whatever

[11:31:36 - 11:31:41]
content you can see in this website okay

[11:31:38 - 11:31:42]
everything is visible now in this XML

[11:31:41 - 11:31:44]
page now what I have to do I have to use

[11:31:42 - 11:31:46]
this concept

[11:31:44 - 11:31:48]
to extract the data that means I'll be

[11:31:46 - 11:31:50]
using Lang Chen data loader so inside

[11:31:48 - 11:31:51]
Lang Chen actually we are having website

[11:31:50 - 11:31:53]
loader with the help of that we can

[11:31:51 - 11:31:54]
easily load these are the content so

[11:31:53 - 11:31:55]
I'll tell you how we can extract the

[11:31:54 - 11:31:57]
information so this is the thing

[11:31:55 - 11:31:58]
actually will be doing now let me show

[11:31:57 - 11:32:00]
you the architecture diagram what we are

[11:31:58 - 11:32:02]
going to perform here so let me open up

[11:32:00 - 11:32:06]
my Blackboard see here first of all I

[11:32:02 - 11:32:09]
told you we'll be using website URL okay

[11:32:06 - 11:32:12]
website URL so from website URL what

[11:32:09 - 11:32:16]
we'll do we'll just get this sit

[11:32:12 - 11:32:19]
map uh sitemap.xml

[11:32:16 - 11:32:21]
okay this page and from this page

[11:32:19 - 11:32:23]
actually we'll be getting different

[11:32:21 - 11:32:24]
different sub Pages as well let's say

[11:32:23 - 11:32:27]
page

[11:32:24 - 11:32:29]
one then page

[11:32:27 - 11:32:31]
two page

[11:32:29 - 11:32:33]
three okay and so

[11:32:31 - 11:32:36]
on that's a multiple page actually will

[11:32:33 - 11:32:38]
get from here now what I have to do from

[11:32:36 - 11:32:41]
each and every page I have to extract

[11:32:38 - 11:32:44]
the documents that means the

[11:32:41 - 11:32:46]
data so it should be docs one let's docs

[11:32:44 - 11:32:48]
2 then after getting all the documents

[11:32:46 - 11:32:49]
we'll be using one embedding model I

[11:32:48 - 11:32:51]
think you know why embedding model

[11:32:49 - 11:32:52]
because I have to convert all the

[11:32:51 - 11:32:55]
documents to the embedding

[11:32:52 - 11:32:57]
representation okay so I'll pass all the

[11:32:55 - 11:33:01]
data to the embedding model okay and

[11:32:57 - 11:33:04]
embedding model will try to return uh

[11:33:01 - 11:33:06]
embedding Vector embedding so you will

[11:33:04 - 11:33:09]
get different different Vector embedding

[11:33:06 - 11:33:10]
let's say 0.2 0.3 0.5 and so on let's

[11:33:09 - 11:33:12]
say these are the vector representation

[11:33:10 - 11:33:14]
as of now just try to consider then with

[11:33:12 - 11:33:16]
all the embeddings what I have to do uh

[11:33:14 - 11:33:20]
I have to create

[11:33:16 - 11:33:21]
one uh cementing index okay cementing

[11:33:20 - 11:33:24]
index I think you know

[11:33:21 - 11:33:24]
build

[11:33:27 - 11:33:33]
cement

[11:33:29 - 11:33:34]
index okay build centic index then this

[11:33:33 - 11:33:36]
uh centic index that means this

[11:33:34 - 11:33:39]
embedding I will rest where I will to

[11:33:36 - 11:33:39]
the vector database let's say this is my

[11:33:39 - 11:33:41]
Vector

[11:33:39 - 11:33:43]
database so in this case actually I'm

[11:33:41 - 11:33:45]
going to use f you can use any other V

[11:33:43 - 11:33:48]
Vector DB let's say this is Vector

[11:33:45 - 11:33:49]
database okay I'll be using F you can

[11:33:48 - 11:33:52]
use anything you can use let's say

[11:33:49 - 11:33:54]
chroma DB you can use find con I'll tell

[11:33:52 - 11:33:56]
you how to use pine con chroma later on

[11:33:54 - 11:34:00]
I will also tell you now what will

[11:33:56 - 11:34:02]
happen so user will ask question okay

[11:34:00 - 11:34:05]
user will ask some question about the

[11:34:02 - 11:34:07]
website and this Vector DB will return

[11:34:05 - 11:34:10]
some rank results okay I think you know

[11:34:07 - 11:34:14]
what is rank results ranked

[11:34:10 - 11:34:15]
results okay rank results I'll get but

[11:34:14 - 11:34:17]
what I have to do I have to initialize

[11:34:15 - 11:34:19]
my large language model because with the

[11:34:17 - 11:34:21]
help of llm only I'll able to get the

[11:34:19 - 11:34:22]
correct response so what I will do I'll

[11:34:21 - 11:34:25]
pass this rank res to my large language

[11:34:22 - 11:34:28]
model as well as this quy also okay and

[11:34:25 - 11:34:31]
this llm will give you the actual

[11:34:28 - 11:34:32]
response okay actual response so this is

[11:34:31 - 11:34:35]
the complete idea okay this is the

[11:34:32 - 11:34:38]
complete architecture of our application

[11:34:35 - 11:34:41]
okay and this is called actually rag

[11:34:38 - 11:34:43]
okay rank that means retable augmented

[11:34:41 - 11:34:44]
generation because here we are inting

[11:34:43 - 11:34:46]
our customer from data okay and we're

[11:34:44 - 11:34:48]
integrating our large language model

[11:34:46 - 11:34:51]
with that uh data that means this is

[11:34:48 - 11:34:55]
called actually knowledge base okay

[11:34:51 - 11:34:57]
knowledge B right now okay in knowledge

[11:34:55 - 11:34:59]
base so now let's open up our collab

[11:34:57 - 11:35:01]
notebook and try to install everything

[11:34:59 - 11:35:02]
and let's implement this project so guys

[11:35:01 - 11:35:04]
as you can see I open up my collab

[11:35:02 - 11:35:07]
notebook so first thing just try to

[11:35:04 - 11:35:08]
change the Run Tye so here run time just

[11:35:07 - 11:35:11]
keep it as CPU only because here we'll

[11:35:08 - 11:35:13]
be using open a model but if you want to

[11:35:11 - 11:35:15]
use let's say any other open source

[11:35:13 - 11:35:17]
Source model that time you can use GPU

[11:35:15 - 11:35:19]
okay that time so as of now let's keep

[11:35:17 - 11:35:20]
it CPU only so later on I will also show

[11:35:19 - 11:35:22]
you how we can use a new open source

[11:35:20 - 11:35:24]
large language model okay now let me

[11:35:22 - 11:35:26]
connect this notebook so here first of

[11:35:24 - 11:35:28]
all you have to install some package so

[11:35:26 - 11:35:30]
you can see I'm installing Lang chain

[11:35:28 - 11:35:32]
langen Community Pi PDF then sentence

[11:35:30 - 11:35:34]
Transformer okay openi Tik Tok and these

[11:35:32 - 11:35:35]
are the things so these are my

[11:35:34 - 11:35:37]
dependency package actually I need so

[11:35:35 - 11:35:39]
let me install all of

[11:35:37 - 11:35:41]
them so some of the package actually you

[11:35:39 - 11:35:43]
don't need I just written additionally

[11:35:41 - 11:35:44]
because later on this project I will

[11:35:43 - 11:35:46]
show you how we can Implement with the

[11:35:44 - 11:35:48]
help of Open Source large language model

[11:35:46 - 11:35:50]
okay that time actually this sentence

[11:35:48 - 11:35:52]
Transformer is required because if I

[11:35:50 - 11:35:53]
want to use any let's say open source

[11:35:52 - 11:35:55]
embedding model that time this is

[11:35:53 - 11:35:57]
required so as of now let's install

[11:35:55 - 11:35:59]
everything then apart from that I also

[11:35:57 - 11:36:02]
need to install some more package so

[11:35:59 - 11:36:03]
tick token fire CPU and unstructured

[11:36:02 - 11:36:05]
let's say if I want to load the website

[11:36:03 - 11:36:07]
now website data that time I need this

[11:36:05 - 11:36:09]
package unstructured because it's

[11:36:07 - 11:36:11]
unstructured data and again I'm going to

[11:36:09 - 11:36:13]
use f Vector database okay that's why F

[11:36:11 - 11:36:15]
CPU I'm installing so let me install all

[11:36:13 - 11:36:15]
of them

[11:36:16 - 11:36:22]
then I also need to install NPI and nltk

[11:36:19 - 11:36:23]
okay so let me install because these are

[11:36:22 - 11:36:25]
some dependency package if I want to

[11:36:23 - 11:36:28]
extract the information from the website

[11:36:25 - 11:36:29]
so Lang needs these are the dependency

[11:36:28 - 11:36:31]
okay so that is why actually we are

[11:36:29 - 11:36:33]
installing

[11:36:31 - 11:36:35]
everything now see uh after installing

[11:36:33 - 11:36:37]
this nay ltk it will tell you restart

[11:36:35 - 11:36:38]
the session so let me restart the

[11:36:37 - 11:36:40]
session so it will restart the session

[11:36:38 - 11:36:42]
then after that we'll be importing all

[11:36:40 - 11:36:44]
the necessary Library we need you can

[11:36:42 - 11:36:46]
see I'm loading unstructured URL loader

[11:36:44 - 11:36:47]
from langin so with the help of

[11:36:46 - 11:36:49]
unstructured URL loader we'll be loading

[11:36:47 - 11:36:51]
this data okay here we'll be giving the

[11:36:49 - 11:36:54]
URL website URL it will automatically

[11:36:51 - 11:36:55]
extract all the information and we'll be

[11:36:54 - 11:36:57]
performing the chunking for this we are

[11:36:55 - 11:36:58]
using character text spitter open

[11:36:57 - 11:37:00]
embedding we'll be using just to convert

[11:36:58 - 11:37:01]
my uh data to the embedding

[11:37:00 - 11:37:03]
representation we'll be using openi

[11:37:01 - 11:37:06]
large language model GPT 3.5 turbo

[11:37:03 - 11:37:08]
that's why we are using CH openi F this

[11:37:06 - 11:37:10]
the vector DB rable QA with Source CH

[11:37:08 - 11:37:12]
that means it will create the QA object

[11:37:10 - 11:37:13]
that means the chain object okay and

[11:37:12 - 11:37:15]
hugging face embedding as of now I don't

[11:37:13 - 11:37:16]
need I'll just try to remove it okay

[11:37:15 - 11:37:18]
later on I'll tell you how we can use

[11:37:16 - 11:37:20]
the hugging p as well now let me import

[11:37:18 - 11:37:20]
all of the

[11:37:20 - 11:37:25]
package so it's working fine there is no

[11:37:22 - 11:37:29]
error now let me uh download this uh two

[11:37:25 - 11:37:30]
thing like p n KT and you have to

[11:37:29 - 11:37:33]
download another thing a percept

[11:37:30 - 11:37:37]
perception tagger okay so this one you

[11:37:33 - 11:37:37]
have to download from the nltk so let me

[11:37:40 - 11:37:44]
download then after that I will set my

[11:37:42 - 11:37:46]
open API key because here I'm going to

[11:37:44 - 11:37:47]
use open large language model definitely

[11:37:46 - 11:37:50]
you need the

[11:37:47 - 11:37:52]
key now I'm going to pass different

[11:37:50 - 11:37:53]
different website URL now you can see I

[11:37:52 - 11:37:55]
have just collected different different

[11:37:53 - 11:37:57]
website URL let me open all of them let

[11:37:55 - 11:37:59]
me show you so these are the website

[11:37:57 - 11:38:01]
actually I'm going to refer so this is

[11:37:59 - 11:38:03]
one uh blog website uh medium website

[11:38:01 - 11:38:05]
you can see and the content about paper

[11:38:03 - 11:38:07]
review Lama 2 open foundation fine tune

[11:38:05 - 11:38:09]
chat model okay now if you just read it

[11:38:07 - 11:38:11]
you will see lots of content related

[11:38:09 - 11:38:14]
Lama to okay now there is another

[11:38:11 - 11:38:16]
website datab I'm using introducing MPT

[11:38:14 - 11:38:18]
7B a new standard for the open source

[11:38:16 - 11:38:21]
Community usable llm so this is another

[11:38:18 - 11:38:22]
large language model now you can see uh

[11:38:21 - 11:38:24]
the information is written about this

[11:38:22 - 11:38:26]
large language model that means we'll be

[11:38:24 - 11:38:28]
extracting these other the data and

[11:38:26 - 11:38:30]
we'll be creating one chatbot it will uh

[11:38:28 - 11:38:32]
provide and that chatbot actually will

[11:38:30 - 11:38:34]
be able to give the answer related these

[11:38:32 - 11:38:37]
are the topic okay the topic actually

[11:38:34 - 11:38:41]
you have feed let's say Lama 2 then MPT

[11:38:37 - 11:38:44]
7B then uh stability. a okay so this is

[11:38:41 - 11:38:45]
another website then uh you can see vuna

[11:38:44 - 11:38:47]
so this is another website okay so these

[11:38:45 - 11:38:50]
are the information actually I want to

[11:38:47 - 11:38:51]
see so I have given all the website link

[11:38:50 - 11:38:53]
so here you can pass any any kinds of

[11:38:51 - 11:38:54]
website link you can pass any kinds of

[11:38:53 - 11:38:56]
website link let's say you have one

[11:38:54 - 11:38:58]
website your own website you can give

[11:38:56 - 11:38:59]
the website link here so this will

[11:38:58 - 11:39:01]
automatically extract your website

[11:38:59 - 11:39:02]
information and you can create your

[11:39:01 - 11:39:06]
website chatbot okay on top of it this

[11:39:02 - 11:39:07]
is amazing now let me initialize the URL

[11:39:06 - 11:39:09]
so it suppos actually multiple website

[11:39:07 - 11:39:11]
URL it's not like that it only supports

[11:39:09 - 11:39:14]
one URL no multiple URL you can give

[11:39:11 - 11:39:16]
here now let me

[11:39:14 - 11:39:18]
uh extract the documents with the help

[11:39:16 - 11:39:20]
of unstructured URL loader inside that

[11:39:18 - 11:39:21]
you have to pass all the URL and it will

[11:39:20 - 11:39:24]
automatically extract all the

[11:39:21 - 11:39:24]
information let me show

[11:39:25 - 11:39:29]
you now if I print the

[11:39:29 - 11:39:35]
data all the information it has

[11:39:32 - 11:39:38]
extracted from all the website see okay

[11:39:35 - 11:39:40]
amazing now if I show you the length

[11:39:38 - 11:39:42]
you'll see that four documents it has

[11:39:40 - 11:39:46]
returned why four documents because I

[11:39:42 - 11:39:47]
have given four website 1 2 3 4 that

[11:39:46 - 11:39:49]
means four website information I'm

[11:39:47 - 11:39:51]
having right now and this is in the

[11:39:49 - 11:39:52]
document format got it because I already

[11:39:51 - 11:39:53]
told if you're loading anything with the

[11:39:52 - 11:39:55]
help of lch that should be document

[11:39:53 - 11:39:57]
format always so now I think this part

[11:39:55 - 11:40:00]
is clear so we have extracted the

[11:39:57 - 11:40:01]
content successfully now what I have to

[11:40:00 - 11:40:02]
do I have to create the chunks okay I

[11:40:01 - 11:40:04]
have to create the chunks different

[11:40:02 - 11:40:06]
different chunks you can see these are

[11:40:04 - 11:40:08]
different different chunks so I think I

[11:40:06 - 11:40:11]
forget to mention this chunking here so

[11:40:08 - 11:40:13]
it should create a chunk okay

[11:40:11 - 11:40:14]
chunk okay all the chunks that means it

[11:40:13 - 11:40:15]
will create all the chunks this chunks

[11:40:14 - 11:40:17]
actually I'll give to the embedding

[11:40:15 - 11:40:19]
model okay now let me create the chunk

[11:40:17 - 11:40:22]
here so to create the chunks actually

[11:40:19 - 11:40:23]
I'll be using character text splitter

[11:40:22 - 11:40:25]
see these are some repetitive code again

[11:40:23 - 11:40:27]
again I'm using previously i al already

[11:40:25 - 11:40:29]
taught you what is character Tex bitter

[11:40:27 - 11:40:30]
what is CH size what is CH overlap

[11:40:29 - 11:40:32]
everything I taught you even in the

[11:40:30 - 11:40:33]
vector database session so this is very

[11:40:32 - 11:40:35]
much important session guys just try to

[11:40:33 - 11:40:37]
complete the session first so you can

[11:40:35 - 11:40:38]
see character text ler separator is

[11:40:37 - 11:40:41]
equal to SL in because you can see Slash

[11:40:38 - 11:40:43]
in is there okay sometimes so slash

[11:40:41 - 11:40:45]
would be the separator so here SL n

[11:40:43 - 11:40:49]
would be the separator it will separate

[11:40:45 - 11:40:52]
by slash now CH size 1,000 chks overlap

[11:40:49 - 11:40:55]
200 okay now let me create my text

[11:40:52 - 11:40:57]
splitter now inside that I'm going to

[11:40:55 - 11:41:00]
provide my

[11:40:57 - 11:41:02]
data now it will give you chunks now let

[11:41:00 - 11:41:05]
me see how many chunks I got so here I

[11:41:02 - 11:41:07]
got 86 chunks if you want to see them

[11:41:05 - 11:41:09]
simply

[11:41:07 - 11:41:11]
just uh print like that let's I want to

[11:41:09 - 11:41:12]
see the first chunks this is the first

[11:41:11 - 11:41:16]
chunks let's I want to see the second

[11:41:12 - 11:41:16]
Chun as as well I can also see

[11:41:16 - 11:41:21]
that see second chunks as well and you

[11:41:19 - 11:41:23]
can see it is also giving me the source

[11:41:21 - 11:41:25]
URL like from which URL it is giving you

[11:41:23 - 11:41:27]
the data okay now we'll be initializing

[11:41:25 - 11:41:29]
the embedding model because you can see

[11:41:27 - 11:41:30]
the architecture now I have to download

[11:41:29 - 11:41:31]
the embedding model then I have to

[11:41:30 - 11:41:33]
convert everything to the embedding

[11:41:31 - 11:41:37]
representation so let's use the open

[11:41:33 - 11:41:38]
embedding now let's test whether it is

[11:41:37 - 11:41:39]
able to convert to the embedding

[11:41:38 - 11:41:41]
representation or not so here I'm

[11:41:39 - 11:41:42]
calling the embedding model and I'm

[11:41:41 - 11:41:44]
passing one sentence hello world so it

[11:41:42 - 11:41:47]
should give me the embeding results let

[11:41:44 - 11:41:49]
me show you and the vector Dimension is

[11:41:47 - 11:41:51]
uh 1

[11:41:49 - 11:41:53]
1536 okay this is the dimension now if I

[11:41:51 - 11:41:55]
show you the numerical representation of

[11:41:53 - 11:41:56]
this sentence so this is the numerical

[11:41:55 - 11:41:58]
representation that means this is my

[11:41:56 - 11:41:59]
Vector embedding okay so we'll be

[11:41:58 - 11:42:03]
following the same concept now let me

[11:41:59 - 11:42:04]
convert my um text to the embeddings but

[11:42:03 - 11:42:05]
for this actually I'm going to use f

[11:42:04 - 11:42:07]
Vector database because whatever

[11:42:05 - 11:42:09]
embeddings I'll be generating I'll store

[11:42:07 - 11:42:11]
in the F okay F Vector database and F is

[11:42:09 - 11:42:13]
a local Vector database I think you know

[11:42:11 - 11:42:15]
so here I'm giving my text chunks and my

[11:42:13 - 11:42:17]
embedding okay embedding model now guys

[11:42:15 - 11:42:18]
see this is my centic Index right now

[11:42:17 - 11:42:20]
okay this is my centic index that means

[11:42:18 - 11:42:21]
my Vector Index right now okay now what

[11:42:20 - 11:42:23]
I have to do I have to connect my large

[11:42:21 - 11:42:25]
language model so let's initialize my

[11:42:23 - 11:42:27]
large language model so here I'm going

[11:42:25 - 11:42:29]
to use open a large language model by

[11:42:27 - 11:42:31]
default it will use gbt 3.5 turbo now

[11:42:29 - 11:42:33]
let's test our large language model

[11:42:31 - 11:42:34]
whether it is able to generate or not so

[11:42:33 - 11:42:36]
here I've given a prompt please provide

[11:42:34 - 11:42:39]
a concise summary of Harry Potter book

[11:42:36 - 11:42:41]
okay now if I execute it should give me

[11:42:39 - 11:42:42]
the summary of Harry Potter book see

[11:42:41 - 11:42:44]
this is the summary of Harry Potter book

[11:42:42 - 11:42:47]
okay it has given me great that means it

[11:42:44 - 11:42:49]
is working fine now with the help of llm

[11:42:47 - 11:42:50]
as well as my Vector database I have to

[11:42:49 - 11:42:52]
create my chain so for this I'll be

[11:42:50 - 11:42:53]
using retal keyway with Source chain

[11:42:52 - 11:42:55]
okay I think I already imported from the

[11:42:53 - 11:42:56]
Lang chain and inside that I'm passing

[11:42:55 - 11:42:58]
my large language model as well as my

[11:42:56 - 11:43:01]
Vector database okay and this will give

[11:42:58 - 11:43:02]
me the chain now inside chain actually I

[11:43:01 - 11:43:05]
can ask any kinds of question right now

[11:43:02 - 11:43:08]
see question is equal to how good is

[11:43:05 - 11:43:12]
vuna so here I'm asking related vuna

[11:43:08 - 11:43:13]
okay this particular vuna so vuna data I

[11:43:12 - 11:43:14]
have already given to my large language

[11:43:13 - 11:43:16]
model I think remember it is already

[11:43:14 - 11:43:20]
available inside my knowledge base now

[11:43:16 - 11:43:20]
it should give me the answer okay let's

[11:43:25 - 11:43:30]
see okay now if I want to see the answer

[11:43:28 - 11:43:32]
so I'll just call result inside that I I

[11:43:30 - 11:43:34]
want to only extract the answer okay now

[11:43:32 - 11:43:36]
let me show you see vuna has shown

[11:43:34 - 11:43:38]
competitive performance compared to the

[11:43:36 - 11:43:40]
others model like Stanford Alpha okay

[11:43:38 - 11:43:41]
that means if you read it okay if you

[11:43:40 - 11:43:43]
read this documentation if you read this

[11:43:41 - 11:43:45]
documentation you will see that uh that

[11:43:43 - 11:43:46]
is what actually they're telling that

[11:43:45 - 11:43:49]
means amazingly it is able to give me

[11:43:46 - 11:43:52]
the answer right now great now let's ask

[11:43:49 - 11:43:52]
any other

[11:43:52 - 11:43:56]
question let's say the next question

[11:43:54 - 11:43:58]
I'll be asking about Lama 2 Lama 2 how

[11:43:56 - 11:44:00]
does Lama 2 outperforms other model okay

[11:43:58 - 11:44:03]
let's ask this question and whatever

[11:44:00 - 11:44:03]
answer I will get I'll also print it

[11:44:04 - 11:44:08]
here now see L 2 model out for from

[11:44:07 - 11:44:10]
others models in various categories

[11:44:08 - 11:44:12]
including MPT models and similar size

[11:44:10 - 11:44:16]
and so on okay now see it is referring

[11:44:12 - 11:44:18]
the L 2 right now uh yeah Lama 2 great

[11:44:16 - 11:44:22]
now let me ask another question so I'll

[11:44:18 - 11:44:23]
be asking about MPT uh this one MPT 7B

[11:44:22 - 11:44:27]
model and whatever result actually I

[11:44:23 - 11:44:30]
will get I'll just showcase it

[11:44:27 - 11:44:33]
here see again I got the amazing

[11:44:30 - 11:44:35]
response okay now see it is referring my

[11:44:33 - 11:44:37]
website data that means my custom data

[11:44:35 - 11:44:39]
not any other data okay this is the main

[11:44:37 - 11:44:40]
thing here we have developed now if

[11:44:39 - 11:44:42]
you're asking any other question let's

[11:44:40 - 11:44:44]
say tell me about India it won't be

[11:44:42 - 11:44:46]
giving the answer because here we have

[11:44:44 - 11:44:48]
created the custom chatbot it will only

[11:44:46 - 11:44:51]
refer my uh data the custom data I have

[11:44:48 - 11:44:52]
given now here I can create a while loop

[11:44:51 - 11:44:54]
and I can continuously ask the question

[11:44:52 - 11:44:57]
okay so you can see I'm taking the

[11:44:54 - 11:44:59]
prompt from the user and if it is exit

[11:44:57 - 11:45:00]
I'm I'll do the exit operation otherwise

[11:44:59 - 11:45:02]
I'll continue and I'll will keep on

[11:45:00 - 11:45:04]
asking the question and it will generate

[11:45:02 - 11:45:06]
the answer okay let me show you see it

[11:45:04 - 11:45:08]
is asking the question so what I can

[11:45:06 - 11:45:11]
give I can give the same prompt again

[11:45:08 - 11:45:14]
copy and here I can pass and let me

[11:45:11 - 11:45:16]
press enter

[11:45:14 - 11:45:18]
now what you can do guys you can convert

[11:45:16 - 11:45:20]
this project to the web interface that

[11:45:18 - 11:45:21]
means web application I think I showed

[11:45:20 - 11:45:24]
you how we can use different different

[11:45:21 - 11:45:26]
let's say python package like flas then

[11:45:24 - 11:45:28]
fast API so this should be your task

[11:45:26 - 11:45:29]
guys try to create one web application

[11:45:28 - 11:45:31]
at least basic web application that user

[11:45:29 - 11:45:33]
will give give that prompt and it will

[11:45:31 - 11:45:34]
provide the answer okay that's it now

[11:45:33 - 11:45:35]
see it has given me the answer okay now

[11:45:34 - 11:45:37]
again it is asking another question now

[11:45:35 - 11:45:40]
let's say if I give exit it will exit

[11:45:37 - 11:45:42]
the application sorry it should be exit

[11:45:40 - 11:45:43]
only but I have given exit parenthesis

[11:45:42 - 11:45:45]
now see if I if I'm giving this prompt

[11:45:43 - 11:45:47]
it is telling that text provided does

[11:45:45 - 11:45:48]
not seems to be relevant to the

[11:45:47 - 11:45:50]
questions now see this question actually

[11:45:48 - 11:45:52]
doesn't have any context whatever

[11:45:50 - 11:45:53]
knowledge base it is referring that's

[11:45:52 - 11:45:55]
why I told you it it it won't be able to

[11:45:53 - 11:45:58]
give you any other information now if I

[11:45:55 - 11:46:00]
give exit right

[11:45:58 - 11:46:02]
now it should exit the application see

[11:46:00 - 11:46:04]
okay so that's how we can create any

[11:46:02 - 11:46:06]
kinds of custom website with the help of

[11:46:04 - 11:46:08]
our custom data now what you can do you

[11:46:06 - 11:46:09]
can open up any kinds of website and you

[11:46:08 - 11:46:11]
can implement this project guys okay and

[11:46:09 - 11:46:13]
later on I'll also tell you how we can

[11:46:11 - 11:46:14]
use the open source language model okay

[11:46:13 - 11:46:15]
and with that how we can create this

[11:46:14 - 11:46:17]
application so with that guys thank you

[11:46:15 - 11:46:19]
so much uh for watching this video and

[11:46:17 - 11:46:21]
try to complete that task try to convert

[11:46:19 - 11:46:23]
this application to the web interface as

[11:46:21 - 11:46:25]
well so guys as of now we have worked

[11:46:23 - 11:46:27]
with open AI based large language model

[11:46:25 - 11:46:29]
which is nothing but uh GPD okay so we

[11:46:27 - 11:46:31]
have seen like how to use GPT series uh

[11:46:29 - 11:46:33]
to build these kinds of Genera VI

[11:46:31 - 11:46:36]
application and one thing I think you

[11:46:33 - 11:46:38]
have seen there like GPT is not free so

[11:46:36 - 11:46:40]
uh you need to pay for it so whenever

[11:46:38 - 11:46:42]
you are using open a API uh you need to

[11:46:40 - 11:46:44]
pay some money okay for that uh but

[11:46:42 - 11:46:46]
let's say if you don't want to spend uh

[11:46:44 - 11:46:48]
this much of money here so what you can

[11:46:46 - 11:46:50]
do you can use something called open

[11:46:48 - 11:46:51]
source large language model so in the

[11:46:50 - 11:46:53]
market actually we have lots of Open

[11:46:51 - 11:46:55]
Source large language models are

[11:46:53 - 11:46:57]
available so so if you are using it so

[11:46:55 - 11:46:59]
you don't need to pay any money for this

[11:46:57 - 11:47:00]
so you can directly use them and it is

[11:46:59 - 11:47:03]
completely open source and for

[11:47:00 - 11:47:04]
commercial use cases as well you can

[11:47:03 - 11:47:06]
either do research on top of it you can

[11:47:04 - 11:47:08]
either uh create a commercial

[11:47:06 - 11:47:10]
application on top of it it's completely

[11:47:08 - 11:47:13]
free for you okay so uh in this video

[11:47:10 - 11:47:14]
actually uh I'll be discussing about uh

[11:47:13 - 11:47:16]
like open source large language model

[11:47:14 - 11:47:18]
like what is open source large language

[11:47:16 - 11:47:20]
model okay and what are the open source

[11:47:18 - 11:47:22]
large language model we have and from

[11:47:20 - 11:47:24]
them actually I'll be discussing some of

[11:47:22 - 11:47:26]
them uh like most popular uh used open

[11:47:24 - 11:47:28]
source large language model and it is

[11:47:26 - 11:47:30]
like very powerful okay and I will also

[11:47:28 - 11:47:32]
show you how we can uh like build gener

[11:47:30 - 11:47:33]
VI application with the help of these

[11:47:32 - 11:47:35]
kinds of Open Source large language

[11:47:33 - 11:47:36]
model okay so it would be completely

[11:47:35 - 11:47:38]
amazing video so make sure you are

[11:47:36 - 11:47:40]
watching this video till the end don't

[11:47:38 - 11:47:42]
skip any part of this video otherwise uh

[11:47:40 - 11:47:44]
you might get confused for sure right so

[11:47:42 - 11:47:46]
so yes guys uh let's start with our uh

[11:47:44 - 11:47:48]
video so guys here we'll be learning

[11:47:46 - 11:47:50]
like most used and most popular very

[11:47:48 - 11:47:53]
powerful large language model uh here

[11:47:50 - 11:47:56]
you can see we have meta Lama 2 so this

[11:47:53 - 11:47:58]
is the uh like model from meta AI I

[11:47:56 - 11:48:00]
think you know uh like we also call them

[11:47:58 - 11:48:02]
Facebook so they have introduced this

[11:48:00 - 11:48:05]
model called Lama 2 it has another

[11:48:02 - 11:48:08]
version called Lama 1 but uh uh Lama 1

[11:48:05 - 11:48:10]
is for like resarch purpose they have

[11:48:08 - 11:48:12]
given the permission but uh you can't

[11:48:10 - 11:48:13]
use Lama one for the commercial use

[11:48:12 - 11:48:16]
cases so for this actually they have

[11:48:13 - 11:48:17]
open source this Lama 2 model so you can

[11:48:16 - 11:48:19]
either uh do research on top of it

[11:48:17 - 11:48:20]
either you can create commercial

[11:48:19 - 11:48:22]
application it's completely fine then

[11:48:20 - 11:48:24]
from Google side we have another large

[11:48:22 - 11:48:26]
language model called um Google Palm 2

[11:48:24 - 11:48:28]
so this is uh one of the very powerful

[11:48:26 - 11:48:30]
large language model okay and it is

[11:48:28 - 11:48:33]
completely open source and free then we

[11:48:30 - 11:48:35]
have another like most used large

[11:48:33 - 11:48:37]
language model called Falcon so Falcon

[11:48:35 - 11:48:38]
had lots of variant I'll show you like

[11:48:37 - 11:48:40]
whenever I'll be discussing like Falcon

[11:48:38 - 11:48:41]
I will tell you like what the variant it

[11:48:40 - 11:48:44]
has actually so it has different

[11:48:41 - 11:48:46]
different uh parameter variant okay even

[11:48:44 - 11:48:48]
meta Lama 2 has different different

[11:48:46 - 11:48:50]
variant okay I will tell you whenever I

[11:48:48 - 11:48:53]
will discussing about this Lama 2 and

[11:48:50 - 11:48:55]
all okay so these are the most used and

[11:48:53 - 11:48:56]
most popular large language model I'll

[11:48:55 - 11:48:59]
be discussing like how we can use it

[11:48:56 - 11:49:00]
okay and how we can create gener

[11:48:59 - 11:49:02]
application on top of it I will be

[11:49:00 - 11:49:04]
discussing each and everything so apart

[11:49:02 - 11:49:05]
from that we have lots of large language

[11:49:04 - 11:49:08]
model are available in the market and it

[11:49:05 - 11:49:10]
is completely open source so guys I

[11:49:08 - 11:49:12]
found one GitHub repository so there

[11:49:10 - 11:49:15]
actually that guy collected lots of Open

[11:49:12 - 11:49:17]
Source large language model list and uh

[11:49:15 - 11:49:19]
he has created one uh read me file there

[11:49:17 - 11:49:20]
so I'll show you that one like what are

[11:49:19 - 11:49:22]
the open source large language models

[11:49:20 - 11:49:23]
are available in the market so if you

[11:49:22 - 11:49:26]
also want to explore that one you can

[11:49:23 - 11:49:28]
also go ahead and check it out okay so

[11:49:26 - 11:49:30]
if you learn like how to use meta Lama

[11:49:28 - 11:49:32]
to Google Pam to Falcon okay you will

[11:49:30 - 11:49:34]
also able to do that okay so guys as you

[11:49:32 - 11:49:37]
can see this is the repository and the

[11:49:34 - 11:49:39]
repository name is like open llms and

[11:49:37 - 11:49:41]
here if you see uh we have lots of opens

[11:49:39 - 11:49:43]
large language model are available you

[11:49:41 - 11:49:47]
can see T5

[11:49:43 - 11:49:50]
E2 then pathia Dolly okay then here you

[11:49:47 - 11:49:54]
you will see like Bloom is there then F

[11:49:50 - 11:49:57]
chat then mp uh mptp uh 7B this is the 7

[11:49:54 - 11:49:59]
billion parameter then Falcon I was uh I

[11:49:57 - 11:50:02]
will be discussing about Falcon so as

[11:49:59 - 11:50:03]
you already saw like in my uh topic I

[11:50:02 - 11:50:05]
will be discussing about this Falcone

[11:50:03 - 11:50:08]
okay so uh even that actually they have

[11:50:05 - 11:50:09]
also shared this paper blog and

[11:50:08 - 11:50:11]
everything okay if you want to learn you

[11:50:09 - 11:50:13]
can open it and all the steps actually

[11:50:11 - 11:50:16]
you will be getting then then lamb 2 is

[11:50:13 - 11:50:18]
also there okay then mrl 7B also there

[11:50:16 - 11:50:21]
then Google Palm is also there okay so

[11:50:18 - 11:50:24]
uh here actually we'll get all kinds of

[11:50:21 - 11:50:26]
open um Source large language model okay

[11:50:24 - 11:50:27]
and if you see here it was committed 4

[11:50:26 - 11:50:29]
days ago so it is like very update

[11:50:27 - 11:50:31]
repository so here you can check it out

[11:50:29 - 11:50:33]
uh if any large language model is coming

[11:50:31 - 11:50:35]
in the market so here actually you will

[11:50:33 - 11:50:37]
get all the list and all and apart from

[11:50:35 - 11:50:38]
that you can also search from your site

[11:50:37 - 11:50:40]
uh let's say if you are exploring any

[11:50:38 - 11:50:42]
other topic and all so you can search

[11:50:40 - 11:50:45]
and you can learn about okay so yes guys

[11:50:42 - 11:50:47]
uh this is all about our large language

[11:50:45 - 11:50:49]
model open source language model I think

[11:50:47 - 11:50:51]
you got it okay so guys we don't only

[11:50:49 - 11:50:54]
have the option using uh like you can

[11:50:51 - 11:50:55]
say open AI GPT model apart from that we

[11:50:54 - 11:50:58]
have these kinds of Open Source L

[11:50:55 - 11:50:59]
language model we can utilize okay uh so

[11:50:58 - 11:51:01]
I personally prefer this kinds of Open

[11:50:59 - 11:51:04]
Source large language model because this

[11:51:01 - 11:51:07]
is like very powerful so it it can also

[11:51:04 - 11:51:09]
work like your uh GPT 3.5 turbo okay so

[11:51:07 - 11:51:10]
it's like very powerful model so using

[11:51:09 - 11:51:12]
these are the model actually you can

[11:51:10 - 11:51:14]
solve very complex problem statement

[11:51:12 - 11:51:15]
even you can create a very beautiful

[11:51:14 - 11:51:17]
Genera application so why you need to

[11:51:15 - 11:51:20]
pay right but if you also want to pay

[11:51:17 - 11:51:23]
because see GPT is like very good model

[11:51:20 - 11:51:27]
I know that but again U it's like

[11:51:23 - 11:51:29]
completely I mean hosted like API so you

[11:51:27 - 11:51:30]
can directly call the API you can hit

[11:51:29 - 11:51:31]
the model you can get the response so

[11:51:30 - 11:51:34]
this is the beautification they have

[11:51:31 - 11:51:35]
created in their website but apart from

[11:51:34 - 11:51:37]
that let's say you don't have money and

[11:51:35 - 11:51:39]
you don't want to spend money on top of

[11:51:37 - 11:51:41]
these kinds of model so you can use this

[11:51:39 - 11:51:43]
kinds of llm model and you can create

[11:51:41 - 11:51:45]
your application on top of that even you

[11:51:43 - 11:51:46]
can also fine-tune them okay so this is

[11:51:45 - 11:51:48]
the beautification of these kinds of

[11:51:46 - 11:51:50]
large language model so in future I will

[11:51:48 - 11:51:51]
also show you how we can fine tune this

[11:51:50 - 11:51:54]
kinds of large language model on top of

[11:51:51 - 11:51:56]
our custom data on top of our custom use

[11:51:54 - 11:51:57]
cases and how how we can use it okay so

[11:51:56 - 11:51:59]
fine tuning is not required unless and

[11:51:57 - 11:52:02]
until your data is like very complex and

[11:51:59 - 11:52:03]
it is like very uh private data so that

[11:52:02 - 11:52:05]
time you can find tune them but most of

[11:52:03 - 11:52:07]
the use cases can be solved using these

[11:52:05 - 11:52:09]
are the model okay so yes guys now let's

[11:52:07 - 11:52:10]
go back and try to see like what are the

[11:52:09 - 11:52:12]
things actually we'll be learning from

[11:52:10 - 11:52:13]
this video so guys uh in this video

[11:52:12 - 11:52:16]
actually I'll be discussing like the

[11:52:13 - 11:52:18]
introduction to Lama 2 like what is Lama

[11:52:16 - 11:52:20]
2 and all like uh who has published this

[11:52:18 - 11:52:22]
Lama 2 like what the variant actually

[11:52:20 - 11:52:25]
Lama 2 has and all then I will show you

[11:52:22 - 11:52:27]
like how we can run this Lama 2 okay

[11:52:25 - 11:52:30]
I'll show you like some difficulty level

[11:52:27 - 11:52:33]
like how why we can't use the actual

[11:52:30 - 11:52:34]
Lama 2 model OKAY hosted from meta AI so

[11:52:33 - 11:52:37]
which model actually I'm going to use it

[11:52:34 - 11:52:39]
so how to execute this L to okay I'll be

[11:52:37 - 11:52:41]
discussing about on Google collab

[11:52:39 - 11:52:43]
because you can also do it in your local

[11:52:41 - 11:52:44]
machine as well but I will on Google

[11:52:43 - 11:52:45]
collab because Google collab would be

[11:52:44 - 11:52:47]
pretty much good environment for me

[11:52:45 - 11:52:50]
because there I will already have lots

[11:52:47 - 11:52:53]
of predefined Library setup right then I

[11:52:50 - 11:52:55]
will U show you like how we can use this

[11:52:53 - 11:52:57]
lambat to with langin because nowadays

[11:52:55 - 11:52:58]
actually people uses this langin

[11:52:57 - 11:53:00]
framework okay to create generative

[11:52:58 - 11:53:02]
application so I'll also show you how we

[11:53:00 - 11:53:03]
can use the langen okay with this kinds

[11:53:02 - 11:53:05]
of Lama to open source large language

[11:53:03 - 11:53:07]
model and at the end of the video I'll

[11:53:05 - 11:53:08]
also show you how we can build

[11:53:07 - 11:53:10]
generative AI projects using Lama 2 so

[11:53:08 - 11:53:12]
there actually we'll be implementing one

[11:53:10 - 11:53:14]
projects very uh interesting projects

[11:53:12 - 11:53:16]
okay okay uh with the help of this Lama

[11:53:14 - 11:53:18]
too even I will be using Lang chin there

[11:53:16 - 11:53:20]
also okay then uh we'll see like how we

[11:53:18 - 11:53:23]
can integrate open source model with

[11:53:20 - 11:53:24]
these kinds of framework Lang chain then

[11:53:23 - 11:53:26]
how we can create this kinds of

[11:53:24 - 11:53:28]
generative AI projects so it would be

[11:53:26 - 11:53:30]
completely end to end video about this

[11:53:28 - 11:53:31]
open source lar language model okay

[11:53:30 - 11:53:33]
you'll be learning each and everything

[11:53:31 - 11:53:34]
about open source language model like

[11:53:33 - 11:53:36]
you will be knowing each and every part

[11:53:34 - 11:53:38]
of this Lama to and all so make sure you

[11:53:36 - 11:53:39]
are watching this video till the end uh

[11:53:38 - 11:53:41]
so this should be my request guys and

[11:53:39 - 11:53:43]
also try to practice with me okay in

[11:53:41 - 11:53:45]
Live or whatever things I'm writing you

[11:53:43 - 11:53:47]
just also try to write with me even all

[11:53:45 - 11:53:49]
the code and everything will share in

[11:53:47 - 11:53:50]
the resources section from there

[11:53:49 - 11:53:52]
actually you can get it so first of all

[11:53:50 - 11:53:54]
let's discuss about Lama 2 and in the

[11:53:52 - 11:53:56]
next video I'll be discussing about

[11:53:54 - 11:53:58]
Google Pam and fcon so guys if you

[11:53:56 - 11:54:00]
search on Google like meta Lama 2 so you

[11:53:58 - 11:54:03]
will able to see this website the first

[11:54:00 - 11:54:05]
website okay so this is the website of

[11:54:03 - 11:54:07]
Lama 2 so here actually they have

[11:54:05 - 11:54:09]
published this Lama 2 documentation and

[11:54:07 - 11:54:11]
all like how we can use it and all and

[11:54:09 - 11:54:13]
uh this documentation will give you the

[11:54:11 - 11:54:16]
entire idea about Lama to like uh what

[11:54:13 - 11:54:18]
is Lama 2 and U uh how many variants

[11:54:16 - 11:54:19]
actually it has okay even The Benchmark

[11:54:18 - 11:54:22]
also you will able to see so guys here

[11:54:19 - 11:54:24]
if you see uh Lama 2 is nothing but it's

[11:54:22 - 11:54:26]
a Next Generation open source large

[11:54:24 - 11:54:28]
language model and Lama 2 is available

[11:54:26 - 11:54:30]
for free uh research and commercial use

[11:54:28 - 11:54:32]
cases as I was discussing about and if

[11:54:30 - 11:54:34]
you want to access this Lamar to so they

[11:54:32 - 11:54:35]
have given the link here so here

[11:54:34 - 11:54:37]
actually you need to fill some

[11:54:35 - 11:54:40]
information like uh your name uh email

[11:54:37 - 11:54:41]
address then country and organization so

[11:54:40 - 11:54:43]
these are the basics form you need to

[11:54:41 - 11:54:45]
feel and you need to submit so after

[11:54:43 - 11:54:47]
some time actually they will give you

[11:54:45 - 11:54:50]
the permission because see you can't

[11:54:47 - 11:54:51]
directly use this Lama 2 model so for

[11:54:50 - 11:54:53]
this you need to send some information

[11:54:51 - 11:54:55]
of you uh then after some time actually

[11:54:53 - 11:54:58]
they will give you the permission okay I

[11:54:55 - 11:55:01]
also applied this uh request form so uh

[11:54:58 - 11:55:03]
after let's say 30 minutes or let's say

[11:55:01 - 11:55:06]
1 hour you will get the access for sure

[11:55:03 - 11:55:08]
okay so uh I I will also show you one Al

[11:55:06 - 11:55:11]
alternative so if you want to do it

[11:55:08 - 11:55:14]
right now so one guy actually cloned

[11:55:11 - 11:55:16]
this uh complete uh lambat 2 model OKAY

[11:55:14 - 11:55:18]
in his uh you can say hugging face

[11:55:16 - 11:55:21]
repository and it is completely public

[11:55:18 - 11:55:22]
okay so you you can use that model uh if

[11:55:21 - 11:55:24]
you're not getting permission and once

[11:55:22 - 11:55:27]
you got the permission you can uh use

[11:55:24 - 11:55:28]
official version of the uh Lama 2 model

[11:55:27 - 11:55:30]
okay so I'll show you like both option

[11:55:28 - 11:55:32]
how we can do it so for me I already got

[11:55:30 - 11:55:34]
the access from this meta so they have

[11:55:32 - 11:55:36]
given me the access I'll tell you like

[11:55:34 - 11:55:39]
how to like uh uh apply for the access

[11:55:36 - 11:55:40]
and all okay so as of now uh the

[11:55:39 - 11:55:42]
experiment actually I'm going to do like

[11:55:40 - 11:55:44]
how we can execute this Lama to model

[11:55:42 - 11:55:46]
I'll be using something called quantized

[11:55:44 - 11:55:48]
Model Because the actual like L model

[11:55:46 - 11:55:50]
you can't execute on Google collab on

[11:55:48 - 11:55:52]
free Google collab so for this actually

[11:55:50 - 11:55:53]
you need uh good instance okay like good

[11:55:52 - 11:55:55]
instance means like you need powerful

[11:55:53 - 11:55:59]
machine you need more RAM okay you need

[11:55:55 - 11:56:01]
more memory there but uh uh if you are

[11:55:59 - 11:56:02]
using free version of Google collab and

[11:56:01 - 11:56:04]
if you're using your local system so

[11:56:02 - 11:56:05]
there actually you can't load this model

[11:56:04 - 11:56:07]
so it would be very hard for you so

[11:56:05 - 11:56:08]
better we be using some quantized model

[11:56:07 - 11:56:10]
I think you know what is the quantized

[11:56:08 - 11:56:12]
model so quantized model is nothing but

[11:56:10 - 11:56:14]
it's a quantized version of the actual

[11:56:12 - 11:56:16]
model so they have just uh compressed

[11:56:14 - 11:56:18]
the model okay with the uh integer

[11:56:16 - 11:56:20]
encoding and they have proposed this

[11:56:18 - 11:56:22]
model and this model size is a little

[11:56:20 - 11:56:23]
bit less so we can load this model in

[11:56:22 - 11:56:25]
our memory okay in very easily I will

[11:56:23 - 11:56:27]
tell you like how to use quantz model

[11:56:25 - 11:56:30]
and all okay so guys here if you see

[11:56:27 - 11:56:32]
Lama 2 was train on 40% more data than

[11:56:30 - 11:56:34]
LMA 1 okay because I told you uh there

[11:56:32 - 11:56:37]
is another model called LMA 1 and LMA 2

[11:56:34 - 11:56:40]
train U and here LMA 2 trained actually

[11:56:37 - 11:56:42]
more than 40% data than lama lama lama 1

[11:56:40 - 11:56:44]
and it has actually double context

[11:56:42 - 11:56:47]
length basically the context length is

[11:56:44 - 11:56:49]
like double okay then you Lama one and

[11:56:47 - 11:56:52]
see these are the LMA 2 variant actually

[11:56:49 - 11:56:53]
Lama 2 has 7 billion parameter and

[11:56:52 - 11:56:56]
another variant has like 13 billion

[11:56:53 - 11:56:59]
parameter and another variant has 70

[11:56:56 - 11:57:01]
billion parameter and uh this is the

[11:56:59 - 11:57:03]
pre-training token you can say so they

[11:57:01 - 11:57:05]
have used true trillion token to train

[11:57:03 - 11:57:07]
this model and here if you see this is

[11:57:05 - 11:57:10]
the context length so it's

[11:57:07 - 11:57:13]
4,096 but uh whenever I was talking

[11:57:10 - 11:57:15]
about Lama 1 so it has actually 2,000

[11:57:13 - 11:57:18]
something context length but it is like

[11:57:15 - 11:57:19]
double okay double than your Lama 1 and

[11:57:18 - 11:57:22]
uh this size is around

[11:57:19 - 11:57:24]
4,096 and here if you see uh the

[11:57:22 - 11:57:26]
training strategy so they also use

[11:57:24 - 11:57:28]
supervised fine tuning technique on top

[11:57:26 - 11:57:29]
of it then they also use something

[11:57:28 - 11:57:32]
called human and preferences I think you

[11:57:29 - 11:57:34]
know like how we can train these kinds

[11:57:32 - 11:57:36]
of large language model okay what is the

[11:57:34 - 11:57:38]
idea and all about uh basically this is

[11:57:36 - 11:57:40]
the strategy we follow in every large

[11:57:38 - 11:57:41]
language model okay then they have

[11:57:40 - 11:57:42]
applied something called reinforcement

[11:57:41 - 11:57:44]
learning to understand understand the

[11:57:42 - 11:57:47]
human human input don't understand the

[11:57:44 - 11:57:49]
human uh you can say prompt okay so they

[11:57:47 - 11:57:51]
they have used this strategy to train

[11:57:49 - 11:57:53]
their entire model and Lama 2 Preen

[11:57:51 - 11:57:55]
models are trained on two trillion

[11:57:53 - 11:57:57]
tokens here I already discussed and uh

[11:57:55 - 11:57:59]
have double context length than Lama one

[11:57:57 - 11:58:02]
it's fine tune models have been uh

[11:57:59 - 11:58:04]
trained over 1 million human annotation

[11:58:02 - 11:58:06]
okay so 1 million human annotation means

[11:58:04 - 11:58:08]
they have applied this supervised fine

[11:58:06 - 11:58:10]
tuning technique so uh they have created

[11:58:08 - 11:58:11]
one chat use cases so basically see

[11:58:10 - 11:58:14]
whenever I'm giving any input let's say

[11:58:11 - 11:58:17]
just just fix this code for me or let's

[11:58:14 - 11:58:18]
say generate a you can say python code

[11:58:17 - 11:58:20]
for me so these are the chat actually

[11:58:18 - 11:58:21]
I'm giving so with respect to that

[11:58:20 - 11:58:23]
actually what is human annotation human

[11:58:21 - 11:58:25]
annotation means like see whenever you

[11:58:23 - 11:58:27]
are giving these kinds of prompt so one

[11:58:25 - 11:58:28]
human will be replying the actual thing

[11:58:27 - 11:58:30]
here okay that's how your model will be

[11:58:28 - 11:58:31]
learning let's see if you're giving any

[11:58:30 - 11:58:34]
random message let's say Hi how are you

[11:58:31 - 11:58:36]
fine okay and all so one human will chat

[11:58:34 - 11:58:37]
with you like manually they will chat

[11:58:36 - 11:58:38]
with you so we call them human

[11:58:37 - 11:58:41]
annotation and with the help of this

[11:58:38 - 11:58:42]
data actually we train our actual model

[11:58:41 - 11:58:45]
and we create these kinds of uh very

[11:58:42 - 11:58:47]
powerful large language model right and

[11:58:45 - 11:58:50]
this is The Benchmark as you can see so

[11:58:47 - 11:58:54]
here uh we have lots of model uh we have

[11:58:50 - 11:58:58]
MPT 7B then Falcon 7B and we also have

[11:58:54 - 11:59:01]
our Lama 2 7B 13B and we also have 60 5B

[11:58:58 - 11:59:04]
and 70b okay so here if you see these

[11:59:01 - 11:59:05]
are some Benchmark data and this is the

[11:59:04 - 11:59:09]
performance of the model as you can see

[11:59:05 - 11:59:11]
MTP uh MPT uh 7 billion uh this was the

[11:59:09 - 11:59:15]
accuracy 26% accuracy and here if you're

[11:59:11 - 11:59:17]
using Falcon so 26.2% accuracy and if

[11:59:15 - 11:59:19]
you're using Lama 2 7B here so see

[11:59:17 - 11:59:23]
accuracy is like very much increased

[11:59:19 - 11:59:26]
here it's around 45 .3% of accuracy and

[11:59:23 - 11:59:28]
if you're using 7B that uh sorry and

[11:59:26 - 11:59:30]
here if you're using 13B that means 13

[11:59:28 - 11:59:32]
billion parameter version of the model

[11:59:30 - 11:59:35]
so here this is the accuracy

[11:59:32 - 11:59:38]
54.8% of the accuracy and here if you're

[11:59:35 - 11:59:41]
using m m PT 30 billion so this is the

[11:59:38 - 11:59:45]
accuracy then I mean it's like less than

[11:59:41 - 11:59:47]
your lamb 2 and Falcon 40 40b actually

[11:59:45 - 11:59:50]
will give you

[11:59:47 - 11:59:53]
55.4% and if you're using Lama 65

[11:59:50 - 11:59:57]
billion so 63 uh

[11:59:53 - 12:00:01]
63.4% and Lama 7B uh like very good

[11:59:57 - 12:00:03]
accuracy here 67.9% of accuracy okay so

[12:00:01 - 12:00:05]
with respect to that you can see this is

[12:00:03 - 12:00:08]
again another data so this is like mm Lu

[12:00:05 - 12:00:10]
data so this is trivia QA data this is

[12:00:08 - 12:00:12]
natural questions data so you have lots

[12:00:10 - 12:00:15]
of Benchmark data with respect to that

[12:00:12 - 12:00:16]
these are the model has been trained and

[12:00:15 - 12:00:18]
this was calculated the acury okay and

[12:00:16 - 12:00:20]
this is the and this is the complete

[12:00:18 - 12:00:22]
Benchmark Benchmark table here you will

[12:00:20 - 12:00:25]
see all the performance of the model

[12:00:22 - 12:00:28]
okay and guys uh if you want to test

[12:00:25 - 12:00:31]
this Lama to a model so here U there is

[12:00:28 - 12:00:34]
one UI has been published here APC on

[12:00:31 - 12:00:37]
top of the Lama 2 model so if you just

[12:00:34 - 12:00:39]
write ww. LMA 2. a so this is the

[12:00:37 - 12:00:41]
chatbot actually you able to see so this

[12:00:39 - 12:00:43]
is kinds of chat GPT kinds of interface

[12:00:41 - 12:00:45]
they providing and in the back end

[12:00:43 - 12:00:47]
actually they're using LMA 2 model here

[12:00:45 - 12:00:49]
ifpc so you can select Lama 2 model

[12:00:47 - 12:00:52]
different different model so by default

[12:00:49 - 12:00:55]
it is selected LMA to 7 billion so let's

[12:00:52 - 12:00:57]
select this one LMA to 7B 7 billion

[12:00:55 - 12:01:00]
parameter this model and you can also

[12:00:57 - 12:01:01]
give the uh your system prompt here so

[12:01:00 - 12:01:03]
let's take this prompt only and the

[12:01:01 - 12:01:04]
temperature you can also select let's

[12:01:03 - 12:01:07]
say if this temperature is close to zero

[12:01:04 - 12:01:09]
that means this model would be more

[12:01:07 - 12:01:11]
strict to the output so it won't give

[12:01:09 - 12:01:13]
you any Randomness and uh if you set

[12:01:11 - 12:01:16]
this temp as close to one that means

[12:01:13 - 12:01:17]
your model will be like more random so

[12:01:16 - 12:01:19]
it will give you like more random output

[12:01:17 - 12:01:22]
okay and if you want to make your model

[12:01:19 - 12:01:23]
like more uh generalized to Randomness

[12:01:22 - 12:01:25]
so you can increase this parameter to

[12:01:23 - 12:01:27]
close to one and this is the max length

[12:01:25 - 12:01:28]
like how many output you want from your

[12:01:27 - 12:01:30]
model and all so you can set this

[12:01:28 - 12:01:32]
parameter and all and this is the top

[12:01:30 - 12:01:34]
probability score and all okay so here

[12:01:32 - 12:01:35]
you can write your custom prompt as well

[12:01:34 - 12:01:38]
let's say here in this case I'll be

[12:01:35 - 12:01:41]
doing uh chat chat operation with this

[12:01:38 - 12:01:42]
Lama 2 here if you see chat with Lama 2

[12:01:41 - 12:01:45]
you can also set this prompt as

[12:01:42 - 12:01:47]
summarization let's say code generation

[12:01:45 - 12:01:48]
anything you can do okay so you need to

[12:01:47 - 12:01:49]
just change this prompt I think you know

[12:01:48 - 12:01:52]
what is prompt and all so this thing is

[12:01:49 - 12:01:54]
very common okay in llm and all so you

[12:01:52 - 12:01:57]
can give the prompt here so let's take

[12:01:54 - 12:02:00]
this LMA 7B parameter this model and

[12:01:57 - 12:02:02]
let's uh do some chat with this model so

[12:02:00 - 12:02:05]
here first of all let's say I just write

[12:02:02 - 12:02:05]
hey uh or let's say

[12:02:08 - 12:02:13]
hi so here if you see this is uh giving

[12:02:10 - 12:02:16]
me the response okay now here I can ask

[12:02:13 - 12:02:18]
like uh what is the so what is the

[12:02:16 - 12:02:23]
library

[12:02:18 - 12:02:23]
uh we can use to

[12:02:24 - 12:02:29]
build

[12:02:26 - 12:02:29]
jna

[12:02:30 - 12:02:35]
application I'm just giving any random

[12:02:33 - 12:02:37]
question let's see whether it is able to

[12:02:35 - 12:02:39]
uh answer or

[12:02:37 - 12:02:41]
not so here if you see it's giving

[12:02:39 - 12:02:43]
different different answer okay with

[12:02:41 - 12:02:47]
respect to the question I have asked now

[12:02:43 - 12:02:50]
let's say here I can also give any error

[12:02:47 - 12:02:52]
of my code and if I tell uh it actually

[12:02:50 - 12:02:55]
just try to solve this error so let's

[12:02:52 - 12:02:57]
say I was trying one OCR code here so

[12:02:55 - 12:03:00]
this is the error actually I got so let

[12:02:57 - 12:03:02]
me show you the error so guys uh this is

[12:03:00 - 12:03:04]
the error actually I got here so could

[12:03:02 - 12:03:06]
not find a version satisfied the padal

[12:03:04 - 12:03:08]
paddle okay this is the error I got so

[12:03:06 - 12:03:11]
this error actually I will ask to this

[12:03:08 - 12:03:12]
uh LMA to and let's see whether it is

[12:03:11 - 12:03:16]
able to f F or not here I will just

[12:03:12 - 12:03:19]
write fix it okay if I just write fix it

[12:03:16 - 12:03:19]
now let's see what

[12:03:20 - 12:03:25]
happens so guys see it is giving me the

[12:03:22 - 12:03:26]
response and uh it's telling like U

[12:03:25 - 12:03:29]
install this version of this paddle

[12:03:26 - 12:03:32]
paddle okay and you can also use some

[12:03:29 - 12:03:34]
third party GitHub uh to build this uh

[12:03:32 - 12:03:36]
setup tool and all so it's giving all

[12:03:34 - 12:03:37]
kinds of possibilities like you can try

[12:03:36 - 12:03:39]
you can get this suggestion and you can

[12:03:37 - 12:03:41]
try and you can solve this error okay so

[12:03:39 - 12:03:44]
Lama 2 is telling actually this model is

[12:03:41 - 12:03:47]
uh like more powerful than GPT 3.5 turbo

[12:03:44 - 12:03:48]
model okay because see I already use

[12:03:47 - 12:03:50]
this lamama 2 model and what I feel like

[12:03:48 - 12:03:53]
yeah this model is pretty good than your

[12:03:50 - 12:03:56]
GPT 3.5 turbo if you're using GPT 3.5

[12:03:53 - 12:03:57]
turbo you saw like lots of task actually

[12:03:56 - 12:03:59]
don't be able to solve in a good way but

[12:03:57 - 12:04:01]
if you're using Lama in this case Lama 2

[12:03:59 - 12:04:02]
in this case actually it can solve like

[12:04:01 - 12:04:04]
various kinds of task okay so this is

[12:04:02 - 12:04:05]
the playground you can play with this

[12:04:04 - 12:04:07]
LMA 2 model you can select different

[12:04:05 - 12:04:08]
different version of the model and you

[12:04:07 - 12:04:10]
can play with this model all kinds of

[12:04:08 - 12:04:12]
question you can ask and you can realize

[12:04:10 - 12:04:15]
like how powerful this modalities okay

[12:04:12 - 12:04:17]
so yes guys this is all about our Lama

[12:04:15 - 12:04:19]
um you can say introduction and all I

[12:04:17 - 12:04:21]
think you got it like what is LMA to and

[12:04:19 - 12:04:23]
all okay the basics overview you got it

[12:04:21 - 12:04:25]
now I will show you like how we can use

[12:04:23 - 12:04:27]
this how we can run this Lama to model

[12:04:25 - 12:04:29]
on the Google collab so guys for this

[12:04:27 - 12:04:30]
actually I already prepared one Google

[12:04:29 - 12:04:32]
collab notebook for you as you can see

[12:04:30 - 12:04:33]
this is the Google collab notebook and

[12:04:32 - 12:04:35]
here we'll be learning like how we can

[12:04:33 - 12:04:38]
execute this Lama to model on the Google

[12:04:35 - 12:04:40]
collab so as I already told you we can

[12:04:38 - 12:04:42]
directly load this Lama to official Lama

[12:04:40 - 12:04:44]
to model from the official

[12:04:42 - 12:04:47]
Lama you can see this is the this Lama 2

[12:04:44 - 12:04:48]
is available on this hugging face so

[12:04:47 - 12:04:52]
from hugging face itself actually you

[12:04:48 - 12:04:53]
can see this uh meta Lama okay and this

[12:04:52 - 12:04:56]
is the Lama 2 model this is the original

[12:04:53 - 12:04:58]
Lama 2 model official Lama 2 model it is

[12:04:56 - 12:05:00]
uh hosted on Hing pH from here actually

[12:04:58 - 12:05:03]
you can load this model but this model

[12:05:00 - 12:05:04]
actually I can't load in my free Google

[12:05:03 - 12:05:07]
collab for this actually you need good

[12:05:04 - 12:05:08]
instance good uh memory good GPU ANL but

[12:05:07 - 12:05:11]
here I'm using free cup that's why I

[12:05:08 - 12:05:13]
can't load and you can also load this

[12:05:11 - 12:05:14]
thing in your local machine okay so for

[12:05:13 - 12:05:17]
this actually what you need to do you

[12:05:14 - 12:05:19]
need to use something of quantized

[12:05:17 - 12:05:20]
version of the model so again hugging

[12:05:19 - 12:05:23]
phas also provides like quantization

[12:05:20 - 12:05:24]
model so uh some of the actually

[12:05:23 - 12:05:27]
organization have already applied this

[12:05:24 - 12:05:28]
quantization technique and they compress

[12:05:27 - 12:05:31]
these are the actual model and they

[12:05:28 - 12:05:33]
hosted on the Hing face community so

[12:05:31 - 12:05:36]
here if you see we have like various

[12:05:33 - 12:05:39]
kinds of quantized model here if you see

[12:05:36 - 12:05:40]
so these are the Quant models so this is

[12:05:39 - 12:05:43]
the so here guys if you see this is the

[12:05:40 - 12:05:45]
GG ml format of quantized version of the

[12:05:43 - 12:05:47]
model and if you see like lots of model

[12:05:45 - 12:05:49]
are available okay so from this model

[12:05:47 - 12:05:50]
actually I'm going to use one particular

[12:05:49 - 12:05:53]
model so this is the model link I have

[12:05:50 - 12:05:58]
given just let me open it so the model

[12:05:53 - 12:06:00]
name is uh um Lama 2 13 billion chat GG

[12:05:58 - 12:06:01]
ml okay gml is the format of

[12:06:00 - 12:06:03]
quantization and this is the

[12:06:01 - 12:06:06]
organization so this organization has

[12:06:03 - 12:06:08]
quantized this model okay and uh it is

[12:06:06 - 12:06:11]
published here now this model is like

[12:06:08 - 12:06:13]
more uh like uh s small model OKAY than

[12:06:11 - 12:06:15]
your ual Lama 2 model which is published

[12:06:13 - 12:06:17]
on hugging face uh this model actually

[12:06:15 - 12:06:19]
you can easily load in your 3D Google

[12:06:17 - 12:06:21]
collab okay or if you're using your

[12:06:19 - 12:06:24]
local system as well you can also load

[12:06:21 - 12:06:26]
there okay and this model has lots of uh

[12:06:24 - 12:06:29]
uh variant here if you see b means this

[12:06:26 - 12:06:31]
is the model okay this is the bin format

[12:06:29 - 12:06:32]
of the model that means binary model so

[12:06:31 - 12:06:34]
from these are the model I'll be using

[12:06:32 - 12:06:36]
one particular model because these are

[12:06:34 - 12:06:38]
different different quantization uh you

[12:06:36 - 12:06:40]
can say format so I'll be using one

[12:06:38 - 12:06:41]
particular quantization here and this is

[12:06:40 - 12:06:42]
the size of the model as you can see

[12:06:41 - 12:06:44]
this is the the size of the model and

[12:06:42 - 12:06:46]
after applied quantization the size size

[12:06:44 - 12:06:48]
has been reduced because what is

[12:06:46 - 12:06:50]
quantization quantization means all the

[12:06:48 - 12:06:52]
weights you have in the model uh by

[12:06:50 - 12:06:54]
default it would be floating number okay

[12:06:52 - 12:06:56]
but if you apply quantization on top of

[12:06:54 - 12:06:57]
it it would be converted to integer and

[12:06:56 - 12:06:58]
your size would be reduced okay your

[12:06:57 - 12:07:00]
model side would be reduced

[12:06:58 - 12:07:02]
automatically so this is the like a idea

[12:07:00 - 12:07:05]
of quantization model so here your

[12:07:02 - 12:07:08]
accuracy might decrease but again um uh

[12:07:05 - 12:07:09]
you are uh like getting the first term

[12:07:08 - 12:07:11]
model here you are getting the smaller

[12:07:09 - 12:07:15]
model here so this is the idea okay and

[12:07:11 - 12:07:18]
if you want to uh use actual this meta

[12:07:15 - 12:07:19]
Lama or that means this Lama 2 model so

[12:07:18 - 12:07:20]
here actually you need to get the

[12:07:19 - 12:07:24]
permission you can directly access this

[12:07:20 - 12:07:27]
model so let's say if I open this link

[12:07:24 - 12:07:29]
in a different or let's say incognito

[12:07:27 - 12:07:30]
window so you will see it will ask for

[12:07:29 - 12:07:32]
the permission actually because I'm

[12:07:30 - 12:07:34]
using my account there so that's why you

[12:07:32 - 12:07:37]
can't see the permission now see here if

[12:07:34 - 12:07:39]
you see access to uh access Lama 2 on

[12:07:37 - 12:07:40]
hugging P so here first of all you need

[12:07:39 - 12:07:42]
to login with this website okay if I

[12:07:40 - 12:07:44]
click on this log loing so it will ask

[12:07:42 - 12:07:45]
for just logging with your hugging face

[12:07:44 - 12:07:46]
so here you need to first of all loging

[12:07:45 - 12:07:49]
with your hugging face let's say I will

[12:07:46 - 12:07:51]
loging with my hugging face here okay

[12:07:49 - 12:07:53]
now see here I have already logged in

[12:07:51 - 12:07:55]
that's why it's telling like uh

[12:07:53 - 12:07:58]
permission granted but for you actually

[12:07:55 - 12:07:59]
it will show like you need to apply for

[12:07:58 - 12:08:01]
the access okay so whenever you will

[12:07:59 - 12:08:03]
apply for the access so it will give you

[12:08:01 - 12:08:05]
that form I think you remember it will

[12:08:03 - 12:08:06]
give you this kinds of form so you need

[12:08:05 - 12:08:08]
to fill this form okay and need to

[12:08:06 - 12:08:09]
select all the information so you can

[12:08:08 - 12:08:11]
select like which model you want to use

[12:08:09 - 12:08:13]
so you can select both of them and and

[12:08:11 - 12:08:15]
you can uh just send a request okay so

[12:08:13 - 12:08:17]
after some times you will receive one

[12:08:15 - 12:08:19]
mail like that so after some times

[12:08:17 - 12:08:22]
actually you will see one mail like that

[12:08:19 - 12:08:24]
uh let's say I applied for this access

[12:08:22 - 12:08:26]
so this is the mail I got so hi puy this

[12:08:24 - 12:08:29]
is let you know that your request to the

[12:08:26 - 12:08:30]
access model metal Lama 2 on the Hing

[12:08:29 - 12:08:32]
face has been accepted by the author

[12:08:30 - 12:08:34]
okay so once you got the access then you

[12:08:32 - 12:08:36]
will able to see this kinds of window

[12:08:34 - 12:08:38]
here uh this kinds of window here GED

[12:08:36 - 12:08:40]
model you have the granted access to

[12:08:38 - 12:08:42]
this model okay but initially whenever

[12:08:40 - 12:08:44]
you will be applying so it will take

[12:08:42 - 12:08:46]
some time at least one to two hours then

[12:08:44 - 12:08:49]
it will give you the access but if you

[12:08:46 - 12:08:51]
uh if you want to try Okay this model so

[12:08:49 - 12:08:52]
again I will tell you another option

[12:08:51 - 12:08:54]
because this model is available on the

[12:08:52 - 12:08:56]
public repository as well okay because

[12:08:54 - 12:08:59]
see in hugging F we have two kinds of

[12:08:56 - 12:09:00]
repository one is like uh organization

[12:08:59 - 12:09:02]
repository like that means private

[12:09:00 - 12:09:04]
repository if you want to use private

[12:09:02 - 12:09:06]
repository so you need to like take the

[12:09:04 - 12:09:09]
permission from the author and one like

[12:09:06 - 12:09:10]
you have like public repository so in

[12:09:09 - 12:09:12]
public repository actually you will have

[12:09:10 - 12:09:13]
the access uh to the model you don't

[12:09:12 - 12:09:15]
need to take any permission from the

[12:09:13 - 12:09:17]
author they will by default provide the

[12:09:15 - 12:09:18]
access and all so you can directly use

[12:09:17 - 12:09:21]
that so one guy actually cloned this

[12:09:18 - 12:09:23]
entire model and he has published from

[12:09:21 - 12:09:25]
his account here and I will be using

[12:09:23 - 12:09:27]
that model okay same model only but this

[12:09:25 - 12:09:29]
is The Unofficial and that is the

[12:09:27 - 12:09:30]
official one okay I'll tell you like

[12:09:29 - 12:09:33]
whenever I'll uh show you like how we

[12:09:30 - 12:09:35]
can use this uh Lama model with the help

[12:09:33 - 12:09:36]
of langen at that time I will show you

[12:09:35 - 12:09:38]
like how we can use it but as of now

[12:09:36 - 12:09:40]
let's try to run this quantied version

[12:09:38 - 12:09:41]
of the model as I already told you I'll

[12:09:40 - 12:09:43]
be running this quantied version of the

[12:09:41 - 12:09:45]
model which is nothing but this model if

[12:09:43 - 12:09:48]
I show you this is the quanti of the

[12:09:45 - 12:09:50]
model okay and guys maai actually also

[12:09:48 - 12:09:52]
provides like different version of the

[12:09:50 - 12:09:55]
LMA 2 model as you can see so we have 7

[12:09:52 - 12:09:57]
billion we have 13 billion we have uh 70

[12:09:55 - 12:09:59]
billion so in this case actually I'm

[12:09:57 - 12:10:01]
running this 13 billion so you can't

[12:09:59 - 12:10:03]
execute this 13 billion in your free

[12:10:01 - 12:10:04]
collab that's why uh we are using

[12:10:03 - 12:10:06]
quantized version of the model but in

[12:10:04 - 12:10:08]
our next experiment so whenever I'll be

[12:10:06 - 12:10:10]
using Lang Chen over there so I'll be

[12:10:08 - 12:10:11]
using this 7 billi parameter model and

[12:10:10 - 12:10:13]
this model actually you can easily load

[12:10:11 - 12:10:15]
in the Google collab or your local

[12:10:13 - 12:10:17]
system as well okay so for this model I

[12:10:15 - 12:10:19]
I'll take the permission and see guys

[12:10:17 - 12:10:20]
these are the model are hosted if you

[12:10:19 - 12:10:23]
see these are the model are hosted from

[12:10:20 - 12:10:24]
the Lama 2 as you can see chat model HF

[12:10:23 - 12:10:25]
model I'll tell you like whenever I will

[12:10:24 - 12:10:27]
be using these are the model I'll tell

[12:10:25 - 12:10:29]
you so yes guys this is all about now

[12:10:27 - 12:10:32]
let me just quickly show you like how we

[12:10:29 - 12:10:33]
can execute so see to execute like

[12:10:32 - 12:10:36]
quantied model you need one Library

[12:10:33 - 12:10:38]
called Lama CPP okay so this is the

[12:10:36 - 12:10:40]
library actually uh you need to use Lama

[12:10:38 - 12:10:42]
CPP is a library actually this Library

[12:10:40 - 12:10:44]
helps you to make the quantized of the

[12:10:42 - 12:10:45]
model okay and if you're using quantized

[12:10:44 - 12:10:47]
version of the model you need to install

[12:10:45 - 12:10:48]
this Library so first of all I will

[12:10:47 - 12:10:51]
connect this

[12:10:48 - 12:10:53]
notebook now make sure you have selected

[12:10:51 - 12:10:56]
runtime as gpus so just click here and

[12:10:53 - 12:11:00]
click on manage GPU uh sorry not here uh

[12:10:56 - 12:11:01]
just click on the runtime and select uh

[12:11:00 - 12:11:03]
here you will get one option called

[12:11:01 - 12:11:06]
change runtime type and I have already

[12:11:03 - 12:11:07]
selected GPU here so now if you want to

[12:11:06 - 12:11:10]
check whether you've got GPU or not so

[12:11:07 - 12:11:12]
you you can execute this command and

[12:11:10 - 12:11:14]
here you will see I'm I got Tesla T4 GPU

[12:11:12 - 12:11:19]
and it has actually

[12:11:14 - 12:11:21]
uh uh 15 GB of uh like vram now here uh

[12:11:19 - 12:11:23]
these are the requirements actually you

[12:11:21 - 12:11:25]
need to install so first of all I'm uh

[12:11:23 - 12:11:28]
installing this one uh Lama CPP Library

[12:11:25 - 12:11:30]
okay and this is the command to install

[12:11:28 - 12:11:32]
everything and uh here I'm also

[12:11:30 - 12:11:35]
installing hugging face Hub because from

[12:11:32 - 12:11:36]
the hugging face itself I want to access

[12:11:35 - 12:11:38]
this model because see this is this

[12:11:36 - 12:11:40]
model is hosted on hugging face and if

[12:11:38 - 12:11:42]
you want to access any hugging F model

[12:11:40 - 12:11:44]
so you need to install hugging Hub and

[12:11:42 - 12:11:46]
here I'm also installing Lama to CPP

[12:11:44 - 12:11:47]
python okay so these two command

[12:11:46 - 12:11:50]
actually you need to execute to install

[12:11:47 - 12:11:52]
Lama uh Lama CPP libr then I also need

[12:11:50 - 12:11:54]
numai with this specific version now let

[12:11:52 - 12:11:54]
me

[12:12:05 - 12:12:10]
execute so guys as you can see my

[12:12:07 - 12:12:12]
installation is done now uh here you

[12:12:10 - 12:12:14]
just need to give the name of the model

[12:12:12 - 12:12:15]
like which model you are using so here

[12:12:14 - 12:12:18]
this is the model I'm using just copy

[12:12:15 - 12:12:20]
this name here and here you just need to

[12:12:18 - 12:12:22]
paste it okay so I have uh just uh given

[12:12:20 - 12:12:24]
this name here now here you also need to

[12:12:22 - 12:12:26]
specify the base model name like which

[12:12:24 - 12:12:28]
particular model you you need to use so

[12:12:26 - 12:12:31]
here I'm using Q5

[12:12:28 - 12:12:33]
1bin model so if I go here so it has

[12:12:31 - 12:12:36]
lots of variant I already told you so

[12:12:33 - 12:12:39]
here I'm using this key5

[12:12:36 - 12:12:42]
uh uh this model actually I think let me

[12:12:39 - 12:12:46]
just see

[12:12:42 - 12:12:47]
q51 dobin q51 dobin um yeah so this is

[12:12:46 - 12:12:49]
the particular model actually I'm using

[12:12:47 - 12:12:51]
so you can use any any model no issue

[12:12:49 - 12:12:54]
with that so I'm using this model and

[12:12:51 - 12:12:56]
this is the size of the model so I'll be

[12:12:54 - 12:12:59]
executing so you need to give the same

[12:12:56 - 12:13:02]
name just copy paste from here and just

[12:12:59 - 12:13:03]
give it here now once it is done now so

[12:13:02 - 12:13:06]
here first of all I'll be importing one

[12:13:03 - 12:13:07]
uh class called HF hub download that

[12:13:06 - 12:13:10]
means hugging face model download so

[12:13:07 - 12:13:12]
this uh class will help you to download

[12:13:10 - 12:13:14]
any particular model from HF first of

[12:13:12 - 12:13:17]
all let me import then I also need to

[12:13:14 - 12:13:19]
import uh this Lama from Lama CPP

[12:13:17 - 12:13:24]
library because we have already uh

[12:13:19 - 12:13:24]
install this Library so let me import

[12:13:24 - 12:13:28]
it and if you're not using quantized

[12:13:27 - 12:13:31]
version of the model okay uh you don't

[12:13:28 - 12:13:33]
need to install this Lama CPP so we can

[12:13:31 - 12:13:35]
directly download the model from hugging

[12:13:33 - 12:13:36]
F okay I'll tell you uh whenever I'll be

[12:13:35 - 12:13:38]
using this model actually because I

[12:13:36 - 12:13:40]
already told you Lama to provide Slots

[12:13:38 - 12:13:42]
of version of the model whenever I'll be

[12:13:40 - 12:13:44]
using smallest version of the model I'll

[12:13:42 - 12:13:46]
be directly downloading the model from

[12:13:44 - 12:13:48]
the Hing face okay at that time I don't

[12:13:46 - 12:13:49]
need this Lama CPP Library okay but here

[12:13:48 - 12:13:51]
I'm using quantied version of the model

[12:13:49 - 12:13:52]
that's why this needed now first of all

[12:13:51 - 12:13:53]
you need to download the model to

[12:13:52 - 12:13:55]
download the model first of all you need

[12:13:53 - 12:13:57]
to give the repo ID repo ID is nothing

[12:13:55 - 12:13:59]
but your model name so this is the URL

[12:13:57 - 12:14:01]
I'm giving okay and you also need to

[12:13:59 - 12:14:03]
give the file name like which particular

[12:14:01 - 12:14:04]
file you you need to download so here

[12:14:03 - 12:14:06]
you need to give this Bas name here now

[12:14:04 - 12:14:07]
it will automatically go to the

[12:14:06 - 12:14:09]
repository and it will automatically

[12:14:07 - 12:14:12]
download for you see guys it's

[12:14:09 - 12:14:16]
downloading and this is around um 9. uh

[12:14:12 - 12:14:16]
76 GB so let's wait it will take some

[12:14:18 - 12:14:26]
time I'm able to load this model because

[12:14:21 - 12:14:28]
here if you see my vram uh GPU vram I

[12:14:26 - 12:14:31]
got

[12:14:28 - 12:14:33]
uh I got 15 GB that's why I can load

[12:14:31 - 12:14:35]
this model very easily uh that's why

[12:14:33 - 12:14:37]
actually I'm using this contage version

[12:14:35 - 12:14:41]
of the model but if you're using actual

[12:14:37 - 12:14:44]
uh this model if I show you

[12:14:41 - 12:14:47]
uh actual uh 13 billion parameter Lama 2

[12:14:44 - 12:14:50]
model okay uh without U you can say

[12:14:47 - 12:14:52]
quantized model so uh it is more than

[12:14:50 - 12:14:54]
your 9gb and you can't load it okay that

[12:14:52 - 12:14:55]
is the issue actually so I'm following

[12:14:54 - 12:14:56]
this approach see this model has been

[12:14:55 - 12:14:58]
downloaded now if you want to see the

[12:14:56 - 12:15:00]
path of the model like what it has

[12:14:58 - 12:15:02]
downloaded so it has downloaded in this

[12:15:00 - 12:15:04]
folder actually in my machine now first

[12:15:02 - 12:15:06]
of all I need to load my model to load

[12:15:04 - 12:15:08]
the model actually first of all I'll be

[12:15:06 - 12:15:11]
defining one class Lama actually you

[12:15:08 - 12:15:12]
have seen like we have imported the Lama

[12:15:11 - 12:15:14]
and here you just need to give the model

[12:15:12 - 12:15:15]
path so this is my model path here I

[12:15:14 - 12:15:16]
have given and these are the parameter

[12:15:15 - 12:15:18]
you need to keep it okay these are the

[12:15:16 - 12:15:21]
default parameter you need to keep it

[12:15:18 - 12:15:21]
now let me execute and load the

[12:15:31 - 12:15:35]
model so guys as you can see my model

[12:15:33 - 12:15:37]
has been loaded now here you can also

[12:15:35 - 12:15:40]
check like the number of GPU layer you

[12:15:37 - 12:15:42]
have in your GPU so we have 32 layers

[12:15:40 - 12:15:44]
and and uh now first of all I'll be

[12:15:42 - 12:15:46]
creating one prompt template because

[12:15:44 - 12:15:49]
because we don't directly uh give the

[12:15:46 - 12:15:51]
prompt to our llm uh we also create a

[12:15:49 - 12:15:53]
promt template okay so we won't be

[12:15:51 - 12:15:54]
directly asking the question because

[12:15:53 - 12:15:55]
let's say what kinds of question

[12:15:54 - 12:15:57]
actually you want to ask to your llm you

[12:15:55 - 12:15:58]
need to specify using the prompt

[12:15:57 - 12:15:59]
template I think you are already

[12:15:58 - 12:16:01]
familiar with what is prompt template

[12:15:59 - 12:16:03]
and all so here I have created one

[12:16:01 - 12:16:04]
prompt template so this is my prompt

[12:16:03 - 12:16:07]
this is the question of the users just

[12:16:04 - 12:16:09]
write amist image classification code in

[12:16:07 - 12:16:12]
kasas and here is the promt template so

[12:16:09 - 12:16:14]
I'm telling my llm so here I'm telling

[12:16:12 - 12:16:17]
to my llm as a system system means uh it

[12:16:14 - 12:16:18]
will consider I'm telling to my llm and

[12:16:17 - 12:16:21]
here I'm telling you are a helpful and

[12:16:18 - 12:16:24]
respectful and honest assistant always

[12:16:21 - 12:16:26]
answer as helpfully okay this is my

[12:16:24 - 12:16:28]
prompt template and here I'm giving one

[12:16:26 - 12:16:30]
example so user will ask this kinds of

[12:16:28 - 12:16:31]
question and you need to give the answer

[12:16:30 - 12:16:34]
as a assistant assist assistant should

[12:16:31 - 12:16:36]
be the response from my llm okay so this

[12:16:34 - 12:16:38]
The Prompt template I have created now

[12:16:36 - 12:16:40]
let me execute now here I'm initializing

[12:16:38 - 12:16:42]
my llm so here I'm giving first of all

[12:16:40 - 12:16:44]
my from template then I'm also

[12:16:42 - 12:16:46]
initializing the max tokens Max token

[12:16:44 - 12:16:48]
means like how many output you wants

[12:16:46 - 12:16:50]
from your model you can if you're using

[12:16:48 - 12:16:52]
CPU so you can decrease this length if

[12:16:50 - 12:16:53]
you're using GPU you can increase this

[12:16:52 - 12:16:55]
length Okay temperature I think you

[12:16:53 - 12:16:57]
already know if it is close to zero that

[12:16:55 - 12:16:59]
means you are uh you are taking like

[12:16:57 - 12:17:01]
more streak output from your model and

[12:16:59 - 12:17:03]
if you are increasing to one that means

[12:17:01 - 12:17:06]
uh you are taking the randomness from

[12:17:03 - 12:17:08]
your model but here I have set 0.5 so

[12:17:06 - 12:17:10]
it's middle position and this is the top

[12:17:08 - 12:17:12]
probability score and uh these are some

[12:17:10 - 12:17:15]
default parameter you need to give okay

[12:17:12 - 12:17:15]
now let me execute

[12:17:15 - 12:17:20]
it so it will take the prompt and it

[12:17:18 - 12:17:21]
will understand the prompt template and

[12:17:20 - 12:17:23]
it will give you the answer so here I

[12:17:21 - 12:17:25]
have written like uh write a amist

[12:17:23 - 12:17:29]
classification code in kasas so it will

[12:17:25 - 12:17:29]
uh give you the code with respect to

[12:17:30 - 12:17:34]
that and this model is pretty huge

[12:17:33 - 12:17:35]
that's why the response time is little

[12:17:34 - 12:17:37]
bit

[12:17:35 - 12:17:40]
High uh so you need to wait for some

[12:17:37 - 12:17:40]
time

[12:17:42 - 12:17:46]
so guys execution done now let me print

[12:17:44 - 12:17:48]
the response I got so this is the

[12:17:46 - 12:17:50]
response but it's not readable so from

[12:17:48 - 12:17:54]
this response I only need to see the

[12:17:50 - 12:17:57]
text uh from my model so let me execute

[12:17:54 - 12:18:00]
see guys so uh so here I got the answer

[12:17:57 - 12:18:02]
so here if you see um this is my system

[12:18:00 - 12:18:04]
that means this is my prompt I have

[12:18:02 - 12:18:06]
given to my model and this is the

[12:18:04 - 12:18:07]
question user has asked and this is the

[12:18:06 - 12:18:09]
response I got from my assistant so

[12:18:07 - 12:18:11]
first of all it's telling hello I would

[12:18:09 - 12:18:14]
be help uh happy to help you your Mist

[12:18:11 - 12:18:17]
classification projects using kasas uh

[12:18:14 - 12:18:19]
before we uh begin may I ask what

[12:18:17 - 12:18:21]
specific aspect of the projects you need

[12:18:19 - 12:18:23]
to assistant uh assistant with do do you

[12:18:21 - 12:18:25]
any pyro experience with the Deep

[12:18:23 - 12:18:28]
learning and caras additional uh so it's

[12:18:25 - 12:18:29]
giving some uh output so what you can do

[12:18:28 - 12:18:33]
you can again execute this code I think

[12:18:29 - 12:18:34]
it will give you uh that because if

[12:18:33 - 12:18:37]
you're using for the first time I think

[12:18:34 - 12:18:41]
it will give you that uh response now

[12:18:37 - 12:18:41]
let me execute for the second time

[12:18:46 - 12:18:50]
so guys now you can see uh it has giving

[12:18:48 - 12:18:52]
me the code for the amist MS

[12:18:50 - 12:18:56]
classification now let me give another

[12:18:52 - 12:18:59]
uh prompt so here I'll just write uh

[12:18:56 - 12:19:02]
wrer um

[12:18:59 - 12:19:05]
linear

[12:19:02 - 12:19:05]
regression

[12:19:06 - 12:19:12]
code wrer linear regression code let me

[12:19:10 - 12:19:15]
let's see like whether it is able to

[12:19:12 - 12:19:15]
give or not so again

[12:19:24 - 12:19:29]
execute now guys I got the response and

[12:19:27 - 12:19:31]
guys this is the code for linear

[12:19:29 - 12:19:35]
regression okay so it's amazing guys so

[12:19:31 - 12:19:37]
we are getting our output and uh like uh

[12:19:35 - 12:19:41]
yeah so that's how actually we can use

[12:19:37 - 12:19:43]
uh our LMA 2 model OKAY Lama model we

[12:19:41 - 12:19:46]
can run and this is the Quant version of

[12:19:43 - 12:19:48]
the model again U some accuracy might be

[12:19:46 - 12:19:49]
uh less okay you you might get some

[12:19:48 - 12:19:51]
wrong output because of the Quant

[12:19:49 - 12:19:54]
version of the model okay but again it's

[12:19:51 - 12:19:56]
a pretty good uh you will get like all

[12:19:54 - 12:19:59]
of the response okay whatever question

[12:19:56 - 12:20:01]
you are asking now uh what I will do uh

[12:19:59 - 12:20:02]
this was like how we can execute like qu

[12:20:01 - 12:20:05]
PR version of the model because I was

[12:20:02 - 12:20:07]
using uh because here I was using lamb

[12:20:05 - 12:20:08]
to 13 billion parameter this model but

[12:20:07 - 12:20:11]
next actually I'll will show you like

[12:20:08 - 12:20:13]
how we can execute using Lang Chen okay

[12:20:11 - 12:20:15]
how we can use using Lang Chen so there

[12:20:13 - 12:20:18]
actually I'm going to use this model

[12:20:15 - 12:20:19]
called 7 billion so s 7 billion

[12:20:18 - 12:20:22]
parameter this model actually I'm going

[12:20:19 - 12:20:23]
to use okay and it this model has

[12:20:22 - 12:20:25]
actually lots of variant okay I'll tell

[12:20:23 - 12:20:27]
you so we'll be using some HF version of

[12:20:25 - 12:20:30]
the model okay then I'll show you like

[12:20:27 - 12:20:32]
how we can load this model so yes guys

[12:20:30 - 12:20:35]
uh this is all of about this execution

[12:20:32 - 12:20:37]
of this Lama 2 model on Google cab now

[12:20:35 - 12:20:39]
let's explore like how we can use this

[12:20:37 - 12:20:41]
Lama to model with the help of Lang chin

[12:20:39 - 12:20:43]
so guys now let's see like how we can

[12:20:41 - 12:20:45]
use Lama 2 model with the help of Lang

[12:20:43 - 12:20:48]
chain framework and uh we have already

[12:20:45 - 12:20:50]
seen like how we can execute this Lama 2

[12:20:48 - 12:20:53]
model on Google collab so there actually

[12:20:50 - 12:20:55]
I used like one particular model uh so

[12:20:53 - 12:20:56]
13 billion parameter model but there

[12:20:55 - 12:20:58]
actually I used something called

[12:20:56 - 12:21:01]
quantized Model because I can't load

[12:20:58 - 12:21:02]
this 30 billion model okay in my uh free

[12:21:01 - 12:21:05]
Google collab I think I was already

[12:21:02 - 12:21:07]
discussing about okay but uh in this uh

[12:21:05 - 12:21:09]
example I'll be using this 7 billion

[12:21:07 - 12:21:12]
parameters so this model would be a

[12:21:09 - 12:21:15]
little bit uh uh small for me to load in

[12:21:12 - 12:21:16]
my memory so I can load this model okay

[12:21:15 - 12:21:18]
in my fre Google collab there is no

[12:21:16 - 12:21:21]
issue with that but but again uh to load

[12:21:18 - 12:21:23]
this model uh you need to take the

[12:21:21 - 12:21:24]
permission from meta AI okay uh this

[12:21:23 - 12:21:26]
model is available on the hugging face

[12:21:24 - 12:21:28]
website I will tell you like where where

[12:21:26 - 12:21:30]
you can get this model so if you search

[12:21:28 - 12:21:32]
on Google like Lama Facebook research so

[12:21:30 - 12:21:34]
you will get this GitHub repository and

[12:21:32 - 12:21:36]
there actually they have mentioned

[12:21:34 - 12:21:37]
everything about Lama 2 and all and uh

[12:21:36 - 12:21:38]
they will also give you the download

[12:21:37 - 12:21:40]
link and all so if you click on this

[12:21:38 - 12:21:42]
download link so it will redirect to

[12:21:40 - 12:21:44]
this page and here you just need to fill

[12:21:42 - 12:21:46]
out this information okay so I think I

[12:21:44 - 12:21:47]
already showed you this thing and they

[12:21:46 - 12:21:49]
have already written like how we can

[12:21:47 - 12:21:51]
access this model from the hugging face

[12:21:49 - 12:21:52]
also see uh this model is also available

[12:21:51 - 12:21:56]
on the hugging face website so you can

[12:21:52 - 12:21:59]
visit hugging face and uh see uh it has

[12:21:56 - 12:22:01]
this three variant uh like 7B 13B and

[12:21:59 - 12:22:03]
70b I think I was already discussing

[12:22:01 - 12:22:05]
about and again if you see here uh these

[12:22:03 - 12:22:10]
are the model has lots of sub variant

[12:22:05 - 12:22:11]
like Lama 27b chat model Lama 213b HF

[12:22:10 - 12:22:13]
model model okay so these are the like

[12:22:11 - 12:22:16]
sub bant of the model so this is nothing

[12:22:13 - 12:22:17]
but like I mean some of the model would

[12:22:16 - 12:22:19]
be bigger some of the model would be

[12:22:17 - 12:22:20]
smaller okay so that's how they have

[12:22:19 - 12:22:22]
trained different different model with

[12:22:20 - 12:22:26]
respect to these are the uh variant of

[12:22:22 - 12:22:27]
the model okay now here if you see here

[12:22:26 - 12:22:29]
in the GitHub they have written one

[12:22:27 - 12:22:31]
thing this Lama to comes with two

[12:22:29 - 12:22:33]
different model one is like pretin model

[12:22:31 - 12:22:35]
and another is like fine tune chat model

[12:22:33 - 12:22:37]
so what is Preen model and what is this

[12:22:35 - 12:22:39]
fine tune chat model so pretin model is

[12:22:37 - 12:22:41]
nothing but these model are not fine

[12:22:39 - 12:22:43]
tune for the chat or question answer

[12:22:41 - 12:22:44]
they should be prompted so that uh

[12:22:43 - 12:22:47]
expected answer is the natural

[12:22:44 - 12:22:48]
continuation of the prompt so basically

[12:22:47 - 12:22:50]
what they're telling actually with this

[12:22:48 - 12:22:51]
pre-end model you can't do actually chat

[12:22:50 - 12:22:53]
operation or you can't do actually

[12:22:51 - 12:22:55]
question answering operation right like

[12:22:53 - 12:22:58]
the way we usually perform with our llm

[12:22:55 - 12:23:00]
model we ask any question we do the chat

[12:22:58 - 12:23:01]
operation with that so with this pretend

[12:23:00 - 12:23:03]
model you can do let's see if you want

[12:23:01 - 12:23:05]
to uh generate text or if you want to

[12:23:03 - 12:23:07]
let's say generate uh something okay

[12:23:05 - 12:23:09]
from the model you can use these kinds

[12:23:07 - 12:23:12]
of PR model okay and what is this fine

[12:23:09 - 12:23:14]
tune chat model so this F chat model we

[12:23:12 - 12:23:16]
trained on dialogue applications so to

[12:23:14 - 12:23:18]
get the expected features from uh and

[12:23:16 - 12:23:20]
performance for them the specific format

[12:23:18 - 12:23:22]
define chat completion so basically what

[12:23:20 - 12:23:23]
they're telling so with this fine tune

[12:23:22 - 12:23:25]
chat model actually you can do the chat

[12:23:23 - 12:23:26]
operation let's say if you want to do

[12:23:25 - 12:23:27]
any question answering if you want to

[12:23:26 - 12:23:29]
perform in chat operation you can use

[12:23:27 - 12:23:31]
this fine tune chat model so in this

[12:23:29 - 12:23:33]
example I'll be using this fine tune

[12:23:31 - 12:23:35]
chat model because I want to perform um

[12:23:33 - 12:23:37]
chat operation with the llm okay I want

[12:23:35 - 12:23:38]
to ask some queries and all so I'll be

[12:23:37 - 12:23:39]
using this model but let's see if you

[12:23:38 - 12:23:41]
want to generate text and if you want to

[12:23:39 - 12:23:45]
generate something so you can use this

[12:23:41 - 12:23:48]
pretin model okay so now if you visit

[12:23:45 - 12:23:49]
here in this metal Lama to on hugging

[12:23:48 - 12:23:51]
face so they have different different

[12:23:49 - 12:23:53]
model as I already told you so it has

[12:23:51 - 12:23:55]
chat model also and it has without chat

[12:23:53 - 12:23:57]
model also so now you can choose any of

[12:23:55 - 12:23:58]
them okay uh so guys from these are the

[12:23:57 - 12:24:00]
model itself I'm I'll be using one

[12:23:58 - 12:24:02]
particular model so I'm going to use

[12:24:00 - 12:24:05]
this particular model called Lama 27b

[12:24:02 - 12:24:06]
chat H model so here is the model

[12:24:05 - 12:24:08]
description and all about you can read

[12:24:06 - 12:24:10]
it out okay so with this model actually

[12:24:08 - 12:24:12]
you can do chat operation and all okay

[12:24:10 - 12:24:14]
and this is 7 billion parameters so I

[12:24:12 - 12:24:15]
can easily load this model in my uh free

[12:24:14 - 12:24:18]
Google collab okay so there is no issue

[12:24:15 - 12:24:20]
with that I don't need to use any U you

[12:24:18 - 12:24:24]
can say quantized model okay uh from

[12:24:20 - 12:24:26]
them so uh now uh what I will do before

[12:24:24 - 12:24:27]
uh see before loading this model you

[12:24:26 - 12:24:29]
need to take the permission from The

[12:24:27 - 12:24:32]
Meta AI so what you need to do here so

[12:24:29 - 12:24:34]
you will see one uh like option here

[12:24:32 - 12:24:36]
just apply for the permission uh see for

[12:24:34 - 12:24:37]
me I have already applied for a

[12:24:36 - 12:24:38]
permission and and they have already

[12:24:37 - 12:24:40]
given me the access that's why it's

[12:24:38 - 12:24:42]
telling you have been granted to this

[12:24:40 - 12:24:44]
this model okay uh so I already have the

[12:24:42 - 12:24:46]
access to this model but if you're doing

[12:24:44 - 12:24:48]
it for the first time make sure you have

[12:24:46 - 12:24:50]
applied for the permission okay so once

[12:24:48 - 12:24:52]
you get the permission so uh you will

[12:24:50 - 12:24:54]
get these kinds of message here if you

[12:24:52 - 12:24:57]
see

[12:24:54 - 12:24:58]
here uh you will get this kinds of email

[12:24:57 - 12:25:00]
like you have granted to this model and

[12:24:58 - 12:25:03]
all so they will mail you with respect

[12:25:00 - 12:25:05]
to that and once you click here so you

[12:25:03 - 12:25:06]
will uh redirect to these kinds of form

[12:25:05 - 12:25:08]
so here you just need to these are the

[12:25:06 - 12:25:10]
form and submit your information so

[12:25:08 - 12:25:11]
after some times actually they will give

[12:25:10 - 12:25:13]
you the permission but if you're doing

[12:25:11 - 12:25:15]
it right now and if you're waiting for

[12:25:13 - 12:25:17]
the permission so what you can do in

[12:25:15 - 12:25:18]
between I will show you another option

[12:25:17 - 12:25:20]
okay another another alternative I will

[12:25:18 - 12:25:22]
show you so that alternative you can

[12:25:20 - 12:25:24]
follow and guys one particular thing you

[12:25:22 - 12:25:26]
will always need to remember so whenever

[12:25:24 - 12:25:28]
you are uh submitting the request okay

[12:25:26 - 12:25:30]
whenever you are submitting the request

[12:25:28 - 12:25:32]
for this model make sure the email

[12:25:30 - 12:25:34]
address you are using the same email

[12:25:32 - 12:25:37]
address you are used in your hugging

[12:25:34 - 12:25:38]
face as well okay so the same uh hugging

[12:25:37 - 12:25:40]
face email address okay you have created

[12:25:38 - 12:25:41]
your account so same email address add

[12:25:40 - 12:25:43]
you need to submit here okay as you can

[12:25:41 - 12:25:45]
see you need to submit your email

[12:25:43 - 12:25:46]
address here so make sure you have

[12:25:45 - 12:25:48]
selected the correct email address with

[12:25:46 - 12:25:49]
respect to your hugging F account so

[12:25:48 - 12:25:51]
that you will get the quick access there

[12:25:49 - 12:25:53]
so guys I already created one notebook

[12:25:51 - 12:25:55]
for you so here I will show you the demo

[12:25:53 - 12:25:57]
how we can use this Lama 2 model with

[12:25:55 - 12:25:59]
the help of Lang Chen and I think you

[12:25:57 - 12:26:00]
already know what is langen langen is

[12:25:59 - 12:26:02]
nothing but it's a framework for

[12:26:00 - 12:26:03]
developing application powered by

[12:26:02 - 12:26:06]
language model or you can say we can

[12:26:03 - 12:26:08]
also uh uh develop generative VI

[12:26:06 - 12:26:10]
application with the help of langen and

[12:26:08 - 12:26:12]
this is the langen documentation and G

[12:26:10 - 12:26:14]
already given here you can go go and

[12:26:12 - 12:26:16]
check and if you and if you don't know

[12:26:14 - 12:26:17]
like Lang chain so we have a tutorial in

[12:26:16 - 12:26:19]
our YouTube channel just go ahead and

[12:26:17 - 12:26:21]
try to uh finish that lecture otherwise

[12:26:19 - 12:26:22]
uh it would be a little bit difficult

[12:26:21 - 12:26:24]
for you to understand like what I'm

[12:26:22 - 12:26:25]
trying to say right so guys here I'm

[12:26:24 - 12:26:27]
already expecting you are familiar with

[12:26:25 - 12:26:29]
this langen framework uh like what is

[12:26:27 - 12:26:30]
chain what is prom template and all

[12:26:29 - 12:26:33]
about okay so this should be the

[12:26:30 - 12:26:34]
prerequisite for this video now guys uh

[12:26:33 - 12:26:36]
the first thing what I need to do I need

[12:26:34 - 12:26:38]
to connect my

[12:26:36 - 12:26:41]
notebook and make sure you have selected

[12:26:38 - 12:26:43]
runtime at GPU because uh you need the

[12:26:41 - 12:26:45]
GPU to run this model so change run type

[12:26:43 - 12:26:48]
to GPU so for me I have already selected

[12:26:45 - 12:26:49]
and let me connect the notebook so guys

[12:26:48 - 12:26:52]
uh notebook is connected now first of

[12:26:49 - 12:26:54]
all let's see whether I got GPU or not

[12:26:52 - 12:26:56]
so this is the command to check the GPU

[12:26:54 - 12:26:59]
so here I got Tesla T4 and here I got

[12:26:56 - 12:27:01]
15gb vram now what I need to do guys uh

[12:26:59 - 12:27:03]
I need to install some of the libraries

[12:27:01 - 12:27:05]
see guys uh if you're using any open

[12:27:03 - 12:27:06]
source large language model okay open

[12:27:05 - 12:27:08]
source llm model which is available in

[12:27:06 - 12:27:10]
hugging pH so for this actually you need

[12:27:08 - 12:27:13]
to install this Transformer Library okay

[12:27:10 - 12:27:15]
so using this Transformer Library we can

[12:27:13 - 12:27:17]
actually uh access our hugging face

[12:27:15 - 12:27:19]
model okay so that's why this

[12:27:17 - 12:27:20]
Transformer Library we need to install

[12:27:19 - 12:27:22]
then uh I need to also install these are

[12:27:20 - 12:27:25]
the two libraries accelerate and uh

[12:27:22 - 12:27:26]
enops then I I need also Lang chain

[12:27:25 - 12:27:29]
because here I'm going to use langin

[12:27:26 - 12:27:31]
okay and uh this uh bense bytes okay so

[12:27:29 - 12:27:32]
this uh these are the packet actually I

[12:27:31 - 12:27:34]
need to install so these are the

[12:27:32 - 12:27:35]
actually dependency so langen I need

[12:27:34 - 12:27:39]
because I will be running these at the

[12:27:35 - 12:27:41]
LM Model H LM model with the help of Lin

[12:27:39 - 12:27:43]
and I also need Transformer because I

[12:27:41 - 12:27:45]
will be using my Lamar to model from my

[12:27:43 - 12:27:48]
Hing fa itself okay that's why this

[12:27:45 - 12:27:48]
Transformer is required now let me

[12:28:00 - 12:28:03]
install uh so guys as you can see

[12:28:02 - 12:28:05]
installation is done then uh first of

[12:28:03 - 12:28:07]
all what I need to do I need to loging

[12:28:05 - 12:28:10]
with the HF account okay so to loging

[12:28:07 - 12:28:12]
with the HF account uh uh you need to

[12:28:10 - 12:28:15]
use hugging face CLI to login okay so

[12:28:12 - 12:28:16]
here you just need to give the uh API

[12:28:15 - 12:28:17]
key okay hugging face API key so there

[12:28:16 - 12:28:20]
is a secret key actually you will get

[12:28:17 - 12:28:22]
from your huging face account so let me

[12:28:20 - 12:28:23]
open with my huging face account so guys

[12:28:22 - 12:28:24]
this is my huging face account if you

[12:28:23 - 12:28:26]
don't have any huging face account just

[12:28:24 - 12:28:28]
try to create one account okay now if

[12:28:26 - 12:28:30]
you click on the profile and go to the

[12:28:28 - 12:28:31]
settings and here you will get one

[12:28:30 - 12:28:33]
option called access token okay just

[12:28:31 - 12:28:34]
click on the access token so here

[12:28:33 - 12:28:36]
previously I already created one access

[12:28:34 - 12:28:37]
token here so I'll be creating a new one

[12:28:36 - 12:28:40]
so you can also create a new access

[12:28:37 - 12:28:43]
token you can give any name so let's say

[12:28:40 - 12:28:45]
I will give as Lama and uh you can get

[12:28:43 - 12:28:47]
uh read and write permission uh I will

[12:28:45 - 12:28:49]
be giving read permission because I only

[12:28:47 - 12:28:51]
want to read the model from here then

[12:28:49 - 12:28:53]
I'll just generate a token so this is my

[12:28:51 - 12:28:55]
token guys now what I will do I'll just

[12:28:53 - 12:28:57]
copy this token and guys don't share

[12:28:55 - 12:28:58]
this token with anyone okay otherwise

[12:28:57 - 12:29:00]
they will also able to access your

[12:28:58 - 12:29:01]
account so I'll remove this uh token

[12:29:00 - 12:29:05]
after this recording okay that's why I'm

[12:29:01 - 12:29:07]
showing now let me execute this uh

[12:29:05 - 12:29:09]
command and it will ask for the token so

[12:29:07 - 12:29:13]
just click here and paste your token and

[12:29:09 - 12:29:15]
just press enter so if you do it so now

[12:29:13 - 12:29:18]
it will tell add token as G credential

[12:29:15 - 12:29:21]
so what I will do I'll just give uh yes

[12:29:18 - 12:29:23]
and press enter now guys here if you see

[12:29:21 - 12:29:25]
my logging is successful now what I will

[12:29:23 - 12:29:28]
do I will import uh then I need to

[12:29:25 - 12:29:30]
import uh this HF pipeline from langin

[12:29:28 - 12:29:32]
len. llms because with this uh HF

[12:29:30 - 12:29:34]
pipeline so with the help of this HF

[12:29:32 - 12:29:35]
pipeline class I will be loading my

[12:29:34 - 12:29:38]
large language model which is nothing

[12:29:35 - 12:29:41]
but my Lama 2 okay so I need to import

[12:29:38 - 12:29:43]
this Library then I also need to uh

[12:29:41 - 12:29:45]
import tokenizer so what is tokenizer

[12:29:43 - 12:29:46]
guys tokenizer is nothing but uh it is

[12:29:45 - 12:29:49]
responsible for uh pre-processing the

[12:29:46 - 12:29:51]
text into Aras of number as uh input to

[12:29:49 - 12:29:53]
the model because so whenever I will be

[12:29:51 - 12:29:55]
giving any input to my model it would be

[12:29:53 - 12:29:58]
completely a text input right but my

[12:29:55 - 12:29:59]
model can't understand that uh text uh

[12:29:58 - 12:30:00]
raw text actually I'll be giving so for

[12:29:59 - 12:30:02]
for this actually what I need to do I

[12:30:00 - 12:30:04]
need to convert to numbers right right

[12:30:02 - 12:30:05]
even I also need to perform some

[12:30:04 - 12:30:07]
pre-processing so everything can be

[12:30:05 - 12:30:09]
perform using this tokenizer okay autot

[12:30:07 - 12:30:12]
tokenizer class that's why I need to

[12:30:09 - 12:30:17]
import it then I also importing uh

[12:30:12 - 12:30:17]
Transformers then torch and this

[12:30:18 - 12:30:23]
warnings okay now uh let's load our L 2

[12:30:21 - 12:30:25]
model from this huging face so as I

[12:30:23 - 12:30:27]
already told you so you will get this

[12:30:25 - 12:30:29]
kinds of access once you got the access

[12:30:27 - 12:30:30]
and all okay so I have already attached

[12:30:29 - 12:30:32]
some screenshot here and once it is done

[12:30:30 - 12:30:34]
it will tell you this message right now

[12:30:32 - 12:30:36]
here guys you need to define the model

[12:30:34 - 12:30:37]
actually you want to use so in this case

[12:30:36 - 12:30:40]
actually I'm using this model as I

[12:30:37 - 12:30:41]
already told you I just copied this name

[12:30:40 - 12:30:43]
and just paste it here if you see this

[12:30:41 - 12:30:44]
is the complete name I have given and

[12:30:43 - 12:30:45]
this is the model from meta because this

[12:30:44 - 12:30:47]
is the official model actually I'm going

[12:30:45 - 12:30:49]
to use and this model I need the

[12:30:47 - 12:30:50]
permission I think I already told you

[12:30:49 - 12:30:52]
this model I need the permission but

[12:30:50 - 12:30:53]
let's say if it is taking for you to uh

[12:30:52 - 12:30:55]
take the permission and all so what you

[12:30:53 - 12:30:58]
can do you can use this model you just

[12:30:55 - 12:31:00]
comment this line and uncommon this line

[12:30:58 - 12:31:02]
so this is the same model but this is

[12:31:00 - 12:31:04]
this is present in the public repository

[12:31:02 - 12:31:05]
and this access is given to everyone

[12:31:04 - 12:31:07]
okay so you can easily use this model

[12:31:05 - 12:31:08]
and this is the same same model guys

[12:31:07 - 12:31:11]
okay this is the same version of the

[12:31:08 - 12:31:13]
model so what this guy has done actually

[12:31:11 - 12:31:17]
so he has cloned the official version of

[12:31:13 - 12:31:19]
this LMA to 7B CH HF model and he has

[12:31:17 - 12:31:21]
published in his uh you can say uh

[12:31:19 - 12:31:22]
repository here and this is completely

[12:31:21 - 12:31:24]
and this is uh completely Public Access

[12:31:22 - 12:31:26]
so you don't need to take any access uh

[12:31:24 - 12:31:29]
okay from from this author so you can

[12:31:26 - 12:31:30]
easily uh use this model so let's say if

[12:31:29 - 12:31:32]
uh you have applied for the access and

[12:31:30 - 12:31:34]
it is taking time and you want to do it

[12:31:32 - 12:31:36]
right now with me so what you can do you

[12:31:34 - 12:31:37]
can uncomment this line and you can load

[12:31:36 - 12:31:39]
this model okay but for me I have

[12:31:37 - 12:31:41]
already access to my official model so

[12:31:39 - 12:31:43]
I'll be using official model and I will

[12:31:41 - 12:31:45]
comment it out okay so it's up to you

[12:31:43 - 12:31:46]
which model you're going to use now guys

[12:31:45 - 12:31:48]
first of all what I need to do I need to

[12:31:46 - 12:31:49]
load my tokenizer so to load the

[12:31:48 - 12:31:51]
tokenizer you need to give the same

[12:31:49 - 12:31:54]
model name okay so with respect to that

[12:31:51 - 12:31:55]
it will load the tokenizer now here uh

[12:31:54 - 12:31:57]
what you need to do you need to create

[12:31:55 - 12:31:59]
one pipeline objects and here you need

[12:31:57 - 12:32:00]
to call this Transformer pipeline okay

[12:31:59 - 12:32:02]
and here you need to uh give the

[12:32:00 - 12:32:05]
pipeline name so here I have given Tex

[12:32:02 - 12:32:07]
generation because if I go to this model

[12:32:05 - 12:32:09]
I'm using so this is a Tex generation

[12:32:07 - 12:32:10]
model as as you can see this is a tech

[12:32:09 - 12:32:13]
generation model so that is why I have

[12:32:10 - 12:32:15]
given Tex generation here now I I also

[12:32:13 - 12:32:16]
need to give the model um like which

[12:32:15 - 12:32:18]
model I'm going to use so this is the

[12:32:16 - 12:32:19]
model I have given here okay then I'm

[12:32:18 - 12:32:21]
also need to give the tokenizer so this

[12:32:19 - 12:32:22]
is the tokenizer I have given and these

[12:32:21 - 12:32:24]
are the parameters just keep it as

[12:32:22 - 12:32:26]
default and this is the maximum input

[12:32:24 - 12:32:28]
length so I've given 1,000 you can also

[12:32:26 - 12:32:30]
increase and decrease the size okay it's

[12:32:28 - 12:32:31]
up to you now guys what I will do I'll

[12:32:30 - 12:32:33]
just quickly uh load my pipeline so

[12:32:31 - 12:32:35]
basically it will load the entire

[12:32:33 - 12:32:36]
pipeline it will load your model it will

[12:32:35 - 12:32:39]
load your tokenizer everything it will

[12:32:36 - 12:32:40]
load as a pipeline so what is the use of

[12:32:39 - 12:32:42]
this pipeline line means like first of

[12:32:40 - 12:32:44]
all whenever you are giving any input to

[12:32:42 - 12:32:46]
the model first of all it will apply the

[12:32:44 - 12:32:48]
tokenizer and it will convert that text

[12:32:46 - 12:32:51]
to numbers okay it will preprocess the

[12:32:48 - 12:32:52]
text then it will apply uh this data to

[12:32:51 - 12:32:54]
the model okay so that's why this

[12:32:52 - 12:32:55]
pipeline handles each and everything you

[12:32:54 - 12:32:58]
don't need to write any custom code for

[12:32:55 - 12:33:00]
it and now guys here if you see uh it is

[12:32:58 - 12:33:03]
downloading the model okay and I'm using

[12:33:00 - 12:33:07]
uh free collab and I got 15gb vram there

[12:33:03 - 12:33:09]
so I think you can see uh RAM is uh is

[12:33:07 - 12:33:10]
not utilized till now because it is

[12:33:09 - 12:33:14]
downloading the mod so once it will load

[12:33:10 - 12:33:14]
the model it will utilize my

[12:33:14 - 12:33:19]
Ram so guys my model has loaded now what

[12:33:17 - 12:33:21]
I need to do I need to call this hugging

[12:33:19 - 12:33:23]
face pipeline I think you remember we

[12:33:21 - 12:33:26]
load this hugging face pipeline from

[12:33:23 - 12:33:28]
langin okay here if you see from langin

[12:33:26 - 12:33:30]
LM we load this Hing face pipeline now I

[12:33:28 - 12:33:33]
need to give this pipeline object to

[12:33:30 - 12:33:36]
this uh huging face pipeline from my

[12:33:33 - 12:33:37]
langin uh so here uh you will get to

[12:33:36 - 12:33:38]
parameter called pipeline so here you

[12:33:37 - 12:33:40]
just need to provide the pipeline okay

[12:33:38 - 12:33:42]
this pipeline we have created

[12:33:40 - 12:33:43]
and another uh keyword you need to give

[12:33:42 - 12:33:45]
the temperature value so what is

[12:33:43 - 12:33:46]
temperature value so see uh I think you

[12:33:45 - 12:33:48]
already know like what is temperature

[12:33:46 - 12:33:51]
value so here I've already written so

[12:33:48 - 12:33:53]
temperature value like uh so if it is

[12:33:51 - 12:33:56]
zero that means the model is very safe

[12:33:53 - 12:33:59]
and it is not taking any Bits And if you

[12:33:56 - 12:34:01]
are uh like uh giving this uh and if

[12:33:59 - 12:34:03]
you're setting this value to close to

[12:34:01 - 12:34:05]
one so it will be uh taking risk okay

[12:34:03 - 12:34:07]
and it might generate wrong output but

[12:34:05 - 12:34:09]
it is very creative so this is the

[12:34:07 - 12:34:11]
parameter actually you can change uh

[12:34:09 - 12:34:12]
let's say if you want some stick output

[12:34:11 - 12:34:15]
from your model okay you can set this

[12:34:12 - 12:34:17]
parameter as close to zero and if you

[12:34:15 - 12:34:19]
want let's say very creative results and

[12:34:17 - 12:34:21]
uh you are not woring about the wrong

[12:34:19 - 12:34:23]
output or let's say random output so you

[12:34:21 - 12:34:24]
can uh give this parameter as one okay

[12:34:23 - 12:34:26]
so this is the parameter you need to

[12:34:24 - 12:34:28]
give so here I want streak output from

[12:34:26 - 12:34:30]
my model that's why I set this parameter

[12:34:28 - 12:34:32]
as zero okay so this is the parameter I

[12:34:30 - 12:34:34]
have given now here I'm defining as llm

[12:34:32 - 12:34:35]
so this is my large language model okay

[12:34:34 - 12:34:37]
but I think you remember initially we I

[12:34:35 - 12:34:39]
was loading I was using something called

[12:34:37 - 12:34:41]
open large language model which is

[12:34:39 - 12:34:44]
nothing but GPT 3.5 turbo you can use

[12:34:41 - 12:34:47]
anything gpt3 GPT 4 anything you can use

[12:34:44 - 12:34:49]
but there actually I I was using open

[12:34:47 - 12:34:50]
API and it was taking charge for me

[12:34:49 - 12:34:52]
right but this is completely free now

[12:34:50 - 12:34:54]
see with the help of these kinds of Open

[12:34:52 - 12:34:56]
Source large language model uh and it is

[12:34:54 - 12:34:58]
also available inside hugging P we have

[12:34:56 - 12:35:02]
easily loaded this model okay and we

[12:34:58 - 12:35:03]
have created our llm object here now

[12:35:02 - 12:35:04]
this is one prompt actually I have

[12:35:03 - 12:35:06]
prepared so what would be the good name

[12:35:04 - 12:35:08]
for a company that makes colorful socks

[12:35:06 - 12:35:10]
so this let's say this is my uh prompt

[12:35:08 - 12:35:12]
this is the user prompt this is the user

[12:35:10 - 12:35:15]
input and it is giving this input to the

[12:35:12 - 12:35:17]
llm and now let's see like what llm will

[12:35:15 - 12:35:20]
predict okay so here I will uh give this

[12:35:17 - 12:35:22]
prom to my llm and let me execute you

[12:35:20 - 12:35:24]
can also set your custom template promp

[12:35:22 - 12:35:26]
template I will tell you like how to set

[12:35:24 - 12:35:27]
it but first of all Let's uh give my

[12:35:26 - 12:35:30]
prompt without any

[12:35:27 - 12:35:32]
template because uh by default your LM

[12:35:30 - 12:35:34]
will have some C like you can say

[12:35:32 - 12:35:36]
default template it will use that

[12:35:34 - 12:35:39]
template so guys here is the response I

[12:35:36 - 12:35:40]
got from my Lama 2 so I would suggest

[12:35:39 - 12:35:43]
the following names for the company that

[12:35:40 - 12:35:46]
makes colorful socks so Soul mats Hue

[12:35:43 - 12:35:47]
and cry tall tally socks okay it's great

[12:35:46 - 12:35:49]
actually even it is giving us the

[12:35:47 - 12:35:51]
description with respect to the name it

[12:35:49 - 12:35:52]
is suggesting now you can give any kinds

[12:35:51 - 12:35:54]
of prompt you can check it out so let's

[12:35:52 - 12:35:56]
give I I uh another prompt so here I

[12:35:54 - 12:35:59]
have given I want to open a restaurant

[12:35:56 - 12:36:01]
for a Chinese food suggest me a fence

[12:35:59 - 12:36:02]
name for this okay so you can also give

[12:36:01 - 12:36:04]
let's

[12:36:02 - 12:36:07]
say Indian

[12:36:04 - 12:36:09]
food okay I'll give Indian food now

[12:36:07 - 12:36:13]
let's see whether it is giving me some

[12:36:09 - 12:36:13]
name or not so I'll execute my

[12:36:16 - 12:36:21]
llm now guys as you can see it has given

[12:36:19 - 12:36:23]
me the name so restaurant I would

[12:36:21 - 12:36:25]
suggest the following uh names for your

[12:36:23 - 12:36:29]
Italian uh sorry uh for your Indian for

[12:36:25 - 12:36:33]
restaurant so tandur kns then spice R

[12:36:29 - 12:36:34]
Mumbai bazer K Leaf okay so great I am

[12:36:33 - 12:36:36]
getting very good name let's say if you

[12:36:34 - 12:36:37]
want to open any Resturant so you can

[12:36:36 - 12:36:39]
refer these are the name and these are

[12:36:37 - 12:36:41]
the name is like very unique okay and

[12:36:39 - 12:36:43]
this is the description now uh also you

[12:36:41 - 12:36:45]
can create your custom prompt let's say

[12:36:43 - 12:36:47]
uh see this is the better practice to

[12:36:45 - 12:36:50]
create our custom prompt always uh let's

[12:36:47 - 12:36:51]
say whatever task you want to perform uh

[12:36:50 - 12:36:53]
with the help of your llm so you can

[12:36:51 - 12:36:56]
give the custom prompt okay instead of

[12:36:53 - 12:36:58]
using the default prompt so to give your

[12:36:56 - 12:37:00]
custom prompt you need to import prompt

[12:36:58 - 12:37:02]
template from Lang Chen first of all so

[12:37:00 - 12:37:04]
let me import and I also need to import

[12:37:02 - 12:37:06]
something called llm chain okay from

[12:37:04 - 12:37:08]
Lang chain now this is the first example

[12:37:06 - 12:37:10]
I have given so this is my prom template

[12:37:08 - 12:37:13]
one so here I I I've given the same

[12:37:10 - 12:37:14]
prompt I I think you remember and uh

[12:37:13 - 12:37:17]
I've just written I want to open a

[12:37:14 - 12:37:19]
Resturant for uh here I've given kins

[12:37:17 - 12:37:21]
cuin should be the input okay here I've

[12:37:19 - 12:37:23]
given this should be the input variable

[12:37:21 - 12:37:25]
could suggest me a fancy name for this

[12:37:23 - 12:37:27]
now I'll be using this prom template and

[12:37:25 - 12:37:29]
I will be giving to my llm model okay so

[12:37:27 - 12:37:32]
it won't be using that uh default prompt

[12:37:29 - 12:37:34]
template after giving it now let's say

[12:37:32 - 12:37:36]
how it will work so uh this is the

[12:37:34 - 12:37:38]
technique it will work so basically it

[12:37:36 - 12:37:40]
will apply this format on top of it and

[12:37:38 - 12:37:42]
whenever it will get this cuins actually

[12:37:40 - 12:37:43]
it will replace this uh input okay the

[12:37:42 - 12:37:46]
input I have given let's say I have

[12:37:43 - 12:37:47]
given Indian now if I print this input

[12:37:46 - 12:37:49]
prompt if you see I want to a resturent

[12:37:47 - 12:37:50]
for the Indian food search me a fancy

[12:37:49 - 12:37:52]
for this okay so this is the input I

[12:37:50 - 12:37:54]
have prepared with the help of this code

[12:37:52 - 12:37:56]
right now let's take take the second

[12:37:54 - 12:37:58]
example so this is the another prompt I

[12:37:56 - 12:38:01]
have created prompt two and here I'm

[12:37:58 - 12:38:03]
using another prompt provide me a coze

[12:38:01 - 12:38:05]
summary for this book and here I'm

[12:38:03 - 12:38:07]
taking book name as input from the user

[12:38:05 - 12:38:08]
so how it will work so whenever user

[12:38:07 - 12:38:10]
will give an input let's say I have

[12:38:08 - 12:38:12]
given an alchemist book book okay so it

[12:38:10 - 12:38:14]
will take as input and it will make the

[12:38:12 - 12:38:16]
complete prompt see it will make the

[12:38:14 - 12:38:18]
complete prompt okay now let's use uh

[12:38:16 - 12:38:20]
the first one first of all so I'll be

[12:38:18 - 12:38:23]
using this prom template one so here

[12:38:20 - 12:38:26]
just let me write now I'm going to use

[12:38:23 - 12:38:29]
this prompt one the very first let's use

[12:38:26 - 12:38:32]
prompt one and here I have created llm

[12:38:29 - 12:38:33]
chain and here I have given my llm okay

[12:38:32 - 12:38:36]
so llm model I have given so which is

[12:38:33 - 12:38:38]
nothing but uh the llm we have created I

[12:38:36 - 12:38:39]
think you remember this is my llm this

[12:38:38 - 12:38:41]
is my llm okay

[12:38:39 - 12:38:43]
and here I have given the llm and here

[12:38:41 - 12:38:45]
I'm giving the prompt as my prompt

[12:38:43 - 12:38:46]
template and here I'm also giving varos

[12:38:45 - 12:38:48]
is equal to true that means it will also

[12:38:46 - 12:38:50]
print the log like what is doing

[12:38:48 - 12:38:52]
actually so if it is if you're making it

[12:38:50 - 12:38:53]
false so you can't see the output log

[12:38:52 - 12:38:56]
and if you are making it two so you can

[12:38:53 - 12:38:59]
you can see the output log okay now here

[12:38:56 - 12:39:00]
uh you need to call chain. run and here

[12:38:59 - 12:39:02]
you just need to give the input okay so

[12:39:00 - 12:39:04]
here let's say I'm running this prompt

[12:39:02 - 12:39:07]
one and this is for the kin so here what

[12:39:04 - 12:39:09]
I will give I'll give Indian kin Indian

[12:39:07 - 12:39:12]
kin okay and this is the response I will

[12:39:09 - 12:39:15]
get now let me execute and show you see

[12:39:12 - 12:39:18]
first of all it is uh uh entering to new

[12:39:15 - 12:39:20]
uh llm chain uh prompt after formatting

[12:39:18 - 12:39:23]
so this is the prompt it has prepared so

[12:39:20 - 12:39:25]
it has taken my input Indian and this is

[12:39:23 - 12:39:27]
the prompt actually it has created now

[12:39:25 - 12:39:31]
it is applying LM on top of it and it

[12:39:27 - 12:39:31]
will uh predict now let's

[12:39:32 - 12:39:38]
see now guys uh chain has been finished

[12:39:35 - 12:39:40]
and this is the response I got aurent

[12:39:38 - 12:39:42]
name uh is is a crucial aspect of the

[12:39:40 - 12:39:44]
any business okay and these are the name

[12:39:42 - 12:39:47]
actually it is suggesting now what I

[12:39:44 - 12:39:49]
will do uh I'll give this prompt

[12:39:47 - 12:39:52]
template two that means my book uh book

[12:39:49 - 12:39:56]
prompt and here now we'll ask any book

[12:39:52 - 12:39:56]
name so let's say I'll give uh Harry

[12:39:57 - 12:40:01]
Potter Harry Potter book I want the

[12:39:59 - 12:40:03]
summary of Harry Potter book let's see

[12:40:01 - 12:40:04]
whether it is able to give or not and

[12:40:03 - 12:40:06]
this model is pretty good guys just try

[12:40:04 - 12:40:09]
to explore this model uh I am loving

[12:40:06 - 12:40:11]
this model A Lot okay um as I opens

[12:40:09 - 12:40:15]
model I can say like this is one of the

[12:40:11 - 12:40:15]
best model you can use from meta

[12:40:16 - 12:40:21]
AI so see guys uh this is giving me the

[12:40:19 - 12:40:22]
summary again if you mention the book

[12:40:21 - 12:40:24]
with a specific name let's say it is

[12:40:22 - 12:40:26]
giving the summary of philosopher stone

[12:40:24 - 12:40:28]
okay you can also give any uh specific

[12:40:26 - 12:40:31]
book it will give you the uh summary in

[12:40:28 - 12:40:33]
that summary it will give you okay so

[12:40:31 - 12:40:35]
great guys we are able to use this lama2

[12:40:33 - 12:40:37]
model with the help of Lang chain and we

[12:40:35 - 12:40:38]
have seen like how we can load this

[12:40:37 - 12:40:40]
model with the help of Lang chin and all

[12:40:38 - 12:40:42]
how we can create the template okay how

[12:40:40 - 12:40:44]
we can create the LM CH and everything

[12:40:42 - 12:40:45]
we have seen right now guys it's time to

[12:40:44 - 12:40:47]
make one projects with the help of this

[12:40:45 - 12:40:49]
Lama 2 now what I will do I will uh

[12:40:47 - 12:40:51]
create one uh chatbot projects with the

[12:40:49 - 12:40:53]
help of this Lama 2 and Lang so

[12:40:51 - 12:40:55]
basically uh we'll be creating one

[12:40:53 - 12:40:57]
chatbot so that can chat with any kinds

[12:40:55 - 12:41:00]
of website so let's say if you have any

[12:40:57 - 12:41:02]
website okay so you can integrate that

[12:41:00 - 12:41:03]
website to your chatbot so whatever

[12:41:02 - 12:41:05]
question user will ask with respect to

[12:41:03 - 12:41:07]
the website it will give you each and

[12:41:05 - 12:41:10]
every answer let's say uh this is one

[12:41:07 - 12:41:12]
website Lama meta website okay so let's

[12:41:10 - 12:41:13]
say I want to ask any questions okay

[12:41:12 - 12:41:16]
from this website let's say I want to

[12:41:13 - 12:41:17]
ask like what this uh website provides

[12:41:16 - 12:41:19]
okay what are the services it provides

[12:41:17 - 12:41:22]
uh give me the contact information and

[12:41:19 - 12:41:24]
all so that chatbot will able to uh give

[12:41:22 - 12:41:26]
me everything with respect to the uh

[12:41:24 - 12:41:27]
website I have so these kinds of chatbot

[12:41:26 - 12:41:30]
actually will be implementing with the

[12:41:27 - 12:41:32]
help of this Lama to and Lang chin okay

[12:41:30 - 12:41:34]
and I will also utilize like vector

[12:41:32 - 12:41:36]
database uh with that uh projects okay

[12:41:34 - 12:41:38]
because I have already explained like

[12:41:36 - 12:41:40]
vector database so I already created one

[12:41:38 - 12:41:42]
dedicated uh session on Vector database

[12:41:40 - 12:41:43]
just go ahead and check it out if you

[12:41:42 - 12:41:45]
haven't checked it out that session so

[12:41:43 - 12:41:47]
guys we'll be using everything like

[12:41:45 - 12:41:48]
vector database this Lama 2 and Lang

[12:41:47 - 12:41:50]
Chen with the help of that actually

[12:41:48 - 12:41:51]
we'll be implementing this entire

[12:41:50 - 12:41:53]
projects okay and this is going to be

[12:41:51 - 12:41:56]
one very interesting projects okay you

[12:41:53 - 12:41:57]
will be enjoying a lot so now let's

[12:41:56 - 12:41:58]
start with the projects and let's see

[12:41:57 - 12:42:01]
like how we can develop these kinds of

[12:41:58 - 12:42:04]
generative VI projects so guys now let's

[12:42:01 - 12:42:06]
uh build one generative VI projects one

[12:42:04 - 12:42:08]
uh like generate API application with

[12:42:06 - 12:42:10]
the help of large language model so here

[12:42:08 - 12:42:12]
I'm going to use uh lamp to and here I'm

[12:42:10 - 12:42:14]
also going to use some of the additional

[12:42:12 - 12:42:15]
tool let's say I'll be using Vector

[12:42:14 - 12:42:17]
database then I will be using Lang and

[12:42:15 - 12:42:19]
framework okay then we'll be

[12:42:17 - 12:42:21]
implementing uh this uh uh amazing

[12:42:19 - 12:42:23]
application so the application actually

[12:42:21 - 12:42:25]
I'm going to implement called uh website

[12:42:23 - 12:42:27]
bot so what is website bot I think you

[12:42:25 - 12:42:29]
have probably seen like uh uh if you

[12:42:27 - 12:42:32]
visit any kinds of website so some of

[12:42:29 - 12:42:33]
them are already created some bot so if

[12:42:32 - 12:42:35]
you ask some question in the website

[12:42:33 - 12:42:37]
like uh what this website and all about

[12:42:35 - 12:42:38]
like what the services is provide so

[12:42:37 - 12:42:40]
everything it will give you the answer

[12:42:38 - 12:42:42]
right whenever we visit any website

[12:42:40 - 12:42:45]
let's say we visit

[12:42:42 - 12:42:46]
open.com so if I visit this website so

[12:42:45 - 12:42:48]
if you want to see this website

[12:42:46 - 12:42:51]
structure like how many pages actually

[12:42:48 - 12:42:53]
it has uh and uh like what is the layout

[12:42:51 - 12:42:54]
of this website what is what the URL of

[12:42:53 - 12:42:57]
that page actually everything you can

[12:42:54 - 12:42:58]
see okay if you visit this uh link

[12:42:57 - 12:43:01]
called

[12:42:58 - 12:43:04]
sitemap

[12:43:01 - 12:43:06]
sitemap uh sitemap.xml okay if you just

[12:43:04 - 12:43:08]
write this one sitemap.xml and if you

[12:43:06 - 12:43:10]
press enter so it will give you all the

[12:43:08 - 12:43:13]
details about this website let's say

[12:43:10 - 12:43:15]
this is the website and it has actually

[12:43:13 - 12:43:17]
different different pages if you see if

[12:43:15 - 12:43:20]
I go to again

[12:43:17 - 12:43:21]
open again if I go to openi so if I

[12:43:20 - 12:43:23]
let's say click on research and click on

[12:43:21 - 12:43:25]
let's say overview so it will open a

[12:43:23 - 12:43:27]
different tab for me like let's say this

[12:43:25 - 12:43:29]
is the different page for this website

[12:43:27 - 12:43:31]
so that's actually you have different

[12:43:29 - 12:43:32]
different website and with with respect

[12:43:31 - 12:43:34]
to that it has the different different

[12:43:32 - 12:43:35]
links as well as you can see different

[12:43:34 - 12:43:37]
different links actually it will also

[12:43:35 - 12:43:39]
provide okay let's say uh this is

[12:43:37 - 12:43:42]
another page okay this is another page

[12:43:39 - 12:43:45]
inside open AI so let's say I'll copy

[12:43:42 - 12:43:47]
this URL and if I paste it here so it

[12:43:45 - 12:43:49]
will open that particular uh see it is

[12:43:47 - 12:43:51]
opening particular that particular page

[12:43:49 - 12:43:53]
okay so that's how actually you can

[12:43:51 - 12:43:55]
export uh with any kinds of website uh

[12:43:53 - 12:43:59]
so I already collected some of the

[12:43:55 - 12:44:00]
website URL so what I will do uh I will

[12:43:59 - 12:44:02]
use that URL and I will build this

[12:44:00 - 12:44:04]
application so here if you see I have

[12:44:02 - 12:44:07]
already prepared one notebook

[12:44:04 - 12:44:09]
here and here I already uh collected

[12:44:07 - 12:44:13]
some of the uh website link so if I open

[12:44:09 - 12:44:15]
it so see this is one blog website link

[12:44:13 - 12:44:17]
so paper review Lama to open foundation

[12:44:15 - 12:44:20]
finding chat model so it has some

[12:44:17 - 12:44:21]
content okay it has some content so

[12:44:20 - 12:44:23]
we'll be chatting through this content

[12:44:21 - 12:44:25]
like what are the things actually uh

[12:44:23 - 12:44:26]
this content is providing okay

[12:44:25 - 12:44:28]
everything we can ask in our bot

[12:44:26 - 12:44:31]
whenever we'll be complete completing

[12:44:28 - 12:44:34]
this thing not only this thing I have uh

[12:44:31 - 12:44:36]
attached multiple uh URL as you can see

[12:44:34 - 12:44:38]
this is another link okay this is

[12:44:36 - 12:44:41]
another link this is another website so

[12:44:38 - 12:44:42]
again some content is inside that again

[12:44:41 - 12:44:44]
it has different different pages as you

[12:44:42 - 12:44:45]
can see it has different different pages

[12:44:44 - 12:44:48]
uh it has different different pages if

[12:44:45 - 12:44:49]
you just visit that site uh map. XML you

[12:44:48 - 12:44:52]
will see different different pages link

[12:44:49 - 12:44:58]
you will see there then I also have

[12:44:52 - 12:45:00]
another one so this is the website of

[12:44:58 - 12:45:02]
stability. and again actually uh it has

[12:45:00 - 12:45:04]
some content so you can give any kinds

[12:45:02 - 12:45:06]
of website link here so I have collected

[12:45:04 - 12:45:08]
these are the website link so you can

[12:45:06 - 12:45:10]
use any of them so here here is another

[12:45:08 - 12:45:13]
website okay so we we'll be using this

[12:45:10 - 12:45:15]
uh four website URL and we'll be

[12:45:13 - 12:45:16]
implementing one website bought on top

[12:45:15 - 12:45:19]
of it so let's say if you're asking

[12:45:16 - 12:45:20]
anything okay if you're asking anything

[12:45:19 - 12:45:22]
regarding these are the four website

[12:45:20 - 12:45:24]
like what are the content everything

[12:45:22 - 12:45:26]
like what are the things actually it is

[12:45:24 - 12:45:28]
providing what is this uh let's say if

[12:45:26 - 12:45:30]
you want to ask something about Lama to

[12:45:28 - 12:45:31]
open foundation fine tune chat model you

[12:45:30 - 12:45:33]
can ask so it will give you the answer

[12:45:31 - 12:45:35]
with respect to the content actually it

[12:45:33 - 12:45:38]
is giving let's if you want to ask like

[12:45:35 - 12:45:40]
M PT 7B okay this is another uh open

[12:45:38 - 12:45:41]
open source large language model if you

[12:45:40 - 12:45:43]
want to ask something so here you can

[12:45:41 - 12:45:46]
ask so it will give you the answer with

[12:45:43 - 12:45:47]
respect to this content so any any

[12:45:46 - 12:45:49]
website you can refer let's say if you

[12:45:47 - 12:45:52]
have created your custom website as well

[12:45:49 - 12:45:54]
so you want uh to create one bot on top

[12:45:52 - 12:45:56]
of it so let's say I am I'm the user so

[12:45:54 - 12:45:57]
I will come to your website first of all

[12:45:56 - 12:45:58]
I will ask to your Bot like what are

[12:45:57 - 12:46:00]
Services actually provide what are the

[12:45:58 - 12:46:02]
things actually provide I can get all

[12:46:00 - 12:46:04]
the information from your bot then uh I

[12:46:02 - 12:46:05]
don't need to visit your website okay

[12:46:04 - 12:46:07]
again and again so I can ask everything

[12:46:05 - 12:46:09]
from the B itself so guys this is going

[12:46:07 - 12:46:11]
to be one Amazing Project and uh what

[12:46:09 - 12:46:13]
you feel like just try to comment in the

[12:46:11 - 12:46:16]
chat okay so uh whether it's helpful or

[12:46:13 - 12:46:18]
not and make sure you are just watching

[12:46:16 - 12:46:20]
this video entirely don't skip any part

[12:46:18 - 12:46:21]
otherwise you might get some issue so

[12:46:20 - 12:46:24]
guys now what I will do I will first of

[12:46:21 - 12:46:25]
all give you the projects idea I'll be

[12:46:24 - 12:46:27]
just uh giving you the projects

[12:46:25 - 12:46:28]
architecture I'll be just writing the

[12:46:27 - 12:46:30]
project architecture like what are the

[12:46:28 - 12:46:31]
steps actually we are going to do uh

[12:46:30 - 12:46:33]
throughout this entire projects like

[12:46:31 - 12:46:34]
what are the component will be

[12:46:33 - 12:46:36]
implementing okay so we'll be seeing the

[12:46:34 - 12:46:38]
project architecture at the very first

[12:46:36 - 12:46:39]
then once you understand this

[12:46:38 - 12:46:41]
architecture we'll be moving to the

[12:46:39 - 12:46:42]
coding part so let's uh go to our

[12:46:41 - 12:46:45]
whiteboard and try to understand the

[12:46:42 - 12:46:46]
project architecture so guys I'm inside

[12:46:45 - 12:46:49]
my whiteboard so now first of all I will

[12:46:46 - 12:46:51]
write just write the Project's name so

[12:46:49 - 12:46:51]
it is uh

[12:46:52 - 12:46:58]
website website

[12:46:55 - 12:46:58]
bot

[12:46:58 - 12:47:04]
using uh

[12:47:00 - 12:47:06]
lama lama 2 okay so here let me give you

[12:47:04 - 12:47:09]
the projects uh architecture like how we

[12:47:06 - 12:47:10]
are going to do the projects so first of

[12:47:09 - 12:47:15]
all what I will

[12:47:10 - 12:47:18]
do I need to uh collect those uh website

[12:47:15 - 12:47:21]
uh uh sitemap.xml basically I need to

[12:47:18 - 12:47:23]
collect all the content okay from the

[12:47:21 - 12:47:24]
website actually I'm referring so first

[12:47:23 - 12:47:27]
of all we'll be

[12:47:24 - 12:47:30]
uh taking all the content uh with the

[12:47:27 - 12:47:30]
help of this

[12:47:31 - 12:47:35]
sitemap sitemap.xml

[12:47:33 - 12:47:38]
okay

[12:47:35 - 12:47:39]
XML and you don't need to worry about uh

[12:47:38 - 12:47:40]
manually you don't need to write these

[12:47:39 - 12:47:42]
are the thing actually if you're using

[12:47:40 - 12:47:44]
Lang chain so with the help of Lang Chen

[12:47:42 - 12:47:46]
actually you can easily extract the

[12:47:44 - 12:47:48]
content from any unstructured website

[12:47:46 - 12:47:49]
okay I'll tell you like how to do it so

[12:47:48 - 12:47:50]
what it will return return it will

[12:47:49 - 12:47:55]
return return

[12:47:50 - 12:47:57]
uh so it will return you page okay page

[12:47:55 - 12:47:59]
let's say

[12:47:57 - 12:48:01]
one page

[12:47:59 - 12:48:05]
two and page

[12:48:01 - 12:48:07]
three so after getting the page actually

[12:48:05 - 12:48:10]
uh I need to get the documents okay

[12:48:07 - 12:48:14]
present in the page

[12:48:10 - 12:48:18]
so so it will return me the

[12:48:14 - 12:48:19]
documents let's say docs okay docs

[12:48:18 - 12:48:20]
one docs

[12:48:19 - 12:48:25]
[Music]

[12:48:20 - 12:48:29]
2 docs 3 okay docs

[12:48:25 - 12:48:31]
4 and so on so docs 4 okay now it will

[12:48:29 - 12:48:34]
return me that

[12:48:31 - 12:48:37]
documentation like all the page uh

[12:48:34 - 12:48:40]
content so once I get all the content

[12:48:37 - 12:48:41]
okay uh basically here um let me write

[12:48:40 - 12:48:44]
out here we are just

[12:48:41 - 12:48:44]
extracting

[12:48:45 - 12:48:52]
extracting text okay excting text and uh

[12:48:49 - 12:48:55]
after getting all the text uh what I

[12:48:52 - 12:48:57]
will do I will use my embedding API that

[12:48:55 - 12:48:59]
means embedding

[12:48:57 - 12:49:02]
model so in this case I'm going to use

[12:48:59 - 12:49:02]
hugging face

[12:49:03 - 12:49:07]
embedding embedding model I think you

[12:49:06 - 12:49:09]
already know what is embedding model and

[12:49:07 - 12:49:12]
all I already discussed this thing in my

[12:49:09 - 12:49:14]
Vector database uh session so if you

[12:49:12 - 12:49:15]
haven't uh watched that session you can

[12:49:14 - 12:49:17]
go ahead and watch it so everything

[12:49:15 - 12:49:19]
would be clear there so I I'll be using

[12:49:17 - 12:49:20]
embedding model so with the help of

[12:49:19 - 12:49:25]
embedding model actually I'll try to

[12:49:20 - 12:49:28]
convert this text to Vector okay Vector

[12:49:25 - 12:49:30]
representation now um this will return

[12:49:28 - 12:49:32]
me the vectors so here I will get lots

[12:49:30 - 12:49:32]
of

[12:49:33 - 12:49:39]
vectors then once I get the vector uh I

[12:49:36 - 12:49:42]
will build one

[12:49:39 - 12:49:42]
build

[12:49:42 - 12:49:48]
semantic semantic

[12:49:46 - 12:49:51]
index okay I think you will know what is

[12:49:48 - 12:49:54]
cementing index uh cementing index means

[12:49:51 - 12:49:57]
you will be uh combining all the vector

[12:49:54 - 12:49:59]
together okay then we'll be building the

[12:49:57 - 12:50:01]
semantic index and you will be storing

[12:49:59 - 12:50:02]
the semantic index to the knowledge base

[12:50:01 - 12:50:05]
okay so what is knowledge base knowledge

[12:50:02 - 12:50:09]
Bas is nothing but your vector database

[12:50:05 - 12:50:09]
so let's say this is my knowledge base

[12:50:09 - 12:50:14]
okay this is my uh knowledge base or

[12:50:12 - 12:50:18]
let's say Vector

[12:50:14 - 12:50:21]
DB Vector DB so these are the vector

[12:50:18 - 12:50:21]
will come

[12:50:22 - 12:50:27]
here these are vector will come here and

[12:50:24 - 12:50:29]
it will store inside my Vector DB okay

[12:50:27 - 12:50:33]
so once I'm able to store these are the

[12:50:29 - 12:50:36]
uh vectors okay in my Vector DB now uh

[12:50:33 - 12:50:39]
what will happen let's say this is the

[12:50:36 - 12:50:39]
user

[12:50:40 - 12:50:45]
let's say this is the user so user will

[12:50:43 - 12:50:48]
H some uh

[12:50:45 - 12:50:50]
queries so let's say this is the

[12:50:48 - 12:50:52]
question from the

[12:50:50 - 12:50:55]
user so the first thing what I need to

[12:50:52 - 12:50:57]
do I need to convert this questions to

[12:50:55 - 12:50:59]
the uh vectors because again it's it's

[12:50:57 - 12:51:00]
going to be the raw text okay so again

[12:50:59 - 12:51:03]
I'll be applying something called

[12:51:00 - 12:51:03]
embedding

[12:51:04 - 12:51:10]
model embedding model

[12:51:08 - 12:51:12]
okay then I'll convert this text to

[12:51:10 - 12:51:14]
Vector so here I will get something

[12:51:12 - 12:51:17]
called

[12:51:14 - 12:51:21]
quy

[12:51:17 - 12:51:21]
embedding or quy

[12:51:22 - 12:51:27]
vector so this quy Vector I will apply

[12:51:25 - 12:51:30]
something called semantic

[12:51:27 - 12:51:30]
semantic

[12:51:31 - 12:51:37]
search I think you already know what is

[12:51:33 - 12:51:40]
centic search okay so centic search on

[12:51:37 - 12:51:42]
top of my vector DB okay so I'll do the

[12:51:40 - 12:51:47]
semantic search so once you do the

[12:51:42 - 12:51:49]
santic search it will uh return you some

[12:51:47 - 12:51:51]
ranked

[12:51:49 - 12:51:54]
result okay rank

[12:51:51 - 12:51:57]
results now I will have my rank results

[12:51:54 - 12:51:59]
now I will take the help from my

[12:51:57 - 12:52:03]
llm I'll be using large language model

[12:51:59 - 12:52:06]
which is nothing but my

[12:52:03 - 12:52:08]
uh Lama 2 okay here I'm going to use LMA

[12:52:06 - 12:52:11]
2 so with the help of this large

[12:52:08 - 12:52:13]
language model I will get my actual uh

[12:52:11 - 12:52:16]
response okay the the query user has

[12:52:13 - 12:52:18]
asked so it will give me the actual

[12:52:16 - 12:52:21]
response okay so this is the complete

[12:52:18 - 12:52:24]
idea and this is nothing but this is my

[12:52:21 - 12:52:27]
user this is my user okay so this is the

[12:52:24 - 12:52:29]
complete uh you can say diagram of our

[12:52:27 - 12:52:31]
projects as you can see first of all uh

[12:52:29 - 12:52:33]
we'll be using these are the website

[12:52:31 - 12:52:35]
with the help of sitemap.xml we'll be

[12:52:33 - 12:52:38]
extracting all the pages available in

[12:52:35 - 12:52:40]
the website then we'll be uh extracting

[12:52:38 - 12:52:43]
ing the documents that means extracting

[12:52:40 - 12:52:47]
the text after that uh we are just

[12:52:43 - 12:52:47]
converting let me write

[12:52:47 - 12:52:52]
here

[12:52:49 - 12:52:54]
converting text to

[12:52:52 - 12:52:56]
Vector vectors okay here we'll be

[12:52:54 - 12:52:59]
converting text to vectors then we'll

[12:52:56 - 12:53:00]
get our Vector embedding that Vector

[12:52:59 - 12:53:02]
embedding we be building one centic

[12:53:00 - 12:53:03]
index and we'll be storing into the

[12:53:02 - 12:53:06]
vector DB so in this case actually I'm

[12:53:03 - 12:53:09]
going to use something called Pine

[12:53:06 - 12:53:11]
con Pine con Vector DB okay you can use

[12:53:09 - 12:53:13]
any any Vector DB where at you can use

[12:53:11 - 12:53:15]
chroma DB you can also use face okay

[12:53:13 - 12:53:19]
from Facebook anything you can use but I

[12:53:15 - 12:53:21]
will be using pine con then uh What uh

[12:53:19 - 12:53:23]
will happen user will ask some query I

[12:53:21 - 12:53:26]
will be applying again embedding model

[12:53:23 - 12:53:27]
and I'll be getting quum beddings and

[12:53:26 - 12:53:29]
with the help of this qu quum beddings

[12:53:27 - 12:53:31]
I'll be do semantic SS on top of my

[12:53:29 - 12:53:34]
Vector DV it will give me rank results

[12:53:31 - 12:53:36]
and with the help of llm I'll uh extract

[12:53:34 - 12:53:38]
my correct output I'm I was expecting

[12:53:36 - 12:53:40]
okay and it will give me the correct

[12:53:38 - 12:53:42]
response uh to the user so this is the

[12:53:40 - 12:53:44]
complete idea of this projects now what

[12:53:42 - 12:53:47]
I will do and here I already uh prepared

[12:53:44 - 12:53:48]
one notebook uh for this projects so

[12:53:47 - 12:53:50]
I'll just explain like whatever things I

[12:53:48 - 12:53:52]
have done so first of all I need to

[12:53:50 - 12:53:55]
connect my notebook make sure you have

[12:53:52 - 12:53:57]
selected runtime as GPU so here uh just

[12:53:55 - 12:53:59]
click change run type type and select

[12:53:57 - 12:54:01]
GPU so for me I've already selected now

[12:53:59 - 12:54:03]
here I need to install some of the

[12:54:01 - 12:54:06]
package so here I'll be installing

[12:54:03 - 12:54:08]
langen then uh by byes accelerate

[12:54:06 - 12:54:11]
Transformers why we need it I think you

[12:54:08 - 12:54:13]
remember I think uh previous experiment

[12:54:11 - 12:54:16]
I was showing how to use Lama with the

[12:54:13 - 12:54:18]
help of um uh langin okay and I was

[12:54:16 - 12:54:20]
reading that L Lama model from my

[12:54:18 - 12:54:21]
hugging Fist and for hugging fist

[12:54:20 - 12:54:23]
actually I need to install these are the

[12:54:21 - 12:54:26]
libraries then uh these are the actually

[12:54:23 - 12:54:29]
dependency you can install okay then uh

[12:54:26 - 12:54:31]
PF should be another dependency and also

[12:54:29 - 12:54:35]
you need to install sentent Transformer

[12:54:31 - 12:54:35]
now let me install them

[12:54:43 - 12:54:47]
so installation is done so so here I'm

[12:54:45 - 12:54:50]
not going to use open AI so let me just

[12:54:47 - 12:54:51]
delete this thing then I also need to

[12:54:50 - 12:54:53]
install this library unstructured

[12:54:51 - 12:54:56]
because uh the website will be loading

[12:54:53 - 12:54:58]
so it has lots of unstructured format so

[12:54:56 - 12:54:59]
to overcome this thing actually you need

[12:54:58 - 12:55:02]
this package called unstructured so let

[12:54:59 - 12:55:02]
me install

[12:55:03 - 12:55:09]
it I'm not using F uh f is again a

[12:55:08 - 12:55:11]
another Vector database so you can

[12:55:09 - 12:55:13]
remove this thing I'll be using

[12:55:11 - 12:55:13]
something called pine

[12:55:14 - 12:55:19]
cone so this is done then I also need to

[12:55:17 - 12:55:24]
install

[12:55:19 - 12:55:24]
tokenizers then X forers as

[12:55:24 - 12:55:28]
well uh now I will be also installing uh

[12:55:27 - 12:55:31]
Pine con client because here I'm going

[12:55:28 - 12:55:33]
to use pine con Vector database and guys

[12:55:31 - 12:55:35]
if you haven't checked my Vector

[12:55:33 - 12:55:37]
database session you can check it out

[12:55:35 - 12:55:39]
okay it is available otherwise uh you

[12:55:37 - 12:55:41]
might get some confusion so it's better

[12:55:39 - 12:55:44]
to try to understand this vctor DV okay

[12:55:41 - 12:55:46]
then you will get the entire idea now uh

[12:55:44 - 12:55:48]
all the things I have uh installed now

[12:55:46 - 12:55:50]
I'll be installing all the requirements

[12:55:48 - 12:55:52]
libraries actually I'm going to use and

[12:55:50 - 12:55:53]
whatever libraries actually I'm going to

[12:55:52 - 12:55:55]
use I will tell you okay which Library

[12:55:53 - 12:55:57]
actually I'm using for which purpose

[12:55:55 - 12:55:59]
actually I will tell you at that time so

[12:55:57 - 12:56:01]
here you can see some additional Library

[12:55:59 - 12:56:03]
also I'm importing but um again I will

[12:56:01 - 12:56:06]
discuss like what are things actually I

[12:56:03 - 12:56:09]
need here now I also need to install

[12:56:06 - 12:56:12]
punctuation mantk

[12:56:09 - 12:56:15]
H so the first thing I need to collect

[12:56:12 - 12:56:17]
some of the website URL the website URL

[12:56:15 - 12:56:19]
actually I want to use for my bot so

[12:56:17 - 12:56:21]
here I already showed you I I'm using

[12:56:19 - 12:56:23]
this four website okay I'm using this

[12:56:21 - 12:56:25]
four website you can uh use any of the

[12:56:23 - 12:56:26]
website and you can uh use it so these

[12:56:25 - 12:56:28]
are the four website link I have

[12:56:26 - 12:56:29]
provided inside one variable called URLs

[12:56:28 - 12:56:33]
okay now let me

[12:56:29 - 12:56:35]
execute yeah now I think you already saw

[12:56:33 - 12:56:38]
uh we have imported one uh class called

[12:56:35 - 12:56:40]
unstructured URL loader from Lang here

[12:56:38 - 12:56:42]
if you see un structure URL loader so

[12:56:40 - 12:56:44]
this uh class will help you to uh

[12:56:42 - 12:56:48]
extract all the data from this other the

[12:56:44 - 12:56:50]
URL okay the I think uh I was explaining

[12:56:48 - 12:56:52]
this project architecture like it will

[12:56:50 - 12:56:54]
be using something called sitemap.xml

[12:56:52 - 12:56:56]
then it will extract the pages okay from

[12:56:54 - 12:56:58]
the pages it will extract the

[12:56:56 - 12:57:00]
documentation so everything can be done

[12:56:58 - 12:57:01]
with the help of this uh function

[12:57:00 - 12:57:03]
actually we have imported here okay

[12:57:01 - 12:57:05]
unstructured data loader and here you

[12:57:03 - 12:57:07]
just need to give the URL and it is not

[12:57:05 - 12:57:09]
only working with the single URL it will

[12:57:07 - 12:57:13]
also work with the multiple URL as well

[12:57:09 - 12:57:16]
okay so now if I execute and show you so

[12:57:13 - 12:57:18]
it will easily extract the data and it

[12:57:16 - 12:57:19]
will go through all the pages actually

[12:57:18 - 12:57:22]
this website has and it will extract all

[12:57:19 - 12:57:23]
the data for me see uh it has extracted

[12:57:22 - 12:57:26]
now if I print my

[12:57:23 - 12:57:27]
data uh see guys all the data you can

[12:57:26 - 12:57:29]
see here it is amazing right so that is

[12:57:27 - 12:57:31]
the power of Lang chain so that's why we

[12:57:29 - 12:57:33]
use this Lang chain framework to build

[12:57:31 - 12:57:36]
these kinds of generative a application

[12:57:33 - 12:57:37]
okay now if I show you my data length so

[12:57:36 - 12:57:39]
it should be four because I'm using four

[12:57:37 - 12:57:43]
website so it will give you four website

[12:57:39 - 12:57:45]
data okay here now uh this data should

[12:57:43 - 12:57:47]
be in a document format I think if you

[12:57:45 - 12:57:52]
see the format of this data it should be

[12:57:47 - 12:57:54]
a document format okay and uh now I need

[12:57:52 - 12:57:56]
to apply something called uh text split

[12:57:54 - 12:57:58]
on top of the uh entire Corpus I have

[12:57:56 - 12:58:00]
because I need to convert my data to

[12:57:58 - 12:58:03]
chunks okay why I need to convert my

[12:58:00 - 12:58:04]
data to chunks because uh see I think I

[12:58:03 - 12:58:07]
already discussed this thing in my

[12:58:04 - 12:58:09]
Vector database uh session why this

[12:58:07 - 12:58:11]
chunks is important because whenever you

[12:58:09 - 12:58:15]
open any kinds of model okay let's say

[12:58:11 - 12:58:17]
if I open um let's say open a model here

[12:58:15 - 12:58:17]
open a

[12:58:17 - 12:58:23]
model open a or let's say if I open my

[12:58:20 - 12:58:27]
Lama 2 model so here if you see uh it

[12:58:23 - 12:58:31]
has context length as 4,000 uh 96 okay

[12:58:27 - 12:58:34]
like it can take like 496 uh uh tokens

[12:58:31 - 12:58:36]
okay at a time but if it is more than

[12:58:34 - 12:58:38]
that actually at the time your uh model

[12:58:36 - 12:58:40]
can take this and it will give you addor

[12:58:38 - 12:58:43]
okay but the data actually we have

[12:58:40 - 12:58:45]
extracted it has like more than 4,096 uh

[12:58:43 - 12:58:47]
you can say tokens okay so that's why I

[12:58:45 - 12:58:50]
can't directly pass this data I can

[12:58:47 - 12:58:51]
directly uh pass this uh Corpus to my

[12:58:50 - 12:58:54]
model so that's why I need to convert to

[12:58:51 - 12:58:55]
chunks chunks means I will be converting

[12:58:54 - 12:58:56]
uh different different chunks okay

[12:58:55 - 12:58:58]
different different chunks mean

[12:58:56 - 12:59:00]
different different paragraph okay and

[12:58:58 - 12:59:01]
that paragraph I will be converting to

[12:59:00 - 12:59:04]
like embedding Vector okay then I'll be

[12:59:01 - 12:59:05]
giving that data to my model okay I

[12:59:04 - 12:59:07]
already discussed this thing in my

[12:59:05 - 12:59:08]
Vector database session just try to go

[12:59:07 - 12:59:11]
ahead and check it out out this should

[12:59:08 - 12:59:13]
be very much clear now here uh I'll be

[12:59:11 - 12:59:16]
converting my enre Corpus to the chunks

[12:59:13 - 12:59:18]
so this is the character splitter uh

[12:59:16 - 12:59:21]
function I have imported from lch here

[12:59:18 - 12:59:23]
if you see character is spitter from uh

[12:59:21 - 12:59:25]
lch I'm importing now with the help of

[12:59:23 - 12:59:27]
this one I will be creating the entire

[12:59:25 - 12:59:28]
chunks now here you need to provide two

[12:59:27 - 12:59:30]
things the Chun size and the chunks

[12:59:28 - 12:59:32]
overlap Chun size means like how many

[12:59:30 - 12:59:35]
tokens you need in a chunks and chunks

[12:59:32 - 12:59:36]
overlap like how many um tokens actually

[12:59:35 - 12:59:38]
you want to consider from your previous

[12:59:36 - 12:59:40]
chunks okay so these two parameter you

[12:59:38 - 12:59:43]
give here now let me execute now my

[12:59:40 - 12:59:46]
chunks object is C uh created now I'll

[12:59:43 - 12:59:48]
give my data I'll give my entire data I

[12:59:46 - 12:59:49]
got from my URL and it will convert

[12:59:48 - 12:59:51]
convert it to

[12:59:49 - 12:59:55]
chunks okay now if you want to see the

[12:59:51 - 12:59:58]
Chun size so it has created 90 chunks so

[12:59:55 - 12:59:58]
if I print my text

[13:00:00 - 13:00:05]
chunks okay so now let me show you see

[13:00:04 - 13:00:09]
this is another

[13:00:05 - 13:00:11]
chunks then again uh this is another

[13:00:09 - 13:00:13]
chunks okay then again this is another

[13:00:11 - 13:00:15]
chunks that's how it has created 90

[13:00:13 - 13:00:17]
chunks okay and if you want to see

[13:00:15 - 13:00:19]
individually you can also see this is

[13:00:17 - 13:00:20]
the Chun zero chunks one and if you just

[13:00:19 - 13:00:23]
read it carefully you will see some of

[13:00:20 - 13:00:24]
the uh tokens are coming okay from your

[13:00:23 - 13:00:27]
previous chunks as well okay so this is

[13:00:24 - 13:00:30]
the Chun overlap so basically it helps

[13:00:27 - 13:00:32]
us to understand the context of the

[13:00:30 - 13:00:34]
sentence actually you have okay now we

[13:00:32 - 13:00:36]
have successfully converted our uh

[13:00:34 - 13:00:39]
entire Corpus to chunks now I'll be

[13:00:36 - 13:00:42]
downloading the Hing Bing because here I

[13:00:39 - 13:00:43]
was discussing I got my uh all the

[13:00:42 - 13:00:45]
documents okay and I have converted to

[13:00:43 - 13:00:47]
chunks okay if you see we have converted

[13:00:45 - 13:00:51]
to chunks dox one docs 2 docs 3 and docs

[13:00:47 - 13:00:53]
so on now I need to use H Model H

[13:00:51 - 13:00:56]
embedding model to convert this chunks

[13:00:53 - 13:00:57]
into embedding okay Vector embedding so

[13:00:56 - 13:00:59]
that's why I'll be downloading first of

[13:00:57 - 13:01:01]
all HF embedding so to download The Hang

[13:00:59 - 13:01:05]
embedding I think I already imported

[13:01:01 - 13:01:07]
this Library here uh here hugging F

[13:01:05 - 13:01:09]
embedding I think somewhere yeah so from

[13:01:07 - 13:01:11]
Lang Chain embeddings Hang embeddings so

[13:01:09 - 13:01:14]
it is available inside langas Lang chain

[13:01:11 - 13:01:16]
now here I'm

[13:01:14 - 13:01:19]
importing okay now if I execute it will

[13:01:16 - 13:01:23]
automatically download the default model

[13:01:19 - 13:01:25]
so hang has lots of you can say

[13:01:23 - 13:01:26]
embedding model so this is the one of

[13:01:25 - 13:01:29]
them okay so this is the name I have

[13:01:26 - 13:01:33]
already given you can open it

[13:01:29 - 13:01:35]
up so this is the model for uh embedding

[13:01:33 - 13:01:37]
okay so you can read about this model I

[13:01:35 - 13:01:39]
have already downloaded this model and

[13:01:37 - 13:01:41]
now let me see the model which model I

[13:01:39 - 13:01:44]
got here so here if you see I got

[13:01:41 - 13:01:47]
something called sentence Transformer

[13:01:44 - 13:01:49]
all MP net base uh V2 this is the model

[13:01:47 - 13:01:51]
I got okay this is the embedding model

[13:01:49 - 13:01:53]
now if I let's say uh if I want to

[13:01:51 - 13:01:54]
convert any text to embeddings okay and

[13:01:53 - 13:01:56]
I want to see like what kinds of vector

[13:01:54 - 13:01:57]
and what is the length of the vector so

[13:01:56 - 13:01:59]
I can test it so let's say I have given

[13:01:57 - 13:02:01]
hello world and from the embedding I'm

[13:01:59 - 13:02:05]
just doing qu embedding

[13:02:01 - 13:02:07]
now see guys the length should be

[13:02:05 - 13:02:10]
768 now this is the vector

[13:02:07 - 13:02:12]
representation of of this

[13:02:10 - 13:02:13]
sentence okay this is the vector

[13:02:12 - 13:02:15]
representation of the sentence so you

[13:02:13 - 13:02:18]
can give any here so let's say I'll give

[13:02:15 - 13:02:21]
hello or let's say how are

[13:02:18 - 13:02:23]
you how are

[13:02:21 - 13:02:26]
you and I have explained this thing

[13:02:23 - 13:02:28]
detail in my Vector database session so

[13:02:26 - 13:02:30]
that's why I'm again and again telling

[13:02:28 - 13:02:31]
you just go ahead and try to check it

[13:02:30 - 13:02:33]
out that video it should be very much

[13:02:31 - 13:02:37]
Clear see again I'm getting the same

[13:02:33 - 13:02:39]
length like 6 768 and this is the uh how

[13:02:37 - 13:02:41]
you Vector representation okay now what

[13:02:39 - 13:02:44]
I will do I will initialize my uh Pine

[13:02:41 - 13:02:45]
con U Vector DB so for this actually I

[13:02:44 - 13:02:48]
need to collect two things one is like

[13:02:45 - 13:02:50]
Pine con API key and is like Pine con

[13:02:48 - 13:02:52]
API environment so for this I need to

[13:02:50 - 13:02:55]
visit first of all pine con so just

[13:02:52 - 13:02:57]
write Pine con. iio and here make sure

[13:02:55 - 13:02:59]
you have the account so I have already

[13:02:57 - 13:03:01]
uh account so I'll just log with my

[13:02:59 - 13:03:03]
account so guys if you logging with your

[13:03:01 - 13:03:04]
accounts you'll able to see these kinds

[13:03:03 - 13:03:06]
of interface so first of all you need to

[13:03:04 - 13:03:08]
get the API key just click on the API

[13:03:06 - 13:03:11]
key and here is my API key I have

[13:03:08 - 13:03:13]
already created so what you can do um

[13:03:11 - 13:03:15]
see this is my previous API key I will

[13:03:13 - 13:03:16]
just copy this API key and if you don't

[13:03:15 - 13:03:18]
have API key just create it here okay

[13:03:16 - 13:03:19]
just click on create API key give the

[13:03:18 - 13:03:22]
name and create the API key will get

[13:03:19 - 13:03:25]
your API key then I'll just paste this

[13:03:22 - 13:03:27]
API key here so this is my API key and

[13:03:25 - 13:03:29]
don't share this API key guys I'll

[13:03:27 - 13:03:31]
remove this after this uh recording

[13:03:29 - 13:03:34]
that's why I'm showing and I also need

[13:03:31 - 13:03:35]
like Pine con uh API environment so for

[13:03:34 - 13:03:37]
this actually you need to create one

[13:03:35 - 13:03:39]
index just click on the indexes and

[13:03:37 - 13:03:41]
create an index index and you need to

[13:03:39 - 13:03:44]
give the name of the index so let's give

[13:03:41 - 13:03:44]
uh Lama

[13:03:45 - 13:03:53]
projects Lama or you need let's give

[13:03:50 - 13:03:55]
Lama only give Lama okay and here you

[13:03:53 - 13:03:58]
need to give the dimension of the vector

[13:03:55 - 13:04:00]
so this is the dimension actually uh so

[13:03:58 - 13:04:03]
here I'm using hang embedding so hang

[13:04:00 - 13:04:06]
embedding this is the dimension 7 68 so

[13:04:03 - 13:04:09]
this Dimension to give it

[13:04:06 - 13:04:10]
768 and I will take this cosine metric

[13:04:09 - 13:04:12]
okay so you have any other metric as

[13:04:10 - 13:04:14]
well so I'll use this cosine metric and

[13:04:12 - 13:04:16]
because I here I'm using free plan then

[13:04:14 - 13:04:16]
I will create the

[13:04:19 - 13:04:25]
index so it will take some time to ready

[13:04:22 - 13:04:27]
your uh indexes so let's wait so once it

[13:04:25 - 13:04:29]
is done it will give you this green icon

[13:04:27 - 13:04:32]
now here uh you will get this

[13:04:29 - 13:04:34]
environment name called gcp starter okay

[13:04:32 - 13:04:37]
I will copy this name and here I need to

[13:04:34 - 13:04:37]
give it

[13:04:39 - 13:04:44]
okay done now let me

[13:04:41 - 13:04:46]
execute so I have set my environment so

[13:04:44 - 13:04:49]
API key and API enironment now I'll

[13:04:46 - 13:04:51]
initialize my uh Pine con so here

[13:04:49 - 13:04:55]
instead of giving inside your ways you

[13:04:51 - 13:04:59]
can give it directly it is also fine so

[13:04:55 - 13:04:59]
let me just give it directly

[13:05:10 - 13:05:14]
so that's how I can provide now let me

[13:05:12 - 13:05:16]
execute and now I'll will give this

[13:05:14 - 13:05:17]
credential and I will just initialize my

[13:05:16 - 13:05:20]
Pine

[13:05:17 - 13:05:21]
con and here you need to give the index

[13:05:20 - 13:05:23]
name you have created so this is my

[13:05:21 - 13:05:25]
index name which is nothing but Lama

[13:05:23 - 13:05:27]
I'll will copy and here I'll just give

[13:05:25 - 13:05:27]
the

[13:05:31 - 13:05:38]
name okay and this particular line will

[13:05:34 - 13:05:39]
convert your uh entire uh like chunks to

[13:05:38 - 13:05:41]
the embedding Vector embedding andore

[13:05:39 - 13:05:43]
inside the pine cone see this is the

[13:05:41 - 13:05:45]
code basically I have my text chunks and

[13:05:43 - 13:05:47]
one by one I'm just reading the content

[13:05:45 - 13:05:49]
and I'm using my embedding okay and I'm

[13:05:47 - 13:05:51]
converting to vectors and index I'm

[13:05:49 - 13:05:52]
giving also like this is the index like

[13:05:51 - 13:05:54]
this is the index I have created so in

[13:05:52 - 13:05:57]
this index actually your vector will

[13:05:54 - 13:05:57]
store now let me execute and show

[13:06:00 - 13:06:07]
you done now if I go to my Pine con and

[13:06:04 - 13:06:07]
refresh the page

[13:06:08 - 13:06:13]
you will see like uh all the vectors

[13:06:11 - 13:06:15]
actually okay see uh this is my text

[13:06:13 - 13:06:16]
with respect to that this is my vectors

[13:06:15 - 13:06:18]
okay this is the vector representation

[13:06:16 - 13:06:21]
and this is the index okay and now see

[13:06:18 - 13:06:23]
we have successfully stored our U data

[13:06:21 - 13:06:24]
we have successfully stored our vectors

[13:06:23 - 13:06:26]
to the vector database okay and you can

[13:06:24 - 13:06:28]
see all the vectors here okay you can

[13:06:26 - 13:06:30]
also query out everything you can do and

[13:06:28 - 13:06:32]
uh this thing you can learn from my

[13:06:30 - 13:06:33]
Vector DV tutorial so there actually

[13:06:32 - 13:06:35]
I've showed you like how to use this

[13:06:33 - 13:06:37]
Vector DV and all so here I'm not going

[13:06:35 - 13:06:38]
to explain in depth okay because they

[13:06:37 - 13:06:40]
already explained and this thing now see

[13:06:38 - 13:06:43]
guys I already stored my vectors inside

[13:06:40 - 13:06:46]
my Vector DV now what I will do I will

[13:06:43 - 13:06:49]
uh first of all loging with my uh uh

[13:06:46 - 13:06:51]
logging with my this one uh my hanging

[13:06:49 - 13:06:53]
face because I want to use that Lama 2

[13:06:51 - 13:06:55]
model from hanging face for this

[13:06:53 - 13:06:58]
actually I need to login so let me log

[13:06:55 - 13:07:00]
in so if you want to log in you need

[13:06:58 - 13:07:01]
this uh um access token I think you

[13:07:00 - 13:07:03]
remember I was collecting the access

[13:07:01 - 13:07:05]
token so this is my access token I'll

[13:07:03 - 13:07:06]
just copy you can create your access

[13:07:05 - 13:07:08]
token okay I I think I already showed

[13:07:06 - 13:07:11]
you how to create it now here I just

[13:07:08 - 13:07:14]
need to give the token and

[13:07:11 - 13:07:16]
login see logging successful now here

[13:07:14 - 13:07:18]
you need to specify the model name which

[13:07:16 - 13:07:20]
model you want to use I already told you

[13:07:18 - 13:07:21]
I'll be using this Lama 27 B chat HF

[13:07:20 - 13:07:23]
model so this is the model name I have

[13:07:21 - 13:07:25]
given here and you can uh use that

[13:07:23 - 13:07:26]
alternative also like let's say if you

[13:07:25 - 13:07:28]
don't have the permission you can uh use

[13:07:26 - 13:07:29]
that model that open source model I

[13:07:28 - 13:07:31]
think previous experiment I was showing

[13:07:29 - 13:07:33]
okay because I already have the access

[13:07:31 - 13:07:35]
so I'll be using this model now first of

[13:07:33 - 13:07:36]
all I'll load my tokenizer and model I

[13:07:35 - 13:07:38]
already discussed like what is tokenizer

[13:07:36 - 13:07:39]
and model okay why loading because I

[13:07:38 - 13:07:41]
want to create the pipeline now let me

[13:07:39 - 13:07:44]
load

[13:07:41 - 13:07:47]
it see it is downloading the model so it

[13:07:44 - 13:07:47]
will take some time let's

[13:07:53 - 13:07:58]
wait so guys uh we have already uh

[13:07:56 - 13:07:59]
downloaded the model now we need to

[13:07:58 - 13:08:01]
create the pipeline I think I already

[13:07:59 - 13:08:02]
showed you like what is Pipeline and all

[13:08:01 - 13:08:05]
okay why we need it so now let me

[13:08:02 - 13:08:07]
initialize the pipeline okay so here if

[13:08:05 - 13:08:08]
I show you my diagram so we have compl

[13:08:07 - 13:08:10]
completed till this point actually we

[13:08:08 - 13:08:12]
have stored the data now we are

[13:08:10 - 13:08:15]
initializing our llm okay then we'll be

[13:08:12 - 13:08:16]
handling the user now pipeline has been

[13:08:15 - 13:08:18]
initialized now I will be calling this

[13:08:16 - 13:08:20]
huging face Pipeline and inside that I

[13:08:18 - 13:08:22]
will give my pipeline objects and I will

[13:08:20 - 13:08:24]
also give this uh argument called

[13:08:22 - 13:08:25]
temperature I already told you what is

[13:08:24 - 13:08:28]
temperature now let me initialize my

[13:08:25 - 13:08:29]
large language model okay now let's

[13:08:28 - 13:08:30]
first of all test it whether it is

[13:08:29 - 13:08:32]
initialized successfully or not so here

[13:08:30 - 13:08:33]
I'm giving one prompt please provide a

[13:08:32 - 13:08:36]
concise summary of the book of Harry

[13:08:33 - 13:08:38]
Potter so it should give me the

[13:08:36 - 13:08:42]
summary uh so guys as you can see we are

[13:08:38 - 13:08:43]
uh getting the output that means my llm

[13:08:42 - 13:08:46]
has been initialized and it is working

[13:08:43 - 13:08:49]
fine now let's do some question answer

[13:08:46 - 13:08:52]
with my uh llm uh the data we have given

[13:08:49 - 13:08:53]
like the website we have given okay so

[13:08:52 - 13:08:55]
from the website we can ask any kinds of

[13:08:53 - 13:08:58]
question now first of all I need to

[13:08:55 - 13:08:59]
import this retrieval keyway okay this

[13:08:58 - 13:09:02]
function now here this is my query like

[13:08:59 - 13:09:05]
I'm just asking how good this uh uh vuna

[13:09:02 - 13:09:06]
okay so there is another uh website

[13:09:05 - 13:09:08]
actually I think you remember this is

[13:09:06 - 13:09:10]
all about vuna so I want to ask

[13:09:08 - 13:09:12]
something about vuna okay from this uh

[13:09:10 - 13:09:13]
website uh so it will give me the

[13:09:12 - 13:09:16]
response okay respect to that now this

[13:09:13 - 13:09:17]
is my question now this is my query uh

[13:09:16 - 13:09:20]
if I perform something called similarity

[13:09:17 - 13:09:23]
SE uh on top of my Vector DB so it will

[13:09:20 - 13:09:25]
give you uh three different uh results

[13:09:23 - 13:09:26]
as you can see I think I already

[13:09:25 - 13:09:29]
discussed this thing like similarity

[13:09:26 - 13:09:31]
sech how to perform and now let's say if

[13:09:29 - 13:09:33]
you want to get the actual results okay

[13:09:31 - 13:09:35]
leses with respect to your questions you

[13:09:33 - 13:09:38]
can take the help from the llm so that's

[13:09:35 - 13:09:40]
why

[13:09:38 - 13:09:42]
so that's why you need to uh call this

[13:09:40 - 13:09:44]
retal QA and here you need to initialize

[13:09:42 - 13:09:46]
the llm CH type and retal you need to

[13:09:44 - 13:09:48]
give your vector restore object here

[13:09:46 - 13:09:49]
okay and as rer it will so basically it

[13:09:48 - 13:09:51]
will refer your vector database and it

[13:09:49 - 13:09:53]
will also take the query and it will

[13:09:51 - 13:09:54]
understand the quy with respect to that

[13:09:53 - 13:09:57]
it will also understand the um question

[13:09:54 - 13:09:58]
you have asked okay the documents uh

[13:09:57 - 13:10:00]
response you got then it will give you

[13:09:58 - 13:10:03]
the authentic results okay now let me

[13:10:00 - 13:10:05]
initialize this one okay yeah now I will

[13:10:03 - 13:10:08]
ask the same query like how good this

[13:10:05 - 13:10:11]
vuna now if I ask this query to my llm

[13:10:08 - 13:10:11]
see it will give you the

[13:10:13 - 13:10:17]
answer so guys as you can see it has

[13:10:15 - 13:10:21]
given me the answer viona is a chat B

[13:10:17 - 13:10:23]
that uh uses uh stable diffusion 2.1

[13:10:21 - 13:10:25]
generate the response while is quality

[13:10:23 - 13:10:27]
is high okay it is giving this response

[13:10:25 - 13:10:29]
now I'll ask another question like how

[13:10:27 - 13:10:32]
does Lama 2 outperforms the other model

[13:10:29 - 13:10:36]
let's see because if you see here I have

[13:10:32 - 13:10:38]
another website of LMA 2 so this is the

[13:10:36 - 13:10:41]
LMA 2 Okay so I'm

[13:10:38 - 13:10:43]
asking uh the question with respect to

[13:10:41 - 13:10:45]
that okay so this is the power of this

[13:10:43 - 13:10:46]
llm and we can create this kinds of

[13:10:45 - 13:10:50]
generative application with with the

[13:10:46 - 13:10:50]
help of this LMA to Pine con and

[13:10:51 - 13:10:56]
langin see guys Lama to out performance

[13:10:54 - 13:10:59]
model uh Benchmark okay so it is giving

[13:10:56 - 13:11:00]
uh like GPT 4 p 2 okay uh basically yeah

[13:10:59 - 13:11:02]
this is the response it is giving now

[13:11:00 - 13:11:05]
let's another uh now let's ask another

[13:11:02 - 13:11:08]
query like what is St stable LM okay I

[13:11:05 - 13:11:10]
think again uh if you see like I am also

[13:11:08 - 13:11:10]
passing one question with respect to

[13:11:10 - 13:11:13]
other

[13:11:10 - 13:11:15]
website see here you can also add your

[13:11:13 - 13:11:17]
custom website you can ask any kinds of

[13:11:15 - 13:11:17]
question with respect to

[13:11:18 - 13:11:23]
that see this is the response I got now

[13:11:21 - 13:11:25]
we can create one while loop um like ask

[13:11:23 - 13:11:28]
the question repetitively one by one so

[13:11:25 - 13:11:30]
now it will ask for the user input now

[13:11:28 - 13:11:32]
here I will ask one query like what is

[13:11:30 - 13:11:36]
uh

[13:11:32 - 13:11:39]
MPT 7B so I think you remember we have

[13:11:36 - 13:11:42]
one website of MPT 7B okay now let's ask

[13:11:39 - 13:11:42]
one qu on top of

[13:11:44 - 13:11:49]
it so yes guys as you can see I got the

[13:11:46 - 13:11:51]
answer MPT 7B is a 7 billion parameter

[13:11:49 - 13:11:52]
language model developed by llm foundary

[13:11:51 - 13:11:54]
okay it is giving all the answer now you

[13:11:52 - 13:11:55]
can ask any kind of question you can

[13:11:54 - 13:11:58]
give see again it is asking for the

[13:11:55 - 13:12:00]
prompt so I won't be asking I just write

[13:11:58 - 13:12:03]
exit so it will exit my code see here I

[13:12:00 - 13:12:04]
have written the logic so yes guys uh I

[13:12:03 - 13:12:06]
hope you got it like how we can

[13:12:04 - 13:12:07]
Implement these kinds of beautiful

[13:12:06 - 13:12:10]
generative application with the help of

[13:12:07 - 13:12:12]
Lama to Pine con and langen okay so this

[13:12:10 - 13:12:14]
project actually you can also convert to

[13:12:12 - 13:12:16]
uh stream lad app in future I will also

[13:12:14 - 13:12:18]
show you how we can uh convert it to

[13:12:16 - 13:12:20]
streamlit app okay and whenever I will

[13:12:18 - 13:12:23]
show you like end project implementation

[13:12:20 - 13:12:25]
I will show you that part so yes guys I

[13:12:23 - 13:12:27]
think uh you have liked this particular

[13:12:25 - 13:12:29]
session and uh you have learned

[13:12:27 - 13:12:31]
everything about Lama 2 like open source

[13:12:29 - 13:12:33]
large language model uh how to run it

[13:12:31 - 13:12:35]
and how we can also implement this kind

[13:12:33 - 13:12:36]
of gen application so if you have liked

[13:12:35 - 13:12:38]
this particular video just try to share

[13:12:36 - 13:12:40]
with with your friends and family and uh

[13:12:38 - 13:12:42]
if you need anything from my side you

[13:12:40 - 13:12:44]
can let me know in the comment okay so

[13:12:42 - 13:12:46]
guys as of now we have seen like various

[13:12:44 - 13:12:48]
kinds of Open Source large language

[13:12:46 - 13:12:51]
model we have seen like how to use LMA 2

[13:12:48 - 13:12:53]
how to use Google Pam 2 so in this video

[13:12:51 - 13:12:54]
I'm going to discuss another U open

[13:12:53 - 13:12:57]
source very powerful large language

[13:12:54 - 13:12:58]
model which is nothing but Falcon so

[13:12:57 - 13:13:01]
guys this is another open source large

[13:12:58 - 13:13:03]
language models uh even Falcon has lots

[13:13:01 - 13:13:07]
of variant like uh so recently Falcon

[13:13:03 - 13:13:09]
has published this 180 B billion par met

[13:13:07 - 13:13:12]
this model but it has some other variant

[13:13:09 - 13:13:15]
as well here if you see Falcon has

[13:13:12 - 13:13:17]
actually 1.3 billion 7.5 billion 40

[13:13:15 - 13:13:20]
billion and this is the recent one which

[13:13:17 - 13:13:23]
is nothing but 180 billion parameter so

[13:13:20 - 13:13:24]
uh actually I can't load this 180

[13:13:23 - 13:13:26]
billion parameter with this Google

[13:13:24 - 13:13:28]
collab and all so if you have good

[13:13:26 - 13:13:30]
instance so you can load it process

[13:13:28 - 13:13:33]
would be same but I will take this model

[13:13:30 - 13:13:35]
guys uh 7.5 billion this model 7 7

[13:13:33 - 13:13:37]
billion model and I will show you one

[13:13:35 - 13:13:39]
demo like how we can use this uh Falcon

[13:13:37 - 13:13:41]
open source uh large language model to

[13:13:39 - 13:13:42]
build our generative by application so

[13:13:41 - 13:13:46]
first of all I will show you like how we

[13:13:42 - 13:13:48]
can uh uh integrate this Falcon 7B uh

[13:13:46 - 13:13:49]
model with our Lang chain so we'll be

[13:13:48 - 13:13:51]
seeing like how we can perform

[13:13:49 - 13:13:52]
inferencing on top of the model then I

[13:13:51 - 13:13:54]
will also show you how we can create

[13:13:52 - 13:13:56]
generative AI application on top of that

[13:13:54 - 13:13:57]
so guys here if you see Falcon is

[13:13:56 - 13:14:00]
nothing but it's a open source large

[13:13:57 - 13:14:02]
language generative AI model and uh if

[13:14:00 - 13:14:05]
you see here Falcon helps us to create a

[13:14:02 - 13:14:07]
very Advanced application and it has

[13:14:05 - 13:14:10]
actually lots of version like uh one 180

[13:14:07 - 13:14:12]
billion 40 billion and 7 billion and um

[13:14:10 - 13:14:15]
1.3 billion parameter and it is trained

[13:14:12 - 13:14:17]
up with high quality like data set so

[13:14:15 - 13:14:19]
that uh actually it can perform all

[13:14:17 - 13:14:22]
kinds of job okay whatever you will be

[13:14:19 - 13:14:24]
giving as a prompt so we'll see like how

[13:14:22 - 13:14:26]
we can do it and it has actually these

[13:14:24 - 13:14:28]
are the variant as I already told you

[13:14:26 - 13:14:30]
14b and even they have already given you

[13:14:28 - 13:14:32]
the download guideline and all so uh to

[13:14:30 - 13:14:34]
download this model actually I'll be

[13:14:32 - 13:14:36]
using huging face because Hing F has

[13:14:34 - 13:14:38]
already these kinds of model hosted here

[13:14:36 - 13:14:39]
if you see this is the fcon 7B instruct

[13:14:38 - 13:14:41]
model so this is the 7 billion parameter

[13:14:39 - 13:14:43]
model so I'm going to use this model so

[13:14:41 - 13:14:46]
you can uh use any other model as well

[13:14:43 - 13:14:49]
let's say if you want to use uh this 14

[13:14:46 - 13:14:50]
billion model okay just uh try to search

[13:14:49 - 13:14:52]
here you will get the model so in this

[13:14:50 - 13:14:53]
example I will show this model okay I

[13:14:52 - 13:14:55]
will use this model and I will show you

[13:14:53 - 13:14:57]
the demo so for this actually I have

[13:14:55 - 13:14:59]
already prepared one notebook as you can

[13:14:57 - 13:15:00]
see this is The Notebook I prepared so

[13:14:59 - 13:15:02]
first of all let's see like how we can

[13:15:00 - 13:15:04]
perform the inference on top of this

[13:15:02 - 13:15:07]
Falcon 7B model okay with the help of

[13:15:04 - 13:15:08]
Lang chain so for this first of all uh

[13:15:07 - 13:15:10]
make sure you have connected your uh

[13:15:08 - 13:15:13]
notebook and you have selected uh GPU as

[13:15:10 - 13:15:14]
a run time so I already selected so uh

[13:15:13 - 13:15:17]
as of now whatever things we have

[13:15:14 - 13:15:19]
learned like Lama then Google p all the

[13:15:17 - 13:15:21]
steps are same only okay but only you

[13:15:19 - 13:15:23]
just need to change the model there so

[13:15:21 - 13:15:24]
this is the idea here so if you're using

[13:15:23 - 13:15:27]
any kinds of large language model not

[13:15:24 - 13:15:28]
only Lama Google pal or let's say Falcon

[13:15:27 - 13:15:29]
if you're using any kinds of large

[13:15:28 - 13:15:31]
language model I already showed you

[13:15:29 - 13:15:32]
right like I already showed you like we

[13:15:31 - 13:15:34]
have different different large language

[13:15:32 - 13:15:36]
models so all the process will remain

[13:15:34 - 13:15:38]
same you need to call the same method

[13:15:36 - 13:15:40]
and all okay if you're using Lang chain

[13:15:38 - 13:15:43]
and all and the way I imported my model

[13:15:40 - 13:15:45]
here you can easily load it okay and you

[13:15:43 - 13:15:46]
can refer some documentation because

[13:15:45 - 13:15:48]
whenever let's say you are referring any

[13:15:46 - 13:15:50]
kinds of large language model they will

[13:15:48 - 13:15:51]
have their documentation you can go

[13:15:50 - 13:15:53]
through the documentation you will get

[13:15:51 - 13:15:55]
the idea and guys throughout this entire

[13:15:53 - 13:15:58]
session actually I showed you three

[13:15:55 - 13:16:00]
large language model like Lama 2 Google

[13:15:58 - 13:16:02]
pom and this Falcon one and rest of the

[13:16:00 - 13:16:03]
large language model you can explore all

[13:16:02 - 13:16:05]
the process will remain same okay only

[13:16:03 - 13:16:07]
you just need to do some exploration on

[13:16:05 - 13:16:09]
top of it so guys here if you see I

[13:16:07 - 13:16:10]
already connected my notebook now if you

[13:16:09 - 13:16:12]
want to check the GPU whether you got

[13:16:10 - 13:16:15]
GPU or not this is the command to

[13:16:12 - 13:16:16]
execute then you will see the GPU then

[13:16:15 - 13:16:18]
first of all I need to import some of

[13:16:16 - 13:16:20]
the libraries because here I uh I'm

[13:16:18 - 13:16:22]
using like hiding face model so for this

[13:16:20 - 13:16:23]
actually I need to install Transformers

[13:16:22 - 13:16:25]
and these are the libraries okay then I

[13:16:23 - 13:16:27]
will be also using langen so I also need

[13:16:25 - 13:16:30]
to install Lang Chen on top of it okay

[13:16:27 - 13:16:30]
so let me install

[13:16:34 - 13:16:39]
them so guys as you can see installtion

[13:16:37 - 13:16:40]
is done now I will be loading the model

[13:16:39 - 13:16:42]
so guys to load the model if you're

[13:16:40 - 13:16:43]
using Hing face model so first of all

[13:16:42 - 13:16:45]
you need to call this Hing face pipeline

[13:16:43 - 13:16:48]
from langen as well as you also need to

[13:16:45 - 13:16:50]
call the tokenizer okay and the pipeline

[13:16:48 - 13:16:51]
objects now here is the name you need to

[13:16:50 - 13:16:54]
Define so this is the name I've just

[13:16:51 - 13:16:55]
copied from here and I pasted here okay

[13:16:54 - 13:16:56]
this is the name and if you're using

[13:16:55 - 13:16:58]
some other model you can change the name

[13:16:56 - 13:16:59]
here so it will automatically download

[13:16:58 - 13:17:01]
the model first of all you need to

[13:16:59 - 13:17:03]
define the tokenizer tokenizer will help

[13:17:01 - 13:17:05]
you to convert your text to numbers okay

[13:17:03 - 13:17:06]
and it will also do the pre-processing

[13:17:05 - 13:17:09]
steps before feding the data to the

[13:17:06 - 13:17:11]
model then uh I will initialize in the

[13:17:09 - 13:17:12]
pipeline so it's a Tex generation model

[13:17:11 - 13:17:14]
that's why I have given the Tex

[13:17:12 - 13:17:15]
generation it will take the model it

[13:17:14 - 13:17:17]
will also take the tokenizer and these

[13:17:15 - 13:17:19]
are the parameter you need to keep it as

[13:17:17 - 13:17:21]
default okay now if you execute this

[13:17:19 - 13:17:22]
particular code so you will able to see

[13:17:21 - 13:17:25]
like it will first of all download the

[13:17:22 - 13:17:25]
model

[13:17:38 - 13:17:45]
so guys this is the model size around

[13:17:41 - 13:17:45]
9.95 GB so let's wait it will take some

[13:17:49 - 13:17:54]
time so guys as you can see my model has

[13:17:52 - 13:17:56]
downloaded now I need to load this model

[13:17:54 - 13:17:58]
so I need to load this pipeline object

[13:17:56 - 13:17:59]
actually so to load this pipeline object

[13:17:58 - 13:18:01]
first of all I need to initialize this

[13:17:59 - 13:18:04]
Hing face pipeline I I think I already

[13:18:01 - 13:18:07]
imported you saw that Hest pipeline from

[13:18:04 - 13:18:08]
lch uh then here I need to give my

[13:18:07 - 13:18:10]
Pipeline and here one parameter I need

[13:18:08 - 13:18:11]
to set called temperature so temperature

[13:18:10 - 13:18:13]
I think you already know what is

[13:18:11 - 13:18:15]
temperature temperature means like if

[13:18:13 - 13:18:18]
you're setting it to zero that means

[13:18:15 - 13:18:20]
your model would be like uh very strict

[13:18:18 - 13:18:22]
and uh it won't be taking any risk uh

[13:18:20 - 13:18:24]
whenever it will give give you the

[13:18:22 - 13:18:26]
response but if you're setting it to one

[13:18:24 - 13:18:28]
so it will uh it will take risk and it

[13:18:26 - 13:18:29]
will give you some random output that's

[13:18:28 - 13:18:31]
why uh you need to think about like

[13:18:29 - 13:18:33]
whether you need very creative results

[13:18:31 - 13:18:35]
or random results from your model or not

[13:18:33 - 13:18:37]
okay if if not then try to keep this

[13:18:35 - 13:18:39]
value close to zero otherwise otherwise

[13:18:37 - 13:18:41]
you can keep this value close to one so

[13:18:39 - 13:18:42]
here I've have given zero because I want

[13:18:41 - 13:18:45]
District output from my model so let me

[13:18:42 - 13:18:46]
initialize my llm okay now here first of

[13:18:45 - 13:18:49]
all I need to initialize one promt

[13:18:46 - 13:18:53]
template okay then I'm also initializing

[13:18:49 - 13:18:55]
uh llm CH okay so let me import them

[13:18:53 - 13:18:56]
then this is my template custom template

[13:18:55 - 13:18:58]
I have defined so you are an intelligent

[13:18:56 - 13:19:00]
chatbot help the following questions

[13:18:58 - 13:19:01]
with the brilliant answer so here you

[13:19:00 - 13:19:02]
will get this kinds of question you need

[13:19:01 - 13:19:04]
to return return these kinds of answer

[13:19:02 - 13:19:06]
okay so this is the custom uh prompt I

[13:19:04 - 13:19:07]
have created now this prompt I will

[13:19:06 - 13:19:09]
initialize with the help of promp

[13:19:07 - 13:19:11]
template it will take the template and

[13:19:09 - 13:19:12]
it will also take the input variable so

[13:19:11 - 13:19:14]
in this case input variable is my

[13:19:12 - 13:19:16]
question now let me initialize my

[13:19:14 - 13:19:18]
template now first of all I will uh

[13:19:16 - 13:19:20]
initialize my llm chain to initialize

[13:19:18 - 13:19:22]
the LM chain first of all you need to

[13:19:20 - 13:19:24]
give the prompt and as well as your uh

[13:19:22 - 13:19:26]
llm okay then it will give you the llm

[13:19:24 - 13:19:28]
Chen now this is my llm Chen so here is

[13:19:26 - 13:19:31]
a question I'm giving explain what is

[13:19:28 - 13:19:33]
artificial intelligence as nurser RS so

[13:19:31 - 13:19:36]
uh it should give me that uh explanation

[13:19:33 - 13:19:38]
okay so here I'm just writing llm chain.

[13:19:36 - 13:19:41]
run and here I'm giving my question now

[13:19:38 - 13:19:41]
let me execute and show

[13:19:43 - 13:19:47]
you and if you see here guys my memory

[13:19:45 - 13:19:49]
is getting full because I loaded this 7

[13:19:47 - 13:19:52]
billion parameter model so that is why I

[13:19:49 - 13:19:54]
was telling like you can't load this uh

[13:19:52 - 13:19:56]
180 billion model because it's like very

[13:19:54 - 13:19:59]
huge model for this you need good system

[13:19:56 - 13:20:02]
you should have good GPU and good memory

[13:19:59 - 13:20:04]
there but all the uh process would be

[13:20:02 - 13:20:05]
remaining same okay only just need to

[13:20:04 - 13:20:08]
change the model name there and

[13:20:05 - 13:20:08]
everything will remain same

[13:20:09 - 13:20:15]
so guys here is the answer I got a child

[13:20:11 - 13:20:17]
may be small but with a AI can do all

[13:20:15 - 13:20:18]
computers and machine learn faster and

[13:20:17 - 13:20:20]
faster allowing the child to Great

[13:20:18 - 13:20:22]
Heights so this is the response I got

[13:20:20 - 13:20:24]
from my model and with respect to this

[13:20:22 - 13:20:26]
uh nursary rims and you can ask any

[13:20:24 - 13:20:29]
kinds of question like let's ask another

[13:20:26 - 13:20:33]
question so I'll copy this one and here

[13:20:29 - 13:20:33]
uh I can ask

[13:20:34 - 13:20:42]
uh give me a code

[13:20:38 - 13:20:42]
for adding two

[13:20:52 - 13:20:56]
numbers so here if you see it it can

[13:20:54 - 13:20:58]
also generate code so any kinds of

[13:20:56 - 13:21:00]
prompt you can give any kinds of task

[13:20:58 - 13:21:02]
you can uh do with this llm let's say

[13:21:00 - 13:21:04]
you want to do summarization generate

[13:21:02 - 13:21:05]
text generate poem generate code

[13:21:04 - 13:21:07]
anything you can perform with this model

[13:21:05 - 13:21:09]
okay and is like very powerful model

[13:21:07 - 13:21:11]
guys even uh you'll be loving a lot

[13:21:09 - 13:21:12]
after learning this one okay I think you

[13:21:11 - 13:21:15]
got the

[13:21:12 - 13:21:18]
idea now guys u in future I will also

[13:21:15 - 13:21:20]
show you how we can fine tune this llm

[13:21:18 - 13:21:23]
okay like we have learned Lama then

[13:21:20 - 13:21:25]
Google pom then Falcon we can also F

[13:21:23 - 13:21:27]
tune them with respect to our custom

[13:21:25 - 13:21:30]
task let's say you have some complex

[13:21:27 - 13:21:32]
data and this task uh your model can't

[13:21:30 - 13:21:34]
perform so at that time you can also F

[13:21:32 - 13:21:35]
tune them so in future I will also show

[13:21:34 - 13:21:37]
you like how we can f tune them on top

[13:21:35 - 13:21:38]
of our custom task okay but guys all

[13:21:37 - 13:21:40]
kinds of task actually these are the

[13:21:38 - 13:21:42]
model can perform so you don't need to

[13:21:40 - 13:21:44]
even F tune them because fine tune is

[13:21:42 - 13:21:46]
not easy so it like more costly so I'll

[13:21:44 - 13:21:47]
always suggest just try to use this are

[13:21:46 - 13:21:50]
the model okay these are the trained

[13:21:47 - 13:21:52]
model so and you can perform your job

[13:21:50 - 13:21:53]
here and you can also give the custom

[13:21:52 - 13:21:55]
data like I already showed you like how

[13:21:53 - 13:21:56]
to put the custom data on top of that

[13:21:55 - 13:21:58]
like how to perform these kinds of

[13:21:56 - 13:22:00]
operation how we can uh do the

[13:21:58 - 13:22:01]
information ret operation how we can

[13:22:00 - 13:22:03]
perform the summarization everything I

[13:22:01 - 13:22:05]
have showed even in future I will also

[13:22:03 - 13:22:07]
create some of the videos like we'll be

[13:22:05 - 13:22:08]
implementing some projects and we'll see

[13:22:07 - 13:22:10]
there like how we can create end to end

[13:22:08 - 13:22:12]
Genera VI application with the help of

[13:22:10 - 13:22:15]
these are the llm model now guys this is

[13:22:12 - 13:22:17]
the inference on top of this Falcon 7B

[13:22:15 - 13:22:19]
now let's uh create one projects with

[13:22:17 - 13:22:21]
the help of Lang chin so here I'll be

[13:22:19 - 13:22:23]
using chroma DB and we'll be creating

[13:22:21 - 13:22:24]
one M multidock retrial system so

[13:22:23 - 13:22:26]
basically here we'll be giving some

[13:22:24 - 13:22:28]
documentation uh in the documentation

[13:22:26 - 13:22:30]
we'll be doing the information retrial

[13:22:28 - 13:22:32]
operation I think we already saw in our

[13:22:30 - 13:22:33]
Google palom one okay there actually I

[13:22:32 - 13:22:36]
was using PDF but here we'll be using

[13:22:33 - 13:22:37]
the textual data so for this actually

[13:22:36 - 13:22:41]
first of all I need to install these are

[13:22:37 - 13:22:43]
the libraries so let me install

[13:22:41 - 13:22:46]
them so I need to first of all terminate

[13:22:43 - 13:22:46]
my previous

[13:22:46 - 13:22:54]
instance done now let me install

[13:22:51 - 13:22:56]
them so here I'm using chroma DV so you

[13:22:54 - 13:22:57]
can use any kinds of vector database you

[13:22:56 - 13:23:01]
can use pine con wave anything you can

[13:22:57 - 13:23:02]
use and I'm also using langen so we are

[13:23:01 - 13:23:04]
installing Lang chain Transformers we

[13:23:02 - 13:23:06]
are also installing because we are using

[13:23:04 - 13:23:07]
HF and we also need Cent trans

[13:23:06 - 13:23:10]
Transformers okay so everything we need

[13:23:07 - 13:23:10]
to install

[13:23:19 - 13:23:24]
here so if you have already watched that

[13:23:21 - 13:23:27]
Google Pam video so this uh notebook

[13:23:24 - 13:23:29]
will be mostly familiar with you because

[13:23:27 - 13:23:31]
I'm referring the same code only but

[13:23:29 - 13:23:33]
only here I'm using Falcone model and

[13:23:31 - 13:23:35]
I'm also changing the database here okay

[13:23:33 - 13:23:37]
only this part I'm

[13:23:35 - 13:23:39]
changing so installation is done now

[13:23:37 - 13:23:41]
I'll be importing these at the libraries

[13:23:39 - 13:23:43]
so I'm importing chroma DB then

[13:23:41 - 13:23:45]
recursive character splitter then

[13:23:43 - 13:23:47]
retrial question text loader and

[13:23:45 - 13:23:49]
directory loader so first of all I need

[13:23:47 - 13:23:50]
to download the data so this data is

[13:23:49 - 13:23:53]
available in this URL so I'm first of

[13:23:50 - 13:23:54]
all downloading this Z file then I'm

[13:23:53 - 13:23:57]
performing unziping operation on top of

[13:23:54 - 13:23:59]
it see if I show you the data so guys

[13:23:57 - 13:24:02]
this is the stock market data so it has

[13:23:59 - 13:24:04]
lots of stock uh uh detail like Nvidia

[13:24:02 - 13:24:06]
stock then Tesla stock so these are the

[13:24:04 - 13:24:07]
txt file data as you can see these are

[13:24:06 - 13:24:09]
the stock data so on top of that we'll

[13:24:07 - 13:24:11]
be performing this uh information

[13:24:09 - 13:24:13]
retrieval operation with the help of

[13:24:11 - 13:24:16]
this llm now first of all I need to load

[13:24:13 - 13:24:18]
this data then I'll be extracting that

[13:24:16 - 13:24:20]
text so this is the code for it then uh

[13:24:18 - 13:24:23]
if you want to see the documents like uh

[13:24:20 - 13:24:25]
the final data you got so these are the

[13:24:23 - 13:24:26]
data I got now what I need to do I need

[13:24:25 - 13:24:30]
to perform this text Splitter on top of

[13:24:26 - 13:24:32]
it basically I want to convert my entire

[13:24:30 - 13:24:35]
Corpus to chunks okay because I already

[13:24:32 - 13:24:37]
told you what is Chunks and all so uh my

[13:24:35 - 13:24:39]
model has like one particular input size

[13:24:37 - 13:24:41]
if you see the documentation so if

[13:24:39 - 13:24:43]
you're using this one Falcon 7 instruct

[13:24:41 - 13:24:45]
so it has some particular U you can say

[13:24:43 - 13:24:47]
input size uh input token size so you

[13:24:45 - 13:24:50]
need to give that particular size so

[13:24:47 - 13:24:51]
it's better to uh convert to chunks so

[13:24:50 - 13:24:53]
that uh these kinds of problem you w be

[13:24:51 - 13:24:56]
facing okay whenever we'll be fitting

[13:24:53 - 13:24:58]
the data so let's convert to chunks so

[13:24:56 - 13:25:00]
that many of chunks I got 49 now if you

[13:24:58 - 13:25:02]
want to see some chunks so this is the

[13:25:00 - 13:25:04]
code for it okay so see guys all codes

[13:25:02 - 13:25:06]
are same as I already used in my

[13:25:04 - 13:25:08]
previous experiment as well okay that's

[13:25:06 - 13:25:09]
why I'm just going little bit fast

[13:25:08 - 13:25:10]
because I think you got the idea like

[13:25:09 - 13:25:12]
how we are performing these are the

[13:25:10 - 13:25:14]
operation right now here first of all I

[13:25:12 - 13:25:17]
will initialize my file instruct model

[13:25:14 - 13:25:19]
the same way I'll be using I showed you

[13:25:17 - 13:25:21]
in that previous notebook right

[13:25:19 - 13:25:24]
yeah so it will first of all download

[13:25:21 - 13:25:28]
the model from the Hang P so it will

[13:25:24 - 13:25:28]
take some time let's wait

[13:25:38 - 13:25:42]
so my model has downloaded now let's

[13:25:40 - 13:25:44]
import my highing face Pipeline and Hing

[13:25:42 - 13:25:46]
face embedding because see guys this

[13:25:44 - 13:25:47]
Falcon model doesn't have any embedding

[13:25:46 - 13:25:48]
model that's why I need to use highing

[13:25:47 - 13:25:50]
face embedding and this is the model

[13:25:48 - 13:25:52]
I'll be using for my embedding basically

[13:25:50 - 13:25:54]
I need to convert my Tex chunks to

[13:25:52 - 13:25:56]
Vector embedding so that's why I need

[13:25:54 - 13:25:59]
this one now I'm initializing my llm and

[13:25:56 - 13:26:00]
I'm also initializing my embedding model

[13:25:59 - 13:26:03]
so see guys it is first of all

[13:26:00 - 13:26:03]
downloading the medic

[13:26:05 - 13:26:09]
model do done now I will initialize my

[13:26:07 - 13:26:11]
chroma DB database uh and I already

[13:26:09 - 13:26:12]
showed you like how to initialize chroma

[13:26:11 - 13:26:14]
DB database in my Vector database

[13:26:12 - 13:26:16]
session just go ahead and check it out

[13:26:14 - 13:26:19]
so here is the DV name I'm giving and

[13:26:16 - 13:26:21]
I'm also passing my text entire Corpus

[13:26:19 - 13:26:23]
okay and I'm also giving my embedding

[13:26:21 - 13:26:25]
embedding this is the embedding model as

[13:26:23 - 13:26:29]
you can see

[13:26:25 - 13:26:34]
uh so it should be embedding model

[13:26:29 - 13:26:34]
so this is the name

[13:26:37 - 13:26:41]
and I'm also uh giving my directory like

[13:26:39 - 13:26:45]
this is my DV directory now let me I

[13:26:41 - 13:26:47]
store the data in my uh chroma DV so it

[13:26:45 - 13:26:48]
will convert all the text to vector

[13:26:47 - 13:26:51]
embeddings and it will store inside your

[13:26:48 - 13:26:54]
chroma now it has done now first of all

[13:26:51 - 13:26:56]
I will load this uh so using this code

[13:26:54 - 13:27:00]
actually we load this

[13:26:56 - 13:27:03]
uh uh Vector emings okay so this code

[13:27:00 - 13:27:06]
will load the vector Bings let me load

[13:27:03 - 13:27:09]
so it should be HF

[13:27:06 - 13:27:09]
HF is my

[13:27:09 - 13:27:14]
embedding then here I'm initializing

[13:27:12 - 13:27:17]
this retriever as my Vector DB then I'm

[13:27:14 - 13:27:19]
creating one uh qn R qn and here I'm

[13:27:17 - 13:27:21]
giving my llm now this is the process

[13:27:19 - 13:27:23]
function I have just written so whatever

[13:27:21 - 13:27:25]
response I will get from my llm so it

[13:27:23 - 13:27:28]
will process the output and it will give

[13:27:25 - 13:27:30]
me that one now let me initialize the

[13:27:28 - 13:27:32]
qn uh now if you give any kind of query

[13:27:30 - 13:27:34]
and execute this code you will able to

[13:27:32 - 13:27:35]
see the response okay as you can see you

[13:27:34 - 13:27:36]
will able to see the response I think I

[13:27:35 - 13:27:38]
already showed you like how to to do it

[13:27:36 - 13:27:42]
okay so that's how we can use this

[13:27:38 - 13:27:44]
Falcon 7B um model okay with our custom

[13:27:42 - 13:27:46]
task as well like we can create this

[13:27:44 - 13:27:48]
kinds of generative application now guys

[13:27:46 - 13:27:50]
I want to give one particular uh task to

[13:27:48 - 13:27:52]
everyone uh basically see you have

[13:27:50 - 13:27:53]
learned lots of concept right now in the

[13:27:52 - 13:27:56]
field of Genera VI like how to use these

[13:27:53 - 13:27:58]
kinds of Open Source llm model now I

[13:27:56 - 13:28:00]
have already shown you like three very

[13:27:58 - 13:28:01]
powerful open source large language

[13:28:00 - 13:28:04]
model now one thing actually you can

[13:28:01 - 13:28:06]
explore from your side there is another

[13:28:04 - 13:28:09]
large language model called mral 7B so

[13:28:06 - 13:28:11]
this is another very good model and this

[13:28:09 - 13:28:13]
is the website of Mr 7B and this model

[13:28:11 - 13:28:17]
is also available inside hugging face so

[13:28:13 - 13:28:20]
Mr 7B huging face so this is the model

[13:28:17 - 13:28:23]
guys Mr 7B uh version 0 01 so this model

[13:28:20 - 13:28:24]
you can U load inside your fre Google

[13:28:23 - 13:28:25]
collab there is no issue with that so

[13:28:24 - 13:28:27]
you can follow the same technique to

[13:28:25 - 13:28:29]
load the model and you can perform these

[13:28:27 - 13:28:30]
kinds of job here and also try to share

[13:28:29 - 13:28:32]
this notebook in the comment section I

[13:28:30 - 13:28:34]
will happy to see that like whatever you

[13:28:32 - 13:28:36]
have done from your site so it would be

[13:28:34 - 13:28:38]
pretty much good learning for you right

[13:28:36 - 13:28:39]
so yes guys this is all about our open

[13:28:38 - 13:28:41]
source large language model we have seen

[13:28:39 - 13:28:42]
like how we can use them and how we can

[13:28:41 - 13:28:45]
create generative application on top of

[13:28:42 - 13:28:47]
it now uh in the next video what I will

[13:28:45 - 13:28:49]
show you I will uh create one end to

[13:28:47 - 13:28:51]
endend uh Genera VI projects okay with

[13:28:49 - 13:28:53]
the help of this Lang chain then Vector

[13:28:51 - 13:28:55]
database and these kinds of llm I'll

[13:28:53 - 13:28:56]
will be also using a streamlit package

[13:28:55 - 13:28:57]
to create the web app and all so guys

[13:28:56 - 13:29:00]
this is going to be very much

[13:28:57 - 13:29:01]
interesting project just try to uh Butch

[13:29:00 - 13:29:03]
that particular video then everything

[13:29:01 - 13:29:05]
would be cleared like as of now we have

[13:29:03 - 13:29:07]
done the projects in the Google collab

[13:29:05 - 13:29:09]
but uh now we'll be converting that

[13:29:07 - 13:29:11]
Google collab to like uh end to end

[13:29:09 - 13:29:13]
projects we'll be creating app and all I

[13:29:11 - 13:29:15]
think you have heard of rag inside genbi

[13:29:13 - 13:29:18]
right because this is the most used uh

[13:29:15 - 13:29:20]
actually topic inside gen VI so the full

[13:29:18 - 13:29:23]
form of rag is like retrial augmented

[13:29:20 - 13:29:25]
generation so in this video we'll try to

[13:29:23 - 13:29:28]
understand what is rag exactly and how

[13:29:25 - 13:29:30]
rag works and why rag is so important

[13:29:28 - 13:29:31]
okay let's say whenever we'll be working

[13:29:30 - 13:29:33]
with genbi whenever we'll be

[13:29:31 - 13:29:35]
implementing any kinds of let's say

[13:29:33 - 13:29:38]
application so why we have to follow

[13:29:35 - 13:29:40]
this rag concept there fine so guys I

[13:29:38 - 13:29:42]
think you already know inside generative

[13:29:40 - 13:29:45]
we use something called large language

[13:29:42 - 13:29:46]
model that means llms so LMS actually

[13:29:45 - 13:29:48]
have some limitation you can see the

[13:29:46 - 13:29:49]
first limitation it is having so the

[13:29:48 - 13:29:51]
first limitation you can see llm can't

[13:29:49 - 13:29:53]
answer correctly to the private data

[13:29:51 - 13:29:55]
let's if we having any kinds of private

[13:29:53 - 13:29:57]
data so that large language model won't

[13:29:55 - 13:29:59]
be able to give you the answer related

[13:29:57 - 13:30:01]
that so if I give you one example let's

[13:29:59 - 13:30:03]
say we are having one personal website

[13:30:01 - 13:30:05]
let's say I have one website called code

[13:30:03 - 13:30:07]
Commander okay so code Commander is my

[13:30:05 - 13:30:10]
website now if you open up your chat GPT

[13:30:07 - 13:30:12]
and if you ask related code Commander

[13:30:10 - 13:30:14]
your chat GPT won't be able to give the

[13:30:12 - 13:30:15]
answer because chat GPT trained with

[13:30:14 - 13:30:19]
older data that means I think CH jbt

[13:30:15 - 13:30:20]
trained around 2021 to 2022 data okay

[13:30:19 - 13:30:23]
around uh this year actually they

[13:30:20 - 13:30:24]
trained this model after that actually I

[13:30:23 - 13:30:27]
created this channel okay so this data

[13:30:24 - 13:30:29]
is not available inside my chat GPT chat

[13:30:27 - 13:30:30]
GPT knowledge base that means that time

[13:30:29 - 13:30:32]
actually this data was not available in

[13:30:30 - 13:30:34]
the internet okay so you can consider

[13:30:32 - 13:30:36]
it's a private data or you can consider

[13:30:34 - 13:30:38]
any kinds of private data your private

[13:30:36 - 13:30:40]
uh let's say website data private let's

[13:30:38 - 13:30:41]
say your company data anything so if you

[13:30:40 - 13:30:43]
ask any question related to the private

[13:30:41 - 13:30:45]
data your model won't be giving you any

[13:30:43 - 13:30:47]
kind of respon to that right then you

[13:30:45 - 13:30:49]
can see the second limitation llm can't

[13:30:47 - 13:30:51]
provide the most current information

[13:30:49 - 13:30:52]
let's say if you're asking uh any

[13:30:51 - 13:30:55]
question which is like more current okay

[13:30:52 - 13:30:56]
more current let's say information your

[13:30:55 - 13:30:57]
model won't be giving you the answer

[13:30:56 - 13:31:00]
let's say if you ask the question

[13:30:57 - 13:31:03]
related this Olympic okay the current

[13:31:00 - 13:31:04]
Olympic it won't be able to give the

[13:31:03 - 13:31:06]
answer because it hasn't trained with

[13:31:04 - 13:31:08]
the current information okay so these

[13:31:06 - 13:31:10]
are the actually limitation we are

[13:31:08 - 13:31:12]
having with the llms but I want to

[13:31:10 - 13:31:13]
create an application that application

[13:31:12 - 13:31:15]
will be also able to give the answer

[13:31:13 - 13:31:18]
related to the private data as well as

[13:31:15 - 13:31:19]
the current information so how it can be

[13:31:18 - 13:31:21]
performed okay we can do it with the

[13:31:19 - 13:31:23]
help of rag concept that means retrial

[13:31:21 - 13:31:25]
augmented generation now let's see how

[13:31:23 - 13:31:27]
rag works so guys here you can see rag

[13:31:25 - 13:31:29]
allows LMS to use external sources for

[13:31:27 - 13:31:30]
the better response that means let's see

[13:31:29 - 13:31:32]
if we having any private data let's say

[13:31:30 - 13:31:34]
any external documents so what you can

[13:31:32 - 13:31:37]
do you can give that documents to the

[13:31:34 - 13:31:39]
large language model how for this you

[13:31:37 - 13:31:40]
just need to use one embedding model you

[13:31:39 - 13:31:42]
just need to use one embedding model

[13:31:40 - 13:31:43]
with the help of this embedding model

[13:31:42 - 13:31:45]
you'll just try to generate the vector

[13:31:43 - 13:31:47]
embedding of the data the data actually

[13:31:45 - 13:31:48]
will be giving and this Vector embedding

[13:31:47 - 13:31:50]
you will be storing to the knowledge

[13:31:48 - 13:31:51]
base that means to the vector database

[13:31:50 - 13:31:53]
okay I think we have already learned

[13:31:51 - 13:31:54]
this thing previously previously we

[13:31:53 - 13:31:56]
already implemented these kinds of

[13:31:54 - 13:31:58]
application but I think you didn't know

[13:31:56 - 13:32:00]
okay this is a rag application I just

[13:31:58 - 13:32:02]
given some high level overview like uh

[13:32:00 - 13:32:03]
how we can let's say use our external

[13:32:02 - 13:32:05]
documents I think we already created

[13:32:03 - 13:32:07]
some of the project right so yes this

[13:32:05 - 13:32:09]
this is called actually rag that means

[13:32:07 - 13:32:11]
we using our external documents we are

[13:32:09 - 13:32:13]
creating our knowledge base and to the

[13:32:11 - 13:32:15]
knowledge base actually we are inting

[13:32:13 - 13:32:16]
our large language model okay now

[13:32:15 - 13:32:18]
whenever user is asking any kinds of

[13:32:16 - 13:32:20]
question okay whenever user is asking

[13:32:18 - 13:32:21]
any kind of question to the private data

[13:32:20 - 13:32:23]
what it will do it will go to the

[13:32:21 - 13:32:25]
knowledge base okay it will go to the

[13:32:23 - 13:32:26]
knowledge base knowledge base will give

[13:32:25 - 13:32:28]
the response okay the question you are

[13:32:26 - 13:32:30]
asking the relevant question you are

[13:32:28 - 13:32:32]
asking and your llm will process that

[13:32:30 - 13:32:33]
answer as well as the query and it will

[13:32:32 - 13:32:36]
give you the correct response okay so

[13:32:33 - 13:32:38]
this is the complete architecture of rag

[13:32:36 - 13:32:39]
that means Ral augmented generation okay

[13:32:38 - 13:32:41]
so with the help of this concept

[13:32:39 - 13:32:42]
actually we can easily use our private

[13:32:41 - 13:32:45]
data sources or let's say external

[13:32:42 - 13:32:47]
documents to get the information okay I

[13:32:45 - 13:32:49]
hope it is clear that means if you're

[13:32:47 - 13:32:51]
using rag concept it would be more

[13:32:49 - 13:32:53]
accurate answer on the private data stay

[13:32:51 - 13:32:55]
updated with the new information let's

[13:32:53 - 13:32:57]
see if you're having new new information

[13:32:55 - 13:32:59]
new data what you can do again you can

[13:32:57 - 13:33:00]
uh give that data to the knowledge base

[13:32:59 - 13:33:02]
that means you can uh use embedding

[13:33:00 - 13:33:04]
model you can convert uh those data to

[13:33:02 - 13:33:05]
the embedding representation you can

[13:33:04 - 13:33:07]
store to the knowledge base and you can

[13:33:05 - 13:33:08]
connect your large language model there

[13:33:07 - 13:33:10]
and if you're asking any question

[13:33:08 - 13:33:11]
related that information it will give

[13:33:10 - 13:33:13]
you the answer okay your model will give

[13:33:11 - 13:33:15]
you the answer so this is the concept of

[13:33:13 - 13:33:18]
retrial augmented generation or rag so

[13:33:15 - 13:33:20]
guys now let's try to see how rag works

[13:33:18 - 13:33:21]
so as I already told you uh whenever you

[13:33:20 - 13:33:23]
are using rag that means you are

[13:33:21 - 13:33:25]
connecting your external data that means

[13:33:23 - 13:33:26]
your private data let's say you have

[13:33:25 - 13:33:28]
connected your private data let's say

[13:33:26 - 13:33:29]
you have connected your website okay you

[13:33:28 - 13:33:31]
have connected your website that means

[13:33:29 - 13:33:33]
from the website itself it will extract

[13:33:31 - 13:33:35]
all the information let's say we are

[13:33:33 - 13:33:37]
running one e-commerce site so user has

[13:33:35 - 13:33:39]
has asked one question what are your

[13:33:37 - 13:33:41]
business hours okay now how it will give

[13:33:39 - 13:33:43]
the response uh by using your

[13:33:41 - 13:33:44]
information so first of all what it will

[13:33:43 - 13:33:46]
do it will try to use something called

[13:33:44 - 13:33:48]
retriever so with the help of retriever

[13:33:46 - 13:33:50]
it will try to fetch all the information

[13:33:48 - 13:33:51]
from your website okay all the

[13:33:50 - 13:33:53]
information it will fetch from the

[13:33:51 - 13:33:54]
website itself then it will perform

[13:33:53 - 13:33:56]
something called augmentation so what

[13:33:54 - 13:33:58]
augmentation will do it will just try to

[13:33:56 - 13:34:00]
augment the query that means whatever

[13:33:58 - 13:34:01]
question user has asked okay and the

[13:34:00 - 13:34:03]
data actually you are getting after

[13:34:01 - 13:34:05]
retriever so it would be actually

[13:34:03 - 13:34:07]
augmented that means it will uh add them

[13:34:05 - 13:34:09]
together okay let's say the query as

[13:34:07 - 13:34:10]
well as the data then it will pass to

[13:34:09 - 13:34:12]
the generation that means to the large

[13:34:10 - 13:34:14]
language model large language model will

[13:34:12 - 13:34:16]
try to understand the entire data as

[13:34:14 - 13:34:18]
well as the quid user has asked okay and

[13:34:16 - 13:34:19]
based on that actually it will provide

[13:34:18 - 13:34:23]
the answer so the answer is Monday to

[13:34:19 - 13:34:25]
Friday from 9:30 a.m. to 6:30 p.m. okay

[13:34:23 - 13:34:26]
so that's how actually rag works that

[13:34:25 - 13:34:28]
means it will use actually three

[13:34:26 - 13:34:30]
component one is like retrieval other is

[13:34:28 - 13:34:32]
like augmentation and this like

[13:34:30 - 13:34:34]
generation okay that is why it is called

[13:34:32 - 13:34:36]
retrial augmented generation okay I hope

[13:34:34 - 13:34:38]
it is clear now so guys this was the

[13:34:36 - 13:34:40]
introduction of the rag and I think you

[13:34:38 - 13:34:42]
got it how rag works and all and why rag

[13:34:40 - 13:34:45]
is important now let's try to see one

[13:34:42 - 13:34:46]
practical example of rag so guys here

[13:34:45 - 13:34:49]
you can see I already prepared one code

[13:34:46 - 13:34:51]
example uh of the rag demo so first of

[13:34:49 - 13:34:53]
all we'll try to understand this uh

[13:34:51 - 13:34:55]
Jupiter notebook file then I will also

[13:34:53 - 13:34:57]
show you how we can create a user

[13:34:55 - 13:34:59]
application that means app let's say

[13:34:57 - 13:35:00]
streamlit app how we can create it okay

[13:34:59 - 13:35:01]
so for this what you have to do guys

[13:35:00 - 13:35:03]
first of all you have to install these

[13:35:01 - 13:35:04]
are the requirements and this code would

[13:35:03 - 13:35:06]
be shared guys in the resources section

[13:35:04 - 13:35:07]
from there you can download

[13:35:06 - 13:35:09]
and I already told you how to create

[13:35:07 - 13:35:11]
virtual environment so to create the

[13:35:09 - 13:35:12]
virtual environment you have to execute

[13:35:11 - 13:35:15]
this command so cond

[13:35:12 - 13:35:17]
create hpen in you have to give the name

[13:35:15 - 13:35:18]
let's say here I have given open demo

[13:35:17 - 13:35:22]
you can give any kinds of name let's say

[13:35:18 - 13:35:25]
I will give test then python is equal to

[13:35:22 - 13:35:26]
3.10 okay 3.10 then hypen y so this is

[13:35:25 - 13:35:29]
the command you have to execute and make

[13:35:26 - 13:35:30]
sure you using python 3.10 okay so for

[13:35:29 - 13:35:31]
me I already created I'm not going to

[13:35:30 - 13:35:33]
create again then after that you have to

[13:35:31 - 13:35:35]
activate it that means cond activate

[13:35:33 - 13:35:37]
your environment name okay then you have

[13:35:35 - 13:35:41]
install this requirements just WR pep

[13:35:37 - 13:35:43]
install okay henr requirement. txt fine

[13:35:41 - 13:35:45]
now if I see press enter it will install

[13:35:43 - 13:35:47]
all the requirements I'm having in the

[13:35:45 - 13:35:48]
requirements file you can see inside

[13:35:47 - 13:35:51]
requirements file I'm installing langen

[13:35:48 - 13:35:52]
langen Community langen openi python.

[13:35:51 - 13:35:54]
stream lead okay so these are the

[13:35:52 - 13:35:56]
actually dependency packets you have to

[13:35:54 - 13:35:57]
install one by one so for me I already

[13:35:56 - 13:35:58]
installed each and everything you can

[13:35:57 - 13:36:01]
see then after that just open this

[13:35:58 - 13:36:02]
notebook rag demo notebook and try to

[13:36:01 - 13:36:04]
select the environment so let's say I

[13:36:02 - 13:36:06]
have created this environment open demo

[13:36:04 - 13:36:08]
I'll select it now see now if I execute

[13:36:06 - 13:36:09]
the first line see it is working fine

[13:36:08 - 13:36:11]
there is no error okay that means it is

[13:36:09 - 13:36:14]
working fine so guys in this experiment

[13:36:11 - 13:36:17]
I'm going to use uh one website okay

[13:36:14 - 13:36:18]
that means uh as a private data as a

[13:36:17 - 13:36:20]
let's say external data we'll be using

[13:36:18 - 13:36:22]
website so from the website itself we'll

[13:36:20 - 13:36:24]
be collecting the data on top of that

[13:36:22 - 13:36:25]
actually uh we'll be implementing this

[13:36:24 - 13:36:28]
rag application so you can see this is

[13:36:25 - 13:36:31]
the website URL now let me open this

[13:36:28 - 13:36:33]
URL so this is the URL of the website so

[13:36:31 - 13:36:34]
this is the entire website guys you can

[13:36:33 - 13:36:36]
see so they have given different

[13:36:34 - 13:36:38]
different information so now I just

[13:36:36 - 13:36:40]
collected some of the more page let me

[13:36:38 - 13:36:41]
show you so this is another page this is

[13:36:40 - 13:36:44]
the index

[13:36:41 - 13:36:47]
page and this is the contact page okay

[13:36:44 - 13:36:49]
now let me open them see this is the

[13:36:47 - 13:36:52]
index page this is the contact page so

[13:36:49 - 13:36:55]
you can see guys this is the index one

[13:36:52 - 13:36:56]
and this is the contact one okay so

[13:36:55 - 13:36:58]
that's how actually you can use any

[13:36:56 - 13:37:00]
kinds of website I'm using this website

[13:36:58 - 13:37:02]
for you you can use your let's say uh

[13:37:00 - 13:37:03]
personal website you can use your let's

[13:37:02 - 13:37:05]
say private website your official

[13:37:03 - 13:37:06]
website anything you can use even I will

[13:37:05 - 13:37:08]
Al show you how we can use any other

[13:37:06 - 13:37:10]
format let's say how we can use PDF

[13:37:08 - 13:37:11]
documents okay these are the things I'll

[13:37:10 - 13:37:14]
also tell you so this is the website

[13:37:11 - 13:37:15]
data actually I'll be using now to load

[13:37:14 - 13:37:17]
this website I'll be using something

[13:37:15 - 13:37:19]
called unistructure URL loader and this

[13:37:17 - 13:37:21]
is available inside langen okay you can

[13:37:19 - 13:37:24]
see I'm importing this un unstructured

[13:37:21 - 13:37:26]
URL loader now this is the URL list so

[13:37:24 - 13:37:27]
if you're having multiple URL you can

[13:37:26 - 13:37:29]
create a list and this list you can pass

[13:37:27 - 13:37:31]
to this uh function and this function

[13:37:29 - 13:37:33]
will give you one loader object now you

[13:37:31 - 13:37:35]
can call load loaded. load and it will

[13:37:33 - 13:37:37]
extract the data let me show you so if I

[13:37:35 - 13:37:39]
execute this

[13:37:37 - 13:37:41]
line now see it is extracting all the

[13:37:39 - 13:37:43]
information from the website itself so

[13:37:41 - 13:37:45]
extraction is done now if I show you the

[13:37:43 - 13:37:47]
data now you can see it has extracted

[13:37:45 - 13:37:48]
all the information now why three

[13:37:47 - 13:37:51]
documents is coming because here I was

[13:37:48 - 13:37:53]
using three URL okay three different uh

[13:37:51 - 13:37:55]
actually pays okay that's why it is

[13:37:53 - 13:37:56]
coming three documents okay now what I

[13:37:55 - 13:37:57]
have to do guys I think you remember we

[13:37:56 - 13:37:59]
have to perform something called

[13:37:57 - 13:38:01]
chunking operation so for this we can

[13:37:59 - 13:38:02]
use recursive character text splitter

[13:38:01 - 13:38:03]
either we can use character text

[13:38:02 - 13:38:06]
splitter either you can also use token

[13:38:03 - 13:38:08]
text splitter okay so here I'm using

[13:38:06 - 13:38:09]
recursive character text splitter so

[13:38:08 - 13:38:11]
here Chun SI is equal to I have given

[13:38:09 - 13:38:13]
1,000 that means 1,000's word would be

[13:38:11 - 13:38:15]
considered as my one chunks so let me

[13:38:13 - 13:38:18]
create the chunks and let me show you

[13:38:15 - 13:38:20]
the uh chunks size okay you can see 11

[13:38:18 - 13:38:22]
chunks it has created okay now if you

[13:38:20 - 13:38:24]
want to see the first one so you can see

[13:38:22 - 13:38:25]
this is the first chance and this is the

[13:38:24 - 13:38:28]
URL it is referring now I think you

[13:38:25 - 13:38:29]
remember after extracting your data that

[13:38:28 - 13:38:31]
means documents you have to use one

[13:38:29 - 13:38:33]
embedding model and you have to generate

[13:38:31 - 13:38:35]
Vector embedding and that Vector

[13:38:33 - 13:38:36]
embedding will be stored into the vector

[13:38:35 - 13:38:38]
database okay any kinds of vector

[13:38:36 - 13:38:40]
database you can use so I have already

[13:38:38 - 13:38:43]
showed you like multiple Vector database

[13:38:40 - 13:38:44]
like we can use chroma DB Pine con web

[13:38:43 - 13:38:45]
okay F you can use any of the vector

[13:38:44 - 13:38:47]
database so here I'm going to use

[13:38:45 - 13:38:49]
something called chroma Vector database

[13:38:47 - 13:38:51]
okay chroma is a so chroma is a local

[13:38:49 - 13:38:53]
Vector database fine so guys you can see

[13:38:51 - 13:38:54]
I'm importing chroma from the Lang chain

[13:38:53 - 13:38:56]
itself because inside Lang chain this

[13:38:54 - 13:38:58]
chroma DB is available then I'm

[13:38:56 - 13:39:00]
importing one embedding model so here

[13:38:58 - 13:39:02]
I'm using open embedding model okay open

[13:39:00 - 13:39:03]
embedding model you can also use any

[13:39:02 - 13:39:05]
open source embedding model I'll also

[13:39:03 - 13:39:07]
tell you okay how we can do it then I'm

[13:39:05 - 13:39:08]
importing openi that means I'm going to

[13:39:07 - 13:39:11]
use open large language model so let me

[13:39:08 - 13:39:12]
import all of the package and now if I

[13:39:11 - 13:39:13]
want to use openi what I have to do I

[13:39:12 - 13:39:16]
have to set my environment okay

[13:39:13 - 13:39:18]
environment variable so open API key you

[13:39:16 - 13:39:19]
have to pass your API key so just try to

[13:39:18 - 13:39:21]
create one API key and try to pass here

[13:39:19 - 13:39:23]
then let's load this API key with help

[13:39:21 - 13:39:25]
of ladb package then after that I'm

[13:39:23 - 13:39:27]
going to initialize my chroma DB Vector

[13:39:25 - 13:39:28]
database okay so you can see I'm going

[13:39:27 - 13:39:30]
to pass my documents here the documents

[13:39:28 - 13:39:32]
I'm getting even I'm also passing my

[13:39:30 - 13:39:33]
embedding model so it will give me the

[13:39:32 - 13:39:34]
vector restore interre Vector restore

[13:39:33 - 13:39:35]
that means this is going to be my

[13:39:34 - 13:39:38]
knowledge base okay see this is my

[13:39:35 - 13:39:39]
knowledge base right now now here you

[13:39:38 - 13:39:41]
can perform something called centic SCE

[13:39:39 - 13:39:43]
operation okay similarity SCE operation

[13:39:41 - 13:39:45]
so let me show you one example so Vector

[13:39:43 - 13:39:47]
store as retriever I want to perform

[13:39:45 - 13:39:49]
similarity sarce operation sarce

[13:39:47 - 13:39:51]
keywords that means how many let's say

[13:39:49 - 13:39:53]
result it will return so here I've given

[13:39:51 - 13:39:55]
three that means after searching it will

[13:39:53 - 13:39:57]
give me three relevant answer okay let

[13:39:55 - 13:39:58]
me show you so let me create the retri

[13:39:57 - 13:40:00]
object now here I'm asking one question

[13:39:58 - 13:40:02]
what kinds of service they provide okay

[13:40:00 - 13:40:04]
this website let's say I'm asking one

[13:40:02 - 13:40:06]
question now if I perform the invok

[13:40:04 - 13:40:08]
operation see it will give you three

[13:40:06 - 13:40:09]
results okay three results actually it

[13:40:08 - 13:40:13]
will give

[13:40:09 - 13:40:16]
you so let me show you see it has given

[13:40:13 - 13:40:17]
you three relevant information and from

[13:40:16 - 13:40:19]
where it is referring it has also given

[13:40:17 - 13:40:21]
the URL and you can see the three

[13:40:19 - 13:40:22]
relevant information but what I need I

[13:40:21 - 13:40:24]
need the actual response okay this

[13:40:22 - 13:40:26]
question I have asked what what kinds of

[13:40:24 - 13:40:28]
service they provide I need the actual

[13:40:26 - 13:40:29]
response I don't need this kinds of

[13:40:28 - 13:40:30]
response okay for this what I have to do

[13:40:29 - 13:40:32]
I have to connect my large language

[13:40:30 - 13:40:34]
model I think remember so here I have to

[13:40:32 - 13:40:35]
connect my large language model okay

[13:40:34 - 13:40:37]
then user will ask the query

[13:40:35 - 13:40:38]
so it will process the query as well as

[13:40:37 - 13:40:40]
the relevant let's say answer will be

[13:40:38 - 13:40:42]
getting from the vector database then

[13:40:40 - 13:40:43]
your LM will give the XEL response okay

[13:40:42 - 13:40:45]
so now let's try to see how we can

[13:40:43 - 13:40:47]
perform it now if you want to see the

[13:40:45 - 13:40:49]
pce content okay the let's say result

[13:40:47 - 13:40:50]
you are G getting if you want to see the

[13:40:49 - 13:40:52]
contents what you can do you can call

[13:40:50 - 13:40:54]
this one pce content okay I want to see

[13:40:52 - 13:40:56]
the first let's say answer pH content so

[13:40:54 - 13:40:58]
this is the entire Bas content you can

[13:40:56 - 13:40:59]
see fine now here I'm initializing my

[13:40:58 - 13:41:00]
large language model I think you know

[13:40:59 - 13:41:03]
what is temperature parameter what is

[13:41:00 - 13:41:05]
Max token parameter now here you can see

[13:41:03 - 13:41:06]
I have created one chain okay create

[13:41:05 - 13:41:08]
retable chain so this will give me the

[13:41:06 - 13:41:10]
chain object that means I can connect my

[13:41:08 - 13:41:11]
large language model as well as the

[13:41:10 - 13:41:13]
vector database okay then I'm also going

[13:41:11 - 13:41:15]
to pass one prompt okay system prompt

[13:41:13 - 13:41:17]
and for this I'm going to use uh prom

[13:41:15 - 13:41:18]
template okay I think remember we we can

[13:41:17 - 13:41:19]
also create the promp template so this

[13:41:18 - 13:41:21]
is the prompt I have created guys you

[13:41:19 - 13:41:22]
can see you are an assistant for the

[13:41:21 - 13:41:25]
question answering task uh use the

[13:41:22 - 13:41:27]
following piece of uh uh retri constuct

[13:41:25 - 13:41:30]
to answer the question if you don't know

[13:41:27 - 13:41:32]
uh the answer say uh that you don't know

[13:41:30 - 13:41:34]
use three sentence maximum to keep the

[13:41:32 - 13:41:36]
answer concise you can also change the

[13:41:34 - 13:41:37]
prompt it's up to you but I will use

[13:41:36 - 13:41:39]
this prompt okay it will take the

[13:41:37 - 13:41:40]
context and it will give you the answer

[13:41:39 - 13:41:42]
now for this I'm going to create a promp

[13:41:40 - 13:41:43]
template first of all so here I've

[13:41:42 - 13:41:45]
created The Prompt template this is

[13:41:43 - 13:41:47]
going to be my system prompt and user

[13:41:45 - 13:41:48]
will give the input okay whatever input

[13:41:47 - 13:41:50]
actually user will ask let's say this is

[13:41:48 - 13:41:51]
the input user will ask okay this input

[13:41:50 - 13:41:53]
actually it will come here okay and it

[13:41:51 - 13:41:55]
will create the complete prompt that

[13:41:53 - 13:41:56]
time now let me initialize the prompt

[13:41:55 - 13:41:59]
now here I'm going to create the chain

[13:41:56 - 13:42:00]
so I'm using Create stop document chain

[13:41:59 - 13:42:02]
so this is the function actually I'm

[13:42:00 - 13:42:03]
using because I already told you inide

[13:42:02 - 13:42:04]
Lang chain actually we are having

[13:42:03 - 13:42:06]
different different chains right now

[13:42:04 - 13:42:08]
here I'm passing my LM as well as the

[13:42:06 - 13:42:09]
prompt then again what you have to do

[13:42:08 - 13:42:11]
you have to call another function create

[13:42:09 - 13:42:12]
retable CH okay so inside that you have

[13:42:11 - 13:42:14]
to give your vector database okay the

[13:42:12 - 13:42:15]
vector database you have created that

[13:42:14 - 13:42:17]
means your knowledge base and you have

[13:42:15 - 13:42:19]
to give the this object your question

[13:42:17 - 13:42:20]
answer CH okay this object actually you

[13:42:19 - 13:42:23]
have to give now it will give you the

[13:42:20 - 13:42:24]
entire rag genen now here you can ask

[13:42:23 - 13:42:26]
any kinds of questions so here I'm

[13:42:24 - 13:42:28]
calling this ragen invok and this is the

[13:42:26 - 13:42:30]
input what kinds of service they provide

[13:42:28 - 13:42:32]
and I'm only extracting the answer now

[13:42:30 - 13:42:34]
see if I show you the answer right

[13:42:32 - 13:42:36]
now see this should be the concise

[13:42:34 - 13:42:37]
answer answer that means the accurate

[13:42:36 - 13:42:40]
answer actually it will try to provide

[13:42:37 - 13:42:42]
now see Victoria on move provides uh

[13:42:40 - 13:42:45]
efficient and careful relocation

[13:42:42 - 13:42:47]
services for the apartment Village

[13:42:45 - 13:42:48]
householders okay see blah blah blah

[13:42:47 - 13:42:50]
that means it is giving me the correct

[13:42:48 - 13:42:53]
information right now okay so this is

[13:42:50 - 13:42:55]
called actually rag system now it is

[13:42:53 - 13:42:56]
referring my private data my external

[13:42:55 - 13:42:59]
data on top of that actually it is

[13:42:56 - 13:43:01]
giving me the answer and if you ask this

[13:42:59 - 13:43:02]
question to the chat GPT CH GPT won't be

[13:43:01 - 13:43:04]
able to give the answer because CH GPT

[13:43:02 - 13:43:06]
hasn't trained with this data okay I

[13:43:04 - 13:43:09]
think getting my point now let's try to

[13:43:06 - 13:43:10]
see how we can create a user app okay so

[13:43:09 - 13:43:12]
what I've done I've created another file

[13:43:10 - 13:43:14]
called app.py and whatever code I have

[13:43:12 - 13:43:16]
written okay s by sell I just copy

[13:43:14 - 13:43:17]
pasted and I just created like that in

[13:43:16 - 13:43:18]
this particular dot file you can see

[13:43:17 - 13:43:21]
I've imported all the library I'm

[13:43:18 - 13:43:24]
loading my let's say secret uh keys that

[13:43:21 - 13:43:26]
means open API Keys then I'm giving the

[13:43:24 - 13:43:28]
URL I'm extracting the data I'm creating

[13:43:26 - 13:43:29]
that that means chunks okay then I'm

[13:43:28 - 13:43:31]
creating the vector store I'm

[13:43:29 - 13:43:34]
initializing my large language model

[13:43:31 - 13:43:36]
then I'm using stream L you can see St

[13:43:34 - 13:43:37]
then I'm initializing my prompt so you

[13:43:36 - 13:43:39]
can see this is the prompt and now if

[13:43:37 - 13:43:41]
user is asking any quy this quy actually

[13:43:39 - 13:43:42]
I'm passing here and it is giving me the

[13:43:41 - 13:43:43]
response that response actually I'm

[13:43:42 - 13:43:45]
showing on the stream L application okay

[13:43:43 - 13:43:47]
now let me execute and let me show you

[13:43:45 - 13:43:49]
how this app will look like so for this

[13:43:47 - 13:43:54]
you can execute one command called

[13:43:49 - 13:43:56]
stream lead run app.py okay now see if I

[13:43:54 - 13:43:57]
execute the command so it will open up

[13:43:56 - 13:44:00]
my

[13:43:57 - 13:44:02]
application now see this is the title I

[13:44:00 - 13:44:05]
think you saw that st. title we have

[13:44:02 - 13:44:08]
written uh here

[13:44:05 - 13:44:09]
um see rag demo and this title will show

[13:44:08 - 13:44:11]
in the search bar you can see this the

[13:44:09 - 13:44:13]
search bar because here I'm taking chat

[13:44:11 - 13:44:15]
input now so you can see this the chat

[13:44:13 - 13:44:16]
mode here it will show the message now

[13:44:15 - 13:44:18]
you can change the message as per your

[13:44:16 - 13:44:21]
requirement now let me ask one query so

[13:44:18 - 13:44:21]
I'll ask the same

[13:44:22 - 13:44:25]
query so I'll copy this

[13:44:25 - 13:44:31]
quy and here I can ask you can go to the

[13:44:29 - 13:44:34]
website and you can U ask any kinds of

[13:44:31 - 13:44:35]
query it's up to you so guys as you can

[13:44:34 - 13:44:36]
see it has given me the response

[13:44:35 - 13:44:38]
victorion move provides range of

[13:44:36 - 13:44:40]
services including apartment moving

[13:44:38 - 13:44:42]
Villa moving okay and so on that means

[13:44:40 - 13:44:44]
it is working fine right now you can ask

[13:44:42 - 13:44:45]
any kinds of question guys any kinds of

[13:44:44 - 13:44:47]
question you can ask uh whatever

[13:44:45 - 13:44:49]
actually information you are having in

[13:44:47 - 13:44:50]
this website fine so yes guys this is

[13:44:49 - 13:44:52]
the rag demo and that's how we can

[13:44:50 - 13:44:54]
create a rag going forward we'll be also

[13:44:52 - 13:44:56]
learning some Advanced rag we be let's

[13:44:54 - 13:44:57]
say creating hybrid drag and all okay

[13:44:56 - 13:44:59]
going forward we'll be learning these

[13:44:57 - 13:45:01]
are some Advanced rag application you

[13:44:59 - 13:45:02]
can also create so in the next video

[13:45:01 - 13:45:04]
what we'll do we'll just try to create

[13:45:02 - 13:45:06]
another rag application okay with the

[13:45:04 - 13:45:08]
help of Google jini pro model okay this

[13:45:06 - 13:45:09]
is the open source model we'll be using

[13:45:08 - 13:45:11]
with the help of that we can also create

[13:45:09 - 13:45:12]
a rag application in this video we'll

[13:45:11 - 13:45:15]
try to understand what is the difference

[13:45:12 - 13:45:17]
between rag versus fine tuning because

[13:45:15 - 13:45:19]
many people has this question when we

[13:45:17 - 13:45:21]
have to perform the rag when we have to

[13:45:19 - 13:45:23]
perform the fine tuning operation and

[13:45:21 - 13:45:25]
what is the difference between them so

[13:45:23 - 13:45:27]
see both technique actually we used to

[13:45:25 - 13:45:30]
extend the abilities of the large

[13:45:27 - 13:45:32]
language model okay see when you have to

[13:45:30 - 13:45:33]
use the fine tune approach when you have

[13:45:32 - 13:45:35]
to use the rag approach let's say you

[13:45:33 - 13:45:37]
are working in a very specific specific

[13:45:35 - 13:45:39]
domain with some specific data okay and

[13:45:37 - 13:45:40]
with some specific task that time

[13:45:39 - 13:45:42]
actually you can use something called

[13:45:40 - 13:45:45]
fine tune approach because whatever pre

[13:45:42 - 13:45:46]
large language model you will be using

[13:45:45 - 13:45:48]
it won be having like these are the

[13:45:46 - 13:45:50]
information let's say you are working in

[13:45:48 - 13:45:51]
the field of medical okay medical domain

[13:45:50 - 13:45:53]
and they actually you are creating one

[13:45:51 - 13:45:55]
bot okay you are creating one medical

[13:45:53 - 13:45:57]
let's say information bot so this will

[13:45:55 - 13:45:59]
give you let's say medical related

[13:45:57 - 13:46:01]
information and here you are using very

[13:45:59 - 13:46:02]
specific data okay so this data actually

[13:46:01 - 13:46:04]
was not used during trading of this

[13:46:02 - 13:46:06]
large language model so that time what

[13:46:04 - 13:46:08]
you can do at the very first time you

[13:46:06 - 13:46:10]
can do the fine tune operation that

[13:46:08 - 13:46:12]
means you can fine tune one pree model

[13:46:10 - 13:46:13]
and you can create this uh application

[13:46:12 - 13:46:15]
so let's say this is the application we

[13:46:13 - 13:46:17]
created now user has given one question

[13:46:15 - 13:46:19]
what are the latest treatment for the

[13:46:17 - 13:46:21]
type two diabetics so whenever you train

[13:46:19 - 13:46:23]
this model so you provided actually

[13:46:21 - 13:46:25]
these are the information so the latest

[13:46:23 - 13:46:27]
treatment for the type two diabetes

[13:46:25 - 13:46:30]
include meditation like like M forming

[13:46:27 - 13:46:33]
then Lifestyle Changes such as diet

[13:46:30 - 13:46:35]
exercise and in some cases actually

[13:46:33 - 13:46:37]
insulin therapy so these the information

[13:46:35 - 13:46:38]
actually you have given ring fine tune

[13:46:37 - 13:46:40]
these are the model now let's say there

[13:46:38 - 13:46:42]
is a new treatment came now if you are

[13:46:40 - 13:46:45]
asking the same question again to your

[13:46:42 - 13:46:46]
let's say uh system it will give you the

[13:46:45 - 13:46:48]
same answer again and again because it

[13:46:46 - 13:46:51]
is already trained with your older data

[13:46:48 - 13:46:53]
yes or no so that new information

[13:46:51 - 13:46:55]
actually it doesn't have so it won't be

[13:46:53 - 13:46:57]
able to give the new new actually let's

[13:46:55 - 13:46:59]
say technique for the let's say

[13:46:57 - 13:47:01]
treatment of diabetics 2 now in case

[13:46:59 - 13:47:02]
what you can do you can use this new

[13:47:01 - 13:47:04]
information and you can create a rag

[13:47:02 - 13:47:06]
based application so what you have to do

[13:47:04 - 13:47:08]
you have to to use the same llm model

[13:47:06 - 13:47:10]
only same llm model only but you will be

[13:47:08 - 13:47:12]
creating one additional knowledge base I

[13:47:10 - 13:47:13]
think I showed you how to create the rag

[13:47:12 - 13:47:15]
so with the help of this data you'll be

[13:47:13 - 13:47:16]
creating one additional knowledge base

[13:47:15 - 13:47:18]
and with that knowledge base you'll be

[13:47:16 - 13:47:20]
connecting your medical bot then your

[13:47:18 - 13:47:22]
medical bot will be able to give the

[13:47:20 - 13:47:24]
response okay from the latest let say

[13:47:22 - 13:47:25]
technique from the latest information

[13:47:24 - 13:47:27]
yes or no okay now I think you got it

[13:47:25 - 13:47:29]
when we have to use the rag technique

[13:47:27 - 13:47:31]
when we have to use the find uning

[13:47:29 - 13:47:32]
technique now see here we are using rag

[13:47:31 - 13:47:34]
technique now if you're asking the same

[13:47:32 - 13:47:35]
question now here you will see that it

[13:47:34 - 13:47:37]
will give you the recent treatment okay

[13:47:35 - 13:47:39]
for the type two diabetics okay the

[13:47:37 - 13:47:42]
recent treatment whatever actually it

[13:47:39 - 13:47:43]
came in the market okay now I think this

[13:47:42 - 13:47:45]
is clear when we have to use the fine

[13:47:43 - 13:47:46]
tuning technique when we have to use the

[13:47:45 - 13:47:49]
rag Bas technique and again fine tuning

[13:47:46 - 13:47:51]
is like more costly so for this you have

[13:47:49 - 13:47:53]
you need huge amount of data you need a

[13:47:51 - 13:47:54]
good computational machine that means

[13:47:53 - 13:47:56]
you you should have GPU good

[13:47:54 - 13:47:58]
configuration GPU good configuration Ram

[13:47:56 - 13:48:00]
okay if you're not having these kinds of

[13:47:58 - 13:48:02]
gpus so you can't do the fine tuning

[13:48:00 - 13:48:05]
operation that means uh in fine tuning

[13:48:02 - 13:48:07]
you are retraining that model you are

[13:48:05 - 13:48:09]
updating the weights right which is not

[13:48:07 - 13:48:10]
involved inside rag so inside rag

[13:48:09 - 13:48:11]
actually we are not training any kind of

[13:48:10 - 13:48:13]
model instead of that we are creating an

[13:48:11 - 13:48:13]
additional knowledge base and with the

[13:48:13 - 13:48:15]
knowledge base actually we are

[13:48:13 - 13:48:17]
connecting our large language model okay

[13:48:15 - 13:48:19]
this is the difference only fine now I

[13:48:17 - 13:48:21]
think guys you got the clearcut idea

[13:48:19 - 13:48:22]
what is the difference between rag

[13:48:21 - 13:48:24]
versus fine tuning and when we have to

[13:48:22 - 13:48:26]
use it so even I will also show you how

[13:48:24 - 13:48:27]
we can perform the fine tuning operation

[13:48:26 - 13:48:29]
okay let's say if I want to create any

[13:48:27 - 13:48:31]
specific task how we can perform the F

[13:48:29 - 13:48:33]
tuning operation not of our custom data

[13:48:31 - 13:48:35]
so guys as of now we have seen the rag

[13:48:33 - 13:48:37]
demo like uh I already showed you what

[13:48:35 - 13:48:39]
is Rag and what is the use of rag and

[13:48:37 - 13:48:40]
why we have to use the rag okay even I

[13:48:39 - 13:48:43]
also showed you what is the difference

[13:48:40 - 13:48:44]
between Rag and fine tuning so in this

[13:48:43 - 13:48:47]
video we'll be implementing one rag

[13:48:44 - 13:48:49]
based project so the project name is QA

[13:48:47 - 13:48:51]
system okay we'll be using here jini pro

[13:48:49 - 13:48:54]
model and langen so if you don't know

[13:48:51 - 13:48:56]
jini is a large language model by

[13:48:54 - 13:48:57]
developed by Google okay so we'll be

[13:48:56 - 13:48:59]
using this model and this model is

[13:48:57 - 13:49:02]
actually free so we can use actually

[13:48:59 - 13:49:03]
Google uh API to use this model okay

[13:49:02 - 13:49:05]
I'll tell you how we can collect the API

[13:49:03 - 13:49:07]
key and with help of that how we can use

[13:49:05 - 13:49:10]
this large language model now see this

[13:49:07 - 13:49:11]
is the entire diagram of our project

[13:49:10 - 13:49:12]
that means here we'll be creating this

[13:49:11 - 13:49:14]
rag application so we are having some

[13:49:12 - 13:49:16]
external documents so in this case

[13:49:14 - 13:49:17]
actually I'm going to use PDF documents

[13:49:16 - 13:49:19]
I'm having some PDF documents okay we'll

[13:49:17 - 13:49:20]
be using this data so we'll be first of

[13:49:19 - 13:49:21]
all extracting the documents then after

[13:49:20 - 13:49:23]
that we will be part the chunking

[13:49:21 - 13:49:24]
operation then we'll be building one

[13:49:23 - 13:49:26]
santic index okay that means we'll be

[13:49:24 - 13:49:28]
creating one knowledge base that means

[13:49:26 - 13:49:30]
whatever let's say data we'll be getting

[13:49:28 - 13:49:32]
we'll be trying to uh using embedding

[13:49:30 - 13:49:33]
model to generate the vector embedding

[13:49:32 - 13:49:34]
then we'll be storing this Vector

[13:49:33 - 13:49:37]
embedding to the vector database then

[13:49:34 - 13:49:38]
user will ask some query this query will

[13:49:37 - 13:49:40]
go to the knowledge Bas knowledge base

[13:49:38 - 13:49:41]
will return some of the relevant answer

[13:49:40 - 13:49:42]
and with the help of large language

[13:49:41 - 13:49:43]
model we'll just try to process the

[13:49:42 - 13:49:45]
answer as well as the question and it

[13:49:43 - 13:49:46]
will give give you the correct answer

[13:49:45 - 13:49:48]
okay so this is what actually we'll be

[13:49:46 - 13:49:49]
implementing here so let me show you how

[13:49:48 - 13:49:51]
we can develop this particular

[13:49:49 - 13:49:53]
application so I already prepared one

[13:49:51 - 13:49:55]
example so let's open up so guys as you

[13:49:53 - 13:49:56]
can see this is the demo uh so for this

[13:49:55 - 13:49:57]
what you have to do again you have to

[13:49:56 - 13:49:58]
create one virtual environment I already

[13:49:57 - 13:50:00]
showed you how to create the virtual

[13:49:58 - 13:50:03]
environment for this you can use this

[13:50:00 - 13:50:05]
command cond create typen in give the

[13:50:03 - 13:50:07]
environment name

[13:50:05 - 13:50:10]
then specify the python version let's

[13:50:07 - 13:50:11]
say 3.10 then hypen y okay this is the

[13:50:10 - 13:50:12]
command to create the virtual

[13:50:11 - 13:50:14]
environment after that just try to

[13:50:12 - 13:50:16]
activate with help of cond activate

[13:50:14 - 13:50:17]
command then install the requirement so

[13:50:16 - 13:50:20]
keep

[13:50:17 - 13:50:21]
install henr requirement.

[13:50:20 - 13:50:24]
[Music]

[13:50:21 - 13:50:26]
txt so for me it is already installed

[13:50:24 - 13:50:27]
see that's why it is telling requirement

[13:50:26 - 13:50:28]
is already satisfied so let me show you

[13:50:27 - 13:50:30]
the requirements so these are the

[13:50:28 - 13:50:32]
requirement you have to install guys so

[13:50:30 - 13:50:33]
same requirements only as part your

[13:50:32 - 13:50:36]
previous project the only thing I have

[13:50:33 - 13:50:37]
added this langin Google J jni so the

[13:50:36 - 13:50:40]
help of this package actually we'll be

[13:50:37 - 13:50:41]
accessing the J model okay so here

[13:50:40 - 13:50:44]
Vector database wise I'm going to use

[13:50:41 - 13:50:45]
chroma DB again you can also use f fine

[13:50:44 - 13:50:47]
cone okay weit any kinds of vector DV

[13:50:45 - 13:50:49]
you can use here so let me open this

[13:50:47 - 13:50:50]
first of all notebook and let me explain

[13:50:49 - 13:50:52]
okay uh what are the things we'll be

[13:50:50 - 13:50:53]
doing here so guys you can see I'm

[13:50:52 - 13:50:55]
having one PDF document let me show you

[13:50:53 - 13:50:57]
this PDF so this is the PDF guys so this

[13:50:55 - 13:50:59]
is my resarch paper actually so I

[13:50:57 - 13:51:01]
published this resarch paper so you can

[13:50:59 - 13:51:03]
see I'm the author here so I'm the

[13:51:01 - 13:51:05]
author here and the research paper is

[13:51:03 - 13:51:07]
about development of multiple combined

[13:51:05 - 13:51:10]
regression method for reain uh rainfall

[13:51:07 - 13:51:11]
measurement okay you can read the paper

[13:51:10 - 13:51:13]
like what are the things actually we

[13:51:11 - 13:51:15]
have proposed here so we'll be asking

[13:51:13 - 13:51:17]
some question okay from this paper

[13:51:15 - 13:51:18]
itself that means this is my private

[13:51:17 - 13:51:20]
data this is my external data on top of

[13:51:18 - 13:51:22]
this data actually I'll be performing

[13:51:20 - 13:51:25]
the chat operation so here I'll be

[13:51:22 - 13:51:27]
asking some questions related uh this

[13:51:25 - 13:51:29]
particular data okay now let's let me

[13:51:27 - 13:51:30]
show you how we can do it for this first

[13:51:29 - 13:51:33]
of all we have to load the PDF for this

[13:51:30 - 13:51:35]
we can use I PDF loader from the langen

[13:51:33 - 13:51:37]
now let me load the data

[13:51:35 - 13:51:39]
so it will you have to give the path of

[13:51:37 - 13:51:42]
your let's say data so here is my path

[13:51:39 - 13:51:43]
my pdf.pdf now see it will give you

[13:51:42 - 13:51:46]
enter extracted documents that means you

[13:51:43 - 13:51:48]
can see it is having around 15 pages

[13:51:46 - 13:51:50]
okay 15 pages in the research paper if

[13:51:48 - 13:51:51]
you open it up then what you have to do

[13:51:50 - 13:51:53]
you have to perform the chunking guys I

[13:51:51 - 13:51:54]
think you know what is chunking so your

[13:51:53 - 13:51:56]
Chun size is equal to have given 1,000

[13:51:54 - 13:51:58]
that means 1,000 what would be

[13:51:56 - 13:52:00]
considered as my one chunks now see if I

[13:51:58 - 13:52:02]
execute here I will get around 44 chunks

[13:52:00 - 13:52:05]
okay now if I want to show you so this

[13:52:02 - 13:52:07]
is my first document chunks now I have

[13:52:05 - 13:52:09]
to get the Google API key so for this

[13:52:07 - 13:52:12]
you can open this

[13:52:09 - 13:52:15]
link so this is available inside uh

[13:52:12 - 13:52:17]
Google AI studio so just click here

[13:52:15 - 13:52:20]
Google AI studio now from here you have

[13:52:17 - 13:52:21]
to collect one API key now see uh it

[13:52:20 - 13:52:23]
will give you this kinds of interface

[13:52:21 - 13:52:24]
now you can create API key for me I

[13:52:23 - 13:52:26]
already created I won't be creating

[13:52:24 - 13:52:28]
again but for you you can create here

[13:52:26 - 13:52:29]
see just select the project if you don't

[13:52:28 - 13:52:31]
have project just try to create a

[13:52:29 - 13:52:33]
projects and try to create the API Keys

[13:52:31 - 13:52:34]
now see if I click here create API key

[13:52:33 - 13:52:36]
in existing project it will create the

[13:52:34 - 13:52:38]
API key okay now after creating the API

[13:52:36 - 13:52:41]
key you will get these kinds of API key

[13:52:38 - 13:52:43]
okay this is your Google API key now

[13:52:41 - 13:52:45]
just try to give the key Google API key

[13:52:43 - 13:52:47]
is equal to past your key here make sure

[13:52:45 - 13:52:50]
you are writing like that otherwise it w

[13:52:47 - 13:52:52]
be working fine now let me save now if I

[13:52:50 - 13:52:53]
open up my notebook now guys what I have

[13:52:52 - 13:52:55]
to do I think remember we have to use

[13:52:53 - 13:52:57]
one embedding model OKAY embedding model

[13:52:55 - 13:52:58]
just to convert my data to the vector

[13:52:57 - 13:53:00]
embedding now for this we'll be using

[13:52:58 - 13:53:01]
one open source embedding model from the

[13:53:00 - 13:53:03]
Google so you can see this is the

[13:53:01 - 13:53:05]
embedding model embedding 001 and this

[13:53:03 - 13:53:07]
is available inside this Google generate

[13:53:05 - 13:53:08]
VI embedding okay nowart from that you

[13:53:07 - 13:53:11]
are having so many embedding model let

[13:53:08 - 13:53:14]
me show you let me open this link so you

[13:53:11 - 13:53:16]
can see you are having a ai2 AI Labs

[13:53:14 - 13:53:19]
then LF Alpha okay so these are the

[13:53:16 - 13:53:20]
actually provider so it is also having

[13:53:19 - 13:53:22]
different different embedding model you

[13:53:20 - 13:53:24]
can use them as well so let me load this

[13:53:22 - 13:53:26]
embedding for this I'm going to uh

[13:53:24 - 13:53:28]
import this Library I'm going to load

[13:53:26 - 13:53:30]
the API key then after that I'm loading

[13:53:28 - 13:53:31]
this embedding model you can see then

[13:53:30 - 13:53:32]
after loading the embedding I'm just

[13:53:31 - 13:53:34]
doing one test operation I'm just

[13:53:32 - 13:53:35]
writing hello world so it should give me

[13:53:34 - 13:53:38]
the Vector representation let me show

[13:53:35 - 13:53:39]
you so this hello word is represented

[13:53:38 - 13:53:41]
with this vector and I'm only printing

[13:53:39 - 13:53:43]
five actually Vector you can also print

[13:53:41 - 13:53:45]
the complete Vector okay now let me

[13:53:43 - 13:53:46]
create the knowledge base for this I'm

[13:53:45 - 13:53:47]
going to use chroma I already told you

[13:53:46 - 13:53:49]
inside that I'm going to pass my

[13:53:47 - 13:53:50]
documents as well as the embedding model

[13:53:49 - 13:53:53]
you can see embedding model now it will

[13:53:50 - 13:53:55]
give me the knowledge base then again I

[13:53:53 - 13:53:57]
can perform similarity Source operation

[13:53:55 - 13:54:00]
that mean stic Source operation for this

[13:53:57 - 13:54:02]
you can execute this line of code so it

[13:54:00 - 13:54:03]
will give me actually 10 relevant answer

[13:54:02 - 13:54:05]
and this is the question I'm asking what

[13:54:03 - 13:54:06]
is the new in development of multiple

[13:54:05 - 13:54:08]
combined regression methods in rainall

[13:54:06 - 13:54:11]
measurement paper this is my question

[13:54:08 - 13:54:13]
now see if I execute it will give me 10

[13:54:11 - 13:54:16]
different response now if I want to show

[13:54:13 - 13:54:17]
you so 10 different relevant response

[13:54:16 - 13:54:19]
actually it will give me now if you want

[13:54:17 - 13:54:21]
to see the pce content you can also see

[13:54:19 - 13:54:22]
that see this is the pce content okay

[13:54:21 - 13:54:24]
now I will be integrating my large

[13:54:22 - 13:54:26]
language model so for this let's

[13:54:24 - 13:54:27]
initialize my jini model you can see so

[13:54:26 - 13:54:28]
here you can see I'm initializing my

[13:54:27 - 13:54:30]
jini model for this I'm using chat

[13:54:28 - 13:54:33]
Google genbi inside that you have to

[13:54:30 - 13:54:34]
give the model name jini 1.5 Pro this is

[13:54:33 - 13:54:35]
the model so J having different

[13:54:34 - 13:54:36]
different model you can search J Min

[13:54:35 - 13:54:38]
model list you will get different

[13:54:36 - 13:54:40]
different model list so from there

[13:54:38 - 13:54:42]
actually I'm using 1.5 pro model and

[13:54:40 - 13:54:43]
temperature max token parameter I think

[13:54:42 - 13:54:45]
you already know okay I already

[13:54:43 - 13:54:47]
explained this part now again I have to

[13:54:45 - 13:54:48]
create the chain I think you remember

[13:54:47 - 13:54:50]
the same chain actually we are creating

[13:54:48 - 13:54:51]
the same we have created our previous

[13:54:50 - 13:54:54]
project as well after that we are

[13:54:51 - 13:54:55]
preparing the prompt okay this is the

[13:54:54 - 13:54:58]
same prompt I'm using this is my prompt

[13:54:55 - 13:54:59]
template right now so let me execute

[13:54:58 - 13:55:01]
then here I'm creating the complete

[13:54:59 - 13:55:03]
chain I'm giving my llm object as well

[13:55:01 - 13:55:05]
as the promp and this one I'm passing to

[13:55:03 - 13:55:07]
my create Ral CH okay you can see I'm

[13:55:05 - 13:55:09]
giving my Vector database as well as my

[13:55:07 - 13:55:11]
this object now this will give me the

[13:55:09 - 13:55:13]
complete CH now here I'm asking the

[13:55:11 - 13:55:15]
question again the same question what is

[13:55:13 - 13:55:16]
the new development of multiple combined

[13:55:15 - 13:55:18]
regression methods for the rfor

[13:55:16 - 13:55:20]
measurement paper now see if I ask the

[13:55:18 - 13:55:22]
question it should give me the answer

[13:55:20 - 13:55:24]
from the paper so guys here you can see

[13:55:22 - 13:55:25]
I got the response the paper of

[13:55:24 - 13:55:27]
development multiple combined regression

[13:55:25 - 13:55:30]
methods for rfor measurement introduce a

[13:55:27 - 13:55:33]
Noel approach to predicting rainall uh

[13:55:30 - 13:55:35]
quantity the author utiliz 10 supervised

[13:55:33 - 13:55:36]
regation machine learning models to

[13:55:35 - 13:55:39]
predict the rful based on the historical

[13:55:36 - 13:55:40]
data historical weather data their goal

[13:55:39 - 13:55:43]
is to identify the most accurate

[13:55:40 - 13:55:45]
regression techniques for the rful uh

[13:55:43 - 13:55:46]
prediction see uh it is giving me the

[13:55:45 - 13:55:48]
correct response now if you see the

[13:55:46 - 13:55:49]
paper now if you read the paper you will

[13:55:48 - 13:55:51]
see that we have proposed the same thing

[13:55:49 - 13:55:52]
here that means it is working fine okay

[13:55:51 - 13:55:55]
that's how also you can use different

[13:55:52 - 13:55:56]
different data sources uh that means if

[13:55:55 - 13:55:58]
you're having any private data okay if

[13:55:56 - 13:55:59]
you're having any custom data you can

[13:55:58 - 13:56:01]
create the rag based application like

[13:55:59 - 13:56:03]
that so guys uh this was The Notebook

[13:56:01 - 13:56:05]
experiment now let me show you how we

[13:56:03 - 13:56:07]
can create a

[13:56:05 - 13:56:09]
uh user app so for this I'm going to

[13:56:07 - 13:56:10]
again use streamlit and whatever code I

[13:56:09 - 13:56:13]
have written here I just copy pasted

[13:56:10 - 13:56:15]
inside this app dop you can see all the

[13:56:13 - 13:56:18]
import operation I'm loading then uh my

[13:56:15 - 13:56:20]
secret key that means my uh Google API

[13:56:18 - 13:56:22]
key okay here I'm loading it then I'm

[13:56:20 - 13:56:24]
loading my documents performing the

[13:56:22 - 13:56:25]
chunking operation creating the vector

[13:56:24 - 13:56:29]
store initializing the large language

[13:56:25 - 13:56:30]
model this is my prompt and this is the

[13:56:29 - 13:56:31]
uh chat input I'm taking that means I'm

[13:56:30 - 13:56:34]
creating one chat input box with the

[13:56:31 - 13:56:36]
help of stream lit so this is my prompt

[13:56:34 - 13:56:39]
then after that if uh user has given any

[13:56:36 - 13:56:41]
query so it will uh do the generation

[13:56:39 - 13:56:43]
and it will show the it will show the on

[13:56:41 - 13:56:45]
top of my stream L application now let

[13:56:43 - 13:56:49]
me show you how it will works so for

[13:56:45 - 13:56:49]
this you can run this command stream

[13:56:50 - 13:56:54]
lit

[13:56:51 - 13:56:54]
run

[13:56:57 - 13:57:01]
f.p so guys you can see this is the

[13:56:59 - 13:57:03]
title rag application using J Pro you

[13:57:01 - 13:57:04]
can also change it here okay anything

[13:57:03 - 13:57:06]
you can give here

[13:57:04 - 13:57:08]
now here I got the input box now I can

[13:57:06 - 13:57:10]
ask any question let's say I will ask

[13:57:08 - 13:57:10]
the same

[13:57:11 - 13:57:14]
question you can ask any question from

[13:57:13 - 13:57:16]
my paper just go through the paper and

[13:57:14 - 13:57:19]
ask any kinds of

[13:57:16 - 13:57:21]
question so here we're using J model uh

[13:57:19 - 13:57:23]
through the API request and it is like

[13:57:21 - 13:57:25]
free API okay you don't need to pay for

[13:57:23 - 13:57:27]
anything now see guys this is the answer

[13:57:25 - 13:57:29]
I got now if you see the answer it's

[13:57:27 - 13:57:30]
pretty good okay that means the correct

[13:57:29 - 13:57:32]
information it has given me so yes guys

[13:57:30 - 13:57:33]
this is the project actually the Q

[13:57:32 - 13:57:34]
project we have developed with the help

[13:57:33 - 13:57:37]
of J Pro length chain and Vector

[13:57:34 - 13:57:39]
database uh so far we have learned about

[13:57:37 - 13:57:40]
like rag Ral augmented generation and

[13:57:39 - 13:57:43]
there I showed you what is the use of

[13:57:40 - 13:57:45]
rag and how we can create a rag okay

[13:57:43 - 13:57:46]
even I already uh I think discussed what

[13:57:45 - 13:57:48]
is the difference between rag versus

[13:57:46 - 13:57:49]
fine tuning that means if you want to

[13:57:48 - 13:57:51]
work in a domain which is like

[13:57:49 - 13:57:53]
completely new domain and you are

[13:57:51 - 13:57:55]
working with very specific task that

[13:57:53 - 13:57:57]
time what you can do instead of

[13:57:55 - 13:57:59]
implementing the rag you can f tune one

[13:57:57 - 13:58:01]
LM okay and to find tune the LM what you

[13:57:59 - 13:58:03]
have to do guys you have to use one

[13:58:01 - 13:58:06]
Preen model on top of prean model you

[13:58:03 - 13:58:07]
have to train your custom data so let me

[13:58:06 - 13:58:09]
open up my Blackboard and let me discuss

[13:58:07 - 13:58:12]
there what is fine tuning exactly so

[13:58:09 - 13:58:12]
guys inside fine

[13:58:14 - 13:58:21]
tuning uh you will be using one pre-tin

[13:58:19 - 13:58:24]
model OKAY

[13:58:21 - 13:58:26]
pre-rain large language model okay I

[13:58:24 - 13:58:28]
think I already showed you there are so

[13:58:26 - 13:58:29]
many large language models are available

[13:58:28 - 13:58:31]
as open source for this you can go to

[13:58:29 - 13:58:32]
the hugging pH so here you can see there

[13:58:31 - 13:58:34]
are thousands of large language models

[13:58:32 - 13:58:35]
are available now you can choose

[13:58:34 - 13:58:37]
any kinds of model as for your

[13:58:35 - 13:58:38]
requirement let's say you want to use

[13:58:37 - 13:58:42]
something called

[13:58:38 - 13:58:45]
llama meta llama you can simply search

[13:58:42 - 13:58:47]
Llama here so you'll get see all the

[13:58:45 - 13:58:48]
Llama model OKAY llama 2 llama 3 all

[13:58:47 - 13:58:51]
kinds of model actually will see that

[13:58:48 - 13:58:53]
see okay and this is from meta AI now

[13:58:51 - 13:58:55]
what you can do you can download this

[13:58:53 - 13:58:58]
model on top of that you can fine tune

[13:58:55 - 13:59:01]
your custom data but before fine tuning

[13:58:58 - 13:59:03]
uh what you can do see first of all

[13:59:01 - 13:59:04]
let's say whatever let's say project you

[13:59:03 - 13:59:07]
want to implement let's see you want to

[13:59:04 - 13:59:09]
implement one chat board let's say you

[13:59:07 - 13:59:13]
want to implement one medical chat

[13:59:09 - 13:59:16]
board okay medical chat

[13:59:13 - 13:59:18]
board first of all use one pre-end large

[13:59:16 - 13:59:20]
language model and try to perform the

[13:59:18 - 13:59:21]
inference operation okay try to perform

[13:59:20 - 13:59:24]
the inference

[13:59:21 - 13:59:26]
operation inference on top of the model

[13:59:24 - 13:59:28]
if this model is able to give the

[13:59:26 - 13:59:29]
correct answer okay if it is able to

[13:59:28 - 13:59:31]
give the correct answer try to select

[13:59:29 - 13:59:34]
this model okay otherwise what you can

[13:59:31 - 13:59:37]
do just try to build one rag rable

[13:59:34 - 13:59:39]
augmented generation okay that means

[13:59:37 - 13:59:44]
create a external knowledge

[13:59:39 - 13:59:47]
base exter null knowledge

[13:59:44 - 13:59:49]
base then try to connect your one

[13:59:47 - 13:59:51]
pre-end large language

[13:59:49 - 13:59:53]
model and try to again perform the

[13:59:51 - 13:59:55]
inference operation okay and try to see

[13:59:53 - 13:59:57]
the accuracy of the metal try to see

[13:59:55 - 13:59:59]
like whether your model is giving able

[13:59:57 - 14:00:00]
to give the correct response or not if

[13:59:59 - 14:00:03]
it is giving try to select this model

[14:00:00 - 14:00:04]
okay otherwise if this boat approach is

[14:00:03 - 14:00:07]
not working that time what you can do

[14:00:04 - 14:00:10]
you can perform the fine tuning

[14:00:07 - 14:00:11]
operation okay fine tuning operation so

[14:00:10 - 14:00:12]
there what you can do you can take one

[14:00:11 - 14:00:14]
pre-end large language model from

[14:00:12 - 14:00:16]
hugging pH from any kinds of let's say

[14:00:14 - 14:00:18]
platform and on top of that you can

[14:00:16 - 14:00:20]
train your custom

[14:00:18 - 14:00:23]
data the data set you are using let's

[14:00:20 - 14:00:25]
say you are using one very specific

[14:00:23 - 14:00:27]
medical okay medical data that time you

[14:00:25 - 14:00:29]
can use this data and you can train one

[14:00:27 - 14:00:31]
custom model on to of it okay this is

[14:00:29 - 14:00:33]
called actually fine tuning and that

[14:00:31 - 14:00:35]
should be my suggestion guys I mean

[14:00:33 - 14:00:38]
directly don't do the fine tuning before

[14:00:35 - 14:00:40]
that try to check whether pre0 model is

[14:00:38 - 14:00:42]
working or not if Preen is not working

[14:00:40 - 14:00:44]
try to build the rag B system if it is

[14:00:42 - 14:00:47]
not working then try to do the fine

[14:00:44 - 14:00:49]
tuning okay because fine tuning is a

[14:00:47 - 14:00:51]
more costly task at the end because here

[14:00:49 - 14:00:53]
you need like huge amount of data even

[14:00:51 - 14:00:54]
you need lots of computational power you

[14:00:53 - 14:00:55]
need you need actually higher

[14:00:54 - 14:00:58]
configuration

[14:00:55 - 14:01:00]
machine okay you should have good GPU

[14:00:58 - 14:01:02]
instance in your system otherwise you

[14:01:00 - 14:01:03]
can't do the fine tuning operation but

[14:01:02 - 14:01:05]
if you want to do the fine tuning

[14:01:03 - 14:01:06]
operation there is some way actually we

[14:01:05 - 14:01:09]
can do it because all kinds of large

[14:01:06 - 14:01:11]
language model you can see all kinds of

[14:01:09 - 14:01:13]
large language model you can see it is

[14:01:11 - 14:01:15]
having actually huge parameter size you

[14:01:13 - 14:01:17]
can see Lama 2 7B that means it is

[14:01:15 - 14:01:19]
having 7 billion parameter it is having

[14:01:17 - 14:01:22]
8 billion parameter that's how it is

[14:01:19 - 14:01:24]
having 70 billion parameter just try to

[14:01:22 - 14:01:27]
consider okay it's a huge huge size

[14:01:24 - 14:01:29]
model so we can't use any kinds of low

[14:01:27 - 14:01:31]
configuration machine here to fine tune

[14:01:29 - 14:01:34]
these are the model so for this what we

[14:01:31 - 14:01:38]
can do we can use something called PF

[14:01:34 - 14:01:43]
Technique we can use something called p

[14:01:38 - 14:01:46]
e f t okay what is the full form of PFT

[14:01:43 - 14:01:48]
parameter efficient fine tuning okay

[14:01:46 - 14:01:50]
this is the full form of PFT so inside

[14:01:48 - 14:01:52]
this PFT we are having some method we

[14:01:50 - 14:01:54]
can use uh so the first one you can use

[14:01:52 - 14:01:55]
something called l or you can use

[14:01:54 - 14:01:58]
something called

[14:01:55 - 14:02:00]
Q okay so this L and Q Lo will help you

[14:01:58 - 14:02:03]
to do to perform this parameter

[14:02:00 - 14:02:05]
efficient F tuning that means uh it

[14:02:03 - 14:02:07]
apply something called quantization

[14:02:05 - 14:02:10]
technique

[14:02:07 - 14:02:13]
quantization technique okay that means

[14:02:10 - 14:02:15]
it will load your model in a lower

[14:02:13 - 14:02:17]
memory instance that means it will load

[14:02:15 - 14:02:19]
your model in a 4bit Precision 8bit

[14:02:17 - 14:02:21]
Precision okay that's how actually it

[14:02:19 - 14:02:23]
will perform the parameter efficient

[14:02:21 - 14:02:25]
fine tuning process now you can ask me

[14:02:23 - 14:02:27]
what is quantization then okay let me

[14:02:25 - 14:02:30]
show you what is quantization see

[14:02:27 - 14:02:30]
quantization is nothing

[14:02:30 - 14:02:36]
but quantization it just a way of

[14:02:34 - 14:02:39]
converting

[14:02:36 - 14:02:43]
from

[14:02:39 - 14:02:47]
higher format uh sorry higher memory

[14:02:43 - 14:02:49]
format to a lower memory format so this

[14:02:47 - 14:02:51]
is called actually quantization now I

[14:02:49 - 14:02:53]
think you already know about neural

[14:02:51 - 14:02:55]
network right let's say this is one

[14:02:53 - 14:02:55]
neural network I'm

[14:02:56 - 14:03:01]
having so inside neural network what

[14:02:58 - 14:03:06]
what we have we have lots of Weights yes

[14:03:01 - 14:03:08]
or no right we have W 1 W2 okay and W3

[14:03:06 - 14:03:09]
and so on so this is this is what

[14:03:08 - 14:03:11]
actually we are having that means we are

[14:03:09 - 14:03:14]
having lots of weight weight and biases

[14:03:11 - 14:03:18]
let's say B1 B2 and so on right now you

[14:03:14 - 14:03:21]
can represent these at the weight as a

[14:03:18 - 14:03:23]
matrix because if you if you know about

[14:03:21 - 14:03:24]
artificial neural network so there I

[14:03:23 - 14:03:26]
think you know how we can represent

[14:03:24 - 14:03:28]
these are the weights okay how we can

[14:03:26 - 14:03:31]
represent our input data and all okay

[14:03:28 - 14:03:33]
let's say this is one 3 cross 3 Matrix

[14:03:31 - 14:03:35]
I'm having and inside that we're having

[14:03:33 - 14:03:38]
having lots of Weights let's say W1 W2

[14:03:35 - 14:03:40]
W3 and so on okay this is the weights

[14:03:38 - 14:03:41]
and this weight is nothing but it's a

[14:03:40 - 14:03:43]
floating

[14:03:41 - 14:03:45]
number okay it's a floating number it's

[14:03:43 - 14:03:47]
a floating value if you see any kinds of

[14:03:45 - 14:03:49]
weight it would be like that let's say

[14:03:47 - 14:03:51]
7.23 like that okay so this is called

[14:03:49 - 14:03:53]
actually floating value these are the

[14:03:51 - 14:03:57]
floating value and if you see this

[14:03:53 - 14:03:59]
floating value stores in a FP

[14:03:57 - 14:04:02]
302

[14:03:59 - 14:04:06]
bit okay ap32 bits now what is the full

[14:04:02 - 14:04:08]
form of AP AP means full Precision okay

[14:04:06 - 14:04:10]
full

[14:04:08 - 14:04:14]
prec okay full Precision you can also

[14:04:10 - 14:04:19]
call it as single

[14:04:14 - 14:04:21]
Precision okay single Precision got it

[14:04:19 - 14:04:22]
so whenever we are doing the

[14:04:21 - 14:04:24]
quantization that means what we are

[14:04:22 - 14:04:26]
doing we are just trying to convert this

[14:04:24 - 14:04:28]
higher memory representation to lower

[14:04:26 - 14:04:30]
memory representation that means it is

[14:04:28 - 14:04:33]
now saving these are the weights in the

[14:04:30 - 14:04:35]
FP 32 bits now what we'll be doing after

[14:04:33 - 14:04:38]
doing the ization we'll be converting

[14:04:35 - 14:04:41]
this 32 bits to let's say 8

[14:04:38 - 14:04:44]
Bits okay 8 Bits or let's say four

[14:04:41 - 14:04:45]
bits four bits that means what will

[14:04:44 - 14:04:49]
happen let's say you are having one

[14:04:45 - 14:04:53]
floating number like that let's say

[14:04:49 - 14:04:55]
1.70 8 9 0 now if you want to convert it

[14:04:53 - 14:04:57]
to 8 Bits what you will be doing you

[14:04:55 - 14:04:59]
will just remove these are the numbers

[14:04:57 - 14:05:01]
actually these are the numbers actually

[14:04:59 - 14:05:03]
will remove and you will take this this

[14:05:01 - 14:05:05]
number only so that's how actually you

[14:05:03 - 14:05:07]
can reduce the memory size that means

[14:05:05 - 14:05:09]
you can convert any kinds of higher

[14:05:07 - 14:05:12]
higher memory higher memory actually

[14:05:09 - 14:05:14]
format to lower memory format so this is

[14:05:12 - 14:05:17]
called actually quantization okay I hope

[14:05:14 - 14:05:20]
you it is cleared and the technique

[14:05:17 - 14:05:22]
actually we usually use let's say

[14:05:20 - 14:05:25]
Loa and Q

[14:05:22 - 14:05:27]
Loa okay Q Lo so this techniques help us

[14:05:25 - 14:05:30]
to perform this quantization that means

[14:05:27 - 14:05:32]
it will it will load the original model

[14:05:30 - 14:05:34]
as a quantized model that means in a

[14:05:32 - 14:05:36]
lower pre

[14:05:34 - 14:05:40]
okay let's say I want to load this model

[14:05:36 - 14:05:41]
in a 4bit Precision 4bit Precision okay

[14:05:40 - 14:05:44]
so let's say previously this model was

[14:05:41 - 14:05:46]
in 32 bit Precision but I want to load

[14:05:44 - 14:05:49]
in 4bit Precision so how it will happen

[14:05:46 - 14:05:50]
with the help of Q Lo or L you can do it

[14:05:49 - 14:05:52]
sorry with the help of L and Q L you can

[14:05:50 - 14:05:55]
perform it we are having already some

[14:05:52 - 14:05:56]
python libraries okay so we are having

[14:05:55 - 14:05:59]
one Library called

[14:05:56 - 14:06:01]
PFT okay this called parameter efficient

[14:05:59 - 14:06:03]
find training so with the help of that

[14:06:01 - 14:06:05]
you can perform Lura and QA technique so

[14:06:03 - 14:06:07]
with the help of that you can load any

[14:06:05 - 14:06:10]
kinds of actual model so these are the

[14:06:07 - 14:06:12]
model okay in a 4bit Precision in 8 bit

[14:06:10 - 14:06:14]
Precision okay that means you can load

[14:06:12 - 14:06:15]
as a quantized model so that you can

[14:06:14 - 14:06:17]
perform the fine tuning operation

[14:06:15 - 14:06:19]
because as I already told you this

[14:06:17 - 14:06:20]
actual model you can't load because it

[14:06:19 - 14:06:23]
is having huge amount of size huge

[14:06:20 - 14:06:24]
amount of let's say weight size okay and

[14:06:23 - 14:06:28]
it is uh storing those are the weights

[14:06:24 - 14:06:29]
in a 32-bit precision and to load this

[14:06:28 - 14:06:31]
at the model we need a good

[14:06:29 - 14:06:34]
configuration machine good configuration

[14:06:31 - 14:06:35]
GPU memory and so on but we don't have

[14:06:34 - 14:06:37]
that much of resources we are having

[14:06:35 - 14:06:40]
let's say Google collab free Google

[14:06:37 - 14:06:42]
collab or let's say you are having 30 60

[14:06:40 - 14:06:45]
GPU that time what you can do that time

[14:06:42 - 14:06:46]
you have to load these are the model

[14:06:45 - 14:06:47]
with the help of this these are the

[14:06:46 - 14:06:49]
technique actually the technique

[14:06:47 - 14:06:51]
actually I showed you uh this one

[14:06:49 - 14:06:53]
quantization that means you will be

[14:06:51 - 14:06:54]
using L and Q Lo with the help of that

[14:06:53 - 14:06:56]
you will be loading the model and we'll

[14:06:54 - 14:06:58]
perform the finding operation now you

[14:06:56 - 14:07:00]
can ask me sir if I'm doing that one so

[14:06:58 - 14:07:02]
definitely I will lose some

[14:07:00 - 14:07:04]
information definitely will lose some

[14:07:02 - 14:07:06]
information because you are loading the

[14:07:04 - 14:07:08]
model in a 8bit and 4bit precision from

[14:07:06 - 14:07:10]
the 32bits that means here you are

[14:07:08 - 14:07:11]
getting rid of some of the numbers so

[14:07:10 - 14:07:13]
definitely you are losing some

[14:07:11 - 14:07:16]
information but again L and K takes care

[14:07:13 - 14:07:18]
this part actually so they try to

[14:07:16 - 14:07:20]
optimize your let's say model weights as

[14:07:18 - 14:07:22]
much uh they can okay so you don't have

[14:07:20 - 14:07:24]
to worry about if you're using these at

[14:07:22 - 14:07:26]
the library everything would be happen

[14:07:24 - 14:07:28]
in a optimized way so we'll be learning

[14:07:26 - 14:07:30]
as a practical also how we can find un

[14:07:28 - 14:07:31]
one large language model so in the next

[14:07:30 - 14:07:34]
video we'll be learning how we can find

[14:07:31 - 14:07:36]
tune one model called Lama to metal Lama

[14:07:34 - 14:07:38]
2 okay we'll be fine tuning this model

[14:07:36 - 14:07:40]
on top of our custom data and here we'll

[14:07:38 - 14:07:42]
be using this PFT technique parameter

[14:07:40 - 14:07:44]
efficient fine tuning technique got it

[14:07:42 - 14:07:46]
because uh I'll be using free collab

[14:07:44 - 14:07:48]
here if you want to do any your local

[14:07:46 - 14:07:49]
machine if you are having let's say any

[14:07:48 - 14:07:51]
basic zpu you can also do it but I'll

[14:07:49 - 14:07:53]
try to suggest try to train on google

[14:07:51 - 14:07:55]
collab if if you're not having any kinds

[14:07:53 - 14:07:56]
of GPU okay and not having any kinds of

[14:07:55 - 14:07:59]
conf good configuration machine you can

[14:07:56 - 14:08:01]
perform on Google collab fine so yes

[14:07:59 - 14:08:02]
guys this is uh the introduction of fine

[14:08:01 - 14:08:04]
tuning and I think you got to know how

[14:08:02 - 14:08:07]
we can perform from the fine tuning

[14:08:04 - 14:08:09]
operation and what is this PFT okay PFT

[14:08:07 - 14:08:11]
technique exactly and what is L and K

[14:08:09 - 14:08:13]
because I know that many people will

[14:08:11 - 14:08:15]
have this question what is Kora laa and

[14:08:13 - 14:08:16]
what is PFT and all okay so I think now

[14:08:15 - 14:08:19]
everything is clear okay how things are

[14:08:16 - 14:08:21]
working here fine so in the next video

[14:08:19 - 14:08:23]
we'll see the Practical demo of the fine

[14:08:21 - 14:08:25]
tuning so we'll be fine tuning one model

[14:08:23 - 14:08:27]
large language model called metal L 2 so

[14:08:25 - 14:08:29]
here we'll be fine tuning one large

[14:08:27 - 14:08:30]
language model called meta Lama 2 I

[14:08:29 - 14:08:32]
think you know Lama 2 right Lama 2 is a

[14:08:30 - 14:08:35]
large language model so if you go to the

[14:08:32 - 14:08:36]
hugging face and if you search for meta

[14:08:35 - 14:08:38]
if you search for Meta Meta is having

[14:08:36 - 14:08:40]
different different large language model

[14:08:38 - 14:08:42]
if I show you let's say if I go to the

[14:08:40 - 14:08:43]
meta LMC it is having different

[14:08:42 - 14:08:46]
different large language model like meta

[14:08:43 - 14:08:48]
Lama 3.1 llama 2 is also there if I

[14:08:46 - 14:08:50]
expand all all the things see this is

[14:08:48 - 14:08:52]
the Lama 3 family this is the Lama 2

[14:08:50 - 14:08:54]
family so the way actually I'm doing the

[14:08:52 - 14:08:57]
let's say fine tuning of llama 2 family

[14:08:54 - 14:08:58]
you can also perform llama 3 as well why

[14:08:57 - 14:09:00]
I'm taking Lama 2 because it would be a

[14:08:58 - 14:09:02]
little bit uh I mean small size model

[14:09:00 - 14:09:03]
that's why I'm taking Lama 2 you can

[14:09:02 - 14:09:06]
also take Lama 3 as well okay the

[14:09:03 - 14:09:07]
process will remain same and how to get

[14:09:06 - 14:09:09]
the permission from the Lama I think I

[14:09:07 - 14:09:11]
already showed you in my open source

[14:09:09 - 14:09:13]
large language model session so you have

[14:09:11 - 14:09:14]
to apply for the permission first of all

[14:09:13 - 14:09:16]
and they will give the permission then

[14:09:14 - 14:09:18]
after that you can load it and if you're

[14:09:16 - 14:09:19]
not getting the permission as of now

[14:09:18 - 14:09:21]
what you can do I can also show you one

[14:09:19 - 14:09:23]
alternative approach you can also follow

[14:09:21 - 14:09:24]
this one fine I think I already showed

[14:09:23 - 14:09:26]
you one alternative approach like you

[14:09:24 - 14:09:28]
can use any other repository to load the

[14:09:26 - 14:09:30]
model it is also fine then what you can

[14:09:28 - 14:09:33]
do after fine tuning this model you can

[14:09:30 - 14:09:35]
also push this model to the hugging is

[14:09:33 - 14:09:37]
Hub let's say if I show you my Hub now

[14:09:35 - 14:09:40]
so if I go to my profile see I already

[14:09:37 - 14:09:42]
published one model this fine tune Lama

[14:09:40 - 14:09:45]
model after fine tuning it I publish

[14:09:42 - 14:09:46]
this model in my um hugging face Hub now

[14:09:45 - 14:09:48]
people can use my model so they will be

[14:09:46 - 14:09:50]
just copying this name and they can use

[14:09:48 - 14:09:53]
my model you can see it is already

[14:09:50 - 14:09:55]
downloaded uh 65 times okay 65 times

[14:09:53 - 14:09:56]
this model got downloaded by the

[14:09:55 - 14:09:58]
audience right so that's how actually

[14:09:56 - 14:09:59]
you can also publish your model if you

[14:09:58 - 14:10:02]
want you can also publish your model to

[14:09:59 - 14:10:03]
the hugging P sub got it so that people

[14:10:02 - 14:10:05]
can also use your model

[14:10:03 - 14:10:07]
got it so now let me show you how we can

[14:10:05 - 14:10:08]
perform the fine tuning for this I have

[14:10:07 - 14:10:09]
prepared one beautiful notebook so in

[14:10:08 - 14:10:11]
this notebook actually I have written

[14:10:09 - 14:10:13]
each and every step you want to follow

[14:10:11 - 14:10:16]
so first of all make sure you selected

[14:10:13 - 14:10:17]
runtime as GPU because you are doing the

[14:10:16 - 14:10:19]
finding operation and definitely you

[14:10:17 - 14:10:21]
need a GPU so I'll be selecting T4 GPU

[14:10:19 - 14:10:22]
because here I'm using free Google

[14:10:21 - 14:10:24]
collab you can also take the premium

[14:10:22 - 14:10:25]
subscription of the Google collab if

[14:10:24 - 14:10:27]
you're taking the premium one so you'll

[14:10:25 - 14:10:29]
see that your training would be a little

[14:10:27 - 14:10:31]
bit faster than this free one fine now

[14:10:29 - 14:10:33]
let me connect this

[14:10:31 - 14:10:35]
notebook so guys as you can see my

[14:10:33 - 14:10:36]
notebook is connected now the first

[14:10:35 - 14:10:38]
thing what you have to do you have to

[14:10:36 - 14:10:40]
install some of the required package so

[14:10:38 - 14:10:41]
here I have listed down all the package

[14:10:40 - 14:10:43]
actually you need like let's say

[14:10:41 - 14:10:45]
accelerate then PFT PFT is the parameter

[14:10:43 - 14:10:46]
efficient F tuning that package

[14:10:45 - 14:10:48]
accelerate you need if you're using

[14:10:46 - 14:10:49]
Transformer Library uh and if you want

[14:10:48 - 14:10:50]
to let's say use the GPU that time

[14:10:49 - 14:10:52]
actually you need to install this

[14:10:50 - 14:10:54]
accelerate as well fine then you can see

[14:10:52 - 14:10:55]
bits and bytes is also requirement of

[14:10:54 - 14:10:57]
the Transformer and if you want to set

[14:10:55 - 14:10:59]
up everything in your local machine that

[14:10:57 - 14:11:00]
means if you're having local GPU but if

[14:10:59 - 14:11:02]
you don't know how to set up the GPU

[14:11:00 - 14:11:03]
don't need to worry I have created one

[14:11:02 - 14:11:05]
dedicated video Let Me Show for you so

[14:11:03 - 14:11:07]
if you search my YouTube channel DS with

[14:11:05 - 14:11:09]
buy so here you will see that I have

[14:11:07 - 14:11:11]
created one video in the video section

[14:11:09 - 14:11:12]
set up Nvidia GPU for the Deep learning

[14:11:11 - 14:11:14]
so here I showed you how you can install

[14:11:12 - 14:11:17]
the Cuda and Cuda toolkit so definitely

[14:11:14 - 14:11:18]
first of all you have to set up your GPU

[14:11:17 - 14:11:19]
in a proper way then you'll be able to

[14:11:18 - 14:11:21]
set up everything that mean you will be

[14:11:19 - 14:11:23]
able to utilize your GPU so make sure if

[14:11:21 - 14:11:26]
you're doing local setup you can try to

[14:11:23 - 14:11:28]
watch this video okay otherwise if

[14:11:26 - 14:11:30]
you're doing on Google cab try to do the

[14:11:28 - 14:11:34]
same thing the way actually I'm doing

[14:11:30 - 14:11:34]
here so let me install all the packet

[14:11:37 - 14:11:41]
so guys as you can see installation is

[14:11:39 - 14:11:43]
completed now the second thing you have

[14:11:41 - 14:11:44]
to import all the necessary Library so

[14:11:43 - 14:11:46]
you can see I have imported all the

[14:11:44 - 14:11:47]
necessary Library like Auto model for

[14:11:46 - 14:11:49]
casual LM Auto tokenizer okay I think

[14:11:47 - 14:11:51]
you already know these are the thing uh

[14:11:49 - 14:11:53]
the hugging face actually Library okay

[14:11:51 - 14:11:54]
why we need it then you can see I'm

[14:11:53 - 14:11:56]
importing something called PFT that

[14:11:54 - 14:11:58]
means parameter efficient fine tuning so

[14:11:56 - 14:12:00]
from PFT I'm importing something called

[14:11:58 - 14:12:02]
L you can also use Q Lo but here I'm

[14:12:00 - 14:12:05]
using L okay so both Technique we can

[14:12:02 - 14:12:07]
use it's up to you so let me import as

[14:12:05 - 14:12:08]
of now so whenever I will be using it

[14:12:07 - 14:12:10]
I'll tell you okay what are the package

[14:12:08 - 14:12:13]
actually uh you are using and for which

[14:12:10 - 14:12:15]
task so see guys execution is completed

[14:12:13 - 14:12:17]
that means everything is working fine

[14:12:15 - 14:12:19]
now let me show you the data set first

[14:12:17 - 14:12:21]
of all see this is the original data so

[14:12:19 - 14:12:23]
let me open the data see this is the

[14:12:21 - 14:12:25]
original data so the data set name is

[14:12:23 - 14:12:27]
open assistant so the data set name is

[14:12:25 - 14:12:30]
open Assistant goano I think this is the

[14:12:27 - 14:12:32]
data set name and you can see this is

[14:12:30 - 14:12:34]
the data that means it is having some

[14:12:32 - 14:12:36]
conversation between human and assistant

[14:12:34 - 14:12:38]
you can see so conversation between

[14:12:36 - 14:12:40]
human and assistant you can see human

[14:12:38 - 14:12:42]
and assistant so this is the human uh

[14:12:40 - 14:12:44]
let's say conversation and this is the

[14:12:42 - 14:12:45]
assistant conversation okay so that's

[14:12:44 - 14:12:47]
why actually they have collected this

[14:12:45 - 14:12:49]
data and it is having actually you can

[14:12:47 - 14:12:53]
see uh how many example in the training

[14:12:49 - 14:12:55]
you are having 9. 85 K rows F almost 10K

[14:12:53 - 14:12:58]
example you are having now see it is

[14:12:55 - 14:12:59]
also using different different language

[14:12:58 - 14:13:00]
see different different language

[14:12:59 - 14:13:02]
actually they have collected the data

[14:13:00 - 14:13:04]
not only English it is also uh they're

[14:13:02 - 14:13:05]
using see Chinese language also they're

[14:13:04 - 14:13:07]
using different different language that

[14:13:05 - 14:13:10]
means it is a multilanguage data and it

[14:13:07 - 14:13:12]
is a conversation data so we'll be

[14:13:10 - 14:13:15]
training one uh chat model that means

[14:13:12 - 14:13:16]
llama to chat model okay I think I

[14:13:15 - 14:13:17]
already showed you what is the

[14:13:16 - 14:13:18]
difference between Lama to chat model

[14:13:17 - 14:13:20]
and find un model let's say if you want

[14:13:18 - 14:13:22]
to only perform the T generation that

[14:13:20 - 14:13:24]
time you can use pretin model okay and

[14:13:22 - 14:13:25]
if you want to perform let's say chat

[14:13:24 - 14:13:27]
operation chat operation and let's say

[14:13:25 - 14:13:28]
all kinds of task the way actually

[14:13:27 - 14:13:31]
perform with the chat GPT that time you

[14:13:28 - 14:13:33]
can use chat model now if you open the

[14:13:31 - 14:13:35]
hugging face and if you go to the

[14:13:33 - 14:13:36]
actually llama llama model you'll see

[14:13:35 - 14:13:38]
that it is having different different

[14:13:36 - 14:13:41]
model let me show you so if I search for

[14:13:38 - 14:13:44]
llama see if I go to the uh llama 2

[14:13:41 - 14:13:47]
Series actually Lama 2 family you can

[14:13:44 - 14:13:49]
see it is having Lama 2 7B model HF

[14:13:47 - 14:13:51]
model and it is also having something

[14:13:49 - 14:13:53]
called chat model you can see uh See

[14:13:51 - 14:13:54]
chat model chat model means you can

[14:13:53 - 14:13:56]
perform the conversation chat operation

[14:13:54 - 14:13:58]
the way actually perform with the chat

[14:13:56 - 14:14:00]
jpt right so we'll be fine tuning one

[14:13:58 - 14:14:02]
chat model so that is why I'm using this

[14:14:00 - 14:14:04]
chat data set conversation data set okay

[14:14:02 - 14:14:06]
instruction so these are the instruction

[14:14:04 - 14:14:08]
um I think this one see this is the

[14:14:06 - 14:14:09]
instruction human is giving assistant is

[14:14:08 - 14:14:11]
replying so this kinds of data set

[14:14:09 - 14:14:13]
actually we'll be using now you can use

[14:14:11 - 14:14:14]
any kinds of data you just try to

[14:14:13 - 14:14:16]
prepare your data okay in that format

[14:14:14 - 14:14:19]
you can also create a CSV file so inside

[14:14:16 - 14:14:20]
CSV file uh in First Column you can

[14:14:19 - 14:14:22]
write the human let's say conversation

[14:14:20 - 14:14:23]
in second column you can write the

[14:14:22 - 14:14:25]
assistant conversation that's how also

[14:14:23 - 14:14:27]
you can collect the data okay it can be

[14:14:25 - 14:14:29]
any kinds of format so as of now we are

[14:14:27 - 14:14:31]
using the data from the hugging F you

[14:14:29 - 14:14:33]
can also use your custom data and how to

[14:14:31 - 14:14:36]
upload your custom data to the hug f for

[14:14:33 - 14:14:38]
this you can see hugging F documentation

[14:14:36 - 14:14:40]
they will also give you the let's say

[14:14:38 - 14:14:41]
entire process like how I can let's say

[14:14:40 - 14:14:43]
publish my data to the hugging face up

[14:14:41 - 14:14:45]
and from there I can load my data it is

[14:14:43 - 14:14:46]
also possible but most of the data

[14:14:45 - 14:14:48]
actually will see from the hugging face

[14:14:46 - 14:14:52]
itself you can use it from there so see

[14:14:48 - 14:14:53]
this is the Lama to uh supported data

[14:14:52 - 14:14:55]
that means whenever you will perform the

[14:14:53 - 14:14:57]
fine uning now so you have to convert

[14:14:55 - 14:14:59]
this data in that format see this is the

[14:14:57 - 14:15:01]
format so first of all you have to give

[14:14:59 - 14:15:02]
the uh s token you can see s token

[14:15:01 - 14:15:04]
inside that you have to give the inst

[14:15:02 - 14:15:06]
instruction and what is the instruction

[14:15:04 - 14:15:08]
instruction is nothing but it's a human

[14:15:06 - 14:15:10]
conversation whatever conversation human

[14:15:08 - 14:15:13]
is doing now this is called instruction

[14:15:10 - 14:15:16]
see if I open this example see this is

[14:15:13 - 14:15:19]
the human see this is the human

[14:15:16 - 14:15:22]
conversation okay see till this token

[14:15:19 - 14:15:23]
actually that means slash NST that means

[14:15:22 - 14:15:25]
instruction this is the human

[14:15:23 - 14:15:27]
conversation after that whatever text

[14:15:25 - 14:15:30]
you can see this is the assistant

[14:15:27 - 14:15:32]
conversation okay this is the assistant

[14:15:30 - 14:15:34]
conversation got it so that's actually

[14:15:32 - 14:15:36]
you have to prep your data and at the

[14:15:34 - 14:15:37]
last your s token will end again okay

[14:15:36 - 14:15:39]
that means this is the complete system

[14:15:37 - 14:15:41]
token right now the complete prompt that

[14:15:39 - 14:15:43]
means you are creating the prompt here

[14:15:41 - 14:15:45]
because my large language model supports

[14:15:43 - 14:15:46]
prompting right so that that means we

[14:15:45 - 14:15:49]
are creating the prompt here so that my

[14:15:46 - 14:15:50]
model can understand whenever we are

[14:15:49 - 14:15:51]
doing the inference whenever we are

[14:15:50 - 14:15:52]
let's say sending any kinds of prompt to

[14:15:51 - 14:15:54]
the large language model it can

[14:15:52 - 14:15:57]
automatically understand we sending the

[14:15:54 - 14:15:59]
prompt okay so that's why I'm first of

[14:15:57 - 14:16:00]
teaching my model this is instruction

[14:15:59 - 14:16:03]
and after instruction whatever actually

[14:16:00 - 14:16:04]
message you can see this is the is the

[14:16:03 - 14:16:06]
your output that means your response

[14:16:04 - 14:16:07]
assistant response okay this is the

[14:16:06 - 14:16:09]
format now if you open any kinds of data

[14:16:07 - 14:16:12]
you'll see that it is using the same

[14:16:09 - 14:16:15]
format only okay same format only so we

[14:16:12 - 14:16:17]
have to convert our data this format to

[14:16:15 - 14:16:18]
this format okay now you can ask me how

[14:16:17 - 14:16:20]
to convert this format to this format

[14:16:18 - 14:16:22]
for this we can use one notebook see

[14:16:20 - 14:16:24]
this is The Notebook guys even I already

[14:16:22 - 14:16:26]
attached this notebook link inside uh

[14:16:24 - 14:16:27]
This original notebook let me show you

[14:16:26 - 14:16:29]
see this is The Notebook okay so in this

[14:16:27 - 14:16:32]
notebook actually I already WR one

[14:16:29 - 14:16:33]
function transform conversion so this

[14:16:32 - 14:16:34]
one actually will take the human

[14:16:33 - 14:16:36]
conversation as well as the assistant

[14:16:34 - 14:16:38]
conversation and will add the other

[14:16:36 - 14:16:41]
token okay like that the way actually I

[14:16:38 - 14:16:43]
showed you here okay I think it is clear

[14:16:41 - 14:16:45]
now you can use this function as it is

[14:16:43 - 14:16:48]
and you can convert any kinds of let's

[14:16:45 - 14:16:51]
say these kinds of conversation data to

[14:16:48 - 14:16:53]
um uh your uh like llm format that means

[14:16:51 - 14:16:55]
your Lama to format now there are so

[14:16:53 - 14:16:56]
many large language model it takes

[14:16:55 - 14:16:58]
actually different different kinds of

[14:16:56 - 14:16:59]
format if you go to the documentation of

[14:16:58 - 14:17:00]
the hugging face you will see that what

[14:16:59 - 14:17:02]
kinds of format they supports based on

[14:17:00 - 14:17:04]
that actually you can U actually write

[14:17:02 - 14:17:05]
the converter also you can get this

[14:17:04 - 14:17:06]
converter from the hugging face itself

[14:17:05 - 14:17:08]
hugging face also provide these kinds of

[14:17:06 - 14:17:11]
converter you can use this converter to

[14:17:08 - 14:17:13]
convert your data to a specific format

[14:17:11 - 14:17:14]
okay so most of the large language model

[14:17:13 - 14:17:16]
will follow this format only okay you'll

[14:17:14 - 14:17:17]
see that most of the large language

[14:17:16 - 14:17:19]
model will follow the same format the

[14:17:17 - 14:17:20]
format actually I'm using here fine so

[14:17:19 - 14:17:23]
that's why you can use this converter as

[14:17:20 - 14:17:24]
it is now see here I'm loading the data

[14:17:23 - 14:17:28]
that means my entire data that means

[14:17:24 - 14:17:30]
this data this uh open Assistant data

[14:17:28 - 14:17:32]
you can see I'm giving the name of the

[14:17:30 - 14:17:33]
open Assistant then see instead of

[14:17:32 - 14:17:36]
taking all the data all the let's say

[14:17:33 - 14:17:38]
10K example I'm only taking 1,000 okay

[14:17:36 - 14:17:40]
1K actually example because here I'm

[14:17:38 - 14:17:42]
using free collab and finding will take

[14:17:40 - 14:17:44]
time that's why I'm only taking 1,000

[14:17:42 - 14:17:46]
example to perform the finding operation

[14:17:44 - 14:17:47]
and I'm doing the let's say conversion

[14:17:46 - 14:17:52]
operation then after that I'm just

[14:17:47 - 14:17:55]
pushing this uh let's a data here so so

[14:17:52 - 14:17:58]
this is the data now see the same data

[14:17:55 - 14:18:00]
but here actually this guy is taking

[14:17:58 - 14:18:02]
actually 1K example and he has already

[14:18:00 - 14:18:04]
converted this data to the required

[14:18:02 - 14:18:05]
format okay okay so this is uh so this

[14:18:04 - 14:18:07]
data is already available you can see

[14:18:05 - 14:18:09]
this guy has already converted this data

[14:18:07 - 14:18:11]
to this format so directly you can use

[14:18:09 - 14:18:12]
this data but if you want to do it so

[14:18:11 - 14:18:14]
this is The Notebook you can use okay

[14:18:12 - 14:18:16]
the same notebook you can use got it and

[14:18:14 - 14:18:18]
if you want to use the entire data guys

[14:18:16 - 14:18:20]
what you can do so here I already given

[14:18:18 - 14:18:22]
the complete reform data set link you

[14:18:20 - 14:18:24]
can open it up so see it is having

[14:18:22 - 14:18:28]
actually 10K example only see around

[14:18:24 - 14:18:30]
9.85 K rows now see it is already uh

[14:18:28 - 14:18:33]
formated okay it is already formated you

[14:18:30 - 14:18:34]
can also use this data if you using good

[14:18:33 - 14:18:36]
configuration PC you can use this data

[14:18:34 - 14:18:38]
okay for the fing operation but I'm

[14:18:36 - 14:18:41]
going to use this data actually 1K

[14:18:38 - 14:18:43]
example data okay only 1K example I'll

[14:18:41 - 14:18:44]
be taking here so guys I think now you

[14:18:43 - 14:18:48]
got to know how how we can reformat our

[14:18:44 - 14:18:50]
data for the Llama 2 model and see here

[14:18:48 - 14:18:52]
we are using free collab and free collab

[14:18:50 - 14:18:55]
actually offers 15gb of graphics card if

[14:18:52 - 14:18:57]
you see here it will give you 15 GB of

[14:18:55 - 14:19:02]
graphics card see okay and here you will

[14:18:57 - 14:19:04]
get uh uh dis around 11 12 GB and RAM

[14:19:02 - 14:19:06]
actually give 12gb okay so this is the

[14:19:04 - 14:19:08]
configuration of our fre cab now here

[14:19:06 - 14:19:10]
you can see uh it is having actually

[14:19:08 - 14:19:12]
limit resources barely enough to store

[14:19:10 - 14:19:14]
llama to 7B vs that means we can only

[14:19:12 - 14:19:16]
use 7 7 billion Lama to model OKAY 7

[14:19:14 - 14:19:19]
billion Lama to model if you're using 70

[14:19:16 - 14:19:20]
B 30 B 13 billion that time actually you

[14:19:19 - 14:19:23]
will get difficulties okay because it is

[14:19:20 - 14:19:24]
a free Google collab but if you're using

[14:19:23 - 14:19:26]
um premium Google collab that time

[14:19:24 - 14:19:27]
actually you can also use this model

[14:19:26 - 14:19:29]
okay it's completely fine now here you

[14:19:27 - 14:19:30]
can see full fine tuning is not possible

[14:19:29 - 14:19:32]
here we need to perform the parameter

[14:19:30 - 14:19:35]
efficient fine tuning technique like we

[14:19:32 - 14:19:37]
be using L and Q because the full model

[14:19:35 - 14:19:39]
we can't load here we have to use

[14:19:37 - 14:19:41]
quantization technique that means we'll

[14:19:39 - 14:19:43]
be using L and Q to perform the

[14:19:41 - 14:19:45]
parameter efficient fine tuning got it

[14:19:43 - 14:19:47]
and to drastically reduce the vram we

[14:19:45 - 14:19:49]
must fine tune the model in 4bit

[14:19:47 - 14:19:52]
position which is why we'll be using uh

[14:19:49 - 14:19:54]
sorry we'll be using Lo here not Q loer

[14:19:52 - 14:19:55]
we'll be using Lo here fine that means

[14:19:54 - 14:19:57]
we'll be loading our model in a 4bit

[14:19:55 - 14:19:58]
position I think I already explain here

[14:19:57 - 14:20:00]
what is 4bit precision right so

[14:19:58 - 14:20:02]
initially your weight would be in the

[14:20:00 - 14:20:04]
full Precision okay 32 bit Precision

[14:20:02 - 14:20:05]
this is called Full precision and we'll

[14:20:04 - 14:20:07]
be loading the model in the for

[14:20:05 - 14:20:10]
precision with the help of Lura

[14:20:07 - 14:20:11]
technique fine I think it is clear now

[14:20:10 - 14:20:14]
now let's load the model guys now you

[14:20:11 - 14:20:15]
can load the official L 2 model you can

[14:20:14 - 14:20:17]
see you can also load the official Lama

[14:20:15 - 14:20:19]
2 model so Lama 2 is having also

[14:20:17 - 14:20:21]
official model so this one so see this

[14:20:19 - 14:20:23]
is the official Lama to model you can

[14:20:21 - 14:20:25]
load you can copy and you can just paste

[14:20:23 - 14:20:26]
it here but if you if you didn't get the

[14:20:25 - 14:20:29]
permission what you can do you can also

[14:20:26 - 14:20:31]
load the model from any other repository

[14:20:29 - 14:20:35]
so see this repository has having this

[14:20:31 - 14:20:36]
model also this lama lama 27b chat HF

[14:20:35 - 14:20:38]
model so this repository has already

[14:20:36 - 14:20:39]
published and here you don't need to

[14:20:38 - 14:20:41]
take the permission you can directly

[14:20:39 - 14:20:42]
download the model so if you if you

[14:20:41 - 14:20:44]
haven't get the permission you can use

[14:20:42 - 14:20:46]
this model either you can use the

[14:20:44 - 14:20:50]
official model OKAY official model let

[14:20:46 - 14:20:53]
me also copy here and let me mention it

[14:20:50 - 14:20:55]
here let's say I can comment here just

[14:20:53 - 14:20:57]
for your reference you can copy the name

[14:20:55 - 14:21:00]
and you can paste it here okay later on

[14:20:57 - 14:21:02]
now this is the data set guys I'll be

[14:21:00 - 14:21:03]
using I think you remember so this onek

[14:21:02 - 14:21:06]
example will be using so copy the name

[14:21:03 - 14:21:08]
and try to mention it here okay and

[14:21:06 - 14:21:09]
after fine tuning what is the name you

[14:21:08 - 14:21:12]
want to assign I want to assign this

[14:21:09 - 14:21:15]
name Lama 2 7 B CH find you and these

[14:21:12 - 14:21:16]
are the lower parameter you can see and

[14:21:15 - 14:21:18]
low parameter wise everything just keep

[14:21:16 - 14:21:19]
it default because you can see I'm

[14:21:18 - 14:21:21]
loading everything in a 4bit Precision

[14:21:19 - 14:21:23]
okay 4bit Precision so no need to change

[14:21:21 - 14:21:24]
anything keep it everything as default

[14:21:23 - 14:21:27]
see I won't be changing anything only

[14:21:24 - 14:21:29]
the change you have to do the epoc size

[14:21:27 - 14:21:30]
number of epoch you want to train so I

[14:21:29 - 14:21:32]
think Epoch I have mentioned here

[14:21:30 - 14:21:34]
somewhere see number of epoch training

[14:21:32 - 14:21:35]
epoch so as of now I'm showing you one

[14:21:34 - 14:21:37]
one let's say Epoch training because one

[14:21:35 - 14:21:39]
Epoch training will take time if you're

[14:21:37 - 14:21:40]
using free collab and if you're doing

[14:21:39 - 14:21:42]
the actual training that time just try

[14:21:40 - 14:21:44]
to increase the EO size now everything

[14:21:42 - 14:21:45]
keep it default no need to change

[14:21:44 - 14:21:47]
anything now let me initialize all the

[14:21:45 - 14:21:49]
parameter so this is my lower parameter

[14:21:47 - 14:21:52]
guys for the parameter efficient fine

[14:21:49 - 14:21:54]
tuning fine now we'll be loading the

[14:21:52 - 14:21:56]
data set I want to use the training data

[14:21:54 - 14:21:58]
set because I want to do the fine tuning

[14:21:56 - 14:21:59]
and here I'm loading everything in a

[14:21:58 - 14:22:01]
4bit position you can see okay with the

[14:21:59 - 14:22:02]
help of bits and bytes actually

[14:22:01 - 14:22:04]
configuration we are loading everything

[14:22:02 - 14:22:07]
a 4bit position so this is the way

[14:22:04 - 14:22:08]
actually we can Define our L and how I

[14:22:07 - 14:22:10]
got this code if you go to the hugging

[14:22:08 - 14:22:12]
pH documentation you will see that okay

[14:22:10 - 14:22:13]
they have already given these kinds of

[14:22:12 - 14:22:14]
codes in a bit so you just copy paste

[14:22:13 - 14:22:16]
and try to use it as it is no need to

[14:22:14 - 14:22:18]
change anything fine now see here I'm

[14:22:16 - 14:22:19]
loading the model in a 4bit position so

[14:22:18 - 14:22:21]
here you can see I'm loading the base

[14:22:19 - 14:22:23]
model as well as the tokenizer okay

[14:22:21 - 14:22:25]
tokenizer I'm also loading so guys here

[14:22:23 - 14:22:27]
you can see I'm setting all the loader

[14:22:25 - 14:22:28]
configuration after that here is the

[14:22:27 - 14:22:30]
training arguments I think you know what

[14:22:28 - 14:22:32]
is training arguments uh in the hugging

[14:22:30 - 14:22:34]
pH you have to set your directory the

[14:22:32 - 14:22:35]
number of epoch your Optimizer

[14:22:34 - 14:22:37]
everything you can set here then with

[14:22:35 - 14:22:39]
the help of sft trainer I'm initializing

[14:22:37 - 14:22:41]
the training process you can see model.

[14:22:39 - 14:22:43]
train now see if I execute this code it

[14:22:41 - 14:22:45]
will start the training but see training

[14:22:43 - 14:22:47]
will take time actually around 30

[14:22:45 - 14:22:48]
minutes actually it will take I was

[14:22:47 - 14:22:50]
training previously I know that it will

[14:22:48 - 14:22:52]
take around 30 minute okay 30 minute you

[14:22:50 - 14:22:54]
have to wait because here we are using

[14:22:52 - 14:22:55]
free Google collab so as you can see it

[14:22:54 - 14:22:57]
is downloading the model after that you

[14:22:55 - 14:23:00]
will see that it will start the training

[14:22:57 - 14:23:01]
see it's downloading the model so see I

[14:23:00 - 14:23:03]
won't be waiting 30 minutes what I'll

[14:23:01 - 14:23:05]
show you uh the next process actually

[14:23:03 - 14:23:07]
you can follow like after training what

[14:23:05 - 14:23:08]
you can do because see I have written

[14:23:07 - 14:23:10]
all the code only you just need to

[14:23:08 - 14:23:12]
execute if you're doing it because uh

[14:23:10 - 14:23:14]
here I'm recording currently so I can't

[14:23:12 - 14:23:16]
wait actually 30 minutes um to train the

[14:23:14 - 14:23:18]
model let me show you what you can

[14:23:16 - 14:23:20]
perform here so after training the model

[14:23:18 - 14:23:22]
you have to save the model you can see

[14:23:20 - 14:23:24]
you have to save the model trainer model

[14:23:22 - 14:23:25]
save pretend then you have to give the

[14:23:24 - 14:23:27]
new model name I think new model name I

[14:23:25 - 14:23:29]
think you remember we have given a new

[14:23:27 - 14:23:30]
model name here whenever we Define the

[14:23:29 - 14:23:33]
all the

[14:23:30 - 14:23:34]
configuration um this is the new model

[14:23:33 - 14:23:36]
okay so it will save with the help of

[14:23:34 - 14:23:39]
this model fine so it will save the

[14:23:36 - 14:23:40]
model in the here in this dis actually

[14:23:39 - 14:23:42]
you'll see that it will create output

[14:23:40 - 14:23:44]
folder inside that it will save the

[14:23:42 - 14:23:46]
model then after that you can also

[14:23:44 - 14:23:48]
visualize the tensorboard logs see this

[14:23:46 - 14:23:50]
tensorboard will show you the losses

[14:23:48 - 14:23:51]
then the accuracy okay of your model

[14:23:50 - 14:23:53]
everything it actually it will show you

[14:23:51 - 14:23:55]
that that means the complete metrics it

[14:23:53 - 14:23:56]
will show you the training losses

[14:23:55 - 14:23:58]
validation losses everything it will

[14:23:56 - 14:24:00]
show here then after that what I was

[14:23:58 - 14:24:01]
doing I'm I was loading the original

[14:24:00 - 14:24:03]
model you can see I'm loading the

[14:24:01 - 14:24:05]
original model not the train model I

[14:24:03 - 14:24:06]
have train I'm loading the original of

[14:24:05 - 14:24:08]
the Lama model and then I'm testing with

[14:24:06 - 14:24:10]
a prompt what is large language model I

[14:24:08 - 14:24:12]
just wanted to see what would be the

[14:24:10 - 14:24:13]
output from my original large language

[14:24:12 - 14:24:15]
model because that means I want to

[14:24:13 - 14:24:16]
compar this result with my train model

[14:24:15 - 14:24:18]
the model I have trained right now okay

[14:24:16 - 14:24:20]
that's why I'm loading the base model

[14:24:18 - 14:24:22]
that means my original model and I'm I'm

[14:24:20 - 14:24:23]
only want to see the output okay so here

[14:24:22 - 14:24:25]
I've given a prompt what is the large

[14:24:23 - 14:24:27]
language model and this is the actually

[14:24:25 - 14:24:29]
output I got okay from my model then

[14:24:27 - 14:24:31]
after that what I did actually I deleted

[14:24:29 - 14:24:33]
all the model Pipeline and everything

[14:24:31 - 14:24:35]
just to uh empty my vram because in Ram

[14:24:33 - 14:24:37]
actually it will occupy lots of space so

[14:24:35 - 14:24:39]
you have to execute this code after

[14:24:37 - 14:24:40]
executing this line actually so no need

[14:24:39 - 14:24:43]
to execute this line of code just try to

[14:24:40 - 14:24:44]
skip as of now first of all execute this

[14:24:43 - 14:24:46]
line of code this line of code what it

[14:24:44 - 14:24:48]
will do it will try to load your base

[14:24:46 - 14:24:50]
model as well as your train model okay

[14:24:48 - 14:24:52]
that means new model then it will Mars

[14:24:50 - 14:24:53]
that means if you want to save the model

[14:24:52 - 14:24:54]
right now if you're using parameter

[14:24:53 - 14:24:56]
efficient finding first of all you have

[14:24:54 - 14:24:59]
to load your base model as well as your

[14:24:56 - 14:25:00]
new model okay both you have to load

[14:24:59 - 14:25:02]
then after that you have to Marge after

[14:25:00 - 14:25:04]
marging what you can do you can also

[14:25:02 - 14:25:06]
load your tokenizer then you can push

[14:25:04 - 14:25:08]
this model to the hugging pH H for this

[14:25:06 - 14:25:10]
just execute this line of code and you

[14:25:08 - 14:25:12]
have to perform the hugging pH C login

[14:25:10 - 14:25:14]
okay huging face AI login and it will

[14:25:12 - 14:25:15]
ask for one authentication token see

[14:25:14 - 14:25:18]
this is the token it will ask now what

[14:25:15 - 14:25:20]
you have to do go to the hugging face uh

[14:25:18 - 14:25:22]
go to the settings I think you know how

[14:25:20 - 14:25:25]
to generate the tokens go to the access

[14:25:22 - 14:25:27]
tokens now create a new tokens let's say

[14:25:25 - 14:25:29]
I'll give the token name is equal to

[14:25:27 - 14:25:31]
test and now you have to give the write

[14:25:29 - 14:25:32]
access because you want to write

[14:25:31 - 14:25:33]
something you want to push something to

[14:25:32 - 14:25:35]
the hugging face up that's say you have

[14:25:33 - 14:25:37]
to give the right access now create the

[14:25:35 - 14:25:39]
token let's create the token now copy

[14:25:37 - 14:25:41]
the token and pass the token inside that

[14:25:39 - 14:25:44]
inside that you have to pass the token

[14:25:41 - 14:25:45]
then give uh y then press enter after

[14:25:44 - 14:25:47]
that it will automatically authenticate

[14:25:45 - 14:25:49]
with your hugging face then it will be

[14:25:47 - 14:25:51]
pushing your model to the hugging face

[14:25:49 - 14:25:53]
itself now here you have to give your

[14:25:51 - 14:25:55]
user username see this is my my username

[14:25:53 - 14:25:57]
entb so make sure you are giving your

[14:25:55 - 14:25:59]
username here okay not my username

[14:25:57 - 14:26:01]
otherwise it won't be working okay so if

[14:25:59 - 14:26:02]
you execute this line of code it will uh

[14:26:01 - 14:26:04]
push your model as as well as the

[14:26:02 - 14:26:07]
tokenizer as well now after executing

[14:26:04 - 14:26:09]
this line of code go to the hugging face

[14:26:07 - 14:26:11]
click on the profile go to the let's say

[14:26:09 - 14:26:13]
your profile now you'll see that in the

[14:26:11 - 14:26:15]
model section this model would be

[14:26:13 - 14:26:16]
published okay and this is the model and

[14:26:15 - 14:26:18]
this is your tokenizer that means the

[14:26:16 - 14:26:19]
same model you have to use for the

[14:26:18 - 14:26:22]
tokenization as well I think I already

[14:26:19 - 14:26:23]
showed right now after that let's test

[14:26:22 - 14:26:25]
this model OKAY whether it is working or

[14:26:23 - 14:26:27]
not so for this I created another

[14:26:25 - 14:26:29]
notebook let me show you so this is The

[14:26:27 - 14:26:31]
Notebook I created guys fine tune model

[14:26:29 - 14:26:33]
test now again just try to install

[14:26:31 - 14:26:34]
Transformer accelerate that means all

[14:26:33 - 14:26:36]
the required packet then after that just

[14:26:34 - 14:26:37]
try to load your model right now the

[14:26:36 - 14:26:40]
model actually you have trained see this

[14:26:37 - 14:26:44]
model just try to copy the name and just

[14:26:40 - 14:26:45]
try to past it here okay then again I'm

[14:26:44 - 14:26:46]
giving the same from what is the large

[14:26:45 - 14:26:48]
language model I'm loading the tokenizer

[14:26:46 - 14:26:50]
first of all so inside this pipeline I'm

[14:26:48 - 14:26:52]
giving my model then after that you can

[14:26:50 - 14:26:54]
see I'm creating the complete pipeline

[14:26:52 - 14:26:55]
then it is predicting and it is giving

[14:26:54 - 14:26:57]
me the results now see this is the

[14:26:55 - 14:26:58]
results actually I'm getting see

[14:26:57 - 14:27:00]
although I have trained only one Epoch

[14:26:58 - 14:27:01]
but if you see the results it's not

[14:27:00 - 14:27:03]
actually bad uh somehow actually it has

[14:27:01 - 14:27:05]
given the good output then again I have

[14:27:03 - 14:27:07]
given another actually prompt now see

[14:27:05 - 14:27:09]
this is the results I'm executing my

[14:27:07 - 14:27:10]
model and this is the result actually

[14:27:09 - 14:27:13]
I'm getting so the prompt is actually

[14:27:10 - 14:27:15]
explain to me in a simple U simple to

[14:27:13 - 14:27:19]
understand way what is the equation of

[14:27:15 - 14:27:21]
finding the uh an triangle number is is

[14:27:19 - 14:27:23]
and how it can be provided by using the

[14:27:21 - 14:27:25]
high school level math please please

[14:27:23 - 14:27:27]
give each step of the of a proof of

[14:27:25 - 14:27:29]
using latex see this is the latex

[14:27:27 - 14:27:31]
actually output I'm getting that means

[14:27:29 - 14:27:32]
all the let's say mathematical equation

[14:27:31 - 14:27:35]
and everything it has given me as a

[14:27:32 - 14:27:36]
latex now you can convert this latex to

[14:27:35 - 14:27:38]
the mathematical format and you can see

[14:27:36 - 14:27:41]
that particular output okay so that's

[14:27:38 - 14:27:42]
how actually we can also test our model

[14:27:41 - 14:27:43]
and this is the entire process of fine

[14:27:42 - 14:27:45]
tuning guys entire process of fine

[14:27:43 - 14:27:46]
tuning and see still training is going

[14:27:45 - 14:27:48]
on you can see still training is going

[14:27:46 - 14:27:50]
on and it has created the result folder

[14:27:48 - 14:27:52]
and inside result inside runs it will

[14:27:50 - 14:27:54]
save the weights okay it will save the

[14:27:52 - 14:27:55]
weights that means the artifacts fine so

[14:27:54 - 14:27:57]
yes guys that's how actually you can

[14:27:55 - 14:27:59]
perform the F tuning operation with the

[14:27:57 - 14:28:01]
help of parameter efficient fine tuning

[14:27:59 - 14:28:04]
you can use either L either you can use

[14:28:01 - 14:28:06]
Q L fine so now what you have to do guys

[14:28:04 - 14:28:07]
just try to perform this fine tuning and

[14:28:06 - 14:28:09]
if you're having any error if you having

[14:28:07 - 14:28:11]
any issue you can let me know in the

[14:28:09 - 14:28:13]
comment I'll try to help you with that

[14:28:11 - 14:28:14]
okay to fix that particular eror now

[14:28:13 - 14:28:16]
apart from that just go to the hugging

[14:28:14 - 14:28:18]
face try to pick any other model guys go

[14:28:16 - 14:28:20]
to the hugging face and pick any other

[14:28:18 - 14:28:22]
model not this Lama 2 model you can also

[14:28:20 - 14:28:24]
take Lama 3 Model you can also take

[14:28:22 - 14:28:26]
let's say mral model Falcone model any

[14:28:24 - 14:28:29]
kinds of model you can take just go to

[14:28:26 - 14:28:30]
the model section just find a model and

[14:28:29 - 14:28:32]
try to perform the fine tuning process

[14:28:30 - 14:28:34]
okay you can use the same Tech technique

[14:28:32 - 14:28:36]
to perform the fine tuning process fine

[14:28:34 - 14:28:37]
so in future I'll create some more video

[14:28:36 - 14:28:39]
there actually I'll show you how we can

[14:28:37 - 14:28:41]
f tune any other model as well let's see

[14:28:39 - 14:28:43]
you want to F tune Jimma model how we

[14:28:41 - 14:28:44]
can do it and all okay we'll be creating

[14:28:43 - 14:28:47]
some more video but before that first of

[14:28:44 - 14:28:49]
all try to uh I mean explore by yourself

[14:28:47 - 14:28:51]
the way actually I showed you the entire

[14:28:49 - 14:28:52]
notebook I shared with you try to pick

[14:28:51 - 14:28:54]
up any kinds of model and try to follow

[14:28:52 - 14:28:56]
the same okay technique to perform the

[14:28:54 - 14:28:58]
fine tuning operation so L index is

[14:28:56 - 14:29:00]
nothing but it's an alternative

[14:28:58 - 14:29:02]
framework of Lang chin so Lama index

[14:29:00 - 14:29:04]
gives you the ability uh to build a very

[14:29:02 - 14:29:07]
powerful generative application with the

[14:29:04 - 14:29:09]
help of large language model so whatever

[14:29:07 - 14:29:11]
things actually we have learned with the

[14:29:09 - 14:29:13]
Lang chain like we saw like how we can

[14:29:11 - 14:29:15]
use Lang chain framework to build

[14:29:13 - 14:29:17]
generative application the same things

[14:29:15 - 14:29:19]
can be performed with the help of Lama

[14:29:17 - 14:29:22]
index as well so this Lama index and

[14:29:19 - 14:29:24]
Lang chain is like very popular in the

[14:29:22 - 14:29:27]
market nowadays so people are using Lama

[14:29:24 - 14:29:29]
index and Lang chain uh very broadly in

[14:29:27 - 14:29:30]
their gener application now it's up to

[14:29:29 - 14:29:32]
you like which framework actually you'll

[14:29:30 - 14:29:33]
be choosing whenever you are developing

[14:29:32 - 14:29:37]
any kinds of generative a application

[14:29:33 - 14:29:38]
right so we have learned like Lang chain

[14:29:37 - 14:29:40]
like how we can develop generative

[14:29:38 - 14:29:42]
application with the help of Lang chain

[14:29:40 - 14:29:44]
now it's time to also explore like this

[14:29:42 - 14:29:46]
lend x one so in this video actually I

[14:29:44 - 14:29:48]
will give you like how we can build

[14:29:46 - 14:29:50]
genbi application with the help of lam

[14:29:48 - 14:29:52]
andex so this is going to be uh one

[14:29:50 - 14:29:54]
amazing video alog together just try to

[14:29:52 - 14:29:56]
watch this video till the end and don't

[14:29:54 - 14:29:58]
skip any part of this video otherwise

[14:29:56 - 14:30:00]
you might get some issue and if you have

[14:29:58 - 14:30:02]
some query you can let me know in the

[14:30:00 - 14:30:04]
comment I will happy to help you so guys

[14:30:02 - 14:30:05]
let's start with our video so first of

[14:30:04 - 14:30:07]
all I will take you through the Lama

[14:30:05 - 14:30:10]
index documentation then I will start

[14:30:07 - 14:30:12]
with our project implementation so guys

[14:30:10 - 14:30:14]
this is the Lama index documentation and

[14:30:12 - 14:30:16]
uh Lama index is nothing but it's a

[14:30:14 - 14:30:17]
simple flexible data framework for

[14:30:16 - 14:30:19]
connecting custom data sources to the

[14:30:17 - 14:30:21]
large language model so basically Lama

[14:30:19 - 14:30:22]
index is nothing but it helps you to

[14:30:21 - 14:30:25]
build these kinds of generative

[14:30:22 - 14:30:26]
application with your custom data as

[14:30:25 - 14:30:28]
well as it will also give you the

[14:30:26 - 14:30:30]
ability to connect with these kinds of

[14:30:28 - 14:30:32]
large language model we have seen right

[14:30:30 - 14:30:34]
so it is the similar kinds of framework

[14:30:32 - 14:30:36]
of your langen so whatever functionality

[14:30:34 - 14:30:38]
langen provides your Lama index will

[14:30:36 - 14:30:39]
also provide that one but some of the

[14:30:38 - 14:30:41]
syntax would be a little bit different

[14:30:39 - 14:30:42]
okay so I will discuss this thing

[14:30:41 - 14:30:44]
whenever I will take you through the

[14:30:42 - 14:30:45]
project demo okay whenever I will be

[14:30:44 - 14:30:47]
building uh projects with the help of

[14:30:45 - 14:30:48]
lendx at that time I will show you like

[14:30:47 - 14:30:51]
where uh what is the syntax change

[14:30:48 - 14:30:52]
actually you need to consider now guys

[14:30:51 - 14:30:54]
uh you can go through the documentation

[14:30:52 - 14:30:56]
they have written everything okay so

[14:30:54 - 14:30:58]
here it is telling we can easily build

[14:30:56 - 14:31:00]
like lots of generative by application

[14:30:58 - 14:31:02]
with the help of this lendex uh even you

[14:31:00 - 14:31:04]
can connect uh with these kinds of

[14:31:02 - 14:31:05]
unstructured data structured data and

[14:31:04 - 14:31:08]
semi structured data so unstructured

[14:31:05 - 14:31:10]
data means uh text Data PDF data video

[14:31:08 - 14:31:11]
data and it can be also image data uh

[14:31:10 - 14:31:13]
structured data means you can also

[14:31:11 - 14:31:15]
connect with Excel data SQL data and so

[14:31:13 - 14:31:18]
on and semi structure data means like

[14:31:15 - 14:31:20]
you can also connect with the API then

[14:31:18 - 14:31:23]
you can also with this slack then

[14:31:20 - 14:31:25]
Salesforce notion so these kinds of I

[14:31:23 - 14:31:27]
mean platform you can also integrate to

[14:31:25 - 14:31:28]
collect the data with the help of this

[14:31:27 - 14:31:31]
lamb andex okay so this is one of the

[14:31:28 - 14:31:34]
very uh popular framework in the market

[14:31:31 - 14:31:36]
and it is like very powerful so you can

[14:31:34 - 14:31:38]
uh use this one also to build your gener

[14:31:36 - 14:31:41]
application so it's fine uh you if you

[14:31:38 - 14:31:42]
know like both framework like Lang chain

[14:31:41 - 14:31:44]
and Lama index so it will help you to

[14:31:42 - 14:31:47]
build like very powerful gener

[14:31:44 - 14:31:49]
application right so um I personally

[14:31:47 - 14:31:52]
like this Lama index a lot okay U I

[14:31:49 - 14:31:54]
usually use langin to build my gener

[14:31:52 - 14:31:56]
application but I also like this Lama

[14:31:54 - 14:31:58]
index sometimes I also use Lama index to

[14:31:56 - 14:32:00]
create my genbi application and guys uh

[14:31:58 - 14:32:01]
this is the documentation of this Lama

[14:32:00 - 14:32:04]
index so there actually they have given

[14:32:01 - 14:32:05]
then how to set up this lamb index and

[14:32:04 - 14:32:07]
what are the things actually it provides

[14:32:05 - 14:32:10]
see it has also this agents uh then

[14:32:07 - 14:32:12]
chatbot structured data extraction then

[14:32:10 - 14:32:14]
uh indexing everything like whatever you

[14:32:12 - 14:32:16]
have seen inside your Lang and

[14:32:14 - 14:32:17]
everything it has uh if you see here all

[14:32:16 - 14:32:19]
the things actually they are providing

[14:32:17 - 14:32:21]
so you can go with the documentation so

[14:32:19 - 14:32:23]
they have uh given each and everything

[14:32:21 - 14:32:25]
now I'll uh quickly show you uh like how

[14:32:23 - 14:32:27]
we can set up this lamb index on our

[14:32:25 - 14:32:29]
Google collab and how we can build like

[14:32:27 - 14:32:31]
one Basics gener projects with the help

[14:32:29 - 14:32:33]
of this lb index okay then it would be

[14:32:31 - 14:32:35]
very much clear for you so first of all

[14:32:33 - 14:32:39]
what I will do uh I will open my Google

[14:32:35 - 14:32:39]
collab so let me open my Google

[14:32:40 - 14:32:45]
collab so here I will create a new

[14:32:42 - 14:32:49]
notebook here you can give the name so

[14:32:45 - 14:32:49]
I'll just give uh Lama

[14:32:50 - 14:32:54]
index

[14:32:52 - 14:32:57]
demo and here make sure you have

[14:32:54 - 14:32:59]
selected runtime at GPU so let me select

[14:32:57 - 14:33:04]
runtime as

[14:32:59 - 14:33:04]
GPU and uh let me The

[14:33:05 - 14:33:10]
Notebook so uh in between what I can

[14:33:08 - 14:33:12]
give you I will give you the project

[14:33:10 - 14:33:14]
architecture like uh actually what I'm

[14:33:12 - 14:33:16]
going to do exactly with the help of

[14:33:14 - 14:33:19]
this L index so for this actually I'll

[14:33:16 - 14:33:21]
open my um Blackboard and here I already

[14:33:19 - 14:33:23]
kept this project uh architecture as you

[14:33:21 - 14:33:26]
can see so basically here we'll be

[14:33:23 - 14:33:29]
building one uh projects uh basically

[14:33:26 - 14:33:31]
here we'll have lots of like documents

[14:33:29 - 14:33:34]
so basically we'll be chatting with the

[14:33:31 - 14:33:34]
documents okay okay so chat

[14:33:36 - 14:33:39]
with

[14:33:39 - 14:33:44]
multiple multiple

[14:33:42 - 14:33:46]
documents okay so this is the project

[14:33:44 - 14:33:47]
name so it can be any kinds of documents

[14:33:46 - 14:33:52]
so it can be

[14:33:47 - 14:33:55]
PDF it can be let's say Doc it can be

[14:33:52 - 14:33:57]
txt okay it can be image anything you

[14:33:55 - 14:33:59]
can give so we'll be extracting the data

[14:33:57 - 14:34:01]
all together okay then we'll be chatting

[14:33:59 - 14:34:03]
with these kinds of documents so this is

[14:34:01 - 14:34:05]
nothing but our custom source okay so

[14:34:03 - 14:34:09]
this is nothing but our

[14:34:05 - 14:34:11]
Custom Custom data okay our custom data

[14:34:09 - 14:34:14]
source you can talk about okay and here

[14:34:11 - 14:34:16]
first of all what I need to do uh so

[14:34:14 - 14:34:18]
user will give me these kinds of like

[14:34:16 - 14:34:21]
data custom data so I need to extract

[14:34:18 - 14:34:24]
the data and U after extracting I also

[14:34:21 - 14:34:26]
need to convert them to chunks because I

[14:34:24 - 14:34:28]
already told you what is this chunks and

[14:34:26 - 14:34:31]
why we need it because here I'm going to

[14:34:28 - 14:34:33]
use large language model okay llm I I'm

[14:34:31 - 14:34:34]
going to use large language model so LM

[14:34:33 - 14:34:37]
wise I'll be using something called

[14:34:34 - 14:34:39]
Google Pam uh Google Pam 2 I already

[14:34:37 - 14:34:41]
discussed like Google Pam 2 and if you

[14:34:39 - 14:34:44]
already know Google Pam 2 has one

[14:34:41 - 14:34:49]
specific input size which is nothing but

[14:34:44 - 14:34:51]
8,90 8,096 tokens okay so uh if you're

[14:34:49 - 14:34:53]
extracting the data alog together so it

[14:34:51 - 14:34:56]
might be more than

[14:34:53 - 14:34:58]
8,96 token so that is why it's better to

[14:34:56 - 14:35:00]
create a chunks so instead of giving all

[14:34:58 - 14:35:02]
the Corpus together I will provide as a

[14:35:00 - 14:35:04]
chunks to chunks so that my input size

[14:35:02 - 14:35:06]
uh it can handle very easily right so

[14:35:04 - 14:35:07]
that why chunks is important so after

[14:35:06 - 14:35:09]
creating the chunks from my entire

[14:35:07 - 14:35:12]
Corpus I also need to convert this text

[14:35:09 - 14:35:15]
to text to Vector okay I'll be

[14:35:12 - 14:35:17]
converting text to Vector so for this

[14:35:15 - 14:35:18]
actually I'll be using some embedding

[14:35:17 - 14:35:21]
model so in this case actually I'm going

[14:35:18 - 14:35:24]
to use hugging face embedding model

[14:35:21 - 14:35:27]
hugging face uh hugging face embedding

[14:35:24 - 14:35:28]
model you can also use Pam to embedding

[14:35:27 - 14:35:30]
model it's completely fine I already

[14:35:28 - 14:35:31]
showed you how to use Pam to embedding

[14:35:30 - 14:35:35]
model you can also use hang embedding

[14:35:31 - 14:35:37]
model then uh after creating this uh

[14:35:35 - 14:35:40]
Vector store I also need to store these

[14:35:37 - 14:35:42]
are the vector okay in a knowledge base

[14:35:40 - 14:35:44]
so by default actually uh this lamb

[14:35:42 - 14:35:46]
index has one functionality so it will

[14:35:44 - 14:35:48]
create a knowledge base in your local I

[14:35:46 - 14:35:50]
will show you like how to created then

[14:35:48 - 14:35:52]
after that U we'll be handling the user

[14:35:50 - 14:35:53]
so user will raise some query so we'll

[14:35:52 - 14:35:55]
first of all convert that query to

[14:35:53 - 14:35:57]
querium buding then we'll be performing

[14:35:55 - 14:35:59]
something called CTIC search so it will

[14:35:57 - 14:36:01]
give me some rank results and we'll be

[14:35:59 - 14:36:03]
applying generative U model that means

[14:36:01 - 14:36:05]
large language model to get our actual

[14:36:03 - 14:36:07]
response okay so this is the complete

[14:36:05 - 14:36:09]
idea of our project uh architecture

[14:36:07 - 14:36:12]
right so now let's Implement with the

[14:36:09 - 14:36:13]
help of this uh lendex as of now we have

[14:36:12 - 14:36:16]
seen like how to implement with the Lang

[14:36:13 - 14:36:18]
chain we have seen like how we can uh

[14:36:16 - 14:36:20]
develop end to end uh Genera bi projects

[14:36:18 - 14:36:22]
with the help of Lang chain and Vector

[14:36:20 - 14:36:24]
database and so on right so same thing

[14:36:22 - 14:36:26]
you can do with the help of lamb index

[14:36:24 - 14:36:29]
you can also add your vector DB here you

[14:36:26 - 14:36:31]
can use pine cone you can use uh webat

[14:36:29 - 14:36:32]
you can also use chroma DB anything you

[14:36:31 - 14:36:34]
can use use but here I'm not going to

[14:36:32 - 14:36:36]
use any kinds of vector DB I'm going to

[14:36:34 - 14:36:39]
use default knowledge base providing

[14:36:36 - 14:36:41]
your uh lamb index okay so it will store

[14:36:39 - 14:36:43]
your vector in a local I'll show you

[14:36:41 - 14:36:45]
like how to do it okay you can also

[14:36:43 - 14:36:47]
connect with the vector DV so that can

[14:36:45 - 14:36:48]
be also done I already taken lots of

[14:36:47 - 14:36:51]
session on it so you can go ahead and

[14:36:48 - 14:36:54]
watch it so guys now let's uh see like

[14:36:51 - 14:36:57]
how we can set up this one so to set up

[14:36:54 - 14:36:59]
Lama index uh there is a python package

[14:36:57 - 14:37:02]
actually will get uh called L index okay

[14:36:59 - 14:37:06]
so just write P install

[14:37:02 - 14:37:10]
P install ipen

[14:37:06 - 14:37:12]
Q Lama index okay Lama hypen index so

[14:37:10 - 14:37:14]
this is the package name you need to

[14:37:12 - 14:37:16]
install if you visit their documentation

[14:37:14 - 14:37:18]
and if you visit their installation

[14:37:16 - 14:37:20]
guideline okay if you visit their

[14:37:18 - 14:37:24]
installation guideline see this is the L

[14:37:20 - 14:37:26]
index package they are using okay now I

[14:37:24 - 14:37:28]
also need to install something called uh

[14:37:26 - 14:37:32]
Pi PDF because here I I'm going to use

[14:37:28 - 14:37:35]
PDF data so let me install install Pi

[14:37:32 - 14:37:35]
PDF

[14:37:36 - 14:37:42]
Pi Pi PDF then I'm also going to install

[14:37:40 - 14:37:44]
something called uh doc to text because

[14:37:42 - 14:37:46]
I'm going to use also doc type data so

[14:37:44 - 14:37:50]
I'll just write P

[14:37:46 - 14:37:50]
install uh

[14:37:50 - 14:37:57]
doc docs to text

[14:37:53 - 14:37:57]
dxt okay this package I

[14:37:57 - 14:38:02]
need then uh I already told you I'll

[14:38:00 - 14:38:04]
will be using uh Google Pam to as my

[14:38:02 - 14:38:05]
large language model so for this

[14:38:04 - 14:38:07]
actually I need to install something

[14:38:05 - 14:38:12]
called Google generated VII so P

[14:38:07 - 14:38:12]
install uh

[14:38:12 - 14:38:17]
Google generative AI package okay now I

[14:38:16 - 14:38:19]
will be using something called hiding

[14:38:17 - 14:38:20]
face embedding so for this I need trans

[14:38:19 - 14:38:24]
uh Transformer so I'll install

[14:38:20 - 14:38:24]
Transformer so pep

[14:38:27 - 14:38:34]
install Transformers okay now let me

[14:38:30 - 14:38:34]
install them together e

[14:39:02 - 14:39:07]
uh so guys installation is done now uh

[14:39:05 - 14:39:11]
I'll import some of the libraries so let

[14:39:07 - 14:39:14]
me import so first of all I will import

[14:39:11 - 14:39:16]
something called uh uh simple directory

[14:39:14 - 14:39:19]
reader and my Vector restore from my

[14:39:16 - 14:39:21]
Lama index I'll tell you like whenever

[14:39:19 - 14:39:24]
uh I'll be using it

[14:39:21 - 14:39:26]
so this two uh function I need so this

[14:39:24 - 14:39:28]
two function actually I need called

[14:39:26 - 14:39:30]
Simple directory reader and my Vector

[14:39:28 - 14:39:31]
store index I'll tell you like whenever

[14:39:30 - 14:39:34]
I'll be using so what is the the use of

[14:39:31 - 14:39:37]
it then I also need something called uh

[14:39:34 - 14:39:40]
pal model so it is already available

[14:39:37 - 14:39:43]
inside lamb andex so as you can see L

[14:39:40 - 14:39:45]
index. llm spam and I'm importing this

[14:39:43 - 14:39:47]
pum and uh this is the similar things

[14:39:45 - 14:39:48]
actually with the Lang chain as well so

[14:39:47 - 14:39:51]
I think you remember we are also

[14:39:48 - 14:39:53]
importing pal 2 model from Lang chain so

[14:39:51 - 14:39:56]
from Lang chain. llms then I was also

[14:39:53 - 14:39:59]
importing this p p model right so if you

[14:39:56 - 14:40:01]
have already used Lang chain so uh using

[14:39:59 - 14:40:02]
this L index would be very much easy for

[14:40:01 - 14:40:05]
you because lots of functionality will

[14:40:02 - 14:40:07]
remain same uh will look like similar to

[14:40:05 - 14:40:09]
you so some of the functionality and

[14:40:07 - 14:40:11]
syntax might different but rest of the

[14:40:09 - 14:40:13]
things are I think similar okay what I

[14:40:11 - 14:40:17]
feel like then I also need something

[14:40:13 - 14:40:19]
called uh service context from lendex

[14:40:17 - 14:40:21]
I'll tell you like what is service

[14:40:19 - 14:40:24]
context then I also need something

[14:40:21 - 14:40:27]
called storage context and

[14:40:24 - 14:40:29]
this load index from Storage okay these

[14:40:27 - 14:40:31]
are the thing then I also need something

[14:40:29 - 14:40:34]
called operating system package

[14:40:31 - 14:40:37]
now let me import

[14:40:34 - 14:40:42]
them okay done now uh I will load my

[14:40:37 - 14:40:42]
data so here let me comment

[14:40:42 - 14:40:48]
out load data so to load the data first

[14:40:45 - 14:40:49]
of all here what I will do I will create

[14:40:48 - 14:40:52]
One Directory

[14:40:49 - 14:40:57]
so here I'll just write one command

[14:40:52 - 14:40:57]
mkd and I will name this directory as

[14:40:58 - 14:41:03]
data now if I refresh I think huh

[14:41:01 - 14:41:05]
directory has created now here I will

[14:41:03 - 14:41:08]
upload some of the uh data that means

[14:41:05 - 14:41:10]
documents so I can upload see I here I

[14:41:08 - 14:41:13]
have PDF as well and this docs data as

[14:41:10 - 14:41:15]
well so let's upload uh these docs first

[14:41:13 - 14:41:15]
of

[14:41:21 - 14:41:26]
all so this is the like L index

[14:41:24 - 14:41:28]
documentation as you can see so it is

[14:41:26 - 14:41:32]
present inside my docs file now here I

[14:41:28 - 14:41:36]
will also upload this uh this one yellow

[14:41:32 - 14:41:36]
okay yellow um

[14:41:38 - 14:41:43]
PDF so with the help of this simple

[14:41:41 - 14:41:45]
directory reader we can load everything

[14:41:43 - 14:41:48]
any kinds of file format you can load

[14:41:45 - 14:41:50]
okay so that is the power of this Lama

[14:41:48 - 14:41:52]
index but if you used I think Lang CH

[14:41:50 - 14:41:54]
you remember we used to use something

[14:41:52 - 14:41:56]
called PDF uh loader then txt loader

[14:41:54 - 14:41:58]
separate separate file but if you're

[14:41:56 - 14:42:00]
using L index so you can directly load

[14:41:58 - 14:42:02]
them together okay so these kinds of

[14:42:00 - 14:42:05]
some functionality with will might vary

[14:42:02 - 14:42:09]
and will uh look new to you so it's

[14:42:05 - 14:42:09]
completely fine but functionality are

[14:42:11 - 14:42:16]
same so guys let me show you like uh my

[14:42:14 - 14:42:19]
data once like what are the things I

[14:42:16 - 14:42:21]
have so in this L index docs I have some

[14:42:19 - 14:42:23]
content related Lama index like what is

[14:42:21 - 14:42:25]
Lama index and all okay so here is the

[14:42:23 - 14:42:28]
content I prepared and it is present

[14:42:25 - 14:42:30]
inside this documents then uh in the PDF

[14:42:28 - 14:42:33]
actually you can see this is yellow

[14:42:30 - 14:42:35]
related PDF so what is yolow and yolow

[14:42:33 - 14:42:37]
architecture so these are the content

[14:42:35 - 14:42:39]
are available so you can ask any kinds

[14:42:37 - 14:42:41]
of query any kinds of question from this

[14:42:39 - 14:42:43]
documents okay you have submitted so

[14:42:41 - 14:42:45]
we'll be uh doing that with the help of

[14:42:43 - 14:42:48]
this uh uh large language model and with

[14:42:45 - 14:42:50]
the help of this uh lamb index okay uh

[14:42:48 - 14:42:52]
so guys as you can see uh my data has

[14:42:50 - 14:42:54]
been uploaded now what I can do I'll

[14:42:52 - 14:42:56]
first of all load the data so I'll

[14:42:54 - 14:42:58]
extract the content uh from these

[14:42:56 - 14:43:00]
documents and PDF so for this I'll be

[14:42:58 - 14:43:02]
using something called uh this simple

[14:43:00 - 14:43:04]
directory reader

[14:43:02 - 14:43:06]
so I'll call it and inside that you just

[14:43:04 - 14:43:08]
need to provide the directory so this is

[14:43:06 - 14:43:11]
the data directory inside that I have

[14:43:08 - 14:43:14]
this data and here is one function

[14:43:11 - 14:43:17]
called uh load uncore data you need to

[14:43:14 - 14:43:19]
call and I will store it inside a

[14:43:17 - 14:43:19]
variable called

[14:43:20 - 14:43:28]
documents okay now let me load

[14:43:24 - 14:43:31]
them yeah now if you want to see the

[14:43:28 - 14:43:34]
data so this is the data it has

[14:43:31 - 14:43:36]
extracted okay and this is in document

[14:43:34 - 14:43:38]
format as you can see okay and it will

[14:43:36 - 14:43:40]
also give you the reference ID and if

[14:43:38 - 14:43:41]
you're using any embedding or not so

[14:43:40 - 14:43:43]
it's none by default because we haven't

[14:43:41 - 14:43:46]
used any embedding and this is the

[14:43:43 - 14:43:49]
content it has extracted okay now what I

[14:43:46 - 14:43:51]
need to do guys U we have successfully

[14:43:49 - 14:43:53]
extracted the data now I need to perform

[14:43:51 - 14:43:55]
something called chunking operation on

[14:43:53 - 14:43:57]
top of it because this is my entire

[14:43:55 - 14:43:59]
carpus and I also need to convert them

[14:43:57 - 14:44:02]
to chunks so for this let me just first

[14:43:59 - 14:44:04]
of all comment

[14:44:02 - 14:44:07]
so we'll be performing split text into

[14:44:04 - 14:44:10]
small chunks so uh before that first of

[14:44:07 - 14:44:14]
all I need to set my

[14:44:10 - 14:44:16]
uh Google API key Okay Google AP API key

[14:44:14 - 14:44:18]
I need to set so the uh using this

[14:44:16 - 14:44:21]
Google API key we'll be able to access

[14:44:18 - 14:44:24]
our P palom model OKAY from this uh

[14:44:21 - 14:44:26]
Google palom API so if you open this uh

[14:44:24 - 14:44:28]
Google palom website so here they're

[14:44:26 - 14:44:30]
telling just try to create one API I

[14:44:28 - 14:44:32]
already showed you how to create the API

[14:44:30 - 14:44:34]
just click on this pal API and here you

[14:44:32 - 14:44:37]
just need to get your API

[14:44:34 - 14:44:39]
key and here you can generate a new key

[14:44:37 - 14:44:41]
okay so for me I already created one key

[14:44:39 - 14:44:42]
so this is my key I already created so

[14:44:41 - 14:44:45]
if you don't have any key you can create

[14:44:42 - 14:44:46]
from here so guys I already created the

[14:44:45 - 14:44:48]
key so this is my key and don't share

[14:44:46 - 14:44:49]
this key with anyone I will remove it

[14:44:48 - 14:44:51]
after the recording so that is why I'm

[14:44:49 - 14:44:53]
showing now let me set this key as my

[14:44:51 - 14:44:56]
environment

[14:44:53 - 14:44:57]
variable done then I need to initialize

[14:44:56 - 14:44:59]
my llm so

[14:44:57 - 14:45:02]
llm wise I am using something called

[14:44:59 - 14:45:02]
this PM model

[14:45:03 - 14:45:09]
so it will automatically uh authenticate

[14:45:05 - 14:45:10]
using this uh API key okay so pal is not

[14:45:09 - 14:45:13]
initialized

[14:45:10 - 14:45:18]
please Google generi uh I think we have

[14:45:13 - 14:45:18]
already installed this package why it is

[14:45:20 - 14:45:24]
giving okay let me install

[14:45:27 - 14:45:34]
it okay I need to restart the run time

[14:45:30 - 14:45:36]
so that is why why I think it was not

[14:45:34 - 14:45:40]
working so guys we have restarted the

[14:45:36 - 14:45:40]
run time now let me import them

[14:45:43 - 14:45:49]
again H now I think my documents is

[14:45:47 - 14:45:52]
already there uh okay so I need to again

[14:45:49 - 14:45:53]
load the

[14:45:52 - 14:45:57]
documents

[14:45:53 - 14:46:02]
now this is my data now I'll set this

[14:45:57 - 14:46:02]
IPI key now I load my pom model

[14:46:04 - 14:46:09]
okay it's loaded now uh see guys uh

[14:46:07 - 14:46:12]
initially whenever I was using uh Lang

[14:46:09 - 14:46:13]
chain so we used to create this chunks

[14:46:12 - 14:46:15]
in a different way we used to use

[14:46:13 - 14:46:17]
something called text uh uh character

[14:46:15 - 14:46:20]
splitter uh function to create this

[14:46:17 - 14:46:22]
chunks but here uh this uh things is

[14:46:20 - 14:46:23]
little bit different so here you need to

[14:46:22 - 14:46:26]
use something called this service

[14:46:23 - 14:46:29]
context okay so here is a service

[14:46:26 - 14:46:32]
context uh function you need to use this

[14:46:29 - 14:46:35]
function so here you just need to

[14:46:32 - 14:46:38]
initialize it so it h it has one method

[14:46:35 - 14:46:41]
called U

[14:46:38 - 14:46:44]
prom uh from documents so from no sorry

[14:46:41 - 14:46:47]
from default so from

[14:46:44 - 14:46:50]
default from defaults and here you just

[14:46:47 - 14:46:55]
need to pass uh the llm at the very

[14:46:50 - 14:46:55]
first so llm wise so Palm is my

[14:46:55 - 14:47:01]
llm then uh I also need to give the

[14:46:58 - 14:47:04]
Chang size

[14:47:01 - 14:47:08]
chunk _ size I think you already know

[14:47:04 - 14:47:11]
what is chunk size so it will uh like uh

[14:47:08 - 14:47:13]
split your data with respect to that and

[14:47:11 - 14:47:15]
I also need to define something called

[14:47:13 - 14:47:19]
chunk uh

[14:47:15 - 14:47:23]
overlap overlap okay

[14:47:19 - 14:47:25]
so overlap so let's give 20 so chunks

[14:47:23 - 14:47:28]
overlap helps us to understand the

[14:47:25 - 14:47:30]
context of my entire Corpus because it

[14:47:28 - 14:47:31]
will convert to chunks and to get your

[14:47:30 - 14:47:33]
previous context I need the chunks

[14:47:31 - 14:47:35]
overlap I already explained this thing

[14:47:33 - 14:47:37]
in my Vector database session now here

[14:47:35 - 14:47:39]
you can also give like embedding which

[14:47:37 - 14:47:41]
embedding you want to use and if you're

[14:47:39 - 14:47:42]
not giving anything so by default it

[14:47:41 - 14:47:45]
will use that hugging face embedding

[14:47:42 - 14:47:48]
I'll show you so

[14:47:45 - 14:47:48]
Service uh

[14:47:49 - 14:47:55]
context uh this is my service context I

[14:47:52 - 14:47:59]
got now if I execute this code you will

[14:47:55 - 14:48:03]
see uh it will first of all uh okay it's

[14:47:59 - 14:48:05]
giving one error no API key found for

[14:48:03 - 14:48:09]
open uh okay it's giving the error

[14:48:05 - 14:48:12]
because I need to again install this uh

[14:48:09 - 14:48:16]
Transformer I think so let

[14:48:12 - 14:48:16]
me let me install the

[14:48:28 - 14:48:32]
Transformers uh so guys as you can see

[14:48:30 - 14:48:35]
it's giving one error it's telling uh no

[14:48:32 - 14:48:37]
API key found for open a so here by

[14:48:35 - 14:48:39]
default if you're not giving any

[14:48:37 - 14:48:41]
embeding model so it will try to take

[14:48:39 - 14:48:43]
the open a embedding model but here in

[14:48:41 - 14:48:44]
this case we haven't provided any op

[14:48:43 - 14:48:47]
open a API key so that's why it's

[14:48:44 - 14:48:48]
throwing error so if you visit this URL

[14:48:47 - 14:48:50]
so they're telling if you want to use

[14:48:48 - 14:48:52]
some other embedding so you need to

[14:48:50 - 14:48:53]
first of all import it so let me import

[14:48:52 - 14:48:56]
this hanging embedding so I told you

[14:48:53 - 14:48:58]
I'll be using hang EMB bding so first of

[14:48:56 - 14:49:01]
all let me import this hang EMB Bing

[14:48:58 - 14:49:02]
here you can also use Google Pam

[14:49:01 - 14:49:04]
embedding the way I showed you in my

[14:49:02 - 14:49:06]
previous project you can do it but let's

[14:49:04 - 14:49:10]
use the sface embedding now I need to

[14:49:06 - 14:49:14]
create one object called embed

[14:49:10 - 14:49:17]
model so here I can create now here I'll

[14:49:14 - 14:49:18]
be using this model uh this is the model

[14:49:17 - 14:49:20]
available in the Hing face this is the

[14:49:18 - 14:49:20]
embedding

[14:49:22 - 14:49:27]
model so I need to install something

[14:49:24 - 14:49:30]
called s sentence transformer for this

[14:49:27 - 14:49:33]
so this is the command

[14:49:30 - 14:49:33]
let me install it

[14:49:44 - 14:49:49]
here done now let me import

[14:49:56 - 14:50:00]
it now guys see first of all it will

[14:49:58 - 14:50:04]
download that embedding model from Hing

[14:50:00 - 14:50:04]
fist this then it will load

[14:50:06 - 14:50:10]
that so done now I need to give one

[14:50:09 - 14:50:13]
parameter here called embed model is

[14:50:10 - 14:50:13]
equal to embed

[14:50:19 - 14:50:26]
model now let me execute

[14:50:22 - 14:50:30]
it h so my service context is prepared

[14:50:26 - 14:50:32]
right now now what I will do now what I

[14:50:30 - 14:50:34]
need to do I need to convert my

[14:50:32 - 14:50:35]
documents to chunks and that chunks I

[14:50:34 - 14:50:37]
need to convert to something called

[14:50:35 - 14:50:41]
Vector embedding okay so for this uh you

[14:50:37 - 14:50:43]
need to use something called uh uh

[14:50:41 - 14:50:44]
vectory store okay so vectory store I

[14:50:43 - 14:50:48]
think we have already imported this

[14:50:44 - 14:50:51]
thing above so this is the vector store

[14:50:48 - 14:50:54]
index so this uh class will help me to

[14:50:51 - 14:50:57]
do that so let me import it here and it

[14:50:54 - 14:50:59]
has one function called from documents

[14:50:57 - 14:51:01]
okay so here you just need to give you a

[14:50:59 - 14:51:03]
document

[14:51:01 - 14:51:05]
so in this case I have my documents here

[14:51:03 - 14:51:08]
I think you remember so this is my

[14:51:05 - 14:51:08]
documents this is my entire

[14:51:10 - 14:51:15]
Corpus then I also need to give my

[14:51:12 - 14:51:18]
service context

[14:51:15 - 14:51:19]
so service context equal to my service

[14:51:18 - 14:51:21]
context this is the service context so

[14:51:19 - 14:51:23]
it will take the model and everything

[14:51:21 - 14:51:25]
from here and all the configure I have

[14:51:23 - 14:51:28]
set here Str SI chks overl everything I

[14:51:25 - 14:51:30]
have given here now I will get my

[14:51:28 - 14:51:32]
something called index here so in Lama

[14:51:30 - 14:51:35]
index uh the vector you get we call them

[14:51:32 - 14:51:38]
index okay so this is my index now let

[14:51:35 - 14:51:38]
me uh convert

[14:51:43 - 14:51:47]
them so it is taking some time because

[14:51:45 - 14:51:49]
it is taking all the documents and

[14:51:47 - 14:51:51]
converting to chunks and converting to

[14:51:49 - 14:51:53]
vectors okay now we have successfully

[14:51:51 - 14:51:54]
converted them now I need to store them

[14:51:53 - 14:51:59]
in my

[14:51:54 - 14:52:01]
local so let me comment it here so to

[14:51:59 - 14:52:03]
store it first of all call this object

[14:52:01 - 14:52:05]
called index and there is a uh method

[14:52:03 - 14:52:08]
called

[14:52:05 - 14:52:15]
storage Storage

[14:52:08 - 14:52:15]
storage uh storage uh context dot

[14:52:17 - 14:52:21]
persist persist okay now if I execute

[14:52:19 - 14:52:24]
this one you will see it will save

[14:52:21 - 14:52:26]
everything as your local okay so there

[14:52:24 - 14:52:28]
is a uh folder it will create called

[14:52:26 - 14:52:31]
stor is inside that see all the vector

[14:52:28 - 14:52:33]
it has saved okay now we can open it

[14:52:31 - 14:52:36]
anything you can see

[14:52:33 - 14:52:39]
that okay see this is

[14:52:36 - 14:52:41]
the uh data it has

[14:52:39 - 14:52:44]
saved so it it follows one particular

[14:52:41 - 14:52:47]
format to save your documents

[14:52:44 - 14:52:49]
so it might not understandable to you

[14:52:47 - 14:52:50]
but this is my see this is my Vector

[14:52:49 - 14:52:53]
okay this is my final Vector of my

[14:52:50 - 14:52:55]
entire data now guys we have

[14:52:53 - 14:52:58]
successfully stored our indexes now

[14:52:55 - 14:53:01]
let's see if you have some existing

[14:52:58 - 14:53:02]
stories or existing index already so

[14:53:01 - 14:53:04]
instead of creating them you can

[14:53:02 - 14:53:07]
directly load it so this is the

[14:53:04 - 14:53:10]
code so this is the code load the index

[14:53:07 - 14:53:11]
so here you need to call Storage context

[14:53:10 - 14:53:14]
I think you remember we imported this

[14:53:11 - 14:53:16]
thing storage context so using storage

[14:53:14 - 14:53:18]
context there is a method called from

[14:53:16 - 14:53:19]
default and here you just need to give

[14:53:18 - 14:53:22]
the purchase directory which is nothing

[14:53:19 - 14:53:23]
by storage and it will load that and to

[14:53:22 - 14:53:26]
load it you need to use load index from

[14:53:23 - 14:53:28]
Storage okay we imported I think I you

[14:53:26 - 14:53:30]
remember load index from stories then it

[14:53:28 - 14:53:32]
will load that index for you okay it

[14:53:30 - 14:53:34]
will load that index for you so you can

[14:53:32 - 14:53:35]
execute this code okay I already created

[14:53:34 - 14:53:38]
my index object that's why I will

[14:53:35 - 14:53:40]
comment it out okay I'll comment it out

[14:53:38 - 14:53:43]
you can uh if you have already so you

[14:53:40 - 14:53:45]
can load it out and here you can also

[14:53:43 - 14:53:48]
use uh like vector DB to store these

[14:53:45 - 14:53:50]
other data to your uh Vector DB as well

[14:53:48 - 14:53:52]
okay this is also possible but LX

[14:53:50 - 14:53:54]
provide this functionality so that's why

[14:53:52 - 14:53:56]
I I'm showing this functionality to you

[14:53:54 - 14:53:59]
okay how to store them in a uh local

[14:53:56 - 14:54:02]
machine now we can perform our keyway

[14:53:59 - 14:54:02]
operation keyn operation

[14:54:03 - 14:54:09]
so let's do q q operation so here uh

[14:54:07 - 14:54:13]
first of all you need to Define one quy

[14:54:09 - 14:54:19]
engine so this is my

[14:54:13 - 14:54:22]
index so it has one uh parameter as quy

[14:54:19 - 14:54:27]
asore quy

[14:54:22 - 14:54:27]
engine and this is my query engine

[14:54:34 - 14:54:39]
now uh I'll call my query

[14:54:37 - 14:54:41]
engine and here I will ask the query so

[14:54:39 - 14:54:43]
this is my

[14:54:41 - 14:54:44]
query so here first of all I will ask

[14:54:43 - 14:54:47]
like what

[14:54:44 - 14:54:49]
is lamb andex because I have one lendex

[14:54:47 - 14:54:53]
related documentation here right so that

[14:54:49 - 14:54:53]
why I'll ask what is LAM

[14:54:54 - 14:54:58]
andex and it will give you the

[14:54:58 - 14:55:03]
response and as response I will print it

[14:55:08 - 14:55:14]
here uh so guys this is my response uh

[14:55:11 - 14:55:16]
again it's not understandable so if you

[14:55:14 - 14:55:19]
want to extract the actual uh response

[14:55:16 - 14:55:23]
if you want to see the actual text so

[14:55:19 - 14:55:25]
for this uh you can use this uh package

[14:55:23 - 14:55:27]
because we are using Google collapse so

[14:55:25 - 14:55:29]
there is a package called I IPython

[14:55:27 - 14:55:31]
display markdown and display so these

[14:55:29 - 14:55:32]
two package I'll will be

[14:55:31 - 14:55:35]
uh

[14:55:32 - 14:55:38]
importing then I'll be using something

[14:55:35 - 14:55:38]
called display.

[14:55:39 - 14:55:42]
markdown and here I will give my

[14:55:41 - 14:55:45]
response okay the response I'm getting

[14:55:42 - 14:55:47]
now if I execute it so it should me uh

[14:55:45 - 14:55:49]
so it should give me the response Lama

[14:55:47 - 14:55:50]
index is a data framework for building

[14:55:49 - 14:55:52]
application it provides a comprehensive

[14:55:50 - 14:55:54]
toolkit for integration management and

[14:55:52 - 14:55:57]
query of your external data so that you

[14:55:54 - 14:55:59]
can use with your llm app great now you

[14:55:57 - 14:56:01]
can ask any other query so let's say I

[14:55:59 - 14:56:06]
have one YOLO documentation so I can ask

[14:56:01 - 14:56:06]
anything about yolow so what is

[14:56:08 - 14:56:16]
yolow now if I execute again see Yow is

[14:56:13 - 14:56:17]
a regression algorithm uh it takes image

[14:56:16 - 14:56:20]
input and output building bounding boxes

[14:56:17 - 14:56:23]
and level uh images okay great now uh

[14:56:20 - 14:56:24]
let's see if I'm asking anything uh out

[14:56:23 - 14:56:26]
of this context out of this data so

[14:56:24 - 14:56:32]
let's see what happens so I'll ask

[14:56:26 - 14:56:32]
uh uh who is uh

[14:56:32 - 14:56:36]
B let's say I will ask this

[14:56:42 - 14:56:47]
question see it's telling B is a random

[14:56:45 - 14:56:49]
name and it's not mentioned in the

[14:56:47 - 14:56:51]
context so basically uh we have created

[14:56:49 - 14:56:54]
this projects and basically it is only

[14:56:51 - 14:56:56]
relying Upon Our Uh custom data we have

[14:56:54 - 14:56:58]
given okay apart from that if you asking

[14:56:56 - 14:57:00]
anything so it w be giving the answer so

[14:56:58 - 14:57:02]
you can ask anything uh

[14:57:00 - 14:57:05]
like related your documents so in this

[14:57:02 - 14:57:07]
case you can use this question anything

[14:57:05 - 14:57:08]
you can ask like whatever question

[14:57:07 - 14:57:11]
actually you have so it will give you

[14:57:08 - 14:57:14]
the answer with respect to

[14:57:11 - 14:57:17]
that yeah and uh this project actually

[14:57:14 - 14:57:18]
you can uh convert to uh stream lit app

[14:57:17 - 14:57:20]
I already showed you how to convert them

[14:57:18 - 14:57:22]
to streamlit app and all so you can try

[14:57:20 - 14:57:23]
this thing from your site okay I think

[14:57:22 - 14:57:26]
you can do it so yes guys this was all

[14:57:23 - 14:57:28]
about lendex I hope you get get it like

[14:57:26 - 14:57:30]
uh how we can use this lendex as our

[14:57:28 - 14:57:33]
alternative framework of our Lang chin

[14:57:30 - 14:57:35]
and this is one of like good framework I

[14:57:33 - 14:57:36]
can say so uh you can visit the

[14:57:35 - 14:57:38]
documentation and you can learn so many

[14:57:36 - 14:57:40]
things about lendex okay now try to

[14:57:38 - 14:57:41]
explore from your site so you'll be

[14:57:40 - 14:57:43]
getting each and everything I think you

[14:57:41 - 14:57:44]
already know about Lama index I already

[14:57:43 - 14:57:46]
explained what is the Lama index Lama

[14:57:44 - 14:57:48]
index is nothing but it's a alternative

[14:57:46 - 14:57:50]
framework of langen that means whatever

[14:57:48 - 14:57:52]
let's say things you can perform with

[14:57:50 - 14:57:54]
the langin the same thing you can also

[14:57:52 - 14:57:56]
perform with the Lama index so both are

[14:57:54 - 14:57:58]
actually Genera VI framework with the

[14:57:56 - 14:58:00]
help of that you can create Genera VI

[14:57:58 - 14:58:03]
based application so in our PR video we

[14:58:00 - 14:58:04]
saw like the entire introduction of the

[14:58:03 - 14:58:06]
Lama index so there actually we already

[14:58:04 - 14:58:08]
performed one practical example so in

[14:58:06 - 14:58:10]
this video I'll show you how we can use

[14:58:08 - 14:58:12]
open source large language model with

[14:58:10 - 14:58:13]
the help of L index so as an open source

[14:58:12 - 14:58:14]
model wise I'll be using something

[14:58:13 - 14:58:16]
called Mistral okay so if you don't know

[14:58:14 - 14:58:17]
Mistral is an open source actually large

[14:58:16 - 14:58:20]
language model and it is available

[14:58:17 - 14:58:22]
inside hugging face now if you search

[14:58:20 - 14:58:23]
here let's say mral if I search here see

[14:58:22 - 14:58:25]
mral is having actually different

[14:58:23 - 14:58:28]
different model let me show you so let

[14:58:25 - 14:58:31]
me go to the mral AI see it is having

[14:58:28 - 14:58:32]
actually 17 different model so expand

[14:58:31 - 14:58:35]
all the 17 different models see Mr is

[14:58:32 - 14:58:37]
having 7B model that means this is the 7

[14:58:35 - 14:58:38]
billion model 22 billion model okay

[14:58:37 - 14:58:41]
that's actually it is having different

[14:58:38 - 14:58:43]
different model so from this model guys

[14:58:41 - 14:58:46]
I'm going to use one model called Mr sa

[14:58:43 - 14:58:48]
me instruct V 01 so this model actually

[14:58:46 - 14:58:49]
will'll be using with the Lama index so

[14:58:48 - 14:58:51]
this model we be downloading from the

[14:58:49 - 14:58:53]
hugging face Hub and we'll be using with

[14:58:51 - 14:58:55]
the help of Lama index okay so here I'm

[14:58:53 - 14:58:57]
going to create a simple system so let

[14:58:55 - 14:58:59]
me show you the diagram what I'm going

[14:58:57 - 14:59:02]
to perform here see here uh I will

[14:58:59 - 14:59:06]
upload one actually PDF

[14:59:02 - 14:59:08]
document then I will extract the data

[14:59:06 - 14:59:11]
extract the documents

[14:59:08 - 14:59:11]
extract

[14:59:12 - 14:59:18]
docs after

[14:59:14 - 14:59:20]
that I'll perform chunking

[14:59:18 - 14:59:22]
operation I think you know what is

[14:59:20 - 14:59:23]
chunking okay and why it is required

[14:59:22 - 14:59:25]
then I'll be using my embedding model

[14:59:23 - 14:59:27]
here I'll be using one open source

[14:59:25 - 14:59:30]
embedding model fine embedding

[14:59:27 - 14:59:32]
model to generate the vector

[14:59:30 - 14:59:33]
embedding so it will give me something

[14:59:32 - 14:59:36]
called Vector

[14:59:33 - 14:59:38]
embedding and this Vector embedding I'll

[14:59:36 - 14:59:40]
be saving to a knowledge base that means

[14:59:38 - 14:59:41]
Vector database and if you're using Lama

[14:59:40 - 14:59:44]
index guys I think you already know Lama

[14:59:41 - 14:59:47]
index has one vector database service so

[14:59:44 - 14:59:50]
we can call it as Vector

[14:59:47 - 14:59:53]
store okay Vector store so inside Vector

[14:59:50 - 14:59:55]
restore we can uh save our uh embedding

[14:59:53 - 14:59:58]
so whatever M actually we'll be

[14:59:55 - 15:00:01]
generating and we'll be using llama

[14:59:58 - 15:00:04]
index okay llama index vectory

[15:00:01 - 15:00:06]
store okay L mind is vectory store and

[15:00:04 - 15:00:09]
this is going to be my knowledge base

[15:00:06 - 15:00:12]
then after that uh user will ask one

[15:00:09 - 15:00:15]
query let's this is the

[15:00:12 - 15:00:18]
user user will uh send one

[15:00:15 - 15:00:20]
query to the knowledge base and

[15:00:18 - 15:00:22]
knowledge base will return return some

[15:00:20 - 15:00:23]
relevant answer okay it will give give

[15:00:22 - 15:00:26]
you some rank

[15:00:23 - 15:00:28]
results rank

[15:00:26 - 15:00:31]
results then what I have to do I have to

[15:00:28 - 15:00:33]
use one large language model llm so here

[15:00:31 - 15:00:37]
we'll be using something called

[15:00:33 - 15:00:38]
Mistral okay Mistral so we'll pass this

[15:00:37 - 15:00:40]
rank results to this large language

[15:00:38 - 15:00:42]
model as well as this quy as well so

[15:00:40 - 15:00:44]
this quy and this rank results will

[15:00:42 - 15:00:46]
process your large language model and it

[15:00:44 - 15:00:49]
will give you the actual response okay

[15:00:46 - 15:00:49]
it will give you the

[15:00:50 - 15:00:54]
response so this is the system actually

[15:00:52 - 15:00:56]
will be implementing fine with help of

[15:00:54 - 15:00:58]
Lama index as well as the open source

[15:00:56 - 15:00:59]
large language model because this system

[15:00:58 - 15:01:01]
we already saw how we can Implement with

[15:00:59 - 15:01:03]
the help of langin now let's try to see

[15:01:01 - 15:01:06]
how we can use the Lama index as well so

[15:01:03 - 15:01:08]
let's get back so here I already created

[15:01:06 - 15:01:09]
one notebook guys you can see mral with

[15:01:08 - 15:01:11]
Lama index so first of all let's connect

[15:01:09 - 15:01:13]
this notebook so resources would be

[15:01:11 - 15:01:15]
shared in the description section so

[15:01:13 - 15:01:17]
from there you can download and you can

[15:01:15 - 15:01:19]
um execute all the code so it is

[15:01:17 - 15:01:21]
connected now let me check the GPU which

[15:01:19 - 15:01:23]
GPU actually I got here so I'm using

[15:01:21 - 15:01:25]
collab Pro guys so that's why I'm using

[15:01:23 - 15:01:28]
a 100 GPU so if I go to the run time

[15:01:25 - 15:01:30]
change run time type c I'm having a 100

[15:01:28 - 15:01:31]
GPU so if you're using cab Pro so you

[15:01:30 - 15:01:34]
can access this GPU otherwise you can

[15:01:31 - 15:01:35]
select T4 GPU okay it's completely fine

[15:01:34 - 15:01:37]
now let's install the pi PDF because I

[15:01:35 - 15:01:39]
already told you I'm going to use PDF

[15:01:37 - 15:01:41]
data here and I have to upload one PDF

[15:01:39 - 15:01:43]
documents here okay but before that let

[15:01:41 - 15:01:45]
me complete the installation then I'm

[15:01:43 - 15:01:47]
going to install the Transformer then

[15:01:45 - 15:01:49]
I'm also going to install some required

[15:01:47 - 15:01:51]
uh package for for the Transformer okay

[15:01:49 - 15:01:53]
so let me install everything why

[15:01:51 - 15:01:54]
Transformer because I want to access

[15:01:53 - 15:01:57]
this Mr model and this model is

[15:01:54 - 15:01:58]
available in the hugging ph up and then

[15:01:57 - 15:01:59]
I need to install something called

[15:01:58 - 15:02:01]
sentence Transformer why because I

[15:01:59 - 15:02:03]
already told you we'll be using open

[15:02:01 - 15:02:04]
source embedding model and for this I

[15:02:03 - 15:02:07]
need this sentence Transformer so let me

[15:02:04 - 15:02:09]
install this as well now I'm going to

[15:02:07 - 15:02:11]
install the Llama index so I'm

[15:02:09 - 15:02:12]
installing one specific version uh why

[15:02:11 - 15:02:14]
specific version because I already told

[15:02:12 - 15:02:16]
you if you're installing any specific

[15:02:14 - 15:02:18]
version uh that will help you a lot in

[15:02:16 - 15:02:20]
future because uh let's say today you

[15:02:18 - 15:02:23]
have created one projects with uh the

[15:02:20 - 15:02:24]
latest llama index what will happen

[15:02:23 - 15:02:26]
after some days actually they will

[15:02:24 - 15:02:28]
upgrate their package and again you will

[15:02:26 - 15:02:29]
get issue right so that's why it's

[15:02:28 - 15:02:32]
always better practice to use when

[15:02:29 - 15:02:33]
specific version fine now let me import

[15:02:32 - 15:02:35]
all the required Library so you can see

[15:02:33 - 15:02:37]
I'm importing from Lama index Vector

[15:02:35 - 15:02:38]
store index simple directory Reader

[15:02:37 - 15:02:41]
Service context okay then hugging face

[15:02:38 - 15:02:42]
llm then simple input from so this is

[15:02:41 - 15:02:45]
the vector restore guys that means this

[15:02:42 - 15:02:47]
is the vector database Service uh Lama

[15:02:45 - 15:02:48]
index provides so uh here actually we

[15:02:47 - 15:02:49]
can create a knowledge base and we can

[15:02:48 - 15:02:51]
instore our embedding and this is the

[15:02:49 - 15:02:53]
local uh local DB okay it will save

[15:02:51 - 15:02:54]
everything in local then simple

[15:02:53 - 15:02:55]
directory reader will help you to read

[15:02:54 - 15:02:57]
your content that means whatever data

[15:02:55 - 15:03:00]
actually will be reading right then

[15:02:57 - 15:03:01]
hugging face LM will help you to load

[15:03:00 - 15:03:03]
that mral

[15:03:01 - 15:03:04]
model then with the help of simple

[15:03:03 - 15:03:06]
prompt you can create a prompt template

[15:03:04 - 15:03:08]
fine so now let me import all of them

[15:03:06 - 15:03:10]
later on I'll tell you whenever I'll be

[15:03:08 - 15:03:13]
using them now here I'm going to create

[15:03:10 - 15:03:14]
a directory called Data okay because

[15:03:13 - 15:03:17]
inside data directory I'm going to

[15:03:14 - 15:03:18]
upload my data now see if I refresh here

[15:03:17 - 15:03:20]
data is created now let me upload one

[15:03:18 - 15:03:22]
PDF

[15:03:20 - 15:03:25]
here so guys I'm having one statistics

[15:03:22 - 15:03:27]
PDF so I'm going to upload it here so

[15:03:25 - 15:03:30]
let me show you the PDF so this is the

[15:03:27 - 15:03:32]
PDF document guys importance and use of

[15:03:30 - 15:03:33]
code relation in statistics so this PDF

[15:03:32 - 15:03:34]
actually I'm going to upload in my

[15:03:33 - 15:03:36]
Google collab and on top of that

[15:03:34 - 15:03:38]
actually we'll be performing this

[15:03:36 - 15:03:39]
operation now here you can use any kinds

[15:03:38 - 15:03:41]
of PDF any kinds of documents okay

[15:03:39 - 15:03:44]
whatever you

[15:03:41 - 15:03:47]
have now see uh it is uploaded now let

[15:03:44 - 15:03:48]
me read the content so inside simple

[15:03:47 - 15:03:49]
directory reader you have to give the

[15:03:48 - 15:03:51]
data location so you can see I've given

[15:03:49 - 15:03:52]
the data folder it will automatically

[15:03:51 - 15:03:54]
load the PDF and it will extract the

[15:03:52 - 15:03:55]
information let me show you see if I

[15:03:54 - 15:03:58]
show you the documents right now see all

[15:03:55 - 15:04:00]
the document is has extracted fine now

[15:03:58 - 15:04:02]
here first of all let's create a so here

[15:04:00 - 15:04:04]
you can see I have created a uh system

[15:04:02 - 15:04:06]
prompt you are an QA assistant your goal

[15:04:04 - 15:04:08]
is to answer the question accurately as

[15:04:06 - 15:04:11]
as possible based on the instruction and

[15:04:08 - 15:04:12]
the context provided now this system

[15:04:11 - 15:04:14]
prompt actually I want to use as a

[15:04:12 - 15:04:16]
default prompt inside my large language

[15:04:14 - 15:04:18]
model for this you have to create one

[15:04:16 - 15:04:20]
query rapper prompt for this you can use

[15:04:18 - 15:04:22]
Simple input prompt okay and inside that

[15:04:20 - 15:04:24]
you can pass these are the keyword fine

[15:04:22 - 15:04:26]
now let me execute now you have to do

[15:04:24 - 15:04:28]
the hugging face C login because this

[15:04:26 - 15:04:30]
model is available inside hugging face

[15:04:28 - 15:04:32]
and to authenticate with hugging face

[15:04:30 - 15:04:33]
you have to give the token now here you

[15:04:32 - 15:04:35]
have to pass the token and how to get

[15:04:33 - 15:04:37]
the token guys I think you remember go

[15:04:35 - 15:04:41]
to the hugging

[15:04:37 - 15:04:43]
face click on the profile go to the

[15:04:41 - 15:04:44]
settings and left hand side you will see

[15:04:43 - 15:04:47]
access

[15:04:44 - 15:04:51]
token uh you can create a new token here

[15:04:47 - 15:04:51]
so let me give the token name let's say

[15:04:51 - 15:04:55]
test I want to give the read permission

[15:04:53 - 15:04:58]
as of now let's create the token I'll

[15:04:55 - 15:04:59]
copy and let's mention it here if I

[15:04:58 - 15:05:01]
paste it and hit enter it will automat

[15:04:59 - 15:05:04]
atically authenticate now here it is

[15:05:01 - 15:05:05]
asking uh token as great credential I'll

[15:05:04 - 15:05:09]
give

[15:05:05 - 15:05:10]
yes now see login successful okay now

[15:05:09 - 15:05:11]
you can see this is the model link I

[15:05:10 - 15:05:13]
have already given so this model

[15:05:11 - 15:05:14]
actually will be using now let's load

[15:05:13 - 15:05:16]
the model and to load the model I'm

[15:05:14 - 15:05:18]
going to use hugging fist llm inside

[15:05:16 - 15:05:20]
that you can pass context with the max

[15:05:18 - 15:05:21]
token I think you already know what is

[15:05:20 - 15:05:24]
Max token so what is context window

[15:05:21 - 15:05:26]
context window means this is the input

[15:05:24 - 15:05:31]
size of this llm that means it can take

[15:05:26 - 15:05:32]
4 496 token U as input okay as the input

[15:05:31 - 15:05:34]
that means this is the input size of

[15:05:32 - 15:05:37]
your large language model M can take

[15:05:34 - 15:05:39]
four 496 token okay now you can give

[15:05:37 - 15:05:41]
this temperature parameter and all and

[15:05:39 - 15:05:42]
inside that just pass your system prompt

[15:05:41 - 15:05:43]
whatever prompt actually you have

[15:05:42 - 15:05:44]
defined here I think remember and you

[15:05:43 - 15:05:46]
have to also pass the query rapper

[15:05:44 - 15:05:47]
prompt that means the default prompt you

[15:05:46 - 15:05:49]
want to set and here you have to give

[15:05:47 - 15:05:50]
the model name like which tokenizer you

[15:05:49 - 15:05:52]
want to use I want to use the same

[15:05:50 - 15:05:54]
tokenizer as per my model see this is

[15:05:52 - 15:05:57]
the model okay I'm giving the model ID

[15:05:54 - 15:05:59]
here now you you need to also give the

[15:05:57 - 15:06:01]
model name that means the same name then

[15:05:59 - 15:06:03]
after that Auto map is equal to that

[15:06:01 - 15:06:04]
means I want to use my GPU here I want

[15:06:03 - 15:06:06]
to load this model in my GPU because

[15:06:04 - 15:06:08]
it's a large language model it is it is

[15:06:06 - 15:06:10]
having actually lots of parameter right

[15:06:08 - 15:06:12]
so we can't U let's say run this model

[15:06:10 - 15:06:15]
on our CPU machine it's not possible if

[15:06:12 - 15:06:17]
you're running U actually it will take

[15:06:15 - 15:06:19]
lots of time even your memory will also

[15:06:17 - 15:06:21]
get crash so that's why we have to load

[15:06:19 - 15:06:24]
everything in the GPU based machine now

[15:06:21 - 15:06:26]
let's load this model see first of all

[15:06:24 - 15:06:29]
it will download the model from the

[15:06:26 - 15:06:33]
internet and it will create one llm raer

[15:06:29 - 15:06:36]
see it's around 9.9 94 GB just try to

[15:06:33 - 15:06:39]
consider guys how much big this model

[15:06:36 - 15:06:40]
is so that's why actually uh whenever

[15:06:39 - 15:06:43]
you are using any kinds of Open Source

[15:06:40 - 15:06:45]
large language model uh to create any

[15:06:43 - 15:06:46]
kinds of llm powered application so this

[15:06:45 - 15:06:47]
is the issue actually will be getting

[15:06:46 - 15:06:49]
that means you should have good

[15:06:47 - 15:06:51]
configuration machine otherwise you

[15:06:49 - 15:06:53]
won't be able to use that model so we'll

[15:06:51 - 15:06:56]
be learning something called llm ops so

[15:06:53 - 15:06:58]
inside L LM Ops actually I will show you

[15:06:56 - 15:07:00]
how we can uh create a efficient llm

[15:06:58 - 15:07:02]
powered application how we can deploy it

[15:07:00 - 15:07:03]
also on the cloud platform we'll be

[15:07:02 - 15:07:05]
discussing each and everything because

[15:07:03 - 15:07:07]
of that only LM Ops SC in the market

[15:07:05 - 15:07:09]
there are so many PL platform actually

[15:07:07 - 15:07:11]
we can use like Cloud generative we can

[15:07:09 - 15:07:13]
use let's say Bedrock is there vertex a

[15:07:11 - 15:07:15]
is there asure open is there we can use

[15:07:13 - 15:07:17]
these are the service okay to overcome

[15:07:15 - 15:07:19]
this issue so this model has downloaded

[15:07:17 - 15:07:21]
successfully now what I have to do I

[15:07:19 - 15:07:22]
have to download the embedding model as

[15:07:21 - 15:07:23]
well so to download this embedding model

[15:07:22 - 15:07:25]
I'm importing hug face embedding from

[15:07:23 - 15:07:27]
langin so because langin is having one

[15:07:25 - 15:07:28]
embedding functionality so from there we

[15:07:27 - 15:07:32]
can easily download the embedding model

[15:07:28 - 15:07:32]
so let's try to download this embedding

[15:07:32 - 15:07:40]
model so we have to install R Lang chain

[15:07:35 - 15:07:40]
Community for this so let me install Len

[15:07:45 - 15:07:50]
Community now let me execute this

[15:07:50 - 15:07:54]
code so see it has downloaded

[15:07:52 - 15:07:56]
successfully now let's create the now

[15:07:54 - 15:07:57]
let's create the service context that

[15:07:56 - 15:07:58]
means my vectory store that means I will

[15:07:57 - 15:08:00]
be creating the knowledge base for this

[15:07:58 - 15:08:02]
we'll be using service context from

[15:08:00 - 15:08:03]
default inside that you have to provide

[15:08:02 - 15:08:04]
the Chun size that means first of all it

[15:08:03 - 15:08:06]
will perform the chunking then it will

[15:08:04 - 15:08:08]
create the let's say Vector embedding

[15:08:06 - 15:08:10]
and it will store that Vector embedding

[15:08:08 - 15:08:11]
to the knowledge base okay now inside

[15:08:10 - 15:08:12]
that you have to pass the LM as well as

[15:08:11 - 15:08:15]
the embedding model now let's create the

[15:08:12 - 15:08:17]
service context so here actually some of

[15:08:15 - 15:08:20]
the syntax are different okay with

[15:08:17 - 15:08:21]
respect to this langin uh if you use the

[15:08:20 - 15:08:23]
langin I think Lin synex is little bit

[15:08:21 - 15:08:25]
different Lama index synex would be

[15:08:23 - 15:08:27]
little bit different but uh I mean

[15:08:25 - 15:08:29]
framework wise both are same okay both

[15:08:27 - 15:08:30]
can perform the same thing now let me

[15:08:29 - 15:08:33]
create the knowledge base so here you

[15:08:30 - 15:08:35]
are so here I'm using Vector store index

[15:08:33 - 15:08:36]
from documents here I'm giving the

[15:08:35 - 15:08:37]
documents as well as the service context

[15:08:36 - 15:08:39]
whatever service context we have

[15:08:37 - 15:08:41]
provided okay now it will create the

[15:08:39 - 15:08:43]
entire knowledge base now I can perform

[15:08:41 - 15:08:46]
the qu operation okay that means this

[15:08:43 - 15:08:47]
operation okay this operation so it will

[15:08:46 - 15:08:48]
go to the vector restore that means

[15:08:47 - 15:08:50]
knowledge base and it will return the

[15:08:48 - 15:08:51]
rank results and your llm will process

[15:08:50 - 15:08:53]
and it will give you the correct

[15:08:51 - 15:08:55]
response okay so here I'm given one

[15:08:53 - 15:08:57]
question what is the correlation now

[15:08:55 - 15:09:00]
let's see what is the response I get

[15:08:57 - 15:09:00]
here

[15:09:05 - 15:09:09]
so inside Lama index you need to write

[15:09:07 - 15:09:11]
Le less than have code but whenever you

[15:09:09 - 15:09:13]
saw the Lang chain actually we have to

[15:09:11 - 15:09:15]
write uh actually our Vector store

[15:09:13 - 15:09:17]
actually manually that means we have to

[15:09:15 - 15:09:18]
write some more additional code right

[15:09:17 - 15:09:20]
but here everything is automated

[15:09:18 - 15:09:21]
everything it will handle that means we

[15:09:20 - 15:09:22]
don't need to perform the chunking

[15:09:21 - 15:09:24]
separately chunking will automatically

[15:09:22 - 15:09:26]
perform here okay with the help of the

[15:09:24 - 15:09:26]
service

[15:09:27 - 15:09:31]
context see although I'm using using GPU

[15:09:29 - 15:09:34]
based machine but still the inference

[15:09:31 - 15:09:37]
timing is high here now see it's done

[15:09:34 - 15:09:38]
now if I show you the response now see

[15:09:37 - 15:09:40]
this is the response I got corelation is

[15:09:38 - 15:09:42]
is a statistical measures that Express

[15:09:40 - 15:09:44]
the extent uh to which the two variables

[15:09:42 - 15:09:46]
are linearly related that means it has

[15:09:44 - 15:09:47]
given me the correct response okay so

[15:09:46 - 15:09:49]
yes that's how actually we can use any

[15:09:47 - 15:09:50]
kinds of Open Source large language

[15:09:49 - 15:09:52]
model with the help of L index now you

[15:09:50 - 15:09:54]
can go to the hugging pH and you can use

[15:09:52 - 15:09:56]
any of the let's say um large language

[15:09:54 - 15:09:58]
model and you can use it with the help

[15:09:56 - 15:10:00]
of Lama index fine so uh I'm not going

[15:09:58 - 15:10:02]
to implement this projects from scratch

[15:10:00 - 15:10:04]
because I have already discussed the

[15:10:02 - 15:10:07]
like process how we develop like one in

[15:10:04 - 15:10:08]
10 projects okay so that is why I

[15:10:07 - 15:10:10]
already implemented one particular

[15:10:08 - 15:10:12]
projects as you can see here so this is

[15:10:10 - 15:10:14]
like a Financial stock analysis project

[15:10:12 - 15:10:16]
I have developed with the help of this

[15:10:14 - 15:10:18]
lendex so first of all I will show you

[15:10:16 - 15:10:19]
the demo of this projects okay like like

[15:10:18 - 15:10:22]
what is the projects and all about so

[15:10:19 - 15:10:23]
those who are interested in the field of

[15:10:22 - 15:10:26]
financial or let's say in the domain of

[15:10:23 - 15:10:28]
financial so uh they will be loving this

[15:10:26 - 15:10:30]
project because here you can do like a

[15:10:28 - 15:10:32]
stock analysis okay so we have some

[15:10:30 - 15:10:33]
stock data we have some articles

[15:10:32 - 15:10:36]
actually as you can see so these are the

[15:10:33 - 15:10:38]
articles I have uh downloaded from the

[15:10:36 - 15:10:39]
internet and this is in the HML format

[15:10:38 - 15:10:41]
so we'll be processing these are the

[15:10:39 - 15:10:42]
data we'll be collecting the content

[15:10:41 - 15:10:45]
okay if you see this is the completely

[15:10:42 - 15:10:47]
HTML data so here we have lots of like

[15:10:45 - 15:10:50]
Financial stock data like we have Google

[15:10:47 - 15:10:53]
data then we have Nvidia we have meta

[15:10:50 - 15:10:54]
okay then we have u ms uh uh here you

[15:10:53 - 15:10:56]
see

[15:10:54 - 15:10:57]
msft okay as you can see so we have

[15:10:56 - 15:11:00]
different different like you can say

[15:10:57 - 15:11:03]
companies uh stock data here so I

[15:11:00 - 15:11:05]
already uh given the link of the data in

[15:11:03 - 15:11:06]
my GitHub so you can download from here

[15:11:05 - 15:11:08]
I will show you like how to download the

[15:11:06 - 15:11:10]
data so that is script I have already

[15:11:08 - 15:11:11]
written so first of all let me execute

[15:11:10 - 15:11:13]
the projects

[15:11:11 - 15:11:17]
so I will first of all execute this

[15:11:13 - 15:11:17]
projects and show you like how it will

[15:11:18 - 15:11:23]
work so see guys this is the stream late

[15:11:20 - 15:11:25]
app I have developed and uh here you can

[15:11:23 - 15:11:28]
do two kinds of analysis one is like you

[15:11:25 - 15:11:31]
can do a single stock analysis another

[15:11:28 - 15:11:33]
is a competitive uh analysis okay like

[15:11:31 - 15:11:34]
competitor analysis I'll show you both

[15:11:33 - 15:11:37]
of you okay so here first of all let's

[15:11:34 - 15:11:41]
do the single uh stock analysis so I'll

[15:11:37 - 15:11:41]
just ask what is the

[15:11:41 - 15:11:46]
stock of here if you see so they have

[15:11:44 - 15:11:49]
given the short name for each and every

[15:11:46 - 15:11:52]
company if you come here so I've already

[15:11:49 - 15:11:55]
listed down so let's ask uh for the

[15:11:52 - 15:11:58]
Nvidia so I'll copy the Nvidia and here

[15:11:55 - 15:11:58]
I will ask

[15:12:06 - 15:12:10]
so guys as you can see I have asked like

[15:12:07 - 15:12:11]
what is the stock of Nvidia so it is

[15:12:10 - 15:12:16]
giving me the answer okay you can see it

[15:12:11 - 15:12:18]
is giving it is giving like 2023 to 2027

[15:12:16 - 15:12:20]
okay it's giving the stock as you can

[15:12:18 - 15:12:23]
see now and you can ask for any kinds of

[15:12:20 - 15:12:24]
stock let's ask for the Google so I'll

[15:12:23 - 15:12:28]
copy

[15:12:24 - 15:12:29]
Google and here if I paste and enter so

[15:12:28 - 15:12:31]
now it will give me made the stock of

[15:12:29 - 15:12:32]
the Google so that's how actually you

[15:12:31 - 15:12:35]
can ask different different stock

[15:12:32 - 15:12:37]
related question okay um if you're uh

[15:12:35 - 15:12:40]
interested in uh these kinds of stock

[15:12:37 - 15:12:41]
and all so you can ask lots of question

[15:12:40 - 15:12:43]
and you can get the response with

[15:12:41 - 15:12:43]
respect to

[15:12:46 - 15:12:50]
that okay as you can see this is the

[15:12:48 - 15:12:53]
Google stock uh answer it is giving now

[15:12:50 - 15:12:54]
you can also perform like competitive uh

[15:12:53 - 15:12:56]
stock analysis so just select the

[15:12:54 - 15:13:00]
competitive one now it will give you the

[15:12:56 - 15:13:02]
interface of the competitive analysis

[15:13:00 - 15:13:03]
so guys as you can see this is the

[15:13:02 - 15:13:06]
competitive analysis one so now here you

[15:13:03 - 15:13:11]
need to provide stock one uh symbol and

[15:13:06 - 15:13:11]
stock two symbol so let's do like uh

[15:13:12 - 15:13:17]
msft and I will also do for my

[15:13:17 - 15:13:24]
Nvidia let's see the competitive

[15:13:20 - 15:13:24]
analysis between them

[15:13:30 - 15:13:33]
uh so see guys uh this is the

[15:13:32 - 15:13:36]
competitive analysis between them as you

[15:13:33 - 15:13:38]
can see you can read it out okay so not

[15:13:36 - 15:13:40]
only that you can uh like see like

[15:13:38 - 15:13:42]
competitive analysis between all the

[15:13:40 - 15:13:44]
company here is the listed okay and this

[15:13:42 - 15:13:46]
is the symbol of the stock like uh you

[15:13:44 - 15:13:48]
can't directly pass the company name so

[15:13:46 - 15:13:49]
you need to give the symbol okay because

[15:13:48 - 15:13:51]
this is your custom data you have given

[15:13:49 - 15:13:53]
like that so yes guys this is the

[15:13:51 - 15:13:54]
projects actually uh I have developed

[15:13:53 - 15:13:56]
with the help of this Lama index and

[15:13:54 - 15:13:58]
this is very much uh interesting

[15:13:56 - 15:14:00]
projects like in the field of financial

[15:13:58 - 15:14:02]
domain and you can see Implement lots of

[15:14:00 - 15:14:04]
thing with the help of this lamb index I

[15:14:02 - 15:14:06]
think I already showed you like lots of

[15:14:04 - 15:14:08]
like functionality and all and I already

[15:14:06 - 15:14:10]
showed you lots of things okay uh with

[15:14:08 - 15:14:12]
the help of Open Source model and now

[15:14:10 - 15:14:14]
you can Implement anything okay whatever

[15:14:12 - 15:14:15]
you can think in your mind you can

[15:14:14 - 15:14:18]
Implement anything just you need to try

[15:14:15 - 15:14:19]
from your site okay now guys U let me

[15:14:18 - 15:14:22]
show you like how I have developed this

[15:14:19 - 15:14:24]
projects okay so this is the projects

[15:14:22 - 15:14:26]
guys I have already developed and uh let

[15:14:24 - 15:14:27]
me show you uh this is the code for the

[15:14:26 - 15:14:29]
projects okay so I'll explain each and

[15:14:27 - 15:14:30]
everything like whatever things actually

[15:14:29 - 15:14:33]
doing and I have already given the idea

[15:14:30 - 15:14:35]
about Lama index and this stream lit and

[15:14:33 - 15:14:36]
all so I think you are already familiar

[15:14:35 - 15:14:38]
with these are the thing okay I'm

[15:14:36 - 15:14:39]
expecting so that's why I'll be

[15:14:38 - 15:14:42]
explaining the projects okay instead of

[15:14:39 - 15:14:45]
writing all the line from scratch so

[15:14:42 - 15:14:47]
first of all let me stop the

[15:14:45 - 15:14:48]
execution then uh I will remove this

[15:14:47 - 15:14:50]
article folder because this is my

[15:14:48 - 15:14:52]
generated

[15:14:50 - 15:14:54]
folder then I will also remove this

[15:14:52 - 15:14:55]
stories okay stories I think you

[15:14:54 - 15:14:57]
remember stories is nothing but it's a

[15:14:55 - 15:14:59]
vector store we created with the help of

[15:14:57 - 15:15:01]
lam Index right so both I have deleted

[15:14:59 - 15:15:03]
now here is the rme file I have already

[15:15:01 - 15:15:05]
shared like what are the steps you need

[15:15:03 - 15:15:06]
to perform so here first of all you need

[15:15:05 - 15:15:07]
to clone the repository so this

[15:15:06 - 15:15:09]
repository will find from the

[15:15:07 - 15:15:10]
description section so from there

[15:15:09 - 15:15:12]
actually you can download the projects

[15:15:10 - 15:15:13]
then you need to create one environment

[15:15:12 - 15:15:16]
okay python

[15:15:13 - 15:15:17]
environment uh using python 3.8 then you

[15:15:16 - 15:15:19]
need to activate the environment then

[15:15:17 - 15:15:20]
you need to install the requirements so

[15:15:19 - 15:15:22]
requirement wise I'm using these are the

[15:15:20 - 15:15:25]
requirements as you can see so you are

[15:15:22 - 15:15:28]
using L index then stream lead python.

[15:15:25 - 15:15:30]
EnV okay and apart from that I'm also

[15:15:28 - 15:15:32]
using openi and some U you can say

[15:15:30 - 15:15:34]
dependency package I'm also installing

[15:15:32 - 15:15:35]
here so this thing you need to install I

[15:15:34 - 15:15:37]
already showed you how to install them

[15:15:35 - 15:15:39]
and all how to create the environment in

[15:15:37 - 15:15:42]
my previous project implementation then

[15:15:39 - 15:15:43]
after that uh you need to uh execute

[15:15:42 - 15:15:46]
this app.py okay but before running the

[15:15:43 - 15:15:48]
app.py you should have your data and you

[15:15:46 - 15:15:50]
should have your vector store presence

[15:15:48 - 15:15:52]
okay otherwise it won't be working so

[15:15:50 - 15:15:53]
for this actually in the SRC folder I

[15:15:52 - 15:15:54]
have written some of the script as you

[15:15:53 - 15:15:57]
can see first of all we need to fetch

[15:15:54 - 15:15:58]
the data so this is the link guys so in

[15:15:57 - 15:16:00]
this link actually this articles is

[15:15:58 - 15:16:02]
available I have already given this link

[15:16:00 - 15:16:03]
and this is uh this is hosted on my

[15:16:02 - 15:16:05]
GitHub so from here you can download

[15:16:03 - 15:16:08]
those data set okay download those

[15:16:05 - 15:16:09]
articles and after that see I have

[15:16:08 - 15:16:11]
written one function with the help of

[15:16:09 - 15:16:13]
this function I'm downloading so

[15:16:11 - 15:16:15]
basically it will take this URL data URL

[15:16:13 - 15:16:18]
and it will download that uh Z file okay

[15:16:15 - 15:16:20]
from my GitHub and it will and it will

[15:16:18 - 15:16:22]
unzip it okay it will unzip it here and

[15:16:20 - 15:16:23]
that zip file it will remove okay so

[15:16:22 - 15:16:25]
this is the code I have written now let

[15:16:23 - 15:16:27]
me show you how it is working so I

[15:16:25 - 15:16:29]
already created the environment so now

[15:16:27 - 15:16:32]
I'll execute this particular file so

[15:16:29 - 15:16:35]
I'll just write python uh inside SRC

[15:16:32 - 15:16:38]
inside SRC I have one file called 01

[15:16:35 - 15:16:40]
fetch data okay I will execute this file

[15:16:38 - 15:16:43]
now see guys it will download that uh

[15:16:40 - 15:16:43]
data from my

[15:16:44 - 15:16:49]
URL so see guys it has downloaded all

[15:16:46 - 15:16:51]
the HTML file and now see if I open my

[15:16:49 - 15:16:53]
articles all the data are presents now

[15:16:51 - 15:16:55]
what I need to do I need to create one

[15:16:53 - 15:16:57]
vector I think you already know like

[15:16:55 - 15:16:58]
what is Vector I I already explained

[15:16:57 - 15:16:59]
these are the thing in my notebook

[15:16:58 - 15:17:01]
experience ment okay what are the steps

[15:16:59 - 15:17:04]
I perform same thing I'm doing here also

[15:17:01 - 15:17:06]
okay so to create the vory store I

[15:17:04 - 15:17:08]
created another file called index news.

[15:17:06 - 15:17:11]
Pi so here I'm using this GPT Vector

[15:17:08 - 15:17:13]
restore to create my Vector embedding so

[15:17:11 - 15:17:14]
here you can also use Google p embedding

[15:17:13 - 15:17:16]
you can also use hugging face embedding

[15:17:14 - 15:17:19]
anything you can use just try to use

[15:17:16 - 15:17:21]
open source embedding U because if you

[15:17:19 - 15:17:22]
if you don't want to use like open AI so

[15:17:21 - 15:17:24]
if you don't want to spend money so you

[15:17:22 - 15:17:26]
can go go with like open source model

[15:17:24 - 15:17:28]
otherwise uh if you have like open a

[15:17:26 - 15:17:29]
account you can also use open AP key so

[15:17:28 - 15:17:31]
here if you see I have already set my

[15:17:29 - 15:17:33]
open IPA key so by default if you're not

[15:17:31 - 15:17:35]
giving any embedding models it will take

[15:17:33 - 15:17:38]
that open a embedding model okay so this

[15:17:35 - 15:17:40]
GPT uh Vector store index already has

[15:17:38 - 15:17:42]
like GPT based embedding model it will

[15:17:40 - 15:17:44]
take that model and it will convert your

[15:17:42 - 15:17:45]
data to Vector embedding okay so guys

[15:17:44 - 15:17:47]
this should be your task just try to

[15:17:45 - 15:17:49]
replace this code with your open source

[15:17:47 - 15:17:50]
model I think I showed you how we can

[15:17:49 - 15:17:53]
use hugging face embedding model in this

[15:17:50 - 15:17:54]
notebook uh see guys here huging Quest

[15:17:53 - 15:17:56]
embedding model I was using so you also

[15:17:54 - 15:17:59]
need to use Hing Quest embedding model

[15:17:56 - 15:18:00]
here okay in this case I'm using open so

[15:17:59 - 15:18:03]
you need to replace with the H embeding

[15:18:00 - 15:18:05]
model okay I think I already showed each

[15:18:03 - 15:18:07]
and everything so you can do it now let

[15:18:05 - 15:18:08]
me first of all generate these are the

[15:18:07 - 15:18:12]
embeddings

[15:18:08 - 15:18:17]
so I'll clear then I will run this

[15:18:12 - 15:18:17]
uh second file so it's

[15:18:20 - 15:18:24]
02 so it will take time because it will

[15:18:22 - 15:18:26]
take all the Articles it will it will

[15:18:24 - 15:18:28]
convert to chunks then it will uh like

[15:18:26 - 15:18:30]
convert them to Vector embedding okay

[15:18:28 - 15:18:31]
then it it will create the stories here

[15:18:30 - 15:18:33]
so here you can also integrate like

[15:18:31 - 15:18:35]
vector database so you can use pine con

[15:18:33 - 15:18:38]
we yet and you can also use chroma DB

[15:18:35 - 15:18:40]
but I'm using this default like vector

[15:18:38 - 15:18:42]
store index so L index provide this

[15:18:40 - 15:18:44]
thing so it will store your embedding

[15:18:42 - 15:18:46]
local okay it will create one storage

[15:18:44 - 15:18:48]
folder and it will store here so you can

[15:18:46 - 15:18:50]
also use Vector database and you can

[15:18:48 - 15:18:53]
store them in the cloud as well okay I

[15:18:50 - 15:18:53]
already showed you just try to integrate

[15:18:54 - 15:19:00]
here uh so guys as you can see my stor

[15:18:57 - 15:19:02]
has been created now now this is my

[15:19:00 - 15:19:05]
Vector uh so see these are my

[15:19:02 - 15:19:08]
embedding so these are my Vector okay so

[15:19:05 - 15:19:11]
now we are successfully uh able to store

[15:19:08 - 15:19:14]
our Vector embedding now see uh now this

[15:19:11 - 15:19:16]
is the third uh script I have written so

[15:19:14 - 15:19:17]
if you want to test on top of your uh

[15:19:16 - 15:19:19]
like stories so I here I'm loading the

[15:19:17 - 15:19:21]
stories and I'm just asking one query

[15:19:19 - 15:19:23]
like what is uh tell me about Google's

[15:19:21 - 15:19:25]
new super computer okay so this is the

[15:19:23 - 15:19:26]
query I'm asking so it will give you the

[15:19:25 - 15:19:29]
response so you can try out okay so let

[15:19:26 - 15:19:30]
me execute and show you how it is work

[15:19:29 - 15:19:34]
working

[15:19:30 - 15:19:34]
so I'll just write

[15:19:37 - 15:19:45]
python then inside SRC I have this

[15:19:42 - 15:19:47]
03

[15:19:45 - 15:19:50]
yeah so see guys uh this is the um

[15:19:47 - 15:19:52]
response I got okay so yeah that means

[15:19:50 - 15:19:54]
my U Storage has been created

[15:19:52 - 15:19:56]
successfully and we are also able to ask

[15:19:54 - 15:19:59]
the query on top of it now we'll be

[15:19:56 - 15:20:02]
converting these are the thing okay uh

[15:19:59 - 15:20:05]
as our app so basically I will uh give

[15:20:02 - 15:20:07]
some of the input okay uh user will ask

[15:20:05 - 15:20:09]
the query and they will also select like

[15:20:07 - 15:20:11]
they they want to perform like single

[15:20:09 - 15:20:13]
stock analysis or let's say multiple

[15:20:11 - 15:20:15]
stock analysis so this kind of

[15:20:13 - 15:20:18]
functionality I also add so for this I I

[15:20:15 - 15:20:19]
have already created one app.py as you

[15:20:18 - 15:20:21]
can see this is the app. pi here if you

[15:20:19 - 15:20:23]
see my index is already created so

[15:20:21 - 15:20:25]
that's why I'm importing the storage

[15:20:23 - 15:20:27]
context and load index from the storage

[15:20:25 - 15:20:29]
because I want to load it then I'm also

[15:20:27 - 15:20:32]
importing like wise openi because I told

[15:20:29 - 15:20:34]
you I'll will be using openi like model

[15:20:32 - 15:20:36]
here instead of using open source so

[15:20:34 - 15:20:38]
here you just need to replace this uh

[15:20:36 - 15:20:39]
openi model with your open source model

[15:20:38 - 15:20:41]
you can also use Palm 2 then you can

[15:20:39 - 15:20:44]
also use lamb 2 anything you can use I

[15:20:41 - 15:20:46]
already showed you this thing in my this

[15:20:44 - 15:20:47]
notbook experiment okay in my L index

[15:20:46 - 15:20:50]
session just try to replace that these

[15:20:47 - 15:20:53]
are the model here then model wise see I

[15:20:50 - 15:20:55]
have initialized zpt 3.5 TBO then here

[15:20:53 - 15:20:57]
I'm just defining my llm predictor and I

[15:20:55 - 15:20:59]
think you remember we had we had created

[15:20:57 - 15:21:00]
one service context okay uh so in lendex

[15:20:59 - 15:21:03]
we create something called service

[15:21:00 - 15:21:04]
context and this will take your llm so

[15:21:03 - 15:21:06]
once it's done I'm also loading my

[15:21:04 - 15:21:08]
Storage storage that means this uh

[15:21:06 - 15:21:10]
Vector embedding okay as you can see I'm

[15:21:08 - 15:21:12]
loading I'm giving the path once it is

[15:21:10 - 15:21:14]
done I'm creating this quy engine okay

[15:21:12 - 15:21:16]
so once quy engine is ready now we'll be

[15:21:14 - 15:21:18]
creating the front end part so here

[15:21:16 - 15:21:21]
basically if you see here we are uh

[15:21:18 - 15:21:23]
creating this uh title and all like this

[15:21:21 - 15:21:25]
is the title Financial stock analysis so

[15:21:23 - 15:21:29]
let me execute and show you how this

[15:21:25 - 15:21:29]
thing will look like

[15:21:31 - 15:21:35]
so see guys uh this is the title and

[15:21:32 - 15:21:37]
this is the report subtitle so these two

[15:21:35 - 15:21:40]
I have created now here I'm creating one

[15:21:37 - 15:21:42]
select box so what type of uh like

[15:21:40 - 15:21:44]
report you want to you want so this is

[15:21:42 - 15:21:45]
the select box guys let me show you this

[15:21:44 - 15:21:46]
is the select box so if you want to

[15:21:45 - 15:21:49]
create any kind of Select box you need

[15:21:46 - 15:21:51]
to select uh select box from stream L

[15:21:49 - 15:21:53]
and here is the message I've given so

[15:21:51 - 15:21:55]
what type of uh report you want to do

[15:21:53 - 15:21:57]
and single and competitive so here if

[15:21:55 - 15:22:01]
you see this two thing I'm giving here

[15:21:57 - 15:22:03]
so single and competitive then if user

[15:22:01 - 15:22:06]
is selecting single one okay so first of

[15:22:03 - 15:22:08]
all we'll be handling the single so here

[15:22:06 - 15:22:11]
is the uh prompt I have written let me

[15:22:08 - 15:22:13]
show you so I'm just using my engine

[15:22:11 - 15:22:16]
query query engine so as you can see

[15:22:13 - 15:22:18]
query engine we have already created and

[15:22:16 - 15:22:21]
this is the like prompt I'm just giving

[15:22:18 - 15:22:24]
so write a report on uh like on the

[15:22:21 - 15:22:26]
outlook for symbols okay symbol user

[15:22:24 - 15:22:28]
will give me that okay user will give me

[15:22:26 - 15:22:32]
that symbol because as you can see we

[15:22:28 - 15:22:34]
are uh receiving the symbol so uh as a

[15:22:32 - 15:22:37]
text input text basically here is the

[15:22:34 - 15:22:38]
symbol AS input text we're receiving and

[15:22:37 - 15:22:41]
that thing we're passing here okay as a

[15:22:38 - 15:22:44]
F string then once it is done this is my

[15:22:41 - 15:22:45]
prompt stock from I'm just uh mentioning

[15:22:44 - 15:22:48]
the year I need this stock from this

[15:22:45 - 15:22:50]
year and uh I'm also telling like be

[15:22:48 - 15:22:52]
sure include the potential risk and the

[15:22:50 - 15:22:54]
uh head winth okay so this is my prompt

[15:22:52 - 15:22:56]
I have given to my llm so my llm will

[15:22:54 - 15:22:57]
give me some response and that that

[15:22:56 - 15:23:00]
response actually I need to show I need

[15:22:57 - 15:23:02]
to Showcase okay so I'm just using s.

[15:23:00 - 15:23:05]
write and I'm just passing my like uh

[15:23:02 - 15:23:06]
this response and it it will show here

[15:23:05 - 15:23:09]
so once it is uh done so I'm also

[15:23:06 - 15:23:11]
handling the competitive analysis so if

[15:23:09 - 15:23:12]
user is selecting competitive analysis

[15:23:11 - 15:23:14]
so first of all I'm taking like two

[15:23:12 - 15:23:17]
competitive as you can see if I select

[15:23:14 - 15:23:18]
the competitive one so here if you see

[15:23:17 - 15:23:21]
I'm receiving the stock one and stock

[15:23:18 - 15:23:23]
two and this thing actually I'm storing

[15:23:21 - 15:23:25]
symbol one symbol two and this is the my

[15:23:23 - 15:23:27]
second prompt okay so I'm just uh

[15:23:25 - 15:23:29]
writing write a report on the

[15:23:27 - 15:23:32]
competitive between my symbol one and

[15:23:29 - 15:23:33]
symbol two uh stock okay then it will

[15:23:32 - 15:23:35]
give me the response and that the

[15:23:33 - 15:23:37]
response I'm showing in my front end so

[15:23:35 - 15:23:39]
this is the simple logic actually I have

[15:23:37 - 15:23:41]
written uh behind this projects okay and

[15:23:39 - 15:23:43]
this is like very easy now you just need

[15:23:41 - 15:23:45]
to uh like convert them to open source

[15:23:43 - 15:23:47]
model and if you have any idea on top of

[15:23:45 - 15:23:49]
it you can also create it okay I think

[15:23:47 - 15:23:50]
you got the overall idea and all the

[15:23:49 - 15:23:52]
resources actually will get from the

[15:23:50 - 15:23:54]
description section so I think you

[15:23:52 - 15:23:55]
already know what is medical chatbot

[15:23:54 - 15:23:57]
let's say if you have any medical

[15:23:55 - 15:23:58]
related query let's say you got one

[15:23:57 - 15:24:00]
disease

[15:23:58 - 15:24:03]
so you are asking for the diagnosis you

[15:24:00 - 15:24:05]
are asking for the medicine so this bot

[15:24:03 - 15:24:06]
will able to give the response with

[15:24:05 - 15:24:08]
respect to that that means it will give

[15:24:06 - 15:24:09]
you the suggestion it will give you the

[15:24:08 - 15:24:11]
medicine suggestion it will give you the

[15:24:09 - 15:24:13]
diagnosis suggestion so these kinds of

[15:24:11 - 15:24:15]
information this bot will provide so

[15:24:13 - 15:24:17]
we'll be creating the complete system

[15:24:15 - 15:24:19]
here that means here first of all we'll

[15:24:17 - 15:24:20]
be using our custom data the entire

[15:24:19 - 15:24:22]
let's say medical information custom

[15:24:20 - 15:24:23]
data we'll be using first of all we'll

[15:24:22 - 15:24:25]
be teaching our model we'll be creating

[15:24:23 - 15:24:27]
the entire knowledge base then I'm going

[15:24:25 - 15:24:28]
to connect my large language model there

[15:24:27 - 15:24:30]
that means whatever information you'll

[15:24:28 - 15:24:31]
be asking related the medical let's say

[15:24:30 - 15:24:34]
any kinds of disease any kinds of

[15:24:31 - 15:24:36]
medicine any kinds of let's say

[15:24:34 - 15:24:38]
diagnosis so everything your chatbot

[15:24:36 - 15:24:39]
will be able to give you the response

[15:24:38 - 15:24:41]
okay so this is the system we'll be

[15:24:39 - 15:24:43]
implementing and this is not going to be

[15:24:41 - 15:24:45]
guys uh like notebook implementation so

[15:24:43 - 15:24:46]
here we'll be creating the complete

[15:24:45 - 15:24:48]
pipeline that means we'll be creating

[15:24:46 - 15:24:49]
the front end part of our application

[15:24:48 - 15:24:51]
that means we'll be creating the

[15:24:49 - 15:24:53]
beautiful user interface so that user

[15:24:51 - 15:24:55]
can put the quy and they can get the

[15:24:53 - 15:24:56]
response from the chat B fine and here

[15:24:55 - 15:24:58]
we'll be using something called modular

[15:24:56 - 15:25:00]
coding in Python so it's not like

[15:24:58 - 15:25:01]
scripting programming we'll be writing

[15:25:00 - 15:25:04]
we'll be using modular concept here to

[15:25:01 - 15:25:05]
implement the entire project fine and

[15:25:04 - 15:25:07]
also we'll be uh using the git and

[15:25:05 - 15:25:09]
GitHub to let's say do the version

[15:25:07 - 15:25:10]
controlling so uh that means we'll be

[15:25:09 - 15:25:12]
following the entire development

[15:25:10 - 15:25:13]
pipeline here what are the things you

[15:25:12 - 15:25:15]
need even I will also show you how we

[15:25:13 - 15:25:16]
can deploy this project okay in a cloud

[15:25:15 - 15:25:18]
platform so everything guys we'll be

[15:25:16 - 15:25:20]
implementing in this project so make

[15:25:18 - 15:25:21]
sure we watching this video till the end

[15:25:20 - 15:25:23]
and if you have any question you can

[15:25:21 - 15:25:24]
feel free to ask me okay in the comment

[15:25:23 - 15:25:26]
section so first of all what I will show

[15:25:24 - 15:25:27]
you guys I will show you the entire

[15:25:26 - 15:25:29]
project architecture like what are the

[15:25:27 - 15:25:30]
things we are going to LEL up then I

[15:25:29 - 15:25:31]
will also show you the tools and

[15:25:30 - 15:25:33]
Technology we'll be using here then

[15:25:31 - 15:25:35]
we'll start the implementation fine so

[15:25:33 - 15:25:37]
let's open up our Blackboard and try to

[15:25:35 - 15:25:39]
understand the project architecture so

[15:25:37 - 15:25:42]
guys as I already told you we'll be

[15:25:39 - 15:25:44]
using our custom data here okay we'll be

[15:25:42 - 15:25:48]
using

[15:25:44 - 15:25:52]
custom data custom Medical Data I can

[15:25:48 - 15:25:55]
write medical

[15:25:52 - 15:25:57]
data so let me show you I'm having one

[15:25:55 - 15:25:59]
entire actually medical book so guys you

[15:25:57 - 15:26:02]
can see this is the book the book name

[15:25:59 - 15:26:03]
is the Gil Encyclopedia of medicine okay

[15:26:02 - 15:26:05]
second edition so this is the book you

[15:26:03 - 15:26:08]
can also search on Google you will get

[15:26:05 - 15:26:12]
this book and it is having uh around

[15:26:08 - 15:26:14]
637 Pages it's like very big book and it

[15:26:12 - 15:26:17]
is having all kinds of information

[15:26:14 - 15:26:18]
regarding the medical so see if you open

[15:26:17 - 15:26:21]
this book actually you will see all

[15:26:18 - 15:26:23]
kinds of content let's say all kinds of

[15:26:21 - 15:26:24]
disease even with respect to that

[15:26:23 - 15:26:26]
disease what kinds of medicine actually

[15:26:24 - 15:26:28]
you need what kinds of diagnosis

[15:26:26 - 15:26:30]
technique you need everything this book

[15:26:28 - 15:26:33]
has uh covered okay so it is having

[15:26:30 - 15:26:34]
different different um different

[15:26:33 - 15:26:36]
different treatment different different

[15:26:34 - 15:26:38]
uh actually medicine different different

[15:26:36 - 15:26:40]
disease even the disease image is also

[15:26:38 - 15:26:41]
visible here all kinds of disease

[15:26:40 - 15:26:43]
actually it is having all kinds of

[15:26:41 - 15:26:45]
disease actually it is having even with

[15:26:43 - 15:26:47]
respect to that they have also given the

[15:26:45 - 15:26:49]
diagnosis even the treatment okay how

[15:26:47 - 15:26:51]
let's say you can do the diagnosis how

[15:26:49 - 15:26:53]
you can do the treatment what kinds of

[15:26:51 - 15:26:55]
medicine you have to let's say take

[15:26:53 - 15:26:57]
everything this book has uh given the

[15:26:55 - 15:26:59]
information so here we'll be using this

[15:26:57 - 15:27:01]
book actually the entire medical

[15:26:59 - 15:27:03]
information and we'll be creating the

[15:27:01 - 15:27:05]
knowledge base that means here we'll be

[15:27:03 - 15:27:08]
using pine cone Vector database okay I

[15:27:05 - 15:27:10]
think you know Pine con is a cloud-based

[15:27:08 - 15:27:11]
Vector database that means there we can

[15:27:10 - 15:27:13]
store the embedding Vector embedding

[15:27:11 - 15:27:15]
that means first of all we'll be

[15:27:13 - 15:27:16]
extracting all the information from this

[15:27:15 - 15:27:18]
book then we'll be creating the chunks

[15:27:16 - 15:27:19]
and that chunks actually with the help

[15:27:18 - 15:27:21]
of embedding model we'll be creating the

[15:27:19 - 15:27:22]
vector embedding and that Vector

[15:27:21 - 15:27:24]
embedding will be storing to the Pine

[15:27:22 - 15:27:26]
con Vector DB and that Pine con Vector

[15:27:24 - 15:27:28]
DB is going to be my knowledge base that

[15:27:26 - 15:27:30]
means the entire knowledge base H why

[15:27:28 - 15:27:32]
I'm not using the local Vector database

[15:27:30 - 15:27:35]
here because my data size is huge if you

[15:27:32 - 15:27:37]
see 637 Pages information I'm having so

[15:27:35 - 15:27:39]
if you just create the chunks just try

[15:27:37 - 15:27:40]
to consider how many chunks you will get

[15:27:39 - 15:27:42]
and if you're storing in the local DV it

[15:27:40 - 15:27:44]
won't be efficient so that's why we'll

[15:27:42 - 15:27:45]
be using cloud-based Vector DV here fine

[15:27:44 - 15:27:47]
and I'll show you how we can use the

[15:27:45 - 15:27:49]
pine cone properly it's one of the

[15:27:47 - 15:27:51]
amazing Vector DB I personally prefer so

[15:27:49 - 15:27:53]
there actually you can also see your

[15:27:51 - 15:27:54]
vector visualization okay everything you

[15:27:53 - 15:27:56]
can see see this is another actually

[15:27:54 - 15:27:58]
disease see this is the disease actually

[15:27:56 - 15:28:00]
even with respect to that they have Al

[15:27:58 - 15:28:02]
given the diagnosis as well as the

[15:28:00 - 15:28:04]
medicine now I'll share this PDF with

[15:28:02 - 15:28:05]
you guys you can uh see The Complete

[15:28:04 - 15:28:06]
Book if you want to see different

[15:28:05 - 15:28:08]
different medicine and different

[15:28:06 - 15:28:10]
different let's say diagnosis okay you

[15:28:08 - 15:28:11]
can check it out so here what we'll be

[15:28:10 - 15:28:13]
doing guys we'll be using this medical

[15:28:11 - 15:28:15]
book so let's say this is one PDF

[15:28:13 - 15:28:18]
documents actually I'm

[15:28:15 - 15:28:21]
having or here I can

[15:28:18 - 15:28:21]
write

[15:28:21 - 15:28:26]
medical okay medical book so from the

[15:28:24 - 15:28:30]
medical book what we'll do we'll just

[15:28:26 - 15:28:30]
extract all the information

[15:28:35 - 15:28:39]
extract all

[15:28:41 - 15:28:46]
docks okay then after that we'll be

[15:28:43 - 15:28:47]
creating different different chunks and

[15:28:46 - 15:28:49]
I think you know what is chunking is

[15:28:47 - 15:28:50]
required right because here we'll be

[15:28:49 - 15:28:53]
using large language model and large

[15:28:50 - 15:28:55]
language model is having input uh

[15:28:53 - 15:28:57]
actually size one specific input size

[15:28:55 - 15:28:58]
and we have to follow that input size I

[15:28:57 - 15:28:59]
think previously we learned about about

[15:28:58 - 15:29:02]
Lama llama is having

[15:28:59 - 15:29:04]
4,096 okay this is the input length uh

[15:29:02 - 15:29:05]
that means this is the maximum input

[15:29:04 - 15:29:08]
length it can take the data if you're

[15:29:05 - 15:29:10]
using open model Also let's say GPT okay

[15:29:08 - 15:29:12]
GPT is also having one specific input

[15:29:10 - 15:29:14]
lend if you want to see that just open

[15:29:12 - 15:29:16]
the open.com and go to the model section

[15:29:14 - 15:29:17]
you will see that GPT input length so

[15:29:16 - 15:29:19]
whatever actually large language model

[15:29:17 - 15:29:21]
you using first of all try to see the

[15:29:19 - 15:29:22]
input length Okay of that model like

[15:29:21 - 15:29:24]
what would be the maximum token size

[15:29:22 - 15:29:25]
based on that try try to perform the

[15:29:24 - 15:29:27]
chunking operation okay that should be

[15:29:25 - 15:29:30]
my suu now it will give me different

[15:29:27 - 15:29:33]
different chunks so let's say I will get

[15:29:30 - 15:29:36]
chunk one a chunk one we'll be getting

[15:29:33 - 15:29:38]
Chun two we'll be getting Chun three and

[15:29:36 - 15:29:41]
so on then after getting the chunks what

[15:29:38 - 15:29:43]
I have to do guys I'll be using one

[15:29:41 - 15:29:43]
embedding

[15:29:44 - 15:29:49]
model

[15:29:47 - 15:29:52]
embedding

[15:29:49 - 15:29:53]
model okay with this embedding model

[15:29:52 - 15:29:56]
will generate the vector

[15:29:53 - 15:29:59]
embedding okay it will give me different

[15:29:56 - 15:30:03]
different Vector embedding

[15:29:59 - 15:30:06]
you'll be getting Vector embedding I can

[15:30:03 - 15:30:07]
copy and I can paste it here so we'll be

[15:30:06 - 15:30:09]
getting different different Vector

[15:30:07 - 15:30:11]
embedding and with this Vector embedding

[15:30:09 - 15:30:14]
guys what we'll do we'll just try to

[15:30:11 - 15:30:16]
build one centic

[15:30:14 - 15:30:20]
index that means the knowledge base

[15:30:16 - 15:30:23]
right build

[15:30:20 - 15:30:24]
centic index so this is going to be my

[15:30:23 - 15:30:27]
knowledge base that means we'll be

[15:30:24 - 15:30:31]
storing this Vector to the vector

[15:30:27 - 15:30:31]
database so I can write knowledge

[15:30:33 - 15:30:38]
base okay knowledge

[15:30:36 - 15:30:41]
base and here we'll be using something

[15:30:38 - 15:30:45]
called Pine con Vector store okay so let

[15:30:41 - 15:30:48]
me just write Vector DB okay

[15:30:45 - 15:30:50]
DB Vector DB and guys uh this is going

[15:30:48 - 15:30:52]
to be my complete backend component

[15:30:50 - 15:30:54]
component okay so here I can write this

[15:30:52 - 15:30:58]
is going to be my

[15:30:54 - 15:30:58]
backend component

[15:30:58 - 15:31:03]
okay component now I have to work on the

[15:31:00 - 15:31:05]
front end component that means user will

[15:31:03 - 15:31:08]
uh give some query and with respect to

[15:31:05 - 15:31:09]
the query actually uh I have to uh give

[15:31:08 - 15:31:13]
the proper response okay let's say this

[15:31:09 - 15:31:16]
is the user this is the

[15:31:13 - 15:31:18]
user so user will send one

[15:31:16 - 15:31:19]
query let's say this is the query user

[15:31:18 - 15:31:22]
has

[15:31:19 - 15:31:23]
asked so first of all it will convert to

[15:31:22 - 15:31:25]
the query EMB bding okay querium bding

[15:31:23 - 15:31:27]
that means this is going to be a English

[15:31:25 - 15:31:29]
text right and that should also

[15:31:27 - 15:31:31]
converted to the Vector embedding this

[15:31:29 - 15:31:32]
Vector embedding will go to the

[15:31:31 - 15:31:34]
knowledge

[15:31:32 - 15:31:36]
base okay it will go to the knowledge

[15:31:34 - 15:31:38]
base and knowledge base will return

[15:31:36 - 15:31:41]
return some rank

[15:31:38 - 15:31:44]
results okay rank result or similarity

[15:31:41 - 15:31:47]
let's say result it will return

[15:31:44 - 15:31:50]
return okay rank results then I'll be

[15:31:47 - 15:31:53]
using one large language model so here

[15:31:50 - 15:31:55]
we'll be using one large language model

[15:31:53 - 15:31:57]
llm so here I'm going to use openi large

[15:31:55 - 15:31:58]
language model you can use any kinds of

[15:31:57 - 15:32:00]
large language model you can use open

[15:31:58 - 15:32:02]
source large language model okay you can

[15:32:00 - 15:32:04]
also use the gini you can also use uh

[15:32:02 - 15:32:06]
let's say mistal anything you can use

[15:32:04 - 15:32:08]
here so here I'm going to use open large

[15:32:06 - 15:32:10]
language model because here I'm going to

[15:32:08 - 15:32:11]
create a production ready application so

[15:32:10 - 15:32:14]
this application will be also deploying

[15:32:11 - 15:32:16]
in the cloud platform okay that's why uh

[15:32:14 - 15:32:18]
I'll be using openi model okay why openi

[15:32:16 - 15:32:20]
model because openi model is already

[15:32:18 - 15:32:22]
hosted in the openi server we can access

[15:32:20 - 15:32:24]
this model through API request but if

[15:32:22 - 15:32:26]
I'm using any open source L language

[15:32:24 - 15:32:28]
model we have to download this model in

[15:32:26 - 15:32:30]
our local machine and local machine

[15:32:28 - 15:32:31]
doesn't have like uh good configuration

[15:32:30 - 15:32:33]
let's say instance let's say you don't

[15:32:31 - 15:32:36]
have good configuration GPU you don't

[15:32:33 - 15:32:37]
have good configuration actually Ram CP

[15:32:36 - 15:32:39]
that time actually you can't execute

[15:32:37 - 15:32:42]
this model in your system okay it it

[15:32:39 - 15:32:43]
will be very much difficult for you and

[15:32:42 - 15:32:45]
you will see that inference time would

[15:32:43 - 15:32:48]
be also very high that means uh this

[15:32:45 - 15:32:50]
model will uh keep processing the input

[15:32:48 - 15:32:51]
it will take lots of time to give you

[15:32:50 - 15:32:53]
the response so that's why we'll be

[15:32:51 - 15:32:55]
using openi model and going forward I'll

[15:32:53 - 15:32:57]
be discussing about llm Ops and there

[15:32:55 - 15:32:59]
I'll tell you how we can also use like

[15:32:57 - 15:33:01]
different different open source large

[15:32:59 - 15:33:03]
language model let's say if I want to

[15:33:01 - 15:33:06]
use llama okay llama if I want to let's

[15:33:03 - 15:33:09]
say use mistal

[15:33:06 - 15:33:11]
Falcon okay cloudy any kinds of model if

[15:33:09 - 15:33:14]
I want to use how I can use it even how

[15:33:11 - 15:33:15]
we can use it use it as a efficient way

[15:33:14 - 15:33:17]
even how we can deploy these are the

[15:33:15 - 15:33:19]
model in the cloud platform so for this

[15:33:17 - 15:33:22]
we'll be using something called llm ops

[15:33:19 - 15:33:23]
okay llm Ops we'll be using that means

[15:33:22 - 15:33:25]
we'll be using different different

[15:33:23 - 15:33:28]
platform we'll be running about

[15:33:25 - 15:33:30]
Bedrock okay AWS bedrock we'll be

[15:33:28 - 15:33:34]
learning about let's say gcp vertex

[15:33:30 - 15:33:37]
AI verx so these are the llm Ops

[15:33:34 - 15:33:38]
platform okay so we'll be uh using this

[15:33:37 - 15:33:40]
lmos platform to access these are the

[15:33:38 - 15:33:42]
model and on top of that we'll be

[15:33:40 - 15:33:43]
creating the application fine so this is

[15:33:42 - 15:33:45]
what actually we'll be explaining later

[15:33:43 - 15:33:47]
on guys so first of all try to see how

[15:33:45 - 15:33:49]
we can implement this production ready

[15:33:47 - 15:33:51]
project with the help of openi model and

[15:33:49 - 15:33:54]
there is another reason actually we are

[15:33:51 - 15:33:55]
using open model because if I uh let's

[15:33:54 - 15:33:56]
say if I'm using open source large

[15:33:55 - 15:33:58]
language model you will see that open

[15:33:56 - 15:34:00]
source large language model size would

[15:33:58 - 15:34:02]
be very huge let's say around 10 GB 20

[15:34:00 - 15:34:04]
GB and this model you can't execute in

[15:34:02 - 15:34:05]
your local uh machine that means your

[15:34:04 - 15:34:07]
loow configuration machine and if you're

[15:34:05 - 15:34:08]
deploying this project to the cloud

[15:34:07 - 15:34:10]
platform there you have to take good

[15:34:08 - 15:34:12]
instance that means you have to take GPU

[15:34:10 - 15:34:14]
based instance with higher Ram higher

[15:34:12 - 15:34:17]
CPU higher GPU and just try to consider

[15:34:14 - 15:34:18]
about the cost like how much how much

[15:34:17 - 15:34:20]
cost actually it will take that cloud

[15:34:18 - 15:34:21]
platform you can go to any kinds of

[15:34:20 - 15:34:23]
cloud platform you can see their

[15:34:21 - 15:34:26]
instance actually type if you're taking

[15:34:23 - 15:34:28]
GPU based instance type with higher Ram

[15:34:26 - 15:34:30]
higher let say CPU you'll see that per

[15:34:28 - 15:34:32]
hour it will cost you like more amount

[15:34:30 - 15:34:33]
of money okay so again you are

[15:34:32 - 15:34:34]
increasing the cost here whenever you

[15:34:33 - 15:34:36]
are using open source large language

[15:34:34 - 15:34:39]
model okay without any kinds of LM Ops

[15:34:36 - 15:34:40]
tool llm Ops platform you will get the

[15:34:39 - 15:34:43]
difficulty for sh right so that's why

[15:34:40 - 15:34:44]
we'll be using here openi model although

[15:34:43 - 15:34:46]
it will charge you but it will charge

[15:34:44 - 15:34:48]
you less than uh the open source model

[15:34:46 - 15:34:50]
actually you'll be hosting in future

[15:34:48 - 15:34:52]
okay this is the idea here so now what

[15:34:50 - 15:34:53]
will happen this uh rank results will go

[15:34:52 - 15:34:56]
to the

[15:34:53 - 15:34:58]
llm even this quy also will go to the

[15:34:56 - 15:35:00]
llm and llm will process L will try to

[15:34:58 - 15:35:01]
understand the query as well as the rank

[15:35:00 - 15:35:03]
results whatever results actually your

[15:35:01 - 15:35:04]
knowledge Bas is returning based on that

[15:35:03 - 15:35:07]
it will give you the correct response

[15:35:04 - 15:35:08]
okay correct response or you can talk

[15:35:07 - 15:35:10]
about answer correct answer let's say

[15:35:08 - 15:35:13]
you are asking one question let's say I

[15:35:10 - 15:35:14]
got fber what can I do so it will first

[15:35:13 - 15:35:17]
of all refer the knowledge base it will

[15:35:14 - 15:35:18]
try to find out the let's say fever

[15:35:17 - 15:35:21]
diagnosis fever medicine then with

[15:35:18 - 15:35:23]
respect to that it will give you the um

[15:35:21 - 15:35:24]
response got it so this is the entire

[15:35:23 - 15:35:27]
system actually will be implementing and

[15:35:24 - 15:35:29]
this is what actually our front end so

[15:35:27 - 15:35:33]
this is what actually our front

[15:35:29 - 15:35:34]
end many people also ask me like sir uh

[15:35:33 - 15:35:36]
just try to create some application with

[15:35:34 - 15:35:38]
the help of good front end development

[15:35:36 - 15:35:39]
as well so that's why I also kept this

[15:35:38 - 15:35:41]
front end development here we'll be

[15:35:39 - 15:35:42]
creating one beautiful user interface so

[15:35:41 - 15:35:44]
that user can give the quid here I think

[15:35:42 - 15:35:46]
you use the chat GPT chat GPT is having

[15:35:44 - 15:35:48]
one beautiful user interface okay so

[15:35:46 - 15:35:50]
we'll be also creating this kinds of

[15:35:48 - 15:35:51]
chatbot kinds of interface so that user

[15:35:50 - 15:35:53]
can give any kinds of query and they can

[15:35:51 - 15:35:55]
get the response fine so this is the

[15:35:53 - 15:35:57]
entire architecture of our project guys

[15:35:55 - 15:35:59]
okay I hope it is clear now now

[15:35:57 - 15:36:03]
technology wise I already told you here

[15:35:59 - 15:36:07]
we'll be using uh large language model

[15:36:03 - 15:36:10]
openi okay open LM we'll be using then

[15:36:07 - 15:36:12]
here we'll be using Lang chin as a

[15:36:10 - 15:36:14]
Genera VI framework to develop the

[15:36:12 - 15:36:16]
entire project then here we'll be using

[15:36:14 - 15:36:18]
Vector database why is Pine con okay

[15:36:16 - 15:36:20]
Pine con is a cloud uh cloud-based

[15:36:18 - 15:36:22]
Vector database okay so there actually

[15:36:20 - 15:36:25]
you can create a um instance and you can

[15:36:22 - 15:36:26]
store your vector and here to create the

[15:36:25 - 15:36:28]
user interface we'll be using something

[15:36:26 - 15:36:30]
called flask okay flask is a python

[15:36:28 - 15:36:34]
framework you can create web application

[15:36:30 - 15:36:36]
okay with that got it uh yeah so I hope

[15:36:34 - 15:36:38]
these are the actually technology we'll

[15:36:36 - 15:36:40]
be using as of now and if I need it

[15:36:38 - 15:36:42]
anything I'll tell you okay later on now

[15:36:40 - 15:36:44]
guys what I have to do guys uh first of

[15:36:42 - 15:36:47]
all let's create one uh yeah so let me

[15:36:44 - 15:36:48]
also write we'll be also using GitHub

[15:36:47 - 15:36:50]
okay GitHub to do the version

[15:36:48 - 15:36:52]
controlling of our entire application

[15:36:50 - 15:36:54]
fine and later on we'll be also

[15:36:52 - 15:36:56]
deploying this project to the AWS Cloud

[15:36:54 - 15:36:58]
okay AWS Cloud so we'll be learning

[15:36:56 - 15:37:01]
about the simple deployment

[15:36:58 - 15:37:03]
as well as the cicd

[15:37:01 - 15:37:05]
deployment okay both will be learning so

[15:37:03 - 15:37:07]
guys this is the entire agenda so now

[15:37:05 - 15:37:09]
let's open up our GitHub and try to

[15:37:07 - 15:37:11]
create one GitHub repository first of

[15:37:09 - 15:37:13]
all with our project then we'll be

[15:37:11 - 15:37:15]
starting with the implementation fine so

[15:37:13 - 15:37:17]
I'll go to my GitHub guys so this is my

[15:37:15 - 15:37:19]
GitHub you can also follow me here I

[15:37:17 - 15:37:21]
have created lots of repository that

[15:37:19 - 15:37:24]
might help you a lot so just go to the

[15:37:21 - 15:37:26]
repository and here uh create one new

[15:37:24 - 15:37:29]
repository and give the name let's to

[15:37:26 - 15:37:29]
create a med

[15:37:30 - 15:37:35]
I'll just write end to end okay medical

[15:37:32 - 15:37:36]
chatbot generate so this is myo name you

[15:37:35 - 15:37:38]
can give any repo name as for your

[15:37:36 - 15:37:40]
requirement now I'll be keeping as a

[15:37:38 - 15:37:42]
public repository because I want to uh

[15:37:40 - 15:37:43]
share this code with you so everyone can

[15:37:42 - 15:37:45]
see that I'll add the readme file as

[15:37:43 - 15:37:47]
well as I will add the dog ignore file

[15:37:45 - 15:37:49]
so here I'll be using Python Programming

[15:37:47 - 15:37:50]
I'll be selecting the python let's take

[15:37:49 - 15:37:51]
the license you can take any license

[15:37:50 - 15:37:55]
I'll be taking Amit license now

[15:37:51 - 15:37:55]
everything is fine now let's create the

[15:37:55 - 15:37:59]
repository okay now let's SC the

[15:37:57 - 15:38:01]
repository I'll copy the link address

[15:37:59 - 15:38:03]
make sure you selected HTTP 1 Now open

[15:38:01 - 15:38:05]
up your local folder so let me open up

[15:38:03 - 15:38:07]
my local folder and here I'll open up my

[15:38:05 - 15:38:09]
terminal you can open up your let's say

[15:38:07 - 15:38:11]
G bash you can open up your anacon

[15:38:09 - 15:38:13]
anything and just write the command G

[15:38:11 - 15:38:15]
clog and press the link here so it will

[15:38:13 - 15:38:17]
clone that repository in your local

[15:38:15 - 15:38:18]
machine now see it has clone now let me

[15:38:17 - 15:38:20]
go inside this folder you can see

[15:38:18 - 15:38:22]
currently I'm inside Lang chain project

[15:38:20 - 15:38:23]
okay now I want to go inside this folder

[15:38:22 - 15:38:25]
so I'll just write CD CD means change

[15:38:23 - 15:38:28]
directory I want to go inside end to end

[15:38:25 - 15:38:29]
medical chatboard gen this folder okay

[15:38:28 - 15:38:31]
now if I now if I hit enter you will see

[15:38:29 - 15:38:33]
that I'm inside this particular folder

[15:38:31 - 15:38:35]
right now now I'm inside this folder now

[15:38:33 - 15:38:38]
inside this folder I'm going to open up

[15:38:35 - 15:38:42]
my vs code so let's open up my vs code

[15:38:38 - 15:38:44]
so this is my vs code guys okay now let

[15:38:42 - 15:38:46]
me Zoom now the first thing guys what I

[15:38:44 - 15:38:47]
have to do I have to create uh one

[15:38:46 - 15:38:48]
virtual environment here because I

[15:38:47 - 15:38:50]
already told you if you are creating any

[15:38:48 - 15:38:52]
kinds of end to end project first of all

[15:38:50 - 15:38:53]
create a virtual environment then you

[15:38:52 - 15:38:55]
have to set up all the requirements you

[15:38:53 - 15:38:58]
need here so here let me add all the

[15:38:55 - 15:39:00]
step you need to perform M so here I

[15:38:58 - 15:39:02]
have added all the stem in the readme

[15:39:00 - 15:39:03]
file uh first of all you have to clone

[15:39:02 - 15:39:04]
the repository if you're using my

[15:39:03 - 15:39:06]
repository first of all clone it then

[15:39:04 - 15:39:08]
try to create the environment with this

[15:39:06 - 15:39:11]
command so make sure you using python

[15:39:08 - 15:39:13]
3.10 okay so I'll copy the command you

[15:39:11 - 15:39:15]
can give any name I have given LM app

[15:39:13 - 15:39:18]
you can give any name here fine so what

[15:39:15 - 15:39:21]
I can do I can I think use medical

[15:39:18 - 15:39:23]
medibot okay I can use medbot you can

[15:39:21 - 15:39:26]
use any name now let's create the

[15:39:23 - 15:39:26]
environment

[15:39:33 - 15:39:36]
so guys as you can see my environment is

[15:39:34 - 15:39:38]
created now let's activate for this you

[15:39:36 - 15:39:40]
have to execute this command all the

[15:39:38 - 15:39:42]
command I have shared in the RM file

[15:39:40 - 15:39:43]
just try to copy paste and I will also

[15:39:42 - 15:39:46]
push this code in my GitHub so that you

[15:39:43 - 15:39:47]
can see the changes now see medical Bo

[15:39:46 - 15:39:49]
has been activated fine now the next

[15:39:47 - 15:39:51]
thing we'll be creating one file called

[15:39:49 - 15:39:52]
requirement. txt file and inside that

[15:39:51 - 15:39:54]
I'll be mentioning all the requirements

[15:39:52 - 15:39:56]
I need and we'll be installing all the

[15:39:54 - 15:39:58]
requirements here so guys here are the

[15:39:56 - 15:39:59]
requirement list so these are the

[15:39:58 - 15:40:01]
requirements actually I need to

[15:39:59 - 15:40:03]
implement this uh project we'll be using

[15:40:01 - 15:40:06]
sentence Transformer because here we'll

[15:40:03 - 15:40:07]
be using open source embedding model to

[15:40:06 - 15:40:09]
generate the vector embedding so that's

[15:40:07 - 15:40:11]
why we'll be using sentence Transformer

[15:40:09 - 15:40:13]
and sentence Transformer uses actually

[15:40:11 - 15:40:15]
Transformer library that means it will

[15:40:13 - 15:40:17]
use hugging F platform hugging fist H to

[15:40:15 - 15:40:18]
download that model open source model

[15:40:17 - 15:40:20]
and with the help of that model actually

[15:40:18 - 15:40:22]
we can generate the vector embedding and

[15:40:20 - 15:40:24]
here I'm installing one specific version

[15:40:22 - 15:40:25]
you can also install the latest version

[15:40:24 - 15:40:28]
but this is the stable version I'm

[15:40:25 - 15:40:30]
installing so far then Lang I you know

[15:40:28 - 15:40:32]
Lang chain then flask we need for the

[15:40:30 - 15:40:34]
user interface then P PDF here we'll be

[15:40:32 - 15:40:35]
using PDF document that's why then

[15:40:34 - 15:40:39]
python. ENB why because here we'll be

[15:40:35 - 15:40:41]
managing one EnV file okay EnV file so

[15:40:39 - 15:40:43]
inside EnV file we'll be mentioning our

[15:40:41 - 15:40:45]
openi credential as well as the we'll be

[15:40:43 - 15:40:47]
also mentioning our Pine con credential

[15:40:45 - 15:40:49]
because Pine con you also need to use

[15:40:47 - 15:40:51]
one API key to authenticate with your

[15:40:49 - 15:40:52]
account fine then you can see I'm

[15:40:51 - 15:40:53]
installing Pine con and if you want to

[15:40:52 - 15:40:57]
install Pine con you need to install

[15:40:53 - 15:41:00]
this to library Pine con gr PC okay then

[15:40:57 - 15:41:02]
you you need to also install Lenore Pine

[15:41:00 - 15:41:04]
con then langen community langen openi

[15:41:02 - 15:41:05]
and langen experimental okay so these

[15:41:04 - 15:41:07]
are the dependency packet you also need

[15:41:05 - 15:41:10]
to install so let me install all of them

[15:41:07 - 15:41:12]
I'll just try to save I'll open up my uh

[15:41:10 - 15:41:15]
readme file I'll copy the

[15:41:12 - 15:41:16]
command and here I can execute now see

[15:41:15 - 15:41:18]
it will install all the package one by

[15:41:16 - 15:41:20]
one so it may take some time guys let's

[15:41:18 - 15:41:23]
wait once installation is completed I

[15:41:20 - 15:41:24]
will come back so guys as you can see my

[15:41:23 - 15:41:26]
installation is completed there is no

[15:41:24 - 15:41:27]
error that means congratulation you have

[15:41:26 - 15:41:29]
installed successfully everything now

[15:41:27 - 15:41:32]
let me minimize the screen and now let

[15:41:29 - 15:41:34]
me save everything yeah now see whenever

[15:41:32 - 15:41:36]
you are implementing any kinds of end to

[15:41:34 - 15:41:38]
end projects the first thing you have to

[15:41:36 - 15:41:43]
create the

[15:41:38 - 15:41:43]
project okay project folder

[15:41:43 - 15:41:47]
structure

[15:41:45 - 15:41:49]
struct structure okay this is very much

[15:41:47 - 15:41:50]
important guys that means you have to

[15:41:49 - 15:41:52]
create the entire project folder

[15:41:50 - 15:41:54]
structure like in which folder in which

[15:41:52 - 15:41:56]
file you have to write which function

[15:41:54 - 15:41:58]
okay that's how you have to create the

[15:41:56 - 15:42:00]
entire project folders structure and

[15:41:58 - 15:42:02]
again this is your uh actually let's say

[15:42:00 - 15:42:04]
design pipeline okay it's not like that

[15:42:02 - 15:42:05]
you have to follow my pipeline always

[15:42:04 - 15:42:07]
you have to follow my project folder

[15:42:05 - 15:42:09]
structure always if you feel like okay

[15:42:07 - 15:42:11]
this folder structure is good for you

[15:42:09 - 15:42:13]
you can use it just try to design with

[15:42:11 - 15:42:15]
respect to your project requirement with

[15:42:13 - 15:42:17]
respect to your let's say uh I mean

[15:42:15 - 15:42:19]
Choice okay no need to follow my one but

[15:42:17 - 15:42:20]
if you want to follow my one you can

[15:42:19 - 15:42:22]
also follow I usually prefer one project

[15:42:20 - 15:42:24]
folder structure okay so I'll be showing

[15:42:22 - 15:42:25]
you how we can implement this particular

[15:42:24 - 15:42:27]
project folder structure that means

[15:42:25 - 15:42:29]
automatically we be creating the project

[15:42:27 - 15:42:34]
fold structure here so here we'll be uh

[15:42:29 - 15:42:37]
creating one file so the file name is

[15:42:34 - 15:42:39]
template template. Pi okay this is going

[15:42:37 - 15:42:41]
to be a python file so this will create

[15:42:39 - 15:42:43]
the entire project template for me so

[15:42:41 - 15:42:44]
here only I need to give my one time

[15:42:43 - 15:42:47]
effort that means I'll be writing the

[15:42:44 - 15:42:48]
entire logic to create the structure

[15:42:47 - 15:42:49]
going forward whenever you want to

[15:42:48 - 15:42:50]
create any kinds of product for the

[15:42:49 - 15:42:52]
structure you can execute this file it

[15:42:50 - 15:42:53]
will automatically create otherwise what

[15:42:52 - 15:42:55]
will happen you have to manually create

[15:42:53 - 15:42:57]
it let's say you want to create a folder

[15:42:55 - 15:42:59]
you'll be clicking here you will give

[15:42:57 - 15:43:00]
the folder name let's say test okay then

[15:42:59 - 15:43:01]
I want to create another file inside

[15:43:00 - 15:43:03]
folder again you'll be opening this

[15:43:01 - 15:43:06]
folder inside that you'll be creating

[15:43:03 - 15:43:08]
another file let's say test. Pi okay so

[15:43:06 - 15:43:09]
this is like very time-taking task let's

[15:43:08 - 15:43:11]
say you want to create 100 of folders

[15:43:09 - 15:43:12]
100 of files just try to consider how

[15:43:11 - 15:43:14]
much time it will take even you have to

[15:43:12 - 15:43:16]
manually check everything whether this

[15:43:14 - 15:43:18]
file is present inside this folder or

[15:43:16 - 15:43:19]
not so it's not a efficient way to

[15:43:18 - 15:43:21]
create the folder structure okay you can

[15:43:19 - 15:43:22]
create it but I won't be suggesting you

[15:43:21 - 15:43:24]
because it will take lots of time so

[15:43:22 - 15:43:25]
what you can do you can create one

[15:43:24 - 15:43:28]
template file and a template file you

[15:43:25 - 15:43:29]
can write one very basic code and this

[15:43:28 - 15:43:31]
code will automatically create the

[15:43:29 - 15:43:33]
project folder structure for me let me

[15:43:31 - 15:43:35]
show you how we can create it so for

[15:43:33 - 15:43:37]
this I'm going to use some package I'll

[15:43:35 - 15:43:38]
using operating system package then I

[15:43:37 - 15:43:41]
also need something called path Li okay

[15:43:38 - 15:43:45]
so let me UT so from it is available

[15:43:41 - 15:43:47]
path Li input okay path I need the path

[15:43:45 - 15:43:49]
why I need the path I'll tell you later

[15:43:47 - 15:43:51]
on as of now let me import all of them

[15:43:49 - 15:43:53]
then I also need something called login

[15:43:51 - 15:43:55]
okay so login is inbuilt package inside

[15:43:53 - 15:43:56]
python so here I'll will also log the

[15:43:55 - 15:43:58]
information in my terminal fine so first

[15:43:56 - 15:44:00]
of first of all you have to create an

[15:43:58 - 15:44:02]
logging stream okay so basic loging

[15:44:00 - 15:44:03]
configuration you have to create so

[15:44:02 - 15:44:06]
that's how you can create a basic loging

[15:44:03 - 15:44:08]
configuration see okay this is the basic

[15:44:06 - 15:44:09]
login configuration so here you have to

[15:44:08 - 15:44:11]
write login. basic config inside that

[15:44:09 - 15:44:13]
you have to mention the log level first

[15:44:11 - 15:44:15]
of all so here I to create a information

[15:44:13 - 15:44:17]
label log and this is the format of my

[15:44:15 - 15:44:19]
log that means first of all it will save

[15:44:17 - 15:44:21]
the uh asky time that means the current

[15:44:19 - 15:44:23]
in uh time stamp like let's say whenever

[15:44:21 - 15:44:25]
you are executing your code it will save

[15:44:23 - 15:44:26]
that time stamp that means the time date

[15:44:25 - 15:44:28]
so it will save everything then after

[15:44:26 - 15:44:30]
that it will also save the log message

[15:44:28 - 15:44:31]
like like which message you want to show

[15:44:30 - 15:44:33]
okay it will also save that so whenever

[15:44:31 - 15:44:34]
I'll execute the code you will get it

[15:44:33 - 15:44:36]
okay what I have written here as of now

[15:44:34 - 15:44:40]
just try to consider you have to mention

[15:44:36 - 15:44:43]
this loging string here fine okay now

[15:44:40 - 15:44:44]
you have to give a list of the file you

[15:44:43 - 15:44:46]
want to create so let's say left hand

[15:44:44 - 15:44:48]
side I want to create some list of the

[15:44:46 - 15:44:50]
folders and file so for this I have

[15:44:48 - 15:44:52]
created a python list you can see so the

[15:44:50 - 15:44:54]
name of the list is list of the files

[15:44:52 - 15:44:57]
inside that I mentioned I want to create

[15:44:54 - 15:44:58]
a folder you can see folder name is SRC

[15:44:57 - 15:45:01]
okay so it will create a folder here

[15:44:58 - 15:45:02]
called SRC inside SRC I want to create a

[15:45:01 - 15:45:05]
file called init.py that means

[15:45:02 - 15:45:08]
underscore init.py and this is nothing

[15:45:05 - 15:45:09]
but my Constructor file if you already

[15:45:08 - 15:45:11]
familiar with OP concept I think you

[15:45:09 - 15:45:13]
know what is Constructor so Constructor

[15:45:11 - 15:45:15]
is nothing but it's a special method

[15:45:13 - 15:45:18]
it's a let's say the magic function it

[15:45:15 - 15:45:20]
can execute automatically inside op but

[15:45:18 - 15:45:23]
you can also create this is uh this

[15:45:20 - 15:45:24]
actually Constructor as a python file

[15:45:23 - 15:45:26]
okay so if you open up any kinds of n2n

[15:45:24 - 15:45:28]
project now let me show you so if you go

[15:45:26 - 15:45:32]
to any kinds of end repository let's say

[15:45:28 - 15:45:35]
if I open tensorflow

[15:45:32 - 15:45:37]
tensorflow uh GitHub it's a open source

[15:45:35 - 15:45:40]
project so I can also see the their code

[15:45:37 - 15:45:42]
implementation see they have

[15:45:40 - 15:45:44]
also uh follow the modular approach see

[15:45:42 - 15:45:45]
if I open any kinds of folder let's say

[15:45:44 - 15:45:48]
if I open Java folder or let's say

[15:45:45 - 15:45:49]
python folder now if you just go below

[15:45:48 - 15:45:52]
you'll see this Constructor file is

[15:45:49 - 15:45:53]
present here okay why because they have

[15:45:52 - 15:45:55]
created so many folders you can see so

[15:45:53 - 15:45:56]
many folders so many folders and inside

[15:45:55 - 15:45:58]
that they have created different

[15:45:56 - 15:46:00]
different python file so this folder

[15:45:58 - 15:46:01]
would be considered as the local package

[15:46:00 - 15:46:03]
that means they can also import some

[15:46:01 - 15:46:06]
functionality from this folder let's say

[15:46:03 - 15:46:07]
I want to UT uh let's say this one this

[15:46:06 - 15:46:10]
particular

[15:46:07 - 15:46:12]
function let's say this function input

[15:46:10 - 15:46:13]
graph dep what I need to do I need to

[15:46:12 - 15:46:17]
write so what I have to write I have to

[15:46:13 - 15:46:19]
write from tensor FL dot python okay

[15:46:17 - 15:46:21]
then dot this file and import I want to

[15:46:19 - 15:46:23]
this I want to import this function okay

[15:46:21 - 15:46:25]
that's how I need to import this file

[15:46:23 - 15:46:27]
that means instead of writing like all

[15:46:25 - 15:46:29]
the function in just one file what I'm

[15:46:27 - 15:46:30]
doing I'm creating a different different

[15:46:29 - 15:46:32]
folder okay different different let's

[15:46:30 - 15:46:34]
say component inside that I'm keeping

[15:46:32 - 15:46:36]
those functionality okay and whenever I

[15:46:34 - 15:46:38]
need it I'll be using it later on inside

[15:46:36 - 15:46:40]
my endpoint okay this is called actually

[15:46:38 - 15:46:42]
modular approach and to uh whenever you

[15:46:40 - 15:46:43]
are uh like following this modular

[15:46:42 - 15:46:45]
approach whenever you are creating this

[15:46:43 - 15:46:47]
kinds of folder to keep your function in

[15:46:45 - 15:46:49]
a file make sure you are creating this

[15:46:47 - 15:46:50]
Constructor file because this folder

[15:46:49 - 15:46:52]
would be considered as your local

[15:46:50 - 15:46:54]
package okay because later on you have

[15:46:52 - 15:46:56]
to import it let's say from tensorflow

[15:46:54 - 15:46:58]
do python import this function so

[15:46:56 - 15:47:00]
whenever you will will be importing uh

[15:46:58 - 15:47:02]
make sure your python interpreter will

[15:47:00 - 15:47:04]
consider this is my local environment

[15:47:02 - 15:47:05]
okay that's that means I can import

[15:47:04 - 15:47:07]
something from that folder this is the

[15:47:05 - 15:47:09]
IDE okay so that's why we are creating

[15:47:07 - 15:47:11]
this Constructor file because SRC is my

[15:47:09 - 15:47:13]
Lo folder inside that I'll be creating

[15:47:11 - 15:47:15]
one file called helper. Pi okay and

[15:47:13 - 15:47:16]
helper. Pi inside helper. Pi I'll be

[15:47:15 - 15:47:19]
writing all the

[15:47:16 - 15:47:21]
functionality let's say I want to inest

[15:47:19 - 15:47:22]
the data I want to let's say extract the

[15:47:21 - 15:47:23]
information I want to download the

[15:47:22 - 15:47:25]
hugging face model all the functionality

[15:47:23 - 15:47:27]
I'll be writing inside helper. Pi okay

[15:47:25 - 15:47:30]
this is the idea now apart from helper.

[15:47:27 - 15:47:33]
PI I need another file so inside SRC

[15:47:30 - 15:47:37]
I'll be creating another file called

[15:47:33 - 15:47:38]
prompt okay prompt. Pi inside that I'm

[15:47:37 - 15:47:40]
I'm going to write the prompt okay

[15:47:38 - 15:47:42]
prompt whatever prompt actually I need

[15:47:40 - 15:47:43]
the prompt let let's say whatever system

[15:47:42 - 15:47:46]
prompt I will be using inside that I can

[15:47:43 - 15:47:47]
write it here now I want to create a EnV

[15:47:46 - 15:47:49]
file then I want to create a

[15:47:47 - 15:47:51]
requirement. txt file oh sorry

[15:47:49 - 15:47:52]
requirement is already created I can

[15:47:51 - 15:47:54]
remove it as of now I don't need it I

[15:47:52 - 15:47:56]
want to get up setup.py file why setup.

[15:47:54 - 15:47:59]
P file because I want to install these

[15:47:56 - 15:48:01]
are the uh folder as my local package

[15:47:59 - 15:48:02]
for this I need setup. Pi okay

[15:48:01 - 15:48:04]
previously I think I already explained

[15:48:02 - 15:48:06]
this part then app.py then I want to

[15:48:04 - 15:48:08]
create a folder called research inside

[15:48:06 - 15:48:10]
that I want to create a jupyter notebook

[15:48:08 - 15:48:11]
file that means trials. i1b so inside

[15:48:10 - 15:48:12]
that first of all we'll be doing the

[15:48:11 - 15:48:14]
jupyter notebook experiment that means

[15:48:12 - 15:48:16]
the entire project will be implementing

[15:48:14 - 15:48:17]
through jupit notebook then we'll try to

[15:48:16 - 15:48:19]
convert everything as our modular coding

[15:48:17 - 15:48:22]
okay this is the idea so this is my list

[15:48:19 - 15:48:24]
of the files and folder I need now I

[15:48:22 - 15:48:26]
have written a simple python logic let

[15:48:24 - 15:48:28]
me show you guys it's not a very fancy

[15:48:26 - 15:48:30]
code code it's a simple python code I

[15:48:28 - 15:48:32]
have written so this code it will Loop

[15:48:30 - 15:48:34]
through this list one by one that means

[15:48:32 - 15:48:36]
it will Loop through this list one by

[15:48:34 - 15:48:39]
one see I'm looking through the list it

[15:48:36 - 15:48:40]
will give you the file path the entire

[15:48:39 - 15:48:42]
file path then you are giving this path

[15:48:40 - 15:48:44]
to the path function why you are giving

[15:48:42 - 15:48:46]
to the path function because see here

[15:48:44 - 15:48:47]
we're using Windows machine and windows

[15:48:46 - 15:48:50]
by default use backwards slash I think

[15:48:47 - 15:48:52]
you know see if I if I click here see

[15:48:50 - 15:48:54]
windows by default use backward slash

[15:48:52 - 15:48:56]
but which slash actually we're using

[15:48:54 - 15:48:58]
here we are using forward slash okay but

[15:48:56 - 15:49:01]
in Linux Mac actually uh they will be

[15:48:58 - 15:49:03]
using uh this forward slash but in

[15:49:01 - 15:49:05]
Windows you have to use backward slash

[15:49:03 - 15:49:07]
so that's why to uh I overcome this

[15:49:05 - 15:49:09]
issue we we are using path uh actually

[15:49:07 - 15:49:12]
path library from path leap see how it

[15:49:09 - 15:49:14]
will work so let me show you one example

[15:49:12 - 15:49:17]
so first of all I will open up my python

[15:49:14 - 15:49:20]
okay now here let me first of all import

[15:49:17 - 15:49:20]
so from path

[15:49:20 - 15:49:28]
Le okay

[15:49:24 - 15:49:30]
import PA

[15:49:28 - 15:49:33]
okay then let's define a path here so

[15:49:30 - 15:49:34]
I'll just write p is equal to test let's

[15:49:33 - 15:49:37]
say

[15:49:34 - 15:49:40]
slash uh T do PI okay let's say this is

[15:49:37 - 15:49:42]
my uh folder inside that I'm having one

[15:49:40 - 15:49:44]
file now what I will do okay it has

[15:49:42 - 15:49:46]
given me one error let me see the okay

[15:49:44 - 15:49:47]
so test is not defined that means I need

[15:49:46 - 15:49:50]
to give

[15:49:47 - 15:49:53]
inside double quotation because it's a

[15:49:50 - 15:49:55]
path now so this should be a string type

[15:49:53 - 15:49:59]
data

[15:49:55 - 15:50:01]
H now fine okay now if I give this P to

[15:49:59 - 15:50:03]
my path uh function now see what will

[15:50:01 - 15:50:05]
happen it will automatically detect my

[15:50:03 - 15:50:07]
operating system based on that it will

[15:50:05 - 15:50:09]
convert that part see it has given me

[15:50:07 - 15:50:10]
Windows path it has automatically

[15:50:09 - 15:50:11]
detected my operating system based on

[15:50:10 - 15:50:13]
that it will convert this part to the

[15:50:11 - 15:50:14]
windows path let's say you are using

[15:50:13 - 15:50:16]
Linux you are using Mac automatically

[15:50:14 - 15:50:17]
this path would be converted to that

[15:50:16 - 15:50:19]
operating system okay so that's why

[15:50:17 - 15:50:21]
instead of manually giving that path as

[15:50:19 - 15:50:22]
a backward SL what I can do I can give

[15:50:21 - 15:50:24]
to the path function path will

[15:50:22 - 15:50:26]
automatically take care that means we

[15:50:24 - 15:50:29]
can execute this project in any kinds of

[15:50:26 - 15:50:30]
op system okay otherwise uh in some of

[15:50:29 - 15:50:32]
the operating system you will might get

[15:50:30 - 15:50:34]
some issue okay that's why we have to

[15:50:32 - 15:50:36]
always handle these kinds of scenario

[15:50:34 - 15:50:37]
got it so whenever you are designing

[15:50:36 - 15:50:39]
your software make sure you are handling

[15:50:37 - 15:50:41]
the these kinds of scenario and you are

[15:50:39 - 15:50:44]
making your application more robust that

[15:50:41 - 15:50:45]
means in production it won't be failing

[15:50:44 - 15:50:47]
whenever it is failing in the production

[15:50:45 - 15:50:49]
this is not a robust application always

[15:50:47 - 15:50:51]
you need to take care then after that

[15:50:49 - 15:50:52]
what I'm doing I'm just splitting my

[15:50:51 - 15:50:55]
folder name as well as the file name

[15:50:52 - 15:50:59]
with the help of this actually function

[15:50:55 - 15:51:01]
so inside oper system path. spit so what

[15:50:59 - 15:51:03]
path. spit will do it will split your

[15:51:01 - 15:51:05]
folder name and your file name that

[15:51:03 - 15:51:07]
means inside this file directory it will

[15:51:05 - 15:51:09]
uh give the folder name inside the file

[15:51:07 - 15:51:11]
name it will give the file name only

[15:51:09 - 15:51:13]
okay so you can also execute and test so

[15:51:11 - 15:51:15]
let me show you so let's say this is my

[15:51:13 - 15:51:17]
path now so this is my folder and this

[15:51:15 - 15:51:21]
is my file now if I use first of all let

[15:51:17 - 15:51:24]
me import operating system so if I give

[15:51:21 - 15:51:27]
WS do path

[15:51:24 - 15:51:29]
doit okay inside that I'll give the P

[15:51:27 - 15:51:31]
now see if I hit enter it will give me

[15:51:29 - 15:51:33]
one couple see so in the first item it

[15:51:31 - 15:51:35]
should be my folder and the second item

[15:51:33 - 15:51:36]
it should be my file okay and this is

[15:51:35 - 15:51:39]
what actually I'm storing inside two

[15:51:36 - 15:51:42]
variable okay two variable I'm doing the

[15:51:39 - 15:51:45]
tole unpacking here okay I have C then

[15:51:42 - 15:51:46]
first of all I have to create the folder

[15:51:45 - 15:51:47]
okay I have to create the folder and to

[15:51:46 - 15:51:49]
create the folder I'm using w. make

[15:51:47 - 15:51:51]
directories so first of all I'm checking

[15:51:49 - 15:51:54]
whether this file directory it is empty

[15:51:51 - 15:51:55]
or not if it is not empty that means

[15:51:54 - 15:51:57]
definitely I have some file folder name

[15:51:55 - 15:51:59]
here so I'm Crea the folder you can see

[15:51:57 - 15:52:01]
then I'm performing the login operation

[15:51:59 - 15:52:03]
I'm just doing the login in my terminal

[15:52:01 - 15:52:05]
I'm telling creating a directory file

[15:52:03 - 15:52:06]
directory from the for the file of file

[15:52:05 - 15:52:08]
name okay this is the log message

[15:52:06 - 15:52:09]
actually I'm printing in my terminal

[15:52:08 - 15:52:12]
then after that I'm also creating the

[15:52:09 - 15:52:13]
file that means folder creation is done

[15:52:12 - 15:52:14]
then inside the folder I also need to

[15:52:13 - 15:52:15]
create the file for this I have written

[15:52:14 - 15:52:17]
this code actually first of all I have

[15:52:15 - 15:52:19]
to check whether this file path is exist

[15:52:17 - 15:52:21]
or not if it is not exist that means if

[15:52:19 - 15:52:22]
it is not created I have to create it

[15:52:21 - 15:52:24]
otherwise it is already created no I

[15:52:22 - 15:52:26]
don't need to create it and I also check

[15:52:24 - 15:52:28]
the size of the file PA that means the

[15:52:26 - 15:52:30]
it is zero or not let's see if it is not

[15:52:28 - 15:52:31]
zero that means inside that file I have

[15:52:30 - 15:52:33]
written some code so I don't need to

[15:52:31 - 15:52:34]
delete that file again let's say you

[15:52:33 - 15:52:35]
want to create again it only be

[15:52:34 - 15:52:37]
replacing that file instead of that it

[15:52:35 - 15:52:40]
will skip that file so that's why I also

[15:52:37 - 15:52:42]
checking the size if size is empty I'm

[15:52:40 - 15:52:44]
creating this file you can see and I'm

[15:52:42 - 15:52:46]
doing the long information otherwise I'm

[15:52:44 - 15:52:47]
telling this file is already exist okay

[15:52:46 - 15:52:50]
so this is the simple python code I have

[15:52:47 - 15:52:52]
written now see the power of this script

[15:52:50 - 15:52:54]
okay see the magic now left hand side

[15:52:52 - 15:52:57]
see there is nothing there is no folder

[15:52:54 - 15:52:59]
structure no file now if I

[15:52:57 - 15:53:02]
execute this script now see what will

[15:52:59 - 15:53:06]
happen I'll clear I'll simply execute

[15:53:02 - 15:53:08]
this template. Pi file see template. Pi

[15:53:06 - 15:53:11]
uh see automatically it will create the

[15:53:08 - 15:53:13]
folder structure for me got it so it's

[15:53:11 - 15:53:15]
just a one time effort guys you have to

[15:53:13 - 15:53:18]
like write this code only one time and

[15:53:15 - 15:53:18]
later on you can use it uh every time

[15:53:18 - 15:53:20]
let's say you want to create another

[15:53:18 - 15:53:22]
project copy this file write to execute

[15:53:20 - 15:53:23]
it will automatically create a folder

[15:53:22 - 15:53:26]
structure for you let's say in future I

[15:53:23 - 15:53:28]
need some more more actually let's say

[15:53:26 - 15:53:30]
uh folder or let a file let I need

[15:53:28 - 15:53:32]
another file called test.py I'll just

[15:53:30 - 15:53:35]
add it here make sure you are giving

[15:53:32 - 15:53:36]
inside a string okay and you are giving

[15:53:35 - 15:53:38]
a comma here because it's a list okay

[15:53:36 - 15:53:40]
now see I'll execute it again it will

[15:53:38 - 15:53:43]
automatically create that for me see

[15:53:40 - 15:53:44]
test. Pi is also created that's how you

[15:53:43 - 15:53:46]
can add as much as file and folder you

[15:53:44 - 15:53:47]
need okay it will automatically create

[15:53:46 - 15:53:50]
you don't need to manually create it

[15:53:47 - 15:53:52]
here okay this is the Advan to use this

[15:53:50 - 15:53:53]
template. P file guys okay I hope it is

[15:53:52 - 15:53:56]
clear now you can check it out since

[15:53:53 - 15:53:58]
resource this trial. i1b file is created

[15:53:56 - 15:53:59]
now inside SRC init created helper

[15:53:58 - 15:54:01]
created promp Created okay you can see

[15:53:59 - 15:54:04]
init created helper created promp

[15:54:01 - 15:54:05]
createdb also created app created setup

[15:54:04 - 15:54:07]
dop is created okay everything has

[15:54:05 - 15:54:10]
created so now let's set up our project

[15:54:07 - 15:54:12]
as my local package okay so for this

[15:54:10 - 15:54:14]
I'll be writing the setup.py code and

[15:54:12 - 15:54:16]
this is a simple code guys I think

[15:54:14 - 15:54:18]
previously I also shared so this is the

[15:54:16 - 15:54:20]
setup.py code first of all give the

[15:54:18 - 15:54:21]
project name that means uh the package

[15:54:20 - 15:54:23]
name you want to give let's say gener

[15:54:21 - 15:54:26]
project because if I show you currently

[15:54:23 - 15:54:28]
in my terminal uh inside my environment

[15:54:26 - 15:54:30]
this uh package is not present so I'll

[15:54:28 - 15:54:35]
just write P

[15:54:30 - 15:54:37]
list see genv project is not there okay

[15:54:35 - 15:54:38]
so I have to install as a gener project

[15:54:37 - 15:54:40]
okay for this we'll be using the

[15:54:38 - 15:54:41]
setup.py now give the version author

[15:54:40 - 15:54:44]
name email okay and find package we'll

[15:54:41 - 15:54:46]
try to find this underscore init.py and

[15:54:44 - 15:54:47]
whenever this init.py is present it will

[15:54:46 - 15:54:49]
consider this folder as my local package

[15:54:47 - 15:54:51]
okay let me show you now to install this

[15:54:49 - 15:54:55]
one you need to give one command inside

[15:54:51 - 15:54:57]
requirement. file called hypen e space

[15:54:55 - 15:55:00]
do okay HP in is space this is the

[15:54:57 - 15:55:03]
command now let me save now let me again

[15:55:00 - 15:55:03]
install the

[15:55:04 - 15:55:08]
requirements now see automatically it

[15:55:07 - 15:55:10]
will install as my local package now see

[15:55:08 - 15:55:12]
one EG info file would be created here

[15:55:10 - 15:55:14]
and whenever this EG info file is

[15:55:12 - 15:55:15]
created that means this uh project has

[15:55:14 - 15:55:20]
been set up as my local package let me

[15:55:15 - 15:55:20]
show you now if I again do the P list

[15:55:20 - 15:55:27]
operation now see Genera VI should be

[15:55:24 - 15:55:29]
there see gener VI POS is there now it

[15:55:27 - 15:55:30]
is my local package okay that means now

[15:55:29 - 15:55:33]
I can import anything from this SRC

[15:55:30 - 15:55:34]
itself got it so this is the entire idea

[15:55:33 - 15:55:37]
now let's commit the code in my GitHub

[15:55:34 - 15:55:38]
guys so for this I'm going to open up my

[15:55:37 - 15:55:40]
G

[15:55:38 - 15:55:42]
bash and here I'm going to write one

[15:55:40 - 15:55:45]
commment called G

[15:55:42 - 15:55:49]
ad then G

[15:55:45 - 15:55:53]
commit Ty a m now let's give one commit

[15:55:49 - 15:55:53]
message let's say folder stuct are

[15:55:55 - 15:56:01]
added then let's do the push operation

[15:55:58 - 15:56:01]
so get push

[15:56:02 - 15:56:05]
origin

[15:56:06 - 15:56:11]
main okay now it has pushed now if I

[15:56:08 - 15:56:14]
want to check let's go back our GitHub

[15:56:11 - 15:56:16]
now let's refresh now see it is pushed

[15:56:14 - 15:56:17]
in my GitHub and readme is also updated

[15:56:16 - 15:56:19]
now you can copy all the command and you

[15:56:17 - 15:56:22]
can execute in your system okay I hope

[15:56:19 - 15:56:23]
it is clear great now the first thing

[15:56:22 - 15:56:25]
we'll be doing the notebook experiment

[15:56:23 - 15:56:26]
okay first of all we'll be implementing

[15:56:25 - 15:56:28]
the entire project in our jup notebook

[15:56:26 - 15:56:29]
then we'll be converting as our modular

[15:56:28 - 15:56:31]
coding and after implementing jupyter

[15:56:29 - 15:56:32]
notebook only you just need to copy

[15:56:31 - 15:56:34]
paste operation okay that's it now first

[15:56:32 - 15:56:36]
of all let me select the Kel so I

[15:56:34 - 15:56:39]
already created one environment called

[15:56:36 - 15:56:42]
medbot okay so let's select it now let's

[15:56:39 - 15:56:43]
test whether this working or not so I'll

[15:56:42 - 15:56:46]
give one print statement let's say print

[15:56:43 - 15:56:48]
okay so this notebook should work now it

[15:56:46 - 15:56:50]
is telling just try to install some IP

[15:56:48 - 15:56:51]
1B cardal package so let me install

[15:56:50 - 15:56:53]
because I'm using jupyter notebook

[15:56:51 - 15:56:54]
inside my vs code for this you need some

[15:56:53 - 15:56:55]
additional package and it will

[15:56:54 - 15:56:57]
automatically install for you so it will

[15:56:55 - 15:56:58]
take some time after that you will see

[15:56:57 - 15:57:00]
that execution would be completed so

[15:56:58 - 15:57:02]
let's wait okay guys so as you can see

[15:57:00 - 15:57:05]
execution is completed and it is giving

[15:57:02 - 15:57:06]
me okay message okay it's fine now one

[15:57:05 - 15:57:08]
thing I just wanted to show you let's

[15:57:06 - 15:57:10]
say if I show you my project working

[15:57:08 - 15:57:13]
directory right now let's say

[15:57:10 - 15:57:16]
PWD so I'm inside this resarch folder

[15:57:13 - 15:57:19]
okay inside resarch folder but I want to

[15:57:16 - 15:57:20]
load my data and that my data would be

[15:57:19 - 15:57:22]
present inside my data folder let's say

[15:57:20 - 15:57:25]
I'll create a folder called Data okay

[15:57:22 - 15:57:27]
inside that I'm going to move the PDF

[15:57:25 - 15:57:28]
I'm having let me move quick quickly so

[15:57:27 - 15:57:31]
guys as you can see inside data folder

[15:57:28 - 15:57:32]
I'm having the PDF okay PDF document now

[15:57:31 - 15:57:34]
see whenever you are implementing any

[15:57:32 - 15:57:35]
project make sure you are working in the

[15:57:34 - 15:57:37]
project directory okay that means your

[15:57:35 - 15:57:38]
root project directory so this is my

[15:57:37 - 15:57:41]
root project directory but currently I'm

[15:57:38 - 15:57:43]
inside this resarch folder but if I want

[15:57:41 - 15:57:45]
to go get back okay inside my project

[15:57:43 - 15:57:47]
working directory so what I have to do I

[15:57:45 - 15:57:49]
have to execute one more command so let

[15:57:47 - 15:57:51]
me import operating system package

[15:57:49 - 15:57:52]
inside operting system you are having

[15:57:51 - 15:57:55]
something called change directory okay

[15:57:52 - 15:57:56]
let me show you so OS do CHD that mean

[15:57:55 - 15:57:58]
change directory

[15:57:56 - 15:58:01]
to hire one folder back so for this you

[15:57:58 - 15:58:03]
can write do slash okay dot do slash

[15:58:01 - 15:58:04]
means so do do slash means it will get

[15:58:03 - 15:58:07]
back one folder back okay let me show

[15:58:04 - 15:58:09]
you now if I execute now if I again show

[15:58:07 - 15:58:11]
you the PWD project working directory

[15:58:09 - 15:58:12]
now see I'm inside my root project

[15:58:11 - 15:58:14]
folder itself okay so that's how

[15:58:12 - 15:58:16]
actually you can check the folder

[15:58:14 - 15:58:19]
location first of all okay otherwise

[15:58:16 - 15:58:21]
what will happen you will get like path

[15:58:19 - 15:58:23]
issue sometimes you'll get let's a data

[15:58:21 - 15:58:24]
not found and so on okay so that to

[15:58:23 - 15:58:26]
prevent this issue actually make sure

[15:58:24 - 15:58:27]
you are working in the project folder

[15:58:26 - 15:58:29]
folder directory always okay this is the

[15:58:27 - 15:58:32]
Su I want to give you so first of all

[15:58:29 - 15:58:34]
let's import some of the library here so

[15:58:32 - 15:58:36]
here I'm importing uh Lang Chen from Len

[15:58:34 - 15:58:38]
actually I'm importing P PDF loader and

[15:58:36 - 15:58:39]
directory loader because I told you I

[15:58:38 - 15:58:41]
will be using PDF documents and to load

[15:58:39 - 15:58:43]
the PDF documents I need this P PDF

[15:58:41 - 15:58:44]
loader it is present inside a directory

[15:58:43 - 15:58:46]
okay that's why I've given directory

[15:58:44 - 15:58:47]
loader then I also need to perform

[15:58:46 - 15:58:49]
chunking operation and to perform the

[15:58:47 - 15:58:51]
sing operation I can use recursive

[15:58:49 - 15:58:52]
character text splitter okay I think you

[15:58:51 - 15:58:55]
already familiar with these other thing

[15:58:52 - 15:58:58]
now let me import all of them now here

[15:58:55 - 15:59:00]
to load the PDF here I have written a

[15:58:58 - 15:59:01]
function let me show you so this is the

[15:59:00 - 15:59:04]
function I have written guys okay

[15:59:01 - 15:59:05]
extract the data from the PDF itself so

[15:59:04 - 15:59:07]
the function name is load PDF it will

[15:59:05 - 15:59:09]
take the actually data directory okay

[15:59:07 - 15:59:11]
data directory and it will only load the

[15:59:09 - 15:59:12]
PDF documents okay it will only load the

[15:59:11 - 15:59:14]
PDF document let's say you want to load

[15:59:12 - 15:59:15]
the docs document txt document at that

[15:59:14 - 15:59:17]
time you can give the extension here

[15:59:15 - 15:59:19]
fine so with help of P PDF loader it

[15:59:17 - 15:59:21]
will extract the information from the

[15:59:19 - 15:59:23]
PDF itself okay and whatever uh let's

[15:59:21 - 15:59:25]
information it will extract it will give

[15:59:23 - 15:59:27]
give me as a documents okay you can see

[15:59:25 - 15:59:29]
now let me show you the let me execute

[15:59:27 - 15:59:31]
so it will return me extracted data so

[15:59:29 - 15:59:33]
here I've given the path okay so it

[15:59:31 - 15:59:36]
should be

[15:59:33 - 15:59:37]
data okay data directory now let me show

[15:59:36 - 15:59:39]
you so if I execute now see it is

[15:59:37 - 15:59:42]
extracting all the information from the

[15:59:39 - 15:59:43]
PDF itself and it is having almost 700

[15:59:42 - 15:59:44]
actually pages so it will take some time

[15:59:43 - 15:59:46]
so let's

[15:59:44 - 15:59:48]
wait so guys as you can see my

[15:59:46 - 15:59:50]
extraction is done now if I show you the

[15:59:48 - 15:59:52]
extracted data see this is the entire

[15:59:50 - 15:59:54]
extracted data actually you got okay

[15:59:52 - 15:59:58]
from all the pages it will show you the

[15:59:54 - 16:00:00]
data now let me comment it as of now H

[15:59:58 - 16:00:02]
now what I have to do I have to uh

[16:00:00 - 16:00:04]
perform the chunking operation because

[16:00:02 - 16:00:06]
you remember see the architecture I have

[16:00:04 - 16:00:08]
extracted the documents now I have to

[16:00:06 - 16:00:10]
perform the chunking operation okay and

[16:00:08 - 16:00:11]
to perform the chunking operation I will

[16:00:10 - 16:00:13]
be using recursive text splitter so with

[16:00:11 - 16:00:15]
that I have created another function

[16:00:13 - 16:00:17]
here so split the data into text chunks

[16:00:15 - 16:00:18]
so it will take the extracted data and

[16:00:17 - 16:00:22]
it will perform the chunking operation

[16:00:18 - 16:00:24]
you can see so here is the code so chunk

[16:00:22 - 16:00:26]
size is 5 500 and chunk over live is 20

[16:00:24 - 16:00:27]
I have given and it will perform the

[16:00:26 - 16:00:30]
chunking operation and it will give you

[16:00:27 - 16:00:33]
the chunk RS okay now let me show

[16:00:30 - 16:00:35]
you so now if I execute the function and

[16:00:33 - 16:00:39]
if I show you the length of the text

[16:00:35 - 16:00:42]
chunks now see you got

[16:00:39 - 16:00:45]
7,20 chunks here guys 7,20 chunks you

[16:00:42 - 16:00:47]
got just try to see how much data

[16:00:45 - 16:00:49]
actually you have in the PDF okay and

[16:00:47 - 16:00:51]
this is enough information to create one

[16:00:49 - 16:00:52]
medical chat B I believe that fine

[16:00:51 - 16:00:54]
that's why I have taken this big data

[16:00:52 - 16:00:57]
guys now see this is the inter CH

[16:00:54 - 16:01:01]
actually I got now what I have to do I

[16:00:57 - 16:01:02]
have to use one embedding model to like

[16:01:01 - 16:01:04]
perform the vector embedding and this

[16:01:02 - 16:01:05]
embedding I'll be storing to the

[16:01:04 - 16:01:07]
knowledge base that means inside my Pine

[16:01:05 - 16:01:09]
con Vector database okay so now let's

[16:01:07 - 16:01:11]
download one embedding model from the

[16:01:09 - 16:01:13]
hugging pH okay

[16:01:11 - 16:01:16]
so here is the function I have written

[16:01:13 - 16:01:18]
guys download H hugging face embedding

[16:01:16 - 16:01:20]
model now for this I need to import this

[16:01:18 - 16:01:22]
package first of all let me import so

[16:01:20 - 16:01:23]
this is the package guys hugging face

[16:01:22 - 16:01:26]
embedding I'm importing from the Lang

[16:01:23 - 16:01:28]
chain embedding okay now let me execute

[16:01:26 - 16:01:29]
H now this function will automatically

[16:01:28 - 16:01:31]
download one embedding model see this is

[16:01:29 - 16:01:33]
the embedding model I want to use let me

[16:01:31 - 16:01:35]
show you this embedding model so this is

[16:01:33 - 16:01:38]
present inside hugging phas so the name

[16:01:35 - 16:01:40]
of the model is all mini LM L6 V2 so

[16:01:38 - 16:01:43]
this is one actually embedding model and

[16:01:40 - 16:01:45]
it will give you Vector dimensional 384

[16:01:43 - 16:01:47]
Dimension four dimensional Vector

[16:01:45 - 16:01:49]
actually it will return you and this

[16:01:47 - 16:01:50]
Dimension you need because whenever you

[16:01:49 - 16:01:53]
are using pine con Vector database you

[16:01:50 - 16:01:55]
need to also mention the dimension of

[16:01:53 - 16:01:56]
the vector like like what is your vector

[16:01:55 - 16:01:58]
dimension whenever you are creating the

[16:01:56 - 16:01:59]
class turn now whenever you are creating

[16:01:58 - 16:02:00]
the index that time you have to mention

[16:01:59 - 16:02:02]
this Dimension so that's why always try

[16:02:00 - 16:02:04]
to remember whenever you are using pine

[16:02:02 - 16:02:06]
con Vector database try to see what

[16:02:04 - 16:02:08]
kinds of let's say embedding model you

[16:02:06 - 16:02:10]
are using and that embedding model uh

[16:02:08 - 16:02:11]
Returns what kinds of dimensional Vector

[16:02:10 - 16:02:14]
just try to see the documentation you

[16:02:11 - 16:02:16]
will al already get it fine now let me

[16:02:14 - 16:02:18]
download the embedding model so let me

[16:02:16 - 16:02:20]
execute this function I'll download the

[16:02:18 - 16:02:22]
embedding

[16:02:20 - 16:02:23]
model see it is downloading from the

[16:02:22 - 16:02:25]
hugging phase Hub so it will take some

[16:02:23 - 16:02:27]
time let's wait so guys you can see my

[16:02:25 - 16:02:30]
has downloaded okay now let's test the

[16:02:27 - 16:02:32]
model whether it is able to convert my

[16:02:30 - 16:02:34]
sentence to Vector embedding or not so

[16:02:32 - 16:02:36]
for this I have given one sentence here

[16:02:34 - 16:02:37]
hello world and there is a function

[16:02:36 - 16:02:38]
called embed query so it will

[16:02:37 - 16:02:40]
automatically give you the vector

[16:02:38 - 16:02:42]
embedding and I'm also checking the

[16:02:40 - 16:02:44]
length whether it is giving me 384

[16:02:42 - 16:02:46]
dimensional vector or not now see if I

[16:02:44 - 16:02:49]
execute the program now see length is

[16:02:46 - 16:02:50]
384 and if you want to see the vector

[16:02:49 - 16:02:52]
see this is the complete Vector actually

[16:02:50 - 16:02:55]
you got okay I hope it is clear now let

[16:02:52 - 16:02:57]
me comment this line as of now got it

[16:02:55 - 16:03:00]
now what I have to do guys I have to

[16:02:57 - 16:03:01]
initialize my pine cone uh inside Pine

[16:03:00 - 16:03:03]
con actually I have to store these are

[16:03:01 - 16:03:04]
the vector okay the complete Vector

[16:03:03 - 16:03:06]
actually I'll be generating from my TCH

[16:03:04 - 16:03:08]
CHS so for this let's open up my Pine

[16:03:06 - 16:03:11]
con so if you want to open up the pine

[16:03:08 - 16:03:13]
con just write Pine con. so this is the

[16:03:11 - 16:03:14]
website and make sure you created One

[16:03:13 - 16:03:16]
account guys just do the sign up

[16:03:14 - 16:03:17]
operation with your email address you

[16:03:16 - 16:03:19]
can create our account so for me I

[16:03:17 - 16:03:22]
already have one account let me login so

[16:03:19 - 16:03:24]
guys as you can see this is my Pine con

[16:03:22 - 16:03:25]
uh website okay this is the interface of

[16:03:24 - 16:03:27]
the pine con and this is one of the

[16:03:25 - 16:03:29]
amazing Vector database provider guys

[16:03:27 - 16:03:31]
you will be loving a lot even I

[16:03:29 - 16:03:33]
personally like it so here what I have

[16:03:31 - 16:03:34]
to do guys I have to create a index that

[16:03:33 - 16:03:36]
means I have to create a cluster in that

[16:03:34 - 16:03:38]
cluster actually I'll be saving all of

[16:03:36 - 16:03:40]
my Vector they have also given the quick

[16:03:38 - 16:03:43]
uh start like how we can set up the pine

[16:03:40 - 16:03:44]
cone how we can let's say stored the

[16:03:43 - 16:03:46]
data see all the code example they have

[16:03:44 - 16:03:48]
also given okay so we'll be following

[16:03:46 - 16:03:49]
the same approach to store our

[16:03:48 - 16:03:51]
embeddings to the Pine con but before

[16:03:49 - 16:03:52]
that you have to collect one API key so

[16:03:51 - 16:03:54]
how to collect the API key left hand

[16:03:52 - 16:03:56]
side you can see one API key option is

[16:03:54 - 16:03:57]
there just try to click here for me I

[16:03:56 - 16:03:59]
already created one API key if you don't

[16:03:57 - 16:04:00]
have just try to create API key just

[16:03:59 - 16:04:02]
give the name let's say I'll give test

[16:04:00 - 16:04:05]
or you can give any name let's create

[16:04:02 - 16:04:07]
the API key okay so this is the API key

[16:04:05 - 16:04:11]
now just try to copy the API key guys

[16:04:07 - 16:04:14]
and try to mention inside this.v file so

[16:04:11 - 16:04:16]
I'll open the EnV file so let me paste

[16:04:14 - 16:04:18]
it here and make sure you are giving one

[16:04:16 - 16:04:21]
key name here that means this is your

[16:04:18 - 16:04:23]
Pine con API key okay that's

[16:04:21 - 16:04:28]
it and make sure you are writing this

[16:04:23 - 16:04:30]
thing in a string got it h now let me

[16:04:28 - 16:04:32]
open up my trials. IP andv now what I

[16:04:30 - 16:04:34]
will do I'll just create a cluster here

[16:04:32 - 16:04:36]
so let me go back to the database and

[16:04:34 - 16:04:37]
don't share this key with anyone guys

[16:04:36 - 16:04:39]
otherwise they will be also able to

[16:04:37 - 16:04:41]
access your account okay I'll be

[16:04:39 - 16:04:43]
removing it after this recording so for

[16:04:41 - 16:04:45]
you don't need to share with anyone now

[16:04:43 - 16:04:47]
inside pine cone either you can manually

[16:04:45 - 16:04:49]
create the index let's say you can click

[16:04:47 - 16:04:52]
here create index let's create one index

[16:04:49 - 16:04:54]
let's say I want to create uh let's say

[16:04:52 - 16:04:57]
anything you can give test now Dimension

[16:04:54 - 16:04:58]
let's say 38 4 the same Dimension I will

[16:04:57 - 16:05:00]
give here the dimension actually I'm

[16:04:58 - 16:05:01]
getting cosine Matrix just keep it you

[16:05:00 - 16:05:03]
can also select different different

[16:05:01 - 16:05:05]
Matrix like what kinds of let's say

[16:05:03 - 16:05:07]
similarity Matrix it will apply whenever

[16:05:05 - 16:05:10]
it will do the semantic SCE operation I

[16:05:07 - 16:05:11]
want to use cosign score now now just

[16:05:10 - 16:05:14]
keep it everything as default you don't

[16:05:11 - 16:05:16]
need to change the provider see AWS is

[16:05:14 - 16:05:18]
the free one if you let's say sign up

[16:05:16 - 16:05:21]
for the first time you can create one to

[16:05:18 - 16:05:23]
two cluster here with the help of AWS

[16:05:21 - 16:05:24]
cloud provider but if you want to take

[16:05:23 - 16:05:26]
this premium subscription that means you

[16:05:24 - 16:05:27]
want to create a multiple class if you

[16:05:26 - 16:05:29]
want to take some more space you can see

[16:05:27 - 16:05:31]
see if you're using free plan you will

[16:05:29 - 16:05:32]
get 2 GB storage here but if you have

[16:05:31 - 16:05:34]
more than 2 GB data that time you have

[16:05:32 - 16:05:35]
to take the premium subscription okay

[16:05:34 - 16:05:37]
that time actually what you have to do

[16:05:35 - 16:05:40]
you have to take their plan subscription

[16:05:37 - 16:05:42]
plan let's see if I take this one uh

[16:05:40 - 16:05:43]
Google Cloud now see see the price plan

[16:05:42 - 16:05:45]
see this is the price plan actually they

[16:05:43 - 16:05:47]
have so with respect to that you can

[16:05:45 - 16:05:49]
also purchase their uh let's say machine

[16:05:47 - 16:05:51]
okay but as of now I'll be using the

[16:05:49 - 16:05:53]
free free services only I don't need the

[16:05:51 - 16:05:54]
let's say premium subscription of the

[16:05:53 - 16:05:56]
pine gon but if you are creating the

[16:05:54 - 16:05:57]
actual project if you need more spaces

[16:05:56 - 16:05:59]
that time you can do it so I'll be

[16:05:57 - 16:06:01]
selecting the AWS cloud provider and

[16:05:59 - 16:06:03]
Reon just keep it everything as default

[16:06:01 - 16:06:06]
only just need to give the name okay

[16:06:03 - 16:06:10]
name and a dimension that's

[16:06:06 - 16:06:12]
it 384 okay now let's create the index

[16:06:10 - 16:06:14]
so this is the manual approach to create

[16:06:12 - 16:06:15]
the index guys okay this is the manual

[16:06:14 - 16:06:17]
approach see this index is getting

[16:06:15 - 16:06:19]
created it is getting initialized and

[16:06:17 - 16:06:21]
once it is initialized see it would be

[16:06:19 - 16:06:22]
connected okay see it is now connected

[16:06:21 - 16:06:24]
okay now if you want to connect it you

[16:06:22 - 16:06:26]
can execute this python code and you can

[16:06:24 - 16:06:28]
insert your data all the conf code they

[16:06:26 - 16:06:30]
have already given okay but I don't want

[16:06:28 - 16:06:32]
to create this index manually I want to

[16:06:30 - 16:06:33]
create through the python code so let me

[16:06:32 - 16:06:35]
delete it so if you want to delete just

[16:06:33 - 16:06:38]
click here and try to delete the index

[16:06:35 - 16:06:38]
so you have to give the

[16:06:39 - 16:06:42]
name okay I'll be deleting because I

[16:06:41 - 16:06:45]
will be creating through the python code

[16:06:42 - 16:06:46]
and how to like create through the

[16:06:45 - 16:06:48]
python code guys I think they have

[16:06:46 - 16:06:51]
already given one starter code remember

[16:06:48 - 16:06:53]
so here you can give the uh index name

[16:06:51 - 16:06:56]
like which index you want to create and

[16:06:53 - 16:06:57]
create index Dimension you can give here

[16:06:56 - 16:06:59]
serverless AWS region okay everything

[16:06:57 - 16:07:01]
you can pass here so now let's use this

[16:06:59 - 16:07:04]
approach to create the index so what

[16:07:01 - 16:07:05]
I'll do I'll go back to my vs code and I

[16:07:04 - 16:07:07]
already prepared this code for you so

[16:07:05 - 16:07:09]
let me show you so this is the code only

[16:07:07 - 16:07:11]
you just need to change the API key so

[16:07:09 - 16:07:13]
let me change the API key the API key I

[16:07:11 - 16:07:16]
have collected here let me

[16:07:13 - 16:07:17]
copy and let me change it here or I

[16:07:16 - 16:07:19]
think I can read it from the environment

[16:07:17 - 16:07:21]
only so what I can do I can import the

[16:07:19 - 16:07:28]
environment just a minute so let's

[16:07:21 - 16:07:30]
import so from EnV import load EnV okay

[16:07:28 - 16:07:32]
then I will load the EnV now simply I'll

[16:07:30 - 16:07:35]
get this Pine con API key from my

[16:07:32 - 16:07:37]
environment and here it will save inside

[16:07:35 - 16:07:39]
this variable now this variable actually

[16:07:37 - 16:07:41]
I'll pass here okay so nobody won't be

[16:07:39 - 16:07:43]
able to see my API key that time so this

[16:07:41 - 16:07:44]
is the best approach guys you can also

[16:07:43 - 16:07:48]
follow now you can give the index name

[16:07:44 - 16:07:50]
let's say I give medical

[16:07:48 - 16:07:53]
bot medical bot let's say this is my

[16:07:50 - 16:07:56]
index name and here you have to give the

[16:07:53 - 16:07:58]
dimension so make sure which uh actually

[16:07:56 - 16:08:00]
U embedding model you are using and what

[16:07:58 - 16:08:03]
is the dimension size 384 that means

[16:08:00 - 16:08:06]
it's fine 384 keep everything as default

[16:08:03 - 16:08:07]
cosine s a US one okay no need to change

[16:08:06 - 16:08:10]
anything because we are using free uh

[16:08:07 - 16:08:11]
cluster here fine now once you will

[16:08:10 - 16:08:13]
execute this

[16:08:11 - 16:08:17]
code okay once you will execute this

[16:08:13 - 16:08:18]
code you will see that uh your U index

[16:08:17 - 16:08:20]
would be automatically created in the

[16:08:18 - 16:08:23]
pine let me show you so if I see if I

[16:08:20 - 16:08:25]
execute discode now see what will

[16:08:23 - 16:08:28]
happen so guys execution is done now if

[16:08:25 - 16:08:31]
I get back to my pine cone and if I

[16:08:28 - 16:08:34]
refresh it here see medical chatboard

[16:08:31 - 16:08:36]
should be created here let me show

[16:08:34 - 16:08:38]
you see medical chatbot is created

[16:08:36 - 16:08:40]
automatically it has created and now it

[16:08:38 - 16:08:43]
is active and running okay now what I

[16:08:40 - 16:08:45]
can do I can uh convert our uh let's say

[16:08:43 - 16:08:47]
chunks to the vector embedding and I can

[16:08:45 - 16:08:50]
store inside the pine con Vector

[16:08:47 - 16:08:52]
database so for this uh what I can do so

[16:08:50 - 16:08:55]
for this first of all set this fine cone

[16:08:52 - 16:08:56]
uh API key as an as your environment

[16:08:55 - 16:09:00]
variable

[16:08:56 - 16:09:02]
because uh whenever we'll be storing the

[16:09:00 - 16:09:04]
let's say data to the Pine con so Pine

[16:09:02 - 16:09:06]
cor internally looks for this API key

[16:09:04 - 16:09:07]
inside the environment variable okay so

[16:09:06 - 16:09:10]
for this we are using operating system

[16:09:07 - 16:09:12]
Environ okay Environ and this is the key

[16:09:10 - 16:09:14]
name guys I've giving and I'm setting my

[16:09:12 - 16:09:16]
Pine con API key okay whatever API key

[16:09:14 - 16:09:18]
I'm loading from myv file so it will set

[16:09:16 - 16:09:20]
inside my environment variable right now

[16:09:18 - 16:09:22]
okay so whenever I'll execute my Pine

[16:09:20 - 16:09:24]
con code I don't need to like again and

[16:09:22 - 16:09:25]
again pass it okay again and again I

[16:09:24 - 16:09:27]
don't need to pass it here this this is

[16:09:25 - 16:09:29]
the advantage now see to store the

[16:09:27 - 16:09:32]
vector embedding this is the Cod snippit

[16:09:29 - 16:09:34]
you have to execute guys so you can see

[16:09:32 - 16:09:37]
this is the code snipp

[16:09:34 - 16:09:40]
it let me comment

[16:09:37 - 16:09:42]
here now I'm importing langen Pine con

[16:09:40 - 16:09:44]
import Pine con Vector store okay now

[16:09:42 - 16:09:46]
inside Pine con vectory store you have

[16:09:44 - 16:09:47]
one function called from documents so

[16:09:46 - 16:09:48]
first of all you have to give the

[16:09:47 - 16:09:51]
documents that means the T chance the

[16:09:48 - 16:09:53]
Tex CHS I have created remember so this

[16:09:51 - 16:09:55]
is the text chunks I have created okay

[16:09:53 - 16:09:58]
so this text chunks you have to give

[16:09:55 - 16:09:59]
then you have to give the index name so

[16:09:58 - 16:10:00]
what is the index name I've given guys I

[16:09:59 - 16:10:02]
think remember this is the index name

[16:10:00 - 16:10:03]
that means this index name we it is

[16:10:02 - 16:10:05]
already created that means inside this

[16:10:03 - 16:10:07]
index it will store the data got it so

[16:10:05 - 16:10:09]
make sure you check this other the

[16:10:07 - 16:10:11]
variable now I need to give the

[16:10:09 - 16:10:12]
embedding model so I think remember we

[16:10:11 - 16:10:14]
downloaded one embedding model OKAY from

[16:10:12 - 16:10:16]
the hugging face out got it so this

[16:10:14 - 16:10:18]
three parameter you have to pass here

[16:10:16 - 16:10:21]
now see if I execute this line if I

[16:10:18 - 16:10:22]
execute this line it will convert all of

[16:10:21 - 16:10:25]
my data to the vector embedding and will

[16:10:22 - 16:10:27]
restore to the uh Pine con vector

[16:10:25 - 16:10:30]
database and how many chunks I got guys

[16:10:27 - 16:10:32]
I think remember I got 7,20 chunks that

[16:10:30 - 16:10:34]
means 7,20 chunks Vector will be P

[16:10:32 - 16:10:36]
stored inside my Pine con so it will

[16:10:34 - 16:10:39]
take some time guys let's wait after

[16:10:36 - 16:10:41]
execution after executing this code I'll

[16:10:39 - 16:10:43]
pause the video and once this Vector

[16:10:41 - 16:10:45]
will get stored in my Pine con I will

[16:10:43 - 16:10:46]
come back again see let me show you if I

[16:10:45 - 16:10:49]
go to my Pine con right now and if you

[16:10:46 - 16:10:50]
refresh the page here see all of the

[16:10:49 - 16:10:55]
vector would be stored here even you can

[16:10:50 - 16:10:55]
also see the count let me show you

[16:10:56 - 16:11:02]
see as of now

[16:10:59 - 16:11:04]
864 let's say chunks has been added now

[16:11:02 - 16:11:06]
see th now see you can also see the

[16:11:04 - 16:11:08]
visualization of the vector it's amazing

[16:11:06 - 16:11:09]
right so whenever you used to use local

[16:11:08 - 16:11:11]
Vector DV it was not possible to

[16:11:09 - 16:11:13]
visualize our Vector but here it is

[16:11:11 - 16:11:16]
possible you can see you can also see

[16:11:13 - 16:11:18]
the score that means um centic score

[16:11:16 - 16:11:20]
like what is the score between this

[16:11:18 - 16:11:21]
Vector this vector and this Vector got

[16:11:20 - 16:11:23]
it this is one amazing visualization

[16:11:21 - 16:11:24]
guys you will get in the pine cone and

[16:11:23 - 16:11:26]
see this is the entire Vector

[16:11:24 - 16:11:29]
representation of this entire sentence

[16:11:26 - 16:11:31]
okay entire text okay and even it is

[16:11:29 - 16:11:33]
also showing the page page number with

[16:11:31 - 16:11:35]
in which page it is extracting the data

[16:11:33 - 16:11:37]
and what is the PDF name as well okay

[16:11:35 - 16:11:39]
every information you can see here even

[16:11:37 - 16:11:40]
you can also perform the qud operation

[16:11:39 - 16:11:41]
that means the way you perform the SQL

[16:11:40 - 16:11:43]
qu you can also perform the quy

[16:11:41 - 16:11:44]
operation here manually everything is

[16:11:43 - 16:11:46]
possible but everything we'll be doing

[16:11:44 - 16:11:47]
through the python code I'm not going to

[16:11:46 - 16:11:50]
use the manual approach here now see the

[16:11:47 - 16:11:53]
vector count guys so

[16:11:50 - 16:11:56]
4, 120 Vector has been stored now let's

[16:11:53 - 16:11:57]
wait uh once it has saved all my all of

[16:11:56 - 16:11:59]
my Vector dor I'll come back and I'll

[16:11:57 - 16:12:01]
show you so guys as you can see my

[16:11:59 - 16:12:06]
execution is completed now if I get back

[16:12:01 - 16:12:06]
to my pine cone and if I

[16:12:11 - 16:12:16]
refresh see all of the vector it has

[16:12:14 - 16:12:19]
stored here like more than 7,000 Vector

[16:12:16 - 16:12:23]
it has stored inside my Pine con index

[16:12:19 - 16:12:24]
okay now what I can do I can use this uh

[16:12:23 - 16:12:26]
index as my knowledge base that means

[16:12:24 - 16:12:28]
we'll be connecting my large language

[16:12:26 - 16:12:30]
model with this knowledge base and will

[16:12:28 - 16:12:32]
be asking the query and it will do the

[16:12:30 - 16:12:34]
centic search operation here okay this

[16:12:32 - 16:12:37]
is the idea now let's get back to my

[16:12:34 - 16:12:40]
code editor now see I already created

[16:12:37 - 16:12:43]
the index and I already stored my Vector

[16:12:40 - 16:12:45]
there now I want to load my

[16:12:43 - 16:12:47]
existing

[16:12:45 - 16:12:49]
okay

[16:12:47 - 16:12:51]
existing

[16:12:49 - 16:12:53]
index if you want to load the IND

[16:12:51 - 16:12:56]
existing index what you can do you can

[16:12:53 - 16:12:56]
use this code cipit

[16:12:57 - 16:13:01]
okay see again I'm importing Pine con

[16:12:58 - 16:13:02]
Vector from Lang and pine con and there

[16:13:01 - 16:13:05]
is another function called from existing

[16:13:02 - 16:13:07]
index okay from existing index you have

[16:13:05 - 16:13:09]
to give the index name so the index name

[16:13:07 - 16:13:10]
I've given the same index name and you

[16:13:09 - 16:13:11]
have to pass the embedding model the

[16:13:10 - 16:13:14]
embedding model you have downloaded now

[16:13:11 - 16:13:16]
see if you execute this line of code it

[16:13:14 - 16:13:18]
will load the index that means whatever

[16:13:16 - 16:13:20]
index you have created and all the

[16:13:18 - 16:13:23]
vector actually it will load and will

[16:13:20 - 16:13:25]
give you the doc Source doc Source

[16:13:23 - 16:13:27]
object

[16:13:25 - 16:13:28]
okay this is on object doc Source object

[16:13:27 - 16:13:30]
now you can also perform the retrieve

[16:13:28 - 16:13:31]
operation here that me you can perform

[16:13:30 - 16:13:33]
the similarity Source operation here let

[16:13:31 - 16:13:35]
me show you one example there's a do as

[16:13:33 - 16:13:37]
reter search type similarity search

[16:13:35 - 16:13:38]
keyword three that means it will give

[16:13:37 - 16:13:40]
you three relevant answer let me show

[16:13:38 - 16:13:42]
you so if I initialize my ret object and

[16:13:40 - 16:13:45]
now I will ask one question

[16:13:42 - 16:13:47]
here so this is my medical data I will

[16:13:45 - 16:13:50]
ask let's say what

[16:13:47 - 16:13:52]
is

[16:13:50 - 16:13:55]
acne okay acne so I think you know

[16:13:52 - 16:13:57]
inside this PDF I'm having acne related

[16:13:55 - 16:14:00]
dis dis also let me show you so if I

[16:13:57 - 16:14:02]
press contrl F acne so guys as you can

[16:14:00 - 16:14:06]
see this is the acne disease what is

[16:14:02 - 16:14:08]
acne and all so you can see acne and AC

[16:14:06 - 16:14:09]
related actually treatment okay medicine

[16:14:08 - 16:14:11]
they have suggested each and everything

[16:14:09 - 16:14:14]
so I asking one question here so what is

[16:14:11 - 16:14:16]
acne it should give me the relevant uh

[16:14:14 - 16:14:17]
answer okay for the acne from my

[16:14:16 - 16:14:20]
knowledge base now let me execute and

[16:14:17 - 16:14:20]
let me show

[16:14:21 - 16:14:26]
you now see if I show you this Rel uh

[16:14:24 - 16:14:28]
retried docs it will give you three

[16:14:26 - 16:14:30]
results actually three results even it

[16:14:28 - 16:14:32]
is also showing the source okay from

[16:14:30 - 16:14:34]
where it is it has referred now see

[16:14:32 - 16:14:36]
different different actually uh acne

[16:14:34 - 16:14:38]
related response it has given me okay

[16:14:36 - 16:14:39]
because I have set SAR keyword is equal

[16:14:38 - 16:14:41]
to three it will only give me three

[16:14:39 - 16:14:43]
response okay but I don't need these

[16:14:41 - 16:14:46]
kinds of output I need a complete let's

[16:14:43 - 16:14:47]
say definition okay what is acne got it

[16:14:46 - 16:14:49]
so for this what I have to do guys I I

[16:14:47 - 16:14:50]
think you remember I have to integrate

[16:14:49 - 16:14:53]
my large language model that means here

[16:14:50 - 16:14:55]
we'll be working on user will give the

[16:14:53 - 16:14:57]
query this query will go to B knowledge

[16:14:55 - 16:14:58]
will give the rank results I'll be using

[16:14:57 - 16:15:01]
the large language model so LM will

[16:14:58 - 16:15:02]
process this rank results as well as the

[16:15:01 - 16:15:04]
qu and it will give me the correct

[16:15:02 - 16:15:06]
response okay so for this let's

[16:15:04 - 16:15:09]
initialize my model so I already told

[16:15:06 - 16:15:11]
you we'll be using openi model so openi

[16:15:09 - 16:15:12]
so let's initialize my open model and I

[16:15:11 - 16:15:14]
think you already know what is

[16:15:12 - 16:15:16]
temperature and Max token so it is

[16:15:14 - 16:15:18]
giving me one error okay it is giving me

[16:15:16 - 16:15:20]
error because I haven't set my open API

[16:15:18 - 16:15:23]
key so let's set the open API key I'll

[16:15:20 - 16:15:26]
open up my environment so here is my API

[16:15:23 - 16:15:28]
key guys so make sure you create one API

[16:15:26 - 16:15:30]
key and just try to paste here and

[16:15:28 - 16:15:32]
similar wise I also need to set this API

[16:15:30 - 16:15:34]
ke as in my environment variable okay so

[16:15:32 - 16:15:38]
let me execute this

[16:15:34 - 16:15:41]
code so here what I can do I can

[16:15:38 - 16:15:44]
duplicate this line and here I can write

[16:15:41 - 16:15:48]
open API

[16:15:44 - 16:15:51]
key so it will also give me my open API

[16:15:48 - 16:15:54]
key then here whenever I'm setting as an

[16:15:51 - 16:15:57]
environment here I can also change open

[16:15:54 - 16:16:00]
a key open I key okay now let's set this

[16:15:57 - 16:16:04]
one string expected non

[16:16:00 - 16:16:07]
time my okay so I think I have to load

[16:16:04 - 16:16:08]
it every uh again then I have to execute

[16:16:07 - 16:16:11]
now it should

[16:16:08 - 16:16:13]
work now it is working fine now if I get

[16:16:11 - 16:16:15]
back here now if I initialize it it

[16:16:13 - 16:16:17]
should work see successfully have

[16:16:15 - 16:16:18]
initialized my large language model now

[16:16:17 - 16:16:20]
I have to create the complete chain for

[16:16:18 - 16:16:22]
this let's import some Library

[16:16:20 - 16:16:24]
previously I showed you now how to

[16:16:22 - 16:16:26]
create the rag application there I think

[16:16:24 - 16:16:28]
you remember we were importing this uh

[16:16:26 - 16:16:30]
Library create T chain create stop

[16:16:28 - 16:16:32]
document chain okay create promp chat

[16:16:30 - 16:16:33]
promp template okay everything I already

[16:16:32 - 16:16:36]
showed you there so we are importing the

[16:16:33 - 16:16:39]
same code here now this is going to be

[16:16:36 - 16:16:41]
my system prompt so here I want to give

[16:16:39 - 16:16:43]
this prompt in my language model OKAY

[16:16:41 - 16:16:45]
large language model now I'm going to

[16:16:43 - 16:16:46]
create the complete prompt promp

[16:16:45 - 16:16:48]
template you can see this is the system

[16:16:46 - 16:16:50]
prompt and whatever input user will give

[16:16:48 - 16:16:51]
that means the input actually have given

[16:16:50 - 16:16:52]
it will come here and it will give you

[16:16:51 - 16:16:55]
the complete output now let me

[16:16:52 - 16:16:57]
initialize

[16:16:55 - 16:16:59]
now let's create my

[16:16:57 - 16:17:01]
chain so create aop chain inside that

[16:16:59 - 16:17:02]
you have to give the llm as well as the

[16:17:01 - 16:17:04]
prompt and whatever object you will get

[16:17:02 - 16:17:05]
in inside create Ral chain you have to

[16:17:04 - 16:17:07]
pass it as well as the r that means your

[16:17:05 - 16:17:10]
vector restore the vector restore you

[16:17:07 - 16:17:15]
created okay ret object now let's

[16:17:10 - 16:17:15]
initialize my chain now let's ask the

[16:17:15 - 16:17:21]
question so here I will give what is

[16:17:22 - 16:17:29]
acne okay what is acne sorry

[16:17:25 - 16:17:32]
acne now see see the response

[16:17:29 - 16:17:35]
guys see acne is a common skin disease

[16:17:32 - 16:17:39]
characterized by pulse on the face chest

[16:17:35 - 16:17:42]
and back it is caused by uh clogged

[16:17:39 - 16:17:44]
force and become inflamed due to the oil

[16:17:42 - 16:17:46]
dead skin cells okay and bacteria

[16:17:44 - 16:17:48]
treatment and so on see that means it

[16:17:46 - 16:17:50]
has given me the correct response if you

[16:17:48 - 16:17:53]
open the PDF now this book right now and

[16:17:50 - 16:17:54]
if you read it here you'll see that it

[16:17:53 - 16:17:57]
it has given me the correct response now

[16:17:54 - 16:17:59]
see if I giving any other question which

[16:17:57 - 16:18:01]
is not relevant about the PDF what will

[16:17:59 - 16:18:03]
happen see now see if I give any other

[16:18:01 - 16:18:04]
let's say question let's say I have

[16:18:03 - 16:18:07]
given what is stats that means what is

[16:18:04 - 16:18:09]
statistics it is telling me I don't know

[16:18:07 - 16:18:10]
because here I have given the prompt now

[16:18:09 - 16:18:12]
so if you if you're not getting the

[16:18:10 - 16:18:14]
context that means here this question

[16:18:12 - 16:18:16]
I'm asking this is out of context that

[16:18:14 - 16:18:18]
means the data I have given to my model

[16:18:16 - 16:18:20]
OKAY the knowledge B I have given uh to

[16:18:18 - 16:18:21]
my model so this information is not

[16:18:20 - 16:18:23]
available here so that's why it is

[16:18:21 - 16:18:26]
telling I don't know okay so this is the

[16:18:23 - 16:18:28]
complete custom uh actually system we

[16:18:26 - 16:18:30]
have created like custom chatbot we have

[16:18:28 - 16:18:32]
created which is only referring our

[16:18:30 - 16:18:34]
custom data okay I hope it is clear so

[16:18:32 - 16:18:36]
guys this is actually entire demo like

[16:18:34 - 16:18:38]
that's actually be implementing the

[16:18:36 - 16:18:39]
entire application now you can ask any

[16:18:38 - 16:18:42]
kinds of question let me show you so you

[16:18:39 - 16:18:43]
can take any other disas let me show you

[16:18:42 - 16:18:45]
or let's take any other disas okay let's

[16:18:43 - 16:18:48]
take these dis

[16:18:45 - 16:18:51]
actually this one I'll

[16:18:48 - 16:18:54]
copy and I'll come back here then I'll

[16:18:51 - 16:18:54]
ask here

[16:18:55 - 16:18:57]
now let's

[16:18:58 - 16:19:04]
see see uh it is giving you the response

[16:19:02 - 16:19:06]
growth hormones resulting the abnormal

[16:19:04 - 16:19:07]
growth okay see that means this is the

[16:19:06 - 16:19:09]
correct response actually I'm getting

[16:19:07 - 16:19:12]
now if you see the image so the same

[16:19:09 - 16:19:14]
thing okay so you can see um this

[16:19:12 - 16:19:17]
disease is a abnormal releases

[16:19:14 - 16:19:19]
particular chemical from the blah blah

[16:19:17 - 16:19:20]
blah okay so you can read it so that

[16:19:19 - 16:19:22]
means we are getting the correct

[16:19:20 - 16:19:24]
response fine now let's try to convert

[16:19:22 - 16:19:25]
this project as our end to end uh

[16:19:24 - 16:19:28]
implementation right now that means

[16:19:25 - 16:19:29]
we'll be also implementing the UI but

[16:19:28 - 16:19:31]
before that I have to first of all

[16:19:29 - 16:19:33]
create the modular coding okay so what

[16:19:31 - 16:19:36]
I'll do guys I will first of all open up

[16:19:33 - 16:19:38]
my helper dopy inside H.P whatever let's

[16:19:36 - 16:19:41]
say uh utility related code I have

[16:19:38 - 16:19:43]
written let's say loading the data then

[16:19:41 - 16:19:45]
U creating the chunks then loading the

[16:19:43 - 16:19:47]
embedding model all the function I'll

[16:19:45 - 16:19:49]
move inside this ala. Pi so let me open

[16:19:47 - 16:19:52]
so inside that I'm going to import all

[16:19:49 - 16:19:53]
of the library see I just copy pasted

[16:19:52 - 16:19:55]
the code from my notebook only if you

[16:19:53 - 16:19:56]
open the notebook the the same code

[16:19:55 - 16:19:58]
actually I'm composting and why is

[16:19:56 - 16:20:00]
giving the error because below you can

[16:19:58 - 16:20:02]
see I have to select my environment the

[16:20:00 - 16:20:03]
correct environment let's say medical B

[16:20:02 - 16:20:05]
now this error will be disappeared now

[16:20:03 - 16:20:06]
see all the function I'll just copy

[16:20:05 - 16:20:11]
paste here all the three function I have

[16:20:06 - 16:20:15]
written now my load PDF then uh this one

[16:20:11 - 16:20:17]
text split and this one my load

[16:20:15 - 16:20:20]
embedding model so here I kept all the

[16:20:17 - 16:20:21]
function you can see because I want to

[16:20:20 - 16:20:23]
import from here so these are the

[16:20:21 - 16:20:25]
function I don't want to create inside

[16:20:23 - 16:20:27]
my endpoint otherwise my code base would

[16:20:25 - 16:20:29]
be like messy right that's why I am

[16:20:27 - 16:20:31]
creating inside this particular file now

[16:20:29 - 16:20:33]
let me save and inside prompt actually

[16:20:31 - 16:20:34]
what I will do I'll give the system

[16:20:33 - 16:20:37]
prompt whatever prompt actually have

[16:20:34 - 16:20:38]
written so here is the prompt guys I

[16:20:37 - 16:20:43]
think you

[16:20:38 - 16:20:46]
remember I'll copy The Prompt and inside

[16:20:43 - 16:20:48]
prompt. Pi I'm going to mention it here

[16:20:46 - 16:20:50]
okay so from here I'm going to open the

[16:20:48 - 16:20:52]
prompt let's see in future use uh you

[16:20:50 - 16:20:53]
want to change the prompt you want to

[16:20:52 - 16:20:54]
give any other prompt you can open this

[16:20:53 - 16:20:56]
prom. P you can change here it will

[16:20:54 - 16:20:57]
reflect in your code okay no need to

[16:20:56 - 16:20:59]
open your actual code implementation

[16:20:57 - 16:21:01]
that time F so let me close this at the

[16:20:59 - 16:21:04]
tab as of now it's not

[16:21:01 - 16:21:06]
required now yeah so helper is fine now

[16:21:04 - 16:21:07]
what I will do I will create another

[16:21:06 - 16:21:10]
file

[16:21:07 - 16:21:13]
here and I will name it as

[16:21:10 - 16:21:16]
store underscore

[16:21:13 - 16:21:20]
index uh do

[16:21:16 - 16:21:21]
file okay file why because let's say you

[16:21:20 - 16:21:24]
want to update this book let's say you

[16:21:21 - 16:21:25]
want to add some more information that

[16:21:24 - 16:21:27]
time again you have to store all the

[16:21:25 - 16:21:28]
embeddings to the knowledge base that

[16:21:27 - 16:21:31]
means inside your Pine con yes or no

[16:21:28 - 16:21:33]
right and to store it I again need to

[16:21:31 - 16:21:36]
execute one like end point that means

[16:21:33 - 16:21:37]
store index. Pi whenever you will

[16:21:36 - 16:21:39]
execute it it will load the new

[16:21:37 - 16:21:41]
information and it will store to the

[16:21:39 - 16:21:43]
vector database again fine so for this

[16:21:41 - 16:21:45]
what I will do uh I'll prepare this one

[16:21:43 - 16:21:48]
so see whatever code I have written now

[16:21:45 - 16:21:50]
here that means I extracted my U let's

[16:21:48 - 16:21:52]
say documents I created the chunks

[16:21:50 - 16:21:54]
downloaded theing model after that I

[16:21:52 - 16:21:55]
pushed everything to my Vector database

[16:21:54 - 16:21:57]
okay see all the let's say Vector

[16:21:55 - 16:21:59]
database code I have written everything

[16:21:57 - 16:22:02]
I need to write inside dat month so let

[16:21:59 - 16:22:05]
me import all of the

[16:22:02 - 16:22:07]
library so you can see I'm importing

[16:22:05 - 16:22:10]
from SRC helper that means from SRC

[16:22:07 - 16:22:13]
helper so inside helper I'm having three

[16:22:10 - 16:22:15]
function load PDF then text split and

[16:22:13 - 16:22:18]
download Face embeddings okay see I'm

[16:22:15 - 16:22:20]
importing all of them Hing face

[16:22:18 - 16:22:22]
embedding okay then I'm also importing

[16:22:20 - 16:22:24]
Pine con then Pine con Vector store then

[16:22:22 - 16:22:27]
ladb and operating system first of all I

[16:22:24 - 16:22:30]
to set my environment variable that

[16:22:27 - 16:22:33]
means my credential okay openi sorry

[16:22:30 - 16:22:35]
Pine con API credential then I will be

[16:22:33 - 16:22:37]
loading my data extracting the data

[16:22:35 - 16:22:40]
creating the chunks then I'll be loading

[16:22:37 - 16:22:42]
the embedding model see load file that

[16:22:40 - 16:22:43]
means I'm loading the data so I have to

[16:22:42 - 16:22:44]
give the data location so this is my

[16:22:43 - 16:22:47]
data

[16:22:44 - 16:22:49]
location then Tex spitter will run then

[16:22:47 - 16:22:51]
download the embeding mod okay then

[16:22:49 - 16:22:54]
after that I will initialize my Pine con

[16:22:51 - 16:22:56]
code base the same code guys if you open

[16:22:54 - 16:22:59]
the the Jupiter notebook file the same

[16:22:56 - 16:23:01]
code see Pine con initialization it will

[16:22:59 - 16:23:02]
create the medical chat board okay

[16:23:01 - 16:23:06]
Medical Board that means this bot it

[16:23:02 - 16:23:08]
will create okay then uh it will

[16:23:06 - 16:23:11]
actually create the

[16:23:08 - 16:23:13]
index then it will store the embeddings

[16:23:11 - 16:23:14]
okay so at the very first time you have

[16:23:13 - 16:23:17]
to execute this line guys okay very

[16:23:14 - 16:23:19]
first time you have to execute this file

[16:23:17 - 16:23:20]
then uh whatever actually let's say data

[16:23:19 - 16:23:22]
you are having it will uh do the vector

[16:23:20 - 16:23:23]
conversion that means aing conversion

[16:23:22 - 16:23:25]
then it will store to the vector

[16:23:23 - 16:23:28]
database okay now what I'll do I'll just

[16:23:25 - 16:23:31]
delete my previous embeddings whatever I

[16:23:28 - 16:23:32]
created uh this uh cluster I want to

[16:23:31 - 16:23:35]
delete it because I now I'm doing the

[16:23:32 - 16:23:37]
modular coding now so I'll be executing

[16:23:35 - 16:23:39]
everything from my modular coding itself

[16:23:37 - 16:23:41]
now let me remove it now see it will

[16:23:39 - 16:23:42]
delete it after sometimes you'll see

[16:23:41 - 16:23:46]
that it won't be visible

[16:23:42 - 16:23:48]
here now see make sure guys before

[16:23:46 - 16:23:51]
launching your application first of all

[16:23:48 - 16:23:54]
you need to execute this store index. Pi

[16:23:51 - 16:23:56]
make sure this index should be created

[16:23:54 - 16:23:58]
other you won't be able to do the query

[16:23:56 - 16:23:59]
operation right so at the very first

[16:23:58 - 16:24:01]
time you have to execute this store

[16:23:59 - 16:24:03]
index. Pi okay then you will be

[16:24:01 - 16:24:05]
launching your application that means

[16:24:03 - 16:24:07]
app.py and this this one you have to

[16:24:05 - 16:24:09]
only execute one time not multiple time

[16:24:07 - 16:24:10]
multiple time when you will be executing

[16:24:09 - 16:24:12]
whenever you will update the data let's

[16:24:10 - 16:24:14]
you want to add any other data one more

[16:24:12 - 16:24:15]
PDF that time you'll be executing this

[16:24:14 - 16:24:19]
file okay otherwise just keep it as

[16:24:15 - 16:24:20]
default that's it now let me save now I

[16:24:19 - 16:24:23]
think this is deleted now see there is

[16:24:20 - 16:24:25]
nothing now what I'll do uh let me show

[16:24:23 - 16:24:28]
you how it will create everything so

[16:24:25 - 16:24:31]
I'll open up my terminal let me clear

[16:24:28 - 16:24:36]
now let's execute this store index. Pi

[16:24:31 - 16:24:36]
python store index. Pi now let's

[16:24:36 - 16:24:40]
execute see again it will perform all

[16:24:38 - 16:24:43]
the operation whatever things we have

[16:24:40 - 16:24:46]
done in the jupyter notebook so let's

[16:24:43 - 16:24:47]
wait after uh sometimes you'll see that

[16:24:46 - 16:24:51]
your uh index would be created and

[16:24:47 - 16:24:51]
inside index all the vector would be

[16:24:51 - 16:24:56]
stored so guys as you can see my uh

[16:24:54 - 16:24:59]
index is created now if I open it up

[16:24:56 - 16:25:01]
inside that uh now it will store the

[16:24:59 - 16:25:02]
embeddings one by one all the embeddings

[16:25:01 - 16:25:04]
it will save so guys as you can see my

[16:25:02 - 16:25:06]
execution is completed and it's it has

[16:25:04 - 16:25:09]
stored all of my Vector now that means

[16:25:06 - 16:25:12]
my um this store index is working fine

[16:25:09 - 16:25:13]
I'm successfully able to store my Vector

[16:25:12 - 16:25:16]
now let's create the Endo okay that

[16:25:13 - 16:25:18]
means my um I mean main application so

[16:25:16 - 16:25:20]
user will uh start this application

[16:25:18 - 16:25:22]
right now so here I already told you

[16:25:20 - 16:25:23]
we'll be using flask okay so here I

[16:25:22 - 16:25:26]
already told you we'll be using flask

[16:25:23 - 16:25:29]
here and if I'm using flask I need a

[16:25:26 - 16:25:31]
HTML and CSS code to create the um one

[16:25:29 - 16:25:32]
beautiful user interface so I already

[16:25:31 - 16:25:34]
created one HTML and CSS code for you

[16:25:32 - 16:25:35]
guys if you don't it's completely fine

[16:25:34 - 16:25:37]
again I'm telling you there are so many

[16:25:35 - 16:25:38]
template you will get over the Internet

[16:25:37 - 16:25:41]
there is a website called

[16:25:38 - 16:25:42]
bootstrap previously I also told you I

[16:25:41 - 16:25:46]
think

[16:25:42 - 16:25:47]
bootstrap okay bootstrap website so from

[16:25:46 - 16:25:49]
here you will get different different

[16:25:47 - 16:25:50]
example even you can also see different

[16:25:49 - 16:25:54]
different template it is having even if

[16:25:50 - 16:25:57]
you search like chatbot HTML

[16:25:54 - 16:26:00]
CSS free

[16:25:57 - 16:26:00]
template free

[16:26:00 - 16:26:04]
template you will get different

[16:26:02 - 16:26:06]
different actually template see

[16:26:04 - 16:26:08]
different different template you can

[16:26:06 - 16:26:09]
also download the source code you see

[16:26:08 - 16:26:11]
code is also visible you can also

[16:26:09 - 16:26:13]
download even you will get some weite

[16:26:11 - 16:26:14]
see different different chat template

[16:26:13 - 16:26:17]
okay different different chat template

[16:26:14 - 16:26:20]
you can use it okay it's up to you now

[16:26:17 - 16:26:21]
what I will do I'll uh quickly just show

[16:26:20 - 16:26:23]
you the HTML CSS code I have prepared

[16:26:21 - 16:26:25]
for this I think you know if you're

[16:26:23 - 16:26:27]
using flask you need to create one

[16:26:25 - 16:26:30]
folder here called

[16:26:27 - 16:26:34]
template okay templates so inside that

[16:26:30 - 16:26:34]
you have to create a file called

[16:26:36 - 16:26:41]
index.

[16:26:38 - 16:26:43]
HTML okay now let me show you my HTML

[16:26:41 - 16:26:44]
code I have prepared or it's a chatbot

[16:26:43 - 16:26:47]
what I can do I can name it as chat.

[16:26:44 - 16:26:51]
HTML okay chat. HTML now this is the

[16:26:47 - 16:26:53]
entire HTML code guys I prepared okay

[16:26:51 - 16:26:56]
save it now I need to create another

[16:26:53 - 16:26:58]
folder folder CSS called startic so

[16:26:56 - 16:27:01]
these are the requirement folder

[16:26:58 - 16:27:02]
folder um flask if you're using flask

[16:27:01 - 16:27:05]
inside python you need to create this

[16:27:02 - 16:27:09]
the folder inside

[16:27:05 - 16:27:14]
startic I'll be creating a file called

[16:27:09 - 16:27:17]
style do CSS okay now let me also paste

[16:27:14 - 16:27:18]
the CSS code I copyed from the internet

[16:27:17 - 16:27:21]
okay so this is one basic template I

[16:27:18 - 16:27:22]
created now whenever I will uh show you

[16:27:21 - 16:27:24]
my application you will see the user

[16:27:22 - 16:27:26]
interface whatever the user interface I

[16:27:24 - 16:27:28]
created now let me create my endpoint

[16:27:26 - 16:27:30]
app. Pi now inside app. Pi I'll be

[16:27:28 - 16:27:32]
integrating all of the functionality I

[16:27:30 - 16:27:34]
have prepared so far so first of all let

[16:27:32 - 16:27:38]
me all the requirement package all the

[16:27:34 - 16:27:39]
required package actually one by one so

[16:27:38 - 16:27:42]
here I'm using flask I have imported

[16:27:39 - 16:27:44]
flask from the flask I imported all the

[16:27:42 - 16:27:45]
required functionality you can see then

[16:27:44 - 16:27:47]
imported uh download hugging face

[16:27:45 - 16:27:49]
embedding model okay because I need the

[16:27:47 - 16:27:51]
embedding object to load my Vector

[16:27:49 - 16:27:54]
restore I think you know that I need to

[16:27:51 - 16:27:57]
load this not this actually Pine Con in

[16:27:54 - 16:27:58]
now so where is the pine Cod index so

[16:27:57 - 16:28:00]
here is the pine code index so I need to

[16:27:58 - 16:28:03]
load this index and to load this index

[16:28:00 - 16:28:05]
what I need I need the let's say this

[16:28:03 - 16:28:07]
one embedding object I think remember at

[16:28:05 - 16:28:09]
the last I showed you loading existing

[16:28:07 - 16:28:12]
index okay I think you need it okay I

[16:28:09 - 16:28:15]
think you remember fine so that is why I

[16:28:12 - 16:28:16]
have to U import it then I'm importing

[16:28:15 - 16:28:18]
you can see Pine code is store openi

[16:28:16 - 16:28:21]
rable keyway that means whatever let's

[16:28:18 - 16:28:23]
say I was loading here here these are

[16:28:21 - 16:28:25]
the thing I'm loading everything fine

[16:28:23 - 16:28:27]
then I also need to load my prompt so

[16:28:25 - 16:28:29]
prompt is available inside my prompt. Pi

[16:28:27 - 16:28:33]
here so I I can UT it so simply I can UT

[16:28:29 - 16:28:33]
just write prompt

[16:28:33 - 16:28:38]
SRC do prompt importar that means I want

[16:28:36 - 16:28:40]
to St everything inside that file okay

[16:28:38 - 16:28:44]
that's it then I also need something

[16:28:40 - 16:28:44]
called operating system so import

[16:28:44 - 16:28:49]
voice that's it now let me initialize my

[16:28:47 - 16:28:50]
flask to initialize the flask you have

[16:28:49 - 16:28:53]
to use this

[16:28:50 - 16:28:55]
code go to the flask documentation you

[16:28:53 - 16:28:58]
will get it now now let's set all of my

[16:28:55 - 16:28:59]
open and pine con environment okay for

[16:28:58 - 16:29:01]
this I need to use the clo in

[16:28:59 - 16:29:03]
environment

[16:29:01 - 16:29:05]
package that's

[16:29:03 - 16:29:07]
it then I will be downloading the

[16:29:05 - 16:29:11]
embedding model then I will uh first of

[16:29:07 - 16:29:14]
all initialize my embedding object then

[16:29:11 - 16:29:16]
I will load my existing uh index from my

[16:29:14 - 16:29:20]
Pine phone so let me show

[16:29:16 - 16:29:22]
you see the same code from The Notebook

[16:29:20 - 16:29:25]
I copied see so I'm loading the existing

[16:29:22 - 16:29:28]
index I'm made B make sure name is

[16:29:25 - 16:29:30]
correct medical B yeah it's

[16:29:28 - 16:29:32]
correct then it will give me the

[16:29:30 - 16:29:34]
retriever object then I'm loading the

[16:29:32 - 16:29:36]
open a model then creating the promp

[16:29:34 - 16:29:38]
template then after that I'm creating

[16:29:36 - 16:29:41]
the chain okay now I have to create two

[16:29:38 - 16:29:42]
route exactly first route would be my

[16:29:41 - 16:29:44]
default route that means user will get

[16:29:42 - 16:29:47]
the interface of my application chat.

[16:29:44 - 16:29:49]
HTML would be rendered got it now second

[16:29:47 - 16:29:51]
route I'll be doing for the chat

[16:29:49 - 16:29:53]
operation that means user is giving any

[16:29:51 - 16:29:55]
query to the chatbot so that message

[16:29:53 - 16:29:57]
actually will be accepting and this

[16:29:55 - 16:29:58]
message I will give to my llm okay that

[16:29:57 - 16:30:00]
means you can see I'm doing the inbo

[16:29:58 - 16:30:03]
operation okay so same inbo operation

[16:30:00 - 16:30:03]
I'm performing let me show

[16:30:04 - 16:30:09]
you so here is the invoc operation

[16:30:07 - 16:30:11]
remember okay

[16:30:09 - 16:30:12]
invok and whatever response I'm getting

[16:30:11 - 16:30:15]
I'm printing it as well as I'm showing

[16:30:12 - 16:30:17]
in in my uh that user interface okay

[16:30:15 - 16:30:20]
that's it now let me execute my

[16:30:17 - 16:30:22]
application so I'm running on my Local

[16:30:20 - 16:30:23]
Host port number 80 de is equal to r

[16:30:22 - 16:30:25]
that means if you change anything it

[16:30:23 - 16:30:27]
will automatically update everything so

[16:30:25 - 16:30:31]
now let me show you my application so

[16:30:27 - 16:30:33]
let's open up my terminal so I'll just

[16:30:31 - 16:30:36]
execute python

[16:30:33 - 16:30:39]
app.py sorry it should be python

[16:30:36 - 16:30:41]
spelling is not cor python okay now it

[16:30:39 - 16:30:41]
should be

[16:30:46 - 16:30:52]
running now see just give the allow

[16:30:49 - 16:30:55]
permission now see your application is

[16:30:52 - 16:30:57]
running now let's open up our Google uh

[16:30:55 - 16:30:59]
Google Chrome search for local host port

[16:30:57 - 16:31:01]
number 8080 see guys this is the

[16:30:59 - 16:31:03]
interface we have created and this is

[16:31:01 - 16:31:05]
one amazing uh interface guys you can

[16:31:03 - 16:31:07]
see amazing um chat template we have

[16:31:05 - 16:31:09]
created uh because many people have

[16:31:07 - 16:31:10]
requested me just try to create one

[16:31:09 - 16:31:12]
front end part of our application as

[16:31:10 - 16:31:14]
well beautiful front end part and that's

[16:31:12 - 16:31:16]
how we can create a beautiful front end

[16:31:14 - 16:31:17]
part now here you can ask any kinds of

[16:31:16 - 16:31:22]
question let's say I will ask the same

[16:31:17 - 16:31:22]
question I'll ask what is acting

[16:31:24 - 16:31:29]
the acne is a common uh skin disease by

[16:31:27 - 16:31:30]
characteristic by pimples on the face

[16:31:29 - 16:31:33]
fine then I will ask another question

[16:31:30 - 16:31:37]
let's say I got

[16:31:33 - 16:31:39]
fever what should I do see now this is

[16:31:37 - 16:31:40]
the response if you are experiencing

[16:31:39 - 16:31:47]
high fever it is important to seek the

[16:31:40 - 16:31:47]
medical attention Okay so tell me some

[16:31:50 - 16:31:54]
medicine now see it is also suggesting

[16:31:52 - 16:31:57]
some medicine okay related fever now you

[16:31:54 - 16:31:58]
can ask any kinds of question from the

[16:31:57 - 16:32:00]
let's say PDF itself any kinds of

[16:31:58 - 16:32:03]
disease you can ask let's say this is

[16:32:00 - 16:32:05]
the disease I want to ask I'll just copy

[16:32:03 - 16:32:08]
and here I'll just write what is this

[16:32:05 - 16:32:08]
dision all

[16:32:09 - 16:32:14]
about see it has uh given me the

[16:32:12 - 16:32:16]
response okay now you can read this uh I

[16:32:14 - 16:32:18]
mean PDF and you can see that you can

[16:32:16 - 16:32:20]
ask the medicine uh you can ask for the

[16:32:18 - 16:32:22]
treatment anything you can ask so this

[16:32:20 - 16:32:24]
is our chatbot guys this is our medical

[16:32:22 - 16:32:26]
chatboard we have created and see it is

[16:32:24 - 16:32:29]
also giving you the one beautiful user

[16:32:26 - 16:32:30]
interface okay it is also returning now

[16:32:29 - 16:32:32]
what we'll do we just try to also deploy

[16:32:30 - 16:32:33]
this application guys but before that

[16:32:32 - 16:32:35]
we'll be implementing some more end

[16:32:33 - 16:32:37]
projects then after that I'll uh keep

[16:32:35 - 16:32:39]
one uh dedicated end to end let's say

[16:32:37 - 16:32:40]
deployment session there I'll show you

[16:32:39 - 16:32:43]
how we can deploy these are the project

[16:32:40 - 16:32:44]
on the cloud platform okay so yes guys I

[16:32:43 - 16:32:46]
hope you liked it but before that what I

[16:32:44 - 16:32:48]
will do guys I will comment these are

[16:32:46 - 16:32:49]
the code in my GitHub so you can also

[16:32:48 - 16:32:55]
comit from the vs code let's comit from

[16:32:49 - 16:32:55]
here light um updated

[16:32:55 - 16:32:57]
let's

[16:33:04 - 16:33:09]
comit and VMV file would be

[16:33:06 - 16:33:10]
automatically ignored by the git ignore

[16:33:09 - 16:33:12]
okay because inside git ignore you have

[16:33:10 - 16:33:14]
already mentioned it do git ignore would

[16:33:12 - 16:33:16]
be ignored see would be ignored okay so

[16:33:14 - 16:33:19]
it w be published inside my GitHub now

[16:33:16 - 16:33:19]
if I open up my

[16:33:19 - 16:33:24]
GitHub now if I

[16:33:21 - 16:33:27]
refresh see all the code has been

[16:33:24 - 16:33:29]
updated now I can write the further uh

[16:33:27 - 16:33:31]
let's step as well in the read me file

[16:33:29 - 16:33:33]
okay so I have added all the step like

[16:33:31 - 16:33:35]
after that what you have to do uh after

[16:33:33 - 16:33:38]
that you can uh set your uh uh

[16:33:35 - 16:33:41]
environment key then run store index

[16:33:38 - 16:33:42]
then app.py then you just need to local

[16:33:41 - 16:33:45]
up open up your local list okay now let

[16:33:42 - 16:33:47]
me comment the changes as well so read

[16:33:45 - 16:33:50]
me

[16:33:47 - 16:33:52]
updated and make sure guys you start

[16:33:50 - 16:33:54]
this uh repository all of you start this

[16:33:52 - 16:33:59]
repository you can also for so that you

[16:33:54 - 16:33:59]
will have the reference okay now if I

[16:33:59 - 16:34:03]
refresh now see readme is updated and

[16:34:01 - 16:34:05]
you can see all the step I have also

[16:34:03 - 16:34:07]
added that's how you can also prepare

[16:34:05 - 16:34:09]
your read me file so that so that if

[16:34:07 - 16:34:11]
other people is referring your let's say

[16:34:09 - 16:34:13]
GitHub they will be also able to set up

[16:34:11 - 16:34:15]
this code okay in their system as well

[16:34:13 - 16:34:16]
fine so yes guys this is the complete

[16:34:15 - 16:34:18]
implementation I hope you liked it so

[16:34:16 - 16:34:20]
that's how we can create any kinds of

[16:34:18 - 16:34:21]
end to end gener VI B project fine and

[16:34:20 - 16:34:23]
don't need to worry I'll also show you

[16:34:21 - 16:34:25]
the deployment even we'll be also

[16:34:23 - 16:34:27]
discussing about LM Ops uh with the help

[16:34:25 - 16:34:29]
of LMS also we'll be learning how we can

[16:34:27 - 16:34:31]
access any kind of Open Source large

[16:34:29 - 16:34:32]
language model okay as a hosted open

[16:34:31 - 16:34:34]
source large language model we can use

[16:34:32 - 16:34:36]
it so yes guys this is all about from

[16:34:34 - 16:34:38]
this video if you liked it so please uh

[16:34:36 - 16:34:39]
try to subscribe to the Channel Try to

[16:34:38 - 16:34:40]
like it and try to share it video will

[16:34:39 - 16:34:43]
be implementing another end to end

[16:34:40 - 16:34:45]
projects called source code analysis so

[16:34:43 - 16:34:46]
here we'll be using Lang chain Vector

[16:34:45 - 16:34:48]
database large language model even I

[16:34:46 - 16:34:50]
will also show you how we can create a

[16:34:48 - 16:34:52]
Content application of the entire

[16:34:50 - 16:34:53]
projects so uh this is going to be

[16:34:52 - 16:34:55]
completely end to end implementation

[16:34:53 - 16:34:57]
guys so I think in our previous video I

[16:34:55 - 16:34:59]
already showed you one NN implementation

[16:34:57 - 16:35:00]
we implemented one medical chatbot so

[16:34:59 - 16:35:02]
here we'll be following the same uh

[16:35:00 - 16:35:04]
actually process to implement this

[16:35:02 - 16:35:05]
project as well fine and what is source

[16:35:04 - 16:35:07]
code analysis I'll tell you I'll show

[16:35:05 - 16:35:09]
you the entire architecture diagram of

[16:35:07 - 16:35:10]
this project then I will start the

[16:35:09 - 16:35:12]
implementation so first of all what I

[16:35:10 - 16:35:15]
will show you guys uh I will show you

[16:35:12 - 16:35:16]
the GitHub repository uh creation after

[16:35:15 - 16:35:18]
uh creating the GitHub repository we'll

[16:35:16 - 16:35:20]
be making all the setups then we'll

[16:35:18 - 16:35:21]
start the implementation so let's open

[16:35:20 - 16:35:23]
up our GitHub and let's create one

[16:35:21 - 16:35:26]
GitHub repository for this so guys as

[16:35:23 - 16:35:27]
you can see I'm inside my GitHub so here

[16:35:26 - 16:35:30]
I'm going to create a new

[16:35:27 - 16:35:32]
repository and I'm going to name it as n

[16:35:30 - 16:35:32]
to

[16:35:33 - 16:35:38]
end source code analysis gener API fine

[16:35:37 - 16:35:40]
so let's keep it as public repository

[16:35:38 - 16:35:42]
I'll select the rme file and I'll will

[16:35:40 - 16:35:45]
also take the G ignore wise

[16:35:42 - 16:35:49]
python then let's take the license I'll

[16:35:45 - 16:35:49]
take MIT license now let's create the

[16:35:49 - 16:35:53]
repository so after that I have to clone

[16:35:52 - 16:35:55]
it so I'll copy the link address I will

[16:35:53 - 16:35:57]
open up my local folder and here I'm

[16:35:55 - 16:36:00]
going to open up my git

[16:35:57 - 16:36:04]
bash now let's write the command git

[16:36:00 - 16:36:07]
clone and press the link that's

[16:36:04 - 16:36:09]
it see it has cloned the repository okay

[16:36:07 - 16:36:11]
now I want to go inside this repository

[16:36:09 - 16:36:14]
I'll just write CD that means change

[16:36:11 - 16:36:16]
directory to my end to end okay uh

[16:36:14 - 16:36:18]
source code

[16:36:16 - 16:36:20]
analysis now I'm inside this folder now

[16:36:18 - 16:36:24]
inside this folder let's open up our uh

[16:36:20 - 16:36:26]
vs code so let me open up my vs code

[16:36:24 - 16:36:29]
so here is my V code so guys I think you

[16:36:26 - 16:36:30]
remember uh the first thing we create a

[16:36:29 - 16:36:32]
virtual environment okay for a new

[16:36:30 - 16:36:33]
project so let's create a virtual

[16:36:32 - 16:36:34]
environment for this you need to follow

[16:36:33 - 16:36:36]
some of the commands so let me mention

[16:36:34 - 16:36:38]
in the readme file so you can see these

[16:36:36 - 16:36:40]
are the step we have to follow so first

[16:36:38 - 16:36:41]
of all if you're using my repository

[16:36:40 - 16:36:43]
first of all clone it then try to create

[16:36:41 - 16:36:46]
an environment with the help of python

[16:36:43 - 16:36:48]
3.10 so that environment name is llm m

[16:36:46 - 16:36:49]
so for me uh what I have done guys I

[16:36:48 - 16:36:51]
already created the environment in my

[16:36:49 - 16:36:53]
system so I'll just activate the

[16:36:51 - 16:36:54]
environment but for you if you don't

[16:36:53 - 16:36:56]
have the environment just try to create

[16:36:54 - 16:36:58]
it so let me show you my environment

[16:36:56 - 16:37:01]
I'll just write cond activate LM see it

[16:36:58 - 16:37:02]
is already there for me okay now the

[16:37:01 - 16:37:04]
next thing what I have to do I have to

[16:37:02 - 16:37:06]
set up the requirements of the projects

[16:37:04 - 16:37:08]
okay so for this I'm I'm going to create

[16:37:06 - 16:37:11]
a file called requirement.

[16:37:08 - 16:37:13]
txt inside that I'm going to mention all

[16:37:11 - 16:37:15]
the requirements actually I

[16:37:13 - 16:37:18]
need so you can see guys these are the

[16:37:15 - 16:37:20]
requirement I need I need open Tik Tok

[16:37:18 - 16:37:22]
and chroma DB so Vector DB wise I'll be

[16:37:20 - 16:37:24]
using chroma DB previously I used Pine

[16:37:22 - 16:37:26]
con you can use any any of the vector DB

[16:37:24 - 16:37:28]
it's up to you then Lang chain flask so

[16:37:26 - 16:37:30]
the front end implementation wise I'll

[16:37:28 - 16:37:32]
be using flask framework then G python

[16:37:30 - 16:37:34]
why G python I'll tell you whenever I'll

[16:37:32 - 16:37:37]
show you the architecture diagram this

[16:37:34 - 16:37:39]
part would be clear then uh python. ENB

[16:37:37 - 16:37:40]
just to manage my credential okay and

[16:37:39 - 16:37:42]
I'll be using open large language model

[16:37:40 - 16:37:44]
you can also use JY you can also use

[16:37:42 - 16:37:45]
open source large language model but I

[16:37:44 - 16:37:47]
told you if you're using open source

[16:37:45 - 16:37:48]
large language model uh you should have

[16:37:47 - 16:37:50]
good configuration machine okay

[16:37:48 - 16:37:51]
otherwise you won't be able to execute

[16:37:50 - 16:37:54]
and that part we will be learning in the

[16:37:51 - 16:37:55]
LM Ops right now let me save everything

[16:37:54 - 16:37:57]
and let me install all the requirements

[16:37:55 - 16:37:59]
so for this you can execute this command

[16:37:57 - 16:38:02]
so let's copy the command and here I'm

[16:37:59 - 16:38:02]
going to

[16:38:02 - 16:38:06]
execute see for me I already installed

[16:38:05 - 16:38:08]
all the package that's why it's telling

[16:38:06 - 16:38:10]
requirement satisfied but for you it

[16:38:08 - 16:38:11]
will take some time now the next thing

[16:38:10 - 16:38:13]
what I do guys usually I create a

[16:38:11 - 16:38:16]
template file I think remember project

[16:38:13 - 16:38:19]
template file so

[16:38:16 - 16:38:20]
templates do p okay and previously I

[16:38:19 - 16:38:21]
shared one template code with you I

[16:38:20 - 16:38:25]
think remember so I'll just copy paste

[16:38:21 - 16:38:25]
the same code

[16:38:25 - 16:38:29]
so if you missed out my previous

[16:38:27 - 16:38:31]
implementation guys please try to check

[16:38:29 - 16:38:32]
the ENT and medical chatbot

[16:38:31 - 16:38:34]
implementation so there I already

[16:38:32 - 16:38:36]
explained this code okay this code how

[16:38:34 - 16:38:38]
we we have written and all everything I

[16:38:36 - 16:38:40]
explain in detail okay see I'm using the

[16:38:38 - 16:38:41]
same code same actually template code

[16:38:40 - 16:38:43]
now what will happen this code will

[16:38:41 - 16:38:44]
automatically create the template for me

[16:38:43 - 16:38:47]
so I already created requirement file I

[16:38:44 - 16:38:49]
don't need it I'll remove it as of now

[16:38:47 - 16:38:52]
okay now everything is fine so now if I

[16:38:49 - 16:38:54]
execute this template. Pi file see uh it

[16:38:52 - 16:38:56]
will create my folder St so let's see

[16:38:54 - 16:38:58]
see it has created the fold structure

[16:38:56 - 16:38:59]
and whatever log actually you have

[16:38:58 - 16:39:02]
written it is showing in the terminal

[16:38:59 - 16:39:04]
you can see okay so my folder structure

[16:39:02 - 16:39:06]
is created now what I will do uh I think

[16:39:04 - 16:39:08]
remember first of all we perform the

[16:39:06 - 16:39:09]
notebook experiment that means we'll be

[16:39:08 - 16:39:11]
implementing the entire projects you our

[16:39:09 - 16:39:13]
jupyter notebook then we'll try to

[16:39:11 - 16:39:14]
convert as our model coding okay so for

[16:39:13 - 16:39:16]
this I'm going to open the resource

[16:39:14 - 16:39:18]
folder inside that I'm have so inside

[16:39:16 - 16:39:20]
resource folder I'm having one jupyter

[16:39:18 - 16:39:23]
notebook file called trials. iyb so here

[16:39:20 - 16:39:26]
first of all let's select my Kel so this

[16:39:23 - 16:39:28]
is my environment okay now let's test

[16:39:26 - 16:39:30]
whether it's working or not so give okay

[16:39:28 - 16:39:33]
message

[16:39:30 - 16:39:35]
here yeah so everything is working fine

[16:39:33 - 16:39:37]
now first of all let me show you the

[16:39:35 - 16:39:39]
project architecture diagram like what

[16:39:37 - 16:39:41]
we are going to perform here so guys as

[16:39:39 - 16:39:43]
you can see this is the entire uh

[16:39:41 - 16:39:45]
project architecture so here we'll be

[16:39:43 - 16:39:47]
basically performing question answer

[16:39:45 - 16:39:49]
over the code base to understand how it

[16:39:47 - 16:39:51]
works see what happens actually whenever

[16:39:49 - 16:39:53]
let's say we Implement any kinds of

[16:39:51 - 16:39:55]
project okay let's say previous L I

[16:39:53 - 16:39:58]
think you remember uh we implemented one

[16:39:55 - 16:40:00]
project called n2n medical chatbot and

[16:39:58 - 16:40:02]
this is the code base we have created

[16:40:00 - 16:40:05]
right this is the entire repository of

[16:40:02 - 16:40:07]
our project now let's say if anyone new

[16:40:05 - 16:40:09]
to this field if actually he's not able

[16:40:07 - 16:40:11]
to understand this project project like

[16:40:09 - 16:40:13]
how I have written let's say uh this

[16:40:11 - 16:40:16]
person will open uh this project let's

[16:40:13 - 16:40:18]
say he will open this helper. by and now

[16:40:16 - 16:40:19]
he's not able to understand uh what is

[16:40:18 - 16:40:22]
this function actually download hugging

[16:40:19 - 16:40:24]
face embedding or let's say what is this

[16:40:22 - 16:40:26]
function load uh PDF file and all okay

[16:40:24 - 16:40:28]
let's say anything anything actually

[16:40:26 - 16:40:30]
he's not able to understand about the

[16:40:28 - 16:40:31]
project the project we have implemented

[16:40:30 - 16:40:34]
he's not able to understand the code we

[16:40:31 - 16:40:37]
have created right so what actually uh

[16:40:34 - 16:40:39]
this uh application can do so if you

[16:40:37 - 16:40:42]
give this uh GitHub repository link uh

[16:40:39 - 16:40:43]
to our software uh my software what it

[16:40:42 - 16:40:45]
will do it will try to first of all

[16:40:43 - 16:40:47]
extract all the code from the repository

[16:40:45 - 16:40:49]
then it will create a knowledge base

[16:40:47 - 16:40:50]
okay and with the help of large langas

[16:40:49 - 16:40:52]
model it will try to understand what you

[16:40:50 - 16:40:53]
have written let's see now if you're

[16:40:52 - 16:40:56]
asking any kinds of question let's say

[16:40:53 - 16:40:58]
what is SRC inside SRC let's say you are

[16:40:56 - 16:40:59]
having helper. Pi now let's say you are

[16:40:58 - 16:41:02]
asking let's say what is Tex split

[16:40:59 - 16:41:04]
function what it does so this model will

[16:41:02 - 16:41:06]
try to read this code and it will able

[16:41:04 - 16:41:08]
to give the uh like answer this function

[16:41:06 - 16:41:09]
does this thing and that is how actually

[16:41:08 - 16:41:12]
it is working okay that means it will

[16:41:09 - 16:41:13]
give you the entire explanation of the

[16:41:12 - 16:41:15]
code you have created okay so this is

[16:41:13 - 16:41:17]
called actually source code analysis

[16:41:15 - 16:41:19]
okay now I think You' got it what is the

[16:41:17 - 16:41:20]
project actually we are implementing so

[16:41:19 - 16:41:22]
project name is source code analysis so

[16:41:20 - 16:41:24]
basically here we'll be performing

[16:41:22 - 16:41:25]
question answer operation question

[16:41:24 - 16:41:27]
answer operation over the codee base

[16:41:25 - 16:41:29]
okay to understand how this code works

[16:41:27 - 16:41:30]
okay and this is the entire diagram you

[16:41:29 - 16:41:32]
can see guys let's say you are having a

[16:41:30 - 16:41:34]
source code that means a complete GitHub

[16:41:32 - 16:41:35]
repository okay that means the complete

[16:41:34 - 16:41:38]
let's

[16:41:35 - 16:41:39]
say I mean end to end implementation so

[16:41:38 - 16:41:41]
first of all what you have to do uh you

[16:41:39 - 16:41:43]
have to first of all uh let's say

[16:41:41 - 16:41:45]
extract all of the source code okay then

[16:41:43 - 16:41:46]
you will be creating um actually chunk

[16:41:45 - 16:41:47]
okay different different chunks for this

[16:41:46 - 16:41:49]
actually we'll be using something called

[16:41:47 - 16:41:52]
context a splitting okay now I think you

[16:41:49 - 16:41:55]
can see here uh we'll be using something

[16:41:52 - 16:41:57]
called context a splitting so here is

[16:41:55 - 16:41:59]
the context a splitting and how context

[16:41:57 - 16:42:00]
a splitting works so let's say this is

[16:41:59 - 16:42:03]
your entire source code and I think you

[16:42:00 - 16:42:04]
know inside Python Programming we use

[16:42:03 - 16:42:06]
functional programming op programming

[16:42:04 - 16:42:07]
concept right so let's say you have

[16:42:06 - 16:42:09]
created different different function I

[16:42:07 - 16:42:11]
think I told you I had created different

[16:42:09 - 16:42:13]
different function let's say this is one

[16:42:11 - 16:42:14]
function let's say this is one example

[16:42:13 - 16:42:16]
def4 let's say this is the function

[16:42:14 - 16:42:18]
inside that you are having some code now

[16:42:16 - 16:42:20]
after doing this context splitting what

[16:42:18 - 16:42:21]
it will do it will first of all extract

[16:42:20 - 16:42:22]
all of the source code then it will

[16:42:21 - 16:42:24]
create different different CHS let's see

[16:42:22 - 16:42:28]
inside this function you are having

[16:42:24 - 16:42:29]
let's say 200 200 line of code okay 200

[16:42:28 - 16:42:32]
line of code now let's see your Chang

[16:42:29 - 16:42:34]
size okay CH

[16:42:32 - 16:42:38]
size let's say You have given uh or

[16:42:34 - 16:42:39]
let's say I can write 20,000 lines of

[16:42:38 - 16:42:42]
code okay now let's see your Chun size

[16:42:39 - 16:42:44]
you have defined 500 okay 500 that means

[16:42:42 - 16:42:47]
what it will happen

[16:42:44 - 16:42:49]
500 okay 500 let's say what that means

[16:42:47 - 16:42:51]
500 these kinds of actually tokens would

[16:42:49 - 16:42:52]
be considered as your one chunks now

[16:42:51 - 16:42:54]
just try to consider how many chunks it

[16:42:52 - 16:42:55]
will create it will create different

[16:42:54 - 16:42:56]
different chunks obviously let's say

[16:42:55 - 16:42:58]
this is the first chunks this is the

[16:42:56 - 16:42:59]
second chunks this is the third chunks

[16:42:58 - 16:43:02]
let's say it has created three chunks

[16:42:59 - 16:43:04]
okay three chunks it has created now how

[16:43:02 - 16:43:06]
your model will try to understand

[16:43:04 - 16:43:08]
whether this chunks the entire chunks so

[16:43:06 - 16:43:09]
it is related to this particular

[16:43:08 - 16:43:12]
function let's say there would be so

[16:43:09 - 16:43:14]
many function there would be let's say

[16:43:12 - 16:43:16]
thousands of function but how your model

[16:43:14 - 16:43:19]
will understand this three chunks I got

[16:43:16 - 16:43:21]
this chance is related this function de

[16:43:19 - 16:43:23]
F function so what context splitting

[16:43:21 - 16:43:25]
will do it will automatically tag so see

[16:43:23 - 16:43:28]
it is automatically tagging so this is

[16:43:25 - 16:43:29]
the chunks of Def F function okay let's

[16:43:28 - 16:43:32]
you are having another function let's

[16:43:29 - 16:43:33]
say def test okay this is that this is

[16:43:32 - 16:43:34]
the function inside that you have

[16:43:33 - 16:43:36]
subcode first of all it will perform

[16:43:34 - 16:43:37]
this splitting that mean chunking

[16:43:36 - 16:43:39]
operation you will get different

[16:43:37 - 16:43:41]
different chunk okay then it will also

[16:43:39 - 16:43:44]
perform the tagging operation let's say

[16:43:41 - 16:43:45]
this is the tag of test function that

[16:43:44 - 16:43:47]
means your model will try to

[16:43:45 - 16:43:48]
automatically understand now now your

[16:43:47 - 16:43:50]
model will try to understand okay this

[16:43:48 - 16:43:52]
chunks actually I'm getting this is

[16:43:50 - 16:43:54]
related to this particular function okay

[16:43:52 - 16:43:55]
so that's how it will understand the

[16:43:54 - 16:43:57]
context it will remember the context

[16:43:55 - 16:43:59]
okay this is called actually context

[16:43:57 - 16:44:01]
splitting and this context splitting we

[16:43:59 - 16:44:03]
only perform whenever we are working

[16:44:01 - 16:44:05]
with uh let's say code okay code data

[16:44:03 - 16:44:07]
because previously we work with text

[16:44:05 - 16:44:08]
Data okay text data is a different thing

[16:44:07 - 16:44:09]
and code data is a different thing

[16:44:08 - 16:44:13]
that's why you have to follow this thing

[16:44:09 - 16:44:14]
okay now let me clear my uh huh screen

[16:44:13 - 16:44:18]
now see what will happen you have to

[16:44:14 - 16:44:21]
create a vector store yes or no you can

[16:44:18 - 16:44:23]
see after uh actually getting uh all the

[16:44:21 - 16:44:24]
text okay all the chunks you using

[16:44:23 - 16:44:26]
embedding model with embedding model

[16:44:24 - 16:44:28]
you'll be creating vector and here we'll

[16:44:26 - 16:44:30]
be using something called chroma DB okay

[16:44:28 - 16:44:32]
chroma DB we'll be using okay then this

[16:44:30 - 16:44:33]
this would be your knowledge base okay

[16:44:32 - 16:44:36]
and you'll be connecting your large

[16:44:33 - 16:44:37]
language model after that whatever uh

[16:44:36 - 16:44:39]
question actually user will ask okay

[16:44:37 - 16:44:41]
let's say this is the user whatever

[16:44:39 - 16:44:43]
question user will ask it will take uh

[16:44:41 - 16:44:45]
this uh this actually relevant answer as

[16:44:43 - 16:44:46]
well as the question it will try to

[16:44:45 - 16:44:48]
understand based on that actually it

[16:44:46 - 16:44:50]
will give you the actual response okay

[16:44:48 - 16:44:52]
so this is the entire application we'll

[16:44:50 - 16:44:53]
be creating and again you can see here

[16:44:52 - 16:44:55]
we are implementing some called M rag

[16:44:53 - 16:44:57]
application rable augmented generation

[16:44:55 - 16:44:58]
okay because here we are feeding our

[16:44:57 - 16:45:01]
custom data custom data wise we are

[16:44:58 - 16:45:03]
using Code data okay our uh let's say

[16:45:01 - 16:45:04]
source code we are using here so I hope

[16:45:03 - 16:45:06]
now it is clear now let's start the

[16:45:04 - 16:45:07]
implementation guys so first of all

[16:45:06 - 16:45:09]
let's Implement everything in our

[16:45:07 - 16:45:12]
jupyter notebook then we'll try to

[16:45:09 - 16:45:14]
convert everything as our modular coding

[16:45:12 - 16:45:16]
now let me clear my screen okay so first

[16:45:14 - 16:45:19]
of all let's import all of the library I

[16:45:16 - 16:45:21]
need so here you can see I have imported

[16:45:19 - 16:45:23]
all of the library actually I need in

[16:45:21 - 16:45:25]
this implementation now the first

[16:45:23 - 16:45:27]
Library I'm importing called uh from git

[16:45:25 - 16:45:30]
import repo so I think you remember we

[16:45:27 - 16:45:31]
installed one package called git python

[16:45:30 - 16:45:34]
okay so what is git python git python is

[16:45:31 - 16:45:36]
nothing but this is the package like git

[16:45:34 - 16:45:38]
uh GitHub okay this is the GitHub

[16:45:36 - 16:45:39]
actually package inside python that

[16:45:38 - 16:45:42]
means with the help of this package you

[16:45:39 - 16:45:44]
can uh clone any kind of repository from

[16:45:42 - 16:45:45]
the GitHub let's say the way actually

[16:45:44 - 16:45:47]
cloned I think remember we open up our

[16:45:45 - 16:45:49]
terminal we just WR one command get

[16:45:47 - 16:45:51]
clone then we pasted that link right we

[16:45:49 - 16:45:53]
pasted our repository link I think

[16:45:51 - 16:45:55]
remember okay and it was was able to

[16:45:53 - 16:45:57]
clone this repository in my system so

[16:45:55 - 16:45:59]
now if I want to do with the help of

[16:45:57 - 16:46:00]
Python Programming how we can do it for

[16:45:59 - 16:46:02]
this we'll be using this package

[16:46:00 - 16:46:04]
actually G python okay so the help of

[16:46:02 - 16:46:06]
that we'll be easily cloning any kinds

[16:46:04 - 16:46:08]
of repository from our GitHub because I

[16:46:06 - 16:46:10]
told you now user will upload one URL

[16:46:08 - 16:46:12]
okay that means GitHub URL project URL

[16:46:10 - 16:46:13]
and from the URL actually it will

[16:46:12 - 16:46:14]
automatically let's say clone the

[16:46:13 - 16:46:16]
repository then it will extract the

[16:46:14 - 16:46:17]
information that means your code base

[16:46:16 - 16:46:20]
then it will perform the chunking

[16:46:17 - 16:46:21]
operation embedding model uh stor the

[16:46:20 - 16:46:23]
embedding in knowledge base then it will

[16:46:21 - 16:46:25]
connect LM okay that's will be

[16:46:23 - 16:46:26]
performing the entire operation got it

[16:46:25 - 16:46:27]
and here I'm also importing another

[16:46:26 - 16:46:29]
package called language because here

[16:46:27 - 16:46:31]
we'll be using programming language so

[16:46:29 - 16:46:32]
I'm going to use Python Programming so

[16:46:31 - 16:46:34]
with the help of language actually I'll

[16:46:32 - 16:46:36]
set I'll try to use Python programming

[16:46:34 - 16:46:38]
language here then generic loader

[16:46:36 - 16:46:39]
language sper recursive character text

[16:46:38 - 16:46:41]
beter okay so these are the actually

[16:46:39 - 16:46:42]
additional package I'm also importing

[16:46:41 - 16:46:43]
and I'll tell you whenever I will be

[16:46:42 - 16:46:45]
using them I'll tell you each and

[16:46:43 - 16:46:46]
everything okay why I'm using it and

[16:46:45 - 16:46:48]
what is the use of it now you can see

[16:46:46 - 16:46:50]
I'm importing open AI embedding because

[16:46:48 - 16:46:51]
I'm going to use open embedding model

[16:46:50 - 16:46:53]
then chroma Vector database I already

[16:46:51 - 16:46:54]
told you then we'll be creating our

[16:46:53 - 16:46:55]
chain okay the complete chain and here

[16:46:54 - 16:46:57]
we'll be using actually memory

[16:46:55 - 16:46:59]
conversation summary memory because I

[16:46:57 - 16:47:01]
think you remember in our Lang chain uh

[16:46:59 - 16:47:02]
series actually we learned how to create

[16:47:01 - 16:47:05]
the memory okay like it will remember

[16:47:02 - 16:47:06]
your previous context so with the help

[16:47:05 - 16:47:08]
of this conversation summary memory we

[16:47:06 - 16:47:10]
can also create a memory buffer okay so

[16:47:08 - 16:47:13]
this thing actually have imported so far

[16:47:10 - 16:47:14]
now let me execute now see it should

[16:47:13 - 16:47:16]
work fine because we have installed

[16:47:14 - 16:47:18]
everything now the next thing what I

[16:47:16 - 16:47:21]
will do guys I'll just create a folder

[16:47:18 - 16:47:23]
here so mkd i r so this is the command

[16:47:21 - 16:47:27]
to create a folder I'll name it as test

[16:47:23 - 16:47:28]
repo okay test repo now see if I show

[16:47:27 - 16:47:31]
you my project working directory right

[16:47:28 - 16:47:31]
now

[16:47:31 - 16:47:35]
so PWD project working directory I'm

[16:47:34 - 16:47:37]
inside research folder so inside

[16:47:35 - 16:47:40]
research folder it will create a folder

[16:47:37 - 16:47:43]
called okay mkd is not recognized okay

[16:47:40 - 16:47:44]
so it should be MK okay not Mac now it

[16:47:43 - 16:47:46]
should work see now in the test folder

[16:47:44 - 16:47:48]
it has created one folder called test

[16:47:46 - 16:47:49]
repo inside test repo I'm going to clone

[16:47:48 - 16:47:51]
the repository and to clone the

[16:47:49 - 16:47:53]
repository guys you can use this code

[16:47:51 - 16:47:54]
snippit so here I'm using using this one

[16:47:53 - 16:47:57]
actually I think

[16:47:54 - 16:48:00]
remember repo so the repo actually I

[16:47:57 - 16:48:01]
have imported from git so inside that

[16:48:00 - 16:48:03]
you have one function called clone form

[16:48:01 - 16:48:05]
now you have to mention the URL like

[16:48:03 - 16:48:06]
which repository you want to clone let's

[16:48:05 - 16:48:09]
say I want to clone this medical chatbot

[16:48:06 - 16:48:11]
repository I've given the entire link so

[16:48:09 - 16:48:12]
this is the link I have given just copy

[16:48:11 - 16:48:14]
the link and try to mention here you can

[16:48:12 - 16:48:15]
give any kinds of URL any kinds of

[16:48:14 - 16:48:17]
GitHub URL you can mention here that

[16:48:15 - 16:48:18]
repository would be clone then after

[16:48:17 - 16:48:19]
that you have to define the path in

[16:48:18 - 16:48:21]
which path you want to clone I want to

[16:48:19 - 16:48:23]
clone inside this particular path okay

[16:48:21 - 16:48:24]
this folder now if I execute it will

[16:48:23 - 16:48:26]
automatically clone this repository

[16:48:24 - 16:48:28]
inside the test repo folder let me show

[16:48:26 - 16:48:30]
you execution done now inside resarch

[16:48:28 - 16:48:32]
test repo see it has cloned all the

[16:48:30 - 16:48:33]
source code see all the source code you

[16:48:32 - 16:48:35]
can see it has already grown okay

[16:48:33 - 16:48:37]
amazing now the next thing we'll be

[16:48:35 - 16:48:39]
loading all the codes okay all the let's

[16:48:37 - 16:48:41]
say codes all the data from this

[16:48:39 - 16:48:42]
repository itself okay all the python

[16:48:41 - 16:48:44]
file will be loading that means we'll be

[16:48:42 - 16:48:45]
extracting all the source code for this

[16:48:44 - 16:48:49]
I'm going to use this code

[16:48:45 - 16:48:51]
snippit so here is the Cod s guys so

[16:48:49 - 16:48:53]
here I'm using generic loader from file

[16:48:51 - 16:48:55]
system so I think remember we imported

[16:48:53 - 16:48:57]
the generic loader from langen okay

[16:48:55 - 16:48:59]
generic now here I'm giving the repo

[16:48:57 - 16:49:01]
path that means where my repo is present

[16:48:59 - 16:49:04]
then I'm giving the globe that means it

[16:49:01 - 16:49:07]
will open that means it will extract all

[16:49:04 - 16:49:09]
the python file okay Pi file then parer

[16:49:07 - 16:49:10]
you have to mention the language so here

[16:49:09 - 16:49:12]
it is the Python language okay that's

[16:49:10 - 16:49:13]
why you have to give the Python language

[16:49:12 - 16:49:15]
and Par threshold you just keep it this

[16:49:13 - 16:49:16]
particular number 500 okay this is the

[16:49:15 - 16:49:19]
default number you can keep it now it

[16:49:16 - 16:49:21]
will give me the loader object okay now

[16:49:19 - 16:49:23]
from the loader object I will load the

[16:49:21 - 16:49:25]
documents now see it will give me the

[16:49:23 - 16:49:28]
entire documents right now if I show you

[16:49:25 - 16:49:31]
see all the uh content is has extracted

[16:49:28 - 16:49:34]
okay now if you want to see

[16:49:31 - 16:49:37]
them now how many documents you got you

[16:49:34 - 16:49:39]
can take the length length of documents

[16:49:37 - 16:49:41]
you'll see that seven documents actually

[16:49:39 - 16:49:43]
I got now if you want to see any kinds

[16:49:41 - 16:49:45]
of specific let's say documents you can

[16:49:43 - 16:49:47]
print it now you can see this is the

[16:49:45 - 16:49:50]
entire source code you can see it has uh

[16:49:47 - 16:49:51]
extracted okay from my repository itself

[16:49:50 - 16:49:53]
now the next thing is we'll be

[16:49:51 - 16:49:56]
performing this

[16:49:53 - 16:49:58]
uh context uh ER splitting okay context

[16:49:56 - 16:49:59]
ER splitting I already told you we'll be

[16:49:58 - 16:50:01]
creating the chunks and this particular

[16:49:59 - 16:50:03]
chunks will tag with the function name

[16:50:01 - 16:50:06]
for this we'll be using this fun uh this

[16:50:03 - 16:50:07]
particular Cod cipit let me show you

[16:50:06 - 16:50:09]
this is the Cod cipit guys recursive

[16:50:07 - 16:50:11]
character test spitter you can use and

[16:50:09 - 16:50:13]
inside that you only need to mention one

[16:50:11 - 16:50:15]
parameter called language is equal to

[16:50:13 - 16:50:16]
language. python so it will

[16:50:15 - 16:50:18]
automatically perform the context D

[16:50:16 - 16:50:20]
splitting that means it will tag it will

[16:50:18 - 16:50:22]
tag the chunks with respect to the

[16:50:20 - 16:50:25]
function got it and Chun SI and chunks

[16:50:22 - 16:50:28]
lab I have given now let me

[16:50:25 - 16:50:30]
execute now I'll apply on top of my

[16:50:28 - 16:50:32]
entire documents okay documents splitter

[16:50:30 - 16:50:34]
split documents I'm passing my documents

[16:50:32 - 16:50:35]
now it will give you the entire chunks

[16:50:34 - 16:50:37]
so let's me show you so this is the

[16:50:35 - 16:50:40]
chunks I got if you want to see the

[16:50:37 - 16:50:42]
length you can also see the length Okay

[16:50:40 - 16:50:43]
see this is the length of my CHS got it

[16:50:42 - 16:50:45]
then next thing what I have to do guys I

[16:50:43 - 16:50:49]
have to uh actually use the embedding

[16:50:45 - 16:50:50]
model okay uh to convert all my source

[16:50:49 - 16:50:51]
code to the embedding representation and

[16:50:50 - 16:50:53]
I will be storing to my knowledge base

[16:50:51 - 16:50:54]
that means chrom ad

[16:50:53 - 16:50:56]
for this I'll be using openi embedding

[16:50:54 - 16:50:59]
model I think remember so let's set our

[16:50:56 - 16:51:01]
openi environment uh API key here so

[16:50:59 - 16:51:03]
this is my openi API key so I already

[16:51:01 - 16:51:06]
created and I already set here now let

[16:51:03 - 16:51:07]
me sa I'll go back to my notebook now

[16:51:06 - 16:51:09]
first of all let's load this API key

[16:51:07 - 16:51:12]
with the help ofb package so here you

[16:51:09 - 16:51:14]
can see I'm loading it then I will set

[16:51:12 - 16:51:16]
this API as an environment

[16:51:14 - 16:51:19]
variable then I'm going to initialize my

[16:51:16 - 16:51:21]
embedding model okay open embedding

[16:51:19 - 16:51:23]
model that's it now let's initialize my

[16:51:21 - 16:51:27]
chroma DB so I think you remember we

[16:51:23 - 16:51:29]
imported already chroma from langin here

[16:51:27 - 16:51:32]
so chroma we already imported you can

[16:51:29 - 16:51:33]
see Vector chroma we imported now inside

[16:51:32 - 16:51:35]
chroma

[16:51:33 - 16:51:38]
DB uh we are passing our text that means

[16:51:35 - 16:51:39]
the chunks actually I created and the

[16:51:38 - 16:51:41]
embedding model as well as the pares

[16:51:39 - 16:51:43]
directory that means it will create a

[16:51:41 - 16:51:45]
directory that means database okay so

[16:51:43 - 16:51:48]
instead of data you can give database

[16:51:45 - 16:51:50]
okay DB okay DB so it will create a data

[16:51:48 - 16:51:53]
database like local database inside that

[16:51:50 - 16:51:54]
it will save all of your uh Bings and

[16:51:53 - 16:51:55]
chroma DB session I have already taken

[16:51:54 - 16:51:57]
in the YouTube channel you can check it

[16:51:55 - 16:51:59]
out how chroma DB works okay now let me

[16:51:57 - 16:52:02]
create the vector

[16:51:59 - 16:52:05]
store now see DB has created okay inside

[16:52:02 - 16:52:07]
resource and it is converting all the

[16:52:05 - 16:52:09]
code to the embedding representation and

[16:52:07 - 16:52:11]
it is saving inside DB now see it has

[16:52:09 - 16:52:14]
created the local database okay see okay

[16:52:11 - 16:52:16]
now what I'll do uh I'll just make it as

[16:52:14 - 16:52:19]
now to activate this Vector DV you have

[16:52:16 - 16:52:22]
to execute this line Vector db. parist

[16:52:19 - 16:52:22]
okay now I'll be initializing my large

[16:52:22 - 16:52:25]
language mod

[16:52:22 - 16:52:26]
model so here you can use any kinds of

[16:52:25 - 16:52:28]
large language model you can also use

[16:52:26 - 16:52:31]
gbt 4 I'll be using the default model

[16:52:28 - 16:52:33]
like gbt 3.5 turbo so let's initialize

[16:52:31 - 16:52:36]
my llm then I'll be creating the memory

[16:52:33 - 16:52:38]
that means uh that sum uh history memory

[16:52:36 - 16:52:40]
conversation summary memory you can see

[16:52:38 - 16:52:41]
I'm importing this library inside that

[16:52:40 - 16:52:43]
I'm passing my large language model then

[16:52:41 - 16:52:44]
memory key is equal to chat history this

[16:52:43 - 16:52:46]
that means it will remember my previous

[16:52:44 - 16:52:47]
context okay then return message is

[16:52:46 - 16:52:49]
equal to true so this is going to be my

[16:52:47 - 16:52:52]
memory object right now then I'll be

[16:52:49 - 16:52:54]
creating my final chain so for this

[16:52:52 - 16:52:57]
you'll be using a conversation retrieval

[16:52:54 - 16:52:59]
chain okay now inside that give the LM

[16:52:57 - 16:53:02]
retriever Vector database okay and as

[16:52:59 - 16:53:04]
retriever so search type I'm giving M

[16:53:02 - 16:53:06]
MMR keyword it will give me eight

[16:53:04 - 16:53:08]
relevant answer and here I've given the

[16:53:06 - 16:53:10]
memory okay now this is going to be my

[16:53:08 - 16:53:13]
key object right now now let's ask one

[16:53:10 - 16:53:17]
question so I'll prepare one question

[16:53:13 - 16:53:18]
here question is equal to let's say I'll

[16:53:17 - 16:53:20]
go to the test repo inside that I'm

[16:53:18 - 16:53:22]
having SRC folder inside help part I'm

[16:53:20 - 16:53:24]
having one function let's say download

[16:53:22 - 16:53:26]
face embedding I'll copy this function

[16:53:24 - 16:53:29]
name and here I will ask what

[16:53:26 - 16:53:31]
is hugging download hugging face

[16:53:29 - 16:53:33]
embedding

[16:53:31 - 16:53:35]
function okay let's see whether my model

[16:53:33 - 16:53:37]
is able to explain or not so this is my

[16:53:35 - 16:53:40]
question so this question I'm going to

[16:53:37 - 16:53:43]
pass inside my uh QA that means my chain

[16:53:40 - 16:53:45]
okay and it will give me and it will

[16:53:43 - 16:53:46]
give me results and I'm going to only

[16:53:45 - 16:53:48]
extract the answer okay from the result

[16:53:46 - 16:53:51]
itself now let's

[16:53:48 - 16:53:53]
see so guys you can see I got the answer

[16:53:51 - 16:53:55]
uh the download hugging face embedding

[16:53:53 - 16:53:57]
function downloads the embedding from

[16:53:55 - 16:53:59]
the hugging face model uh so this is the

[16:53:57 - 16:54:02]
model actually okay now see if I open it

[16:53:59 - 16:54:03]
up uh see it is correctly identified

[16:54:02 - 16:54:07]
this model actually we are trying to

[16:54:03 - 16:54:10]
download and which returns embedding of

[16:54:07 - 16:54:13]
304 Dimensions uh these embeddings are

[16:54:10 - 16:54:15]
used for the pro processing and analyze

[16:54:13 - 16:54:16]
text Data into context of the

[16:54:15 - 16:54:18]
application that means correct

[16:54:16 - 16:54:20]
information okay amazingly it has

[16:54:18 - 16:54:22]
explained this function now you can give

[16:54:20 - 16:54:24]
any other question so what I will do

[16:54:22 - 16:54:27]
I'll call copy this question and let's

[16:54:24 - 16:54:30]
ask about this function right

[16:54:27 - 16:54:32]
now let's say I'll ask about load PDF

[16:54:30 - 16:54:34]
file okay this function right now let's

[16:54:32 - 16:54:37]
see what it will give

[16:54:34 - 16:54:40]
me so I'll copy the same

[16:54:37 - 16:54:42]
code and here I can mention I think now

[16:54:40 - 16:54:42]
let's

[16:54:42 - 16:54:47]
see so ignore this line okay this line

[16:54:45 - 16:54:49]
is not required so this is your ACC

[16:54:47 - 16:54:52]
response the load PDF function loads the

[16:54:49 - 16:54:54]
PDF file from a specified directory

[16:54:52 - 16:54:57]
using directory loader class uh which is

[16:54:54 - 16:54:59]
a filter uh filter of PDF files and then

[16:54:57 - 16:55:02]
it extract the documents and return the

[16:54:59 - 16:55:03]
items amazing guys so that's how you can

[16:55:02 - 16:55:05]
uh perform the keyway operation with

[16:55:03 - 16:55:07]
your code base right now if you don't

[16:55:05 - 16:55:09]
understand any kinds of code if you

[16:55:07 - 16:55:11]
don't understand any kinds of function

[16:55:09 - 16:55:12]
just try to I mean give it here and try

[16:55:11 - 16:55:14]
to ask it so it will give you the entire

[16:55:12 - 16:55:16]
explanation of your code base okay this

[16:55:14 - 16:55:17]
is called actually source code analysis

[16:55:16 - 16:55:20]
and this is one of the Amazing Project

[16:55:17 - 16:55:22]
guys Amazing Project got it now this is

[16:55:20 - 16:55:24]
the actually notebook experiment now

[16:55:22 - 16:55:26]
let's try to convert this project as our

[16:55:24 - 16:55:27]
end to end implementation okay so I'll

[16:55:26 - 16:55:29]
just do the copy paste operation from my

[16:55:27 - 16:55:30]
notebook only because I think I showed

[16:55:29 - 16:55:32]
you in my previous implementation I did

[16:55:30 - 16:55:34]
the same thing so now what I will do

[16:55:32 - 16:55:35]
guys I'll open up my SRC folder inside

[16:55:34 - 16:55:37]
help part so whatever let's say code I

[16:55:35 - 16:55:39]
have written okay then let's

[16:55:37 - 16:55:42]
individually I was loading the uh I was

[16:55:39 - 16:55:44]
cloning the GitHub I was extracting the

[16:55:42 - 16:55:45]
data I was performing the uh embedding

[16:55:44 - 16:55:47]
model operation okay so everything I'll

[16:55:45 - 16:55:49]
just write as a function inside helper.

[16:55:47 - 16:55:51]
F okay so now let's do it this is how

[16:55:49 - 16:55:53]
actually I implemented guys so I'm

[16:55:51 - 16:55:55]
importing all of the library then first

[16:55:53 - 16:55:58]
of all I created one function called

[16:55:55 - 16:55:59]
repo injection it will take the repo URL

[16:55:58 - 16:56:01]
and it will do the inje operation that

[16:55:59 - 16:56:03]
means clone operation the same thing we

[16:56:01 - 16:56:04]
are doing in our notebook only got it

[16:56:03 - 16:56:07]
then second function I have written

[16:56:04 - 16:56:09]
called load repo the same code guys that

[16:56:07 - 16:56:11]
loader generic loader I'm using here see

[16:56:09 - 16:56:13]
it will take the repo path and it will

[16:56:11 - 16:56:15]
load the let's say I mean code and it

[16:56:13 - 16:56:17]
will give you the documents after

[16:56:15 - 16:56:18]
extracting then the third function I

[16:56:17 - 16:56:20]
written called text splitter that means

[16:56:18 - 16:56:22]
it will perform the context splitting

[16:56:20 - 16:56:24]
okay the same thing then it it will will

[16:56:22 - 16:56:25]
give you the uh embedding model okay it

[16:56:24 - 16:56:27]
will first of all get the embedding

[16:56:25 - 16:56:29]
model from the open air it will return

[16:56:27 - 16:56:30]
you so instead of actually writing the

[16:56:29 - 16:56:32]
scripting I've just written as a

[16:56:30 - 16:56:35]
function that's it now the next thing

[16:56:32 - 16:56:36]
what I will do I'll uh add everything

[16:56:35 - 16:56:38]
inside my endpoint which is nothing but

[16:56:36 - 16:56:41]
my app.py because app. Pi user will

[16:56:38 - 16:56:42]
execute and uh they will get one user

[16:56:41 - 16:56:44]
interface and from there actually will

[16:56:42 - 16:56:46]
they will upload uh let's say they will

[16:56:44 - 16:56:48]
give the URL they will uh to the keyway

[16:56:46 - 16:56:50]
operation okay so for this actually I

[16:56:48 - 16:56:51]
already told you we'll be using flask

[16:56:50 - 16:56:53]
and for the flask actually you need one

[16:56:51 - 16:56:55]
time template and static file I think

[16:56:53 - 16:56:56]
you remember so let me show you I

[16:56:55 - 16:56:58]
already prepared one HTML and CSS code

[16:56:56 - 16:57:00]
for you so guys as you can see this is

[16:56:58 - 16:57:01]
the template file and inside that I'm

[16:57:00 - 16:57:04]
having my index.html and this is the

[16:57:01 - 16:57:06]
HTML code and again I refer the internet

[16:57:04 - 16:57:09]
bootstrap website to implement this uh

[16:57:06 - 16:57:10]
actually HTML and CSS code if you're not

[16:57:09 - 16:57:13]
aware about it's completely fine you can

[16:57:10 - 16:57:15]
use my template as it is okay now inside

[16:57:13 - 16:57:18]
static folder I'm having the uh CSS that

[16:57:15 - 16:57:21]
mean CSS code okay that mean style uh of

[16:57:18 - 16:57:23]
our uh web interface and all and to

[16:57:21 - 16:57:25]
execute this style. CSS I am using some

[16:57:23 - 16:57:26]
JavaScript actually code you can see

[16:57:25 - 16:57:30]
this is the JavaScript code again I got

[16:57:26 - 16:57:31]
it from the bootstrap now see how your

[16:57:30 - 16:57:34]
application will look like I'll tell you

[16:57:31 - 16:57:36]
before that let me uh write this app.py

[16:57:34 - 16:57:38]
code so inside app.py I'm going to

[16:57:36 - 16:57:39]
import all of the library I need so you

[16:57:38 - 16:57:41]
can see I'm imported all of the library

[16:57:39 - 16:57:43]
like chroma DB load embeddings okay from

[16:57:41 - 16:57:46]
the SRC hire because I need the

[16:57:43 - 16:57:48]
embedding model right then uh repo in

[16:57:46 - 16:57:49]
I'm also importing from the SRC then my

[16:57:48 - 16:57:52]
chat openi okay function then

[16:57:49 - 16:57:53]
conversation summary okay conversation r

[16:57:52 - 16:57:55]
chain so everything you can see in the

[16:57:53 - 16:57:57]
notebook I'm importing all of them here

[16:57:55 - 16:57:59]
now first of all what I have to do I

[16:57:57 - 16:58:01]
have to initialize my flask and I will

[16:57:59 - 16:58:03]
set the open environment key as my

[16:58:01 - 16:58:04]
environment variable here that's it okay

[16:58:03 - 16:58:06]
see now first of all I will load my

[16:58:04 - 16:58:08]
embeddings okay from my Vector database

[16:58:06 - 16:58:10]
you can see I'm loading the embedding

[16:58:08 - 16:58:12]
from my Vector database so for this

[16:58:10 - 16:58:14]
before that see before that what I have

[16:58:12 - 16:58:15]
to do I have to first of all generate

[16:58:14 - 16:58:17]
the vector embedding let's say if user

[16:58:15 - 16:58:19]
has given the URL so it will generate

[16:58:17 - 16:58:20]
the embedding right it will uh create

[16:58:19 - 16:58:22]
the embeddings and it will save inside

[16:58:20 - 16:58:25]
my Vector database yes or no so for this

[16:58:22 - 16:58:27]
I'm going to create another file called

[16:58:25 - 16:58:32]
uh

[16:58:27 - 16:58:34]
store _ index do file so previously in

[16:58:32 - 16:58:36]
the medical chatboard implementation I

[16:58:34 - 16:58:39]
return the same file I think remember

[16:58:36 - 16:58:42]
inside that I was doing the um actually

[16:58:39 - 16:58:44]
embedding storing operation see so you

[16:58:42 - 16:58:46]
can see repo in load URL so I'm

[16:58:44 - 16:58:49]
importing everything I'm setting my open

[16:58:46 - 16:58:52]
API key then load repo that means see

[16:58:49 - 16:58:55]
user will give the URL so this URL

[16:58:52 - 16:58:56]
actually rep injection will load and it

[16:58:55 - 16:58:58]
will load the let's say documents it

[16:58:56 - 16:59:01]
will perform the text splitter embedding

[16:58:58 - 16:59:03]
then this embedding will store inside my

[16:59:01 - 16:59:05]
uh like chrom ADB chrom ADB will create

[16:59:03 - 16:59:07]
like local database inside that it will

[16:59:05 - 16:59:08]
save everything okay I think remember

[16:59:07 - 16:59:10]
now here I have commented this two line

[16:59:08 - 16:59:12]
because I will be doing this thing with

[16:59:10 - 16:59:15]
the help of user interface that means UI

[16:59:12 - 16:59:17]
okay not manually actually so that means

[16:59:15 - 16:59:19]
from the app. pi user will give the URL

[16:59:17 - 16:59:21]
okay from the user interface web

[16:59:19 - 16:59:22]
application user will give the URL this

[16:59:21 - 16:59:24]
URL I will receive here okay I'll

[16:59:22 - 16:59:25]
receive here then I will execute this

[16:59:24 - 16:59:27]
line of code okay so that's why I've

[16:59:25 - 16:59:28]
commented this line but if you want if

[16:59:27 - 16:59:30]
you want to test what you can do you can

[16:59:28 - 16:59:31]
uncomment it and you can execute this

[16:59:30 - 16:59:33]
line you will see that it will work fine

[16:59:31 - 16:59:35]
okay so as of now I've just commented

[16:59:33 - 16:59:39]
out now let me save it now I'll go back

[16:59:35 - 16:59:41]
to my app.py now let's create the llm

[16:59:39 - 16:59:43]
chain so this is the chain the same code

[16:59:41 - 16:59:46]
I have copy pasted from my notebook guys

[16:59:43 - 16:59:48]
I'm creating the llm creating the memory

[16:59:46 - 16:59:50]
after that I'm creating the qm that's it

[16:59:48 - 16:59:52]
then I'll be creating two

[16:59:50 - 16:59:54]
route then I'm going to Creator route

[16:59:52 - 16:59:56]
actually from my flask so this is the

[16:59:54 - 16:59:58]
default route first of all it will

[16:59:56 - 17:00:00]
render the index.html whenever user will

[16:59:58 - 17:00:02]
open the application okay then the

[17:00:00 - 17:00:06]
second route I'll be

[17:00:02 - 17:00:09]
creating um for the repo injection so

[17:00:06 - 17:00:11]
whenever user will uh pass the URL pass

[17:00:09 - 17:00:14]
the URL of the GitHub and they will

[17:00:11 - 17:00:15]
submit so what will happen it will

[17:00:14 - 17:00:17]
execute this store index. Pi you can see

[17:00:15 - 17:00:19]
I'm executing this command python store

[17:00:17 - 17:00:20]
index. piy and if you want to execute

[17:00:19 - 17:00:22]
any python find that means if you want

[17:00:20 - 17:00:23]
to execute any command you have to use

[17:00:22 - 17:00:26]
system voice. system you can see I have

[17:00:23 - 17:00:27]
imported operating system so voice.

[17:00:26 - 17:00:29]
system and inside that just give the

[17:00:27 - 17:00:30]
command it will execute this file that

[17:00:29 - 17:00:33]
means what will happen whatever URL user

[17:00:30 - 17:00:34]
will give okay so first of all it will

[17:00:33 - 17:00:36]
perform the repo injection I think you

[17:00:34 - 17:00:38]
remember we created the repo injection

[17:00:36 - 17:00:42]
function repo would be ined in the repo

[17:00:38 - 17:00:44]
folder and um if I go it back now see

[17:00:42 - 17:00:46]
now it will execute this store index. Pi

[17:00:44 - 17:00:48]
file that means this file now this code

[17:00:46 - 17:00:49]
will be executed that means it will load

[17:00:48 - 17:00:53]
the repo extract the documents create

[17:00:49 - 17:00:55]
the chunks uh load them model then store

[17:00:53 - 17:00:56]
all the embeddings to the knowledge base

[17:00:55 - 17:00:58]
that means inside my chroma Vector

[17:00:56 - 17:01:00]
database okay now I think you got it now

[17:00:58 - 17:01:02]
see this is my second route now I'll be

[17:01:00 - 17:01:03]
creating another last route this is for

[17:01:02 - 17:01:06]
the chat

[17:01:03 - 17:01:07]
operation that means after ingesting the

[17:01:06 - 17:01:08]
data creating the knowledge base it will

[17:01:07 - 17:01:11]
perform the chat operation user will

[17:01:08 - 17:01:14]
give the masses okay and if message is

[17:01:11 - 17:01:16]
equal to clear it will remove your let's

[17:01:14 - 17:01:17]
say enre repository that let's say you

[17:01:16 - 17:01:19]
want to clone another repository so your

[17:01:17 - 17:01:21]
previous repository should be deleted

[17:01:19 - 17:01:23]
okay otherwise what will happen it will

[17:01:21 - 17:01:24]
take all I I'm in this space okay in my

[17:01:23 - 17:01:27]
system that's why I'm removing it I'm

[17:01:24 - 17:01:28]
doing the you can say rm. RF operation

[17:01:27 - 17:01:30]
that means it will remove it so this is

[17:01:28 - 17:01:33]
a Linux command that's why I'm executing

[17:01:30 - 17:01:34]
inside w. system okay then after that

[17:01:33 - 17:01:36]
whatever input user is giving I'm

[17:01:34 - 17:01:38]
getting the results I'm rendering the

[17:01:36 - 17:01:40]
answer okay that's it now let's open up

[17:01:38 - 17:01:43]
my application and let me show

[17:01:40 - 17:01:45]
you now I think this part would be clear

[17:01:43 - 17:01:49]
so I'll open up my terminal now let's uh

[17:01:45 - 17:01:52]
execute my app.py so app.py will open

[17:01:49 - 17:01:55]
it's running now let's go back now just

[17:01:52 - 17:01:56]
search for local host port number 8080

[17:01:55 - 17:01:58]
now see this is the interface of your

[17:01:56 - 17:02:00]
application okay now here you have to

[17:01:58 - 17:02:01]
give the URL so let's say I will give

[17:02:00 - 17:02:04]
this

[17:02:01 - 17:02:06]
URL I'll just give it here now see I'll

[17:02:04 - 17:02:08]
just send it now see in the back end

[17:02:06 - 17:02:09]
what will happen it will inest that

[17:02:08 - 17:02:11]
means it will clone this repository

[17:02:09 - 17:02:14]
first of all after that it will create

[17:02:11 - 17:02:16]
the embeddings and it will save this

[17:02:14 - 17:02:18]
embedding in the vector database now see

[17:02:16 - 17:02:21]
internally everything is executing if

[17:02:18 - 17:02:23]
you go here now see repo it is cloning

[17:02:21 - 17:02:25]
as well as DB would be also created now

[17:02:23 - 17:02:27]
let's wait and let's try to see so guys

[17:02:25 - 17:02:29]
as you can see my execution is done so

[17:02:27 - 17:02:31]
if execution is done you will see this

[17:02:29 - 17:02:33]
message actually

[17:02:31 - 17:02:37]
response okay

[17:02:33 - 17:02:40]
response so now if I open it up now see

[17:02:37 - 17:02:41]
my repo has invested and also my DB

[17:02:40 - 17:02:44]
object is created that means my

[17:02:41 - 17:02:45]
embeddings has already stored here now I

[17:02:44 - 17:02:47]
can perform the keyway operation for

[17:02:45 - 17:02:48]
this I'll be using this template right

[17:02:47 - 17:02:50]
now and this is the same actually

[17:02:48 - 17:02:52]
chatboard template I'm using from my

[17:02:50 - 17:02:53]
medical chatboard okay now here you can

[17:02:52 - 17:02:57]
give any kinds of question let's say

[17:02:53 - 17:03:00]
I'll give what is I'll ask the same

[17:02:57 - 17:03:04]
question again so I'll open the repo

[17:03:00 - 17:03:05]
SRC helper let's say will ask this one

[17:03:04 - 17:03:07]
download Hanging face like what is this

[17:03:05 - 17:03:09]
function and all

[17:03:07 - 17:03:12]
about

[17:03:09 - 17:03:12]
function let's

[17:03:13 - 17:03:17]
see see this is the answer I got the

[17:03:16 - 17:03:19]
download uh hugging face embedding

[17:03:17 - 17:03:20]
function responsible for downloading the

[17:03:19 - 17:03:23]
embedding model from the hugging face

[17:03:20 - 17:03:24]
called sentence this model and specifi

[17:03:23 - 17:03:27]
the

[17:03:24 - 17:03:30]
384 dimensional Vector great now I'll

[17:03:27 - 17:03:34]
ask another question what

[17:03:30 - 17:03:34]
is this function let's say text is

[17:03:38 - 17:03:43]
spit see text spit function see text

[17:03:41 - 17:03:45]
split function purposes to split the

[17:03:43 - 17:03:48]
extracted uh data into smaller text juns

[17:03:45 - 17:03:50]
this text chunks are useful for the

[17:03:48 - 17:03:53]
processing analyzing the text in a

[17:03:50 - 17:03:54]
smaller Moree manageable section great

[17:03:53 - 17:03:55]
that means it is giving you the correct

[17:03:54 - 17:03:58]
response now you can ask any kinds of

[17:03:55 - 17:03:59]
question regarding your source code okay

[17:03:58 - 17:04:02]
so this is the entire implementation

[17:03:59 - 17:04:04]
guys of our project uh yeah so I think

[17:04:02 - 17:04:06]
you like it guys and in the next video

[17:04:04 - 17:04:08]
we'll see the deployment like how we can

[17:04:06 - 17:04:11]
deploy these kinds of projects okay to

[17:04:08 - 17:04:13]
the uh like Cloud platform so for this

[17:04:11 - 17:04:15]
SE we'll be using AWS so in AWS I'll

[17:04:13 - 17:04:16]
show you the deployment part so before

[17:04:15 - 17:04:19]
ending the session first of all let me

[17:04:16 - 17:04:21]
comit the changes in my GitHub so I

[17:04:19 - 17:04:23]
don't want to push the repo

[17:04:21 - 17:04:25]
H let's say this repo I don't want to

[17:04:23 - 17:04:26]
push so what I can do see let me show

[17:04:25 - 17:04:28]
you another thing let's say if I give

[17:04:26 - 17:04:31]
clear message here it will remove the

[17:04:28 - 17:04:33]
repo folder automatically

[17:04:31 - 17:04:35]
see see repo folder would be deleted

[17:04:33 - 17:04:39]
because you have written the code here I

[17:04:35 - 17:04:43]
think remember uh inside

[17:04:39 - 17:04:43]
helper not helper I think inside app.

[17:04:43 - 17:04:48]
Pi see here if you give the clear it

[17:04:46 - 17:04:51]
will remove the repo folder okay now if

[17:04:48 - 17:04:53]
I click here now see then I also don't

[17:04:51 - 17:04:55]
want to push P this uh DB objects what I

[17:04:53 - 17:04:59]
can do in the G ignore I can mention

[17:04:55 - 17:04:59]
this DB let's say DB would be

[17:05:00 - 17:05:08]
IGN inside everything just try to ignore

[17:05:04 - 17:05:08]
now let's try to see ah D is

[17:05:08 - 17:05:14]
also okay another actually repo I'm

[17:05:10 - 17:05:17]
having inside resource so let me also

[17:05:14 - 17:05:21]
mention resarch

[17:05:17 - 17:05:23]
also inside resarch I'm having test repo

[17:05:21 - 17:05:27]
so everything I want to ignore as well

[17:05:23 - 17:05:27]
as I want to ignore the DB as

[17:05:27 - 17:05:31]
well now I

[17:05:32 - 17:05:36]
think okay research spelling is not

[17:05:34 - 17:05:38]
correct so it should be like that okay

[17:05:36 - 17:05:41]
research now let me

[17:05:38 - 17:05:43]
save now see it is ignoring everything

[17:05:41 - 17:05:45]
okay now let me push the changes so I'll

[17:05:43 - 17:05:47]
just write

[17:05:45 - 17:05:52]
updated

[17:05:47 - 17:05:52]
commit and seeing the changes

[17:05:54 - 17:05:58]
now if I get

[17:05:56 - 17:06:01]
back and refresh

[17:05:58 - 17:06:03]
here see all the source code has been

[17:06:01 - 17:06:05]
updated now let me write the further

[17:06:03 - 17:06:06]
step you can perform so here I have

[17:06:05 - 17:06:08]
added the next step like you have to

[17:06:06 - 17:06:11]
create the environment file inside that

[17:06:08 - 17:06:14]
just say open a API key and just run

[17:06:11 - 17:06:15]
app.py and uh you can execute your

[17:06:14 - 17:06:17]
project okay that's it now let me also

[17:06:15 - 17:06:22]
update this readme

[17:06:17 - 17:06:22]
file readme updated

[17:06:25 - 17:06:30]
now let's refresh here now see

[17:06:29 - 17:06:32]
everything is mentioned okay all of the

[17:06:30 - 17:06:34]
command I have shared with you so before

[17:06:32 - 17:06:35]
starting with our chain L discussion

[17:06:34 - 17:06:37]
first of all I just wanted to tell you

[17:06:35 - 17:06:40]
something uh like why we should use this

[17:06:37 - 17:06:41]
chain lit and uh as a data scientist

[17:06:40 - 17:06:43]
actually what are the difficulties

[17:06:41 - 17:06:46]
actually we Face uh whenever we try to

[17:06:43 - 17:06:49]
develop any kinds of application right

[17:06:46 - 17:06:51]
so uh I think uh you have used something

[17:06:49 - 17:06:54]
called stream lead to create your uh

[17:06:51 - 17:06:55]
this kind of web application even uh I

[17:06:54 - 17:06:57]
have already showed you how we can

[17:06:55 - 17:06:59]
create end to end like these kinds of

[17:06:57 - 17:07:02]
Genera VI projects with the help of

[17:06:59 - 17:07:05]
stream lit and all uh so uh see whenever

[17:07:02 - 17:07:07]
we are uh using streamlit it's a a

[17:07:05 - 17:07:10]
initial interface right initial uh like

[17:07:07 - 17:07:13]
uh demo of your application uh but

[17:07:10 - 17:07:15]
nowadays actually this llm cames and

[17:07:13 - 17:07:18]
people are creating lots of application

[17:07:15 - 17:07:19]
on top of these kinds of llms and uh

[17:07:18 - 17:07:21]
also like there are lots of application

[17:07:19 - 17:07:23]
there are lots of product in the market

[17:07:21 - 17:07:25]
right now like chat GPT is there Google

[17:07:23 - 17:07:27]
B is there right then Microsoft Bing

[17:07:25 - 17:07:29]
chat is also there so if you have seen

[17:07:27 - 17:07:31]
these kinds of product this kinds of

[17:07:29 - 17:07:34]
application so you will see like this

[17:07:31 - 17:07:35]
application has like very beautiful user

[17:07:34 - 17:07:37]
interface right so whenever let's say

[17:07:35 - 17:07:39]
I'm creating any kinds of conversational

[17:07:37 - 17:07:42]
agents okay let's say I'm creating any

[17:07:39 - 17:07:44]
kind of chatbot so we should have one

[17:07:42 - 17:07:46]
like very beautiful uh user interface

[17:07:44 - 17:07:48]
otherwise user might not get interest

[17:07:46 - 17:07:50]
okay uh with your uh application so that

[17:07:48 - 17:07:52]
is the main thing actually and gener it

[17:07:50 - 17:07:54]
provides actually these kinds of

[17:07:52 - 17:07:55]
beautiful user interface whenever you

[17:07:54 - 17:07:57]
are trying to create any kinds of

[17:07:55 - 17:08:00]
conversational agents and all so we can

[17:07:57 - 17:08:02]
use this chain Le to build uh these

[17:08:00 - 17:08:04]
kinds of llm app super fast okay I'll

[17:08:02 - 17:08:06]
tell you like why it is super fast

[17:08:04 - 17:08:08]
because you will see uh using very short

[17:08:06 - 17:08:10]
line of code will be uh creating these

[17:08:08 - 17:08:12]
kinds of application very easily right

[17:08:10 - 17:08:13]
but if you're using streamlit I think

[17:08:12 - 17:08:15]
you saw we need to write some more code

[17:08:13 - 17:08:18]
there okay but if you're using chain

[17:08:15 - 17:08:20]
lead so like more code doesn't required

[17:08:18 - 17:08:22]
here so only using some line of code

[17:08:20 - 17:08:24]
actually will be able to complete our

[17:08:22 - 17:08:26]
entire projects okay so this is like

[17:08:24 - 17:08:28]
very amazing package I was exploring and

[17:08:26 - 17:08:30]
I thought let's uh also show you this

[17:08:28 - 17:08:32]
one so that actually whenever you are

[17:08:30 - 17:08:34]
learning these kinds of large language

[17:08:32 - 17:08:36]
model generative AI so at the end you

[17:08:34 - 17:08:37]
need to build some application right so

[17:08:36 - 17:08:40]
you can use this kinds of chain lit

[17:08:37 - 17:08:42]
package uh with your application and uh

[17:08:40 - 17:08:43]
there is another reason actually you

[17:08:42 - 17:08:45]
should use uh this chain lit you should

[17:08:43 - 17:08:47]
explore this chain lit let's say you are

[17:08:45 - 17:08:49]
building some projects for your client

[17:08:47 - 17:08:52]
so you need to submit that projects to

[17:08:49 - 17:08:54]
your client so uh you need to sub some

[17:08:52 - 17:08:56]
good uh uh you can say output from your

[17:08:54 - 17:08:58]
side otherwise your client might not get

[17:08:56 - 17:08:59]
interest so at that time if you're using

[17:08:58 - 17:09:02]
this kinds of chain lad interface okay

[17:08:59 - 17:09:03]
chain lad package to create your apps

[17:09:02 - 17:09:05]
and all so it would be very much

[17:09:03 - 17:09:07]
realistic and it would be very much

[17:09:05 - 17:09:10]
amazing uh to your client whenever they

[17:09:07 - 17:09:12]
will look into your application so uh

[17:09:10 - 17:09:14]
that is why actually whenever you are

[17:09:12 - 17:09:16]
trying to build something you have

[17:09:14 - 17:09:17]
implemented any kinds of PC and all so

[17:09:16 - 17:09:19]
at a time just try to use these kinds of

[17:09:17 - 17:09:21]
chain lead package to create your apps

[17:09:19 - 17:09:23]
so that actually you can submit some

[17:09:21 - 17:09:25]
good application to your client okay and

[17:09:23 - 17:09:28]
they will be very much happy with you

[17:09:25 - 17:09:31]
right with your work so guys uh this is

[17:09:28 - 17:09:32]
the video agenda so first of all I will

[17:09:31 - 17:09:34]
uh take you through the chain lad

[17:09:32 - 17:09:36]
documentation then I will show you like

[17:09:34 - 17:09:39]
how we can use this chain lad and we'll

[17:09:36 - 17:09:41]
be building one basic chatboard here so

[17:09:39 - 17:09:43]
I'm going to implement one food delivery

[17:09:41 - 17:09:45]
chatboard so basically it will uh asks

[17:09:43 - 17:09:48]
for the order okay it will suggest you

[17:09:45 - 17:09:50]
the food then uh it will ask for the

[17:09:48 - 17:09:51]
location and it will like take your

[17:09:50 - 17:09:53]
order and all so this kind of of chatbot

[17:09:51 - 17:09:55]
actually will be implementing I think

[17:09:53 - 17:09:57]
you have seen like zatu right so we'll

[17:09:55 - 17:09:59]
be building some uh something like zatu

[17:09:57 - 17:10:01]
uh you can build anything but this is

[17:09:59 - 17:10:02]
the projects actually I prepared for you

[17:10:01 - 17:10:05]
so that actually you can learn something

[17:10:02 - 17:10:08]
right uh so I just wanted to like make

[17:10:05 - 17:10:09]
you this thing as realistic so that uh

[17:10:08 - 17:10:11]
whenever you are building your own

[17:10:09 - 17:10:13]
projects okay will get interest so yes

[17:10:11 - 17:10:15]
guys this is all about now let's start

[17:10:13 - 17:10:17]
with our CH discussion so guys as you

[17:10:15 - 17:10:19]
can see this is the chain lit

[17:10:17 - 17:10:21]
documentation and uh chain lit is

[17:10:19 - 17:10:23]
nothing but uh chain lit is an open

[17:10:21 - 17:10:26]
Source python package that makes uh

[17:10:23 - 17:10:28]
incredibly first to build chat GPT like

[17:10:26 - 17:10:31]
uh application uh with your own business

[17:10:28 - 17:10:34]
logic and data as you can see if I open

[17:10:31 - 17:10:36]
chat GPT so here you will see uh it has

[17:10:34 - 17:10:38]
one beautiful user interface okay that's

[17:10:36 - 17:10:41]
why user more interested to uh use this

[17:10:38 - 17:10:42]
kinds of chat GPT kinds of application

[17:10:41 - 17:10:44]
now let's see if you give any kinds of

[17:10:42 - 17:10:47]
message so it will take your message

[17:10:44 - 17:10:49]
even it will reply like that okay so

[17:10:47 - 17:10:51]
we'll be building something like that so

[17:10:49 - 17:10:54]
it would be like chat GPT like interface

[17:10:51 - 17:10:56]
right then if you see here it has also

[17:10:54 - 17:10:59]
official tutorial so you can also visit

[17:10:56 - 17:11:01]
the tutorial they have given so from

[17:10:59 - 17:11:03]
there actually you can also learn but I

[17:11:01 - 17:11:04]
will uh make this video very simple so

[17:11:03 - 17:11:06]
that actually you can understand each

[17:11:04 - 17:11:08]
and everything like uh uh you don't need

[17:11:06 - 17:11:09]
to go through even the documentation I

[17:11:08 - 17:11:11]
will uh discuss everything whatever

[17:11:09 - 17:11:13]
things actually you need to explore okay

[17:11:11 - 17:11:15]
and apart from that anything is left and

[17:11:13 - 17:11:17]
anything you want to explore from your

[17:11:15 - 17:11:20]
side you can visit the documentation and

[17:11:17 - 17:11:22]
learn okay uh yes guys this is the

[17:11:20 - 17:11:24]
documentation as you can see and it has

[17:11:22 - 17:11:27]
also integration with these kinds of

[17:11:24 - 17:11:29]
Lang Chen then autogen lamb index okay

[17:11:27 - 17:11:30]
you can either uh use open either use

[17:11:29 - 17:11:32]
Lang chain either use lamb index

[17:11:30 - 17:11:34]
anything you can use okay all the things

[17:11:32 - 17:11:36]
has been integrated with that so in this

[17:11:34 - 17:11:39]
video actually I'm going to use open AI

[17:11:36 - 17:11:41]
API that means I'm going to use U GPT

[17:11:39 - 17:11:43]
3.5 turbo model to create this

[17:11:41 - 17:11:45]
application because I just want to uh

[17:11:43 - 17:11:47]
show you quickly that's why I will be

[17:11:45 - 17:11:48]
using this open AI model because there

[17:11:47 - 17:11:50]
actually I will get one API key and

[17:11:48 - 17:11:52]
everything would be done for me right

[17:11:50 - 17:11:54]
but you can also use open source large

[17:11:52 - 17:11:56]
language model I I think I already taken

[17:11:54 - 17:11:58]
some of the session like how we can use

[17:11:56 - 17:12:01]
Google Pam to Lama then we have Lama 2

[17:11:58 - 17:12:03]
then we have Falcon we have Mr 7B

[17:12:01 - 17:12:04]
anything you can use here you can also

[17:12:03 - 17:12:06]
integrate Lang chain with that I have

[17:12:04 - 17:12:08]
already showed you like lots of things

[17:12:06 - 17:12:11]
with the help of Lang chain and all so

[17:12:08 - 17:12:13]
you can explore this thing right so yes

[17:12:11 - 17:12:15]
guys this is the documentation now here

[17:12:13 - 17:12:17]
they have already given some starter

[17:12:15 - 17:12:20]
code like how we can start with this uh

[17:12:17 - 17:12:22]
chain L and all so I'll show you like

[17:12:20 - 17:12:24]
how we can launch this chain lead app

[17:12:22 - 17:12:26]
and all okay but before that what I need

[17:12:24 - 17:12:30]
to do I'll be creating one GitHub

[17:12:26 - 17:12:31]
repository so here is my GitHub so let

[17:12:30 - 17:12:34]
me create one GitHub repository I'll

[17:12:31 - 17:12:36]
name it as uh llm app with chain lad you

[17:12:34 - 17:12:40]
can give any kinds of name so let's keep

[17:12:36 - 17:12:42]
it as public I'll add rme file then G

[17:12:40 - 17:12:44]
ignore wise I'll be using Python and

[17:12:42 - 17:12:46]
license you can take any kinds of

[17:12:44 - 17:12:50]
license so let's take MIT license then I

[17:12:46 - 17:12:50]
will be creating my Repository

[17:12:51 - 17:12:55]
now uh let's clone this uh repository in

[17:12:53 - 17:12:57]
my local machine so I'll copy this link

[17:12:55 - 17:13:01]
address

[17:12:57 - 17:13:05]
and I will open my uh local machine and

[17:13:01 - 17:13:05]
here uh I'll open my

[17:13:07 - 17:13:13]
terminal and just write get

[17:13:10 - 17:13:17]
clone and paste this link and clone

[17:13:13 - 17:13:20]
it okay now I'll redirect to this folder

[17:13:17 - 17:13:21]
llm apps with chain lit now I am inside

[17:13:20 - 17:13:25]
this

[17:13:21 - 17:13:27]
uh folder now here I will launch my vs

[17:13:25 - 17:13:30]
code so you can use any kinds of code

[17:13:27 - 17:13:33]
editor it's completely

[17:13:30 - 17:13:35]
fine so I already opened my vs code now

[17:13:33 - 17:13:37]
here I'll be creating some of the um

[17:13:35 - 17:13:38]
like folders and file then we'll be

[17:13:37 - 17:13:40]
doing the environment setup because I

[17:13:38 - 17:13:41]
need to install some of the libraries

[17:13:40 - 17:13:43]
like let's say chain lit I need to

[17:13:41 - 17:13:46]
install then I need to also install open

[17:13:43 - 17:13:47]
and all okay so let's do it and uh see

[17:13:46 - 17:13:50]
like how we can use this kinds of chain

[17:13:47 - 17:13:53]
lit so here uh I'm going to create one

[17:13:50 - 17:13:55]
for folder called

[17:13:53 - 17:13:59]
SRC then inside SRC I'm going to create

[17:13:55 - 17:14:03]
one file called underscore uncore init

[17:13:59 - 17:14:04]
_ dop uh I think you already know why

[17:14:03 - 17:14:06]
this Constructor is needed because I'm

[17:14:04 - 17:14:08]
going to consider this SRC as my local

[17:14:06 - 17:14:10]
package because here I'm going to

[17:14:08 - 17:14:12]
writing some of the Python file and from

[17:14:10 - 17:14:13]
that file I'll be importing some of the

[17:14:12 - 17:14:15]
function and all okay that's why I need

[17:14:13 - 17:14:17]
to create it I think I showed you in my

[17:14:15 - 17:14:19]
Bend projects okay what is the use of

[17:14:17 - 17:14:21]
this then uh inside that actually I'm

[17:14:19 - 17:14:25]
going to create uh two

[17:14:21 - 17:14:29]
file uh one file I will keep my llm

[17:14:25 - 17:14:32]
model and another file I will keep my uh

[17:14:29 - 17:14:35]
system related configuration or you can

[17:14:32 - 17:14:40]
also talk about this prompt okay you can

[17:14:35 - 17:14:45]
uh also tell it as prompt so prompt

[17:14:40 - 17:14:50]
dop yeah now uh outside I will create

[17:14:45 - 17:14:50]
another uh file called app.py

[17:14:51 - 17:14:55]
app.py then I also need something called

[17:14:53 - 17:14:57]
requirement. txt so

[17:14:55 - 17:15:00]
[Music]

[17:14:57 - 17:15:02]
requirements.txt

[17:15:00 - 17:15:05]
then I also need something called

[17:15:02 - 17:15:07]
setup.py because of this local package

[17:15:05 - 17:15:09]
installation yeah so this thing is

[17:15:07 - 17:15:11]
required now let me just write down all

[17:15:09 - 17:15:13]
the requirements actually I'm going to

[17:15:11 - 17:15:17]
use so the first requirement actually I

[17:15:13 - 17:15:18]
need something called uh chain lit so CH

[17:15:17 - 17:15:20]
lit so this is the package you need to

[17:15:18 - 17:15:21]
install then I need something called

[17:15:20 - 17:15:24]
open

[17:15:21 - 17:15:27]
ni uh then I need something called

[17:15:24 - 17:15:30]
python Dov I think you know why we need

[17:15:27 - 17:15:33]
this EnV because I'll be keeping my uh

[17:15:30 - 17:15:36]
like open credential inside this EnV

[17:15:33 - 17:15:39]
file and using this python. EnV I will

[17:15:36 - 17:15:40]
read that uh yeah then I also need

[17:15:39 - 17:15:43]
something called hypen space dot because

[17:15:40 - 17:15:45]
of this setup.py now let me create that

[17:15:43 - 17:15:47]
file also

[17:15:45 - 17:15:50]
EnV

[17:15:47 - 17:15:52]
EnV so here uh I'm going to paste my

[17:15:50 - 17:15:54]
open my API key so I already created

[17:15:52 - 17:15:56]
this API key so you can also create your

[17:15:54 - 17:15:59]
own API key okay don't use my one I will

[17:15:56 - 17:16:01]
just remove it after this recording uh

[17:15:59 - 17:16:02]
then uh I need to install these are the

[17:16:01 - 17:16:04]
requirements so for this I need to

[17:16:02 - 17:16:07]
create one virtual environment so I'll

[17:16:04 - 17:16:13]
open my terminal and here I'll just

[17:16:07 - 17:16:15]
write cond create typen in uh let's name

[17:16:13 - 17:16:20]
it as uh

[17:16:15 - 17:16:24]
chain or I can give uh yeah chain lit

[17:16:20 - 17:16:27]
chain lead demo this is the environment

[17:16:24 - 17:16:29]
name and python version wise I'll be

[17:16:27 - 17:16:32]
using python

[17:16:29 - 17:16:32]
3.9 and H and

[17:16:42 - 17:16:46]
Y now let's activate my

[17:16:48 - 17:16:56]
invironment H now I'll installing the

[17:16:51 - 17:16:59]
requirement so just WR P install

[17:16:56 - 17:16:59]
henard requirement.

[17:17:00 - 17:17:05]
txt okay it's giving error because

[17:17:03 - 17:17:07]
because we haven't added uh like

[17:17:05 - 17:17:09]
setup.py code here that is why it's

[17:17:07 - 17:17:11]
throwing error so I think you remember

[17:17:09 - 17:17:14]
so this code actually we usually add

[17:17:11 - 17:17:16]
inside our setup. PI so this code is a

[17:17:14 - 17:17:19]
responsible uh to find this uh

[17:17:16 - 17:17:21]
Constructor file and it will set up that

[17:17:19 - 17:17:23]
folder as my local package okay and you

[17:17:21 - 17:17:25]
here you can check the uh check the

[17:17:23 - 17:17:27]
project name version author name email

[17:17:25 - 17:17:30]
address and anything right now let me

[17:17:27 - 17:17:32]
install them

[17:17:30 - 17:17:35]
so now I'll again execute my

[17:17:32 - 17:17:35]
requirement.

[17:17:39 - 17:17:46]
txt so it may take some time let's wait

[17:17:42 - 17:17:46]
I'll come back when it is done

[17:17:50 - 17:17:54]
so guys as you can see my installation

[17:17:52 - 17:17:56]
is done

[17:17:54 - 17:17:59]
now yeah so everything is done now let

[17:17:56 - 17:18:04]
me select the environment I created

[17:17:59 - 17:18:07]
here so it was uh chain L demo yeah

[17:18:04 - 17:18:10]
that's it now first of all Let's test it

[17:18:07 - 17:18:13]
whether everything is fine or

[17:18:10 - 17:18:16]
not so uh I'll close these are the file

[17:18:13 - 17:18:19]
first of all yeah so I'll visit this

[17:18:16 - 17:18:21]
documentation again uh this chain L

[17:18:19 - 17:18:23]
documentation and if you click on in

[17:18:21 - 17:18:26]
pure python so they have given one um

[17:18:23 - 17:18:28]
like code here so let me just copy so

[17:18:26 - 17:18:30]
this code actually this is the Eco like

[17:18:28 - 17:18:33]
if you send anything so it will response

[17:18:30 - 17:18:35]
the same message okay as Eco so it's

[17:18:33 - 17:18:37]
just for the testing purpose like uh

[17:18:35 - 17:18:39]
whether we are able to launch our chain

[17:18:37 - 17:18:42]
Le tap or not and it is working fine or

[17:18:39 - 17:18:45]
not okay so first of all let me uh check

[17:18:42 - 17:18:47]
it everything is fine or not then I'll

[17:18:45 - 17:18:49]
uh add my logic I'll add my chatbot

[17:18:47 - 17:18:51]
logic here and here if you see this code

[17:18:49 - 17:18:53]
will remain same and here you just need

[17:18:51 - 17:18:55]
to write your logic okay uh here we'll

[17:18:53 - 17:18:57]
be writing our custom logic and this

[17:18:55 - 17:19:01]
code will remain same okay and this is

[17:18:57 - 17:19:04]
the eobot currently now here uh what I

[17:19:01 - 17:19:06]
need to do uh I'll open my terminal and

[17:19:04 - 17:19:07]
if you visit the documentation so there

[17:19:06 - 17:19:10]
telling first of all you need to write

[17:19:07 - 17:19:13]
one command called chain

[17:19:10 - 17:19:14]
lit chain lit init okay first of all you

[17:19:13 - 17:19:16]
need to initialize the chain lit here so

[17:19:14 - 17:19:18]
it will create one folder here called do

[17:19:16 - 17:19:19]
chain lit and inside that it will

[17:19:18 - 17:19:21]
contain all the

[17:19:19 - 17:19:23]
configuration see it has created this

[17:19:21 - 17:19:25]
chain lead inside that it has created

[17:19:23 - 17:19:26]
another toml file this is the

[17:19:25 - 17:19:28]
configuration file and it has all the

[17:19:26 - 17:19:31]
configuration okay so here is the

[17:19:28 - 17:19:33]
configuration so you can change this uh

[17:19:31 - 17:19:35]
GitHub URL and all okay you can also

[17:19:33 - 17:19:37]
change the project name here so here is

[17:19:35 - 17:19:39]
the project name you can also change it

[17:19:37 - 17:19:41]
so these kinds of configuration you can

[17:19:39 - 17:19:43]
change so I'll just keep it as default

[17:19:41 - 17:19:46]
no issue with

[17:19:43 - 17:19:48]
that then um I'll again open my terminal

[17:19:46 - 17:19:51]
again I will run one command called

[17:19:48 - 17:19:54]
chain lit run

[17:19:51 - 17:19:55]
app.py okay now if I execute this

[17:19:54 - 17:19:59]
command so you will see it will launch

[17:19:55 - 17:20:01]
one uh server for me and this it is

[17:19:59 - 17:20:04]
running on Local Host port number 8,000

[17:20:01 - 17:20:07]
so I'll give allow access and this is

[17:20:04 - 17:20:09]
the default user interface okay so why

[17:20:07 - 17:20:11]
this message is coming here welcome to

[17:20:09 - 17:20:13]
chain lit and all so if you see here it

[17:20:11 - 17:20:15]
has created one uh MD file here

[17:20:13 - 17:20:17]
automatically it has created one. MD

[17:20:15 - 17:20:18]
file like markdown file and these are

[17:20:17 - 17:20:20]
the content actually it has

[17:20:18 - 17:20:22]
automatically generated okay now let's

[17:20:20 - 17:20:26]
see if I change anything here so let's

[17:20:22 - 17:20:29]
say I will change welcome to uh my

[17:20:26 - 17:20:32]
bot okay if I change anything here now

[17:20:29 - 17:20:35]
if I go to my app and refresh see it has

[17:20:32 - 17:20:36]
changed that means if you want to let's

[17:20:35 - 17:20:38]
say print any kinds of massage okay

[17:20:36 - 17:20:40]
whenever user will launch your uh

[17:20:38 - 17:20:44]
application okay so you can customize

[17:20:40 - 17:20:46]
here so I already created this uh MD

[17:20:44 - 17:20:48]
file I already made some customization

[17:20:46 - 17:20:51]
there because I told you I'm going to

[17:20:48 - 17:20:54]
implement something called uh uh this

[17:20:51 - 17:20:56]
one jatu bot okay so for this actually I

[17:20:54 - 17:20:57]
created some of the content related jatu

[17:20:56 - 17:20:59]
and again I generated these are the

[17:20:57 - 17:21:01]
content with the help of chat GPT okay

[17:20:59 - 17:21:06]
so let me show you like what are things

[17:21:01 - 17:21:09]
I have done so here I'll just copy paste

[17:21:06 - 17:21:12]
see this is the content I prepared hello

[17:21:09 - 17:21:14]
welcome to zato bot and here I'm just uh

[17:21:12 - 17:21:17]
showing some of the item like P we have

[17:21:14 - 17:21:19]
pizzas then pasta noodles then Asian

[17:21:17 - 17:21:21]
Cuisines okay so these are the thing

[17:21:19 - 17:21:23]
actually I have gener generated with the

[17:21:21 - 17:21:25]
help of chat gbt so here you can give

[17:21:23 - 17:21:27]
anything any message whatever you feel

[17:21:25 - 17:21:28]
good you can give it here and whatever

[17:21:27 - 17:21:31]
application you are building with

[17:21:28 - 17:21:33]
respect to that just add the content

[17:21:31 - 17:21:35]
here now if I go back to my application

[17:21:33 - 17:21:37]
and refresh it see guys now it has

[17:21:35 - 17:21:38]
changed to this content okay now let's

[17:21:37 - 17:21:41]
see if I give any kind of message here

[17:21:38 - 17:21:43]
hi so it will give me the same response

[17:21:41 - 17:21:45]
like hi okay now if I open my chat GPT

[17:21:43 - 17:21:47]
and if you just compare with the chat

[17:21:45 - 17:21:49]
GPT okay now see it's looking like chat

[17:21:47 - 17:21:52]
GPT only right so that's why they're

[17:21:49 - 17:21:54]
telling ch is nothing but it's a like

[17:21:52 - 17:21:56]
open source python package and with the

[17:21:54 - 17:21:58]
help of that you can create chat gbt

[17:21:56 - 17:22:00]
like interface okay chat chat gbt like

[17:21:58 - 17:22:03]
application so I love this chit a lot

[17:22:00 - 17:22:06]
because see only using this line of code

[17:22:03 - 17:22:08]
okay only using this line of code like

[17:22:06 - 17:22:10]
uh this only using just one function we

[17:22:08 - 17:22:11]
are able to launch this kinds of user

[17:22:10 - 17:22:13]
interface now let's see if you're

[17:22:11 - 17:22:15]
building any kinds of product for your

[17:22:13 - 17:22:17]
client so if you submit like that so

[17:22:15 - 17:22:20]
they will be pretty much impressed by

[17:22:17 - 17:22:21]
your work okay so that is why actually

[17:22:20 - 17:22:23]
we should always use some good user

[17:22:21 - 17:22:25]
interface whenever we are delivering our

[17:22:23 - 17:22:29]
application right now here you can give

[17:22:25 - 17:22:30]
any message like I am buy so it will

[17:22:29 - 17:22:33]
give you the sa response okay because we

[17:22:30 - 17:22:35]
have created the eobot how it is working

[17:22:33 - 17:22:37]
so let me show you so they have created

[17:22:35 - 17:22:39]
one function and this is The Decorator

[17:22:37 - 17:22:41]
they're using this chain L decorator so

[17:22:39 - 17:22:42]
this decorator is handling everything

[17:22:41 - 17:22:44]
and again they're using asence and AIT

[17:22:42 - 17:22:47]
because asence and AET is helping us to

[17:22:44 - 17:22:50]
read this message okay real time so it

[17:22:47 - 17:22:51]
is always sensing our uh input and when

[17:22:50 - 17:22:53]
whenever we are giving something it is

[17:22:51 - 17:22:55]
receiving and it is also sending the

[17:22:53 - 17:22:57]
message to the front end right so this

[17:22:55 - 17:22:59]
is the like code simple code now here

[17:22:57 - 17:23:01]
we'll be writing our custom logic so

[17:22:59 - 17:23:04]
basically we'll be building one uh Jato

[17:23:01 - 17:23:05]
bot with the help of this um large

[17:23:04 - 17:23:09]
language model I'll be using uh like

[17:23:05 - 17:23:12]
open a GPT uh 3.5 turbo and uh here

[17:23:09 - 17:23:14]
we'll be like chatting with our bot okay

[17:23:12 - 17:23:16]
with the help of this Chann Le and here

[17:23:14 - 17:23:18]
if you see your app name is chatbot

[17:23:16 - 17:23:20]
currently so you can also change this

[17:23:18 - 17:23:22]
name so I told you there is a

[17:23:20 - 17:23:25]
configuration it has generated now if

[17:23:22 - 17:23:27]
you go below so here is the option to

[17:23:25 - 17:23:28]
change the name so by default it is

[17:23:27 - 17:23:32]
chatbot so we can also give something

[17:23:28 - 17:23:35]
called U uh chatbot

[17:23:32 - 17:23:35]
for

[17:23:36 - 17:23:39]
zato

[17:23:39 - 17:23:45]
zato okay now if I refresh and again

[17:23:43 - 17:23:48]
refresh

[17:23:45 - 17:23:52]
here um I need to I think stop the

[17:23:48 - 17:23:52]
execution so I'll open my

[17:23:57 - 17:24:02]
code now guys see this name has been

[17:23:59 - 17:24:05]
changed uh chatbot for zato okay now I

[17:24:02 - 17:24:07]
can uh close the previous one and again

[17:24:05 - 17:24:10]
it's the eobot now guys let's uh add our

[17:24:07 - 17:24:12]
custom logic so so for this first of all

[17:24:10 - 17:24:14]
I will prepare my llm that means large

[17:24:12 - 17:24:16]
language model so this is the file so

[17:24:14 - 17:24:18]
here first of all I'm going to import

[17:24:16 - 17:24:22]
open AI so I think you know open has

[17:24:18 - 17:24:25]
been updated uh now it is like a latest

[17:24:22 - 17:24:26]
version so they have upgraded lots of

[17:24:25 - 17:24:28]
thing and if you visit that

[17:24:26 - 17:24:29]
documentation currently so if I go to

[17:24:28 - 17:24:31]
this

[17:24:29 - 17:24:35]
open

[17:24:31 - 17:24:35]
open.com and if I log

[17:24:38 - 17:24:43]
in so this is the documentation now

[17:24:41 - 17:24:45]
let's uh go to any kinds of task and

[17:24:43 - 17:24:47]
let's see how we need to import see this

[17:24:45 - 17:24:49]
is the UT and we need to uh like

[17:24:47 - 17:24:52]
initialize this client object okay but

[17:24:49 - 17:24:54]
initially we just uh need to install uh

[17:24:52 - 17:24:56]
like import open a okay that's how we we

[17:24:54 - 17:24:57]
can do it but now now actually you need

[17:24:56 - 17:25:00]
to import like that from open import

[17:24:57 - 17:25:02]
open a okay so this is the updated

[17:25:00 - 17:25:04]
version of openi and if you see here we

[17:25:02 - 17:25:05]
need to upgrade it also okay if you are

[17:25:04 - 17:25:08]
using previous one so you need to

[17:25:05 - 17:25:11]
upgrade also okay so this is the like uh

[17:25:08 - 17:25:12]
requirement you always need to follow U

[17:25:11 - 17:25:13]
you always need to upgrade with the

[17:25:12 - 17:25:16]
documentation otherwise you might get

[17:25:13 - 17:25:20]
some issue okay so let's import open a

[17:25:16 - 17:25:20]
so from open import

[17:25:21 - 17:25:24]
open

[17:25:22 - 17:25:27]
AI okay so I need to make one client

[17:25:24 - 17:25:30]
object here client open

[17:25:27 - 17:25:32]
AI then here I will be initializing one

[17:25:30 - 17:25:33]
function I'll create one function so

[17:25:32 - 17:25:36]
I'll name this function as

[17:25:33 - 17:25:36]
ask uh

[17:25:37 - 17:25:43]
order okay ask

[17:25:39 - 17:25:44]
order so uh this function will uh like

[17:25:43 - 17:25:46]
uh this is going to be like main

[17:25:44 - 17:25:48]
function so basically this function will

[17:25:46 - 17:25:50]
uh give me the response what whatever

[17:25:48 - 17:25:52]
question actually user will ask so it

[17:25:50 - 17:25:53]
will take the masses first of all it

[17:25:52 - 17:25:56]
will take the

[17:25:53 - 17:25:59]
masses then uh it will also take the

[17:25:56 - 17:26:05]
model so model wise model wise I'll be

[17:25:59 - 17:26:08]
using something called GPT um 3.5 turbo

[17:26:05 - 17:26:10]
3.5 uh 3.5 turbo so this is the model

[17:26:08 - 17:26:13]
I'm going to use you can use any kinds

[17:26:10 - 17:26:15]
of model you can use dpt4 U anything you

[17:26:13 - 17:26:17]
can use here I'll be using this model

[17:26:15 - 17:26:19]
because this model charge would be a

[17:26:17 - 17:26:20]
little bit less for me so that's why

[17:26:19 - 17:26:22]
then I will also take uh this

[17:26:20 - 17:26:24]
temperature

[17:26:22 - 17:26:27]
value uh what is temperature I think you

[17:26:24 - 17:26:29]
know in llm temperature is like uh uh

[17:26:27 - 17:26:31]
like how much Randomness you want from

[17:26:29 - 17:26:33]
your model okay if you're giving it to

[17:26:31 - 17:26:34]
zero so that means it won't be giving

[17:26:33 - 17:26:37]
any Randomness it won't be like more

[17:26:34 - 17:26:39]
creative it will give be give you Auto

[17:26:37 - 17:26:40]
like always stick output but if your

[17:26:39 - 17:26:42]
setting is too close to one that means

[17:26:40 - 17:26:44]
uh you're telling your model to take

[17:26:42 - 17:26:46]
risk and it will also generat some

[17:26:44 - 17:26:49]
random output okay so that's why this

[17:26:46 - 17:26:52]
temperature parameter is important also

[17:26:49 - 17:26:54]
now this is my function now here U they

[17:26:52 - 17:26:56]
have already given like how to

[17:26:54 - 17:26:58]
initialize this uh one if you see here

[17:26:56 - 17:27:00]
so we need to use something called cent.

[17:26:58 - 17:27:05]
chat completion. create so let me copy

[17:27:00 - 17:27:05]
this line I'll copy this

[17:27:07 - 17:27:12]
line then I will uh open my code and

[17:27:09 - 17:27:12]
here I will add

[17:27:16 - 17:27:20]
it now inside that I think you saw first

[17:27:19 - 17:27:22]
of all it will take the model model

[17:27:20 - 17:27:24]
model is equal to

[17:27:22 - 17:27:27]
model then uh it will also take

[17:27:24 - 17:27:28]
something called masses okay masses so

[17:27:27 - 17:27:30]
what is masses here so let me show you

[17:27:28 - 17:27:32]
see message is nothing but uh it's kinds

[17:27:30 - 17:27:34]
of prompt actually you are giving uh

[17:27:32 - 17:27:36]
basically you are giving some U like

[17:27:34 - 17:27:38]
zero short or few short prompt here like

[17:27:36 - 17:27:41]
you are telling this is the role okay

[17:27:38 - 17:27:44]
role means system system means like you

[17:27:41 - 17:27:46]
are the role okay like you as a uh

[17:27:44 - 17:27:48]
chatbot this is your RO system and this

[17:27:46 - 17:27:50]
is the content so you are a helpful

[17:27:48 - 17:27:52]
assistant okay basically it is uh I'm

[17:27:50 - 17:27:54]
telling to my bot you are help assistant

[17:27:52 - 17:27:56]
and whenever user okay user is giving

[17:27:54 - 17:27:58]
some content okay let's say this is the

[17:27:56 - 17:28:01]
content user has given so you also need

[17:27:58 - 17:28:02]
to uh reply as a assistant okay as you

[17:28:01 - 17:28:04]
can see this is this is this should be

[17:28:02 - 17:28:07]
your answer so that means we are giving

[17:28:04 - 17:28:08]
some prompt here okay we are just uh

[17:28:07 - 17:28:11]
giving some zero shot or free shot

[17:28:08 - 17:28:12]
prompt here to my llm so that my llm can

[17:28:11 - 17:28:15]
understand what kinds of job actually I

[17:28:12 - 17:28:16]
want to perform okay so I think you

[17:28:15 - 17:28:18]
already learned this prompt engineering

[17:28:16 - 17:28:20]
and all okay so this is very much

[17:28:18 - 17:28:22]
important here so let's also Define this

[17:28:20 - 17:28:25]
one so I already prepared one prompt

[17:28:22 - 17:28:27]
here so let me show you so you can also

[17:28:25 - 17:28:30]
create your custom prompt there is no

[17:28:27 - 17:28:34]
issue with that so in this prom. Pi I'll

[17:28:30 - 17:28:38]
paste it out so this is going to be like

[17:28:34 - 17:28:40]
uh very creative uh the more good prompt

[17:28:38 - 17:28:41]
you actually will uh give to your llm

[17:28:40 - 17:28:43]
the more good results actually you will

[17:28:41 - 17:28:45]
get okay so this is the prompt actually

[17:28:43 - 17:28:47]
I developed so system instruction as you

[17:28:45 - 17:28:49]
can see you to bought an automated

[17:28:47 - 17:28:52]
service to collect other orders from

[17:28:49 - 17:28:54]
online restaurant okay if you see here

[17:28:52 - 17:28:56]
so many like content I have written here

[17:28:54 - 17:28:58]
like so here I'm just trying to making

[17:28:56 - 17:29:01]
my B understand like what uh it is going

[17:28:58 - 17:29:04]
to do exactly and these are the actually

[17:29:01 - 17:29:07]
item I also like pasted here so if

[17:29:04 - 17:29:08]
anyone is asking like for the menu so uh

[17:29:07 - 17:29:09]
it should return something right so

[17:29:08 - 17:29:11]
these are the actually prompt I have

[17:29:09 - 17:29:13]
developed from my site okay so this

[17:29:11 - 17:29:14]
prompt actually I'm going to use now I

[17:29:13 - 17:29:17]
think you remember you need to create

[17:29:14 - 17:29:18]
one uh format as you can see roll as

[17:29:17 - 17:29:20]
system assistant so that's kinds of

[17:29:18 - 17:29:23]
format actually you need so for this

[17:29:20 - 17:29:27]
actually I already prepared so this is

[17:29:23 - 17:29:29]
going to be the format as you can see

[17:29:27 - 17:29:31]
massage roll system content and system

[17:29:29 - 17:29:34]
instruction I need to import from my

[17:29:31 - 17:29:37]
prompt so here I'll just write

[17:29:34 - 17:29:44]
from uh

[17:29:37 - 17:29:46]
SRC SRC do uh hiab llm no sorry SRC do

[17:29:44 - 17:29:50]
prompt then I need to import something

[17:29:46 - 17:29:50]
called system instruction

[17:29:50 - 17:29:54]
okay so here you here is my system

[17:29:52 - 17:29:57]
instruction I'm importing this one now

[17:29:54 - 17:30:00]
here I'm just telling RO system and

[17:29:57 - 17:30:03]
content okay so here I'm giving the

[17:30:00 - 17:30:05]
prompt to my llm as you can see now this

[17:30:03 - 17:30:08]
message actually I'll will give it

[17:30:05 - 17:30:10]
here okay

[17:30:08 - 17:30:14]
yes now I also need to set the

[17:30:10 - 17:30:18]
temperature so temperature is equal to

[17:30:14 - 17:30:19]
temperature okay now uh this will also

[17:30:18 - 17:30:22]
return something as you can see if you

[17:30:19 - 17:30:23]
go below so this is the response format

[17:30:22 - 17:30:26]
it will give you this kinds of format as

[17:30:23 - 17:30:29]
a response it's a Json format response

[17:30:26 - 17:30:31]
so from here actually I will um need to

[17:30:29 - 17:30:34]
collect this content okay if you see

[17:30:31 - 17:30:35]
here I need to uh collect this content

[17:30:34 - 17:30:37]
okay content is the response okay actual

[17:30:35 - 17:30:39]
response and these are some parameter it

[17:30:37 - 17:30:41]
will also give you so if you want to

[17:30:39 - 17:30:44]
like extract the content so you can copy

[17:30:41 - 17:30:46]
this either you can also copy this one

[17:30:44 - 17:30:49]
uh you can also copy this one okay this

[17:30:46 - 17:30:49]
one also you can copy

[17:30:50 - 17:30:57]
so let me copy this one and I'll open my

[17:30:53 - 17:30:57]
part again and here I'll just write

[17:30:58 - 17:31:03]
return uh response. Choice message.

[17:31:01 - 17:31:06]
content I only need the content okay so

[17:31:03 - 17:31:09]
this is my function I have developed so

[17:31:06 - 17:31:11]
it should be messages instead of masses

[17:31:09 - 17:31:13]
yeah now it's fine so now uh I will

[17:31:11 - 17:31:15]
write my final logic so I'll open my

[17:31:13 - 17:31:18]
app. Pi so here first of all I need to

[17:31:15 - 17:31:21]
import my uh this function ask order so

[17:31:18 - 17:31:21]
let me import so from

[17:31:22 - 17:31:27]
SRC llm

[17:31:25 - 17:31:30]
import uh ask

[17:31:27 - 17:31:32]
order then I also need to import

[17:31:30 - 17:31:33]
something called messages okay because

[17:31:32 - 17:31:36]
here if you see we have also created

[17:31:33 - 17:31:38]
this messages I also need this one here

[17:31:36 - 17:31:42]
let me save

[17:31:38 - 17:31:44]
it h then if I show you now here if you

[17:31:42 - 17:31:46]
see here whenever I was discussing this

[17:31:44 - 17:31:48]
thing so you need to prepare this

[17:31:46 - 17:31:49]
message okay uh we have created for the

[17:31:48 - 17:31:51]
system okay system that means we have

[17:31:49 - 17:31:53]
given The Prompt now I also need to

[17:31:51 - 17:31:56]
create for the user okay like whatever

[17:31:53 - 17:31:59]
uh input user will give okay so for this

[17:31:56 - 17:32:03]
in this uh like a list actually if I

[17:31:59 - 17:32:05]
show you uh we have a message okay this

[17:32:03 - 17:32:08]
is the list actually and inside that we

[17:32:05 - 17:32:11]
have a dictionary so I need to add some

[17:32:08 - 17:32:12]
more like you can say u u i mean masses

[17:32:11 - 17:32:14]
as you can see one by one so this is for

[17:32:12 - 17:32:17]
the system then I also need to add for

[17:32:14 - 17:32:20]
the user as well okay so I need to just

[17:32:17 - 17:32:24]
append it so for this um what I need to

[17:32:20 - 17:32:24]
do so I'll open my app.py and

[17:32:25 - 17:32:30]
here um you can appen like that so I'll

[17:32:28 - 17:32:32]
just write message. appen and here I'm

[17:32:30 - 17:32:34]
just initializing my user right now R

[17:32:32 - 17:32:35]
this is user and this is the content

[17:32:34 - 17:32:37]
what is the content user will give the

[17:32:35 - 17:32:39]
message okay the message actually will

[17:32:37 - 17:32:41]
send okay the message actually will send

[17:32:39 - 17:32:43]
from here so this is going to be the

[17:32:41 - 17:32:45]
content so it will uh store here okay it

[17:32:43 - 17:32:46]
will store it here that means in this

[17:32:45 - 17:32:49]
list because we are doing the append

[17:32:46 - 17:32:52]
operation right so once it is done I

[17:32:49 - 17:32:55]
also need to uh give this message okay I

[17:32:52 - 17:32:55]
also need to give this

[17:32:55 - 17:33:02]
message uh to my uh bot so I'll just

[17:32:59 - 17:33:04]
write ask order inside that it will take

[17:33:02 - 17:33:04]
the

[17:33:06 - 17:33:11]
messages okay then it will also give me

[17:33:09 - 17:33:11]
something called

[17:33:11 - 17:33:15]
response it will give some some uh it

[17:33:14 - 17:33:19]
will give me something called response

[17:33:15 - 17:33:21]
okay now uh if you see here I also need

[17:33:19 - 17:33:24]
to uh provide the response here if I

[17:33:21 - 17:33:26]
show you I also need to give the

[17:33:24 - 17:33:28]
assistant response as well okay as you

[17:33:26 - 17:33:31]
can see assistant response as well so

[17:33:28 - 17:33:33]
again I will append so I whenever I will

[17:33:31 - 17:33:35]
receive the response okay I will extract

[17:33:33 - 17:33:35]
the

[17:33:35 - 17:33:41]
content so uh as a assistant actually it

[17:33:38 - 17:33:43]
will uh give me some response so this

[17:33:41 - 17:33:45]
response actually I'm appending because

[17:33:43 - 17:33:46]
if you if I show you here this response

[17:33:45 - 17:33:48]
should be my content okay as you can see

[17:33:46 - 17:33:51]
it is returning the content and that

[17:33:48 - 17:33:53]
content actually I'm storing now once it

[17:33:51 - 17:33:57]
is done uh now I also need to send the

[17:33:53 - 17:33:59]
response to my uh this uh chain lad user

[17:33:57 - 17:34:01]
interface right so to do it actually if

[17:33:59 - 17:34:03]
you see by default it is sending the uh

[17:34:01 - 17:34:04]
like Eco command only the message user

[17:34:03 - 17:34:06]
is giving the same message actually it

[17:34:04 - 17:34:09]
is uh sending so instead of that

[17:34:06 - 17:34:11]
actually I just need to send my uh

[17:34:09 - 17:34:15]
response okay this is the response

[17:34:11 - 17:34:18]
actually I need to send to my uh front

[17:34:15 - 17:34:20]
end done uh yes so this is the logic

[17:34:18 - 17:34:22]
only so this is a uh like very easy code

[17:34:20 - 17:34:24]
we have written now here you can also

[17:34:22 - 17:34:26]
integrate your open source llm you can

[17:34:24 - 17:34:28]
use Pam 2 you can use Lama okay you can

[17:34:26 - 17:34:29]
also use Falcon anything you can use I

[17:34:28 - 17:34:31]
think I already showed you how to use

[17:34:29 - 17:34:33]
them and you can also integrate Lang CH

[17:34:31 - 17:34:36]
with that okay so if you're using open

[17:34:33 - 17:34:37]
source llm so you can also use uh Lang

[17:34:36 - 17:34:39]
chain okay with the help of Lang chain

[17:34:37 - 17:34:41]
you can also do it and the same thing

[17:34:39 - 17:34:43]
you can uh do the uh return here okay as

[17:34:41 - 17:34:45]
a response now let's test it whether

[17:34:43 - 17:34:47]
it's working or not so I'll go back to

[17:34:45 - 17:34:50]
my so I'll go back to my uh chain lit

[17:34:47 - 17:34:52]
then I will refresh yeah now let's say

[17:34:50 - 17:34:55]
if I give any message let's say

[17:34:52 - 17:34:57]
hi so it is received High because I need

[17:34:55 - 17:35:02]
to I think

[17:34:57 - 17:35:02]
uh uh restart it so I'll open

[17:35:02 - 17:35:09]
my uh open my terminal and I will close

[17:35:06 - 17:35:12]
the execution if you press uh contr C it

[17:35:09 - 17:35:15]
will close now now let's restart again

[17:35:12 - 17:35:18]
so I have restarted

[17:35:15 - 17:35:21]
now here is my new one now let's see if

[17:35:18 - 17:35:24]
I give any message

[17:35:21 - 17:35:28]
hi see it's giving hello uh welcome to

[17:35:24 - 17:35:30]
zomato how I can assist you so here uh I

[17:35:28 - 17:35:32]
can give

[17:35:30 - 17:35:36]
uh

[17:35:32 - 17:35:36]
my name is

[17:35:36 - 17:35:43]
buy

[17:35:39 - 17:35:47]
uh and I am

[17:35:43 - 17:35:49]
looking for some I'm looking for

[17:35:47 - 17:35:52]
something I'm looking something for

[17:35:49 - 17:35:55]
dinner I can I'm looking

[17:35:52 - 17:35:58]
something

[17:35:55 - 17:35:58]
for

[17:35:58 - 17:36:03]
dinner okay now it is telling hi buppy

[17:36:01 - 17:36:05]
I'm here to help you find something

[17:36:03 - 17:36:08]
delicious for dinner what type of kins

[17:36:05 - 17:36:12]
you uh you are in mood for we have

[17:36:08 - 17:36:16]
options like pizza pasta then Asian cins

[17:36:12 - 17:36:18]
then uh Beverages and Indian cins let me

[17:36:16 - 17:36:22]
know you're preferred so I'll uh tell

[17:36:18 - 17:36:25]
I'll will go for I will go

[17:36:22 - 17:36:25]
for Indian

[17:36:29 - 17:36:35]
food okay now see it is giving great

[17:36:32 - 17:36:37]
choice buppy Indian kins is always uh

[17:36:35 - 17:36:39]
treat and here is some option for the

[17:36:37 - 17:36:41]
Indian menu now it is telling butter

[17:36:39 - 17:36:43]
chicken we have with none and even it is

[17:36:41 - 17:36:45]
also giving the cost because we have

[17:36:43 - 17:36:48]
added the promt here I think you

[17:36:45 - 17:36:49]
remember then chicken T Tika Masala rice

[17:36:48 - 17:36:54]
then palak pan

[17:36:49 - 17:36:58]
then uh chana masala vegetable Biryani

[17:36:54 - 17:37:01]
Samosa Lai so I'll give I need this one

[17:36:58 - 17:37:05]
chicken tikka masala with rice

[17:37:01 - 17:37:10]
okay so I'll just write um

[17:37:05 - 17:37:13]
add chicken tikka masala rice in

[17:37:10 - 17:37:13]
the

[17:37:14 - 17:37:19]
cart yeah so I have added chicken TI

[17:37:17 - 17:37:23]
masal the cut uh is there anything else

[17:37:19 - 17:37:28]
would you like to order or this is all

[17:37:23 - 17:37:28]
for you uh no it's

[17:37:30 - 17:37:35]
fine okay all right here is the summary

[17:37:32 - 17:37:37]
of your order so you Tak Masala now if

[17:37:35 - 17:37:39]
you see this is the price now it is

[17:37:37 - 17:37:42]
telling uh is that correct and would you

[17:37:39 - 17:37:49]
like to pick up your order or have it

[17:37:42 - 17:37:49]
delivered so I'll tell have it delivered

[17:37:53 - 17:37:58]
delivered great we have uh Del uh we'll

[17:37:56 - 17:38:01]
deliver your order to you could you

[17:37:58 - 17:38:02]
please provide me your delivery address

[17:38:01 - 17:38:08]
so I'll give some address here so I'll

[17:38:02 - 17:38:08]
tell uh I'll tell my address my address

[17:38:09 - 17:38:15]
is uh this is my address let's give this

[17:38:12 - 17:38:16]
address okay so thanks for providing

[17:38:15 - 17:38:20]
your address buy your order will be

[17:38:16 - 17:38:22]
delivered uh to 17th floor uh Brigade

[17:38:20 - 17:38:25]
signature Tower the total amount for

[17:38:22 - 17:38:28]
your order $10.99 how would you like to

[17:38:25 - 17:38:31]
make the payment uh we accept cash on

[17:38:28 - 17:38:34]
delivery or online payment I'll go for

[17:38:31 - 17:38:34]
cash on delivery cash

[17:38:35 - 17:38:38]
on cash on

[17:38:39 - 17:38:44]
delivery perfect you can uh pay in Cash

[17:38:42 - 17:38:46]
When the delivery thank for uh the

[17:38:44 - 17:38:48]
placing your order your chicken Tika

[17:38:46 - 17:38:52]
Masala with rice will be delivered

[17:38:48 - 17:38:54]
shortly if you have any other questions

[17:38:52 - 17:38:58]
or need further assistant feel free to

[17:38:54 - 17:39:03]
ask enjoy your mail uh

[17:38:58 - 17:39:05]
great thank you okay see guys uh we have

[17:39:03 - 17:39:07]
implemented one amazing food delivery B

[17:39:05 - 17:39:09]
uh with the help of this chain lead and

[17:39:07 - 17:39:12]
now see the interface guys it's like

[17:39:09 - 17:39:14]
very professional very amazing right

[17:39:12 - 17:39:15]
very amazing now if you deliver this

[17:39:14 - 17:39:17]
project to someone else they will be

[17:39:15 - 17:39:19]
going mad right like whatever things

[17:39:17 - 17:39:21]
actually you have developed right now

[17:39:19 - 17:39:23]
now uh what I will do quickly I'll just

[17:39:21 - 17:39:25]
uh now uh what I will do I will just

[17:39:23 - 17:39:27]
quickly commit the changes to my GitHub

[17:39:25 - 17:39:30]
so that I see you can get the code so

[17:39:27 - 17:39:30]
I'll just write uh

[17:39:30 - 17:39:33]
completed

[17:39:40 - 17:39:45]
comment done now if I go back to my

[17:39:43 - 17:39:48]
gethub and

[17:39:45 - 17:39:50]
refresh yeah so you have committed so

[17:39:48 - 17:39:52]
yes guys uh this was was the demo of the

[17:39:50 - 17:39:55]
CH lit I think uh you enjoyed this

[17:39:52 - 17:39:57]
package a lot and even I'm also enjoying

[17:39:55 - 17:39:59]
this package a lot okay I'm just trying

[17:39:57 - 17:40:01]
to use this uh Trend L package to build

[17:39:59 - 17:40:03]
my llm apps and all and see guys like by

[17:40:01 - 17:40:05]
using some uh like very less line of

[17:40:03 - 17:40:06]
code actually we are able to build this

[17:40:05 - 17:40:09]
kinds of awesome application and it's

[17:40:06 - 17:40:10]
like very fast right uh now we'll try to

[17:40:09 - 17:40:12]
uh see the deployment part like how we

[17:40:10 - 17:40:14]
can deploy these kinds of projects on

[17:40:12 - 17:40:16]
the cloud platform so I think you

[17:40:14 - 17:40:18]
already know we implemented so many NN

[17:40:16 - 17:40:20]
project right so implemented medical

[17:40:18 - 17:40:21]
chatboard then source SC analysis they

[17:40:20 - 17:40:24]
then we also implemented something

[17:40:21 - 17:40:26]
called J to chatbot right so different

[17:40:24 - 17:40:28]
different application we imp implemented

[17:40:26 - 17:40:29]
so far now in this video I'll will show

[17:40:28 - 17:40:31]
you how we can deploy these kinds of

[17:40:29 - 17:40:32]
application on the cloud platform that

[17:40:31 - 17:40:34]
means here we'll be deploying our

[17:40:32 - 17:40:36]
application on the AWS Cloud if you want

[17:40:34 - 17:40:38]
to learn any other Cloud deployment it

[17:40:36 - 17:40:40]
is also fine see the process will remain

[17:40:38 - 17:40:42]
same only the cloud functionality would

[17:40:40 - 17:40:44]
be different so uh I'll try to create

[17:40:42 - 17:40:46]
some more video on the deployment like

[17:40:44 - 17:40:48]
I'll also show you how we can deploy

[17:40:46 - 17:40:50]
these kinds of project on the gcp cloud

[17:40:48 - 17:40:51]
on the let's say the aure Cloud but

[17:40:50 - 17:40:54]
first of all let's try to see how we can

[17:40:51 - 17:40:55]
deploy this project on the AWS cloud and

[17:40:54 - 17:40:57]
see this is not going to be a simple

[17:40:55 - 17:40:59]
deployment so here we'll be doing

[17:40:57 - 17:41:02]
continuous integration and continuous

[17:40:59 - 17:41:04]
delivery or deployment that means cicd

[17:41:02 - 17:41:06]
so I think you have heard of this uh

[17:41:04 - 17:41:08]
particular term called cicd right so

[17:41:06 - 17:41:10]
we'll be learning how we can deploy uh

[17:41:08 - 17:41:12]
this project as a cicd I think you

[17:41:10 - 17:41:13]
already know how to deploy any machine

[17:41:12 - 17:41:15]
learning project de learning project as

[17:41:13 - 17:41:18]
cicd but we haven't seen how we can

[17:41:15 - 17:41:20]
deploy any kinds of genv based project

[17:41:18 - 17:41:22]
as a cicd right so that's why make sure

[17:41:20 - 17:41:23]
you are uh watching this video till the

[17:41:22 - 17:41:25]
end so here I'm going to show you each

[17:41:23 - 17:41:27]
and every step you have to follow and

[17:41:25 - 17:41:30]
trust me if you follow this step guys

[17:41:27 - 17:41:32]
you can use this step to deploy any

[17:41:30 - 17:41:33]
kinds of let's say gen VI project okay

[17:41:32 - 17:41:36]
and this is going to be production grade

[17:41:33 - 17:41:37]
deployment okay so here I'm going to use

[17:41:36 - 17:41:39]
different different kinds of service

[17:41:37 - 17:41:41]
from the AWS even I I I'll be also using

[17:41:39 - 17:41:43]
Docker that means first of all we'll be

[17:41:41 - 17:41:44]
dockerizing the entire source code then

[17:41:43 - 17:41:46]
we'll be deploying this application on

[17:41:44 - 17:41:48]
the cloud platform okay so make sure you

[17:41:46 - 17:41:50]
are watching this video till the end so

[17:41:48 - 17:41:52]
before starting the deployment guys

[17:41:50 - 17:41:53]
first of all let me show you what

[17:41:52 - 17:41:56]
exactly we're going to perform here what

[17:41:53 - 17:41:57]
is cicd exactly then I will also discuss

[17:41:56 - 17:41:58]
let's say what are the tools and

[17:41:57 - 17:42:00]
Technology will be using here what are

[17:41:58 - 17:42:02]
the services we'll be using here then I

[17:42:00 - 17:42:04]
will start with the deployment and make

[17:42:02 - 17:42:06]
sure you have the AWS account if you

[17:42:04 - 17:42:07]
don't have the awx account guys so you

[17:42:06 - 17:42:09]
won't be able to deploy this project so

[17:42:07 - 17:42:10]
first of all try to create one account

[17:42:09 - 17:42:12]
if you're creating for the first time

[17:42:10 - 17:42:14]
you will get $300 free credit okay and

[17:42:12 - 17:42:16]
this is enough for you so try to create

[17:42:14 - 17:42:18]
an account guys then you can start with

[17:42:16 - 17:42:19]
the deployment with me so let's open up

[17:42:18 - 17:42:21]
our Blackboard and try to to see the

[17:42:19 - 17:42:23]
architecture overview so guys as I

[17:42:21 - 17:42:25]
already told you here we'll be doing

[17:42:23 - 17:42:27]
something called cicd deployment right

[17:42:25 - 17:42:29]
and I already told you what is uh cicd

[17:42:27 - 17:42:31]
full form it's continuous integration

[17:42:29 - 17:42:33]
continuous delivery or deployment right

[17:42:31 - 17:42:34]
so inside continuous integration

[17:42:33 - 17:42:36]
continuous delivery what happens let's

[17:42:34 - 17:42:38]
say you are the

[17:42:36 - 17:42:41]
developer okay let's say you are the

[17:42:38 - 17:42:44]
developer so what is your task your task

[17:42:41 - 17:42:47]
is to develop a project in the

[17:42:44 - 17:42:49]
development let's say environment so

[17:42:47 - 17:42:50]
development environment means like your

[17:42:49 - 17:42:53]
local system let's say you are using

[17:42:50 - 17:42:55]
your laptop or computer let's say local

[17:42:53 - 17:42:58]
computer okay

[17:42:55 - 17:42:58]
local

[17:42:58 - 17:43:03]
computer fine then what we are doing I

[17:43:01 - 17:43:04]
think you remember we are committing

[17:43:03 - 17:43:06]
this code to the GitHub right we are

[17:43:04 - 17:43:07]
doing the code management I think you

[17:43:06 - 17:43:09]
remember that means that means whenever

[17:43:07 - 17:43:10]
I was adding some new feature I was

[17:43:09 - 17:43:13]
pushing this code to the

[17:43:10 - 17:43:15]
GitHub yes or no okay with the help of

[17:43:13 - 17:43:17]
git client we are pushing the code in

[17:43:15 - 17:43:19]
the GitHub GitHub server now what

[17:43:17 - 17:43:20]
happens actually let's say after

[17:43:19 - 17:43:23]
deployment so this is called actually

[17:43:20 - 17:43:26]
development server or I can write uh

[17:43:23 - 17:43:26]
this is actually development

[17:43:27 - 17:43:33]
environment okay development environment

[17:43:29 - 17:43:34]
so after implementing this project what

[17:43:33 - 17:43:37]
we have to do we have to deploy this

[17:43:34 - 17:43:39]
project yes or no let's say um somehow

[17:43:37 - 17:43:41]
you have deployed this project on the

[17:43:39 - 17:43:44]
AWS Cloud let's say this is your AWS

[17:43:41 - 17:43:46]
Cloud fine so let's say you have

[17:43:44 - 17:43:49]
deployed this project to the a

[17:43:46 - 17:43:51]
cloud manually manually you you just

[17:43:49 - 17:43:53]
created a let's say instance there you

[17:43:51 - 17:43:55]
create you just took a machine there K2

[17:43:53 - 17:43:58]
machine and you manually deployed this

[17:43:55 - 17:43:59]
project now it will give you some

[17:43:58 - 17:44:02]
endpoint okay

[17:43:59 - 17:44:04]
endpoint so with the help of this

[17:44:02 - 17:44:07]
endpoint any of the

[17:44:04 - 17:44:10]
user okay user can access your

[17:44:07 - 17:44:12]
application now let's say after 4 month

[17:44:10 - 17:44:15]
or let's say 6 month you want to add

[17:44:12 - 17:44:17]
some more features in this let's say uh

[17:44:15 - 17:44:19]
application let's say you are deploying

[17:44:17 - 17:44:22]
medical chatboard the medic chat but we

[17:44:19 - 17:44:23]
implemented I think you remember right

[17:44:22 - 17:44:25]
let's say you want to add some more data

[17:44:23 - 17:44:27]
you want to add some more knowledge base

[17:44:25 - 17:44:28]
and you want to add some more features

[17:44:27 - 17:44:30]
in this application then what you have

[17:44:28 - 17:44:32]
to do you have to again develop this

[17:44:30 - 17:44:33]
let's say features in your code then

[17:44:32 - 17:44:36]
what you will be doing again you'll be

[17:44:33 - 17:44:37]
deploying this application to the cloud

[17:44:36 - 17:44:40]
now just try to see whenever you are

[17:44:37 - 17:44:41]
deploying the project for the second

[17:44:40 - 17:44:42]
time let's say this is the first time

[17:44:41 - 17:44:44]
you have deployed then you are trying to

[17:44:42 - 17:44:47]
reply for the second time then what you

[17:44:44 - 17:44:50]
have to do first of all you have to stop

[17:44:47 - 17:44:51]
this application in thews okay stop this

[17:44:50 - 17:44:53]
application then you will be uploading

[17:44:51 - 17:44:55]
your updated code then this code will

[17:44:53 - 17:44:57]
reflect to the endpoint then user will

[17:44:55 - 17:44:59]
able to access that now let's say in

[17:44:57 - 17:45:02]
between whenever you stop this AWS

[17:44:59 - 17:45:05]
server let's say your uh application

[17:45:02 - 17:45:07]
let's say it took 3 hours it took 3

[17:45:05 - 17:45:10]
hours to change the entire source code

[17:45:07 - 17:45:11]
that means uh change the entire features

[17:45:10 - 17:45:13]
okay of your application so what will

[17:45:11 - 17:45:15]
happen 3 hours user won't be able to

[17:45:13 - 17:45:17]
access your application so they will

[17:45:15 - 17:45:19]
come your website and they will see

[17:45:17 - 17:45:22]
server error okay server error actually

[17:45:19 - 17:45:23]
they will get so if user is getting

[17:45:22 - 17:45:26]
these kinds of experience so definitely

[17:45:23 - 17:45:27]
it would be a negative let's say effect

[17:45:26 - 17:45:29]
okay on your application so next time

[17:45:27 - 17:45:31]
actually they are not going to use your

[17:45:29 - 17:45:34]
application yes or no let's say if CH

[17:45:31 - 17:45:36]
GPT is down for the uh let's say 3 hours

[17:45:34 - 17:45:38]
definitely people will move to the

[17:45:36 - 17:45:41]
Google b or any other let's say software

[17:45:38 - 17:45:43]
whatever we are having okay so now see

[17:45:41 - 17:45:45]
chat chat GPT is also updating their

[17:45:43 - 17:45:48]
let's say application day by day but did

[17:45:45 - 17:45:49]
you ever observe this server is down no

[17:45:48 - 17:45:51]
you are not seeing the servers is down

[17:45:49 - 17:45:53]
but still they're able to make the

[17:45:51 - 17:45:54]
changes in their application how because

[17:45:53 - 17:45:55]
they are following something called cicd

[17:45:54 - 17:45:57]
approach continuous integration

[17:45:55 - 17:45:59]
continuous delivery that means this

[17:45:57 - 17:46:01]
application is keep on running but in

[17:45:59 - 17:46:02]
the back end they're pushing their

[17:46:01 - 17:46:04]
source code they're pushing their let's

[17:46:02 - 17:46:05]
say new features and this feature is

[17:46:04 - 17:46:07]
automatically getting updated okay so

[17:46:05 - 17:46:10]
this is collect cicd that means you are

[17:46:07 - 17:46:11]
not going to deploy this application

[17:46:10 - 17:46:12]
manual instead of that what you have to

[17:46:11 - 17:46:14]
do you have to follow the cicd that

[17:46:12 - 17:46:16]
means what will happen let's say you

[17:46:14 - 17:46:18]
have changed something in your code you

[17:46:16 - 17:46:20]
will push the code to the GitHub okay

[17:46:18 - 17:46:23]
GitHub will automatically uh let's say

[17:46:20 - 17:46:25]
deploy your code to the AWS Cloud it

[17:46:23 - 17:46:28]
will automatically push your code to the

[17:46:25 - 17:46:30]
AWS cloud and your endpoint would be

[17:46:28 - 17:46:32]
automatically updated okay automatically

[17:46:30 - 17:46:34]
updated so that if user is using your

[17:46:32 - 17:46:37]
application okay they won't be filling

[17:46:34 - 17:46:39]
any kinds of let's say server down issue

[17:46:37 - 17:46:41]
okay server down issue actually they

[17:46:39 - 17:46:43]
won't be failing got it so this is what

[17:46:41 - 17:46:45]
actually uh we have to do that means

[17:46:43 - 17:46:46]
we'll be creating the entire pipeline

[17:46:45 - 17:46:49]
entire let's say cicd pipeline so we'll

[17:46:46 - 17:46:52]
be just pushing the code in our GTH iub

[17:46:49 - 17:46:54]
and GitHub will automatically trigger uh

[17:46:52 - 17:46:56]
this uh action and my code will updated

[17:46:54 - 17:46:59]
to the AWS cloud and AWS will update the

[17:46:56 - 17:47:01]
end point okay now see the automated

[17:46:59 - 17:47:02]
process we'll be doing now whenever we

[17:47:01 - 17:47:04]
we'll let's say push our code to the

[17:47:02 - 17:47:06]
GitHub GitHub will automatically trigger

[17:47:04 - 17:47:09]
how it will trigger for this you have to

[17:47:06 - 17:47:11]
use some cicd tool okay cicd tool cicd

[17:47:09 - 17:47:12]
automation tool so here there are

[17:47:11 - 17:47:13]
different kinds of cicd tool so the

[17:47:12 - 17:47:16]
first to you can use something called

[17:47:13 - 17:47:18]
GitHub action okay GitHub action you can

[17:47:16 - 17:47:19]
use then you can use something called

[17:47:18 - 17:47:21]
Jenkins

[17:47:19 - 17:47:22]
okay genkins then you can use something

[17:47:21 - 17:47:26]
called Circle

[17:47:22 - 17:47:27]
C Circle CI so these actually three

[17:47:26 - 17:47:29]
famous tool actually we are having in

[17:47:27 - 17:47:31]
the market right now so people are using

[17:47:29 - 17:47:33]
more this GitHub action because GitHub

[17:47:31 - 17:47:34]
action you don't need to set up anything

[17:47:33 - 17:47:36]
it is already set up everything in the

[17:47:34 - 17:47:37]
GitHub but if you're using genkins and

[17:47:36 - 17:47:39]
circle CI you have to set up this server

[17:47:37 - 17:47:40]
manually okay so here we'll be using

[17:47:39 - 17:47:42]
GitHub action because it is already

[17:47:40 - 17:47:43]
inbuilt with the GitHub we don't need to

[17:47:42 - 17:47:45]
set up anything going forward I will

[17:47:43 - 17:47:47]
also show you how we can uh let's say

[17:47:45 - 17:47:49]
use genin Circle CI these are the

[17:47:47 - 17:47:50]
services as well fine so yes guys this

[17:47:49 - 17:47:53]
is the complete uh high level

[17:47:50 - 17:47:54]
architecture of our deployment now now

[17:47:53 - 17:47:56]
let's discuss what the services actually

[17:47:54 - 17:47:57]
will be using for the deployment see

[17:47:56 - 17:48:00]
here the first Services actually I'm

[17:47:57 - 17:48:02]
going to use uh called

[17:48:00 - 17:48:04]
Docker so I think you already know

[17:48:02 - 17:48:06]
Docker so Docker is a containerization

[17:48:04 - 17:48:07]
service so with the help of that you can

[17:48:06 - 17:48:09]
containerize your code that means let's

[17:48:07 - 17:48:11]
say you are having a source code you can

[17:48:09 - 17:48:12]
perform the containerization that means

[17:48:11 - 17:48:15]
it will create a Docker image for you

[17:48:12 - 17:48:16]
okay so this image you can let's say

[17:48:15 - 17:48:18]
keep anywh let you can keep in the

[17:48:16 - 17:48:20]
docker Hub you can keep let's say in the

[17:48:18 - 17:48:21]
ECR that mean elastic container regist

[17:48:20 - 17:48:23]
from there you can pull the image and

[17:48:21 - 17:48:25]
you can execute this image okay so if

[17:48:23 - 17:48:26]
you using Docker so you won't be getting

[17:48:25 - 17:48:28]
any kinds of setup issue this is the

[17:48:26 - 17:48:32]
main advantage here then we'll be using

[17:48:28 - 17:48:34]
something called ECR here ECR ECR means

[17:48:32 - 17:48:37]
elastic container resist so this is the

[17:48:34 - 17:48:39]
service from the AWS okay AWS giving the

[17:48:37 - 17:48:41]
service so here you can store any kinds

[17:48:39 - 17:48:43]
of Docker image it is the same like your

[17:48:41 - 17:48:45]
Docker Hub okay but it is the uh it is

[17:48:43 - 17:48:47]
the service from the AWS you can store

[17:48:45 - 17:48:49]
the private image there but in dockerhub

[17:48:47 - 17:48:51]
actually the all the image be public

[17:48:49 - 17:48:54]
this is the difference only now we'll be

[17:48:51 - 17:48:55]
using another service called ec2 okay

[17:48:54 - 17:48:58]
ec2 is a virtual machine service from

[17:48:55 - 17:48:59]
the AWS again it is from the AWS okay so

[17:48:58 - 17:49:01]
this will give you virtual machine there

[17:48:59 - 17:49:04]
you can buy let's say CPU based machine

[17:49:01 - 17:49:05]
GPU based machine okay so all kinds of

[17:49:04 - 17:49:07]
configuration would be there so here

[17:49:05 - 17:49:09]
we're using a local computer so there

[17:49:07 - 17:49:11]
we'll be getting a cloud computer okay

[17:49:09 - 17:49:13]
this is the difference only then as a

[17:49:11 - 17:49:15]
cicd tool I'll be using something GitHub

[17:49:13 - 17:49:17]
action as I already told

[17:49:15 - 17:49:19]
you okay we'll be using GitHub action

[17:49:17 - 17:49:22]
for the cicd

[17:49:19 - 17:49:24]
cicd management fine so yes Guys these

[17:49:22 - 17:49:26]
are the services as of now I'm going to

[17:49:24 - 17:49:28]
use so let me show you the deployment

[17:49:26 - 17:49:30]
step will be following for this what I

[17:49:28 - 17:49:31]
have done guys I think remember we

[17:49:30 - 17:49:33]
implemented one medical chatbot this is

[17:49:31 - 17:49:35]
the code and this code would be also

[17:49:33 - 17:49:36]
available uh in your resources section

[17:49:35 - 17:49:38]
even you will also get this code in my

[17:49:36 - 17:49:40]
GitHub so guys this is my GitHub profile

[17:49:38 - 17:49:42]
just search entb in the Google you will

[17:49:40 - 17:49:44]
see my GitHub and here I have created

[17:49:42 - 17:49:46]
one repository called uh Inn medical

[17:49:44 - 17:49:48]
chatbot so I'm going to commit this code

[17:49:46 - 17:49:50]
here so you will get all the source code

[17:49:48 - 17:49:51]
from this repository itself okay and

[17:49:50 - 17:49:53]
even I will also add the deployment step

[17:49:51 - 17:49:54]
in the readme file so that is what

[17:49:53 - 17:49:55]
actually I have written you can see the

[17:49:54 - 17:49:57]
entire deployment step I have written

[17:49:55 - 17:49:59]
here now this is the cicd deployment

[17:49:57 - 17:50:00]
will be following so first of all what I

[17:49:59 - 17:50:03]
have to do we have to uh let's say

[17:50:00 - 17:50:05]
create a im user uh then we'll be uh

[17:50:03 - 17:50:07]
creating the2 machine easier okay then

[17:50:05 - 17:50:08]
we'll be see this is the deployment step

[17:50:07 - 17:50:10]
as of now just try to follow the step

[17:50:08 - 17:50:13]
I'm going to show you first of all we'll

[17:50:10 - 17:50:14]
be building our uh so here first of all

[17:50:13 - 17:50:15]
we'll be building the docker image of

[17:50:14 - 17:50:17]
our source code that means Docker image

[17:50:15 - 17:50:19]
we'll be implementing then we'll be

[17:50:17 - 17:50:20]
pushing this Docker image to the e that

[17:50:19 - 17:50:22]
means elastic container to store my

[17:50:20 - 17:50:24]
Docker image then we'll be pulling this

[17:50:22 - 17:50:26]
image from uh from ECR in the ec2 that

[17:50:24 - 17:50:29]
means we'll be pulling that image in the

[17:50:26 - 17:50:31]
ec2 machine in our virtual computer then

[17:50:29 - 17:50:32]
we'll be launching this Docker image in

[17:50:31 - 17:50:34]
my E2 machine and from there we'll be

[17:50:32 - 17:50:36]
creating an endpoint and that endpoint

[17:50:34 - 17:50:37]
user will be able to access okay and

[17:50:36 - 17:50:38]
these are the policy I have to give

[17:50:37 - 17:50:40]
whenever I will be creating the IM am

[17:50:38 - 17:50:42]
user fine so this is the entire step

[17:50:40 - 17:50:43]
guys I have uh written even I have also

[17:50:42 - 17:50:45]
given all the command you need to

[17:50:43 - 17:50:47]
execute here now let's start the

[17:50:45 - 17:50:49]
deployment guys but before that you just

[17:50:47 - 17:50:50]
need to prepare some of the files the

[17:50:49 - 17:50:52]
first file you have to prepare the

[17:50:50 - 17:50:54]
docker file so this file will help you

[17:50:52 - 17:50:54]
to containerize entire your application

[17:50:54 - 17:50:56]
that means it will perform the

[17:50:54 - 17:50:58]
dockerization and these are the docker

[17:50:56 - 17:51:00]
command you have to write so I think

[17:50:58 - 17:51:02]
remember we are using python 3.10 okay

[17:51:00 - 17:51:05]
this python version that's why I've

[17:51:02 - 17:51:06]
taken python 3.10 slim Buster image then

[17:51:05 - 17:51:07]
working directory it will create a

[17:51:06 - 17:51:09]
working directory called app inside that

[17:51:07 - 17:51:10]
it will copy all the source code then it

[17:51:09 - 17:51:11]
will install the requirements okay

[17:51:10 - 17:51:14]
whatever requirements actually we are

[17:51:11 - 17:51:17]
having here it then it will execute this

[17:51:14 - 17:51:18]
Python 3 app.py command so that means my

[17:51:17 - 17:51:20]
endpoint would be executed okay okay my

[17:51:18 - 17:51:23]
application would be running and make

[17:51:20 - 17:51:25]
sure uh before actually deployment you

[17:51:23 - 17:51:27]
just store your index okay in the pine

[17:51:25 - 17:51:28]
cone so this is the pine con guys it is

[17:51:27 - 17:51:31]
running and all the vector is already

[17:51:28 - 17:51:33]
stored here you can see 7,20 uh uh

[17:51:31 - 17:51:35]
actually record is already stored here

[17:51:33 - 17:51:37]
so I already executed this file I think

[17:51:35 - 17:51:39]
remember store index so it will create

[17:51:37 - 17:51:40]
all the let's say Vector embedding and

[17:51:39 - 17:51:43]
it will store in the pine con okay Pine

[17:51:40 - 17:51:44]
con Vector database so in this project I

[17:51:43 - 17:51:46]
was using pine con I think remember okay

[17:51:44 - 17:51:48]
so this should be available here got it

[17:51:46 - 17:51:50]
so once it is available now what have to

[17:51:48 - 17:51:51]
do guys then you can create another file

[17:51:50 - 17:51:53]
called Docker ignore inside Docker

[17:51:51 - 17:51:55]
ignore you can mention like some of the

[17:51:53 - 17:51:58]
file which is not required let's say

[17:51:55 - 17:52:00]
here this file is not required let's say

[17:51:58 - 17:52:03]
uh I think this file is not required

[17:52:00 - 17:52:05]
genv project do. EG info okay so

[17:52:03 - 17:52:07]
whenever it will perform the let's say

[17:52:05 - 17:52:09]
containerization that means uh

[17:52:07 - 17:52:11]
dockerization so I don't need this uh

[17:52:09 - 17:52:13]
folder that time what you can do you can

[17:52:11 - 17:52:14]
mention this folder name in the doer

[17:52:13 - 17:52:16]
Docker ignore file it is the same thing

[17:52:14 - 17:52:17]
as your git ignore so it is already

[17:52:16 - 17:52:19]
mentioned inside inside my git ignore

[17:52:17 - 17:52:20]
that's why I haven't mention inside my

[17:52:19 - 17:52:22]
Docker ignore Docker ignot is completely

[17:52:20 - 17:52:25]
empty as of now I need all the file

[17:52:22 - 17:52:26]
that's why I haven't keep anything here

[17:52:25 - 17:52:27]
now let's say if you want to ignore any

[17:52:26 - 17:52:29]
kind of file which is not required that

[17:52:27 - 17:52:31]
time you can store this other file

[17:52:29 - 17:52:33]
inside Docker ignore okay that's the

[17:52:31 - 17:52:35]
thing now the next things you have to

[17:52:33 - 17:52:37]
create you have to create one folder

[17:52:35 - 17:52:38]
called do GitHub okay inside that you

[17:52:37 - 17:52:40]
have to create one folder called

[17:52:38 - 17:52:42]
workflows inside that you have to create

[17:52:40 - 17:52:44]
one yl file you can give any name here I

[17:52:42 - 17:52:46]
have given C.L okay now see this is the

[17:52:44 - 17:52:49]
complete EML file so this EML file will

[17:52:46 - 17:52:51]
help me to do the cic deployment okay

[17:52:49 - 17:52:53]
that means uh here it will be using

[17:52:51 - 17:52:56]
something called GitHub action okay and

[17:52:53 - 17:52:57]
GitHub action need this yl file so here

[17:52:56 - 17:52:59]
all the command is already written so

[17:52:57 - 17:53:00]
first of all you will see that it will

[17:52:59 - 17:53:02]
perform continuous integration inside

[17:53:00 - 17:53:04]
continuous integration it will

[17:53:02 - 17:53:06]
authenticate with my AWS account okay

[17:53:04 - 17:53:08]
then it will log with my ECR then

[17:53:06 - 17:53:09]
whatever let's say Docker image actually

[17:53:08 - 17:53:10]
you will be building you will push that

[17:53:09 - 17:53:12]
image to the ECR okay that means elastic

[17:53:10 - 17:53:14]
container then your continuous

[17:53:12 - 17:53:16]
deployment will start again it will

[17:53:14 - 17:53:19]
authenticate with AWS account then it

[17:53:16 - 17:53:21]
will pull that let's say uh image from

[17:53:19 - 17:53:23]
your ECR to ec2 machine then it will

[17:53:21 - 17:53:24]
execute it here and here all the

[17:53:23 - 17:53:26]
environment variable I have set you can

[17:53:24 - 17:53:28]
see hypen means this is the environment

[17:53:26 - 17:53:29]
variable see AWS access key aw secret

[17:53:28 - 17:53:32]
key I'll tell you how to generate these

[17:53:29 - 17:53:34]
are the key then Pine con API key open

[17:53:32 - 17:53:36]
API key everything I have set here okay

[17:53:34 - 17:53:38]
so these are the thing we'll be reading

[17:53:36 - 17:53:39]
from the secret okay GitHub secret I'll

[17:53:38 - 17:53:41]
tell you how to create the GitHub secret

[17:53:39 - 17:53:42]
as well so as of now just try to

[17:53:41 - 17:53:44]
remember this is the ml file you have to

[17:53:42 - 17:53:46]
use for the cicd and this EML file you

[17:53:44 - 17:53:47]
can use as it is no need to change

[17:53:46 - 17:53:49]
anything in your other other project as

[17:53:47 - 17:53:51]
well okay that's the thing now let's

[17:53:49 - 17:53:53]
open up our AWS account so guys this is

[17:53:51 - 17:53:55]
my AWS account I already logged in with

[17:53:53 - 17:53:56]
my AWS account so here so first of all

[17:53:55 - 17:53:59]
what you have to do you have to create a

[17:53:56 - 17:54:01]
im am user so let's create IM am user so

[17:53:59 - 17:54:03]
I am so the first thing we'll be

[17:54:01 - 17:54:06]
creating one user here so let's create

[17:54:03 - 17:54:09]
one user I'll create a user so let's say

[17:54:06 - 17:54:09]
usern name is I'll give uh

[17:54:11 - 17:54:16]
medical medical B you can give any name

[17:54:13 - 17:54:18]
it's up to you so let's click on next

[17:54:16 - 17:54:19]
now you have to give policies okay like

[17:54:18 - 17:54:22]
what are the policy you want to give in

[17:54:19 - 17:54:23]
this user I don't want to give my entire

[17:54:22 - 17:54:25]
policy that means all the services I I

[17:54:23 - 17:54:27]
don't want to give the access so I'll be

[17:54:25 - 17:54:29]
giving some specific access so Access

[17:54:27 - 17:54:31]
wise I already WR in the readme file let

[17:54:29 - 17:54:32]
me show you so these are the access I'll

[17:54:31 - 17:54:35]
be providing my

[17:54:32 - 17:54:37]
ec2 uh container regist full access and

[17:54:35 - 17:54:39]
ec2 full access okay these are the thing

[17:54:37 - 17:54:41]
we'll be giving so here just search it

[17:54:39 - 17:54:43]
so this is the ECR okay ECR elastic

[17:54:41 - 17:54:46]
Container regist full service here I'm

[17:54:43 - 17:54:47]
giving so let's select and after that

[17:54:46 - 17:54:50]
again I can delete it then I'll try to

[17:54:47 - 17:54:51]
copy the next service this is the

[17:54:50 - 17:54:54]
service okay this is the E2 machine

[17:54:51 - 17:54:56]
service so again starts here and select

[17:54:54 - 17:54:59]
the E2 machine and click on the next now

[17:54:56 - 17:55:01]
see that I have given this two service

[17:54:59 - 17:55:03]
okay next thing just create the user so

[17:55:01 - 17:55:04]
right hand side you can see one button

[17:55:03 - 17:55:06]
is there create user just click on

[17:55:04 - 17:55:08]
create

[17:55:06 - 17:55:10]
user so guys as you can see my user has

[17:55:08 - 17:55:12]
created now I'll click on the user then

[17:55:10 - 17:55:14]
here you will get one option security

[17:55:12 - 17:55:16]
credential just click here then you have

[17:55:14 - 17:55:18]
to create a access key so uh click on

[17:55:16 - 17:55:21]
create access key select command

[17:55:18 - 17:55:23]
interface and I understand this above

[17:55:21 - 17:55:24]
recommendation and click on the next so

[17:55:23 - 17:55:27]
there is a next button just click on the

[17:55:24 - 17:55:28]
next now create the access key here now

[17:55:27 - 17:55:30]
see guys this is your access key and

[17:55:28 - 17:55:32]
secret access key try to download as a

[17:55:30 - 17:55:34]
CSV file so let's download so and just

[17:55:32 - 17:55:36]
keep it with you okay this thing I need

[17:55:34 - 17:55:38]
later on okay and no need to share this

[17:55:36 - 17:55:41]
key with anyone otherwise they will also

[17:55:38 - 17:55:42]
access your uh AWS account okay so here

[17:55:41 - 17:55:45]
I'm showing because after the recording

[17:55:42 - 17:55:47]
I'll delete everything got it so my IM

[17:55:45 - 17:55:48]
am creation is done now I'll go back to

[17:55:47 - 17:55:50]
the home page

[17:55:48 - 17:55:52]
now the next thing what I have to do

[17:55:50 - 17:55:54]
guys I have to create a ECR repository

[17:55:52 - 17:55:56]
to store my Docker image so let's search

[17:55:54 - 17:55:58]
for ECR so just search for ECR that

[17:55:56 - 17:56:01]
means elastic contain register just open

[17:55:58 - 17:56:03]
it up and make sure you check your

[17:56:01 - 17:56:05]
region in which region you are working

[17:56:03 - 17:56:07]
see I'm working uh in Mumbai AP South

[17:56:05 - 17:56:09]
one if you're in other region just try

[17:56:07 - 17:56:11]
to note it down okay you have to note it

[17:56:09 - 17:56:14]
down this this syntax actually AP South

[17:56:11 - 17:56:16]
one then CA Central one if you let's say

[17:56:14 - 17:56:17]
in North Virginia you have to give us

[17:56:16 - 17:56:20]
East one so just try to remember these

[17:56:17 - 17:56:22]
are the tag okay so I'm inside Mumbai

[17:56:20 - 17:56:24]
that means AP sou one now I'll be

[17:56:22 - 17:56:27]
creating a elastic container regist so

[17:56:24 - 17:56:28]
let's create uh so let's click there now

[17:56:27 - 17:56:30]
you have to give the name let's say I'll

[17:56:28 - 17:56:32]
give

[17:56:30 - 17:56:34]
medical

[17:56:32 - 17:56:36]
chatbot you can give any name it's up to

[17:56:34 - 17:56:40]
you everything keep it as default now

[17:56:36 - 17:56:41]
click on next now see my repo is created

[17:56:40 - 17:56:44]
now what you have to do just copy the

[17:56:41 - 17:56:46]
URI and uh just try to paste it as of

[17:56:44 - 17:56:48]
now here because this thing I need later

[17:56:46 - 17:56:52]
on just for reference I'm saving it here

[17:56:48 - 17:56:54]
okay H that's it now what I will do I

[17:56:52 - 17:56:56]
will go back again now the next thing I

[17:56:54 - 17:57:00]
have to do I have to create my ec2

[17:56:56 - 17:57:01]
machine then I have to set up uh these

[17:57:00 - 17:57:03]
are the requirements okay that means I

[17:57:01 - 17:57:04]
have to set up the docker there then I

[17:57:03 - 17:57:06]
will be also updating that machine so

[17:57:04 - 17:57:08]
let's create my ec2 machine right now so

[17:57:06 - 17:57:12]
search for ec2 here ec2 instance so this

[17:57:08 - 17:57:15]
is the E2 service Now launch the

[17:57:12 - 17:57:17]
instance now select the UB to

[17:57:15 - 17:57:19]
machine and what you have to do give the

[17:57:17 - 17:57:24]
name name of the machine let's say

[17:57:19 - 17:57:24]
medical bot machine you can give

[17:57:24 - 17:57:30]
anything then um see instance type you

[17:57:27 - 17:57:32]
have to take at least 8 GB

[17:57:30 - 17:57:35]
Ram 8 GB Ram just take 8 GB Ram I'll be

[17:57:32 - 17:57:36]
taking T2 large okay this machine and

[17:57:35 - 17:57:38]
then select the key value here if you

[17:57:36 - 17:57:40]
don't have the key value here you can

[17:57:38 - 17:57:43]
also create it so let's say I'll give

[17:57:40 - 17:57:44]
medical so it will create one rsf file

[17:57:43 - 17:57:46]
so guys you can see after creating and

[17:57:44 - 17:57:47]
download you will it will give you one

[17:57:46 - 17:57:49]
Pam file so this Pam file you can use

[17:57:47 - 17:57:50]
let let's say if you're using any third

[17:57:49 - 17:57:52]
party tool to connect with your uh ec2

[17:57:50 - 17:57:54]
machine let's say py or mobile ex stream

[17:57:52 - 17:57:56]
that time you can use this Pam file but

[17:57:54 - 17:57:59]
I'm going to launch my let's say machine

[17:57:56 - 17:58:03]
in my uh second tab with the help of AWS

[17:57:59 - 17:58:04]
only I don't need this P file okay so

[17:58:03 - 17:58:07]
now I'll select this two option https

[17:58:04 - 17:58:08]
and HTTP keep it everything as default

[17:58:07 - 17:58:11]
configuration storage at least take

[17:58:08 - 17:58:13]
let's say 30gb and launch the instance

[17:58:11 - 17:58:13]
right

[17:58:13 - 17:58:18]
now so here you can see click on view

[17:58:16 - 17:58:20]
all instance then see my machine is

[17:58:18 - 17:58:22]
running so if Stratus is running now

[17:58:20 - 17:58:23]
click on the machine ID now here you

[17:58:22 - 17:58:26]
have to connect this machine so click on

[17:58:23 - 17:58:28]
the connect button now I'll be selecting

[17:58:26 - 17:58:30]
the E2 connector and let's connect the

[17:58:28 - 17:58:33]
machine so it will create a new tab for

[17:58:30 - 17:58:35]
me so here I will get one terminal block

[17:58:33 - 17:58:38]
terminal so we we have to use this

[17:58:35 - 17:58:40]
terminal to set up everything here and

[17:58:38 - 17:58:41]
this is the production server guys okay

[17:58:40 - 17:58:43]
that's how your production server looks

[17:58:41 - 17:58:45]
like see this is the production server

[17:58:43 - 17:58:47]
let me Zoom now let me clear see here

[17:58:45 - 17:58:49]
you won't be getting any kinds of UI

[17:58:47 - 17:58:51]
interf okay that means the way we are

[17:58:49 - 17:58:52]
using our computer it is having UI but

[17:58:51 - 17:58:54]
in the production server you won't be

[17:58:52 - 17:58:56]
getting any of UI you have to work with

[17:58:54 - 17:58:57]
the terminal always and this is the

[17:58:56 - 17:58:59]
Linux terminal I got this is the Linux

[17:58:57 - 17:59:00]
machine guys so that's why if you know

[17:58:59 - 17:59:02]
any kinds of Linux command it will help

[17:59:00 - 17:59:04]
you a lot got it so here first of all I

[17:59:02 - 17:59:05]
have to update this machine for this you

[17:59:04 - 17:59:08]
have to execute this are the command one

[17:59:05 - 17:59:10]
by one so let's copy all the command one

[17:59:08 - 17:59:10]
by

[17:59:11 - 17:59:17]
one okay so this is done now I'll copy

[17:59:14 - 17:59:17]
the next command

[17:59:18 - 17:59:25]
and just try to past

[17:59:20 - 17:59:25]
here now give yes permission and press

[17:59:25 - 17:59:32]
enter okay so execution is completed now

[17:59:29 - 17:59:33]
I have to set up the dogger in the E2

[17:59:32 - 17:59:35]
machine so this is the command you have

[17:59:33 - 17:59:35]
to

[17:59:37 - 17:59:43]
run copy the next one and execute

[17:59:49 - 17:59:53]
then I will execute this one then the

[17:59:51 - 17:59:56]
last command so we have to add the

[17:59:53 - 17:59:59]
docker in the sudo group

[17:59:56 - 18:00:00]
okay now if it is running on not so what

[17:59:59 - 18:00:03]
you can do you can execute one command

[18:00:00 - 18:00:04]
Docker ipen ipen version so if it is

[18:00:03 - 18:00:08]
showing the version that means Docker is

[18:00:04 - 18:00:11]
installed successfully now uh we have to

[18:00:08 - 18:00:13]
set up our self hosted Runner ec2 as our

[18:00:11 - 18:00:15]
self hosted Runner that means we have to

[18:00:13 - 18:00:16]
connect our GitHub okay you can see this

[18:00:15 - 18:00:18]
is the GitHub now this is our project

[18:00:16 - 18:00:21]
GitHub so this GitHub I have to connect

[18:00:18 - 18:00:23]
with my uh AWS that means whenever user

[18:00:21 - 18:00:25]
will uh sorry whenever let's say

[18:00:23 - 18:00:26]
developer will push the code in the

[18:00:25 - 18:00:29]
GitHub it will automatically get updated

[18:00:26 - 18:00:32]
to the AWS okay AWS Cloud so for this

[18:00:29 - 18:00:34]
what I have to do I have to go to my uh

[18:00:32 - 18:00:36]
project make sure you are you committed

[18:00:34 - 18:00:39]
your repository in your GitHub and go to

[18:00:36 - 18:00:41]
the settings okay go to the settings now

[18:00:39 - 18:00:42]
here left hand side you will see one

[18:00:41 - 18:00:44]
option call Action just click on the

[18:00:42 - 18:00:47]
action click on the

[18:00:44 - 18:00:49]
runners now create a new self hosted

[18:00:47 - 18:00:49]
Runner

[18:00:50 - 18:00:54]
now select the Linux machine and you

[18:00:52 - 18:00:56]
have to execute these are the commands

[18:00:54 - 18:00:58]
so let's copy this command one by one

[18:00:56 - 18:01:00]
and let me execute here so it will

[18:00:58 - 18:01:04]
automatically make the connection with

[18:01:00 - 18:01:04]
your uh GitHub let me show

[18:01:06 - 18:01:10]
you then the third

[18:01:11 - 18:01:16]
command then fourth command

[18:01:22 - 18:01:25]
now you have to go to the configuration

[18:01:23 - 18:01:27]
section and copy this command and

[18:01:25 - 18:01:29]
execute it

[18:01:27 - 18:01:31]
here now see GitHub action it will

[18:01:29 - 18:01:33]
automatically connect now it will uh see

[18:01:31 - 18:01:34]
it has connected to the GitHub now it is

[18:01:33 - 18:01:36]
asking for enter the name of the runner

[18:01:34 - 18:01:38]
group I don't want to give anything

[18:01:36 - 18:01:39]
press enter now it is asking enter the

[18:01:38 - 18:01:43]
name of the runner so here you have to

[18:01:39 - 18:01:44]
give self hypen hosted okay self hen

[18:01:43 - 18:01:46]
hosted this is the thing you have to

[18:01:44 - 18:01:47]
give if you're giving another thing it

[18:01:46 - 18:01:49]
won't be working okay make sure you're

[18:01:47 - 18:01:51]
giving self hen noer now let's press

[18:01:49 - 18:01:54]
enter now keep it everything in default

[18:01:51 - 18:01:54]
just press enter

[18:01:55 - 18:02:00]
again then again press enter now see it

[18:01:59 - 18:02:03]
is done now the last command we have to

[18:02:00 - 18:02:04]
execute this one and you can ignore this

[18:02:03 - 18:02:06]
one it is not

[18:02:04 - 18:02:08]
required now see it would be connected

[18:02:06 - 18:02:08]
with my

[18:02:08 - 18:02:13]
GitHub see connected to the GitHub

[18:02:11 - 18:02:16]
listening for the jobs okay now if I

[18:02:13 - 18:02:18]
show you if I come back and now if I go

[18:02:16 - 18:02:20]
to the Runners let's say I'll go to the

[18:02:18 - 18:02:22]
runners now see status should be ideal

[18:02:20 - 18:02:24]
you can see it is connected okay now the

[18:02:22 - 18:02:26]
next thing what I have to do I have to

[18:02:24 - 18:02:28]
set up all the GitHub Secrets okay now

[18:02:26 - 18:02:32]
let's go back to the secret so secret

[18:02:28 - 18:02:33]
variable click on the Action Now new

[18:02:32 - 18:02:37]
repository

[18:02:33 - 18:02:39]
secret now give the secret uh ID okay so

[18:02:37 - 18:02:42]
the first ID I have to give AWS access

[18:02:39 - 18:02:43]
key ID just copy and give the key name

[18:02:42 - 18:02:45]
here and why you will get the value I

[18:02:43 - 18:02:48]
think remember we downloaded one CSV

[18:02:45 - 18:02:49]
file so let me open this CSV file I will

[18:02:48 - 18:02:53]
open in a notepad++

[18:02:49 - 18:02:57]
and this is my a access keyl

[18:02:53 - 18:02:57]
copy and here let me paste

[18:02:57 - 18:03:02]
it then the next one I have to give

[18:02:59 - 18:03:04]
secret access key ID copy and create

[18:03:02 - 18:03:07]
another new repository secret and give

[18:03:04 - 18:03:10]
it here and in the CSV file you will get

[18:03:07 - 18:03:13]
the next one see it is comma separated

[18:03:10 - 18:03:15]
so before the comma this is the AWS kid

[18:03:13 - 18:03:17]
uh access kid and after the command is

[18:03:15 - 18:03:19]
the secret access K so let me copy the

[18:03:17 - 18:03:22]
secret ACC

[18:03:19 - 18:03:22]
and I will past it

[18:03:23 - 18:03:28]
here okay now the next thing you have to

[18:03:25 - 18:03:31]
give AWS default region so region I

[18:03:28 - 18:03:33]
already told you I'm inside uh Mumbai

[18:03:31 - 18:03:36]
that means AP South one so I think

[18:03:33 - 18:03:37]
remember I inside AP South one see AP

[18:03:36 - 18:03:41]
South one you have to write it so let's

[18:03:37 - 18:03:45]
write AP ien

[18:03:41 - 18:03:49]
South okay ien one AP South one let's

[18:03:45 - 18:03:51]
try to check AP South one

[18:03:49 - 18:03:54]
a South one okay fine now let me add

[18:03:51 - 18:03:56]
it now the next thing I have to add my

[18:03:54 - 18:03:56]
ECR

[18:03:59 - 18:04:06]
repo so e rep wise I think you remember

[18:04:02 - 18:04:08]
we copied one URL so just try to get

[18:04:06 - 18:04:12]
this name only okay after.com just try

[18:04:08 - 18:04:12]
to get the name and try to mention

[18:04:13 - 18:04:18]
here then the next thing I have to set

[18:04:16 - 18:04:20]
my um

[18:04:18 - 18:04:24]
Pine con API key so let's

[18:04:20 - 18:04:24]
copy and add it

[18:04:25 - 18:04:32]
here and I think remember in my DOT EnV

[18:04:29 - 18:04:35]
file I had my Pine API let's

[18:04:32 - 18:04:36]
copy and this is not available inside my

[18:04:35 - 18:04:39]
GitHub that's why I'm reading from the

[18:04:36 - 18:04:42]
GitHub secret okay this is the idea now

[18:04:39 - 18:04:44]
I also need to add my openi secret okay

[18:04:42 - 18:04:48]
that means open IP key the last one you

[18:04:44 - 18:04:51]
can see open IP key let's add it

[18:04:48 - 18:04:53]
so let's copy the open API and I'm going

[18:04:51 - 18:04:56]
to paste it now let's add the

[18:04:53 - 18:04:58]
secret okay now see everything is added

[18:04:56 - 18:05:00]
now let me see anything is left no

[18:04:58 - 18:05:02]
everything I have added now what I have

[18:05:00 - 18:05:05]
to do I have to push the changes okay

[18:05:02 - 18:05:07]
but before that let me get back to my

[18:05:05 - 18:05:10]
project now I'll push the changes so

[18:05:07 - 18:05:11]
just try to comit to comit just open up

[18:05:10 - 18:05:15]
your uh G bash and try to write this

[18:05:11 - 18:05:15]
command get add space

[18:05:15 - 18:05:22]
dot then get comment

[18:05:18 - 18:05:25]
typen in let's say CI

[18:05:22 - 18:05:25]
CD

[18:05:26 - 18:05:33]
edit then get

[18:05:29 - 18:05:33]
push origin

[18:05:34 - 18:05:39]
main now if I go back to my GitHub now

[18:05:36 - 18:05:41]
see if I refresh here so it will start

[18:05:39 - 18:05:45]
running my action now just go to the

[18:05:41 - 18:05:47]
action now see my uh action is running

[18:05:45 - 18:05:49]
see first of all it is running the uh

[18:05:47 - 18:05:50]
continuous integration so inside

[18:05:49 - 18:05:53]
continuous integration first of all it

[18:05:50 - 18:05:55]
will authenticate with my WS ECR build

[18:05:53 - 18:05:56]
the docker image push it to the ECR okay

[18:05:55 - 18:05:58]
everything will happen see automatically

[18:05:56 - 18:06:00]
it's just a one time setup guys next

[18:05:58 - 18:06:02]
time you don't need to set up it you

[18:06:00 - 18:06:04]
just need to write the code and push it

[18:06:02 - 18:06:07]
to the GitHub automatically it will uh

[18:06:04 - 18:06:10]
push to the uh let's say server okay now

[18:06:07 - 18:06:12]
see so let's wait uh once this execution

[18:06:10 - 18:06:15]
is completed I will come back so guys as

[18:06:12 - 18:06:16]
you can see my continuous integration is

[18:06:15 - 18:06:17]
completed now it is running the

[18:06:16 - 18:06:20]
continuous deployment now what it will

[18:06:17 - 18:06:22]
do it will again authenticate with myws

[18:06:20 - 18:06:25]
cloud and it will pull that image from

[18:06:22 - 18:06:26]
the e to E2 machine and if you go to the

[18:06:25 - 18:06:28]
El lasting container right now and if

[18:06:26 - 18:06:30]
you refresh here you will see the image

[18:06:28 - 18:06:32]
okay see doer image has been uploaded

[18:06:30 - 18:06:34]
here now see it is running the uh

[18:06:32 - 18:06:36]
deployment now see it is pulling the

[18:06:34 - 18:06:38]
image so once it is pull then uh we're

[18:06:36 - 18:06:40]
doing the port mapping uh we'll create

[18:06:38 - 18:06:43]
the endpoint and uh we can access our

[18:06:40 - 18:06:44]
application let me show you so guys as

[18:06:43 - 18:06:46]
you can see my execution is completed

[18:06:44 - 18:06:48]
that means both uh integration and

[18:06:46 - 18:06:50]
deployment is executed if you're not

[18:06:48 - 18:06:53]
getting added that means congratulation

[18:06:50 - 18:06:56]
it's done now I will go back to my ec2

[18:06:53 - 18:06:58]
machine okay now here in the2 machine uh

[18:06:56 - 18:07:00]
you will get one public IP address just

[18:06:58 - 18:07:02]
let me show you so this is the public IP

[18:07:00 - 18:07:05]
address just try to copy and just try to

[18:07:02 - 18:07:07]
open it okay now see if I open it up so

[18:07:05 - 18:07:08]
it won't be opening because uh see my

[18:07:07 - 18:07:11]
application is running on port number

[18:07:08 - 18:07:13]
8080 I think remember okay so by default

[18:07:11 - 18:07:14]
port number 8080 is not set so I have to

[18:07:13 - 18:07:18]
do the port mapping so what I have to do

[18:07:14 - 18:07:20]
I'll go back go to the instance

[18:07:18 - 18:07:23]
uh this is my instance then I'll go to

[18:07:20 - 18:07:25]
the security okay now here you will see

[18:07:23 - 18:07:26]
one option called uh Security Group just

[18:07:25 - 18:07:29]
click

[18:07:26 - 18:07:31]
here now on top you'll see edit and

[18:07:29 - 18:07:34]
bound rules okay just try to click click

[18:07:31 - 18:07:37]
here now I'll just add the rules custom

[18:07:34 - 18:07:40]
TCP port number just give

[18:07:37 - 18:07:41]
8080 uh just sck 00 0 okay and here you

[18:07:40 - 18:07:43]
will see save rules okay just click on

[18:07:41 - 18:07:45]
the save rules that's it okay so rules

[18:07:43 - 18:07:48]
has been added now I'll go to the

[18:07:45 - 18:07:50]
instance again I'll open it up now I'll

[18:07:48 - 18:07:52]
copy the public IP address again and

[18:07:50 - 18:07:55]
here let me paste now you have to give

[18:07:52 - 18:07:57]
clone port number

[18:07:55 - 18:07:59]
8080 now see if I hit enter my

[18:07:57 - 18:08:01]
application should be running see guys

[18:07:59 - 18:08:03]
this is my chatbot is

[18:08:01 - 18:08:07]
running now if I give any message let's

[18:08:03 - 18:08:07]
say uh what is

[18:08:08 - 18:08:13]
acne see guys it is giving me the

[18:08:10 - 18:08:15]
response now see my application is live

[18:08:13 - 18:08:17]
right now so it is already deployed now

[18:08:15 - 18:08:19]
user can use my applications now what

[18:08:17 - 18:08:21]
you can do can buy a domain okay your

[18:08:19 - 18:08:23]
custom domain and you can publish this

[18:08:21 - 18:08:24]
application to the audience okay now for

[18:08:23 - 18:08:26]
the second time let's say you changed

[18:08:24 - 18:08:27]
anything in the code let's say you added

[18:08:26 - 18:08:29]
some more function what you have to do

[18:08:27 - 18:08:31]
only just need to commit the changes it

[18:08:29 - 18:08:33]
will automatically get updated here fine

[18:08:31 - 18:08:36]
so no need to set up anything from

[18:08:33 - 18:08:38]
scratch it just a one time setup once

[18:08:36 - 18:08:39]
setup is completed just try to commit

[18:08:38 - 18:08:41]
the changes it will automatically

[18:08:39 - 18:08:43]
running okay now you can ask me if I

[18:08:41 - 18:08:44]
close this terminal will it work yes

[18:08:43 - 18:08:46]
definitely you can close it let's say I

[18:08:44 - 18:08:47]
will close this terminal now if I again

[18:08:46 - 18:08:49]
go to the chat bot if I refresh see

[18:08:47 - 18:08:52]
still my bot is running okay so that's

[18:08:49 - 18:08:54]
how guys we can do the cicd deployment

[18:08:52 - 18:08:55]
now let me show you how we can terminate

[18:08:54 - 18:08:57]
all the instance like whatever instance

[18:08:55 - 18:08:58]
we created if you don't want to keep it

[18:08:57 - 18:09:00]
running otherwise it will charge you

[18:08:58 - 18:09:02]
right so what I can do uh first of all I

[18:09:00 - 18:09:04]
will stop the easy to machine I've

[18:09:02 - 18:09:07]
created so select the machine click on

[18:09:04 - 18:09:10]
the instance State and terminate so

[18:09:07 - 18:09:12]
terminate will delete it okay so it will

[18:09:10 - 18:09:14]
terminate and delete the instance then

[18:09:12 - 18:09:19]
after that I also need to uh delete my

[18:09:14 - 18:09:22]
EC ECR so let's go to the ECR

[18:09:19 - 18:09:26]
so first of all delete the image inside

[18:09:22 - 18:09:26]
that just write the delete

[18:09:28 - 18:09:32]
command now try to select and

[18:09:35 - 18:09:40]
delete okay then uh what I have to do I

[18:09:38 - 18:09:42]
have to delete

[18:09:40 - 18:09:45]
the

[18:09:42 - 18:09:49]
uh then I will also delete my IM I'm

[18:09:45 - 18:09:49]
user okay I'm user I created

[18:09:50 - 18:09:56]
user let's select and try to delete

[18:09:54 - 18:09:59]
it medical chatbot I have to write here

[18:09:56 - 18:09:59]
so let me

[18:09:59 - 18:10:03]
copy let me delete

[18:10:03 - 18:10:08]
it see everything is deleted now nothing

[18:10:06 - 18:10:10]
will charge you okay so guys that's how

[18:10:08 - 18:10:13]
we can perform the deployment and this

[18:10:10 - 18:10:15]
is the code you can use uh this code as

[18:10:13 - 18:10:17]
it is okay the code actually have shared

[18:10:15 - 18:10:19]
so yes guys this is all about uh and I

[18:10:17 - 18:10:21]
hope you liked it so thanks for watching

[18:10:19 - 18:10:24]
guys and what you need to do guys uh the

[18:10:21 - 18:10:26]
next project I showed you now that uh

[18:10:24 - 18:10:28]
this one source code analysis you can

[18:10:26 - 18:10:29]
deploy this project with the same

[18:10:28 - 18:10:32]
process okay whatever project we have

[18:10:29 - 18:10:33]
created so far you can deploy with the S

[18:10:32 - 18:10:35]
uh same process so guys we'll be

[18:10:33 - 18:10:38]
starting with another very important

[18:10:35 - 18:10:40]
concept inside genbi called llm ops so I

[18:10:38 - 18:10:42]
think you already heard of this name

[18:10:40 - 18:10:44]
okay called llm ops so the full form is

[18:10:42 - 18:10:46]
large language model operation so those

[18:10:44 - 18:10:48]
who are from machine learning and deep

[18:10:46 - 18:10:49]
learning background I think you know

[18:10:48 - 18:10:52]
there is another uh actually concept

[18:10:49 - 18:10:53]
called mlops so with the help of mlops

[18:10:52 - 18:10:54]
we can perform machine learning

[18:10:53 - 18:10:56]
operations that means let's say if you

[18:10:54 - 18:10:59]
want to build any kinds of end to end

[18:10:56 - 18:11:02]
mldl application you can follow some

[18:10:59 - 18:11:03]
certain step okay some certain pipeline

[18:11:02 - 18:11:06]
you can follow that means you can follow

[18:11:03 - 18:11:09]
some certain pipeline to implement that

[18:11:06 - 18:11:10]
particular application and here mlops

[18:11:09 - 18:11:13]
usually help help you to implement that

[18:11:10 - 18:11:15]
particular pipeline right so similar uh

[18:11:13 - 18:11:18]
things actually we can also apply in the

[18:11:15 - 18:11:20]
geni so I think we saw inside gen we can

[18:11:18 - 18:11:22]
use different different kinds of let's

[18:11:20 - 18:11:23]
say uh tools and Technology like we can

[18:11:22 - 18:11:26]
use different different kinds of

[18:11:23 - 18:11:27]
framework we can use commercial large

[18:11:26 - 18:11:29]
language model we can use open source

[18:11:27 - 18:11:31]
large language model yes or no so

[18:11:29 - 18:11:33]
commercial wise I already told you we

[18:11:31 - 18:11:36]
can use open AI platform because openi

[18:11:33 - 18:11:38]
gives you the model with the help of API

[18:11:36 - 18:11:39]
access that means you can create a API

[18:11:38 - 18:11:42]
with the help of that you can access

[18:11:39 - 18:11:43]
this model in the openi platform so for

[18:11:42 - 18:11:46]
this you don't need to download the

[18:11:43 - 18:11:47]
model in your system okay so download

[18:11:46 - 18:11:50]
you don't need to do if say if you're

[18:11:47 - 18:11:52]
using any low configuration system still

[18:11:50 - 18:11:54]
you can use that model but whenever it

[18:11:52 - 18:11:56]
comes to open source large language

[18:11:54 - 18:11:57]
model and it can of foundation model I

[18:11:56 - 18:11:59]
think I showed you the entire hugging F

[18:11:57 - 18:12:01]
platform there we are having so many

[18:11:59 - 18:12:02]
open source large langage model right

[18:12:01 - 18:12:05]
let's see if you want to use these kinds

[18:12:02 - 18:12:07]
of foundation model because apart from

[18:12:05 - 18:12:09]
openi these are the model are also good

[18:12:07 - 18:12:10]
now this is also better some of the

[18:12:09 - 18:12:13]
model you will see it is better than

[18:12:10 - 18:12:15]
openi model okay now if I want to use

[18:12:13 - 18:12:16]
these are the model efficiently if I

[18:12:15 - 18:12:18]
want to create a efficient application

[18:12:16 - 18:12:19]
if even if I want to deploy this

[18:12:18 - 18:12:22]
particular application on the cloud

[18:12:19 - 18:12:24]
platform how we can do it because we saw

[18:12:22 - 18:12:26]
that if I'm using this kinds of model

[18:12:24 - 18:12:28]
like open source model I have to first

[18:12:26 - 18:12:29]
of all download the model in our system

[18:12:28 - 18:12:31]
and whenever I'm downloading you should

[18:12:29 - 18:12:32]
have good configuration machine yes or

[18:12:31 - 18:12:34]
no that means you should have good GPU

[18:12:32 - 18:12:36]
good memory good CPU then you will be

[18:12:34 - 18:12:38]
able to execute this model and let's say

[18:12:36 - 18:12:40]
you want to fine tune these are the

[18:12:38 - 18:12:42]
model definitely you need a very good

[18:12:40 - 18:12:44]
configuration GPU otherwise you won't be

[18:12:42 - 18:12:46]
a able to fine tune that I think we

[18:12:44 - 18:12:48]
already saw one fine tuning example of

[18:12:46 - 18:12:50]
Lama to model there I was fine tuning

[18:12:48 - 18:12:51]
this model onto our custom data and I

[18:12:50 - 18:12:54]
was using Google collab so there

[18:12:51 - 18:12:56]
actually it was taking lots of time uh

[18:12:54 - 18:12:58]
let's say to train only oneop just try

[18:12:56 - 18:13:00]
to consider got it so that's why llm Ops

[18:12:58 - 18:13:02]
comes into pictures so llm Ops will

[18:13:00 - 18:13:04]
gives you the flexibility to work with

[18:13:02 - 18:13:06]
uh different kinds of foundation model

[18:13:04 - 18:13:08]
OKAY like uh what kinds of foundation

[18:13:06 - 18:13:11]
model I think we you saw like Lama is

[18:13:08 - 18:13:12]
there mral is there okay jini is there

[18:13:11 - 18:13:13]
different different large language

[18:13:12 - 18:13:15]
models are available so different

[18:13:13 - 18:13:17]
different foundations model are

[18:13:15 - 18:13:19]
available uh I already showed you in the

[18:13:17 - 18:13:21]
hugging P platform okay so if you want

[18:13:19 - 18:13:23]
to use these kinds of foundation model

[18:13:21 - 18:13:24]
Foundation large language model with all

[18:13:23 - 18:13:26]
the flexibility you have to use

[18:13:24 - 18:13:29]
something called llm ops there are some

[18:13:26 - 18:13:31]
llm Ops platform are available uh this

[18:13:29 - 18:13:33]
will give you all kinds of flexibility

[18:13:31 - 18:13:34]
you can work with these kinds of

[18:13:33 - 18:13:36]
foundation model even it will give you

[18:13:34 - 18:13:38]
all kinds of functionality okay all

[18:13:36 - 18:13:39]
kinds of functionality it will provide

[18:13:38 - 18:13:42]
you all you just need to use this

[18:13:39 - 18:13:43]
platform to implement your LM power

[18:13:42 - 18:13:45]
application I'll teach you all the

[18:13:43 - 18:13:47]
platform whatever platform actually we

[18:13:45 - 18:13:49]
are having which is like famous in the

[18:13:47 - 18:13:50]
market I'll discuss all of them one by

[18:13:49 - 18:13:53]
one okay no need to worry so first of

[18:13:50 - 18:13:55]
all let's try to see uh why llm Ops is

[18:13:53 - 18:13:57]
required because we saw that like what

[18:13:55 - 18:14:00]
is llm OPS exactly now we'll try to see

[18:13:57 - 18:14:01]
why llm Ops is required uh why we need

[18:14:00 - 18:14:03]
it exactly for this I'm going to open up

[18:14:01 - 18:14:05]
my Blackboard and there I'm going to

[18:14:03 - 18:14:09]
explain this concept so guys I think so

[18:14:05 - 18:14:09]
far you have learned about Lang

[18:14:09 - 18:14:16]
chain okay Lang chain then you learn

[18:14:13 - 18:14:16]
learn about llama index

[18:14:17 - 18:14:22]
okay then you also learn about open

[18:14:19 - 18:14:22]
source large language

[18:14:23 - 18:14:29]
model okay open source llm even I also

[18:14:27 - 18:14:32]
taught you the open

[18:14:29 - 18:14:33]
AI okay openi and open a provides

[18:14:32 - 18:14:35]
actually commercial model because all

[18:14:33 - 18:14:37]
the models are paid here if you want to

[18:14:35 - 18:14:38]
use them you have to pay for that right

[18:14:37 - 18:14:41]
and how it will charge you based on the

[18:14:38 - 18:14:43]
token token limit and this will give you

[18:14:41 - 18:14:45]
the API key okay API key with the help

[18:14:43 - 18:14:48]
of API key you can access this this

[18:14:45 - 18:14:50]
model but apart from that there are so

[18:14:48 - 18:14:51]
many actually Foundation model I think I

[18:14:50 - 18:14:53]
already discussed inside hugging fish

[18:14:51 - 18:14:57]
okay hugging fish platform like Lama was

[18:14:53 - 18:15:02]
there okay then mral was

[18:14:57 - 18:15:04]
there then Falcon was there okay then

[18:15:02 - 18:15:06]
then

[18:15:04 - 18:15:10]
jini

[18:15:06 - 18:15:11]
Jimma okay and so on there are so many

[18:15:10 - 18:15:13]
model so many model if you open the

[18:15:11 - 18:15:14]
hugging face platform you'll see that

[18:15:13 - 18:15:16]
there are so many models are available

[18:15:14 - 18:15:17]
and these are the foundation model and

[18:15:16 - 18:15:19]
this model is pretty good guys if you

[18:15:17 - 18:15:22]
see this model this model is like very

[18:15:19 - 18:15:24]
powerful model it's very powerful model

[18:15:22 - 18:15:25]
even I already showed you some of the

[18:15:24 - 18:15:26]
demo now we created some of the

[18:15:25 - 18:15:28]
application with the help of Open Source

[18:15:26 - 18:15:31]
L language model there I think you saw

[18:15:28 - 18:15:33]
the power of the model yes or no right

[18:15:31 - 18:15:35]
but I think one issue you saw whenever I

[18:15:33 - 18:15:38]
was using this open source large

[18:15:35 - 18:15:39]
language model the issue was this model

[18:15:38 - 18:15:41]
size is very big let's say if I'm

[18:15:39 - 18:15:42]
considering llama 2 just try to consider

[18:15:41 - 18:15:47]
about Lama

[18:15:42 - 18:15:49]
2 so now tell me llama 2 having a how

[18:15:47 - 18:15:51]
many variant I think you know Lama 2 is

[18:15:49 - 18:15:53]
having three variant like 7 billion

[18:15:51 - 18:15:56]
parameter model then it is also having

[18:15:53 - 18:15:59]
13 billion parameter variant model it is

[18:15:56 - 18:16:02]
also having 70 billion uh parameter

[18:15:59 - 18:16:04]
model even uh even recently there is

[18:16:02 - 18:16:08]
another model you will see called llama

[18:16:04 - 18:16:10]
3 okay llama 3 and llama 3 is very huge

[18:16:08 - 18:16:11]
than your llama 2 so you can open up the

[18:16:10 - 18:16:13]
hugging pH Hub and there you can search

[18:16:11 - 18:16:15]
for Lama 3 you will see the model so

[18:16:13 - 18:16:17]
here I already told you if I want to use

[18:16:15 - 18:16:20]
this model actually I have to use use

[18:16:17 - 18:16:22]
GPU based

[18:16:20 - 18:16:24]
machine GPU based machine GPU based

[18:16:22 - 18:16:26]
system yes or no and if I'm not using

[18:16:24 - 18:16:28]
GPU based machine so what will happen I

[18:16:26 - 18:16:29]
won't be able execute deser the model

[18:16:28 - 18:16:31]
but if you see there are so many

[18:16:29 - 18:16:33]
developer there there would be so many

[18:16:31 - 18:16:35]
Enthusiast uh they will prefer to use

[18:16:33 - 18:16:38]
these are the open source large language

[18:16:35 - 18:16:41]
model but most of them will not have the

[18:16:38 - 18:16:42]
GPU based machine okay because it's

[18:16:41 - 18:16:45]
obvious now because if you see nowadays

[18:16:42 - 18:16:48]
actually uh whatever laptop whatever

[18:16:45 - 18:16:50]
let's say uh system we usually buy uh

[18:16:48 - 18:16:54]
people usually take this um actually GPU

[18:16:50 - 18:16:56]
let's say 30 60 okay ti so I can

[18:16:54 - 18:17:00]
consider

[18:16:56 - 18:17:02]
RTX RTX okay RT RTX 30 60 TI if you if

[18:17:00 - 18:17:05]
you do if you have actually less budget

[18:17:02 - 18:17:06]
then you can buy this uh GPU if you have

[18:17:05 - 18:17:08]
more budget you can also buy higher

[18:17:06 - 18:17:10]
configuration GPU but there are very

[18:17:08 - 18:17:12]
less people they will buy the higher

[18:17:10 - 18:17:14]
configuration GPU let's say who have the

[18:17:12 - 18:17:16]
huge amount of earning they will buy buy

[18:17:14 - 18:17:18]
it okay but if you but if you have

[18:17:16 - 18:17:19]
actually less budget because see most

[18:17:18 - 18:17:21]
majority of the person will have the

[18:17:19 - 18:17:23]
less budget whenever they buy any kinds

[18:17:21 - 18:17:26]
of system so they will have let's say

[18:17:23 - 18:17:31]
this GPU 30 60 Ty TI okay so this GPU

[18:17:26 - 18:17:37]
having actually I think around 4 GB 4 to

[18:17:31 - 18:17:40]
8 GB I think uh vram okay vram it is

[18:17:37 - 18:17:42]
having okay now just try to consider

[18:17:40 - 18:17:44]
let's say I'm loading this Lama to 7

[18:17:42 - 18:17:47]
billion parameter okay this model in

[18:17:44 - 18:17:49]
this GPU so what would be the inference

[18:17:47 - 18:17:51]
time as of now let's try to consider

[18:17:49 - 18:17:54]
let's say it will take 5

[18:17:51 - 18:17:56]
minutes okay 5 minutes to give you the

[18:17:54 - 18:17:58]
response now just try to consider if

[18:17:56 - 18:18:01]
your application is taking 5 minutes to

[18:17:58 - 18:18:02]
execute only one prompt will people will

[18:18:01 - 18:18:05]
use your application tell me if let's

[18:18:02 - 18:18:07]
say I'm using chat GPT and if I'm giving

[18:18:05 - 18:18:08]
any prompt to the chat GPT and chat GPT

[18:18:07 - 18:18:11]
is taking let's say 5 minutes to give me

[18:18:08 - 18:18:14]
that response so we I use the chat GPT

[18:18:11 - 18:18:17]
again no definitely I will not use

[18:18:14 - 18:18:19]
because nowadays you'll see see that

[18:18:17 - 18:18:21]
people will have very less time they

[18:18:19 - 18:18:23]
they want actually quick response from

[18:18:21 - 18:18:24]
any kinds of application so what you

[18:18:23 - 18:18:26]
have to do the system you have

[18:18:24 - 18:18:28]
developing this should be very fast okay

[18:18:26 - 18:18:29]
the inference time would be very fast

[18:18:28 - 18:18:32]
here otherwise people won't be using

[18:18:29 - 18:18:34]
your application right then let's see we

[18:18:32 - 18:18:39]
are loading this 13 billion parameter

[18:18:34 - 18:18:40]
model OKAY in the RTX 3060 TI GPU let's

[18:18:39 - 18:18:43]
say now it is taking 10 minutes to

[18:18:40 - 18:18:45]
execute okay 10 minutes to execute and

[18:18:43 - 18:18:47]
after that let's see you are taking 70

[18:18:45 - 18:18:49]
billion parameter model in the TX 3060

[18:18:47 - 18:18:52]
TI and you will see that sometimes it

[18:18:49 - 18:18:54]
will give you

[18:18:52 - 18:19:00]
memory okay

[18:18:54 - 18:19:04]
memory out of space okay out of space

[18:19:00 - 18:19:06]
error okay because this uh GPU doesn't

[18:19:04 - 18:19:08]
have the capacity to load this 7 billion

[18:19:06 - 18:19:11]
parameter model because I told you it is

[18:19:08 - 18:19:13]
having four 4GB and 8GB vram okay so

[18:19:11 - 18:19:15]
that time actually we are not able to

[18:19:13 - 18:19:17]
use this kinds of foundation model but

[18:19:15 - 18:19:19]
let's say some somehow we are using this

[18:19:17 - 18:19:21]
Foundation model let's say we are using

[18:19:19 - 18:19:22]
small variant of the model let's say 70

[18:19:21 - 18:19:24]
billion or 13 billion but what is

[18:19:22 - 18:19:27]
happening inference time is very high

[18:19:24 - 18:19:28]
here okay it is like very slow here so

[18:19:27 - 18:19:31]
again people won't be using my

[18:19:28 - 18:19:33]
application so this is another issue got

[18:19:31 - 18:19:35]
it now let's say somehow you created one

[18:19:33 - 18:19:37]
application let's say it is taking 5

[18:19:35 - 18:19:40]
minutes to execute now what you have to

[18:19:37 - 18:19:42]
do uh if you want to publish this

[18:19:40 - 18:19:44]
application to the audience you have to

[18:19:42 - 18:19:46]
deploy this project yes or no let's say

[18:19:44 - 18:19:48]
you want to do the deployment you want

[18:19:46 - 18:19:50]
to do the deployment

[18:19:48 - 18:19:52]
M okay

[18:19:50 - 18:19:54]
deployment now I think previously I

[18:19:52 - 18:19:57]
showed you one deployment right uh like

[18:19:54 - 18:20:00]
uh we deployed One n to Medical chatbot

[18:19:57 - 18:20:03]
project there I was using actually AWS

[18:20:00 - 18:20:07]
okay AWS so I was using let's say ec2

[18:20:03 - 18:20:10]
service from there ec2 then I was using

[18:20:07 - 18:20:13]
ECR okay lastic container then I was

[18:20:10 - 18:20:15]
also using something called

[18:20:13 - 18:20:18]
Docker okay so these are the services

[18:20:15 - 18:20:20]
actually I was using there one by one

[18:20:18 - 18:20:22]
now see there I was actually deploying

[18:20:20 - 18:20:24]
the open a based application that means

[18:20:22 - 18:20:26]
I was using open a model that's why I

[18:20:24 - 18:20:27]
was able to deploy this project in the

[18:20:26 - 18:20:29]
cloud platform with the help of these

[18:20:27 - 18:20:31]
are the simple service only but whenever

[18:20:29 - 18:20:33]
you are using open source large language

[18:20:31 - 18:20:35]
model so that means this model you have

[18:20:33 - 18:20:36]
downloaded in your local machine and now

[18:20:35 - 18:20:38]
what you have to do you have to move

[18:20:36 - 18:20:40]
this model to the production server that

[18:20:38 - 18:20:42]
means your Cloud machine and there just

[18:20:40 - 18:20:44]
try to consider if you are using these

[18:20:42 - 18:20:46]
kinds of 8GB let's say instance like T

[18:20:44 - 18:20:49]
to large instance will it work so I

[18:20:46 - 18:20:51]
think remember we use something called

[18:20:49 - 18:20:54]
t2. large instance there and it was

[18:20:51 - 18:20:57]
having 8GB memory only okay 8GB memory

[18:20:54 - 18:20:59]
with CPU CPU code so it won't be working

[18:20:57 - 18:21:01]
right if I'm loading this llama 3 or

[18:20:59 - 18:21:03]
Lama 2 in this machine it won't be

[18:21:01 - 18:21:05]
working so for this what I have to do I

[18:21:03 - 18:21:07]
have to purchase I have to purchase

[18:21:05 - 18:21:09]
actually a GPU based machine there so if

[18:21:07 - 18:21:10]
you see the ec2 instance you will see

[18:21:09 - 18:21:12]
that there actually will also have GPU

[18:21:10 - 18:21:14]
based machine so there actually you can

[18:21:12 - 18:21:17]
also purchase GPU based machine apart

[18:21:14 - 18:21:21]
from that AWS provides another service

[18:21:17 - 18:21:24]
called AWS

[18:21:21 - 18:21:26]
salemaker those were from actually uh

[18:21:24 - 18:21:28]
MLS background they already know what is

[18:21:26 - 18:21:31]
aw says maker so salemaker is a complete

[18:21:28 - 18:21:33]
actually platform so here you can uh

[18:21:31 - 18:21:36]
actually

[18:21:33 - 18:21:39]
ingest okay

[18:21:36 - 18:21:39]
train

[18:21:40 - 18:21:46]
evaluate okay evaluate and

[18:21:43 - 18:21:48]
deploy any kinds of machine learning or

[18:21:46 - 18:21:50]
deep learning project okay and it also

[18:21:48 - 18:21:52]
provides different different virtual

[18:21:50 - 18:21:54]
instance that means virtual computer

[18:21:52 - 18:21:56]
okay virtual let's say uh computer it

[18:21:54 - 18:21:57]
will also give you so there actually you

[18:21:56 - 18:21:59]
can take any kind of instance and you

[18:21:57 - 18:22:01]
can let's say host your model it is also

[18:21:59 - 18:22:03]
possible so salemaker provides actually

[18:22:01 - 18:22:05]
lots of service you can search uh over

[18:22:03 - 18:22:07]
the Google you'll see that it provide

[18:22:05 - 18:22:09]
different different Services okay now a

[18:22:07 - 18:22:11]
few month back actually I was uh going

[18:22:09 - 18:22:13]
through one actually research article so

[18:22:11 - 18:22:15]
there I found if I want to let's say

[18:22:13 - 18:22:18]
deploy any kinds of Open Source lar

[18:22:15 - 18:22:19]
language model uh as as a let's say my

[18:22:18 - 18:22:22]
custom created let's say server let's

[18:22:19 - 18:22:24]
say I want to uh launch my own server

[18:22:22 - 18:22:25]
and there I want to host my model for

[18:22:24 - 18:22:27]
this what I can use I can use something

[18:22:25 - 18:22:29]
called sales maker okay A W salemaker I

[18:22:27 - 18:22:31]
can use because salesmaker will give you

[18:22:29 - 18:22:32]
different different kinds of instance

[18:22:31 - 18:22:34]
okay so there actually you can host your

[18:22:32 - 18:22:36]
model and if I want to use says maker

[18:22:34 - 18:22:39]
and if I want to let's say deploy this

[18:22:36 - 18:22:40]
kinds of uh open source large language

[18:22:39 - 18:22:41]
model because see if I want to use this

[18:22:40 - 18:22:43]
kinds of Open Source large language

[18:22:41 - 18:22:44]
model I have to use different different

[18:22:43 - 18:22:46]
Library like I I told you we have to use

[18:22:44 - 18:22:48]
hugging face okay we have to use Lang

[18:22:46 - 18:22:51]
chain so different different things we

[18:22:48 - 18:22:52]
have to uh install even if I want to use

[18:22:51 - 18:22:55]
hugging fist I also need to install

[18:22:52 - 18:22:57]
accelerate bits and bytes because this

[18:22:55 - 18:22:59]
model access the GPU right and to access

[18:22:57 - 18:23:01]
the GPU I also need deserve the package

[18:22:59 - 18:23:03]
okay I already explained uh in my

[18:23:01 - 18:23:04]
hugging F session so if I want to

[18:23:03 - 18:23:06]
install these are the package when let's

[18:23:04 - 18:23:08]
say I'm taking any ec2 machine there you

[18:23:06 - 18:23:09]
will see installation issue so most of

[18:23:08 - 18:23:11]
the time you will see lots of

[18:23:09 - 18:23:13]
installation issue actually will get but

[18:23:11 - 18:23:16]
what they did actually they created one

[18:23:13 - 18:23:18]
service called DLC okay DLC that means

[18:23:16 - 18:23:20]
deep learning container so this service

[18:23:18 - 18:23:22]
is already available in the AWS okay you

[18:23:20 - 18:23:23]
can use with the help of salemaker

[18:23:22 - 18:23:26]
salesmaker you can use this DLC that

[18:23:23 - 18:23:27]
means deep learning container so inside

[18:23:26 - 18:23:29]
deep learning container you can install

[18:23:27 - 18:23:31]
any kinds of deep learning package let's

[18:23:29 - 18:23:34]
say you can install hugging face you can

[18:23:31 - 18:23:35]
install let's say F tensor flow so all

[18:23:34 - 18:23:37]
the let's say library would be already

[18:23:35 - 18:23:39]
pre-installed there so you don't need to

[18:23:37 - 18:23:41]
let's say manually put the effort to

[18:23:39 - 18:23:42]
install these are the library okay with

[18:23:41 - 18:23:44]
the GPU configuration everything would

[18:23:42 - 18:23:46]
be already there okay only just need to

[18:23:44 - 18:23:48]
take the DLC uh let's say uh instance

[18:23:46 - 18:23:50]
and you have to connect with the

[18:23:48 - 18:23:52]
salemaker that is the idea okay so with

[18:23:50 - 18:23:54]
the help of salemaker with the help of

[18:23:52 - 18:23:56]
DLC you can host this model let's say

[18:23:54 - 18:23:57]
you are having one open source model now

[18:23:56 - 18:24:01]
you can host this model in the DLC

[18:23:57 - 18:24:02]
platform got it and to get the let's say

[18:24:01 - 18:24:04]
Endo from the model what you have to do

[18:24:02 - 18:24:07]
you have to use something called API

[18:24:04 - 18:24:09]
Gateway okay API Gateway so this is

[18:24:07 - 18:24:11]
another service from the AWS with API

[18:24:09 - 18:24:15]
Gateway what you can do you can cre an

[18:24:11 - 18:24:17]
API okay API like we saw like open a API

[18:24:15 - 18:24:19]
now we used to use one API so here also

[18:24:17 - 18:24:21]
you can create API with the help of API

[18:24:19 - 18:24:24]
other people can access your model let's

[18:24:21 - 18:24:26]
say this is user so user can access your

[18:24:24 - 18:24:28]
model with the help of API request so

[18:24:26 - 18:24:30]
this API will request this uh let's say

[18:24:28 - 18:24:32]
model that means let's say you are using

[18:24:30 - 18:24:33]
llama model okay and llama model is

[18:24:32 - 18:24:35]
present inside DLC that means deep

[18:24:33 - 18:24:37]
learning container it is running on the

[18:24:35 - 18:24:39]
salemaker actually instance okay from uh

[18:24:37 - 18:24:41]
from there actually you can get the

[18:24:39 - 18:24:44]
response now let's say somehow you

[18:24:41 - 18:24:45]
deployed this uh model like that okay

[18:24:44 - 18:24:47]
the way actually I showed you with the

[18:24:45 - 18:24:49]
help of say makeer DC API Gateway okay

[18:24:47 - 18:24:50]
all the services let's say you deployed

[18:24:49 - 18:24:53]
this model and now let's say it is

[18:24:50 - 18:24:57]
working fine now there one issue we'll

[18:24:53 - 18:24:59]
get the issue is cost okay so it will

[18:24:57 - 18:25:01]
actually charge you huge amount of money

[18:24:59 - 18:25:04]
let me show

[18:25:01 - 18:25:07]
you so uh in that research article I got

[18:25:04 - 18:25:09]
one image actually let me show you the

[18:25:07 - 18:25:12]
image so I have already taken the

[18:25:09 - 18:25:15]
screenshot so this is the image guys I

[18:25:12 - 18:25:16]
think is this image is visible H see

[18:25:15 - 18:25:18]
what they did actually they have taken

[18:25:16 - 18:25:19]
different different llama model you can

[18:25:18 - 18:25:22]
see they have taken different different

[18:25:19 - 18:25:25]
llama model let's say llama 2 7B 7B chat

[18:25:22 - 18:25:27]
13B 70b okay and this is the model ID

[18:25:25 - 18:25:28]
and this is the max tokens like uh what

[18:25:27 - 18:25:31]
would be the input length Okay of this

[18:25:28 - 18:25:35]
model I think you know Lama 2 Tes

[18:25:31 - 18:25:36]
actually 496 token okay and this is the

[18:25:35 - 18:25:38]
default instance type actually they're

[18:25:36 - 18:25:41]
suggesting let's say if I want to use

[18:25:38 - 18:25:44]
Lama 27b model so I have to take M ml.

[18:25:41 - 18:25:47]
g5. 2x large machine okay and this

[18:25:44 - 18:25:48]
machine is available in the Sal platform

[18:25:47 - 18:25:50]
now let me show you the salesmaker so if

[18:25:48 - 18:25:53]
you just search for sales

[18:25:50 - 18:25:54]
maker okay sales

[18:25:53 - 18:25:57]
maker

[18:25:54 - 18:25:58]
pricing just search for salesmaker

[18:25:57 - 18:26:00]
pricing in

[18:25:58 - 18:26:01]
Google so you will get one website

[18:26:00 - 18:26:03]
machine learning service Amazon

[18:26:01 - 18:26:06]
salesmaker pricing a let just try to

[18:26:03 - 18:26:08]
open it up now here if you just go below

[18:26:06 - 18:26:10]
you will see uh salesmaker will give you

[18:26:08 - 18:26:13]
all kinds of pricee list with respect to

[18:26:10 - 18:26:16]
all kinds of uh let's say machine type

[18:26:13 - 18:26:18]
let's say you want to use MLT 3 medium

[18:26:16 - 18:26:21]
it is having actually 4GB RAM and here

[18:26:18 - 18:26:23]
you will get two vcpu and this is the

[18:26:21 - 18:26:24]
price per hour like that actually it is

[18:26:23 - 18:26:25]
having actually different different

[18:26:24 - 18:26:27]
instance actually you can see it is also

[18:26:25 - 18:26:29]
having large instance so you can see it

[18:26:27 - 18:26:32]
is also having large instance x large

[18:26:29 - 18:26:34]
instance okay then 24x large also

[18:26:32 - 18:26:36]
instance it is also having now see the

[18:26:34 - 18:26:39]
more good configuration instance you

[18:26:36 - 18:26:40]
will be taking that means your vcpu is

[18:26:39 - 18:26:42]
increasing as well as the let's say

[18:26:40 - 18:26:44]
memory is also increasing you'll see

[18:26:42 - 18:26:46]
that price is also increasing so this is

[18:26:44 - 18:26:48]
the par hour price let's say par hour

[18:26:46 - 18:26:50]
price it will charge you $6 if you're

[18:26:48 - 18:26:53]
taking M ml

[18:26:50 - 18:26:55]
m5d 24x large now see if I show you the

[18:26:53 - 18:26:57]
chart now so this chart also they have

[18:26:55 - 18:26:58]
also suggested let's say you are

[18:26:57 - 18:27:01]
implementing one project with the help

[18:26:58 - 18:27:04]
of llama let's say Lama 70 okay Lama to

[18:27:01 - 18:27:05]
70 billion parameter and now see this is

[18:27:04 - 18:27:08]
the configuration you have to take this

[18:27:05 - 18:27:11]
is the configuration you have to take

[18:27:08 - 18:27:13]
mlg5 48x large okay configuration

[18:27:11 - 18:27:14]
machine uh but let's try to consider

[18:27:13 - 18:27:16]
Lama to 1 billion okay let's say you

[18:27:14 - 18:27:17]
want to use this this actually

[18:27:16 - 18:27:20]
configuration model now let's find this

[18:27:17 - 18:27:22]
configuration MLG fine 12x large so here

[18:27:20 - 18:27:23]
you can find out that configuration you

[18:27:22 - 18:27:27]
can see uh there are different different

[18:27:23 - 18:27:29]
CI are available this is the M5 C5 you

[18:27:27 - 18:27:30]
can also find out the G5 so as of now

[18:27:29 - 18:27:35]
let's try to consider this machine let's

[18:27:30 - 18:27:38]
say ml uh M m5d 24x large okay let's say

[18:27:35 - 18:27:40]
I want to use uh this okay this machine

[18:27:38 - 18:27:43]
I want to use this machine this machine

[18:27:40 - 18:27:46]
is having U 96 actually CPU and it is

[18:27:43 - 18:27:48]
also having 384 GB

[18:27:46 - 18:27:51]
uh memory now what is the Power Hour

[18:27:48 - 18:27:55]
cost Power Hour cost is you can see uh

[18:27:51 - 18:27:57]
$6 okay almost $6.5 you can consider $6

[18:27:55 - 18:28:00]
as of now now let's calculate the

[18:27:57 - 18:28:02]
pricing so what I will do I will open up

[18:28:00 - 18:28:04]
my

[18:28:02 - 18:28:06]
calculator uh I'm going to actually

[18:28:04 - 18:28:07]
calculate the price per day actually per

[18:28:06 - 18:28:10]
day how much actually it is charge me

[18:28:07 - 18:28:14]
let's say the price you can see it's $6

[18:28:10 - 18:28:15]
okay $6 times I want to run 24 hours

[18:28:14 - 18:28:18]
this model okay this model I want to run

[18:28:15 - 18:28:20]
let's say 24 hours in my uh actually

[18:28:18 - 18:28:22]
says make okay platform because see 24

[18:28:20 - 18:28:23]
hours your application should be keep on

[18:28:22 - 18:28:25]
running it's not like that you are

[18:28:23 - 18:28:26]
running for two hours again you are

[18:28:25 - 18:28:29]
stopping no people won't be using your

[18:28:26 - 18:28:32]
application chat ZB is running uh 24

[18:28:29 - 18:28:35]
hours okay uh 7 days it is all uh I mean

[18:28:32 - 18:28:37]
running every every time so you will see

[18:28:35 - 18:28:38]
there is no downtime so whenever you are

[18:28:37 - 18:28:41]
creating your application it should be

[18:28:38 - 18:28:43]
always running in 24 hours okay so let's

[18:28:41 - 18:28:46]
say I want to consider part day how much

[18:28:43 - 18:28:49]
actually it will charge me so 24 six six

[18:28:46 - 18:28:53]
6 * 24 so it will uh charge me actually

[18:28:49 - 18:28:55]
$144 only just one day it will charge me

[18:28:53 - 18:28:56]
$144 now if you're from India if you're

[18:28:55 - 18:28:58]
from Bangladesh if you're from any other

[18:28:56 - 18:29:00]
country just try to convert the currency

[18:28:58 - 18:29:01]
okay in your let's say money and try to

[18:29:00 - 18:29:04]
see how much money actually it is taking

[18:29:01 - 18:29:07]
part day from me got it now let's say I

[18:29:04 - 18:29:08]
want to run uh this model uh let's say I

[18:29:07 - 18:29:10]
want to run this model let's say seven

[18:29:08 - 18:29:13]
days what I do I'll just multiply with

[18:29:10 - 18:29:17]
seven multiply with seven now see this

[18:29:13 - 18:29:19]
is the C Day cost I got 1, $8 so it is

[18:29:17 - 18:29:21]
more than 1 lakh rupees okay more than

[18:29:19 - 18:29:24]
one lakh rupees actually it will take if

[18:29:21 - 18:29:27]
you're running this model uh 7 Days

[18:29:24 - 18:29:30]
let's say I want to run this model 4

[18:29:27 - 18:29:32]
weeks so this is the charge actually it

[18:29:30 - 18:29:35]
will take now let's say I want to run

[18:29:32 - 18:29:37]
this model one year so I can multiply

[18:29:35 - 18:29:40]
with 12 see this is the one year cost

[18:29:37 - 18:29:43]
actually you are getting

[18:29:40 - 18:29:45]
$48,000 okay

[18:29:43 - 18:29:47]
3384 so now let's see if you're running

[18:29:45 - 18:29:50]
a uh small startup if you're running is

[18:29:47 - 18:29:52]
a small company so will you afford that

[18:29:50 - 18:29:54]
much amount of money will you be able to

[18:29:52 - 18:29:56]
pay this this much amount of money no

[18:29:54 - 18:29:58]
definitely you are not so at then your

[18:29:56 - 18:29:59]
cost is increasing if you're using this

[18:29:58 - 18:30:02]
kinds of Open Source large language

[18:29:59 - 18:30:03]
model if you're deploying uh on this

[18:30:02 - 18:30:06]
kinds of let's say platform on the

[18:30:03 - 18:30:09]
custom let's say hosted server so you

[18:30:06 - 18:30:11]
will have lots of cost at end so better

[18:30:09 - 18:30:12]
to use the openi model that time yes or

[18:30:11 - 18:30:15]
no because openi model will charge you

[18:30:12 - 18:30:18]
less very less than okay very less than

[18:30:15 - 18:30:20]
than the this amount of money got it so

[18:30:18 - 18:30:23]
that's why so that's why actually llm

[18:30:20 - 18:30:25]
Ops comes into picture so what big tech

[18:30:23 - 18:30:26]
company actually did they came up with

[18:30:25 - 18:30:30]
actually different different kinds of

[18:30:26 - 18:30:32]
llm Ops platform so I think you saw um

[18:30:30 - 18:30:36]
not recently actually this llm Ops

[18:30:32 - 18:30:38]
platform came actually long back so

[18:30:36 - 18:30:41]
Google actually came up with one um LM

[18:30:38 - 18:30:45]
Ops platform called vertex

[18:30:41 - 18:30:47]
AI okay vertex AI so previously when you

[18:30:45 - 18:30:49]
used to use mops now also we used to use

[18:30:47 - 18:30:51]
something called vertex a for the mlops

[18:30:49 - 18:30:53]
also because this vertex a provides all

[18:30:51 - 18:30:55]
kinds of functionality all kinds of

[18:30:53 - 18:30:57]
let's say pipeline for the machine

[18:30:55 - 18:30:59]
learning operation as well okay nowadays

[18:30:57 - 18:31:03]
they also integrated geni okay in the

[18:30:59 - 18:31:05]
vertex AI even AWS that means Amazon web

[18:31:03 - 18:31:08]
service they also came up with another

[18:31:05 - 18:31:11]
lmos platform called

[18:31:08 - 18:31:14]
Bedrock okay Bedrock okay Bedrock so

[18:31:11 - 18:31:16]
Bedrock is also one llm of

[18:31:14 - 18:31:19]
platform and this is the new service

[18:31:16 - 18:31:20]
actually they have launched in the AWS

[18:31:19 - 18:31:21]
actually let's say website you will see

[18:31:20 - 18:31:23]
that there there would be one section

[18:31:21 - 18:31:25]
called Bedrock okay so Bedrock also

[18:31:23 - 18:31:26]
provides all kinds of llm off Services

[18:31:25 - 18:31:28]
let's say you want to use any kinds of

[18:31:26 - 18:31:30]
foundation model you want to use Lama

[18:31:28 - 18:31:33]
Mistral okay any kinds of foundation

[18:31:30 - 18:31:35]
model so this model is already hosted

[18:31:33 - 18:31:38]
see this model they have already hosted

[18:31:35 - 18:31:39]
in their server let's say whatever Lama

[18:31:38 - 18:31:41]
model whatever Mr model whatever model

[18:31:39 - 18:31:43]
you see these are the model is already

[18:31:41 - 18:31:45]
hosted in this llm offs platform like

[18:31:43 - 18:31:47]
that Google has also hosted lots of

[18:31:45 - 18:31:49]
found model in their server it's not

[18:31:47 - 18:31:50]
like that they're only hosting their

[18:31:49 - 18:31:52]
model let's say Google is having their

[18:31:50 - 18:31:54]
own model they having jini model they

[18:31:52 - 18:31:57]
having Jimma model yes or no apart from

[18:31:54 - 18:31:58]
these are the model they also hosted

[18:31:57 - 18:32:01]
some of the foundation model from any

[18:31:58 - 18:32:04]
other organization let's say from meta

[18:32:01 - 18:32:06]
AI from let's say mistal so they so what

[18:32:04 - 18:32:07]
they did actually they collaborated with

[18:32:06 - 18:32:09]
these are the organization even they

[18:32:07 - 18:32:11]
hosted their model in their platform as

[18:32:09 - 18:32:13]
well and they created one endpoint they

[18:32:11 - 18:32:16]
created one API okay they created one

[18:32:13 - 18:32:19]
API now as an user as a user what I can

[18:32:16 - 18:32:21]
do I can use this API to interact with

[18:32:19 - 18:32:24]
this model that means like our openi

[18:32:21 - 18:32:26]
will send the request okay to we send a

[18:32:24 - 18:32:28]
request to this kinds of llm of platform

[18:32:26 - 18:32:29]
with the help of API and here I will

[18:32:28 - 18:32:31]
mention what kinds of model I want to

[18:32:29 - 18:32:32]
use and this will give me the response

[18:32:31 - 18:32:34]
that means I don't need to download this

[18:32:32 - 18:32:36]
are the model in my system okay so this

[18:32:34 - 18:32:39]
is the main benefit to use this kinds of

[18:32:36 - 18:32:40]
lmos platform okay and it is having all

[18:32:39 - 18:32:43]
kinds of flexibility let's say you want

[18:32:40 - 18:32:44]
to connect the data you can easily

[18:32:43 - 18:32:46]
connect let's say you want to connect

[18:32:44 - 18:32:48]
the vector database you can easily

[18:32:46 - 18:32:51]
connect okay that means all kinds of

[18:32:48 - 18:32:53]
storage all kinds of flexibility this LM

[18:32:51 - 18:32:55]
platform will provide you it's not like

[18:32:53 - 18:32:57]
that manually you have to take from any

[18:32:55 - 18:32:59]
third party let's say tool it's not it's

[18:32:57 - 18:33:01]
not like that complete like let's say

[18:32:59 - 18:33:02]
pipeline it is already having even let's

[18:33:01 - 18:33:04]
say you are thinking to fine tune this

[18:33:02 - 18:33:06]
kinds of foundation model you can also

[18:33:04 - 18:33:08]
fine tune you can also perform the fine

[18:33:06 - 18:33:10]
tune operation so fine tuning will

[18:33:08 - 18:33:13]
happening in their server only not your

[18:33:10 - 18:33:15]
not your system only you just need to

[18:33:13 - 18:33:17]
set the configuration of the model then

[18:33:15 - 18:33:19]
you have to pass your data automatically

[18:33:17 - 18:33:22]
it will perform the fine tuning in their

[18:33:19 - 18:33:24]
server yeah it is sure they will charge

[18:33:22 - 18:33:27]
you but you will see this price would be

[18:33:24 - 18:33:28]
very less very less than your this cost

[18:33:27 - 18:33:30]
actually whatever cost actually I I

[18:33:28 - 18:33:33]
showed you here now if you're let's say

[18:33:30 - 18:33:35]
manually creating your Ser if you're

[18:33:33 - 18:33:36]
using manually different different kinds

[18:33:35 - 18:33:38]
of services that time price would be

[18:33:36 - 18:33:40]
high but if you're using this kinds of

[18:33:38 - 18:33:42]
lmos platform your price would be very

[18:33:40 - 18:33:43]
low guys trust me it would be very low

[18:33:42 - 18:33:45]
if you see the pricing now if you see

[18:33:43 - 18:33:47]
the pricing I'll tell you whenever we'll

[18:33:45 - 18:33:49]
be exploring these are the LMS platform

[18:33:47 - 18:33:50]
there I'll also show you the pricing

[18:33:49 - 18:33:53]
you'll see the pricing it should be very

[18:33:50 - 18:33:55]
low cor so that's why actually llm Ops

[18:33:53 - 18:33:57]
is required we need the LM offs if I

[18:33:55 - 18:33:59]
want to use this kinds of foundational

[18:33:57 - 18:34:01]
model it's not like that we only need to

[18:33:59 - 18:34:03]
rely on the openi model because we we

[18:34:01 - 18:34:05]
saw that there are so many model which

[18:34:03 - 18:34:07]
is more powerful than my openi model

[18:34:05 - 18:34:10]
even there is another cloud provider I

[18:34:07 - 18:34:13]
think you know a so a also having one

[18:34:10 - 18:34:16]
lmos platform called a your openi okay a

[18:34:13 - 18:34:17]
your openi so they have what they did

[18:34:16 - 18:34:20]
they collaborated with openi and they

[18:34:17 - 18:34:21]
bring the openi platform in the Azure

[18:34:20 - 18:34:23]
platform only okay on top of that they

[18:34:21 - 18:34:25]
created some more services and it is

[18:34:23 - 18:34:27]
running on the AZ right now so if you

[18:34:25 - 18:34:29]
know about open now open so you'll be

[18:34:27 - 18:34:32]
also work with the AO okay AO let's say

[18:34:29 - 18:34:34]
open so openi wise we already saw how we

[18:34:32 - 18:34:35]
can use openi with the help of open py

[18:34:34 - 18:34:38]
how we can access different different

[18:34:35 - 18:34:39]
kinds of foundation model okay so yes

[18:34:38 - 18:34:42]
guys this is the complete idea of our

[18:34:39 - 18:34:44]
llm Ops and why llm Ops is required okay

[18:34:42 - 18:34:46]
so in the next video we'll be learning

[18:34:44 - 18:34:48]
about one amazing actually L platform

[18:34:46 - 18:34:49]
called verx a from the Google site so

[18:34:48 - 18:34:51]
we'll see the entire platform what kinds

[18:34:49 - 18:34:53]
of service it provides even we'll also

[18:34:51 - 18:34:55]
do lots of practical we'll also do the

[18:34:53 - 18:34:56]
handson we'll be creating different

[18:34:55 - 18:34:58]
different let's say llm power

[18:34:56 - 18:35:00]
application with help of verx a even I

[18:34:58 - 18:35:02]
will also show you the AWS Bedrock how

[18:35:00 - 18:35:03]
we can use the Bedrock okay to implement

[18:35:02 - 18:35:05]
any kinds of end to end LM powered

[18:35:03 - 18:35:06]
application even we also learning how we

[18:35:05 - 18:35:08]
can deploy these at the project as well

[18:35:06 - 18:35:10]
fine in this video we'll be starting

[18:35:08 - 18:35:13]
with our very first llm Ops platform

[18:35:10 - 18:35:16]
called verx and I think I already told

[18:35:13 - 18:35:18]
you verx is the platform from the Google

[18:35:16 - 18:35:20]
so it is available in the Google Cloud

[18:35:18 - 18:35:22]
so Google has developed this platform so

[18:35:20 - 18:35:24]
here we'll be doing this complete genv

[18:35:22 - 18:35:25]
on the Google Cloud we'll be learning

[18:35:24 - 18:35:27]
how we can use different kinds of

[18:35:25 - 18:35:28]
foundation model even uh with that how

[18:35:27 - 18:35:31]
we can uh create different different

[18:35:28 - 18:35:32]
kinds of LM powered application so guys

[18:35:31 - 18:35:35]
here you can see this is the complete

[18:35:32 - 18:35:37]
Revolution at the Google uh inside

[18:35:35 - 18:35:39]
artificial intelligence I think you

[18:35:37 - 18:35:41]
remember in 2017 uh they bring actually

[18:35:39 - 18:35:43]
one architecture called Transformer so

[18:35:41 - 18:35:45]
whenever this Transformer architecture

[18:35:43 - 18:35:47]
came in the market uh after there

[18:35:45 - 18:35:49]
actually so many Revolution happened in

[18:35:47 - 18:35:51]
the field of language model in the field

[18:35:49 - 18:35:52]
of large language model that means

[18:35:51 - 18:35:55]
whatever architecture you can see

[18:35:52 - 18:35:56]
nowadays all the architecture are using

[18:35:55 - 18:35:59]
this Transformer architecture in the

[18:35:56 - 18:36:01]
back end even I already uh created one

[18:35:59 - 18:36:02]
video right I already took one session

[18:36:01 - 18:36:04]
on the Transformer architecture like

[18:36:02 - 18:36:05]
what was the main component inside

[18:36:04 - 18:36:08]
Transformer architecture and why it is

[18:36:05 - 18:36:10]
so powerful right so then after that

[18:36:08 - 18:36:13]
actually in 2018 actually they came up

[18:36:10 - 18:36:14]
with another model called Bart BT so

[18:36:13 - 18:36:16]
this is one of the actually language

[18:36:14 - 18:36:18]
model they brought then they brought

[18:36:16 - 18:36:20]
actually T5 model then slightly actually

[18:36:18 - 18:36:22]
in 2020 actually they brought one large

[18:36:20 - 18:36:24]
language model called Lambda so Lambda

[18:36:22 - 18:36:27]
was amazing model in the field of large

[18:36:24 - 18:36:29]
language model then 2021 they uh

[18:36:27 - 18:36:32]
actually published Alpha fold model then

[18:36:29 - 18:36:34]
22 Palm model and in 2023 they

[18:36:32 - 18:36:37]
introduced something called B model OKAY

[18:36:34 - 18:36:39]
b a r d b I think we used to use uh

[18:36:37 - 18:36:41]
Google B right Google B that means uh it

[18:36:39 - 18:36:44]
is the Char gbt kinds of interface I

[18:36:41 - 18:36:47]
think remember nowadays this B has been

[18:36:44 - 18:36:49]
let's say replaced with the jini so we

[18:36:47 - 18:36:50]
uh now actually we search for Jin but

[18:36:49 - 18:36:52]
previously we used to search for B right

[18:36:50 - 18:36:54]
so this was the first application from

[18:36:52 - 18:36:56]
the Google actually the published and

[18:36:54 - 18:36:57]
you can see the model summary like what

[18:36:56 - 18:36:59]
are the task this model can perform so

[18:36:57 - 18:37:01]
as you can see T5 can perform Tex to

[18:36:59 - 18:37:03]
text generation it's a transfer learning

[18:37:01 - 18:37:05]
model uh it is having actually 10

[18:37:03 - 18:37:07]
billion parameter and it's open source

[18:37:05 - 18:37:09]
model then Google Lambda model then you

[18:37:07 - 18:37:11]
can see the Lambda model uh trained to

[18:37:09 - 18:37:14]
convers then Alpha fold predict

[18:37:11 - 18:37:16]
structure for uh for all known proteins

[18:37:14 - 18:37:18]
then Palm actually this is the industry

[18:37:16 - 18:37:19]
leading actually large language model

[18:37:18 - 18:37:21]
they they introduced something called

[18:37:19 - 18:37:23]
conversational AI service powered by

[18:37:21 - 18:37:25]
Lambda okay then in 2024 I think you can

[18:37:23 - 18:37:29]
see from the Google research we are

[18:37:25 - 18:37:31]
having gin then uh imag 2 okay this is

[18:37:29 - 18:37:32]
uh this can actually generate image okay

[18:37:31 - 18:37:34]
with respect to the text prompt then

[18:37:32 - 18:37:35]
we're having also something called Jima

[18:37:34 - 18:37:37]
okay Zima is one of the large langage

[18:37:35 - 18:37:39]
model then there is another model called

[18:37:37 - 18:37:42]
chart this is the model it can generate

[18:37:39 - 18:37:44]
is to text so that's actually Revolution

[18:37:42 - 18:37:46]
happened that means uh it took actually

[18:37:44 - 18:37:49]
lots of time time to came up in this

[18:37:46 - 18:37:51]
position and Google introduced actually

[18:37:49 - 18:37:53]
so many research so many model okay so

[18:37:51 - 18:37:55]
many technology and nowadays actually we

[18:37:53 - 18:37:57]
are using these kinds of Technology okay

[18:37:55 - 18:37:58]
in the field of gen tvi and guys here

[18:37:57 - 18:38:00]
you can see these are some actually

[18:37:58 - 18:38:03]
first party Foundation model like Palm

[18:38:00 - 18:38:05]
for text you can customize language task

[18:38:03 - 18:38:07]
then uh Palm for actually chat so here

[18:38:05 - 18:38:09]
you can perform conversation okay then

[18:38:07 - 18:38:11]
you can uh do the Imaging okay for the

[18:38:09 - 18:38:13]
text to image that means if you give any

[18:38:11 - 18:38:15]
let's say prompt it will generate the

[18:38:13 - 18:38:16]
image okay then we also had something

[18:38:15 - 18:38:18]
called embeddings model that means

[18:38:16 - 18:38:19]
embedding API let's say you want to

[18:38:18 - 18:38:21]
generate any kinds of embedding for the

[18:38:19 - 18:38:23]
text or image you can use this kinds of

[18:38:21 - 18:38:25]
embedding model okay then chart model

[18:38:23 - 18:38:27]
spe to text then code generation model

[18:38:25 - 18:38:29]
was also available so this was the first

[18:38:27 - 18:38:31]
party Foundation model in the Google

[18:38:29 - 18:38:33]
research okay then they introduce

[18:38:31 - 18:38:35]
something called Model Garden okay so

[18:38:33 - 18:38:36]
what is model Garden so here you can

[18:38:35 - 18:38:39]
access customize and experiment with

[18:38:36 - 18:38:41]
different Foundation models and its API

[18:38:39 - 18:38:43]
okay that means what Google did actually

[18:38:41 - 18:38:46]
they uh introduced one platform called

[18:38:43 - 18:38:48]
vertex a so vertex a was the platform in

[18:38:46 - 18:38:50]
the Google and it's been actually long

[18:38:48 - 18:38:53]
this platform is uh available in the

[18:38:50 - 18:38:54]
Google uh Google Cloud but only we used

[18:38:53 - 18:38:57]
to perform mlops operation with the help

[18:38:54 - 18:38:59]
of vertex a but whenever actually this

[18:38:57 - 18:39:01]
Genera VI came so they updated this

[18:38:59 - 18:39:03]
vertex Ai and they introduced something

[18:39:01 - 18:39:05]
called Model Garden that means inside

[18:39:03 - 18:39:07]
verx AI you have one model Garden inside

[18:39:05 - 18:39:09]
model Garden you are having all kinds of

[18:39:07 - 18:39:11]
Google model whatever model actually

[18:39:09 - 18:39:12]
Google has published now all the model

[18:39:11 - 18:39:14]
you will get all the foundation model

[18:39:12 - 18:39:15]
you will get in the model Garden apart

[18:39:14 - 18:39:16]
from that you will also get something

[18:39:15 - 18:39:18]
called called open source model like

[18:39:16 - 18:39:19]
whatever open source model I think I

[18:39:18 - 18:39:20]
showed you now from the hugging phase

[18:39:19 - 18:39:23]
from different different let's say

[18:39:20 - 18:39:25]
organization like llama mistal Falone

[18:39:23 - 18:39:26]
right different different kinds of Open

[18:39:25 - 18:39:28]
Source model I think I already

[18:39:26 - 18:39:29]
introduced in the hugging pH so what

[18:39:28 - 18:39:31]
they did actually they also hosted these

[18:39:29 - 18:39:32]
kinds of Open Source model in the model

[18:39:31 - 18:39:33]
Garden that means you can use all kinds

[18:39:32 - 18:39:36]
of Open Source model from the model

[18:39:33 - 18:39:38]
Garden itself okay from the verx a then

[18:39:36 - 18:39:40]
it is also having some partner Partners

[18:39:38 - 18:39:41]
model so what is Partners model exactly

[18:39:40 - 18:39:43]
so they collaborated with different

[18:39:41 - 18:39:44]
different kinds of organization they

[18:39:43 - 18:39:46]
collaborated with the different

[18:39:44 - 18:39:49]
different kinds of company let's say

[18:39:46 - 18:39:51]
cloud is a company then we are having

[18:39:49 - 18:39:52]
Meta Meta is a company okay that's how

[18:39:51 - 18:39:54]
we are having different different kinds

[18:39:52 - 18:39:57]
of company so this company has also

[18:39:54 - 18:39:58]
introduced so many large Lang Bas model

[18:39:57 - 18:40:00]
okay so what they did actually they

[18:39:58 - 18:40:01]
collaborated with the company

[18:40:00 - 18:40:02]
collaborated with the organization and

[18:40:01 - 18:40:04]
all kinds of actually model they

[18:40:02 - 18:40:06]
introduce in the model Garden so this is

[18:40:04 - 18:40:08]
called actually partner models now let

[18:40:06 - 18:40:10]
me show you the vertx platform right now

[18:40:08 - 18:40:13]
how it looks like you can see guys this

[18:40:10 - 18:40:14]
is the previous vxi platform okay that

[18:40:13 - 18:40:16]
means here we used to only perform the

[18:40:14 - 18:40:18]
ml operation that means machine learning

[18:40:16 - 18:40:20]
operation that means you can apart from

[18:40:18 - 18:40:22]
the experiment train and deploy okay for

[18:40:20 - 18:40:23]
the data science workbench now what they

[18:40:22 - 18:40:26]
introduce actually on top of this

[18:40:23 - 18:40:27]
platform they introduce genbi you can

[18:40:26 - 18:40:29]
see they introduce something called

[18:40:27 - 18:40:31]
genbi platform that means here you can

[18:40:29 - 18:40:33]
perform the pr designing fine tuning gen

[18:40:31 - 18:40:36]
Studio okay Foundation model open source

[18:40:33 - 18:40:37]
model okay then uh you can also perform

[18:40:36 - 18:40:39]
actually LM Ops everything you can

[18:40:37 - 18:40:41]
perform in this platform right now that

[18:40:39 - 18:40:43]
means instead of replacing uh the

[18:40:41 - 18:40:45]
previous actually let's say verx AI

[18:40:43 - 18:40:47]
services on top of that they create

[18:40:45 - 18:40:49]
created one additional layer and this is

[18:40:47 - 18:40:50]
called actually llm of splat form now it

[18:40:49 - 18:40:53]
is on the vertic L okay now I think it

[18:40:50 - 18:40:56]
is clear now as I already told you uh

[18:40:53 - 18:40:57]
they introduce so many actually Partners

[18:40:56 - 18:40:59]
model okay I already told you they

[18:40:57 - 18:41:00]
introduce so many partners model in the

[18:40:59 - 18:41:02]
model Guiden so these are the partners

[18:41:00 - 18:41:04]
okay these are the partners actually

[18:41:02 - 18:41:06]
with Google I think nowadays they also

[18:41:04 - 18:41:09]
collaborated with so many organization

[18:41:06 - 18:41:10]
if you open the Google U Cloud vertx

[18:41:09 - 18:41:12]
we'll see different kinds of actually

[18:41:10 - 18:41:15]
partner models are available so here you

[18:41:12 - 18:41:17]
can see AI 21 Labs uh this another organ

[18:41:15 - 18:41:21]
ation they collaborated with the Google

[18:41:17 - 18:41:25]
then anthropy C then contextual AI okay

[18:41:21 - 18:41:28]
mid Journey then osmo then resistant. a

[18:41:25 - 18:41:29]
meta okay Runway and so on so these are

[18:41:28 - 18:41:31]
the actually

[18:41:29 - 18:41:33]
Partners model actually it will you'll

[18:41:31 - 18:41:36]
be getting in the model garden now let

[18:41:33 - 18:41:38]
me show you this uh gcp okay gcp vertex

[18:41:36 - 18:41:40]
AI so let's open up our account and

[18:41:38 - 18:41:41]
let's open up the verx there and try to

[18:41:40 - 18:41:43]
see whether these are the things are

[18:41:41 - 18:41:45]
available or not so for this guys what

[18:41:43 - 18:41:48]
you can do just search for gcp

[18:41:45 - 18:41:49]
okay gcp console in your Google and make

[18:41:48 - 18:41:51]
sure you have one gcp account okay if

[18:41:49 - 18:41:53]
you don't have the gcp account guys so

[18:41:51 - 18:41:55]
you won't be able to use the vertx so

[18:41:53 - 18:41:56]
make sure you if you don't have the

[18:41:55 - 18:41:58]
account just try to create one account

[18:41:56 - 18:42:01]
initially it will give you $300 credit

[18:41:58 - 18:42:03]
okay so let me uh login with my console

[18:42:01 - 18:42:05]
so guys as you can see this is my gcp

[18:42:03 - 18:42:07]
console so here what you have to do in

[18:42:05 - 18:42:11]
the search button just search for vertex

[18:42:07 - 18:42:14]
AI okay verx AI so you'll see this is

[18:42:11 - 18:42:15]
the platform this is the lmop platform

[18:42:14 - 18:42:17]
you'll get see this this is the complete

[18:42:15 - 18:42:19]
vertx AI now left hand side you will see

[18:42:17 - 18:42:20]
different different kinds of services so

[18:42:19 - 18:42:21]
here I already told you it is having

[18:42:20 - 18:42:24]
model Garden so let me click on the

[18:42:21 - 18:42:26]
model Garden so here you will see all

[18:42:24 - 18:42:28]
kinds of model so guys as you can see

[18:42:26 - 18:42:30]
whatever model I showed you all kinds of

[18:42:28 - 18:42:32]
model are available apart from that uh

[18:42:30 - 18:42:34]
they have also actually brought new new

[18:42:32 - 18:42:37]
model here you can see uh so Foundation

[18:42:34 - 18:42:39]
model okay then Partners model see all

[18:42:37 - 18:42:41]
kinds of models are available okay as

[18:42:39 - 18:42:43]
you can see Meta model is available that

[18:42:41 - 18:42:46]
means llama 2 llama 3 okay then Palm

[18:42:43 - 18:42:49]
model uh you can also show all the model

[18:42:46 - 18:42:51]
here so see here I can click on the show

[18:42:49 - 18:42:53]
all model see all kinds of model are

[18:42:51 - 18:42:57]
available see mral Al also is there then

[18:42:53 - 18:42:59]
Jamba model then you can see cloudy okay

[18:42:57 - 18:43:02]
apart from that you will see different

[18:42:59 - 18:43:04]
kinds of uh actually Foundation model

[18:43:02 - 18:43:06]
you will get okay and these are the

[18:43:04 - 18:43:08]
actually partner okay partner company

[18:43:06 - 18:43:10]
apart from that you can also filter out

[18:43:08 - 18:43:11]
let's say you need language model so

[18:43:10 - 18:43:13]
here you are having 63 language model

[18:43:11 - 18:43:15]
you can filter out all the language

[18:43:13 - 18:43:16]
model let's you need visual model you

[18:43:15 - 18:43:18]
are having 11 Vision model you can also

[18:43:16 - 18:43:20]
filter out all the vision model okay now

[18:43:18 - 18:43:21]
let's say you want to use this model

[18:43:20 - 18:43:23]
just click

[18:43:21 - 18:43:25]
here and you will get all the guideline

[18:43:23 - 18:43:26]
how to use this model andal okay they

[18:43:25 - 18:43:29]
have already given the source code

[18:43:26 - 18:43:32]
everything they have given okay how to

[18:43:29 - 18:43:34]
uh use the python uh SDK for uh let's

[18:43:32 - 18:43:35]
say using this model and all all the

[18:43:34 - 18:43:37]
let's say guideline they have already

[18:43:35 - 18:43:39]
given okay I'll tell you how we can use

[18:43:37 - 18:43:40]
these are the model one by one okay now

[18:43:39 - 18:43:42]
let's say you want to also play this

[18:43:40 - 18:43:43]
model in the model Garden okay it is

[18:43:42 - 18:43:45]
also possible let me show you so let's

[18:43:43 - 18:43:48]
say this is my model Garden let's I want

[18:43:45 - 18:43:52]
to uh like play with this model jini 1.5

[18:43:48 - 18:43:52]
Pro uh so I'll just click

[18:43:52 - 18:43:58]
here now you can see open in a Vertex AI

[18:43:55 - 18:44:00]
studio so here you can open this model

[18:43:58 - 18:44:02]
in the AI studio so they are also having

[18:44:00 - 18:44:03]
one AI Studio let me show you even you

[18:44:02 - 18:44:05]
can also open with the help of collab

[18:44:03 - 18:44:07]
notebook and there also you can also

[18:44:05 - 18:44:09]
play with this model now let's click on

[18:44:07 - 18:44:11]
the I agree and continue now here you

[18:44:09 - 18:44:12]
can pass any kinds of prompt let's say I

[18:44:11 - 18:44:15]
give

[18:44:12 - 18:44:16]
hello and I will send this prompt

[18:44:15 - 18:44:18]
and this is the response actually I'm

[18:44:16 - 18:44:19]
getting okay so that's how actually you

[18:44:18 - 18:44:21]
can play with different different kinds

[18:44:19 - 18:44:22]
of model before using it like how this

[18:44:21 - 18:44:24]
model is working on all what is the

[18:44:22 - 18:44:26]
performance of the model everything you

[18:44:24 - 18:44:27]
can perform here okay then you can also

[18:44:26 - 18:44:29]
search by the model name let's say you

[18:44:27 - 18:44:31]
need Jimma model Lama model anything you

[18:44:29 - 18:44:34]
can search here you will also get these

[18:44:31 - 18:44:35]
are the model got it and Guys these are

[18:44:34 - 18:44:36]
the model is already hosted in the

[18:44:35 - 18:44:38]
Google Cloud so you don't need to

[18:44:36 - 18:44:40]
manually download these are the model in

[18:44:38 - 18:44:43]
your system you can use this at the

[18:44:40 - 18:44:45]
model with the help of uh API request as

[18:44:43 - 18:44:48]
I already told you that's how so that is

[18:44:45 - 18:44:49]
why we call it as a llm of platform okay

[18:44:48 - 18:44:50]
so they gives the API canel

[18:44:49 - 18:44:52]
functionality with the help of API

[18:44:50 - 18:44:53]
request we can use these are the model

[18:44:52 - 18:44:55]
in our uh let's say project

[18:44:53 - 18:44:56]
implementation and don't you worry I'll

[18:44:55 - 18:44:57]
tell you how we can access different

[18:44:56 - 18:44:59]
different kinds of model we'll be also

[18:44:57 - 18:45:01]
implementing some kinds of

[18:44:59 - 18:45:03]
application now apart from that vertic

[18:45:01 - 18:45:04]
also provide so many services you can

[18:45:03 - 18:45:06]
see it provides the pipeline services

[18:45:04 - 18:45:08]
this is the pipeline for the mlops let's

[18:45:06 - 18:45:10]
say you want to perform any end to end

[18:45:08 - 18:45:12]
pipeline data ination data validation

[18:45:10 - 18:45:14]
model training model evaluation you can

[18:45:12 - 18:45:15]
use the pipeline Services apart from

[18:45:14 - 18:45:17]
that it also provides the notebook

[18:45:15 - 18:45:19]
services that means let's say you want

[18:45:17 - 18:45:21]
to uh let's say use one large language

[18:45:19 - 18:45:22]
model uh you want to find in one large

[18:45:21 - 18:45:24]
language model you can use their collab

[18:45:22 - 18:45:26]
Enterprise that means you you can U take

[18:45:24 - 18:45:27]
the machine okay good configuration

[18:45:26 - 18:45:29]
machine good configuration collab

[18:45:27 - 18:45:31]
notebook in their Google cloud service

[18:45:29 - 18:45:32]
okay then you can also take the

[18:45:31 - 18:45:33]
workbench as well then you can see

[18:45:32 - 18:45:35]
different different studio is there you

[18:45:33 - 18:45:38]
can perform different different kinds of

[18:45:35 - 18:45:39]
let's say u i mean task task demo let's

[18:45:38 - 18:45:41]
say you can perform chat demo Vision

[18:45:39 - 18:45:42]
demo translation speech okay you can

[18:45:41 - 18:45:44]
play with these are the functionality as

[18:45:42 - 18:45:46]
of now I'm not showing then you can also

[18:45:44 - 18:45:47]
download different different kinds of

[18:45:46 - 18:45:49]
extension for the geni from the

[18:45:47 - 18:45:50]
extension Market here you will also get

[18:45:49 - 18:45:52]
something called feature restore data

[18:45:50 - 18:45:54]
set okay labeling task then training

[18:45:52 - 18:45:56]
experiment okay so some of the services

[18:45:54 - 18:45:58]
you will see these are the MLF services

[18:45:56 - 18:45:59]
not the Genera Services AP from that you

[18:45:58 - 18:46:01]
will also get something called vectors

[18:45:59 - 18:46:03]
RCR this is another super important

[18:46:01 - 18:46:05]
service from the verx a let's say you

[18:46:03 - 18:46:07]
don't want to use any other Vector

[18:46:05 - 18:46:09]
database what you can do you can use uh

[18:46:07 - 18:46:11]
this verx a vector SE this is another

[18:46:09 - 18:46:13]
Vector database okay and this is hosted

[18:46:11 - 18:46:15]
in the Google Cloud that means in the

[18:46:13 - 18:46:17]
verx AI so going forward I will also

[18:46:15 - 18:46:19]
show you how we can use this uh Vector

[18:46:17 - 18:46:21]
search Okay Vector search functionality

[18:46:19 - 18:46:22]
from the verx a itself so yes Guys these

[18:46:21 - 18:46:24]
are the services actually verx a

[18:46:22 - 18:46:26]
provides so unless an Al one not

[18:46:24 - 18:46:27]
exploring all the functionality okay you

[18:46:26 - 18:46:29]
won't be getting so try to open this

[18:46:27 - 18:46:31]
account guys and try to explore all

[18:46:29 - 18:46:32]
kinds of functionality okay now there I

[18:46:31 - 18:46:34]
told you you can perform different

[18:46:32 - 18:46:35]
different kinds of operation okay

[18:46:34 - 18:46:36]
different different kinds of this

[18:46:35 - 18:46:37]
operation it will give you all kinds of

[18:46:36 - 18:46:40]
functionality okay and I showed you the

[18:46:37 - 18:46:41]
model guarden and all uh so then I

[18:46:40 - 18:46:43]
already told you we can also perform

[18:46:41 - 18:46:45]
something called fine tuning so it's not

[18:46:43 - 18:46:46]
like that you can only use these are the

[18:46:45 - 18:46:47]
Foundation model for the inference no

[18:46:46 - 18:46:49]
you can also perform the fine tuning

[18:46:47 - 18:46:51]
operation that means this vertx I will

[18:46:49 - 18:46:53]
give you the functionality you can also

[18:46:51 - 18:46:55]
improve the model performance with the

[18:46:53 - 18:46:56]
help of fine tuning okay on top of your

[18:46:55 - 18:46:58]
custom data you can also perform

[18:46:56 - 18:47:00]
something called human feedback to

[18:46:58 - 18:47:02]
increase your model usefulness like I

[18:47:00 - 18:47:05]
think previously you saw uh in the chat

[18:47:02 - 18:47:07]
GPT uh it used to give one feedback box

[18:47:05 - 18:47:09]
right let's say how use your experience

[18:47:07 - 18:47:10]
so that you can uh give your experience

[18:47:09 - 18:47:12]
rating so that kinds of rating also you

[18:47:10 - 18:47:14]
can pass if you're using this kinds of

[18:47:12 - 18:47:16]
verx AI then here you can also generate

[18:47:14 - 18:47:18]
customize for your business then here

[18:47:16 - 18:47:20]
you can also improve Google's predictive

[18:47:18 - 18:47:22]
AI with your own custom data okay

[18:47:20 - 18:47:23]
everything is possible here now you can

[18:47:22 - 18:47:25]
ask me what kinds of task actually I can

[18:47:23 - 18:47:27]
perform here you can perform all kinds

[18:47:25 - 18:47:29]
of task so you can perform language

[18:47:27 - 18:47:31]
image video okay documents speech

[18:47:29 - 18:47:33]
tabular so here all kinds of task you

[18:47:31 - 18:47:36]
can perform with the help of vertx AI

[18:47:33 - 18:47:37]
okay and what verx actually provides uh

[18:47:36 - 18:47:39]
as I already told you it will give you

[18:47:37 - 18:47:41]
stateof the Art Foundation model even

[18:47:39 - 18:47:43]
you will also get end to end governance

[18:47:41 - 18:47:45]
that means you can do the pro prompting

[18:47:43 - 18:47:48]
tuning okay you can also perform mlops

[18:47:45 - 18:47:50]
operation on the verx a even here you

[18:47:48 - 18:47:51]
will get the data privacy so whenever

[18:47:50 - 18:47:53]
let's say you are uploading your custom

[18:47:51 - 18:47:54]
data to the verx a it's not like that

[18:47:53 - 18:47:56]
your data would be leaked uh it would be

[18:47:54 - 18:47:59]
secure okay so this kinds of actually

[18:47:56 - 18:48:00]
ensure you will get if you're using verx

[18:47:59 - 18:48:02]
platform that means you will have the

[18:48:00 - 18:48:03]
complete data security so no need to

[18:48:02 - 18:48:05]
worry about your data if you're having

[18:48:03 - 18:48:07]
any custom data all the data would be

[18:48:05 - 18:48:09]
secured here so now I think you got the

[18:48:07 - 18:48:12]
difference between mlops and LM Ops so

[18:48:09 - 18:48:14]
in the verx I we have the AML Ops um

[18:48:12 - 18:48:16]
like Services already on top of that

[18:48:14 - 18:48:18]
they created the LMS okay so here we

[18:48:16 - 18:48:20]
don't need to throw out your existing

[18:48:18 - 18:48:22]
mlfs investment okay so here what you

[18:48:20 - 18:48:24]
need to do you just need to understand

[18:48:22 - 18:48:26]
the unique MLS need for the Gen that

[18:48:24 - 18:48:27]
means whatever additional let's say

[18:48:26 - 18:48:29]
functionality they have given just try

[18:48:27 - 18:48:31]
to understand and try to use uh let's

[18:48:29 - 18:48:32]
say those are the service in the genbi

[18:48:31 - 18:48:34]
field okay that means uh you can see in

[18:48:32 - 18:48:36]
the verx AI you will see multitask model

[18:48:34 - 18:48:38]
fronting okay then model Garden

[18:48:36 - 18:48:40]
customization managing new artifacts

[18:48:38 - 18:48:41]
evaluation monitoring okay connecting

[18:48:40 - 18:48:42]
with the Enterprise data let's say you

[18:48:41 - 18:48:44]
want to connect with different different

[18:48:42 - 18:48:47]
kinds of data sources it is also

[18:48:44 - 18:48:49]
possible in the vertx a so now as a high

[18:48:47 - 18:48:51]
level you can see the complete mlops on

[18:48:49 - 18:48:53]
the verx a this is the so this was

[18:48:51 - 18:48:54]
actually our traditional verx a that

[18:48:53 - 18:48:57]
means here we can perform experiment

[18:48:54 - 18:48:58]
training and deploy uh and predict okay

[18:48:57 - 18:49:00]
for the machine learning operation and

[18:48:58 - 18:49:03]
now in the vertic a you can also perform

[18:49:00 - 18:49:04]
something called uh prom predict okay

[18:49:03 - 18:49:05]
then you can also use something called

[18:49:04 - 18:49:07]
Foundation model that means all kinds of

[18:49:05 - 18:49:09]
Z VI based functionality you will get

[18:49:07 - 18:49:10]
here then uh I already told you you can

[18:49:09 - 18:49:12]
also connect with uh different different

[18:49:10 - 18:49:15]
Enterprise data let's say you want to

[18:49:12 - 18:49:16]
connect any external sources any API any

[18:49:15 - 18:49:19]
website you can also connect okay with

[18:49:16 - 18:49:20]
the help of vertx a so guys all kinds of

[18:49:19 - 18:49:23]
flexibility you will get here if you're

[18:49:20 - 18:49:25]
using verx LL platform so no need to

[18:49:23 - 18:49:27]
worry about anything so yes guys this is

[18:49:25 - 18:49:30]
the complete uh introduction of our verx

[18:49:27 - 18:49:32]
a the complete generative AI on the GCB

[18:49:30 - 18:49:33]
cloud in the next video we'll try to see

[18:49:32 - 18:49:35]
how we can build different kinds of

[18:49:33 - 18:49:37]
transformative llm powered application

[18:49:35 - 18:49:39]
okay with the help of this verx a

[18:49:37 - 18:49:42]
platform so far we have discussed about

[18:49:39 - 18:49:44]
llm Ops and this uh generative vertex AI

[18:49:42 - 18:49:46]
now in this video we'll be uh trying to

[18:49:44 - 18:49:48]
use this vertic as a practical that

[18:49:46 - 18:49:50]
means let's say if I want to use any

[18:49:48 - 18:49:52]
kinds of foundation model uh with the

[18:49:50 - 18:49:53]
help of python code so how we can do it

[18:49:52 - 18:49:55]
okay that means we'll be doing the

[18:49:53 - 18:49:57]
entire handson in this video so try to

[18:49:55 - 18:49:59]
open up your Google uh cloud guys

[18:49:57 - 18:50:01]
everyone and just try to open up your

[18:49:59 - 18:50:03]
verx I I already show you how we can

[18:50:01 - 18:50:04]
open the open up the vertex a right now

[18:50:03 - 18:50:06]
after opening the vertx a the first

[18:50:04 - 18:50:08]
thing you have to do you have to enable

[18:50:06 - 18:50:09]
all the recommended apis so there you

[18:50:08 - 18:50:12]
will see one option enable all the

[18:50:09 - 18:50:14]
recommended apis so make sure you have

[18:50:12 - 18:50:16]
already enabled all the recommended apis

[18:50:14 - 18:50:18]
so after en in uh in the notification

[18:50:16 - 18:50:20]
bar you will see uh See all the API has

[18:50:18 - 18:50:22]
been enabled so these are the API you

[18:50:20 - 18:50:23]
should enable otherwise sometimes

[18:50:22 - 18:50:25]
actually will get actually different

[18:50:23 - 18:50:28]
different add so that's why make sure

[18:50:25 - 18:50:30]
you enabled all the API now here you can

[18:50:28 - 18:50:32]
either open up your Google collab uh to

[18:50:30 - 18:50:33]
perform all the let's say operation I'll

[18:50:32 - 18:50:36]
be doing here either you can also open

[18:50:33 - 18:50:38]
up this collab Enterprise or workbench

[18:50:36 - 18:50:41]
okay so here I'm using this Cloud

[18:50:38 - 18:50:42]
platform that means LM Ops platform so

[18:50:41 - 18:50:44]
in this video I'll show you how we can

[18:50:42 - 18:50:47]
use their services actually that if I

[18:50:44 - 18:50:48]
want to use collab Enterprise how we can

[18:50:47 - 18:50:50]
use collab Enterprise you can also

[18:50:48 - 18:50:52]
launch this Marben so what is the

[18:50:50 - 18:50:53]
difference between Marben and collab

[18:50:52 - 18:50:54]
Enterprise let me show you so in

[18:50:53 - 18:50:56]
workbench actually you can select the

[18:50:54 - 18:50:58]
machine configuration so here you can

[18:50:56 - 18:51:00]
create a new workbench just try to click

[18:50:58 - 18:51:02]
on create now here you can select the

[18:51:00 - 18:51:04]
machine configuration like uh what

[18:51:02 - 18:51:05]
should be the machine name what is the

[18:51:04 - 18:51:07]
reason then you can also select the

[18:51:05 - 18:51:08]
instance type okay that's how actually

[18:51:07 - 18:51:09]
you can uh change the configuration okay

[18:51:08 - 18:51:11]
all the configurations see you can

[18:51:09 - 18:51:13]
change here okay everything you can

[18:51:11 - 18:51:14]
change here that means if you want to

[18:51:13 - 18:51:16]
create a custom machine as per your

[18:51:14 - 18:51:17]
requirement you can change here and here

[18:51:16 - 18:51:20]
you can see the pricing summary that

[18:51:17 - 18:51:21]
means per hour it will charge you $0.18

[18:51:20 - 18:51:23]
you can see price is very less it's not

[18:51:21 - 18:51:25]
like very huge amount of money they will

[18:51:23 - 18:51:26]
be charging it's like very less money so

[18:51:25 - 18:51:28]
you can also create your custom

[18:51:26 - 18:51:29]
configuration but here I'm not going to

[18:51:28 - 18:51:32]
create the custom configuration what

[18:51:29 - 18:51:34]
I'll do I'll use the collab Enterprise

[18:51:32 - 18:51:36]
okay this one so it will give me Google

[18:51:34 - 18:51:39]
collab kinds of interface and there I

[18:51:36 - 18:51:41]
can um actually do my coding so after

[18:51:39 - 18:51:43]
clicking on collab Enterprise so here

[18:51:41 - 18:51:46]
you will get one option create a

[18:51:43 - 18:51:46]
notebook Okay so just create a

[18:51:47 - 18:51:51]
notebook you can also select the region

[18:51:49 - 18:51:53]
but I will keep the default region e

[18:51:51 - 18:51:55]
Central one okay that's it now you can

[18:51:53 - 18:52:01]
give the name I can rename this notebook

[18:51:55 - 18:52:02]
let's say I'll rename it as um vertex AI

[18:52:01 - 18:52:04]
demo okay you can give any name I've

[18:52:02 - 18:52:06]
given this name now if you want to

[18:52:04 - 18:52:08]
increase the size of the notebook if you

[18:52:06 - 18:52:10]
want to increase the size of the Cale

[18:52:08 - 18:52:12]
let's say if I write something so the

[18:52:10 - 18:52:15]
text is like very small

[18:52:12 - 18:52:16]
here so I can also so increase the size

[18:52:15 - 18:52:17]
so for this what I can do I can click on

[18:52:16 - 18:52:20]
the

[18:52:17 - 18:52:22]
settings uh just go to the

[18:52:20 - 18:52:25]
editor and here you'll see this font

[18:52:22 - 18:52:28]
size just try to make it as uh I can

[18:52:25 - 18:52:29]
take 28 okay 28 I think it is fine now

[18:52:28 - 18:52:31]
the next thing what you have to do guys

[18:52:29 - 18:52:33]
you have to connect this notebook so

[18:52:31 - 18:52:35]
let's click on the connect button see

[18:52:33 - 18:52:36]
guys once you will be connecting the

[18:52:35 - 18:52:37]
notebook it will give you this kinds of

[18:52:36 - 18:52:39]
popup screen that means you have to

[18:52:37 - 18:52:41]
select account okay like which account

[18:52:39 - 18:52:43]
you want to use so make sure whatever

[18:52:41 - 18:52:44]
actually account you are using for the

[18:52:43 - 18:52:46]
Google Cloud console that means is for

[18:52:44 - 18:52:48]
the vertic a that account you have to

[18:52:46 - 18:52:50]
select here so this is my Google Cloud

[18:52:48 - 18:52:53]
account I'll just try to

[18:52:50 - 18:52:54]
select now it is also asking for

[18:52:53 - 18:52:56]
password so let me give my password and

[18:52:54 - 18:52:58]
I'll click on

[18:52:56 - 18:53:00]
next so if you're doing for the first

[18:52:58 - 18:53:02]
time so it will give you this kinds of

[18:53:00 - 18:53:04]
authentication uh it's just a one time

[18:53:02 - 18:53:05]
authentication okay that's it so guys as

[18:53:04 - 18:53:07]
you can see my runtime is connected now

[18:53:05 - 18:53:09]
if I execute the cell if you want to

[18:53:07 - 18:53:11]
execute the cell just press shift and

[18:53:09 - 18:53:13]
enter the same thing the way actually

[18:53:11 - 18:53:14]
you execute any collab notebook you can

[18:53:13 - 18:53:16]
execute as a same now see I'm getting

[18:53:14 - 18:53:17]
the okay output now you can also

[18:53:16 - 18:53:19]
download this notebook so there is a

[18:53:17 - 18:53:21]
download button you can also download

[18:53:19 - 18:53:22]
The Notebook so first of all uh let's do

[18:53:21 - 18:53:24]
the coding after that you can also

[18:53:22 - 18:53:25]
download uh this notebook even I will

[18:53:24 - 18:53:28]
also share this notebook with you in the

[18:53:25 - 18:53:31]
resources section fine all right now see

[18:53:28 - 18:53:32]
here we'll be using actually verx okay

[18:53:31 - 18:53:34]
we'll be using verx services that means

[18:53:32 - 18:53:36]
we'll be using model Garden so from the

[18:53:34 - 18:53:37]
model Garden itself what we'll do we'll

[18:53:36 - 18:53:40]
try to access different different kinds

[18:53:37 - 18:53:41]
of foundation model got it and if I want

[18:53:40 - 18:53:43]
to use model guardan that means the

[18:53:41 - 18:53:45]
complete vertx I I have to install one

[18:53:43 - 18:53:47]
Library so you have install vertex AI

[18:53:45 - 18:53:49]
SDK for python because we'll be using

[18:53:47 - 18:53:51]
python code right and if you're using

[18:53:49 - 18:53:54]
python code you have to install this

[18:53:51 - 18:53:56]
Library so here I want to install the

[18:53:54 - 18:53:57]
upgraded version of the package and this

[18:53:56 - 18:53:59]
is the package name Google Cloud AI

[18:53:57 - 18:54:01]
platform got it if you want to use Vex a

[18:53:59 - 18:54:04]
you have to install this python package

[18:54:01 - 18:54:04]
now let me install

[18:54:16 - 18:54:19]
okay now after installing it will tell

[18:54:17 - 18:54:21]
you restart the runtime just click here

[18:54:19 - 18:54:23]
so it will automatically restart the run

[18:54:21 - 18:54:26]
time after that you just need to import

[18:54:23 - 18:54:28]
vertex AI okay just to test whether

[18:54:26 - 18:54:30]
everything is fine or

[18:54:28 - 18:54:33]
not now see if I

[18:54:30 - 18:54:35]
import it should work see it's working

[18:54:33 - 18:54:36]
fine there is no error fine now see

[18:54:35 - 18:54:38]
those who are running this code from the

[18:54:36 - 18:54:40]
collab notebook you just need to do uh

[18:54:38 - 18:54:42]
two configuration here so let me show

[18:54:40 - 18:54:45]
you so the first configuration you have

[18:54:42 - 18:54:46]
to do um this one that means you have to

[18:54:45 - 18:54:48]
authenticate with the Google Cloud first

[18:54:46 - 18:54:50]
of all so here let me write the code so

[18:54:48 - 18:54:52]
first of all you have to authenticate

[18:54:50 - 18:54:54]
with the Google Cloud okay from the um

[18:54:52 - 18:54:56]
collab notebook and for this you have to

[18:54:54 - 18:54:59]
execute this line of

[18:54:56 - 18:55:01]
code so here everything I'm running from

[18:54:59 - 18:55:03]
the vertex only that me I'm using collab

[18:55:01 - 18:55:05]
Enterprise from the verx a I don't need

[18:55:03 - 18:55:06]
to perform the authentication but if

[18:55:05 - 18:55:07]
you're running from the Google collab

[18:55:06 - 18:55:08]
that time you have to do the

[18:55:07 - 18:55:10]
authentication guys okay so let me show

[18:55:08 - 18:55:12]
you one example let's say if I want to

[18:55:10 - 18:55:14]
load any model uh from the collab

[18:55:12 - 18:55:16]
Enterprise that means if I'm using Tex a

[18:55:14 - 18:55:18]
services I don't need to authenticate it

[18:55:16 - 18:55:19]
I don't need to authenticate it I can

[18:55:18 - 18:55:21]
easily load it let me show you so for

[18:55:19 - 18:55:24]
this let's import some of the library

[18:55:21 - 18:55:25]
first so here I'm importing some of the

[18:55:24 - 18:55:27]
library you can see gen generation

[18:55:25 - 18:55:29]
config generative model okay I'll tell

[18:55:27 - 18:55:30]
you why I'm importing them and what is

[18:55:29 - 18:55:31]
the use of it first of all let me import

[18:55:30 - 18:55:34]
all of

[18:55:31 - 18:55:37]
them now let's say I want to load one

[18:55:34 - 18:55:40]
model let's say I want to load this gini

[18:55:37 - 18:55:45]
1 uh Z pro model so you can see there is

[18:55:40 - 18:55:47]
a model zmin 1 Point uh Z Pro just click

[18:55:45 - 18:55:48]
here uh if I click here you will see the

[18:55:47 - 18:55:51]
model ID you just need to copy the model

[18:55:48 - 18:55:53]
ID from here now if you just go below

[18:55:51 - 18:55:55]
they have already given the source

[18:55:53 - 18:55:58]
code here you can see this is the model

[18:55:55 - 18:55:59]
ID just try to copy copy this ID and try

[18:55:58 - 18:56:01]
to paste it here okay that's it now see

[18:55:59 - 18:56:03]
if I execute this code it will

[18:56:01 - 18:56:06]
automatically load the model see there

[18:56:03 - 18:56:07]
is no error but if you executing from

[18:56:06 - 18:56:09]
the collab notebook you will see you

[18:56:07 - 18:56:11]
will get one error that means your

[18:56:09 - 18:56:13]
notebook is not authenticated with the

[18:56:11 - 18:56:15]
Google Cloud okay so that's why you have

[18:56:13 - 18:56:16]
to execute this lineup code it will uh

[18:56:15 - 18:56:18]
what it will do it will authenticate

[18:56:16 - 18:56:20]
first of all it will ask for the email

[18:56:18 - 18:56:22]
address that means which email address

[18:56:20 - 18:56:23]
you are using for the Google Cloud

[18:56:22 - 18:56:25]
account that email address you have to

[18:56:23 - 18:56:27]
select first of all got it then the next

[18:56:25 - 18:56:30]
uh actually configuration code you have

[18:56:27 - 18:56:32]
to run this one let me show

[18:56:30 - 18:56:34]
you this one if you're using collab

[18:56:32 - 18:56:35]
Enterprise guys you don't need to

[18:56:34 - 18:56:37]
execute but if you're using Google

[18:56:35 - 18:56:38]
collab you have to execute now see this

[18:56:37 - 18:56:41]
is the code you have to execute so here

[18:56:38 - 18:56:43]
you have to pass the project ID as well

[18:56:41 - 18:56:45]
as your location okay that means region

[18:56:43 - 18:56:47]
now how you will get the project ID so

[18:56:45 - 18:56:49]
here you can see on top you have the

[18:56:47 - 18:56:52]
project ID just try to click here now

[18:56:49 - 18:56:53]
see I'm inside my first project so here

[18:56:52 - 18:56:56]
is the project ID just try to copy the

[18:56:53 - 18:56:58]
project ID and try to mention it here

[18:56:56 - 18:56:59]
okay in the uh in this box actually you

[18:56:58 - 18:57:01]
just need to paste it here then you have

[18:56:59 - 18:57:02]
to give the region name and what is your

[18:57:01 - 18:57:04]
region name you can see I'm inside us

[18:57:02 - 18:57:06]
Central one so try to mention us Central

[18:57:04 - 18:57:08]
one here okay then if you execute it

[18:57:06 - 18:57:11]
will automatically initialize with the

[18:57:08 - 18:57:12]
vertex a that means it will authenticate

[18:57:11 - 18:57:14]
with the vert.x a with your

[18:57:12 - 18:57:15]
configuration now it will get to know

[18:57:14 - 18:57:17]
okay now you are you are the correct

[18:57:15 - 18:57:19]
user so once it is authenticated then

[18:57:17 - 18:57:20]
you will be able to use all the services

[18:57:19 - 18:57:22]
from the vertx a that is all the

[18:57:20 - 18:57:23]
foundation model all the services you

[18:57:22 - 18:57:25]
can use got it so this two line actually

[18:57:23 - 18:57:28]
you have to execute if you're using

[18:57:25 - 18:57:29]
Google collab see collab only and if

[18:57:28 - 18:57:31]
you're using collab Enterprise no need

[18:57:29 - 18:57:34]
to execute guys okay you can run as it

[18:57:31 - 18:57:35]
is I hope it is clear now okay so now I

[18:57:34 - 18:57:37]
think you saw how we can load the model

[18:57:35 - 18:57:38]
to load the model you have to use one

[18:57:37 - 18:57:40]
function called generative model you can

[18:57:38 - 18:57:42]
see I already imported this generative

[18:57:40 - 18:57:44]
model from the vertex a preview.

[18:57:42 - 18:57:46]
generative a models now P generative

[18:57:44 - 18:57:47]
model inside that you just need to give

[18:57:46 - 18:57:49]
the model ID now if you want to use any

[18:57:47 - 18:57:52]
other model simply just try to open

[18:57:49 - 18:57:53]
let's say you want to use 1.5 pro model

[18:57:52 - 18:57:55]
so just click here okay so you can see

[18:57:53 - 18:57:59]
jini 1.5 pro model now just try to go

[18:57:55 - 18:58:01]
below and here is the model ID so try to

[18:57:59 - 18:58:03]
copy the model ID so this is the model

[18:58:01 - 18:58:05]
ID just try to copy and try to paste it

[18:58:03 - 18:58:06]
here so that's how if you want to use

[18:58:05 - 18:58:08]
any model from the model Garden just try

[18:58:06 - 18:58:09]
to copy the model ID and try to past it

[18:58:08 - 18:58:11]
inside this function it will

[18:58:09 - 18:58:13]
automatically load that model for you so

[18:58:11 - 18:58:16]
now let's uh test this model so here I'm

[18:58:13 - 18:58:19]
going to pass one prompt so here I have

[18:58:16 - 18:58:22]
already prepared one prompt let me show

[18:58:19 - 18:58:24]
you this is the prompt guys I have

[18:58:22 - 18:58:26]
prepared okay see so here I'm using the

[18:58:24 - 18:58:28]
model object and I'm calling one

[18:58:26 - 18:58:30]
function called generate undor content

[18:58:28 - 18:58:33]
inside that I'm passing the prompt why

[18:58:30 - 18:58:36]
is Sky uh so here is the prompt why is

[18:58:33 - 18:58:37]
the sky blue and stream is equal to True

[18:58:36 - 18:58:39]
why I have given stream as equal to true

[18:58:37 - 18:58:43]
because if I show you if I let's say

[18:58:39 - 18:58:45]
open the j j or chat chat GPT if you can

[18:58:43 - 18:58:47]
open anything let's say if I give this

[18:58:45 - 18:58:50]
same prompt here now so if I let's say

[18:58:47 - 18:58:51]
pass the same prompt I is the sky blue

[18:58:50 - 18:58:54]
any kind of prompt if you give it will

[18:58:51 - 18:58:55]
give you stream kinds of output see it's

[18:58:54 - 18:58:57]
not uh it's not actually onot output it

[18:58:55 - 18:58:59]
will give you stream output so I think

[18:58:57 - 18:59:01]
here you saw it will give you stream

[18:58:59 - 18:59:02]
output that means after one word it is

[18:59:01 - 18:59:03]
coming another word another word okay

[18:59:02 - 18:59:06]
that's how it is giving stream output

[18:59:03 - 18:59:08]
not in one shot so that's how we also

[18:59:06 - 18:59:09]
want to get the output from my response

[18:59:08 - 18:59:10]
okay that's why I've given this

[18:59:09 - 18:59:12]
parameter stream is equal to true that

[18:59:10 - 18:59:16]
means it will give you stream output got

[18:59:12 - 18:59:18]
it now see if I execute so here you will

[18:59:16 - 18:59:21]
get one response object see this is the

[18:59:18 - 18:59:23]
object okay so it would be a object see

[18:59:21 - 18:59:25]
this generator object now here I can

[18:59:23 - 18:59:26]
apply any kinds of iterator that means

[18:59:25 - 18:59:29]
looping and I can get the response now

[18:59:26 - 18:59:32]
let me show you so here you can apply

[18:59:29 - 18:59:34]
looping so here I'm applying looping for

[18:59:32 - 18:59:37]
response in responses and I just wanted

[18:59:34 - 18:59:38]
to print the text okay whatever text

[18:59:37 - 18:59:41]
actually I'm having from the response I

[18:59:38 - 18:59:44]
want to print it now so if I execute the

[18:59:41 - 18:59:45]
for Loop right now you will see the

[18:59:44 - 18:59:48]
response see this is the response

[18:59:45 - 18:59:49]
actually I got and this response is uh

[18:59:48 - 18:59:51]
actually short response that's why you

[18:59:49 - 18:59:53]
didn't saw the streaming output but if

[18:59:51 - 18:59:54]
it is generating bigger output you will

[18:59:53 - 18:59:56]
see the streaming output would be

[18:59:54 - 18:59:58]
visible got it now you can try with

[18:59:56 - 18:59:59]
different prompt let's try with another

[18:59:58 - 19:00:01]
prompt so I'll give another prompt here

[18:59:59 - 19:00:04]
let's say I'll give U uh what are the

[19:00:01 - 19:00:07]
latest developments in the auto uh

[19:00:04 - 19:00:09]
automotive industry okay now if I

[19:00:07 - 19:00:11]
execute so it should give me the

[19:00:09 - 19:00:12]
response okay see this is the staming

[19:00:11 - 19:00:14]
response I'm getting guys I think you

[19:00:12 - 19:00:17]
saw okay that this is called streaming

[19:00:14 - 19:00:19]
response see the complete response I got

[19:00:17 - 19:00:21]
great now see here I pass the prompt

[19:00:19 - 19:00:23]
directly okay in the generative uh

[19:00:21 - 19:00:24]
generate content function but if you

[19:00:23 - 19:00:27]
want to pass as a parameter you can also

[19:00:24 - 19:00:29]
do it for this Ive created another

[19:00:27 - 19:00:33]
example so this is the example

[19:00:29 - 19:00:34]
guys just a minute huh just see that so

[19:00:33 - 19:00:36]
here I created a variable called prompt

[19:00:34 - 19:00:37]
and inside that I've written The Prompt

[19:00:36 - 19:00:40]
let's say this is my complete prompt

[19:00:37 - 19:00:42]
create a numbered list of the 10 items

[19:00:40 - 19:00:44]
each item in the list should be a trend

[19:00:42 - 19:00:46]
in the take industry in Trend should be

[19:00:44 - 19:00:49]
a less than five wordss okay try uh now

[19:00:46 - 19:00:50]
you can give any kind of prom now here

[19:00:49 - 19:00:51]
what I'm doing I'm calling the model

[19:00:50 - 19:00:53]
object generate content inside that I'm

[19:00:51 - 19:00:54]
giving the prompt okay whatever prompt

[19:00:53 - 19:00:55]
actually I have defined stream is equal

[19:00:54 - 19:00:58]
to two then again I'm performing the

[19:00:55 - 19:01:00]
looping operation now see if I execute

[19:00:58 - 19:01:03]
it should give me the

[19:01:00 - 19:01:08]
output okay now you can also customize

[19:01:03 - 19:01:08]
the prompt let's say here I can give uh

[19:01:09 - 19:01:14]
translate in Hindi

[19:01:15 - 19:01:19]
see I'm also getting the Hindi

[19:01:17 - 19:01:20]
translation as well got it so that's how

[19:01:19 - 19:01:22]
you can also customize your prompt it's

[19:01:20 - 19:01:25]
up to you now I think you remember

[19:01:22 - 19:01:28]
whenever I was uh like going through the

[19:01:25 - 19:01:30]
model Garden so I can also open this

[19:01:28 - 19:01:32]
model in a vertic a studio I think I

[19:01:30 - 19:01:34]
showed you so let's open this model in

[19:01:32 - 19:01:36]
the verx a studio see if you open the

[19:01:34 - 19:01:38]
verx a studio right hand side you can

[19:01:36 - 19:01:40]
see you can also set some of the model

[19:01:38 - 19:01:41]
parameter like temperature output token

[19:01:40 - 19:01:44]
okay so these are the thing you can also

[19:01:41 - 19:01:45]
change so how we can change with of

[19:01:44 - 19:01:47]
python code because as a developer we

[19:01:45 - 19:01:49]
have to use with the help of python code

[19:01:47 - 19:01:50]
not from the UI interface got it from

[19:01:49 - 19:01:52]
the UI interface also you can use the

[19:01:50 - 19:01:54]
model but as a developer we have to use

[19:01:52 - 19:01:56]
from the python SDK so here we can also

[19:01:54 - 19:01:58]
set the model configuration so let me

[19:01:56 - 19:02:00]
show you so for this you have to use

[19:01:58 - 19:02:03]
this function actually so I think you

[19:02:00 - 19:02:05]
remember the generation config okay so

[19:02:03 - 19:02:06]
let me show you so I already prepared

[19:02:05 - 19:02:08]
see in that generation config I'm

[19:02:06 - 19:02:11]
passing all the parameter okay let me

[19:02:08 - 19:02:13]
the temperature top P top K candidate

[19:02:11 - 19:02:14]
okay Max output and so on and I think

[19:02:13 - 19:02:15]
you already know this the parameter I

[19:02:14 - 19:02:17]
already explained previously what is

[19:02:15 - 19:02:19]
temperature what is top b top K got it

[19:02:17 - 19:02:20]
here temperature means here you are

[19:02:19 - 19:02:22]
assigning the model creativity like how

[19:02:20 - 19:02:23]
much creativity you want from the model

[19:02:22 - 19:02:25]
if it is close to one that means it will

[19:02:23 - 19:02:27]
take risk it will be more creative if it

[19:02:25 - 19:02:29]
is close to zero it won't be taking any

[19:02:27 - 19:02:30]
kinds of risk okay that's the idea now

[19:02:29 - 19:02:32]
this generation config you have to pass

[19:02:30 - 19:02:33]
as a parameter of generation config here

[19:02:32 - 19:02:35]
here you can see generation config is

[19:02:33 - 19:02:37]
equal to generation config and the same

[19:02:35 - 19:02:38]
prompt I have given stream is equal to

[19:02:37 - 19:02:41]
two again I'm loing through the response

[19:02:38 - 19:02:43]
now if I show you I'll see that your uh

[19:02:41 - 19:02:44]
output would be more creative okay so

[19:02:43 - 19:02:46]
previously I think you remember we we

[19:02:44 - 19:02:48]
got actually uh very short output now

[19:02:46 - 19:02:50]
see this output is more creative right

[19:02:48 - 19:02:52]
now because we given the uh

[19:02:50 - 19:02:53]
configuration model parameter right now

[19:02:52 - 19:02:56]
okay I hope it is clear now let me show

[19:02:53 - 19:02:58]
you another thing you can do this is

[19:02:56 - 19:03:00]
called actually test chat prompt now

[19:02:58 - 19:03:01]
what is test chat prompt let me show you

[19:03:00 - 19:03:04]
one example let's say here I ask one

[19:03:01 - 19:03:07]
question why is the sky blue okay now

[19:03:04 - 19:03:08]
this promt actually have given and my J

[19:03:07 - 19:03:10]
will try to remember this prompt now if

[19:03:08 - 19:03:12]
I ask give

[19:03:10 - 19:03:14]
me the

[19:03:12 - 19:03:17]
answer

[19:03:14 - 19:03:20]
in bullet

[19:03:17 - 19:03:23]
point okay now see here I haven't

[19:03:20 - 19:03:25]
mentioned I want the this answer I just

[19:03:23 - 19:03:26]
given give me the answer in bullet point

[19:03:25 - 19:03:28]
it will automatically remember my

[19:03:26 - 19:03:30]
previous let's say context okay that

[19:03:28 - 19:03:31]
means I want to ask this particular

[19:03:30 - 19:03:33]
response now see it has given me in the

[19:03:31 - 19:03:35]
bullet point okay so this is called

[19:03:33 - 19:03:37]
actually memory that means it is trying

[19:03:35 - 19:03:38]
to remember the chat history so that

[19:03:37 - 19:03:41]
thing you can also perform here so let

[19:03:38 - 19:03:44]
me show you so for this you have to use

[19:03:41 - 19:03:47]
one more line here this the line guys

[19:03:44 - 19:03:49]
model. start chat so this start chat

[19:03:47 - 19:03:50]
will automatically remember all the

[19:03:49 - 19:03:52]
conversation you are doing with your

[19:03:50 - 19:03:53]
large language model now this is the

[19:03:52 - 19:03:56]
prompt actually I've have given my name

[19:03:53 - 19:03:58]
is buy you are my personal assistant my

[19:03:56 - 19:04:01]
favorite movies are the lord of rings

[19:03:58 - 19:04:03]
and Hobbit suggest another movie I might

[19:04:01 - 19:04:04]
like so this is the prompt I'm giving

[19:04:03 - 19:04:06]
and this is the stream is equal to two

[19:04:04 - 19:04:09]
I'm giving and now see if you're using

[19:04:06 - 19:04:12]
chat that time you have to use chat.

[19:04:09 - 19:04:13]
send message okay chat. send message

[19:04:12 - 19:04:15]
because here you have initialized the

[19:04:13 - 19:04:17]
model you remember now see if I execute

[19:04:15 - 19:04:20]
the program so guys as you can see I got

[19:04:17 - 19:04:22]
the output okay now what I will do now

[19:04:20 - 19:04:24]
what I will do based on this answer I

[19:04:22 - 19:04:26]
will ask another question so because it

[19:04:24 - 19:04:29]
has remembered my previous context H so

[19:04:26 - 19:04:31]
here now asking are my favorite movies

[19:04:29 - 19:04:32]
based on uh a book series this is the

[19:04:31 - 19:04:35]
this is what actually I'm asking now see

[19:04:32 - 19:04:38]
if I ask this question see it will refer

[19:04:35 - 19:04:40]
my previous actually context yeah you

[19:04:38 - 19:04:42]
can see both uh the lord of rings and

[19:04:40 - 19:04:46]
The Hobbit trilogies are the based on

[19:04:42 - 19:04:50]
the book series okay by JRR to tolken

[19:04:46 - 19:04:51]
okay now I can show you the story so if

[19:04:50 - 19:04:52]
you want to see the story just write

[19:04:51 - 19:04:53]
chat. history so it will show you the

[19:04:52 - 19:04:57]
entire

[19:04:53 - 19:04:59]
history see so first of all you ask this

[19:04:57 - 19:05:00]
prompt your model has given this answer

[19:04:59 - 19:05:02]
then again you ask this question your

[19:05:00 - 19:05:04]
model has given this answer got it I

[19:05:02 - 19:05:06]
hope it is clear fine so that's how

[19:05:04 - 19:05:08]
actually we can use any kind of language

[19:05:06 - 19:05:09]
model now let's try to see uh any

[19:05:08 - 19:05:11]
multimodel that means we'll be also

[19:05:09 - 19:05:13]
using some visual model so I think you

[19:05:11 - 19:05:15]
know U here actually we are also having

[19:05:13 - 19:05:16]
some Vision model as well so this is my

[19:05:15 - 19:05:17]
model garden now just click on the

[19:05:16 - 19:05:18]
vision model you'll see there are

[19:05:17 - 19:05:20]
different different kinds of vision

[19:05:18 - 19:05:23]
model are available so from here I'm

[19:05:20 - 19:05:26]
going to use One Vision model so Jin 1

[19:05:23 - 19:05:28]
Point Pro Vision model so you can search

[19:05:26 - 19:05:30]
this model here now if you want to load

[19:05:28 - 19:05:32]
this model you can load like that this

[19:05:30 - 19:05:34]
is the model ID so let me show you this

[19:05:32 - 19:05:36]
model I'll copy the name and in the

[19:05:34 - 19:05:39]
model Garden so here you can sech this

[19:05:36 - 19:05:40]
model you will see J 1.0 Pro Vision

[19:05:39 - 19:05:42]
model okay now see this is the visual

[19:05:40 - 19:05:45]
model so with this model actually you

[19:05:42 - 19:05:47]
can also work with the images and videos

[19:05:45 - 19:05:49]
okay now this is the model ID you have

[19:05:47 - 19:05:52]
to give now I have given the model ID

[19:05:49 - 19:05:54]
now let's load the model fine now here

[19:05:52 - 19:05:56]
I'll be working with images and videos

[19:05:54 - 19:05:57]
and to work with images videos I need

[19:05:56 - 19:05:59]
some helper function this that means

[19:05:57 - 19:06:01]
this helper function will help me to

[19:05:59 - 19:06:02]
load the image visualize the image okay

[19:06:01 - 19:06:04]
so here I have created some helper

[19:06:02 - 19:06:05]
function let me show you so these are

[19:06:04 - 19:06:07]
the helper function I created you can

[19:06:05 - 19:06:10]
see different different helper function

[19:06:07 - 19:06:12]
I created uh display image so it will

[19:06:10 - 19:06:14]
display the image if you want to get any

[19:06:12 - 19:06:16]
image as a bytes from from the URL you

[19:06:14 - 19:06:17]
can get uh with help of this function

[19:06:16 - 19:06:20]
load image from the URL you can use this

[19:06:17 - 19:06:22]
function get URL from the GCS you can

[19:06:20 - 19:06:24]
use this function print multimodel

[19:06:22 - 19:06:25]
prompt that means if you want to print

[19:06:24 - 19:06:26]
any multimodel prompt you can use this

[19:06:25 - 19:06:28]
function okay so that's how we can

[19:06:26 - 19:06:30]
create some utility function and this

[19:06:28 - 19:06:31]
function you will get over the internet

[19:06:30 - 19:06:33]
if you just simply search how to display

[19:06:31 - 19:06:35]
image give me a function you will get

[19:06:33 - 19:06:36]
these kinds of cod okay so I have

[19:06:35 - 19:06:39]
initialized these are the utility

[19:06:36 - 19:06:41]
related function as of now okay so here

[19:06:39 - 19:06:43]
the first thing I'm going to show you uh

[19:06:41 - 19:06:46]
how to generate actually caption from

[19:06:43 - 19:06:47]
any image is okay so for this uh let's

[19:06:46 - 19:06:50]
see one

[19:06:47 - 19:06:52]
example this is the example guys so here

[19:06:50 - 19:06:55]
I'm downloading my image you can see

[19:06:52 - 19:06:57]
this is the image uh

[19:06:55 - 19:07:00]
URL so so guys you can see this is the

[19:06:57 - 19:07:03]
image okay this image actually will be

[19:07:00 - 19:07:04]
downloading so here let me show you and

[19:07:03 - 19:07:07]
how we are downloading the image we're

[19:07:04 - 19:07:08]
using U GS util command okay so if you

[19:07:07 - 19:07:10]
execute this command it will download

[19:07:08 - 19:07:12]
the image from the URL then I'm loading

[19:07:10 - 19:07:14]
the image then I'm giving a prompt

[19:07:12 - 19:07:15]
describe this image okay I'm passing the

[19:07:14 - 19:07:17]
image as well as the prompt then I'm

[19:07:15 - 19:07:19]
using the multi model that means the

[19:07:17 - 19:07:22]
model we have loaded I think remember

[19:07:19 - 19:07:24]
this uh gini 1 Point U zero Pro Vision

[19:07:22 - 19:07:26]
model okay you can also use any other

[19:07:24 - 19:07:28]
Vision model so simply go to the model

[19:07:26 - 19:07:30]
garden and try to choose any other

[19:07:28 - 19:07:34]
Vision model you can use as it is okay

[19:07:30 - 19:07:36]
now let's get back now whatever actually

[19:07:34 - 19:07:37]
let's say output I'm getting I'm just

[19:07:36 - 19:07:40]
rendering okay that's it now let me show

[19:07:37 - 19:07:40]
you

[19:07:45 - 19:07:49]
so guys as you can see this is my

[19:07:46 - 19:07:50]
results I got so here I given a prompt

[19:07:49 - 19:07:53]
and this is the image now it has given

[19:07:50 - 19:07:56]
me the caption so the image shown a gray

[19:07:53 - 19:08:00]
cat with black strips working uh in the

[19:07:56 - 19:08:01]
snow the cat has yellow eyes and long

[19:08:00 - 19:08:04]
tail you can see yellow eyes and long

[19:08:01 - 19:08:06]
tail cat is working towards the camera

[19:08:04 - 19:08:08]
okay that means this is a great caption

[19:08:06 - 19:08:11]
my model has given me now let me show

[19:08:08 - 19:08:12]
you another example so I prepared

[19:08:11 - 19:08:15]
another

[19:08:12 - 19:08:19]
example H so guys you can see I'm using

[19:08:15 - 19:08:22]
another image now if I show you this

[19:08:19 - 19:08:24]
example see this is my uh prompt I have

[19:08:22 - 19:08:26]
given describ the image that means

[19:08:24 - 19:08:27]
describ the scene now see this is the

[19:08:26 - 19:08:32]
response I got now this is the response

[19:08:27 - 19:08:33]
to ponon boats are anded in the charless

[19:08:32 - 19:08:36]
river in

[19:08:33 - 19:08:39]
Boston in the background are two Breeze

[19:08:36 - 19:08:41]
and Boston skyline so guys as you can

[19:08:39 - 19:08:43]
see this is a correct caption my model

[19:08:41 - 19:08:45]
has given me okay now if you're use load

[19:08:43 - 19:08:48]
image function that means the function

[19:08:45 - 19:08:50]
we created in the utility function uh to

[19:08:48 - 19:08:52]
load this image URL you can use this

[19:08:50 - 19:08:53]
load image URL function as well and with

[19:08:52 - 19:08:55]
the help of that we can also do the same

[19:08:53 - 19:08:56]
thing okay there are different different

[19:08:55 - 19:08:58]
technique you can load the image you can

[19:08:56 - 19:08:59]
also use open CB to load the image okay

[19:08:58 - 19:09:02]
it's completely fine now see I'm getting

[19:08:59 - 19:09:04]
the same output now here we'll be

[19:09:02 - 19:09:05]
learning another thing here we'll be

[19:09:04 - 19:09:08]
combining

[19:09:05 - 19:09:09]
multiple uh multiple image and text

[19:09:08 - 19:09:11]
promp for the F shot prompting that

[19:09:09 - 19:09:14]
means here I'll be passing the F shot to

[19:09:11 - 19:09:16]
my model and my model will try to give

[19:09:14 - 19:09:18]
me the response so let me show you one

[19:09:16 - 19:09:19]
example I prepared so this is the

[19:09:18 - 19:09:22]
example guys so here I'm using three

[19:09:19 - 19:09:23]
image so let me open all the image so

[19:09:22 - 19:09:24]
this is stored in the Google Cloud

[19:09:23 - 19:09:26]
Storage okay you can see this is another

[19:09:24 - 19:09:28]
image so you can see this is one of the

[19:09:26 - 19:09:29]
image this is another image and this is

[19:09:28 - 19:09:31]
another image so this three image

[19:09:29 - 19:09:34]
actually I'm using here and with the

[19:09:31 - 19:09:36]
help of load image from URL I'm loading

[19:09:34 - 19:09:38]
both three images then first of all I'm

[19:09:36 - 19:09:39]
giving the prompt for two images you can

[19:09:38 - 19:09:42]
see this two images I'm giving the

[19:09:39 - 19:09:44]
prompt this one and this one this one

[19:09:42 - 19:09:45]
I'm not giving any kinds of prompt okay

[19:09:44 - 19:09:47]
you can see I've given city is equal to

[19:09:45 - 19:09:50]
London because you can see this is a

[19:09:47 - 19:09:52]
London city and the landmark is a big b

[19:09:50 - 19:09:54]
okay it's a big ban so you can search on

[19:09:52 - 19:09:56]
Google big ban I think yeah see this is

[19:09:54 - 19:09:57]
the big ban okay so that's why I'm

[19:09:56 - 19:09:59]
giving some prompting that means I'm

[19:09:57 - 19:10:01]
giving the label okay now promp two the

[19:09:59 - 19:10:04]
second image I'm giving this is the

[19:10:01 - 19:10:06]
Paris city city is equal to Paris and

[19:10:04 - 19:10:08]
landmark you can see it's iffel Tower

[19:10:06 - 19:10:10]
okay you can see it's I to and the third

[19:10:08 - 19:10:11]
image I'm not giving any kinds of prompt

[19:10:10 - 19:10:15]
now let's try to see my model is able to

[19:10:11 - 19:10:17]
generate the actual uh let say promt for

[19:10:15 - 19:10:18]
that particular image or not so here you

[19:10:17 - 19:10:20]
can see I'm passing my image one prompt

[19:10:18 - 19:10:21]
one image two prompt two and I'm only

[19:10:20 - 19:10:23]
giving the image three here not the

[19:10:21 - 19:10:25]
prompt now I'm using the multimodel and

[19:10:23 - 19:10:27]
generate content now let's try to see

[19:10:25 - 19:10:31]
whether it is able to uh identify that

[19:10:27 - 19:10:33]
image or not see uh this two actually I

[19:10:31 - 19:10:37]
have given it's fine now see third one

[19:10:33 - 19:10:39]
city roome Landmark uh kosm okay so let

[19:10:37 - 19:10:42]
me copy and let me try to

[19:10:39 - 19:10:45]
verify uh see correct it's the correct

[19:10:42 - 19:10:48]
one okay so beautifully my model is able

[19:10:45 - 19:10:50]
to generate the response so this is

[19:10:48 - 19:10:52]
called actually few shot prompting now

[19:10:50 - 19:10:54]
also let's try to see some video example

[19:10:52 - 19:10:57]
so what I will do I'll download one

[19:10:54 - 19:10:59]
video so this is the URL of the video

[19:10:57 - 19:11:01]
I'll download this video let me download

[19:10:59 - 19:11:03]
and let me show you here so I think you

[19:11:01 - 19:11:05]
remember Google has launched one phone

[19:11:03 - 19:11:09]
actually called pixel okay you can see

[19:11:05 - 19:11:10]
this the pixel this is the pixel advice

[19:11:09 - 19:11:12]
advertisement you can see this is the

[19:11:10 - 19:11:14]
pixel advertisement okay so this video

[19:11:12 - 19:11:16]
actually have loed from the URL now I

[19:11:14 - 19:11:17]
will give this video to my multimodel

[19:11:16 - 19:11:19]
and I will give some prompt let me show

[19:11:17 - 19:11:21]
you so I already prepared one prompt

[19:11:19 - 19:11:23]
this is the prompt answer the following

[19:11:21 - 19:11:26]
questions using the video only what is

[19:11:23 - 19:11:27]
the profession of the main person what

[19:11:26 - 19:11:30]
are the main features of the phone

[19:11:27 - 19:11:32]
highlighted which uh CT was this

[19:11:30 - 19:11:34]
recorded in provide the answer in the

[19:11:32 - 19:11:37]
Jon format now see if I give this view

[19:11:34 - 19:11:38]
uh video and if I give pass it to my

[19:11:37 - 19:11:41]
multimodel it should give me the

[19:11:38 - 19:11:41]
response

[19:11:45 - 19:11:50]
see guys I got the response now you can

[19:11:46 - 19:11:52]
see the person name is sha shim shimada

[19:11:50 - 19:11:54]
profession is a photographer brand is

[19:11:52 - 19:11:58]
Google phone brand is Google model is

[19:11:54 - 19:12:02]
pixel 8 and uh and you can see the

[19:11:58 - 19:12:05]
features video boost night sight City

[19:12:02 - 19:12:06]
Tokyo country Japan amazing okay amazing

[19:12:05 - 19:12:08]
actually response I got now you can use

[19:12:06 - 19:12:11]
any kinds of video you can do the

[19:12:08 - 19:12:12]
caption generation got it so that's how

[19:12:11 - 19:12:15]
guys you can export different different

[19:12:12 - 19:12:17]
kinds of mod model in the uh model

[19:12:15 - 19:12:19]
Garden it's not like only Google model

[19:12:17 - 19:12:21]
you can also let's say use meta model as

[19:12:19 - 19:12:22]
well let's say you want to use Lama

[19:12:21 - 19:12:24]
model just simply click on the llama and

[19:12:22 - 19:12:26]
try to open this notebook so they have

[19:12:24 - 19:12:27]
already given the all the code example

[19:12:26 - 19:12:29]
and everything okay only just you need

[19:12:27 - 19:12:31]
to execute and you have to see how we

[19:12:29 - 19:12:33]
can access the Lama model and all got it

[19:12:31 - 19:12:36]
so just try to explore guys uh this is

[19:12:33 - 19:12:38]
uh up to you because because all the

[19:12:36 - 19:12:40]
model I can't show you so I have just

[19:12:38 - 19:12:41]
given the demo like how we can access

[19:12:40 - 19:12:44]
different different kinds of foundation

[19:12:41 - 19:12:46]
model now you'll be exploring whatever

[19:12:44 - 19:12:48]
model actually you need later on got it

[19:12:46 - 19:12:49]
okay and one thing guys after

[19:12:48 - 19:12:52]
implementing all the code what you can

[19:12:49 - 19:12:54]
do you can download uh this notebook and

[19:12:52 - 19:12:56]
after that you can delete this instance

[19:12:54 - 19:12:58]
okay no need to keep on running just try

[19:12:56 - 19:12:59]
to delete the instance other way you can

[19:12:58 - 19:13:01]
you can also stop the instance but I

[19:12:59 - 19:13:03]
will try to delete it okay I'll just try

[19:13:01 - 19:13:04]
to do the confirmation so after some

[19:13:03 - 19:13:05]
time actually you'll see that this

[19:13:04 - 19:13:08]
notebook would be deleted okay now see

[19:13:05 - 19:13:11]
this deleted so yes uh this is the

[19:13:08 - 19:13:12]
actually Hands-On part of this vertex AI

[19:13:11 - 19:13:14]
so in the next video we'll try to see

[19:13:12 - 19:13:17]
how we can uh do the set up everything

[19:13:14 - 19:13:19]
on our let's say local machine that

[19:13:17 - 19:13:20]
means uh how we can connect this vertx

[19:13:19 - 19:13:22]
with the help of local machine that

[19:13:20 - 19:13:24]
means uh we'll be coding everything in

[19:13:22 - 19:13:27]
our vs code from the vs code itself

[19:13:24 - 19:13:29]
we'll try to access the uh like verx a

[19:13:27 - 19:13:31]
model that means Foundation model okay

[19:13:29 - 19:13:33]
so we'll try to access the model Garden

[19:13:31 - 19:13:35]
from the vs code so for this whatever

[19:13:33 - 19:13:37]
setup actually required I'll tell you

[19:13:35 - 19:13:39]
each and everything see how we can uh

[19:13:37 - 19:13:42]
use this vertex AI from our local

[19:13:39 - 19:13:43]
machine that means we'll be uh doing the

[19:13:42 - 19:13:45]
setup everything in our our local so

[19:13:43 - 19:13:46]
previously I showed you how we can use

[19:13:45 - 19:13:49]
collab Enterprise that means everything

[19:13:46 - 19:13:52]
I was performing in the gcloud but uh in

[19:13:49 - 19:13:53]
this video I'll try to use my vs code

[19:13:52 - 19:13:55]
and to access this vertx a what are the

[19:13:53 - 19:13:56]
configuration we have to perform we'll

[19:13:55 - 19:13:58]
be learning each and everything because

[19:13:56 - 19:13:59]
see going forward whenever you will be

[19:13:58 - 19:14:02]
implementing projects Right End to End

[19:13:59 - 19:14:03]
projects so you have to implement

[19:14:02 - 19:14:05]
through the vs code right and if you

[19:14:03 - 19:14:07]
want to implement through the vs code

[19:14:05 - 19:14:10]
you have to know how to configure this

[19:14:07 - 19:14:11]
verx AI in your local machine okay so

[19:14:10 - 19:14:13]
that's why it's super important to know

[19:14:11 - 19:14:16]
how we can set up everything in our

[19:14:13 - 19:14:18]
local machine itself so for this guys uh

[19:14:16 - 19:14:20]
you need one tool actually so the tool

[19:14:18 - 19:14:23]
name is

[19:14:20 - 19:14:25]
gcp uh CLI okay gcp CLI install just

[19:14:23 - 19:14:27]
search gcp CLI install on the Google so

[19:14:25 - 19:14:29]
after searching this gcp CLI install if

[19:14:27 - 19:14:32]
you just go below you'll see this link

[19:14:29 - 19:14:34]
actually install the gcloud CLI so just

[19:14:32 - 19:14:37]
try to open it

[19:14:34 - 19:14:39]
up mhm now here you will get the

[19:14:37 - 19:14:40]
installer see download the installer so

[19:14:39 - 19:14:42]
I'll click on the link so it will

[19:14:40 - 19:14:44]
automatically start downloading this CLI

[19:14:42 - 19:14:46]
for me see it has downloaded okay and if

[19:14:44 - 19:14:50]
you're using any other operating system

[19:14:46 - 19:14:51]
like say Linux then Debian Red Hat sento

[19:14:50 - 19:14:54]
Mac voice okay all the command is

[19:14:51 - 19:14:56]
already written here you can follow the

[19:14:54 - 19:14:58]
command and you can install this gcloud

[19:14:56 - 19:15:00]
CLI in your system because with the help

[19:14:58 - 19:15:02]
of this gcloud CLI will be doing the

[19:15:00 - 19:15:04]
authentication with our account okay

[19:15:02 - 19:15:05]
that is the thing now I have already

[19:15:04 - 19:15:07]
downloaded it now what you have to do

[19:15:05 - 19:15:09]
just double click and try to install so

[19:15:07 - 19:15:10]
the way actually you install any kinds

[19:15:09 - 19:15:12]
of normal software you have to follow

[19:15:10 - 19:15:14]
the same step okay there is nothing new

[19:15:12 - 19:15:16]
so for me I already installed see after

[19:15:14 - 19:15:18]
installing just search for

[19:15:16 - 19:15:20]
Google so you'll see this Google uh

[19:15:18 - 19:15:22]
Cloud SDK shell just try to open it up

[19:15:20 - 19:15:23]
so we will see this kinds of window okay

[19:15:22 - 19:15:24]
if you are getting this kinds of window

[19:15:23 - 19:15:27]
that means you have installed

[19:15:24 - 19:15:29]
successfully okay now let me close it

[19:15:27 - 19:15:31]
now what I will do guys I will open up

[19:15:29 - 19:15:34]
my local folder and here I'm going to

[19:15:31 - 19:15:36]
open up my um

[19:15:34 - 19:15:38]
terminal you can open up your any kinds

[19:15:36 - 19:15:41]
of terminal whether your anagon terminal

[19:15:38 - 19:15:44]
GB terminal anything now let's also open

[19:15:41 - 19:15:45]
up my vs code here all right so here the

[19:15:44 - 19:15:47]
first thing what you have to do guys you

[19:15:45 - 19:15:48]
have to create one virtual environment

[19:15:47 - 19:15:50]
after that you have to install all the

[19:15:48 - 19:15:53]
required packet okay then after that

[19:15:50 - 19:15:54]
we'll be writing our actually code okay

[19:15:53 - 19:15:56]
with the help of vertic C so to create

[19:15:54 - 19:16:00]
the environment you can execute this

[19:15:56 - 19:16:02]
command so cond create typen in let's

[19:16:00 - 19:16:06]
say uh vertex

[19:16:02 - 19:16:08]
AI verx a demo python is equal to let's

[19:16:06 - 19:16:10]
say I'll take

[19:16:08 - 19:16:13]
3.10 ien y now let's create the

[19:16:10 - 19:16:13]
environment

[19:16:15 - 19:16:18]
okay it's done now let's clear uh before

[19:16:17 - 19:16:19]
clearing I have to activate the

[19:16:18 - 19:16:24]
environment so this is the command let's

[19:16:19 - 19:16:25]
try to copy and try to execute it here H

[19:16:24 - 19:16:28]
now let's create a file called

[19:16:25 - 19:16:30]
requirement. txt so I'll just create

[19:16:28 - 19:16:34]
this file

[19:16:30 - 19:16:35]
requirements. dxt inside that I will

[19:16:34 - 19:16:37]
mention all the requirements I need so

[19:16:35 - 19:16:38]
these are the requirements guys I need I

[19:16:37 - 19:16:40]
think you remember so I think you

[19:16:38 - 19:16:42]
remember to use the vertx a we have to

[19:16:40 - 19:16:43]
install this package Google Cloud AI

[19:16:42 - 19:16:45]
platform I think in the collab

[19:16:43 - 19:16:47]
Enterprise also did the same thing then

[19:16:45 - 19:16:49]
stream lead I want to use because I want

[19:16:47 - 19:16:51]
to create a simple user interface uh

[19:16:49 - 19:16:53]
there actually you can give a prompt and

[19:16:51 - 19:16:55]
you can get the response and python.

[19:16:53 - 19:16:57]
because I'm going to manage my gcp

[19:16:55 - 19:17:01]
credential okay that's why now here let

[19:16:57 - 19:17:04]
me create this file as well so do EnV

[19:17:01 - 19:17:06]
okay inside EnV you need actually your

[19:17:04 - 19:17:09]
project

[19:17:06 - 19:17:10]
ID okay then you need region I'll tell

[19:17:09 - 19:17:12]
you how to collect this project and

[19:17:10 - 19:17:15]
region but before that let's do the

[19:17:12 - 19:17:16]
configuration okay without gcloud so

[19:17:15 - 19:17:19]
first of all let's me install all the

[19:17:16 - 19:17:21]
requirements so I'll just write P

[19:17:19 - 19:17:24]
install ien our

[19:17:21 - 19:17:24]
requirement.

[19:17:31 - 19:17:36]
dxt all right so installation is

[19:17:33 - 19:17:39]
completed now let's do the configuration

[19:17:36 - 19:17:41]
uh with our gcloud so for this uh you

[19:17:39 - 19:17:43]
have to execute this command called

[19:17:41 - 19:17:45]
gcloud

[19:17:43 - 19:17:47]
in it okay just try to execute this

[19:17:45 - 19:17:48]
command guys so if I execute this

[19:17:47 - 19:17:50]
command you will see that see if you're

[19:17:48 - 19:17:52]
doing it for the first time you will get

[19:17:50 - 19:17:53]
this kinds of window you must log in to

[19:17:52 - 19:17:55]
continue would you like to log in I'll

[19:17:53 - 19:17:55]
give

[19:17:56 - 19:17:59]
yes so guys now here you have to select

[19:17:58 - 19:18:01]
the account the account actually you are

[19:17:59 - 19:18:04]
using for your gcloud account so this is

[19:18:01 - 19:18:04]
my account I

[19:18:04 - 19:18:09]
select now you have to provide the

[19:18:06 - 19:18:12]
password so this is my password and I

[19:18:09 - 19:18:13]
try to do the next operation okay then

[19:18:12 - 19:18:16]
click on the

[19:18:13 - 19:18:16]
continue and

[19:18:18 - 19:18:24]
allow okay now you can see uh I'm done

[19:18:22 - 19:18:27]
with the authentication now if I come

[19:18:24 - 19:18:29]
back uh see now actually I'm getting my

[19:18:27 - 19:18:32]
project ID you can see I'm getting my

[19:18:29 - 19:18:34]
project ID got it so let me show you if

[19:18:32 - 19:18:37]
I go to my dashboard now if I click here

[19:18:34 - 19:18:39]
this is my project ID uh studos uh

[19:18:37 - 19:18:43]
loader

[19:18:39 - 19:18:46]
4361 I think you can see that uh Studio

[19:18:43 - 19:18:48]
loader 43 61 and2 okay so this is my

[19:18:46 - 19:18:49]
project IDE yeah now if you already have

[19:18:48 - 19:18:51]
one existing project you can select it

[19:18:49 - 19:18:52]
either you can create a new project so

[19:18:51 - 19:18:55]
for me I already have the projects I'll

[19:18:52 - 19:18:59]
just select the one I'll select the one

[19:18:55 - 19:18:59]
that means my uh existing

[19:18:59 - 19:19:03]
project now it is asking for do you want

[19:19:01 - 19:19:05]
to configure a default compute region

[19:19:03 - 19:19:07]
and zone I'll give

[19:19:05 - 19:19:09]
yes now it is telling which region you

[19:19:07 - 19:19:11]
actually want to take so what I will do

[19:19:09 - 19:19:14]
I'll take this region actually so

[19:19:11 - 19:19:19]
Central us so let's say I will take this

[19:19:14 - 19:19:19]
one US Central 1 C so I'll give seven

[19:19:21 - 19:19:27]
here okay now I think it is done now let

[19:19:24 - 19:19:30]
me clear my terminal okay so everything

[19:19:27 - 19:19:35]
is set now let's uh create one file here

[19:19:30 - 19:19:36]
called main. by inside that I'm going to

[19:19:35 - 19:19:39]
write all of the code okay that means we

[19:19:36 - 19:19:41]
will be trying to access one that means

[19:19:39 - 19:19:44]
here we'll be trying to access one um

[19:19:41 - 19:19:46]
model from the model Garden but before

[19:19:44 - 19:19:48]
that you have to set this EnV so you

[19:19:46 - 19:19:49]
have to give the project ID so here is

[19:19:48 - 19:19:51]
the project ID guys I think I showed you

[19:19:49 - 19:19:54]
how to get the project ID this is the

[19:19:51 - 19:19:55]
project ID just try to copy and here try

[19:19:54 - 19:19:57]
to

[19:19:55 - 19:19:59]
pens then you have to give the region so

[19:19:57 - 19:20:01]
I think region I already showed you so

[19:19:59 - 19:20:03]
here you can check the region click on

[19:20:01 - 19:20:06]
the collab Enterprise left hand side you

[19:20:03 - 19:20:10]
can see us ipen Central one just try to

[19:20:06 - 19:20:13]
select it us ipen

[19:20:10 - 19:20:18]
Central one okay now just try to verify

[19:20:13 - 19:20:18]
T Central H uh one

[19:20:18 - 19:20:23]
okay huh so it's fine now let me save

[19:20:21 - 19:20:26]
now let's create the main. pi so first

[19:20:23 - 19:20:28]
of all let's import all the necessary

[19:20:26 - 19:20:30]
Library yeah so these are the library I

[19:20:28 - 19:20:32]
need guys I think remember I was also

[19:20:30 - 19:20:34]
importing them in my collab Enterprise

[19:20:32 - 19:20:36]
so verx AI then stream L I need for the

[19:20:34 - 19:20:38]
user interface then I'm also importing

[19:20:36 - 19:20:39]
some of the necessary uh let's say

[19:20:38 - 19:20:41]
function from the vertic preview

[19:20:39 - 19:20:42]
generative models okay so I need

[19:20:41 - 19:20:44]
generative generation config generative

[19:20:42 - 19:20:46]
model and EnV I need because I want to

[19:20:44 - 19:20:48]
load this EnV file now let's select my

[19:20:46 - 19:20:50]
current environment so this is my

[19:20:48 - 19:20:52]
environment okay now this error will be

[19:20:50 - 19:20:54]
disappear now the first thing I'll uh

[19:20:52 - 19:20:56]
load my project ID as as well as the

[19:20:54 - 19:20:58]
region from my environment okay for this

[19:20:56 - 19:21:01]
this codit you have to run got

[19:20:58 - 19:21:02]
it then I'll be

[19:21:01 - 19:21:04]
initializing uh then I'll be

[19:21:02 - 19:21:06]
authenticating with my verx a so this is

[19:21:04 - 19:21:08]
the authentication code guys verx a.

[19:21:06 - 19:21:10]
init you have to give the project ID as

[19:21:08 - 19:21:12]
well as the project location that's it

[19:21:10 - 19:21:14]
now let's load the model so here I'm

[19:21:12 - 19:21:17]
going to load one model from the model

[19:21:14 - 19:21:19]
Garden called gin 1.0 Pro so let me show

[19:21:17 - 19:21:22]
you if I go to the model

[19:21:19 - 19:21:24]
Garden so this is the model guys I'm

[19:21:22 - 19:21:26]
trying to load just click here and you

[19:21:24 - 19:21:29]
will see the model ID so just try to

[19:21:26 - 19:21:30]
copy the model ID and you can use it so

[19:21:29 - 19:21:33]
this is the model ID guys here just try

[19:21:30 - 19:21:36]
to copy and mention it here okay that's

[19:21:33 - 19:21:39]
it then I have created a simple function

[19:21:36 - 19:21:41]
let me show you so this is the function

[19:21:39 - 19:21:44]
I created inside that what I'm doing I'm

[19:21:41 - 19:21:47]
just first all creating my uh streamly

[19:21:44 - 19:21:49]
title first of all I'm U first of all

[19:21:47 - 19:21:51]
I'm setting my page configuration like

[19:21:49 - 19:21:53]
verx a demo so it will give you one name

[19:21:51 - 19:21:54]
then I'm uh setting the header that

[19:21:53 - 19:21:56]
means that means what will happen it

[19:21:54 - 19:21:58]
will give you one title so here you can

[19:21:56 - 19:22:02]
give any name so here I have given let's

[19:21:58 - 19:22:04]
J mini on vertx a or you can give vertex

[19:22:02 - 19:22:06]
AI uh vertx

[19:22:04 - 19:22:08]
a local

[19:22:06 - 19:22:11]
demo because everything we're doing in

[19:22:08 - 19:22:13]
the local machine okay then uh user will

[19:22:11 - 19:22:15]
give one question so that's why I have

[19:22:13 - 19:22:16]
taken a uh text input box and this

[19:22:15 - 19:22:19]
question actually I'm passing to my

[19:22:16 - 19:22:21]
model you can see okay if question if

[19:22:19 - 19:22:23]
there is a question it will execute this

[19:22:21 - 19:22:25]
uh model otherwise it won't be executing

[19:22:23 - 19:22:26]
okay after that actually I'm going

[19:22:25 - 19:22:29]
through the response and I'm printing in

[19:22:26 - 19:22:31]
my console okay that means in my stream

[19:22:29 - 19:22:33]
Le console that's it now if I want to

[19:22:31 - 19:22:35]
execute I have to call the function as

[19:22:33 - 19:22:37]
well so let's call the

[19:22:35 - 19:22:39]
function that's it now let's try to

[19:22:37 - 19:22:43]
execute and try to see whether it's

[19:22:39 - 19:22:46]
working or not so I'll write stream l

[19:22:43 - 19:22:50]
run app.py sorry main.py

[19:22:46 - 19:22:50]
needs now let's give the allow

[19:22:51 - 19:22:55]
permission so this is the interface guys

[19:22:53 - 19:22:57]
now here you can ask anything let's say

[19:22:55 - 19:22:57]
I'll give a

[19:22:58 - 19:23:03]
hello let's see you can also see the

[19:23:01 - 19:23:05]
terminal to get the log okay you can see

[19:23:03 - 19:23:06]
it is giving me one error it is telling

[19:23:05 - 19:23:08]
uh Google authentication default

[19:23:06 - 19:23:10]
credential your default credential are

[19:23:08 - 19:23:11]
not found to set the default

[19:23:10 - 19:23:14]
configuration you can visit this link so

[19:23:11 - 19:23:16]
let's open this link um and I think it

[19:23:14 - 19:23:19]
will suggest me some command

[19:23:16 - 19:23:22]
there ah so let's copy this

[19:23:19 - 19:23:28]
command and now I'll execute from my

[19:23:22 - 19:23:28]
terminal let I'll stop it now let's

[19:23:29 - 19:23:33]
execute I'll select my account the

[19:23:31 - 19:23:37]
account actually I'm using for my

[19:23:33 - 19:23:39]
gcloud so I'll give my password next so

[19:23:37 - 19:23:40]
if you're doing for the first time so

[19:23:39 - 19:23:42]
you might get this kinds of issue so

[19:23:40 - 19:23:45]
once this setup is done now uh you can

[19:23:42 - 19:23:49]
use it as it is okay now I think it is

[19:23:45 - 19:23:49]
done now let's execute the application

[19:23:51 - 19:23:54]
again now let's keep

[19:23:58 - 19:24:01]
hello okay guys now see I got the output

[19:24:00 - 19:24:03]
there is no issue that means what you

[19:24:01 - 19:24:05]
have to do you have to set the

[19:24:03 - 19:24:08]
credential as a default uh default

[19:24:05 - 19:24:10]
actually okay credential so that's why

[19:24:08 - 19:24:13]
we uh we actually executed this command

[19:24:10 - 19:24:15]
gcloud o application default login got

[19:24:13 - 19:24:16]
it now see I'm getting the output now

[19:24:15 - 19:24:19]
here you can pass any kinds of prompt so

[19:24:16 - 19:24:23]
here I can give let's say

[19:24:19 - 19:24:23]
uh tell me

[19:24:24 - 19:24:27]
about

[19:24:28 - 19:24:34]
python okay see I'm getting the entire

[19:24:31 - 19:24:35]
response okay got it so you can now ask

[19:24:34 - 19:24:37]
any kinds of question that means from

[19:24:35 - 19:24:39]
our local machine itself now we are able

[19:24:37 - 19:24:42]
to access the model Garden that means by

[19:24:39 - 19:24:44]
verx a Services all right okay great so

[19:24:42 - 19:24:46]
yes guys this is all about from this

[19:24:44 - 19:24:47]
video now we'll be using this technique

[19:24:46 - 19:24:49]
going forward whenever we'll be

[19:24:47 - 19:24:51]
implementing any kinds of project okay

[19:24:49 - 19:24:53]
so in the next video we'll try to see

[19:24:51 - 19:24:55]
how we can uh Implement a rag based

[19:24:53 - 19:24:58]
application okay with the help of

[19:24:55 - 19:24:59]
actually uh verx a platform and we'll be

[19:24:58 - 19:25:02]
using some vertica Services there all

[19:24:59 - 19:25:04]
right so as of now we saw how we can use

[19:25:02 - 19:25:05]
model Garden uh that means how we can

[19:25:04 - 19:25:06]
access different different kinds of

[19:25:05 - 19:25:08]
model on top of that how we can perform

[19:25:06 - 19:25:10]
the inference but let's say if you have

[19:25:08 - 19:25:11]
some custom data and with the help of

[19:25:10 - 19:25:12]
that custom data you want to create a

[19:25:11 - 19:25:14]
knowledge base and you want to connect

[19:25:12 - 19:25:15]
your large language model there okay and

[19:25:14 - 19:25:18]
you want to perform the quy operation on

[19:25:15 - 19:25:19]
top of it so how we can perform it and

[19:25:18 - 19:25:21]
this is called actually rag I I think I

[19:25:19 - 19:25:23]
already explained okay in my previous

[19:25:21 - 19:25:24]
video so if you're not sure about the r

[19:25:23 - 19:25:26]
guys first of all check those video then

[19:25:24 - 19:25:27]
you will be able to understand okay what

[19:25:26 - 19:25:29]
I'm trying to implement here so that

[19:25:27 - 19:25:31]
means uh let's say here I'll be using my

[19:25:29 - 19:25:34]
custom data and with that custom data

[19:25:31 - 19:25:36]
what I will do I create a knowledge base

[19:25:34 - 19:25:37]
okay and I'll just try to connect my

[19:25:36 - 19:25:39]
large language model there then I'll be

[19:25:37 - 19:25:40]
performing the quy operation on top of

[19:25:39 - 19:25:42]
my data the data actually I have

[19:25:40 - 19:25:44]
uploaded this is the thing we be be

[19:25:42 - 19:25:46]
implementing and here technology wise

[19:25:44 - 19:25:47]
actually will be using the verx entire

[19:25:46 - 19:25:49]
verx a platform that means here

[19:25:47 - 19:25:51]
everything will be using uh Google cloud

[19:25:49 - 19:25:53]
services okay we are not going to use

[19:25:51 - 19:25:55]
any third party services that means uh

[19:25:53 - 19:25:57]
to store our data we'll be using Google

[19:25:55 - 19:25:59]
Cloud bucket and to store our embedding

[19:25:57 - 19:26:01]
we'll be using uh Vector restore okay

[19:25:59 - 19:26:03]
Vector restore service from the vertx AI

[19:26:01 - 19:26:04]
this is one of the vector database they

[19:26:03 - 19:26:06]
have created okay this is called

[19:26:04 - 19:26:08]
actually Vector restore so we'll be

[19:26:06 - 19:26:10]
using all the Google cloud service only

[19:26:08 - 19:26:11]
not any other service okay in this video

[19:26:10 - 19:26:14]
so for this guys you can see I prepared

[19:26:11 - 19:26:15]
one notebook in the collab Enterprise so

[19:26:14 - 19:26:17]
first of all try to connect the notebook

[19:26:15 - 19:26:18]
after that you can check with the help

[19:26:17 - 19:26:19]
of okay command and if it is giving the

[19:26:18 - 19:26:21]
okay message that means notebook is

[19:26:19 - 19:26:23]
running then the first thing what you

[19:26:21 - 19:26:25]
have to do we have to install these are

[19:26:23 - 19:26:27]
the library as I told you we'll be using

[19:26:25 - 19:26:28]
uh some custom data I'm going to use PDF

[19:26:27 - 19:26:30]
document that's why I'm installing this

[19:26:28 - 19:26:32]
Pi PDF 2 okay this library then Google

[19:26:30 - 19:26:34]
Cloud AI platform because if I want to

[19:26:32 - 19:26:36]
use the verx a I need to install this

[19:26:34 - 19:26:37]
package then I already told you we'll be

[19:26:36 - 19:26:39]
using custom data that means custom

[19:26:37 - 19:26:41]
document and to store this custom

[19:26:39 - 19:26:42]
document I'll be using uh Google Cloud

[19:26:41 - 19:26:44]
bucket I think you

[19:26:42 - 19:26:47]
Google Cloud also provides bucket

[19:26:44 - 19:26:50]
service let me show you so if you just

[19:26:47 - 19:26:52]
open Google cloud and search for bucket

[19:26:50 - 19:26:53]
so this is the bucket so here you can

[19:26:52 - 19:26:54]
create different different bucket and

[19:26:53 - 19:26:56]
inside a bucket you can store the data

[19:26:54 - 19:26:58]
see I already created one bucket called

[19:26:56 - 19:27:00]
start content 2024 inside that I'm

[19:26:58 - 19:27:03]
having one

[19:27:00 - 19:27:06]
documents I'll tell you how to uh upload

[19:27:03 - 19:27:08]
this document here as of now just try to

[19:27:06 - 19:27:10]
consider uh we'll be using this bucket

[19:27:08 - 19:27:11]
services to store my content okay and no

[19:27:10 - 19:27:12]
need to create manually it will

[19:27:11 - 19:27:14]
automatically create I've already

[19:27:12 - 19:27:15]
written the code for it so these are the

[19:27:14 - 19:27:17]
package you have to install for me I

[19:27:15 - 19:27:18]
already installed everything so I'm not

[19:27:17 - 19:27:20]
going to install again now see you have

[19:27:18 - 19:27:22]
to import these are the library right

[19:27:20 - 19:27:24]
now so here I'm importing stories from

[19:27:22 - 19:27:25]
google. cloud because I told you we'll

[19:27:24 - 19:27:28]
be using bucket and to use to bucket I

[19:27:25 - 19:27:30]
need this uh actually function then I'm

[19:27:28 - 19:27:32]
also importing text embedding model from

[19:27:30 - 19:27:34]
the verx AI language model because here

[19:27:32 - 19:27:36]
we have to perform the embedding

[19:27:34 - 19:27:37]
generation and to generate the embedding

[19:27:36 - 19:27:40]
and need some embedding model and here

[19:27:37 - 19:27:42]
I'm going to use Google embedding model

[19:27:40 - 19:27:43]
OKAY from the vertx a from the model

[19:27:42 - 19:27:45]
Garden that's why I have imported this

[19:27:43 - 19:27:48]
text embedding model function then I

[19:27:45 - 19:27:49]
also imported AI platform Pi PDF and

[19:27:48 - 19:27:52]
these are the library I also imported

[19:27:49 - 19:27:55]
here and here I'm using UI ID okay why

[19:27:52 - 19:27:56]
I'm using UI ID let me tell you see

[19:27:55 - 19:27:59]
there is a reason actually I'm using UI

[19:27:56 - 19:28:01]
ID see if you're using vertex AI this

[19:27:59 - 19:28:04]
rag would be slightly different okay

[19:28:01 - 19:28:05]
slightly different that means let's say

[19:28:04 - 19:28:06]
whatever documents you will be

[19:28:05 - 19:28:08]
publishing let's say I will be

[19:28:06 - 19:28:10]
publishing one statistics PDF I'm having

[19:28:08 - 19:28:11]
let me show you the statistics PDF so

[19:28:10 - 19:28:13]
guys as you can see this is the

[19:28:11 - 19:28:14]
statistics PDF actually I'm having so

[19:28:13 - 19:28:17]
this particular data actually I'll be

[19:28:14 - 19:28:18]
using as my custom data now what will

[19:28:17 - 19:28:21]
happen first of all I have to extract

[19:28:18 - 19:28:22]
the documents from the PDF yes or no so

[19:28:21 - 19:28:25]
after extracting what I will get I will

[19:28:22 - 19:28:27]
get uh different different documents I

[19:28:25 - 19:28:30]
think you know I'll get different

[19:28:27 - 19:28:33]
different documents that means doc one

[19:28:30 - 19:28:36]
okay then doc two doc two and so on now

[19:28:33 - 19:28:38]
what will happen this document I have to

[19:28:36 - 19:28:40]
convert to embeddings as well that means

[19:28:38 - 19:28:42]
it would be converted to embeddings so

[19:28:40 - 19:28:43]
let's say you will get some Vector here

[19:28:42 - 19:28:45]
let's say

[19:28:43 - 19:28:48]
0.29 comma

[19:28:45 - 19:28:50]
0.55 0.88 and so on let's say this is

[19:28:48 - 19:28:53]
the vector representation of this doc

[19:28:50 - 19:28:55]
one and Doc two and so on let's

[19:28:53 - 19:28:58]
say I'll I'll just create some dummy

[19:28:55 - 19:28:58]
Vector

[19:28:58 - 19:29:03]
here now here what I want to do with the

[19:29:01 - 19:29:06]
help of this ey ID I want to assign some

[19:29:03 - 19:29:08]
unique ID let's say the document one it

[19:29:06 - 19:29:09]
has extracted I will assign one unique

[19:29:08 - 19:29:13]
ID let's say this is the unique ID let's

[19:29:09 - 19:29:15]
say 1 2 1 0 let's say this is the unique

[19:29:13 - 19:29:16]
ID okay it has assigned to the doc one

[19:29:15 - 19:29:20]
then the doc two it will assign another

[19:29:16 - 19:29:22]
unique ID let's say 1 2 1 1 okay now

[19:29:20 - 19:29:24]
what will happen this unique ID also

[19:29:22 - 19:29:26]
would be assigned in the vector because

[19:29:24 - 19:29:28]
this Vector is representing this

[19:29:26 - 19:29:31]
documentation yes or no okay that's why

[19:29:28 - 19:29:32]
this ID would be there 1 2 1 0 then this

[19:29:31 - 19:29:34]
ID would be also there because this

[19:29:32 - 19:29:37]
Vector is representing this document so

[19:29:34 - 19:29:38]
1 2 1 1 now what will happen let's say

[19:29:37 - 19:29:40]
whenever you will perform the similarity

[19:29:38 - 19:29:42]
s operation that time what happens

[19:29:40 - 19:29:44]
actually it will return the relevant

[19:29:42 - 19:29:46]
answer yes or no I think you know

[19:29:44 - 19:29:47]
whenever you implement any kinds of rag

[19:29:46 - 19:29:49]
whenever you perform similarity

[19:29:47 - 19:29:51]
operation it will give you some relevant

[19:29:49 - 19:29:54]
answer okay relevant relevant answer you

[19:29:51 - 19:29:55]
will get okay and from where you will

[19:29:54 - 19:29:56]
get the relevant answer from the

[19:29:55 - 19:29:59]
documents only you will get the relevant

[19:29:56 - 19:30:01]
answer the documents you are having okay

[19:29:59 - 19:30:02]
now let's say it will give you this

[19:30:01 - 19:30:04]
relevant answer let's say Doc one

[19:30:02 - 19:30:05]
whenever it will give you doc one

[19:30:04 - 19:30:07]
relevant answer that means it will

[19:30:05 - 19:30:08]
return the vector because your model

[19:30:07 - 19:30:10]
will only return the numbers not the

[19:30:08 - 19:30:13]
text okay and this particular number

[19:30:10 - 19:30:15]
will map where in this document that

[19:30:13 - 19:30:16]
means this document is representing this

[19:30:15 - 19:30:18]
Vector that means whenever your model is

[19:30:16 - 19:30:20]
generating this Vector that means it

[19:30:18 - 19:30:22]
will map this documents that means the

[19:30:20 - 19:30:25]
text okay how with the help of this ey

[19:30:22 - 19:30:26]
ID okay with the help of this ey ID so

[19:30:25 - 19:30:28]
it will look for where this U ID is

[19:30:26 - 19:30:30]
present that documents actually it will

[19:30:28 - 19:30:32]
show you as a relevant answer okay now I

[19:30:30 - 19:30:35]
think it is clear why I'm using this UI

[19:30:32 - 19:30:38]
ID to give uh to assign actually unique

[19:30:35 - 19:30:41]
ID uh like uh in front of my documents

[19:30:38 - 19:30:42]
and in front of my Vector embeddings

[19:30:41 - 19:30:44]
okay now I think it is clear now let me

[19:30:42 - 19:30:45]
clear my boat now the next thing what

[19:30:44 - 19:30:47]
you have to do guys you have to

[19:30:45 - 19:30:49]
initialize some of the variable now see

[19:30:47 - 19:30:51]
if you're doing this project from the

[19:30:49 - 19:30:53]
Google cab first of all you have to

[19:30:51 - 19:30:54]
authenticate with your gcloud and how to

[19:30:53 - 19:30:56]
authenticate I already shared you two

[19:30:54 - 19:30:57]
code I think you remember two

[19:30:56 - 19:31:00]
configuration code I shared with you in

[19:30:57 - 19:31:01]
my uh like verx demo session so you can

[19:31:00 - 19:31:03]
refer the notebook and you can first of

[19:31:01 - 19:31:04]
all authenticate with your Google Cloud

[19:31:03 - 19:31:06]
okay said until you are not doing the

[19:31:04 - 19:31:08]
authentication it w be working I'm

[19:31:06 - 19:31:09]
running from a collab Enterprise that's

[19:31:08 - 19:31:10]
why I don't need to do the

[19:31:09 - 19:31:12]
authentication so if you're running from

[19:31:10 - 19:31:14]
the collab Google collabs so you have to

[19:31:12 - 19:31:16]
activate this line actually project so

[19:31:14 - 19:31:17]
you have to give the project ID here how

[19:31:16 - 19:31:19]
to collect the project ID this is the

[19:31:17 - 19:31:21]
project ID got it so here I'm running

[19:31:19 - 19:31:22]
from the collab Enterprise so I don't

[19:31:21 - 19:31:24]
need this variable I'll just try to

[19:31:22 - 19:31:27]
comment it out so here what I need I

[19:31:24 - 19:31:30]
need the location and this is my

[19:31:27 - 19:31:31]
location uh then uh PDF path so why do

[19:31:30 - 19:31:33]
you have to upload the PDF so in the

[19:31:31 - 19:31:35]
files actually you have to upload the

[19:31:33 - 19:31:37]
PDF let me show you so here you can

[19:31:35 - 19:31:38]
right click and upload and try to select

[19:31:37 - 19:31:40]
the PDF whatever PDF you are having just

[19:31:38 - 19:31:41]
try to open it here it will

[19:31:40 - 19:31:43]
automatically upload here see for me

[19:31:41 - 19:31:45]
I've have already uploaded and this two

[19:31:43 - 19:31:46]
file would be generated as of now U see

[19:31:45 - 19:31:48]
I already executed this project okay

[19:31:46 - 19:31:50]
that's why all the artifacts you can see

[19:31:48 - 19:31:52]
okay but for you it would be empty

[19:31:50 - 19:31:54]
initially so this two file would be

[19:31:52 - 19:31:55]
created how it will be created I'll tell

[19:31:54 - 19:31:57]
you as of now just try to consider we

[19:31:55 - 19:31:59]
have uploaded the statistics of PDF file

[19:31:57 - 19:32:01]
got it then you have to give the bucket

[19:31:59 - 19:32:03]
name so you can give any kinds of bucket

[19:32:01 - 19:32:04]
name and make sure this bucket name

[19:32:03 - 19:32:06]
should be unique so this bucket would be

[19:32:04 - 19:32:07]
created automatically in the bucket

[19:32:06 - 19:32:09]
section see it is already created for me

[19:32:07 - 19:32:10]
again this would be created

[19:32:09 - 19:32:12]
automatically you don't need to create

[19:32:10 - 19:32:14]
it manually then here you have to give

[19:32:12 - 19:32:17]
embed file path what is embed file path

[19:32:14 - 19:32:18]
because see I already told you uh first

[19:32:17 - 19:32:21]
of all we have to extract the documents

[19:32:18 - 19:32:22]
from my PDF then what we have to do we

[19:32:21 - 19:32:24]
have to generate the embedding as well

[19:32:22 - 19:32:26]
with respect to the documents and this

[19:32:24 - 19:32:28]
documents and this embedding I I'm going

[19:32:26 - 19:32:29]
to save in a Json file okay that's why

[19:32:28 - 19:32:31]
I'm just creating some Json file you can

[19:32:29 - 19:32:34]
see these two Json file I'm creating

[19:32:31 - 19:32:37]
okay starts embedding Json and start

[19:32:34 - 19:32:39]
sentence. Json inside sentence it will

[19:32:37 - 19:32:41]
store all the documents that me the

[19:32:39 - 19:32:44]
English text and inside embedding it

[19:32:41 - 19:32:46]
will all the uh your embedding okay

[19:32:44 - 19:32:47]
embedding of the sentence that means

[19:32:46 - 19:32:49]
whatever let's say documents you are

[19:32:47 - 19:32:51]
having that means whatever documents you

[19:32:49 - 19:32:52]
have okay with respect to that it will

[19:32:51 - 19:32:54]
store the embeddings as well okay with

[19:32:52 - 19:32:56]
the unique ID so that is the thing then

[19:32:54 - 19:32:58]
you have to give the index name index

[19:32:56 - 19:32:59]
name means let's say here we'll be using

[19:32:58 - 19:33:02]
Vector search now and inside Vector

[19:32:59 - 19:33:03]
search we we just create an index the

[19:33:02 - 19:33:05]
way actually used to create the fine

[19:33:03 - 19:33:06]
code index I think remember we create

[19:33:05 - 19:33:08]
index here so this is the index name it

[19:33:06 - 19:33:09]
will automatically create that index now

[19:33:08 - 19:33:11]
here I have written a function this

[19:33:09 - 19:33:13]
function will extract the sentence from

[19:33:11 - 19:33:14]
the PDF so it will take the PDF path and

[19:33:13 - 19:33:15]
it will give you the sentences that

[19:33:14 - 19:33:17]
means the all the documents it will give

[19:33:15 - 19:33:18]
you then I have written some of the

[19:33:17 - 19:33:20]
helper function guys you can see

[19:33:18 - 19:33:21]
generate text embedding that means this

[19:33:20 - 19:33:22]
function will generate the text

[19:33:21 - 19:33:24]
embedding it will take the sentence and

[19:33:22 - 19:33:25]
it will generate a text embedding with

[19:33:24 - 19:33:28]
the help of text embedding model you can

[19:33:25 - 19:33:30]
see I'm using text embedding Geo model

[19:33:28 - 19:33:32]
uh so this is the model G text embeding

[19:33:30 - 19:33:36]
Geo 001 so this model is available in

[19:33:32 - 19:33:38]
the model Garden uh in vertx AI got it

[19:33:36 - 19:33:39]
then I have written another function

[19:33:38 - 19:33:41]
generate and save embedding that means

[19:33:39 - 19:33:44]
that means this function will actually

[19:33:41 - 19:33:46]
add the unique ID uh in front to of your

[19:33:44 - 19:33:48]
sentence that means documents and in

[19:33:46 - 19:33:50]
front to of your uh embeddings that

[19:33:48 - 19:33:52]
means Vector embeddings okay that means

[19:33:50 - 19:33:54]
it will generate this both file okay and

[19:33:52 - 19:33:55]
it will it will save as a it will save

[19:33:54 - 19:33:57]
as a juston file you can see here I'm

[19:33:55 - 19:33:59]
doing it I'm first of all uh actually

[19:33:57 - 19:34:00]
creating my embedding okay and I'm

[19:33:59 - 19:34:02]
adding the unique ID I'm also creating

[19:34:00 - 19:34:04]
the sentence I'm adding the unique ID

[19:34:02 - 19:34:06]
then I'm saving in a Json file okay this

[19:34:04 - 19:34:08]
is the thing actually we are doing that

[19:34:06 - 19:34:11]
means this function is responsible for

[19:34:08 - 19:34:13]
creating this two file and it will store

[19:34:11 - 19:34:15]
uh your sent sentences and it will store

[19:34:13 - 19:34:17]
your documents as well as the embedding

[19:34:15 - 19:34:19]
with the unique ID okay that's it then

[19:34:17 - 19:34:21]
there is another function I created

[19:34:19 - 19:34:24]
called upload file that means after uh

[19:34:21 - 19:34:27]
let's say generating this file I have to

[19:34:24 - 19:34:29]
upload this start sentence dojon in the

[19:34:27 - 19:34:31]
bucket and how I will push to the bucket

[19:34:29 - 19:34:32]
we'll be using this function upload file

[19:34:31 - 19:34:35]
you can see if you go to the bucket

[19:34:32 - 19:34:36]
section so this file is already present

[19:34:35 - 19:34:38]
okay so if you want to push any kinds of

[19:34:36 - 19:34:40]
file you can use this function that

[19:34:38 - 19:34:41]
means we created some helper function

[19:34:40 - 19:34:44]
this helper function will help me to do

[19:34:41 - 19:34:45]
certain operation this is the thing now

[19:34:44 - 19:34:46]
here another function I have written

[19:34:45 - 19:34:49]
called create Vector index so this

[19:34:46 - 19:34:51]
function will create the vector index in

[19:34:49 - 19:34:54]
the vector s okay in the vector s Vector

[19:34:51 - 19:34:55]
database and each of the dimension would

[19:34:54 - 19:34:57]
be

[19:34:55 - 19:34:59]
784 I think you remember previously we

[19:34:57 - 19:35:01]
used sentence Transformer uh actually

[19:34:59 - 19:35:02]
embedding model and we we used to create

[19:35:01 - 19:35:04]
I think

[19:35:02 - 19:35:06]
384 Vector representation I think you

[19:35:04 - 19:35:10]
remember right but if you're using this

[19:35:06 - 19:35:12]
uh text Geo model from the model Guiden

[19:35:10 - 19:35:15]
your vector Dimension would

[19:35:12 - 19:35:17]
780 sorry 768 this is the dimension and

[19:35:15 - 19:35:18]
you can see with the help of AI platform

[19:35:17 - 19:35:20]
actually Library we are creating the

[19:35:18 - 19:35:21]
index so this function will

[19:35:20 - 19:35:23]
automatically create the index for you

[19:35:21 - 19:35:24]
got it then after that I'm calling these

[19:35:23 - 19:35:25]
are the function you can see first of

[19:35:24 - 19:35:27]
all I'm calling generate and save the

[19:35:25 - 19:35:29]
vector I'm giving my PDF path sentence

[19:35:27 - 19:35:31]
file path as well as the embedding file

[19:35:29 - 19:35:33]
path then I'm also uploading this file

[19:35:31 - 19:35:34]
to my bucket that means if I execute

[19:35:33 - 19:35:36]
this line what will happen it will

[19:35:34 - 19:35:38]
create this two file first of all let me

[19:35:36 - 19:35:39]
open it so this is my sentence that

[19:35:38 - 19:35:42]
means this is my document and you can

[19:35:39 - 19:35:44]
see first of all it will show you the ID

[19:35:42 - 19:35:45]
then it will show you the sentence okay

[19:35:44 - 19:35:47]
that means this is the document it has

[19:35:45 - 19:35:49]
extracted from the PDF with respect to

[19:35:47 - 19:35:51]
that it has also saved the embeddings as

[19:35:49 - 19:35:52]
well let me show you so this is the

[19:35:51 - 19:35:55]
embedding and here you also you'll see

[19:35:52 - 19:35:57]
the unique ID that means the same ID and

[19:35:55 - 19:36:00]
now this is the embedding representation

[19:35:57 - 19:36:01]
okay I hope now it is clear now so once

[19:36:00 - 19:36:04]
it is executed then upload file will

[19:36:01 - 19:36:06]
execute and it will upload this sentence

[19:36:04 - 19:36:07]
dojon to my bucket now if I show you see

[19:36:06 - 19:36:10]
bucket would be created and inside

[19:36:07 - 19:36:12]
bucket actually you will see this start

[19:36:10 - 19:36:14]
uh sentence dojon would be present okay

[19:36:12 - 19:36:16]
because later on whenever I perform the

[19:36:14 - 19:36:18]
let's say similarity s operation I need

[19:36:16 - 19:36:20]
that file I need to download that file

[19:36:18 - 19:36:21]
with that I'll will do the source

[19:36:20 - 19:36:23]
operation okay similarity Source

[19:36:21 - 19:36:24]
operation that is the thing now the next

[19:36:23 - 19:36:26]
thing what we'll be doing we'll be

[19:36:24 - 19:36:27]
creating the vector index that means

[19:36:26 - 19:36:29]
we'll be creating the index and inside

[19:36:27 - 19:36:31]
index actually will be storing all of my

[19:36:29 - 19:36:32]
Vector okay so here you can see I'm

[19:36:31 - 19:36:35]
giving the bucket name that means from

[19:36:32 - 19:36:36]
the bucket name it will load this file

[19:36:35 - 19:36:39]
okay it will load this file that means

[19:36:36 - 19:36:40]
the sentence file so sentence file it

[19:36:39 - 19:36:42]
will load then it will also take the

[19:36:40 - 19:36:44]
index name and with the help of actually

[19:36:42 - 19:36:46]
that embedding model it will generate

[19:36:44 - 19:36:47]
the embeddings of that documents the

[19:36:46 - 19:36:49]
documents actually we are having and it

[19:36:47 - 19:36:51]
will store to the vctor database that

[19:36:49 - 19:36:53]
means inside my Vector SCE now if I

[19:36:51 - 19:36:54]
execute this line okay if I execute this

[19:36:53 - 19:36:56]
line it will take some time it will that

[19:36:54 - 19:36:58]
means it will process all the data it

[19:36:56 - 19:36:59]
will restore to the vector embedding

[19:36:58 - 19:37:02]
after that if you open it up let me show

[19:36:59 - 19:37:04]
you so if you open it up so you'll see

[19:37:02 - 19:37:06]
that it will create an

[19:37:04 - 19:37:08]
index the name actually you have given

[19:37:06 - 19:37:09]
start index okay now you can see both

[19:37:08 - 19:37:11]
places you are getting this green TI

[19:37:09 - 19:37:13]
icon that means everything is ex uted

[19:37:11 - 19:37:15]
successfully if you're getting any red

[19:37:13 - 19:37:16]
icon it's not completed okay that means

[19:37:15 - 19:37:19]
there are some

[19:37:16 - 19:37:21]
issue now if I click on the deployed

[19:37:19 - 19:37:23]
index you'll see one ID here so we need

[19:37:21 - 19:37:25]
this ID later on so guys you can see

[19:37:23 - 19:37:26]
this is the ID the last number you can

[19:37:25 - 19:37:29]
see this is the ID so we need this ID

[19:37:26 - 19:37:31]
later on okay see this is the ID this ID

[19:37:29 - 19:37:33]
actually we need later on so now let's

[19:37:31 - 19:37:35]
get back to my colar now again just

[19:37:33 - 19:37:37]
import some of the necessary library

[19:37:35 - 19:37:39]
then again said these are the actually

[19:37:37 - 19:37:40]
variable like your location sentence

[19:37:39 - 19:37:42]
file path and index name that means the

[19:37:40 - 19:37:44]
same index name name okay same index

[19:37:42 - 19:37:47]
name you have to give start index okay

[19:37:44 - 19:37:49]
that's it then just load the model large

[19:37:47 - 19:37:50]
language model here so here I'm using JD

[19:37:49 - 19:37:53]
you can also load any other model then

[19:37:50 - 19:37:55]
just try to load the index that me index

[19:37:53 - 19:37:56]
endpoint you have to load and to load

[19:37:55 - 19:37:58]
the index endpoint you just need to give

[19:37:56 - 19:37:59]
this ID and how you'll get the ID guys I

[19:37:58 - 19:38:01]
already told you so this is the ID just

[19:37:59 - 19:38:03]
try to copy this ID and just try to

[19:38:01 - 19:38:05]
paste it here now if you execute it will

[19:38:03 - 19:38:06]
load the index ID got it that means this

[19:38:05 - 19:38:08]
is going to be your knowledge base right

[19:38:06 - 19:38:10]
now and this is going to be your

[19:38:08 - 19:38:12]
model now again I have written some of

[19:38:10 - 19:38:13]
the helper function generate embedding

[19:38:12 - 19:38:15]
that means whatever user will give the

[19:38:13 - 19:38:16]
prompt now let's say I have given one

[19:38:15 - 19:38:17]
prompt this prompt should be also

[19:38:16 - 19:38:19]
converted to the embedding okay then

[19:38:17 - 19:38:20]
this function will help me to do that

[19:38:19 - 19:38:22]
then I written another function generate

[19:38:20 - 19:38:23]
context and load file that means it will

[19:38:22 - 19:38:25]
load that documents file and it will

[19:38:23 - 19:38:27]
generate the context okay that means if

[19:38:25 - 19:38:29]
we are performing similarity s operation

[19:38:27 - 19:38:31]
uh it will give you some rank results

[19:38:29 - 19:38:32]
and how it will give the rank results

[19:38:31 - 19:38:34]
with the help of this two function it

[19:38:32 - 19:38:37]
will give the rank results now here I've

[19:38:34 - 19:38:40]
loaded the file then uh you can

[19:38:37 - 19:38:41]
see then this is my query let's say what

[19:38:40 - 19:38:43]
is corelation first of all I'm

[19:38:41 - 19:38:45]
generating the query embedding with the

[19:38:43 - 19:38:47]
help of that embedding model and if you

[19:38:45 - 19:38:49]
want to see the query embedding see this

[19:38:47 - 19:38:50]
is the vector representation guys this

[19:38:49 - 19:38:53]
is the entire query embedding now let me

[19:38:50 - 19:38:55]
comment it now this query embedding I

[19:38:53 - 19:38:58]
will pass to my Vector SS okay now you

[19:38:55 - 19:39:00]
can see find neighbor it will give me 10

[19:38:58 - 19:39:02]
rank results okay 10 rank results

[19:39:00 - 19:39:04]
actually it will give me then this

[19:39:02 - 19:39:05]
response actually I'm giving to my model

[19:39:04 - 19:39:07]
okay this is the code cipit my model

[19:39:05 - 19:39:09]
will try to analyze this response even

[19:39:07 - 19:39:10]
the query I have given based on that it

[19:39:09 - 19:39:13]
will give me one response now if I

[19:39:10 - 19:39:15]
execute see if I execute this last kind

[19:39:13 - 19:39:16]
of code see here you will get the

[19:39:15 - 19:39:19]
response code delation is a statical

[19:39:16 - 19:39:20]
measure that indicates uh see blah blah

[19:39:19 - 19:39:21]
I'm getting the output and here you you

[19:39:20 - 19:39:24]
can also give the prompt based on the

[19:39:21 - 19:39:26]
context uh delated in the brackets

[19:39:24 - 19:39:28]
answer the query okay that's how you can

[19:39:26 - 19:39:29]
give any kinds of promp and that's

[19:39:28 - 19:39:31]
actually we can build a retable

[19:39:29 - 19:39:33]
augmented generation kinds of

[19:39:31 - 19:39:34]
application okay with the help of vertic

[19:39:33 - 19:39:36]
platform and all the steps guys I have

[19:39:34 - 19:39:37]
mentioned here so if you're implementing

[19:39:36 - 19:39:39]
any kinds of rag based actually

[19:39:37 - 19:39:41]
application you can follow the same step

[19:39:39 - 19:39:43]
okay even you can also perform in your

[19:39:41 - 19:39:44]
local machine that means I told you how

[19:39:43 - 19:39:46]
we can connect our local machine that

[19:39:44 - 19:39:48]
means how we can connect our vs code so

[19:39:46 - 19:39:50]
with help of vs code also you can create

[19:39:48 - 19:39:52]
this kinds of R rag application and you

[19:39:50 - 19:39:53]
can create a user interface let's say

[19:39:52 - 19:39:55]
you want to create a flask interface you

[19:39:53 - 19:39:56]
want to create a stream late interface

[19:39:55 - 19:39:58]
you can also create so this task

[19:39:56 - 19:39:59]
actually I want to assign you just try

[19:39:58 - 19:40:01]
to create one user interface so you have

[19:39:59 - 19:40:03]
to use the same logic only you just need

[19:40:01 - 19:40:05]
to integrate one user interface that is

[19:40:03 - 19:40:07]
the idea okay I hope it is clear now see

[19:40:05 - 19:40:08]
once it is done now if you want to

[19:40:07 - 19:40:12]
terminate all the instance what you can

[19:40:08 - 19:40:14]
do so first of all uh just try to delete

[19:40:12 - 19:40:15]
this uh so first of all just try to

[19:40:14 - 19:40:17]
delete the bucket to delete the bucket

[19:40:15 - 19:40:19]
just try to select the bucket and there

[19:40:17 - 19:40:20]
is a delete button you will see just try

[19:40:19 - 19:40:23]
to click on delete and delete

[19:40:20 - 19:40:23]
confirmation you have to

[19:40:24 - 19:40:28]
give so it will delete the bucket then

[19:40:26 - 19:40:31]
you also need to delete the index so to

[19:40:28 - 19:40:33]
delete the index just go to the index

[19:40:31 - 19:40:33]
Vector

[19:40:36 - 19:40:42]
SE so first of all you have to do the r

[19:40:39 - 19:40:42]
deploy

[19:40:47 - 19:40:52]
then you can delete it right now I

[19:40:50 - 19:40:54]
think now there is a delete button just

[19:40:52 - 19:40:57]
try to click on delete so it would be

[19:40:54 - 19:40:59]
deleted okay so that's how you can

[19:40:57 - 19:41:01]
remove all the instance you will be

[19:40:59 - 19:41:04]
creating okay so I think guys uh this is

[19:41:01 - 19:41:06]
helpful I showed you the entire uh uh

[19:41:04 - 19:41:08]
like process how we can Implement rack

[19:41:06 - 19:41:10]
see I think you already saw how we can

[19:41:08 - 19:41:11]
set up everything in our local machine

[19:41:10 - 19:41:13]
that means if I want to connect with my

[19:41:11 - 19:41:15]
verx so what are the setup actually I

[19:41:13 - 19:41:17]
can perform so setup wise I already

[19:41:15 - 19:41:19]
covered in my previous video so you can

[19:41:17 - 19:41:20]
check it out so here actually I've

[19:41:19 - 19:41:22]
already prepared everything because see

[19:41:20 - 19:41:24]
most of the code are similar whatever

[19:41:22 - 19:41:26]
things we implemented previously so make

[19:41:24 - 19:41:28]
sure first of all you configured

[19:41:26 - 19:41:30]
everything your account uh then your

[19:41:28 - 19:41:32]
let's say uh configuration everything

[19:41:30 - 19:41:34]
you just prepared after that in the EMV

[19:41:32 - 19:41:38]
file just try to uh change this project

[19:41:34 - 19:41:41]
ID and region so let me copy my project

[19:41:38 - 19:41:44]
ID so just try to click here so this is

[19:41:41 - 19:41:46]
my project Ed gu just try to copy and

[19:41:44 - 19:41:49]
let's mention it

[19:41:46 - 19:41:51]
here okay and reason I'm inside us

[19:41:49 - 19:41:53]
Central one only I don't need to change

[19:41:51 - 19:41:54]
it now the next thing you have to create

[19:41:53 - 19:41:56]
an environment how to create the

[19:41:54 - 19:41:58]
environment I already told you okay I'm

[19:41:56 - 19:42:00]
using the same environment Veri demo now

[19:41:58 - 19:42:01]
you have to install the requirements so

[19:42:00 - 19:42:03]
one more requirement I have added called

[19:42:01 - 19:42:04]
flask so let me install the flask

[19:42:03 - 19:42:06]
because in this project I'm going to use

[19:42:04 - 19:42:08]
flask okay flask framework to create the

[19:42:06 - 19:42:11]
front end application so for this just

[19:42:08 - 19:42:14]
write this command P install ien add

[19:42:11 - 19:42:14]
requirement.

[19:42:14 - 19:42:18]
txd now it should install the

[19:42:16 - 19:42:21]
requirements so guys many people were

[19:42:18 - 19:42:24]
asking me how to uh install actually uh

[19:42:21 - 19:42:25]
GPU Nvidia GPU uh in our local system

[19:42:24 - 19:42:27]
for this what I did actually I created

[19:42:25 - 19:42:29]
one video in my YouTube channel let me

[19:42:27 - 19:42:31]
show you so if you go to my YouTube

[19:42:29 - 19:42:33]
channel guys this is my YouTube channel

[19:42:31 - 19:42:34]
you can also subscribe me here now if I

[19:42:33 - 19:42:38]
go to the video section so here I

[19:42:34 - 19:42:40]
already created one video uh here you

[19:42:38 - 19:42:41]
can see the video set up Nvidia GPU okay

[19:42:40 - 19:42:43]
so here I showed you

[19:42:41 - 19:42:44]
all these steps you can follow to set up

[19:42:43 - 19:42:46]
your Nvidia GPU for the Deep learning

[19:42:44 - 19:42:48]
task got it so let's say if you're

[19:42:46 - 19:42:50]
having good GPU and if want to let's say

[19:42:48 - 19:42:51]
execute open source our language model

[19:42:50 - 19:42:53]
uh in your local machine instead of

[19:42:51 - 19:42:55]
using collab you can refer this video

[19:42:53 - 19:42:56]
that time and make sure guys you

[19:42:55 - 19:42:58]
subscribe uh to this channel because

[19:42:56 - 19:43:00]
here also I create lots of content

[19:42:58 - 19:43:02]
related genv mlops then end to project

[19:43:00 - 19:43:05]
implementation Okay computer vision

[19:43:02 - 19:43:08]
everything now let's get back so I think

[19:43:05 - 19:43:10]
installation is completed yeah now see

[19:43:08 - 19:43:13]
what I have done I created one template

[19:43:10 - 19:43:14]
file and inside that this is my HTML

[19:43:13 - 19:43:16]
code because you already know if I want

[19:43:14 - 19:43:18]
to use flask I need a HTML okay HTML

[19:43:16 - 19:43:20]
code to create my front end part and

[19:43:18 - 19:43:21]
again I used the bootstrap website to

[19:43:20 - 19:43:22]
prepare this front end I'll tell you

[19:43:21 - 19:43:25]
whenever I'll execute how it will look

[19:43:22 - 19:43:27]
like now this is my endpoint app.py and

[19:43:25 - 19:43:29]
here I imported all the necessary

[19:43:27 - 19:43:30]
library and these code are common I

[19:43:29 - 19:43:32]
think you know we are doing the

[19:43:30 - 19:43:34]
authentication with my verx a now this

[19:43:32 - 19:43:36]
is the route I created this route is my

[19:43:34 - 19:43:38]
default route it will launch my

[19:43:36 - 19:43:39]
index.html page and this is my

[19:43:38 - 19:43:41]
prediction route that means whenever

[19:43:39 - 19:43:43]
user will give any query okay user input

[19:43:41 - 19:43:44]
I'm getting the user input and this

[19:43:43 - 19:43:46]
input actually I'm passing to my model

[19:43:44 - 19:43:48]
and whatever response actually I'm

[19:43:46 - 19:43:51]
getting I'm showing in my plus cver

[19:43:48 - 19:43:53]
that's it now let me um execute the

[19:43:51 - 19:43:55]
application so what I will do I'll run

[19:43:53 - 19:43:58]
this application in the port number 8080

[19:43:55 - 19:43:59]
save it now I'll open up my terminal and

[19:43:58 - 19:44:02]
let's execute

[19:43:59 - 19:44:04]
python

[19:44:02 - 19:44:05]
app.py okay so it is running now let's

[19:44:04 - 19:44:09]
get

[19:44:05 - 19:44:10]
back Local Host now see this is how your

[19:44:09 - 19:44:12]
user interface will look like now he can

[19:44:10 - 19:44:17]
give a any commment now here you can

[19:44:12 - 19:44:17]
give any query so I'll ask what is

[19:44:17 - 19:44:23]
python now send the request you can also

[19:44:20 - 19:44:24]
see the log in the terminal see I got

[19:44:23 - 19:44:27]
the response so this is the complete

[19:44:24 - 19:44:29]
response I got guys got it this is the

[19:44:27 - 19:44:30]
complete response I got now if you want

[19:44:29 - 19:44:33]
to ask another query just try to refresh

[19:44:30 - 19:44:34]
again you can pass that query okay now

[19:44:33 - 19:44:36]
that's how actually what you can do the

[19:44:34 - 19:44:38]
previous rag uh application we

[19:44:36 - 19:44:40]
implemented with the help of verx you

[19:44:38 - 19:44:42]
can create your custom rag that means

[19:44:40 - 19:44:44]
you can up use your custom documents

[19:44:42 - 19:44:46]
like uh we did one project like I think

[19:44:44 - 19:44:48]
remember medical chatbot so that's how

[19:44:46 - 19:44:49]
you can use your custom documents and

[19:44:48 - 19:44:51]
you can create this kinds of application

[19:44:49 - 19:44:52]
and this is the front end you can use as

[19:44:51 - 19:44:54]
it is got it all the HTML code I will

[19:44:52 - 19:44:56]
share with you so yes guys that's how we

[19:44:54 - 19:44:58]
can also create llm power application

[19:44:56 - 19:45:00]
with the help of vertex a so as I

[19:44:58 - 19:45:02]
already told you in the model Garden you

[19:45:00 - 19:45:04]
are having so many Foundation model and

[19:45:02 - 19:45:05]
if you want to F tune these are the

[19:45:04 - 19:45:07]
model so what are the step you have to

[19:45:05 - 19:45:09]
follow in this video I'll tell you each

[19:45:07 - 19:45:10]
and everything so I think remember

[19:45:09 - 19:45:12]
previously whenever we used to do the

[19:45:10 - 19:45:15]
find tuning operation first of all we

[19:45:12 - 19:45:18]
had to download that model in our system

[19:45:15 - 19:45:19]
then I Was preparing the data then I was

[19:45:18 - 19:45:21]
fine tuning these are the model but here

[19:45:19 - 19:45:23]
if you're using these kinds of llm Ops

[19:45:21 - 19:45:25]
platform you don't need to download the

[19:45:23 - 19:45:27]
other the model in your system so here

[19:45:25 - 19:45:28]
what you have to do you have to use that

[19:45:27 - 19:45:30]
model endpoint that means you will be

[19:45:28 - 19:45:32]
accessing this model through the API

[19:45:30 - 19:45:33]
right that means uh first of all you

[19:45:32 - 19:45:34]
have to authenticate with the verx I

[19:45:33 - 19:45:36]
think I already told you how to

[19:45:34 - 19:45:38]
authenticate with the verx a after that

[19:45:36 - 19:45:40]
just give the model ID which model you

[19:45:38 - 19:45:42]
want to use it will automatically hit

[19:45:40 - 19:45:44]
that model so here the only thing you

[19:45:42 - 19:45:45]
have to do you have to prepare your data

[19:45:44 - 19:45:48]
after that all the thing would be

[19:45:45 - 19:45:49]
happening in their server only okay now

[19:45:48 - 19:45:51]
let me tell you the STP actually you can

[19:45:49 - 19:45:52]
follow to perform the fine tuning

[19:45:51 - 19:45:54]
operation so for this what I will do

[19:45:52 - 19:45:55]
guys I will use the collab notebook so

[19:45:54 - 19:45:57]
I'll open up collab notebook you can

[19:45:55 - 19:45:59]
also use collab Enterprise you can also

[19:45:57 - 19:46:00]
do it from your local machine it's

[19:45:59 - 19:46:03]
completely fine but as of now we have

[19:46:00 - 19:46:05]
explored uh like V code we have also

[19:46:03 - 19:46:07]
explored like collab Enterprise now

[19:46:05 - 19:46:09]
let's try to see how we can also use the

[19:46:07 - 19:46:11]
collab okay like our Google collab so

[19:46:09 - 19:46:13]
here let me change my account so let's

[19:46:11 - 19:46:15]
say I'm going to use this account okay

[19:46:13 - 19:46:16]
this account actually I'm going to use

[19:46:15 - 19:46:17]
and make sure the account actually you

[19:46:16 - 19:46:19]
are using for the gcloud the same

[19:46:17 - 19:46:21]
account you have to use in the Google

[19:46:19 - 19:46:23]
Club as well okay otherwise uh you might

[19:46:21 - 19:46:24]
get some authentication issue now what I

[19:46:23 - 19:46:25]
will do guys I'll just create a new

[19:46:24 - 19:46:27]
notebook here so let me create a new

[19:46:25 - 19:46:29]
notebook now simply just connect this

[19:46:27 - 19:46:32]
notebook and in between let me show you

[19:46:29 - 19:46:34]
the fine tuning step you have to follow

[19:46:32 - 19:46:36]
so see you can follow this uh blog

[19:46:34 - 19:46:38]
actually so this is from actually Google

[19:46:36 - 19:46:40]
so Google developer so they have already

[19:46:38 - 19:46:41]
given all the step actually you have to

[19:46:40 - 19:46:43]
follow to perform the fine tuning

[19:46:41 - 19:46:45]
operation so I already prepared all the

[19:46:43 - 19:46:47]
steps you have to follow to perform the

[19:46:45 - 19:46:49]
fine tuning only I will show you one

[19:46:47 - 19:46:51]
thing from this blog actually the data

[19:46:49 - 19:46:53]
format okay so here let me show you the

[19:46:51 - 19:46:55]
preparation and loading the data see if

[19:46:53 - 19:46:58]
you're fine tuning on the vertx AI you

[19:46:55 - 19:47:00]
have to prepare your data in the uh Json

[19:46:58 - 19:47:02]
Json L format okay see this is the Json

[19:47:00 - 19:47:03]
L format data you can see so here they

[19:47:02 - 19:47:06]
have already given one example let me

[19:47:03 - 19:47:09]
open up so you can see this is the U

[19:47:06 - 19:47:11]
train juston L format data and it is

[19:47:09 - 19:47:12]
present inside this GitHub so what you

[19:47:11 - 19:47:14]
can do from this GitHub actually see

[19:47:12 - 19:47:16]
this is the data you can download this

[19:47:14 - 19:47:17]
data okay in your system you can

[19:47:16 - 19:47:18]
download this data so I've already

[19:47:17 - 19:47:20]
downloaded let me show you so this is

[19:47:18 - 19:47:22]
the data I'll open it with the notepad++

[19:47:20 - 19:47:24]
now if you open the data guys you will

[19:47:22 - 19:47:26]
see it's a Json okay Json structure that

[19:47:24 - 19:47:27]
means you will have one key here called

[19:47:26 - 19:47:29]
input text and this is the input text

[19:47:27 - 19:47:32]
and this is the BBC data guys okay BBC

[19:47:29 - 19:47:34]
News data so in the input text actually

[19:47:32 - 19:47:37]
they are having the entire news and

[19:47:34 - 19:47:39]
they're having another actually key here

[19:47:37 - 19:47:41]
let me show you or I can perform the

[19:47:39 - 19:47:43]
contr F operation now now here I will

[19:47:41 - 19:47:45]
just write

[19:47:43 - 19:47:49]
output underscore

[19:47:45 - 19:47:51]
text now if I find it now see guys this

[19:47:49 - 19:47:52]
is the output text okay so inside output

[19:47:51 - 19:47:55]
text actually what they are having they

[19:47:52 - 19:47:56]
are having the summary okay summary of

[19:47:55 - 19:47:58]
that news so this is the data actually

[19:47:56 - 19:47:59]
that's how actually you have to also

[19:47:58 - 19:48:01]
prepare your data if you're having any

[19:47:59 - 19:48:03]
custom data what you can do you can

[19:48:01 - 19:48:04]
prepare your data with respect to that

[19:48:03 - 19:48:07]
that means what I'm trying to say that

[19:48:04 - 19:48:09]
means in the Json uh file actually the

[19:48:07 - 19:48:12]
first key will have the

[19:48:09 - 19:48:14]
input okay in input _

[19:48:12 - 19:48:17]
text okay inside input text what you

[19:48:14 - 19:48:19]
will have you will have the entire story

[19:48:17 - 19:48:23]
okay entire story and you will have

[19:48:19 - 19:48:27]
another actually uh key called

[19:48:23 - 19:48:30]
output text sorry

[19:48:27 - 19:48:32]
output output text okay so inside output

[19:48:30 - 19:48:34]
text you will have the summary okay

[19:48:32 - 19:48:36]
summary of the entire story so this is

[19:48:34 - 19:48:38]
going to be your data format okay that's

[19:48:36 - 19:48:40]
why actually you can take as many as

[19:48:38 - 19:48:43]
record you can got it I hope now it is

[19:48:40 - 19:48:45]
clear the format uh so whatever dat you

[19:48:43 - 19:48:46]
are having try to convert in a jonl

[19:48:45 - 19:48:48]
format and how to convert in a JL format

[19:48:46 - 19:48:50]
there are so many converter you will see

[19:48:48 - 19:48:51]
inside python simply you can execute

[19:48:50 - 19:48:54]
those converter it will automatically

[19:48:51 - 19:48:56]
convert your data in a jol format got it

[19:48:54 - 19:48:57]
that is the idea now you can ask me sir

[19:48:56 - 19:48:59]
where I will get these kinds of data I

[19:48:57 - 19:49:01]
think I already told you now so you can

[19:48:59 - 19:49:03]
use hugging phase Hub actually so there

[19:49:01 - 19:49:05]
actually will have like so many kinds of

[19:49:03 - 19:49:06]
data set so you can use any kinds of

[19:49:05 - 19:49:07]
data from the hugging ph up you can

[19:49:06 - 19:49:09]
download it and you can convert to the

[19:49:07 - 19:49:11]
jonl format and if you're using your

[19:49:09 - 19:49:13]
custom data that time you have to

[19:49:11 - 19:49:14]
convert everything in a Jin format okay

[19:49:13 - 19:49:16]
this is the idea okay you can see the

[19:49:14 - 19:49:18]
image also they have already given the

[19:49:16 - 19:49:19]
data format so first of all you have to

[19:49:18 - 19:49:20]
take the input text this is the entire

[19:49:19 - 19:49:22]
BBC News you can see and this is the

[19:49:20 - 19:49:24]
output text just means this is the uh

[19:49:22 - 19:49:26]
summary of that uh story okay this

[19:49:24 - 19:49:27]
should be your data format now apart

[19:49:26 - 19:49:29]
from that they have already given all

[19:49:27 - 19:49:31]
the step you can follow so I've already

[19:49:29 - 19:49:32]
prepared one notebook let me show you

[19:49:31 - 19:49:36]
what other the thing you have to

[19:49:32 - 19:49:37]
do now let me also add this link in the

[19:49:36 - 19:49:41]
notebook so that you will have the

[19:49:37 - 19:49:41]
reference later on

[19:49:42 - 19:49:45]
so this is the link I have

[19:49:45 - 19:49:50]
added now here the first thing you have

[19:49:47 - 19:49:52]
to install some of the library so here

[19:49:50 - 19:49:53]
I'm going to uh install Google Cloud AI

[19:49:52 - 19:49:56]
platform because I want to access the

[19:49:53 - 19:49:57]
verx a then data sets then Google Cloud

[19:49:56 - 19:49:59]
pipeline components okay these are the

[19:49:57 - 19:50:01]
library I have to install one by one let

[19:49:59 - 19:50:03]
me

[19:50:01 - 19:50:05]
install so after installing these are

[19:50:03 - 19:50:07]
the library you have to restart the Kel

[19:50:05 - 19:50:09]
and if you want to restart the Kel you

[19:50:07 - 19:50:11]
can use this code snippit actually uh

[19:50:09 - 19:50:13]
see you can also do it from the UI just

[19:50:11 - 19:50:14]
click on the runtime restart the runtime

[19:50:13 - 19:50:16]
so there is a restart runtime option

[19:50:14 - 19:50:17]
okay restart the session otherwise you

[19:50:16 - 19:50:20]
can also execute this line of code it

[19:50:17 - 19:50:22]
will also restart the your run

[19:50:20 - 19:50:24]
time okay now what you have to do you

[19:50:22 - 19:50:27]
have to authenticate with your gcloud

[19:50:24 - 19:50:30]
account for this you can execute this

[19:50:27 - 19:50:32]
line of code so here I'm using actually

[19:50:30 - 19:50:33]
uh Google Authenticator with the help of

[19:50:32 - 19:50:35]
Google Authenticator actually I will

[19:50:33 - 19:50:37]
authenticate with my account got it so

[19:50:35 - 19:50:38]
now let me execute so it will look for

[19:50:37 - 19:50:41]
your account so it will give you one

[19:50:38 - 19:50:43]
popup screen let's give that

[19:50:41 - 19:50:45]
permission select your account let's say

[19:50:43 - 19:50:46]
I want to use this account because this

[19:50:45 - 19:50:49]
is my Google

[19:50:46 - 19:50:53]
account now I'll try to select

[19:50:49 - 19:50:53]
it now you have to provide the

[19:51:01 - 19:51:06]
password so guys as you can see my uh

[19:51:04 - 19:51:07]
authentication is completed there is no

[19:51:06 - 19:51:10]
error that means you are successfully

[19:51:07 - 19:51:12]
authenticate with your uh this one your

[19:51:10 - 19:51:13]
gcloud account fine all right now the

[19:51:12 - 19:51:15]
next thing you have to select the

[19:51:13 - 19:51:17]
project so to select the project you

[19:51:15 - 19:51:20]
have to execute this line of code so let

[19:51:17 - 19:51:22]
me select the

[19:51:20 - 19:51:24]
project so I think you know how to

[19:51:22 - 19:51:26]
select the project click here copy the

[19:51:24 - 19:51:26]
project

[19:51:28 - 19:51:33]
ID and just try to mention it here and

[19:51:31 - 19:51:35]
with this actually we'll be initializing

[19:51:33 - 19:51:38]
our vertic so let me initialize my

[19:51:35 - 19:51:40]
verx then let's say uh set some actually

[19:51:38 - 19:51:42]
variable that means my region and the

[19:51:40 - 19:51:44]
project ID again I'll will give the same

[19:51:42 - 19:51:44]
project

[19:51:48 - 19:51:52]
ID now I have to set one configuration

[19:51:50 - 19:51:54]
here for this you have to execute this

[19:51:52 - 19:51:56]
line of

[19:51:54 - 19:51:59]
quot okay you have to execute this

[19:51:56 - 19:52:00]
command gcloud config set project this

[19:51:59 - 19:52:05]
is the project ID okay the project ID

[19:52:00 - 19:52:05]
actually I'm having here now let me

[19:52:06 - 19:52:11]
set fine now let's import some necessary

[19:52:08 - 19:52:12]
Library

[19:52:11 - 19:52:14]
so guys you can see I'm importing some

[19:52:12 - 19:52:16]
necessary library now you can ask me

[19:52:14 - 19:52:20]
from where actually I got this code if

[19:52:16 - 19:52:21]
you go to that uh uh blog actually so

[19:52:20 - 19:52:22]
they actually they are suggesting

[19:52:21 - 19:52:24]
install and import see they're also

[19:52:22 - 19:52:26]
importing these are the library okay so

[19:52:24 - 19:52:27]
just try to read this blog actually will

[19:52:26 - 19:52:28]
see all the steps actually they have

[19:52:27 - 19:52:30]
written I'm following the same thing

[19:52:28 - 19:52:32]
only now let me import all of the

[19:52:30 - 19:52:34]
library okay so I have imported all the

[19:52:32 - 19:52:37]
library now the next thing uh I will

[19:52:34 - 19:52:39]
load my data so let's upload my data

[19:52:37 - 19:52:41]
either you can upload in the gcloud

[19:52:39 - 19:52:42]
bucket so from the bucket also you can

[19:52:41 - 19:52:43]
download the data if if you're having

[19:52:42 - 19:52:45]
let's say use data that time you can

[19:52:43 - 19:52:47]
keep in the bucket I think I told you so

[19:52:45 - 19:52:49]
it is already having one bucket Service

[19:52:47 - 19:52:51]
as well so you can also open up the

[19:52:49 - 19:52:53]
bucket inside that you can store any

[19:52:51 - 19:52:55]
kinds of data and you can also load it

[19:52:53 - 19:52:57]
here okay so if I show you the bucket so

[19:52:55 - 19:52:59]
this is the bucket guys so here my data

[19:52:57 - 19:53:02]
size is not used so what I will do I'll

[19:52:59 - 19:53:04]
directly upload here so I'll just upload

[19:53:02 - 19:53:07]
this is the

[19:53:04 - 19:53:09]
data now with the help of pandas

[19:53:07 - 19:53:11]
actually I'm going to load my data so

[19:53:09 - 19:53:13]
now we can call Cy the

[19:53:11 - 19:53:16]
path

[19:53:13 - 19:53:19]
and you can paste it here now let's

[19:53:16 - 19:53:20]
execute okay see this is the data I have

[19:53:19 - 19:53:22]
loaded now you can see this is the input

[19:53:20 - 19:53:23]
text and this is the output testt now if

[19:53:22 - 19:53:25]
you want to see the shape of the data

[19:53:23 - 19:53:27]
you can also see this is the shape of

[19:53:25 - 19:53:28]
the data and now we can start the

[19:53:27 - 19:53:30]
training and it's like very easy see

[19:53:28 - 19:53:31]
only you just need to execute this line

[19:53:30 - 19:53:33]
of code your training would be started

[19:53:31 - 19:53:35]
in their server only okay not in my

[19:53:33 - 19:53:38]
Google collab actually uh it will use

[19:53:35 - 19:53:40]
their instance got it now see here is my

[19:53:38 - 19:53:42]
fine tune model name so this model name

[19:53:40 - 19:53:44]
actually I'm giving BBC fine model you

[19:53:42 - 19:53:45]
can give any name so after fineing what

[19:53:44 - 19:53:47]
would be your model name okay that is

[19:53:45 - 19:53:49]
what you have to give here then you can

[19:53:47 - 19:53:50]
give the Preen model that means which

[19:53:49 - 19:53:53]
model you want to find you here I want

[19:53:50 - 19:53:54]
to find text Bon 002 model and if you go

[19:53:53 - 19:53:56]
to the model Garden you will see this

[19:53:54 - 19:53:57]
particular model and if you want to use

[19:53:56 - 19:53:59]
any other model you can also give the

[19:53:57 - 19:54:01]
model ID here got it that's the thing

[19:53:59 - 19:54:03]
now you have to pass the data that P by

[19:54:01 - 19:54:05]
DF the DF actually I got and you have to

[19:54:03 - 19:54:07]
set the number of epoch training Epoch

[19:54:05 - 19:54:08]
you want to let's say train so here I

[19:54:07 - 19:54:10]
mentioned 100 Epoch okay I want to train

[19:54:08 - 19:54:12]
as of now and you have to give that

[19:54:10 - 19:54:14]
tuning job location okay so I have given

[19:54:12 - 19:54:16]
EUR W 4 you can keep the default size if

[19:54:14 - 19:54:17]
you go to the like blog you will see

[19:54:16 - 19:54:19]
that they are also using this particular

[19:54:17 - 19:54:22]
location now see if I execute the

[19:54:19 - 19:54:24]
program it will give me one URL and if I

[19:54:22 - 19:54:26]
click on the URL I I can see the

[19:54:24 - 19:54:28]
pipeline that isans completely uh that

[19:54:26 - 19:54:31]
means I can see the complete pipeline my

[19:54:28 - 19:54:33]
training process is running and it will

[19:54:31 - 19:54:34]
take guys uh like one to two hours to

[19:54:33 - 19:54:35]
complete the training but I can't wait

[19:54:34 - 19:54:38]
one to two hours what I will do I'll

[19:54:35 - 19:54:39]
stop the execution so guys I stop the

[19:54:38 - 19:54:41]
execution because it will take time see

[19:54:39 - 19:54:44]
I'm telling you after actually executing

[19:54:41 - 19:54:45]
this line of code what you have to do so

[19:54:44 - 19:54:48]
you can see one URL just try to open up

[19:54:45 - 19:54:49]
the URL so this is the URL guys and try

[19:54:48 - 19:54:52]
to make make sure you have selected your

[19:54:49 - 19:54:54]
account okay that gcp account then you

[19:54:52 - 19:54:55]
can see this pipeline okay this uh

[19:54:54 - 19:54:57]
pipeline would be running and this is

[19:54:55 - 19:54:58]
the jobs so here you will see all the

[19:54:57 - 19:55:00]
let's say logs so in the pipeline

[19:54:58 - 19:55:01]
section you will see all the logs that

[19:55:00 - 19:55:03]
means whether your training is running

[19:55:01 - 19:55:04]
or not okay and how how how much time

[19:55:03 - 19:55:06]
actually it will take to complete so

[19:55:04 - 19:55:08]
everything all the log actually you can

[19:55:06 - 19:55:10]
see here got it so once this execution

[19:55:08 - 19:55:12]
is completed you will see it will

[19:55:10 - 19:55:15]
automatically stop after that your model

[19:55:12 - 19:55:16]
would be ready okay and then you can use

[19:55:15 - 19:55:17]
this model and if you want to delete

[19:55:16 - 19:55:18]
this pipeline so what you have to do

[19:55:17 - 19:55:20]
guys so there is a delete button just

[19:55:18 - 19:55:22]
try to click on the delete and try to

[19:55:20 - 19:55:24]
delete the pipeline okay it will

[19:55:22 - 19:55:26]
automatically delete the instance okay

[19:55:24 - 19:55:27]
and guys one thing after completing the

[19:55:26 - 19:55:29]
training if you open up your bucket you

[19:55:27 - 19:55:30]
will see two bucket would be

[19:55:29 - 19:55:32]
automatically created okay and inside

[19:55:30 - 19:55:34]
this bucket actually it will save all

[19:55:32 - 19:55:35]
the model checkpoints okay let's say

[19:55:34 - 19:55:37]
whatever training it is doing all the

[19:55:35 - 19:55:39]
artifacts would be saved inside this

[19:55:37 - 19:55:41]
bucket itself okay you can see but once

[19:55:39 - 19:55:43]
you complete the execution see it is it

[19:55:41 - 19:55:45]
will already save the tune model okay

[19:55:43 - 19:55:47]
inside that that you can see the text B

[19:55:45 - 19:55:48]
model got it so that's how actually it

[19:55:47 - 19:55:50]
will save all the artifacts in the

[19:55:48 - 19:55:52]
bucket and from this bucket itself we

[19:55:50 - 19:55:53]
have to deploy our model as an end point

[19:55:52 - 19:55:56]
okay and this model would be available

[19:55:53 - 19:55:58]
in your model Garden so if you click on

[19:55:56 - 19:56:01]
the model Garden so there you will see

[19:55:58 - 19:56:03]
one option so here is the option my uh

[19:56:01 - 19:56:04]
view my endpoint and model if you click

[19:56:03 - 19:56:06]
here you will see that that model would

[19:56:04 - 19:56:08]
be present here okay I hope it is clear

[19:56:06 - 19:56:10]
now let me show you the next step you

[19:56:08 - 19:56:12]
have to perform so previously I already

[19:56:10 - 19:56:14]
did this actually uh find un name so let

[19:56:12 - 19:56:16]
me show you what you have to do after

[19:56:14 - 19:56:19]
that see after that actually what you

[19:56:16 - 19:56:20]
can do you can use your train model that

[19:56:19 - 19:56:22]
means the model actually you have

[19:56:20 - 19:56:24]
trained and you can do the inference

[19:56:22 - 19:56:26]
operation so here I'm giving this uh

[19:56:24 - 19:56:29]
actually uh prompt actually summarize

[19:56:26 - 19:56:31]
this text to generate uh generate a

[19:56:29 - 19:56:33]
title so this is the entire actually

[19:56:31 - 19:56:34]
prompt I'm giving and this is the output

[19:56:33 - 19:56:36]
actually I'm getting got it now you have

[19:56:34 - 19:56:38]
to deploy your model as an end point for

[19:56:36 - 19:56:40]
this you have to execute this line of

[19:56:38 - 19:56:42]
code okay so this will uh like deploy

[19:56:40 - 19:56:43]
your model as an endo okay to the gcp

[19:56:42 - 19:56:46]
server that means this model would be

[19:56:43 - 19:56:48]
available in your model Garden right now

[19:56:46 - 19:56:50]
so if I go to the model Garden so here

[19:56:48 - 19:56:52]
you will see one option view my endpoint

[19:56:50 - 19:56:53]
and model just click here in this

[19:56:52 - 19:56:55]
section actually will see your model

[19:56:53 - 19:56:56]
would be published okay from here

[19:56:55 - 19:56:58]
actually it will load the model but what

[19:56:56 - 19:57:00]
I did actually I deleted the model

[19:56:58 - 19:57:01]
because again I'm using Cloud platform I

[19:57:00 - 19:57:02]
don't want to keep anything okay

[19:57:01 - 19:57:04]
otherwise it will charge me so that's

[19:57:02 - 19:57:06]
why I already deleted okay then after

[19:57:04 - 19:57:08]
that I was loading that model and I was

[19:57:06 - 19:57:09]
again performing the prediction you can

[19:57:08 - 19:57:11]
see this is the results actually I'm

[19:57:09 - 19:57:13]
getting from my model then I was also

[19:57:11 - 19:57:15]
loading the base model that means the

[19:57:13 - 19:57:16]
actual model and I given the same

[19:57:15 - 19:57:18]
actually prompt and I was just checking

[19:57:16 - 19:57:21]
the actually output okay whether this

[19:57:18 - 19:57:23]
output and this output uh actually good

[19:57:21 - 19:57:25]
or not that means which model is giving

[19:57:23 - 19:57:27]
the better output and here you can see

[19:57:25 - 19:57:29]
both model uh giving the good response

[19:57:27 - 19:57:31]
okay it's not a bad although I only

[19:57:29 - 19:57:33]
trained 100 Depo but you can see this

[19:57:31 - 19:57:35]
response is pretty good got it so that's

[19:57:33 - 19:57:36]
how actually you can perform the fineing

[19:57:35 - 19:57:39]
operation after that you can deploy your

[19:57:36 - 19:57:41]
model as an end point to the uh gcloud

[19:57:39 - 19:57:43]
okay now I I think it is clear now you

[19:57:41 - 19:57:45]
can pick up any other model and you can

[19:57:43 - 19:57:47]
perform the same F tring operation all

[19:57:45 - 19:57:48]
right so this resources would be shared

[19:57:47 - 19:57:50]
guys in your resources section from

[19:57:48 - 19:57:51]
there you can uh download this notebook

[19:57:50 - 19:57:54]
and you can perform the fine tuning

[19:57:51 - 19:57:56]
operation so guys uh as of now we have

[19:57:54 - 19:57:59]
seen the uh vertx a demo the complete

[19:57:56 - 19:58:00]
let's say verx a demo we have seen we

[19:57:59 - 19:58:02]
have implemented different different

[19:58:00 - 19:58:04]
kinds of application with the help of

[19:58:02 - 19:58:07]
vertx a so now it's time to explore

[19:58:04 - 19:58:09]
another H name ofs platform called AWS

[19:58:07 - 19:58:11]
badrock so this uh servic is available

[19:58:09 - 19:58:14]
in the AWS Cloud so make sure you have

[19:58:11 - 19:58:15]
the AWS account so if you don't have the

[19:58:14 - 19:58:17]
account just try to create one account

[19:58:15 - 19:58:18]
initially it will give you $300 free

[19:58:17 - 19:58:20]
credit but you have to add your card

[19:58:18 - 19:58:22]
there got it so after login with your

[19:58:20 - 19:58:24]
console so you will get these kinds of

[19:58:22 - 19:58:26]
window okay in the AWS so this is my

[19:58:24 - 19:58:28]
console so now here what you have to do

[19:58:26 - 19:58:32]
you have to search for bedro so let me

[19:58:28 - 19:58:34]
search so see Amazon bedro and this is

[19:58:32 - 19:58:36]
the service actually the easiest way to

[19:58:34 - 19:58:38]
build anale gen application with the

[19:58:36 - 19:58:41]
foundation model so let me open up the B

[19:58:38 - 19:58:43]
drop m

[19:58:41 - 19:58:45]
now I'll just click on get started see

[19:58:43 - 19:58:46]
if you're opening for the first time

[19:58:45 - 19:58:48]
this Bedrock what you have to do you

[19:58:46 - 19:58:50]
have to request for the model access so

[19:58:48 - 19:58:51]
there is a button you will see request

[19:58:50 - 19:58:54]
model access just try to click here and

[19:58:51 - 19:58:55]
see for me I already requested the model

[19:58:54 - 19:58:57]
okay for me I already requested the

[19:58:55 - 19:58:58]
model and I got the access you can see

[19:58:57 - 19:59:00]
some of the model actually they didn't

[19:58:58 - 19:59:01]
given me the access for this what I have

[19:59:00 - 19:59:04]
to do I have to again uh let's say

[19:59:01 - 19:59:06]
resubmit the access request then I think

[19:59:04 - 19:59:08]
I might get but for you what you will do

[19:59:06 - 19:59:10]
you will select all the model and try to

[19:59:08 - 19:59:12]
send the request okay send the request

[19:59:10 - 19:59:13]
will see that in 5 to 10 minutes

[19:59:12 - 19:59:16]
actually they will provide the access

[19:59:13 - 19:59:18]
got it and make sure you check your

[19:59:16 - 19:59:19]
region actually in which region actually

[19:59:18 - 19:59:21]
you are sending the request okay because

[19:59:19 - 19:59:22]
that in that region actually your model

[19:59:21 - 19:59:24]
would be available so I'm currently

[19:59:22 - 19:59:26]
inside AP South one that means Asia

[19:59:24 - 19:59:28]
Pacific Mumbai okay so now if I go to

[19:59:26 - 19:59:30]
any other region let me show you so if I

[19:59:28 - 19:59:32]
let's say go to North Virginia so there

[19:59:30 - 19:59:35]
you will able to see I don't have any

[19:59:32 - 19:59:35]
access of any

[19:59:35 - 19:59:40]
model now see it will show you these

[19:59:38 - 19:59:43]
kinds of window enable all model okay

[19:59:40 - 19:59:46]
now if I click here now just select all

[19:59:43 - 19:59:49]
the model and try to click on the next

[19:59:46 - 19:59:51]
okay now you have to submit the request

[19:59:49 - 19:59:54]
okay you have to submit the request so

[19:59:51 - 19:59:54]
let's submit the

[19:59:54 - 19:59:59]
request sometimes actually they will ask

[19:59:56 - 20:00:00]
for some information so you also need to

[19:59:59 - 20:00:02]
uh let's submit some information let's

[20:00:00 - 20:00:04]
say your name email address okay then

[20:00:02 - 20:00:06]
you can send the request after sending

[20:00:04 - 20:00:07]
the request in 5 to 10 minutes you will

[20:00:06 - 20:00:09]
see that they will give you the model

[20:00:07 - 20:00:12]
access so guys you can see after sending

[20:00:09 - 20:00:14]
the request actually I got the access

[20:00:12 - 20:00:16]
you can see granted access and some of

[20:00:14 - 20:00:17]
the model you can see it is still in

[20:00:16 - 20:00:19]
progress so I think it will take some

[20:00:17 - 20:00:20]
time to give me the access okay so

[20:00:19 - 20:00:22]
that's actually you can apply for the

[20:00:20 - 20:00:24]
access so once you got the access that

[20:00:22 - 20:00:26]
means congratulations now you can start

[20:00:24 - 20:00:28]
with the Bedrock services that means now

[20:00:26 - 20:00:30]
you got all the let's say access of the

[20:00:28 - 20:00:34]
foundation model now let me get back to

[20:00:30 - 20:00:39]
my that region actually mbai

[20:00:34 - 20:00:41]
region H now see this is your bedrock

[20:00:39 - 20:00:43]
interface if I click on the overview now

[20:00:41 - 20:00:44]
you are having different different

[20:00:43 - 20:00:45]
Foundation model here and what is

[20:00:44 - 20:00:47]
foundation model I already told you

[20:00:45 - 20:00:49]
these are large language model and

[20:00:47 - 20:00:51]
different different companies also has

[20:00:49 - 20:00:52]
collaborated with the AWS even they have

[20:00:51 - 20:00:55]
also published their model like you can

[20:00:52 - 20:00:57]
see Amazon is having their own model

[20:00:55 - 20:01:01]
apart from that cloud has like updated

[20:00:57 - 20:01:03]
their model then coh Lama mistal okay so

[20:01:01 - 20:01:05]
you can see all the provider okay all

[20:01:03 - 20:01:07]
the provider they have collaborated with

[20:01:05 - 20:01:10]
the AWS and they hosted their model on

[20:01:07 - 20:01:11]
the AWS that means AWS bed drop okay now

[20:01:10 - 20:01:13]
what you can do you can access the the

[20:01:11 - 20:01:14]
model through API got it so you don't

[20:01:13 - 20:01:17]
need to download the the model in your

[20:01:14 - 20:01:18]
system that is the m Advantage here now

[20:01:17 - 20:01:21]
you can also play with the playground

[20:01:18 - 20:01:22]
let's say if I click on the chat so here

[20:01:21 - 20:01:25]
is the chat guys so you can select the

[20:01:22 - 20:01:29]
model let's I want to select this model

[20:01:25 - 20:01:30]
um let's say I'll select this llama 3 8

[20:01:29 - 20:01:32]
billion instruct

[20:01:30 - 20:01:35]
model now if I send any request let's

[20:01:32 - 20:01:35]
say

[20:01:36 - 20:01:41]
hello let say this is my prompt now see

[20:01:39 - 20:01:42]
it is giving me the answer so that's how

[20:01:41 - 20:01:44]
actually it is having different

[20:01:42 - 20:01:45]
different kinds of playground text

[20:01:44 - 20:01:47]
playground chat playground image

[20:01:45 - 20:01:49]
playground because it is also having

[20:01:47 - 20:01:51]
multimodel as well so you can see here

[20:01:49 - 20:01:53]
different different model let's say I

[20:01:51 - 20:01:55]
you want to use this uh uh Amazon model

[20:01:53 - 20:01:58]
so just try to click here see all kinds

[20:01:55 - 20:02:02]
of Amazon model you'll be able to see it

[20:01:58 - 20:02:04]
is having Titan uh text G1 light Titan

[20:02:02 - 20:02:07]
text G1 Express okay Titan image

[20:02:04 - 20:02:09]
generator then uh Titan multimodel

[20:02:07 - 20:02:10]
embeddings now if you want to use let's

[20:02:09 - 20:02:12]
say this model what you can do you need

[20:02:10 - 20:02:14]
to just copy the model ID so this is the

[20:02:12 - 20:02:16]
model ID and with the help of model ID

[20:02:14 - 20:02:18]
you can use it similar wise for The Meta

[20:02:16 - 20:02:20]
Also let's say you want to access llama

[20:02:18 - 20:02:22]
okay llama model you can see so for this

[20:02:20 - 20:02:24]
you have to use this uh you have to use

[20:02:22 - 20:02:26]
this model ID okay even from here also

[20:02:24 - 20:02:27]
you can directly open in the playground

[20:02:26 - 20:02:29]
and you can also play with these other

[20:02:27 - 20:02:30]
the model even if you go to the example

[20:02:29 - 20:02:32]
section they have given different

[20:02:30 - 20:02:33]
different example even you can also copy

[20:02:32 - 20:02:35]
these are the code and you can execute

[20:02:33 - 20:02:36]
in your system now let's click on the

[20:02:35 - 20:02:38]
Bas model you can see different

[20:02:36 - 20:02:40]
different kinds of base model it is also

[20:02:38 - 20:02:42]
having even if you want to train your

[20:02:40 - 20:02:44]
custom model it is also possible just go

[20:02:42 - 20:02:46]
to the custom model you can also perform

[20:02:44 - 20:02:47]
the fine tuning operation so from the UI

[20:02:46 - 20:02:49]
itself you can do the fine tuning

[20:02:47 - 20:02:52]
operation even let's say after fining

[20:02:49 - 20:02:54]
you can also keep your model here okay

[20:02:52 - 20:02:57]
in the custom model section so that you

[20:02:54 - 20:02:58]
can load this model as an API okay every

[20:02:57 - 20:03:01]
functionality actually this Bedrock will

[20:02:58 - 20:03:03]
give you so you can use them so yes this

[20:03:01 - 20:03:05]
is the overview of our Amazon Bedrock

[20:03:03 - 20:03:06]
that means it's a platform it's LM of

[20:03:05 - 20:03:08]
platform here we are having different

[20:03:06 - 20:03:10]
different kinds of foundation model even

[20:03:08 - 20:03:11]
all the functionality it is also

[20:03:10 - 20:03:12]
provides with the help of these are the

[20:03:11 - 20:03:15]
functionality you can create any kinds

[20:03:12 - 20:03:16]
of gni based application so in the next

[20:03:15 - 20:03:20]
video what we'll do guys we'll just try

[20:03:16 - 20:03:23]
to uh uh do the handson on this uh AWS B

[20:03:20 - 20:03:24]
drop that means we'll be accessing these

[20:03:23 - 20:03:26]
are the foundation model through the

[20:03:24 - 20:03:28]
python okay python code this video we'll

[20:03:26 - 20:03:30]
be learning uh how we can let's say

[20:03:28 - 20:03:32]
access this kinds of foundation model uh

[20:03:30 - 20:03:33]
without python code that means we'll be

[20:03:32 - 20:03:35]
set uping everything in our local

[20:03:33 - 20:03:37]
machine I will be writing everything

[20:03:35 - 20:03:40]
from our V code okay so what I will do

[20:03:37 - 20:03:42]
guys uh I'll open up my local folder and

[20:03:40 - 20:03:44]
here I've already created one empty

[20:03:42 - 20:03:46]
folder let me open up my

[20:03:44 - 20:03:48]
vspot okay so I'm also going to open up

[20:03:46 - 20:03:49]
my terminal here and make sure you

[20:03:48 - 20:03:51]
create one environment so for me I

[20:03:49 - 20:03:53]
already created one environment so let

[20:03:51 - 20:03:56]
me activate so cond

[20:03:53 - 20:03:58]
activate llm app I think remember this

[20:03:56 - 20:04:00]
uh environment we created previously so

[20:03:58 - 20:04:02]
I'm using the same environment here and

[20:04:00 - 20:04:06]
you can see the python version I'm using

[20:04:02 - 20:04:07]
it's 3.10 so you can use 3.9 3.8 it's up

[20:04:06 - 20:04:09]
to

[20:04:07 - 20:04:11]
you okay here then first thing you have

[20:04:09 - 20:04:15]
to set up the requirements so let me

[20:04:11 - 20:04:15]
create a file called

[20:04:16 - 20:04:20]
requirements. dxt inside that let me

[20:04:18 - 20:04:23]
mention all the requirements actually I

[20:04:20 - 20:04:26]
need so I need the

[20:04:23 - 20:04:27]
langin then I also need stream Le

[20:04:26 - 20:04:31]
because I'm going to create a small

[20:04:27 - 20:04:32]
let's say user interface here and I need

[20:04:31 - 20:04:36]
two more

[20:04:32 - 20:04:38]
Library boto three and python. python. I

[20:04:36 - 20:04:41]
think you know why we need it because we

[20:04:38 - 20:04:45]
here we're going to create one EnV

[20:04:41 - 20:04:47]
file okay EnV file so inside that you

[20:04:45 - 20:04:49]
have to mention the um I mean your

[20:04:47 - 20:04:50]
secret credential that means we'll be

[20:04:49 - 20:04:53]
generating access key AWS access key and

[20:04:50 - 20:04:54]
AWS secret access key with the help of

[20:04:53 - 20:04:56]
that we'll be authenticating with our

[20:04:54 - 20:04:57]
AWS account got it so we'll be uh

[20:04:56 - 20:05:00]
keeping these are the key inside this

[20:04:57 - 20:05:02]
EnV file and to load it I need this

[20:05:00 - 20:05:04]
python. EnV and what is boto 3C with the

[20:05:02 - 20:05:06]
help of boto 3 python package will be

[20:05:04 - 20:05:07]
making the connection with our AWS okay

[20:05:06 - 20:05:09]
so this Library will give you the

[20:05:07 - 20:05:11]
functionality you can connect with your

[20:05:09 - 20:05:13]
a this now let me set up everything in

[20:05:11 - 20:05:16]
my environment so I'll open it up and

[20:05:13 - 20:05:16]
just write P

[20:05:17 - 20:05:23]
install requirement.

[20:05:20 - 20:05:26]
dxt okay for me it is already installed

[20:05:23 - 20:05:28]
for you it it will take some time now

[20:05:26 - 20:05:30]
the next thing what I have to do guys uh

[20:05:28 - 20:05:32]
I have to create a im am user so let's

[20:05:30 - 20:05:32]
go to my

[20:05:33 - 20:05:39]
AWS I'll go to the homepage and here you

[20:05:36 - 20:05:42]
will see or you can also search I am

[20:05:39 - 20:05:44]
okay identity access management because

[20:05:42 - 20:05:46]
I have to create an user and there

[20:05:44 - 20:05:49]
actually I will only give the permission

[20:05:46 - 20:05:51]
related my Bedrock I click on the

[20:05:49 - 20:05:53]
user now just create a user here I'll

[20:05:51 - 20:05:55]
give let's say

[20:05:53 - 20:05:58]
Bedrock

[20:05:55 - 20:06:00]
test attach

[20:05:58 - 20:06:01]
policy Now search for bedro I want to

[20:06:00 - 20:06:05]
give the

[20:06:01 - 20:06:08]
bedro Amazon bedro full access now click

[20:06:05 - 20:06:10]
on the next and create the

[20:06:08 - 20:06:12]
user then after that I will click on

[20:06:10 - 20:06:14]
Bedrock test and go to the security

[20:06:12 - 20:06:16]
credential and here you'll get one

[20:06:14 - 20:06:18]
option uh create access key just try to

[20:06:16 - 20:06:21]
click here uh select common line

[20:06:18 - 20:06:24]
interface I understand and click on the

[20:06:21 - 20:06:26]
next now create the access

[20:06:24 - 20:06:28]
key now so guys this is your access key

[20:06:26 - 20:06:29]
and this is your secret access key now

[20:06:28 - 20:06:32]
you can also download as a CSV file let

[20:06:29 - 20:06:33]
me download now I have to configure it

[20:06:32 - 20:06:37]
so for this you have to install one tool

[20:06:33 - 20:06:40]
actually so just search for AWS

[20:06:37 - 20:06:42]
CLI okay AWS CLI

[20:06:40 - 20:06:44]
this is the first website you can open

[20:06:42 - 20:06:45]
so for all the operating system they

[20:06:44 - 20:06:48]
have mentioned okay how we can install

[20:06:45 - 20:06:50]
it for Linux Mac macway okay see Linux

[20:06:48 - 20:06:51]
you have to execute some of the command

[20:06:50 - 20:06:53]
these are the command you have to

[20:06:51 - 20:06:54]
execute for Mac wise also you have to

[20:06:53 - 20:06:57]
execute some of the command and for

[20:06:54 - 20:06:59]
Windows you are having one MSI file so

[20:06:57 - 20:07:01]
you can directly download this MSI file

[20:06:59 - 20:07:03]
and you can you can install Okay as a

[20:07:01 - 20:07:05]
software that means the way you usually

[20:07:03 - 20:07:07]
install any software now next next

[20:07:05 - 20:07:08]
install you have to do the same thing

[20:07:07 - 20:07:10]
after doing it let me cancel it because

[20:07:08 - 20:07:13]
I already have after doing it just try

[20:07:10 - 20:07:15]
to open up your terminal okay and

[20:07:13 - 20:07:17]
execute this command AWS

[20:07:15 - 20:07:19]
configure AWS configure now see if I

[20:07:17 - 20:07:20]
execute it should give you these kinds

[20:07:19 - 20:07:21]
of window if you're getting these kinds

[20:07:20 - 20:07:23]
of window that means your installation

[20:07:21 - 20:07:25]
is fine now what I have to do guys I

[20:07:23 - 20:07:28]
have to set this at the access key now

[20:07:25 - 20:07:29]
just try to copy the access key open the

[20:07:28 - 20:07:31]
terminal and it is asking for the access

[20:07:29 - 20:07:33]
key just try to paste just right click

[20:07:31 - 20:07:34]
it will paste and press enter Then you

[20:07:33 - 20:07:36]
have to give the secret access key just

[20:07:34 - 20:07:38]
try to copy this is my secret access key

[20:07:36 - 20:07:40]
and I'll paste it here and don't share

[20:07:38 - 20:07:41]
guys this key with anyone otherwise they

[20:07:40 - 20:07:43]
will be also accessing your account I

[20:07:41 - 20:07:45]
will delete it after the recording and

[20:07:43 - 20:07:46]
now it is asking for the region now you

[20:07:45 - 20:07:48]
can see which region you are in I'm

[20:07:46 - 20:07:50]
inside mumai that means AP South one so

[20:07:48 - 20:07:52]
I have to give the reason so you just

[20:07:50 - 20:07:56]
check which reason you are working on

[20:07:52 - 20:08:00]
based on that you can decide so AP

[20:07:56 - 20:08:02]
South one Now default output format just

[20:08:00 - 20:08:05]
keep it empty press enter that's it see

[20:08:02 - 20:08:06]
my credential has been set so this was

[20:08:05 - 20:08:08]
the first method and the second method

[20:08:06 - 20:08:10]
what you can do you

[20:08:08 - 20:08:13]
can uh I think you remember we created

[20:08:10 - 20:08:13]
this EnV

[20:08:14 - 20:08:19]
file so here inside EnV file also you

[20:08:17 - 20:08:22]
can mention so let me show you so inside

[20:08:19 - 20:08:24]
that you can mention AWS access key ID

[20:08:22 - 20:08:27]
secret key ID and region name so let me

[20:08:24 - 20:08:30]
replace all of the secret key again is

[20:08:27 - 20:08:30]
my access key

[20:08:37 - 20:08:41]
ID and this is my secret access

[20:08:44 - 20:08:48]
and sou one it's fine now let me save

[20:08:46 - 20:08:52]
now here I'm going to create a file I'll

[20:08:48 - 20:08:54]
name it as main do PI inside that I'm

[20:08:52 - 20:08:56]
going to do the coding so here first of

[20:08:54 - 20:08:58]
all let's import some librar so these

[20:08:56 - 20:09:01]
are the library I need let me select my

[20:08:58 - 20:09:03]
environment uh llm app I'm using now

[20:09:01 - 20:09:05]
here you can see guys I'm importing

[20:09:03 - 20:09:07]
Bedrock from Lang Chen Lang chen. LM

[20:09:05 - 20:09:11]
Bedrock I'm inputting Bedrock then llm

[20:09:07 - 20:09:13]
chain then prompt template boto 3 and

[20:09:11 - 20:09:16]
stream lit okay then I need another

[20:09:13 - 20:09:18]
package uh this uh one actually because

[20:09:16 - 20:09:20]
I want to load this at the credential

[20:09:18 - 20:09:22]
and how to load guys I think remembered

[20:09:20 - 20:09:25]
so you have to use this code snippit so

[20:09:22 - 20:09:27]
load ENB and you also need operating

[20:09:25 - 20:09:29]
system with help of operating system

[20:09:27 - 20:09:30]
we'll be loading these are the key okay

[20:09:29 - 20:09:33]
from the environment variable now here

[20:09:30 - 20:09:35]
it will restore everything now if I want

[20:09:33 - 20:09:37]
to initialize Bedrock client so I have

[20:09:35 - 20:09:40]
to use boto 3 so this is the

[20:09:37 - 20:09:41]
syntax if you go to the documentation

[20:09:40 - 20:09:42]
you will see that they're using this

[20:09:41 - 20:09:45]
synx Bedrock client you have to make a

[20:09:42 - 20:09:46]
Bedrock client now boto three client you

[20:09:45 - 20:09:48]
have to mention the service name I want

[20:09:46 - 20:09:49]
to use Bedrock okay Bedrock Services

[20:09:48 - 20:09:51]
that's why I've given Bedrock run time

[20:09:49 - 20:09:53]
you have to give the region AWS access

[20:09:51 - 20:09:54]
key ID and secret key ID so with the

[20:09:53 - 20:09:57]
help of that it will authenticate with

[20:09:54 - 20:10:00]
your account okay I hope it is clear now

[20:09:57 - 20:10:01]
the next thing you have to give the

[20:10:00 - 20:10:05]
model ID like which model you want to

[20:10:01 - 20:10:07]
access I'll give the model ID is equal

[20:10:05 - 20:10:09]
to let's say I want to use one

[20:10:07 - 20:10:11]
Foundation model

[20:10:09 - 20:10:13]
let's say I want to use this mistal

[20:10:11 - 20:10:14]
model I'll click on mistal now you can

[20:10:13 - 20:10:19]
see mistal having different different

[20:10:14 - 20:10:20]
variants 7B 8X 7B then Mr Large now

[20:10:19 - 20:10:23]
let's I want to use srct so what I will

[20:10:20 - 20:10:25]
do I'll copy this model ID so that's how

[20:10:23 - 20:10:27]
just try to open any kinds of model and

[20:10:25 - 20:10:30]
copy the model ID and here you just need

[20:10:27 - 20:10:32]
to mention it that's it okay so it will

[20:10:30 - 20:10:35]
automatically load this model now let's

[20:10:32 - 20:10:38]
create our llm rapper so inside Bedrock

[20:10:35 - 20:10:40]
you have to give the model ID okay and

[20:10:38 - 20:10:43]
here you have to give the Bedrock

[20:10:40 - 20:10:45]
client okay client is equal to bed drop

[20:10:43 - 20:10:46]
fine and this is the temperature

[20:10:45 - 20:10:48]
parameter that means the creativity

[20:10:46 - 20:10:50]
parameter I think you already know now

[20:10:48 - 20:10:53]
here I'm going to create a

[20:10:50 - 20:10:56]
function so this function will take the

[20:10:53 - 20:10:58]
input from the user like in which

[20:10:56 - 20:11:00]
language they want to let's say get the

[20:10:58 - 20:11:02]
output and what is the input prompt okay

[20:11:00 - 20:11:04]
so this function will take this input

[20:11:02 - 20:11:06]
you can see language as well as the user

[20:11:04 - 20:11:07]
text then it is create then inside that

[20:11:06 - 20:11:09]
I'm creating a prom template I think you

[20:11:07 - 20:11:11]
know what is prom template right so this

[20:11:09 - 20:11:12]
is the input variable language and user

[20:11:11 - 20:11:15]
text and I'm creating a prom template

[20:11:12 - 20:11:18]
youf chatboard and you are in this

[20:11:15 - 20:11:19]
language and this user text now based on

[20:11:18 - 20:11:21]
that you have to give give me the

[20:11:19 - 20:11:23]
response now here I'm creating a llm

[20:11:21 - 20:11:26]
chain and I'm passing my llm as well as

[20:11:23 - 20:11:28]
the prompt and finally I'm passing my

[20:11:26 - 20:11:30]
language as well as the user input to my

[20:11:28 - 20:11:31]
uh Bedrock chain that means the chain I

[20:11:30 - 20:11:33]
actually have created okay because

[20:11:31 - 20:11:35]
inside that I'm having my large language

[20:11:33 - 20:11:36]
model as well as the prom and whatever

[20:11:35 - 20:11:39]
response I'm getting I'm just returning

[20:11:36 - 20:11:43]
that's it now let me create a stream Le

[20:11:39 - 20:11:46]
title stream L let's say user interface

[20:11:43 - 20:11:49]
Bedrock chatbot demo now user will also

[20:11:46 - 20:11:50]
able to give the language so let's say

[20:11:49 - 20:11:53]
here I'll take a language input from the

[20:11:50 - 20:11:56]
user whether uh he want to get

[20:11:53 - 20:11:57]
English response Spanish response or

[20:11:56 - 20:11:59]
Hindi response you can so here you can

[20:11:57 - 20:12:00]
also pass any other language it will

[20:11:59 - 20:12:02]
also work because I think you know these

[20:12:00 - 20:12:04]
kinds of large language model can also

[20:12:02 - 20:12:06]
support multi language then this is my

[20:12:04 - 20:12:08]
final logic so if language is there so

[20:12:06 - 20:12:10]
they will give the input that means what

[20:12:08 - 20:12:11]
kinds of question they want to ask then

[20:12:10 - 20:12:13]
once they have let's say given the

[20:12:11 - 20:12:14]
prompt this particular prompt I'm

[20:12:13 - 20:12:16]
checking first of all this uh they have

[20:12:14 - 20:12:18]
given the prompt or not if they have

[20:12:16 - 20:12:19]
given I'm passing it to my my chat bot

[20:12:18 - 20:12:21]
you can see this function so it will

[20:12:19 - 20:12:23]
take the language as well as the user

[20:12:21 - 20:12:24]
input language and user input and

[20:12:23 - 20:12:26]
whatever response actually I'm getting

[20:12:24 - 20:12:29]
I'm writing in my stream lit application

[20:12:26 - 20:12:29]
now let me execute and let me show

[20:12:30 - 20:12:38]
you I'll save it now simply I'll just

[20:12:35 - 20:12:40]
open up my terminal and this is the

[20:12:38 - 20:12:43]
command stream lft

[20:12:40 - 20:12:43]
run

[20:12:44 - 20:12:47]
main.py so this is the interface guys

[20:12:46 - 20:12:50]
now you can select the language that's I

[20:12:47 - 20:12:54]
want to select the English now here I

[20:12:50 - 20:12:55]
can ask any query let's say what

[20:12:54 - 20:12:58]
is

[20:12:55 - 20:13:00]
python now you just need to press shift

[20:12:58 - 20:13:02]
uh sorry you just need to press control

[20:13:00 - 20:13:04]
and enter so guys as you can see uh if

[20:13:02 - 20:13:06]
you give any kinds of prompt now here is

[20:13:04 - 20:13:08]
the response so here I've given what is

[20:13:06 - 20:13:10]
Python and here is the response I got

[20:13:08 - 20:13:11]
now you can ask any of quy let's say I

[20:13:10 - 20:13:13]
will ask

[20:13:11 - 20:13:17]
uh

[20:13:13 - 20:13:22]
uh give me a

[20:13:17 - 20:13:22]
python code to add two

[20:13:24 - 20:13:28]
numbers see here I got the python code

[20:13:27 - 20:13:30]
to add the two numbers okay so that's

[20:13:28 - 20:13:33]
how you can pass any kinds of prompt and

[20:13:30 - 20:13:35]
you can uh get the response it's amazing

[20:13:33 - 20:13:38]
guys and and here we're using Mistral

[20:13:35 - 20:13:40]
model OKAY Mistral model we are using

[20:13:38 - 20:13:41]
okay and and it is present inside

[20:13:40 - 20:13:43]
Bedrock platform that's why this

[20:13:41 - 20:13:45]
inference time is very low you will see

[20:13:43 - 20:13:47]
that I'm getting very fast response but

[20:13:45 - 20:13:49]
whenever I was using mral model I think

[20:13:47 - 20:13:51]
remember in hugging pH okay hugging pH

[20:13:49 - 20:13:53]
Hub so there I had to download this

[20:13:51 - 20:13:56]
model in my system and the execution

[20:13:53 - 20:13:58]
time was like very slow there yes or no

[20:13:56 - 20:14:00]
right so that's why we have to use this

[20:13:58 - 20:14:01]
kinds of lmos platform if I'm

[20:14:00 - 20:14:03]
implementing any kinds of project

[20:14:01 - 20:14:05]
efficient project okay in the industry

[20:14:03 - 20:14:07]
so yes guys now you can uh explore

[20:14:05 - 20:14:08]
different different kinds of model

[20:14:07 - 20:14:10]
different different kinds of like

[20:14:08 - 20:14:12]
Foundation model you can also export Co

[20:14:10 - 20:14:15]
model meta model anything you can export

[20:14:12 - 20:14:17]
only just need to keep the model ID and

[20:14:15 - 20:14:19]
everything you can access got it so yes

[20:14:17 - 20:14:21]
guys I hope uh it is clear now how we

[20:14:19 - 20:14:23]
can use this Bedrock platform and if you

[20:14:21 - 20:14:25]
want to get this kinds of content more

[20:14:23 - 20:14:26]
so please try to support our channel so

[20:14:25 - 20:14:28]
please try to subscribe to the Channel

[20:14:26 - 20:14:29]
Try to share these kinds of content with

[20:14:28 - 20:14:31]
your friends and family so that they can

[20:14:29 - 20:14:33]
also get to know okay this kinds of

[20:14:31 - 20:14:35]
session is going on so please try to

[20:14:33 - 20:14:37]
support the channel guys try to like the

[20:14:35 - 20:14:38]
video try to subscribe to the channel

[20:14:37 - 20:14:40]
you can subscribe to the code Commander

[20:14:38 - 20:14:42]
Channel even you can also subscribe to

[20:14:40 - 20:14:43]
my channel D with buy okay both Channel

[20:14:42 - 20:14:45]
actually I'm operating you will see that

[20:14:43 - 20:14:47]
in both Channel I'm creating lots of

[20:14:45 - 20:14:49]
content related data science machine

[20:14:47 - 20:14:51]
learning genbi mlops okay n project

[20:14:49 - 20:14:53]
implementation okay everything I'm

[20:14:51 - 20:14:55]
creating the content if you don't know

[20:14:53 - 20:14:57]
what is AWS Bedrock AWS bedro is a

[20:14:55 - 20:14:59]
platform from Amazon web service we can

[20:14:57 - 20:15:01]
use this particular AWS Bedrock to

[20:14:59 - 20:15:03]
create scalable genbi application with

[20:15:01 - 20:15:05]
the help of large language model so if

[20:15:03 - 20:15:07]
you want to use this particular platform

[20:15:05 - 20:15:09]
uh Amazon Bedrock so you should have one

[20:15:07 - 20:15:11]
AWS account so so for me I already have

[20:15:09 - 20:15:12]
the account so if so if you don't have

[20:15:11 - 20:15:14]
any account so please try to create one

[20:15:12 - 20:15:16]
AWS account then you will be able to

[20:15:14 - 20:15:18]
access this particular platform now if

[20:15:16 - 20:15:19]
you can't see this particular service

[20:15:18 - 20:15:21]
here so what you can do you can search

[20:15:19 - 20:15:22]
here called Bedrock okay if you just

[20:15:21 - 20:15:24]
search for Bedrock so you will get this

[20:15:22 - 20:15:27]
particular service called Amazon Bedrock

[20:15:24 - 20:15:28]
now let's try to click here so it will

[20:15:27 - 20:15:30]
launch this particular platform for you

[20:15:28 - 20:15:32]
see guys so this is the Amazon Bedrock

[20:15:30 - 20:15:34]
platform and this is the easiest way to

[20:15:32 - 20:15:36]
build an scale genbi application with

[20:15:34 - 20:15:37]
the help of foundation model so it is

[20:15:36 - 20:15:39]
having lots of foundation model I'll

[20:15:37 - 20:15:40]
tell you what are the models actually is

[20:15:39 - 20:15:41]
having so it has one beautiful

[20:15:40 - 20:15:43]
documentation you can go through this

[20:15:41 - 20:15:45]
particular documentation like what it

[20:15:43 - 20:15:47]
can perform and all so you can perform

[20:15:45 - 20:15:48]
Tex generation you can also create a

[20:15:47 - 20:15:50]
chat BS you can also perform the searce

[20:15:48 - 20:15:52]
operation Tech summarization image

[20:15:50 - 20:15:54]
generation and personalization okay so

[20:15:52 - 20:15:56]
this many task actually you can perform

[20:15:54 - 20:15:58]
here and these are the actually uh

[20:15:56 - 20:16:00]
Foundation model so it is having let's

[20:15:58 - 20:16:02]
say lots of model it is having Jurassic

[20:16:00 - 20:16:06]
2 model cloudy model command Stone

[20:16:02 - 20:16:07]
defusion and Amazon Titan and you have

[20:16:06 - 20:16:10]
another model called Lama 2 okay Lama 2

[20:16:07 - 20:16:12]
is a model from met AI so this is one of

[20:16:10 - 20:16:14]
the like very popular and Powerful model

[20:16:12 - 20:16:15]
okay you can use so in this particular

[20:16:14 - 20:16:17]
project actually I'm going to use this

[20:16:15 - 20:16:20]
particular Lama 2 model okay and I will

[20:16:17 - 20:16:21]
also use any other model to show you

[20:16:20 - 20:16:23]
like how we can access this particular

[20:16:21 - 20:16:25]
Bedrock model OKAY from the Bedrock

[20:16:23 - 20:16:26]
platform now what you have to do you

[20:16:25 - 20:16:28]
have to click on this particular uh

[20:16:26 - 20:16:30]
geted button so if you just click on the

[20:16:28 - 20:16:32]
get started button okay so initially it

[20:16:30 - 20:16:34]
will tell you just try to request for

[20:16:32 - 20:16:36]
the model OKAY request to access all the

[20:16:34 - 20:16:38]
model because if you're using for the

[20:16:36 - 20:16:40]
first time you have to send a request

[20:16:38 - 20:16:41]
like toess access all the model okay so

[20:16:40 - 20:16:43]
I already made the request and I already

[20:16:41 - 20:16:45]
got the permission and I I can access

[20:16:43 - 20:16:47]
all the model OKAY from this particular

[20:16:45 - 20:16:49]
platform now guys as you can see so in

[20:16:47 - 20:16:51]
the overview section so these are the

[20:16:49 - 20:16:53]
models are available now let's say if

[20:16:51 - 20:16:54]
you want to use this particular model

[20:16:53 - 20:16:56]
jasic to model just click on this

[20:16:54 - 20:16:58]
particular model now if you see Jurassic

[20:16:56 - 20:16:59]
model is having different different

[20:16:58 - 20:17:01]
variant okay so it is having Jurassic to

[20:16:59 - 20:17:03]
ultra and it is having another model

[20:17:01 - 20:17:05]
called Jurassic to Mid okay you can

[20:17:03 - 20:17:07]
either use this mid model either you can

[20:17:05 - 20:17:08]
use this Ultra model okay so similar

[20:17:07 - 20:17:10]
wise if you if you're using let's say

[20:17:08 - 20:17:11]
Amazon okay so it is having different

[20:17:10 - 20:17:14]
different model so it is having let's

[20:17:11 - 20:17:16]
say Amazon uh this Titan embedding G1

[20:17:14 - 20:17:18]
text model so this is the embedding

[20:17:16 - 20:17:20]
model then it is having Titan text G1

[20:17:18 - 20:17:22]
model light model then Titan text G1

[20:17:20 - 20:17:23]
Express model okay that's how it is

[20:17:22 - 20:17:25]
having different different model even it

[20:17:23 - 20:17:27]
is also having Titan image generation

[20:17:25 - 20:17:29]
model okay that's actually let's say if

[20:17:27 - 20:17:31]
I click on meta okay that means Lama 2

[20:17:29 - 20:17:33]
so it is having different different

[20:17:31 - 20:17:35]
variant of the model Lama 2 so it is

[20:17:33 - 20:17:37]
having Lama to chat 1 billion model it

[20:17:35 - 20:17:39]
is having Lama to chat 70 billion model

[20:17:37 - 20:17:41]
even it is also having to 30 million

[20:17:39 - 20:17:42]
model and 70 million model okay so these

[20:17:41 - 20:17:44]
are the preent model and these are the

[20:17:42 - 20:17:45]
chat model let's see if you want to

[20:17:44 - 20:17:46]
perform question answering and chat

[20:17:45 - 20:17:48]
operation you have to use these are the

[20:17:46 - 20:17:49]
model and let's say if you want to only

[20:17:48 - 20:17:51]
generate let's say a text and if you

[20:17:49 - 20:17:52]
want to let's say do the sentence

[20:17:51 - 20:17:54]
completion at that time you can go with

[20:17:52 - 20:17:55]
this particular model okay so that's how

[20:17:54 - 20:17:56]
actually it is having different

[20:17:55 - 20:17:58]
different model OKAY based on the base

[20:17:56 - 20:18:00]
model actually you can see here so again

[20:17:58 - 20:18:02]
I will go to the overview now you can

[20:18:00 - 20:18:03]
see I already showed you the foundation

[20:18:02 - 20:18:05]
model now it can perform different

[20:18:03 - 20:18:06]
different task I already showed you

[20:18:05 - 20:18:09]
let's say you want to do any example so

[20:18:06 - 20:18:10]
we just go to the example section now

[20:18:09 - 20:18:12]
here you can select what kinds of task

[20:18:10 - 20:18:13]
actually want to perform so here you can

[20:18:12 - 20:18:15]
see different different task even it is

[20:18:13 - 20:18:17]
also having the playground let's say I

[20:18:15 - 20:18:19]
will open this particular playground

[20:18:17 - 20:18:21]
okay so playground I want to perform

[20:18:19 - 20:18:22]
this chat operation so now here what I

[20:18:21 - 20:18:24]
have to do first of all I have to select

[20:18:22 - 20:18:25]
the model I want to use so let's say I

[20:18:24 - 20:18:26]
will be using this particular model

[20:18:25 - 20:18:29]
called Jurassic to mid model so I'll

[20:18:26 - 20:18:30]
select this particular model and apply

[20:18:29 - 20:18:32]
okay after that I will get this kinds of

[20:18:30 - 20:18:34]
interface now here you can give any

[20:18:32 - 20:18:37]
kinds of promp let's say if I give hello

[20:18:34 - 20:18:39]
so here let's say if I send hello okay

[20:18:37 - 20:18:42]
to this particular uh

[20:18:39 - 20:18:45]
model so it will give me the

[20:18:42 - 20:18:47]
response see it is also responding like

[20:18:45 - 20:18:48]
uh hello how are you how how I can help

[20:18:47 - 20:18:49]
you today that's why actually you can

[20:18:48 - 20:18:51]
also change the temperature parameter

[20:18:49 - 20:18:53]
topic parameter okay so these are the

[20:18:51 - 20:18:54]
parameter you can uh change so what is

[20:18:53 - 20:18:56]
the temperature parameter temperature

[20:18:54 - 20:18:57]
parameter is a creativity actually

[20:18:56 - 20:18:59]
parameter so let's say if this

[20:18:57 - 20:19:00]
temperature parameter is like let's say

[20:18:59 - 20:19:02]
close to zero that means you are telling

[20:19:00 - 20:19:04]
your model uh to be stick okay it don't

[20:19:02 - 20:19:05]
be taking any risk and if you are

[20:19:04 - 20:19:07]
setting this parameter to close to one

[20:19:05 - 20:19:09]
that means you are uh like telling your

[20:19:07 - 20:19:11]
model just take any risk okay okay and

[20:19:09 - 20:19:12]
try to give a uh creative output so

[20:19:11 - 20:19:13]
that's actually you can change these

[20:19:12 - 20:19:15]
other parameters so by default you can

[20:19:13 - 20:19:16]
so by default just keep this default

[20:19:15 - 20:19:18]
parameter only now you can give any

[20:19:16 - 20:19:20]
kinds of prompt here okay it will

[20:19:18 - 20:19:21]
response with respect to that only now

[20:19:20 - 20:19:22]
guys this is for the playground okay but

[20:19:21 - 20:19:24]
whenever I'll be creating the

[20:19:22 - 20:19:27]
application I I'm not going to use this

[20:19:24 - 20:19:28]
particular model like that so I have to

[20:19:27 - 20:19:29]
uh use this particular model okay with

[20:19:28 - 20:19:31]
the help of this Python programming

[20:19:29 - 20:19:32]
language so with the help of python

[20:19:31 - 20:19:34]
client actually will be accessing this

[20:19:32 - 20:19:36]
this particular model but how to access

[20:19:34 - 20:19:38]
this particular model because this model

[20:19:36 - 20:19:39]
is already available in the AWS okay so

[20:19:38 - 20:19:41]
how to authenticate with the this

[20:19:39 - 20:19:42]
particular account so for this first of

[20:19:41 - 20:19:44]
all you have to create one IM user okay

[20:19:42 - 20:19:47]
so first of all let let me create one IM

[20:19:44 - 20:19:48]
user and let me uh like add this

[20:19:47 - 20:19:49]
particular secret key and access key

[20:19:48 - 20:19:52]
then I'll tell you how we can access

[20:19:49 - 20:19:55]
this particular uh Foundation model OKAY

[20:19:52 - 20:19:56]
from the AWS bedro uh so guys as I

[20:19:55 - 20:19:58]
already told you to authenticate with

[20:19:56 - 20:20:00]
this particular AWS and if you want to

[20:19:58 - 20:20:02]
access this particular Bedrock services

[20:20:00 - 20:20:03]
and all so you have to first of all

[20:20:02 - 20:20:05]
create one IM user and you have to

[20:20:03 - 20:20:06]
collect that particular access key and

[20:20:05 - 20:20:08]
secret access key okay then you have to

[20:20:06 - 20:20:09]
configure that so for this you have to

[20:20:08 - 20:20:11]
search for this particular service

[20:20:09 - 20:20:14]
called I am okay that means identity

[20:20:11 - 20:20:17]
access management now here I'll go to

[20:20:14 - 20:20:17]
the first option I

[20:20:17 - 20:20:22]
am now left hand side you can see there

[20:20:20 - 20:20:25]
is a user option okay let's click on the

[20:20:22 - 20:20:27]
user now here I'll be creating one user

[20:20:25 - 20:20:29]
create user just give the name so here

[20:20:27 - 20:20:32]
is let's say I'm doing a Bedrock project

[20:20:29 - 20:20:35]
so I'll just give it as Bedrock user

[20:20:32 - 20:20:38]
okay then I'll just click on next then I

[20:20:35 - 20:20:39]
will be adding the policies directly so

[20:20:38 - 20:20:41]
here you need to select this particular

[20:20:39 - 20:20:43]
option now here you have to search for

[20:20:41 - 20:20:44]
the Bedrock service okay because I want

[20:20:43 - 20:20:47]
to only give the Bedrock access okay not

[20:20:44 - 20:20:49]
the enre service access okay from my WS

[20:20:47 - 20:20:51]
account now here if you see Amazon

[20:20:49 - 20:20:54]
Bedrock full access okay so I'll select

[20:20:51 - 20:20:56]
the first option then click on next then

[20:20:54 - 20:20:59]
once it is done I will just create the

[20:20:56 - 20:21:01]
user now my user has created now I'll go

[20:20:59 - 20:21:02]
to the user I'll go to the security

[20:21:01 - 20:21:04]
credential and here you will see

[20:21:02 - 20:21:06]
something called create access key okay

[20:21:04 - 20:21:08]
let's click on the create access key now

[20:21:06 - 20:21:10]
I select on the common line interface

[20:21:08 - 20:21:12]
then I understand the above

[20:21:10 - 20:21:13]
recommendation then click on the next

[20:21:12 - 20:21:15]
then once it is done I will create the

[20:21:13 - 20:21:17]
access key okay now see guys this is my

[20:21:15 - 20:21:18]
access key and this is the secret access

[20:21:17 - 20:21:20]
key and don't share this particular

[20:21:18 - 20:21:21]
credential with anyone else otherwise

[20:21:20 - 20:21:23]
they will also able to access your

[20:21:21 - 20:21:25]
account okay I'm sharing uh because I'm

[20:21:23 - 20:21:26]
going to delete this particular user

[20:21:25 - 20:21:28]
after the recording okay that's why I'm

[20:21:26 - 20:21:29]
showing now what I have to do I have to

[20:21:28 - 20:21:31]
download this thing as a CSV file so

[20:21:29 - 20:21:32]
click on this particular button okay it

[20:21:31 - 20:21:34]
will download as a CSV file okay see

[20:21:32 - 20:21:36]
I've already downloaded now if you want

[20:21:34 - 20:21:38]
to authenticate okay if you want to

[20:21:36 - 20:21:39]
authenticate with your actually code so

[20:21:38 - 20:21:42]
what you have to do first of all you

[20:21:39 - 20:21:45]
have to install one tool okay called

[20:21:42 - 20:21:48]
AWS CLI Okay aw CLI download just search

[20:21:45 - 20:21:50]
on Google aw C download so this is the

[20:21:48 - 20:21:52]
website actually you will get and you

[20:21:50 - 20:21:53]
have to install this particular tool now

[20:21:52 - 20:21:54]
you have different different operating

[20:21:53 - 20:21:56]
system let's say if you're using Windows

[20:21:54 - 20:21:58]
so you will get one MSI file okay as you

[20:21:56 - 20:21:59]
can see this is a MSI file so try to

[20:21:58 - 20:22:01]
download this particular MSI file and

[20:21:59 - 20:22:04]
try to install it the way actually you

[20:22:01 - 20:22:06]
do install any regular software Okay

[20:22:04 - 20:22:07]
then if you're using any macway or let's

[20:22:06 - 20:22:08]
say Linux operating system you can

[20:22:07 - 20:22:11]
follow these are the command to install

[20:22:08 - 20:22:13]
this particular aw CLI so here I'm using

[20:22:11 - 20:22:14]
Windows machine so I already downloaded

[20:22:13 - 20:22:17]
this particular MSI file okay let me

[20:22:14 - 20:22:19]
show you so this is the MSI file so

[20:22:17 - 20:22:20]
inside windows so this is the MSI file

[20:22:19 - 20:22:23]
if I click here so it will start

[20:22:20 - 20:22:25]
download see guys it will start download

[20:22:23 - 20:22:26]
okay now we cancel it okay after

[20:22:25 - 20:22:28]
downloading you have just need to double

[20:22:26 - 20:22:31]
click and you to install as a regular

[20:22:28 - 20:22:32]
software okay then once it is done then

[20:22:31 - 20:22:34]
I will open up my terminal so first of

[20:22:32 - 20:22:36]
all let me open up my local

[20:22:34 - 20:22:38]
folder okay so this is my local folder

[20:22:36 - 20:22:41]
so here I'm going to open up my terminal

[20:22:38 - 20:22:43]
okay but before that let me create one

[20:22:41 - 20:22:46]
folder here so inside that I'm going to

[20:22:43 - 20:22:47]
do my project so here I'm going to name

[20:22:46 - 20:22:50]
this particular folder

[20:22:47 - 20:22:55]
as

[20:22:50 - 20:22:55]
uh um Genera

[20:22:56 - 20:23:01]
application okay generative

[20:22:59 - 20:23:04]
AI

[20:23:01 - 20:23:08]
uh gen

[20:23:04 - 20:23:10]
project okay bed Dr

[20:23:08 - 20:23:13]
let's say this is the name now inside

[20:23:10 - 20:23:15]
that I will I'll open up my terminal

[20:23:13 - 20:23:15]
okay so let's open up my

[20:23:19 - 20:23:24]
terminal yeah so now here uh what you

[20:23:22 - 20:23:26]
have to do first of all you have to test

[20:23:24 - 20:23:28]
this particular aw whether it has

[20:23:26 - 20:23:29]
downloaded successfully or not so for

[20:23:28 - 20:23:32]
this you just need to execute this

[20:23:29 - 20:23:34]
particular command called AWS okay

[20:23:32 - 20:23:36]
configure so if you execute this

[20:23:34 - 20:23:38]
particular command so it will give you

[20:23:36 - 20:23:40]
this kinds of interface see it will give

[20:23:38 - 20:23:41]
you this kinds of interface and if it is

[20:23:40 - 20:23:42]
not giving this kinds of interface if it

[20:23:41 - 20:23:44]
is throwing any kinds of error that

[20:23:42 - 20:23:45]
means you are not able to install

[20:23:44 - 20:23:47]
successfully okay you have to install it

[20:23:45 - 20:23:48]
successfully so for me I already

[20:23:47 - 20:23:50]
installed successfully that's why I'm

[20:23:48 - 20:23:51]
getting this particular option now here

[20:23:50 - 20:23:53]
you have to provide that particular

[20:23:51 - 20:23:55]
credential okay that FW secret key ID

[20:23:53 - 20:23:56]
you have downloaded now let's go back to

[20:23:55 - 20:23:58]
the CSV file I downloaded so this is the

[20:23:56 - 20:24:00]
CSV file let me open it up so guys I

[20:23:58 - 20:24:02]
already open up this particular file

[20:24:00 - 20:24:05]
with the help of my notepad++ now as you

[20:24:02 - 20:24:06]
can see this is the access key ID now

[20:24:05 - 20:24:07]
you have to copy before the comma

[20:24:06 - 20:24:09]
because this is the comma separated this

[20:24:07 - 20:24:12]
is a CS v file so I'll copy this

[20:24:09 - 20:24:13]
particular credential and I'm going to

[20:24:12 - 20:24:15]
open up my

[20:24:13 - 20:24:16]
terminal and I'm going to paste it here

[20:24:15 - 20:24:18]
okay so just right click and paste it

[20:24:16 - 20:24:21]
okay so it hasn't com copy yet I think

[20:24:18 - 20:24:23]
so I'll copy again open up the terminal

[20:24:21 - 20:24:25]
and let me

[20:24:23 - 20:24:28]
remove now I'm going to paste okay now

[20:24:25 - 20:24:29]
see if you right click it will paste now

[20:24:28 - 20:24:31]
if you hit enter it will automatically

[20:24:29 - 20:24:34]
save okay now you have to also set for

[20:24:31 - 20:24:36]
the a secret access key okay so this is

[20:24:34 - 20:24:38]
the secret access key so copy before the

[20:24:36 - 20:24:41]
comma and again open up the terminal and

[20:24:38 - 20:24:43]
past it here okay then it is telling

[20:24:41 - 20:24:44]
select the region okay so so make sure

[20:24:43 - 20:24:46]
you are checking the region currently

[20:24:44 - 20:24:50]
which region actually you are in so for

[20:24:46 - 20:24:51]
this just go to the home okay AWS home

[20:24:50 - 20:24:52]
so here you actually will see that

[20:24:51 - 20:24:54]
particular region okay see now currently

[20:24:52 - 20:24:56]
I'm inside North Virginia that means Us

[20:24:54 - 20:24:58]
East one okay but if you're in any other

[20:24:56 - 20:24:59]
region you have to select this

[20:24:58 - 20:25:01]
particular name let's say you are inside

[20:24:59 - 20:25:03]
Asia Pacific that means Mumbai you have

[20:25:01 - 20:25:05]
to write AP South one that time but I'm

[20:25:03 - 20:25:07]
inside Us East one okay that means not

[20:25:05 - 20:25:09]
Virginia so I'm going to write Us East

[20:25:07 - 20:25:10]
one here so I'm be opening the terminal

[20:25:09 - 20:25:14]
and here you just need to write in the

[20:25:10 - 20:25:16]
same way us past one okay now I'll press

[20:25:14 - 20:25:18]
enter now you have to keep it as default

[20:25:16 - 20:25:21]
press enter now see all the credential

[20:25:18 - 20:25:22]
has been set now I can easily

[20:25:21 - 20:25:24]
authenticate with my Bedrock okay

[20:25:22 - 20:25:26]
Bedrock platform with the help of this

[20:25:24 - 20:25:28]
particular terminal okay now what I have

[20:25:26 - 20:25:31]
to do so let me open up my

[20:25:28 - 20:25:34]
folder the project folder I have created

[20:25:31 - 20:25:36]
now inside that I'm going to open up my

[20:25:34 - 20:25:38]
V code okay so let's open the vas code

[20:25:36 - 20:25:40]
so here let me write down all the steps

[20:25:38 - 20:25:42]
so that that you can refer later on also

[20:25:40 - 20:25:45]
in the readme file I'll add everything

[20:25:42 - 20:25:48]
so here let me close it now first of all

[20:25:45 - 20:25:48]
I'll create a file called

[20:25:49 - 20:25:55]
readme okay readme do MD so here first

[20:25:53 - 20:25:56]
of all Let me give the project name so

[20:25:55 - 20:26:01]
this is uh

[20:25:56 - 20:26:01]
N2 okay n2n generative

[20:26:02 - 20:26:08]
AI a

[20:26:05 - 20:26:11]
project okay using

[20:26:08 - 20:26:15]
AWS

[20:26:11 - 20:26:17]
bedro bedro okay so this is the title of

[20:26:15 - 20:26:19]
my project now inside that I'm going to

[20:26:17 - 20:26:21]
write the step okay you have to perform

[20:26:19 - 20:26:22]
to set up this particular project so

[20:26:21 - 20:26:24]
first of all you have to create one

[20:26:22 - 20:26:28]
virtual environment so I already written

[20:26:24 - 20:26:29]
so let me just uh give it it here so

[20:26:28 - 20:26:31]
these are the step I have to perform

[20:26:29 - 20:26:32]
okay if I want to execute this

[20:26:31 - 20:26:34]
particular project so first of all I

[20:26:32 - 20:26:36]
have to create one okay I have to create

[20:26:34 - 20:26:39]
one virtual environment so let's give

[20:26:36 - 20:26:42]
the name so this is let's say

[20:26:39 - 20:26:42]
Bedrock project okay so

[20:26:42 - 20:26:48]
Bedrock

[20:26:44 - 20:26:51]
Bedrock okay Bedrock project Bedrock

[20:26:48 - 20:26:53]
Pro Bedrock project now you have to

[20:26:51 - 20:26:54]
activate this particular Bedrock uh

[20:26:53 - 20:26:56]
environment okay you have created and

[20:26:54 - 20:26:58]
make sure you using python 3.8 you can

[20:26:56 - 20:26:59]
also use more than python 3.8 is

[20:26:58 - 20:27:01]
completely fine then you have to install

[20:26:59 - 20:27:02]
the requirements because I'm going to

[20:27:01 - 20:27:03]
write some requirements okay for this

[20:27:02 - 20:27:05]
particular project you also need to

[20:27:03 - 20:27:07]
install them then I already told you you

[20:27:05 - 20:27:09]
have to uh download this particular aw

[20:27:07 - 20:27:11]
CLI okay and this is the link I have

[20:27:09 - 20:27:12]
already given then you have to set up it

[20:27:11 - 20:27:14]
okay after set uping you have to

[20:27:12 - 20:27:15]
configure that and add all the

[20:27:14 - 20:27:18]
credential okay so these are the step

[20:27:15 - 20:27:20]
actually you have to perform then uh

[20:27:18 - 20:27:22]
what I will do I'll quickly uh create

[20:27:20 - 20:27:23]
some of the folders and file here so

[20:27:22 - 20:27:25]
first of all I'm going to create a

[20:27:23 - 20:27:27]
folder called

[20:27:25 - 20:27:30]
research okay

[20:27:27 - 20:27:31]
research inside research I'm going to

[20:27:30 - 20:27:33]
create one file called

[20:27:31 - 20:27:36]
trials

[20:27:33 - 20:27:39]
okay I can write B Bedrock trials okay

[20:27:36 - 20:27:39]
bedro

[20:27:40 - 20:27:45]
trials do

[20:27:43 - 20:27:47]
file then outside I'll be creating

[20:27:45 - 20:27:50]
another file called

[20:27:47 - 20:27:54]
uh main.

[20:27:50 - 20:27:55]
F okay then I'm going to create a

[20:27:54 - 20:27:57]
requirements

[20:27:55 - 20:28:01]
file

[20:27:57 - 20:28:05]
requirements okay.

[20:28:01 - 20:28:07]
dxt yeah so as of now I need these are

[20:28:05 - 20:28:09]
the folders and file if you want to add

[20:28:07 - 20:28:11]
uh like G ignore and license file you

[20:28:09 - 20:28:12]
can add it if you want to comit this

[20:28:11 - 20:28:14]
particular code in the GitHub but I'm

[20:28:12 - 20:28:16]
not going to comit okay so that's why I

[20:28:14 - 20:28:17]
only need deserve the files and folder

[20:28:16 - 20:28:19]
now first of all let's add all the

[20:28:17 - 20:28:20]
requirements actually I need for this

[20:28:19 - 20:28:22]
particular project so first of all let

[20:28:20 - 20:28:24]
me show you what are the tools and

[20:28:22 - 20:28:26]
Technology I'm going to use so for this

[20:28:24 - 20:28:30]
I'm going to open up my Blackboard so

[20:28:26 - 20:28:32]
here uh I'm going to use some of the

[20:28:30 - 20:28:34]
tools okay so the first thing I'm going

[20:28:32 - 20:28:37]
to use Lang

[20:28:34 - 20:28:38]
chain okay I think you already know what

[20:28:37 - 20:28:41]
is Lang chain Lang Lang chain is a

[20:28:38 - 20:28:42]
generative VI framework okay so we can

[20:28:41 - 20:28:44]
use this particular Lang chain to create

[20:28:42 - 20:28:45]
generative VI application okay so it it

[20:28:44 - 20:28:47]
is having different different

[20:28:45 - 20:28:50]
functionality uh so it will help you to

[20:28:47 - 20:28:53]
create that particular application okay

[20:28:50 - 20:28:58]
so then second I need something called P

[20:28:53 - 20:29:00]
PDF okay Pi PDF why I need P Pi PDF

[20:28:58 - 20:29:03]
because I'm going to um upload my PDF

[20:29:00 - 20:29:05]
data okay and from there actually I'm

[20:29:03 - 20:29:07]
going to uh do the retriever operation

[20:29:05 - 20:29:08]
okay that means qu operation I'll tell

[20:29:07 - 20:29:10]
you like what kind of of application

[20:29:08 - 20:29:11]
we're building okay so we'll be building

[20:29:10 - 20:29:12]
something called rag application so

[20:29:11 - 20:29:14]
there actually we'll be creating one

[20:29:12 - 20:29:16]
knowledge base okay with the help of

[20:29:14 - 20:29:18]
custom data actually I'm giving so

[20:29:16 - 20:29:20]
that's why my data source would be PDF

[20:29:18 - 20:29:21]
data you can also use dogs data or txt

[20:29:20 - 20:29:23]
data it's it's completely fine but I'm

[20:29:21 - 20:29:25]
going to use PDF data here so I'm going

[20:29:23 - 20:29:26]
to like also show you the architecture

[20:29:25 - 20:29:28]
okay architecture of this particular

[20:29:26 - 20:29:29]
project like how everything will work

[20:29:28 - 20:29:31]
but before that let me write down the

[20:29:29 - 20:29:33]
tools and Technology I'm going to use in

[20:29:31 - 20:29:36]
this particular project then I'm going

[20:29:33 - 20:29:38]
to use something called stream lead okay

[20:29:36 - 20:29:39]
stream stream lead

[20:29:38 - 20:29:41]
streem L I'm going to use to create the

[20:29:39 - 20:29:43]
user app Okay because I'm going to

[20:29:41 - 20:29:44]
create a user app so so that actually

[20:29:43 - 20:29:46]
user will get some interface to use your

[20:29:44 - 20:29:48]
application so for this I'm going to use

[20:29:46 - 20:29:50]
is stream lit you can also use flask

[20:29:48 - 20:29:52]
okay first API or any other let's say

[20:29:50 - 20:29:54]
web framework it's completely fine but

[20:29:52 - 20:29:56]
streamlit would be easy for me to like

[20:29:54 - 20:29:58]
you can Implement because there I'm not

[20:29:56 - 20:29:59]
going to write any HTML and CSS code

[20:29:58 - 20:30:02]
okay then after that fourth I'm going to

[20:29:59 - 20:30:04]
use Vector DV so Vector DV wise I'm

[20:30:02 - 20:30:06]
going to use f okay so F so f is a

[20:30:04 - 20:30:08]
vector DB so this is for Facebook Okay

[20:30:06 - 20:30:10]
Facebook team has this particular Vector

[20:30:08 - 20:30:13]
DB called f and this is the local Vector

[20:30:10 - 20:30:15]
DB okay you can also integrate Pine con

[20:30:13 - 20:30:17]
then we chroma DB okay it's up to you

[20:30:15 - 20:30:18]
but I'm going to use f so in future

[20:30:17 - 20:30:20]
maybe we'll be creating some other

[20:30:18 - 20:30:21]
projects so there actually we can use

[20:30:20 - 20:30:23]
any other Vector DB okay so these are

[20:30:21 - 20:30:25]
the tools and Technology I'm going to

[20:30:23 - 20:30:28]
use for this particular projects and

[20:30:25 - 20:30:30]
definitely the final tool and platform

[20:30:28 - 20:30:32]
I'm going to use something called bedro

[20:30:30 - 20:30:34]
okay bedro from the a okay so Bedrock

[20:30:32 - 20:30:36]
I'm going to use and llm wise I'm going

[20:30:34 - 20:30:37]
to use something called Lama 2 as I

[20:30:36 - 20:30:39]
already told you I'm going to use Lama 2

[20:30:37 - 20:30:42]
okay from M so this is the LM I'm going

[20:30:39 - 20:30:44]
to use so yes so this is the tools and

[20:30:42 - 20:30:46]
Technology I'm going to use now let me

[20:30:44 - 20:30:48]
quickly uh I mean install these are the

[20:30:46 - 20:30:50]
tools and technology so what I will do

[20:30:48 - 20:30:52]
I'll open up my code and here let me

[20:30:50 - 20:30:54]
write down everything one by one so

[20:30:52 - 20:30:56]
first of all I need something called Len

[20:30:54 - 20:31:00]
okay

[20:30:56 - 20:31:04]
Len then I need something called P PDF P

[20:31:00 - 20:31:04]
PDF then I need something called stream

[20:31:04 - 20:31:09]
lit okay then I need something called

[20:31:07 - 20:31:09]
fire CPU

[20:31:11 - 20:31:15]
P CPU okay so let me save it now first

[20:31:14 - 20:31:18]
of all I need to create an environment

[20:31:15 - 20:31:21]
so I'll copy this particular command and

[20:31:18 - 20:31:23]
I'm going to open up my

[20:31:21 - 20:31:26]
terminal and let me create this

[20:31:23 - 20:31:26]
particular environment first of

[20:31:31 - 20:31:34]
all so guys as you can see my

[20:31:33 - 20:31:36]
environment is created now I have to

[20:31:34 - 20:31:40]
activate so this is the command G

[20:31:36 - 20:31:40]
activate so now let's activate

[20:31:44 - 20:31:48]
also now see I'm inside this Bedrock

[20:31:47 - 20:31:50]
project okay that means this particular

[20:31:48 - 20:31:51]
environment now I have to install the

[20:31:50 - 20:31:54]
requirements so for this I'm going to

[20:31:51 - 20:31:54]
execute this particular

[20:32:02 - 20:32:06]
command see now it is installing

[20:32:04 - 20:32:08]
everything so it will take some time

[20:32:06 - 20:32:10]
okay so let's wait I'll come back when

[20:32:08 - 20:32:10]
once it is

[20:32:15 - 20:32:20]
done so guys as you can see installation

[20:32:17 - 20:32:24]
is completed now what I have to do yeah

[20:32:20 - 20:32:27]
so now I can uh start the coding part so

[20:32:24 - 20:32:29]
yeah so make sure uh yeah so now what I

[20:32:27 - 20:32:30]
will do I'll go inside this particular

[20:32:29 - 20:32:32]
resarch folder and first of all I will

[20:32:30 - 20:32:33]
test this particular Bedrock okay like

[20:32:32 - 20:32:35]
how we can connect this particular

[20:32:33 - 20:32:36]
bedrock and how we can access the model

[20:32:35 - 20:32:38]
and all because I already showed you it

[20:32:36 - 20:32:40]
is having some Foundation model

[20:32:38 - 20:32:41]
and if you want to access it so for this

[20:32:40 - 20:32:43]
first of all you need to do some

[20:32:41 - 20:32:45]
authentication so that authentication we

[20:32:43 - 20:32:48]
have already completed so let's go

[20:32:45 - 20:32:48]
inside this particular Amazon

[20:32:49 - 20:32:54]
Bedrock yeah so now see these are the

[20:32:52 - 20:32:55]
models are available okay and I think

[20:32:54 - 20:32:57]
you already know this Lama 2 then

[20:32:55 - 20:32:59]
Mistral so these are the model is also

[20:32:57 - 20:33:00]
open source model okay so this model is

[20:32:59 - 20:33:02]
also available in the hugging face okay

[20:33:00 - 20:33:04]
hugging face is also having these are

[20:33:02 - 20:33:05]
the model let's say I want to access

[20:33:04 - 20:33:08]
meta Lama model okay so this is the

[20:33:05 - 20:33:11]
model actually I can see so all the

[20:33:08 - 20:33:13]
model actually you have 7B then 70b 13B

[20:33:11 - 20:33:14]
all the model actually you are having

[20:33:13 - 20:33:16]
but if you want to load this particular

[20:33:14 - 20:33:17]
model okay you have to download this

[20:33:16 - 20:33:19]
particular model from the hugging P

[20:33:17 - 20:33:21]
itself okay for this you need GPU

[20:33:19 - 20:33:22]
machine okay you need a GPU machine and

[20:33:21 - 20:33:24]
you you you should have a good memory

[20:33:22 - 20:33:26]
there okay otherwise the you can't

[20:33:24 - 20:33:27]
actually load this particular model even

[20:33:26 - 20:33:29]
if you have already used this particular

[20:33:27 - 20:33:31]
model okay so you'll see like inference

[20:33:29 - 20:33:33]
time would be also High because it's a

[20:33:31 - 20:33:35]
huge model again okay uh because

[20:33:33 - 20:33:37]
everything you are running on your local

[20:33:35 - 20:33:38]
machine okay and then you are executing

[20:33:37 - 20:33:39]
the are the model but whenever I'm

[20:33:38 - 20:33:41]
talking about this particular Amazon

[20:33:39 - 20:33:44]
Bedrock so this model actually is

[20:33:41 - 20:33:46]
already hosted here okay uh as an API so

[20:33:44 - 20:33:48]
you can connect this model through API

[20:33:46 - 20:33:50]
okay API request so first of all you

[20:33:48 - 20:33:51]
just need to make a client okay with the

[20:33:50 - 20:33:53]
help of this particular client you can

[20:33:51 - 20:33:55]
send a request that means you can send a

[20:33:53 - 20:33:56]
prompt and you can get a response okay

[20:33:55 - 20:33:58]
from this particular model and this

[20:33:56 - 20:34:00]
execution time would be very fast okay

[20:33:58 - 20:34:01]
so for this if you want to let's say

[20:34:00 - 20:34:02]
create a production grade application

[20:34:01 - 20:34:04]
and if you want let's say Fuster

[20:34:02 - 20:34:05]
inference okay at that time you can go

[20:34:04 - 20:34:08]
with this particular Amazon Bedrock

[20:34:05 - 20:34:09]
service okay but let's say you have uh

[20:34:08 - 20:34:10]
good instance okay you have a good

[20:34:09 - 20:34:12]
instance you have lots of money you can

[20:34:10 - 20:34:14]
buy good instance good GPU configuration

[20:34:12 - 20:34:15]
machine and all and if you are not

[20:34:14 - 20:34:16]
worrying about the fer inference at the

[20:34:15 - 20:34:18]
time you can go with these are the model

[20:34:16 - 20:34:20]
okay you can like manually download this

[20:34:18 - 20:34:22]
particular model you can use it but here

[20:34:20 - 20:34:24]
we'll be using the client okay to access

[20:34:22 - 20:34:25]
this particular model and every request

[20:34:24 - 20:34:27]
actually you'll be sending okay will

[20:34:25 - 20:34:28]
have some of the cost okay now if you

[20:34:27 - 20:34:30]
want to check the cost also so you can

[20:34:28 - 20:34:34]
check it out let's say if I want to use

[20:34:30 - 20:34:36]
llama model so Lama is having there uh

[20:34:34 - 20:34:38]
like cost okay cost per request so here

[20:34:36 - 20:34:41]
you can see the

[20:34:38 - 20:34:44]
view pricing option so part token

[20:34:41 - 20:34:46]
actually it will charge you okay so see

[20:34:44 - 20:34:49]
so if you if you're using this this

[20:34:46 - 20:34:50]
model Jurassic to mid model so let's see

[20:34:49 - 20:34:54]
the Llama model I think llama model is

[20:34:50 - 20:34:56]
also there yeah meta Lama so this is the

[20:34:54 - 20:34:58]
price uh per thousand tokens okay see

[20:34:56 - 20:34:59]
per thousand tokens this is the price

[20:34:58 - 20:35:02]
actually it will charge it's like very

[20:34:59 - 20:35:05]
less okay lesser than your open I think

[20:35:02 - 20:35:06]
okay so uh there is no like more charts

[20:35:05 - 20:35:07]
so you don't need to worry about so if

[20:35:06 - 20:35:08]
you want to create a produ grade

[20:35:07 - 20:35:10]
applications you can go with this

[20:35:08 - 20:35:12]
particular Amazon Bedrock service okay

[20:35:10 - 20:35:14]
you can visit that particular pricing

[20:35:12 - 20:35:16]
pce and you can try to understand now

[20:35:14 - 20:35:18]
what I have to do guys uh first of all

[20:35:16 - 20:35:19]
let's try to access one particular model

[20:35:18 - 20:35:20]
OKAY from this particular Amazon bedro

[20:35:19 - 20:35:23]
so let's say I want to access this

[20:35:20 - 20:35:24]
particular model called this Jurassic

[20:35:23 - 20:35:25]
model OKAY Jurassic model I want to

[20:35:24 - 20:35:27]
access that's I want to access this

[20:35:25 - 20:35:28]
particular model Jurassic mid model so

[20:35:27 - 20:35:31]
if I want to access this particular

[20:35:28 - 20:35:32]
model I have to hit the API request okay

[20:35:31 - 20:35:34]
so here I have to send the API request

[20:35:32 - 20:35:36]
but I'm going to send the API request

[20:35:34 - 20:35:38]
throughout the python okay so guys now

[20:35:36 - 20:35:40]
let's see how we can uh use this

[20:35:38 - 20:35:41]
particular Amazon Bedrock that means the

[20:35:40 - 20:35:43]
different different actually Foundation

[20:35:41 - 20:35:45]
model okay so first of all we'll be

[20:35:43 - 20:35:46]
doing this particular experiment and if

[20:35:45 - 20:35:48]
we are able to access these are the

[20:35:46 - 20:35:50]
model okay so next actually I'm going to

[20:35:48 - 20:35:52]
show you how we can create this

[20:35:50 - 20:35:54]
particular uh Inn rag application with

[20:35:52 - 20:35:56]
the help of this particular Amazon bed

[20:35:54 - 20:35:58]
so I'll go to my code editor and first

[20:35:56 - 20:36:00]
of all here I'm going to import this

[20:35:58 - 20:36:02]
Bedrock from the langen because it is

[20:36:00 - 20:36:04]
already available in the langin okay Len

[20:36:02 - 20:36:05]
framework so we have already installed

[20:36:04 - 20:36:07]
this particular langin so make sure you

[20:36:05 - 20:36:10]
have selected the correct environment so

[20:36:07 - 20:36:13]
so let me refresh so this is the

[20:36:10 - 20:36:18]
environment uh I'm using yeah so Lang

[20:36:13 - 20:36:19]
chain do uh you have to import llms then

[20:36:18 - 20:36:21]
inside that you have something called

[20:36:19 - 20:36:22]
this particular service called Bedrock

[20:36:21 - 20:36:25]
now I'm going to import this particular

[20:36:22 - 20:36:27]
Bedrock class okay so bed drop then I

[20:36:25 - 20:36:30]
also need something called llm chain

[20:36:27 - 20:36:32]
because uh here whenever you will be

[20:36:30 - 20:36:34]
creating that particular QA object okay

[20:36:32 - 20:36:36]
so you need this particular LM chain so

[20:36:34 - 20:36:38]
let's create this particular LM chain so

[20:36:36 - 20:36:41]
from L chain

[20:36:38 - 20:36:43]
dot chains so if you already know about

[20:36:41 - 20:36:44]
Lang chain I think you already know what

[20:36:43 - 20:36:45]
is the things actually I'm importing

[20:36:44 - 20:36:47]
because these are the requirement

[20:36:45 - 20:36:48]
actually I'm expecting you are already

[20:36:47 - 20:36:52]
familiar with this particular Lang chain

[20:36:48 - 20:36:54]
framework okay so chain I'm I'm going to

[20:36:52 - 20:36:56]
import something called LM

[20:36:54 - 20:36:58]
chain then I'm going to import something

[20:36:56 - 20:36:59]
called prom template so here I'm going

[20:36:58 - 20:37:02]
to write prom Lang

[20:36:59 - 20:37:04]
chin uh do

[20:37:02 - 20:37:06]
prompts okay I'm going to import

[20:37:04 - 20:37:08]
something called prompt

[20:37:06 - 20:37:11]
template then I'm going to import

[20:37:08 - 20:37:13]
another Library called boto 3 okay so if

[20:37:11 - 20:37:15]
you don't know what is boto 3 boto 3 is

[20:37:13 - 20:37:18]
a library python Library actually we can

[20:37:15 - 20:37:19]
use to connect with our AWS account okay

[20:37:18 - 20:37:20]
but here we haven't installed this

[20:37:19 - 20:37:24]
particular package so let me install

[20:37:20 - 20:37:24]
also so here I can write boto

[20:37:25 - 20:37:29]
3 now let me open up my

[20:37:30 - 20:37:34]
terminal now again I'm going to install

[20:37:32 - 20:37:34]
this particular

[20:37:35 - 20:37:40]
requirements so installation completed

[20:37:38 - 20:37:42]
now let's create the client quickly so

[20:37:40 - 20:37:44]
with the help of this particular um

[20:37:42 - 20:37:46]
client actually I'll be accessing the

[20:37:44 - 20:37:48]
bedro so we have imported B of three

[20:37:46 - 20:37:49]
then I also need to import uh stream

[20:37:48 - 20:37:52]
lead Okay because I'm going to create

[20:37:49 - 20:37:53]
one Basics uh UI for my user okay so

[20:37:52 - 20:37:58]
that's why it's needed so let's import

[20:37:53 - 20:38:01]
it so I import stream lit as

[20:37:58 - 20:38:03]
STD

[20:38:01 - 20:38:05]
yeah okay it should be uh import okay

[20:38:03 - 20:38:07]
not form yeah now I think everything is

[20:38:05 - 20:38:10]
fine now first of all I'll be

[20:38:07 - 20:38:11]
uh defining the Bedrock client okay so

[20:38:10 - 20:38:13]
let's define the Bedrock

[20:38:11 - 20:38:16]
client

[20:38:13 - 20:38:16]
Bedrock

[20:38:16 - 20:38:23]
client so for this I'm going to use this

[20:38:19 - 20:38:23]
particular boto 3 so boto

[20:38:23 - 20:38:30]
3 okay dot

[20:38:26 - 20:38:32]
client and uh here you have to mention

[20:38:30 - 20:38:36]
the service actually want to use so

[20:38:32 - 20:38:37]
service servicecore name so I want to

[20:38:36 - 20:38:41]
use this particular Bedrock service okay

[20:38:37 - 20:38:41]
so you have to write Bedrock underscore

[20:38:42 - 20:38:47]
runtime okay bedro bedore runtime then

[20:38:46 - 20:38:49]
you also need to define the region like

[20:38:47 - 20:38:52]
which region actually you want to use in

[20:38:49 - 20:38:53]
the AWS you are having I already told

[20:38:52 - 20:38:56]
you how to check the region so we are

[20:38:53 - 20:38:57]
inside this particular Us East one okay

[20:38:56 - 20:39:00]
so let me also write down this

[20:38:57 - 20:39:03]
particular region so I'm inside this Us

[20:39:00 - 20:39:05]
ipen East ipen one okay so this is the

[20:39:03 - 20:39:07]
reason so yeah guys this is my client so

[20:39:05 - 20:39:11]
I'll store this particular client in in

[20:39:07 - 20:39:15]
a variable so let's name it as

[20:39:11 - 20:39:15]
Bedrock okay Bedrock

[20:39:17 - 20:39:22]
client then I need to write the model ID

[20:39:20 - 20:39:23]
okay which model actually want to access

[20:39:22 - 20:39:25]
from the Bedrock okay so you have to

[20:39:23 - 20:39:27]
define the model ID now how you will get

[20:39:25 - 20:39:29]
this particular model ID so again go

[20:39:27 - 20:39:30]
back to this particular bedro and I

[20:39:29 - 20:39:31]
already told you it is having different

[20:39:30 - 20:39:33]
different Foundation model let's say I

[20:39:31 - 20:39:35]
want to use this particular Jurassic 2

[20:39:33 - 20:39:37]
model okay I'll click here now it is

[20:39:35 - 20:39:39]
having different like variant Jurassic

[20:39:37 - 20:39:40]
and Jurassic mid let's say I want to use

[20:39:39 - 20:39:42]
this particular Jurassic mid I'll click

[20:39:40 - 20:39:43]
here now if you just go below this is

[20:39:42 - 20:39:45]
the model ID okay now let's copy this

[20:39:43 - 20:39:49]
particular model

[20:39:45 - 20:39:50]
ID I'll copy and I'll open up my code

[20:39:49 - 20:39:53]
and here I'm going to paste it okay so

[20:39:50 - 20:39:54]
this is the model ID now here what I

[20:39:53 - 20:39:56]
have to do I have to create a llm rapper

[20:39:54 - 20:40:00]
so let's create LM rapper llm is equal

[20:39:56 - 20:40:02]
to uh bedro and inside that first of all

[20:40:00 - 20:40:04]
you have to define the model ID OKAY

[20:40:02 - 20:40:05]
model ID so model ID means the model ID

[20:40:04 - 20:40:07]
actually we have defined okay this

[20:40:05 - 20:40:08]
particular model I want to access then

[20:40:07 - 20:40:11]
after

[20:40:08 - 20:40:13]
that I have to also Define the client

[20:40:11 - 20:40:15]
okay so client is equal to this Bedrock

[20:40:13 - 20:40:16]
client we have created okay with the

[20:40:15 - 20:40:18]
help of this bedro client it will

[20:40:16 - 20:40:19]
authenticate and how it will get this

[20:40:18 - 20:40:21]
particular credential I think you

[20:40:19 - 20:40:23]
remember I think you remember we already

[20:40:21 - 20:40:25]
set uh those credential okay in the

[20:40:23 - 20:40:27]
terminal uh by running that particular

[20:40:25 - 20:40:28]
AWS configure command Okay so it will

[20:40:27 - 20:40:30]
take the access key and secret access

[20:40:28 - 20:40:32]
key from there and it will take by this

[20:40:30 - 20:40:34]
particular Library called boto 3 okay

[20:40:32 - 20:40:35]
boto 3 automatically will take like take

[20:40:34 - 20:40:38]
this particular credential okay from the

[20:40:35 - 20:40:40]
environment then uh what I have to do I

[20:40:38 - 20:40:42]
have to define the

[20:40:40 - 20:40:44]
model uh keyword okay so let's define

[20:40:42 - 20:40:47]
the model keyword also so model

[20:40:44 - 20:40:50]
arguments so inside that I'm going to

[20:40:47 - 20:40:52]
mention one arguments called temperature

[20:40:50 - 20:40:54]
parameter okay because this is the

[20:40:52 - 20:40:56]
parameter we usually twak a lot actually

[20:40:54 - 20:40:58]
whenever we are using llm and all okay

[20:40:56 - 20:41:02]
so here is the temperature parameter but

[20:40:58 - 20:41:04]
it should be defined as a string right

[20:41:02 - 20:41:05]
then here you have to provide the value

[20:41:04 - 20:41:07]
of this particular temperature parameter

[20:41:05 - 20:41:09]
so let's take 0.9 that me I'm taking

[20:41:07 - 20:41:13]
close to one I'm telling my model just

[20:41:09 - 20:41:15]
take any risk and try to give my and try

[20:41:13 - 20:41:16]
to give a creative output okay whenever

[20:41:15 - 20:41:18]
you are generating any kinds of let's

[20:41:16 - 20:41:20]
say output and all so you can set this

[20:41:18 - 20:41:23]
particular parameter based on your

[20:41:20 - 20:41:26]
requirements so I said

[20:41:23 - 20:41:27]
0.9 now what I will do I'll create a uh

[20:41:26 - 20:41:30]
I'll create a function here called my

[20:41:27 - 20:41:34]
chatbot mycore

[20:41:30 - 20:41:34]
chatbot okay my

[20:41:34 - 20:41:39]
chatbot so inside that actually I'm

[20:41:36 - 20:41:41]
going to write the final logic okay so

[20:41:39 - 20:41:43]
it will take the

[20:41:41 - 20:41:45]
language uh I also want to give the

[20:41:43 - 20:41:47]
language okay language let's a choice

[20:41:45 - 20:41:49]
let's say you want to generate this

[20:41:47 - 20:41:51]
particular response in English language

[20:41:49 - 20:41:52]
or let's say uh Spanish language or

[20:41:51 - 20:41:53]
let's say Hindi language okay you can

[20:41:52 - 20:41:54]
give any kinds of language so you can

[20:41:53 - 20:41:57]
give this particular parameter as

[20:41:54 - 20:42:00]
language then it will also take the user

[20:41:57 - 20:42:02]
okay user text user text like whatever

[20:42:00 - 20:42:03]
text user is giving it will also take

[20:42:02 - 20:42:06]
that particular input then what I have

[20:42:03 - 20:42:07]
to do I have to create a prom template

[20:42:06 - 20:42:09]
here so prom template

[20:42:07 - 20:42:11]
I have already imported this particular

[20:42:09 - 20:42:13]
prom template now inside prom template

[20:42:11 - 20:42:16]
first of all I need to specify the input

[20:42:13 - 20:42:19]
variable okay so input

[20:42:16 - 20:42:22]
variables okay so here input variables

[20:42:19 - 20:42:24]
I'm having the language okay language

[20:42:22 - 20:42:26]
and this user text okay the these two

[20:42:24 - 20:42:29]
actually I have this input input

[20:42:26 - 20:42:31]
variable okay here now what I have to

[20:42:29 - 20:42:33]
specify I think I should also close this

[20:42:31 - 20:42:36]
particular quotation yeah then I also

[20:42:33 - 20:42:37]
need to specify my actual template okay

[20:42:36 - 20:42:39]
so the template is equal to

[20:42:37 - 20:42:42]
so here uh you can give any kinds of

[20:42:39 - 20:42:43]
let's say prompt so I'll give this kinds

[20:42:42 - 20:42:46]
of prompt actually so you add a

[20:42:43 - 20:42:48]
chatboard uh you are in this particular

[20:42:46 - 20:42:50]
language and this is the user text okay

[20:42:48 - 20:42:51]
so this is the prompt I have given to my

[20:42:50 - 20:42:53]
llm okay that's how you can Define this

[20:42:51 - 20:42:54]
particular prompt template now let's

[20:42:53 - 20:42:57]
instore this particular promp template

[20:42:54 - 20:43:00]
in a variable I'll just name it as

[20:42:57 - 20:43:00]
prompt okay

[20:43:01 - 20:43:05]
prompt now what I will do I'll just uh

[20:43:04 - 20:43:09]
create a LM chain so LM chain is equal

[20:43:05 - 20:43:11]
to uh I'll Define this particular llm

[20:43:09 - 20:43:14]
object okay llm is equal to the llm

[20:43:11 - 20:43:16]
rapper we have created llm then I also

[20:43:14 - 20:43:18]
need to give this particular prompt so

[20:43:16 - 20:43:21]
prompt is equal

[20:43:18 - 20:43:24]
to okay prompt is equal to prompt we

[20:43:21 - 20:43:26]
have created okay then I store this

[20:43:24 - 20:43:29]
particular things in a variable I'll

[20:43:26 - 20:43:33]
just name it as

[20:43:29 - 20:43:37]
Bedrock okay bedro _

[20:43:33 - 20:43:38]
chain now uh user will uh ask the query

[20:43:37 - 20:43:40]
and they will get the response so for

[20:43:38 - 20:43:42]
this I'm going to use utilize this

[20:43:40 - 20:43:44]
particular Bedrock chain I have created

[20:43:42 - 20:43:47]
so Bedrock chain so it will take first

[20:43:44 - 20:43:49]
of all the language okay input as a

[20:43:47 - 20:43:51]
language because first of all user will

[20:43:49 - 20:43:52]
give one language so it will take that

[20:43:51 - 20:43:54]
particular

[20:43:52 - 20:43:58]
language so

[20:43:54 - 20:44:01]
language should be

[20:43:58 - 20:44:05]
language okay then it will also take the

[20:44:01 - 20:44:06]
user input user text so user text uh

[20:44:05 - 20:44:09]
should be user text I think everything

[20:44:06 - 20:44:12]
is fine let's test okay it should be

[20:44:09 - 20:44:15]
text okay not a test so that's why this

[20:44:12 - 20:44:17]
error is coming user text user text and

[20:44:15 - 20:44:19]
now I think everything is fine now the

[20:44:17 - 20:44:22]
response actually I'll be getting so it

[20:44:19 - 20:44:25]
will uh it will return me the

[20:44:22 - 20:44:26]
response okay so I'll return this

[20:44:25 - 20:44:28]
particular

[20:44:26 - 20:44:29]
response so

[20:44:28 - 20:44:33]
return this

[20:44:29 - 20:44:36]
response yeah now uh this function is

[20:44:33 - 20:44:37]
ready now I can uh inference on top of

[20:44:36 - 20:44:40]
the model actually

[20:44:37 - 20:44:43]
uh I'm I'm using here now what I will do

[20:44:40 - 20:44:45]
I'll create a Basics stream L uh uh you

[20:44:43 - 20:44:49]
can say UI so for this first of all I'll

[20:44:45 - 20:44:51]
give one title s. title s. title so here

[20:44:49 - 20:44:55]
you can give any name of the application

[20:44:51 - 20:44:55]
so here I can write U

[20:44:56 - 20:45:02]
Bedrock okay Bedrock

[20:44:58 - 20:45:07]
demo or Bedrock test okay Bedrock uh

[20:45:02 - 20:45:09]
Bedrock test I can just write uh then uh

[20:45:07 - 20:45:12]
first of all I'll be taking one uh you

[20:45:09 - 20:45:15]
can say select box here because user

[20:45:12 - 20:45:16]
will uh you can say choose the language

[20:45:15 - 20:45:18]
so for this you can uh use this

[20:45:16 - 20:45:21]
particular code snippit so see here I'm

[20:45:18 - 20:45:23]
creating one uh like slate box and user

[20:45:21 - 20:45:25]
will select the language so here you can

[20:45:23 - 20:45:27]
add as many as language you can so I

[20:45:25 - 20:45:29]
have only added three language English

[20:45:27 - 20:45:31]
Spanish and Hindi okay you can also add

[20:45:29 - 20:45:34]
Bengali then you can also add let's say

[20:45:31 - 20:45:37]
uh I mean U like Russian okay anything

[20:45:34 - 20:45:40]
you can add here it's up to you now what

[20:45:37 - 20:45:42]
I will do uh I'll just write one logic

[20:45:40 - 20:45:43]
if user is given any kinds of language

[20:45:42 - 20:45:46]
so what you have to do first of all you

[20:45:43 - 20:45:49]
have to take the input from the user so

[20:45:46 - 20:45:51]
I'll take this input and I will store in

[20:45:49 - 20:45:54]
this particular variable user text okay

[20:45:51 - 20:45:58]
user text is equal to so here I'm going

[20:45:54 - 20:46:00]
to create a uh select uh text area Okay

[20:45:58 - 20:46:01]
because uh I'm going to just create a

[20:46:00 - 20:46:03]
box in inside that particular box user

[20:46:01 - 20:46:07]
will give the input okay so for this you

[20:46:03 - 20:46:09]
can use std. sidebar

[20:46:07 - 20:46:11]
s.

[20:46:09 - 20:46:13]
sidebar okay then you can take something

[20:46:11 - 20:46:16]
called text idea okay text

[20:46:13 - 20:46:19]
idea yeah then inside that you can

[20:46:16 - 20:46:22]
Define the label that means uh the

[20:46:19 - 20:46:25]
question actually you want to render

[20:46:22 - 20:46:29]
here so I'll give a message what is

[20:46:25 - 20:46:29]
your okay what is your

[20:46:31 - 20:46:37]
question okay and you can also Define

[20:46:35 - 20:46:39]
like how many let's say uh character

[20:46:37 - 20:46:42]
user will able to put okay so here you

[20:46:39 - 20:46:44]
can just Define Max character is equal

[20:46:42 - 20:46:46]
to I will just specify 100 okay so 100

[20:46:44 - 20:46:49]
character user will put here then once

[20:46:46 - 20:46:51]
it is done so I also need to check this

[20:46:49 - 20:46:54]
user text that means if user has given

[20:46:51 - 20:46:56]
any kinds of input text that means the

[20:46:54 - 20:46:58]
prompt okay to the llm so what I have to

[20:46:56 - 20:47:00]
do first of all I have to uh give it to

[20:46:58 - 20:47:02]
my model so I'll call this particular

[20:47:00 - 20:47:04]
function my chatbot inside that first of

[20:47:02 - 20:47:06]
all I'll give my language okay the

[20:47:04 - 20:47:08]
language user has selected then I will

[20:47:06 - 20:47:09]
also provide something called user text

[20:47:08 - 20:47:12]
okay whatever question actually user is

[20:47:09 - 20:47:15]
asking then it will give me the response

[20:47:12 - 20:47:17]
okay so it will give me the

[20:47:15 - 20:47:19]
response yeah then after that I will

[20:47:17 - 20:47:21]
write this particular response in the

[20:47:19 - 20:47:25]
Stream lit okay stream L application say

[20:47:21 - 20:47:26]
St dot write and here I'm going to write

[20:47:25 - 20:47:28]
this particular

[20:47:26 - 20:47:31]
response so I'm going to only extract

[20:47:28 - 20:47:33]
the text okay from the response so it

[20:47:31 - 20:47:35]
should be text yeah so I think it should

[20:47:33 - 20:47:37]
work now let's test whether it is

[20:47:35 - 20:47:39]
working or not so I'm going to open up

[20:47:37 - 20:47:41]
my terminal so let me Cate this

[20:47:39 - 20:47:43]
particular terminal and I'm going to

[20:47:41 - 20:47:45]
execute this particular file this

[20:47:43 - 20:47:46]
Bedrock trials. P so for this you have

[20:47:45 - 20:47:48]
to execute this particular command okay

[20:47:46 - 20:47:50]
so let me also add this particular

[20:47:48 - 20:47:53]
command so if you want to execute the

[20:47:50 - 20:47:58]
file so you can write stream

[20:47:53 - 20:47:59]
lit okay stream lit run uh this is

[20:47:58 - 20:48:02]
inside

[20:47:59 - 20:48:03]
resarch okay slash uh the name of this

[20:48:02 - 20:48:07]
file is

[20:48:03 - 20:48:07]
bedra Trials

[20:48:08 - 20:48:14]
okay do p is the name now let's copy the

[20:48:12 - 20:48:17]
command I'll open up my terminal and let

[20:48:14 - 20:48:17]
me

[20:48:18 - 20:48:23]
execute okay so it is giving one error

[20:48:20 - 20:48:27]
it is telling research okay so research

[20:48:23 - 20:48:27]
spelling is not correct let me check so

[20:48:30 - 20:48:37]
research okay now I think it's fine now

[20:48:32 - 20:48:37]
let me copy and execute

[20:48:38 - 20:48:44]
okay now my application is

[20:48:40 - 20:48:46]
running now if I go to my browser now if

[20:48:44 - 20:48:48]
I open up my browser okay so it will

[20:48:46 - 20:48:50]
open up one one new tab so this is the

[20:48:48 - 20:48:53]
tab it has opened but again I can see

[20:48:50 - 20:48:55]
there is a error so what is the error so

[20:48:53 - 20:48:57]
unknown service error so unknown service

[20:48:55 - 20:49:00]
Bedrock undor runtime okay so let me

[20:48:57 - 20:49:02]
check this particular C snippit so here

[20:49:00 - 20:49:05]
uh okay so it should be Bedrock hypen

[20:49:02 - 20:49:07]
runtime okay not a underscore runtime

[20:49:05 - 20:49:09]
now I think it should work I go back and

[20:49:07 - 20:49:11]
rerun this particular application okay

[20:49:09 - 20:49:13]
now see this is my interface now you can

[20:49:11 - 20:49:15]
select any kinds of language so let's

[20:49:13 - 20:49:18]
select the English language now ask any

[20:49:15 - 20:49:22]
kind of qu so I'll ask what is okay what

[20:49:18 - 20:49:24]
is uh let's say um what is C++ okay what

[20:49:22 - 20:49:26]
is

[20:49:24 - 20:49:28]
C++ so now let's see whether it is able

[20:49:26 - 20:49:32]
to give me answer or not now if you want

[20:49:28 - 20:49:32]
to execute you need to press control and

[20:49:32 - 20:49:36]
enter so here it is giving me the

[20:49:34 - 20:49:38]
response C++ is a general programming

[20:49:36 - 20:49:40]
Lang language uh that means uh yeah so

[20:49:38 - 20:49:42]
it's a correct response now you can any

[20:49:40 - 20:49:45]
ask any kind of query so you can ask

[20:49:42 - 20:49:49]
like what is python okay and control

[20:49:45 - 20:49:50]
enter see it is also giving the response

[20:49:49 - 20:49:53]
now see guys although I'm using this

[20:49:50 - 20:49:54]
particular model okay this large

[20:49:53 - 20:49:56]
language model and I'm also using this

[20:49:54 - 20:49:58]
open source model OKAY zuras is also

[20:49:56 - 20:50:01]
open source model but the response time

[20:49:58 - 20:50:03]
is like very uh first here because this

[20:50:01 - 20:50:05]
model is already hosted okay over the

[20:50:03 - 20:50:06]
wraw and we we can access this

[20:50:05 - 20:50:07]
particular model with the help of this

[20:50:06 - 20:50:09]
particular client okay the client

[20:50:07 - 20:50:11]
actually we have created okay this

[20:50:09 - 20:50:12]
particular client we have created okay

[20:50:11 - 20:50:13]
so that's is why actually uh whenever

[20:50:12 - 20:50:15]
you want to create any kind of

[20:50:13 - 20:50:17]
production gr application and you want

[20:50:15 - 20:50:18]
to let's say get a quick response at

[20:50:17 - 20:50:20]
that time you can go with these other

[20:50:18 - 20:50:21]
the services but whenever let's say you

[20:50:20 - 20:50:23]
are loading these other the model on

[20:50:21 - 20:50:26]
your machine at that time your inference

[20:50:23 - 20:50:27]
time would be very very higher okay like

[20:50:26 - 20:50:28]
it will take lots of time to execute

[20:50:27 - 20:50:30]
that particular code so that's why

[20:50:28 - 20:50:32]
actually you can use this particular

[20:50:30 - 20:50:34]
bedrock and this like very scalable okay

[20:50:32 - 20:50:35]
like it is like very efficient solution

[20:50:34 - 20:50:37]
whenever you are trying to create any

[20:50:35 - 20:50:39]
kind of genbi application now see guys

[20:50:37 - 20:50:40]
uh I already showed you how we can

[20:50:39 - 20:50:42]
access different different model now

[20:50:40 - 20:50:43]
let's say you want to also access Meta

[20:50:42 - 20:50:45]
Meta model okay so what you can do you

[20:50:43 - 20:50:47]
can come to the meta and you can take

[20:50:45 - 20:50:49]
this particular model ID now let's say

[20:50:47 - 20:50:51]
you want to access this particular model

[20:50:49 - 20:50:53]
this seven 7 70 billion parameter model

[20:50:51 - 20:50:54]
so you need to give this particular ID

[20:50:53 - 20:50:57]
okay so here you just only need to

[20:50:54 - 20:50:59]
change so let me show you if I open up

[20:50:57 - 20:51:00]
the code so here you only need to change

[20:50:59 - 20:51:02]
okay inside the model ID and everything

[20:51:00 - 20:51:04]
will remain same but here only we're

[20:51:02 - 20:51:06]
doing the inferencing okay on top of the

[20:51:04 - 20:51:07]
model but now what I'm going to do I'm

[20:51:06 - 20:51:10]
I'm going to create one NN rag

[20:51:07 - 20:51:13]
application okay so NN rag uh like you

[20:51:10 - 20:51:15]
can say project we'll be implementing so

[20:51:13 - 20:51:16]
what is rag so let me give you one uh

[20:51:15 - 20:51:19]
idea so first of all I'm going to create

[20:51:16 - 20:51:21]
a architecture okay of this particular

[20:51:19 - 20:51:22]
project I'm going to develop so here

[20:51:21 - 20:51:23]
first of all what I'm going to do as I

[20:51:22 - 20:51:25]
already told you I'm going to use PDF

[20:51:23 - 20:51:29]
documents okay let's say I'm having some

[20:51:25 - 20:51:32]
PDF documents okay PDF

[20:51:29 - 20:51:34]
docs okay so it can be multiple PDF also

[20:51:32 - 20:51:35]
it can be one PDF also it's up to you

[20:51:34 - 20:51:40]
now what I have to do first of all I

[20:51:35 - 20:51:40]
have to extract the text okay I have to

[20:51:40 - 20:51:45]
extract okay extract data okay from this

[20:51:43 - 20:51:45]
particular

[20:51:45 - 20:51:51]
PDF after extracting what I have to do I

[20:51:49 - 20:51:51]
have to create a

[20:51:52 - 20:51:57]
chance I have to create a chance why I

[20:51:55 - 20:51:58]
have to create a chance because all the

[20:51:57 - 20:52:00]
model is having their input length okay

[20:51:58 - 20:52:02]
if I show you uh let's say I'm using

[20:52:00 - 20:52:05]
this uh metal Lama 2 okay going forward

[20:52:02 - 20:52:08]
I'm I'll be using this metal Lama 2 so

[20:52:05 - 20:52:09]
metal Lama 2 uh is is having actually uh

[20:52:08 - 20:52:11]
input size okay this token input size

[20:52:09 - 20:52:13]
let me show you so if I go to the

[20:52:11 - 20:52:16]
official metal Lama 2

[20:52:13 - 20:52:19]
website so let's go to the

[20:52:16 - 20:52:20]
website so here you can see guys so it

[20:52:19 - 20:52:22]
is having different different models 7

[20:52:20 - 20:52:25]
billion 13 billion and 70 billion and if

[20:52:22 - 20:52:27]
you see here the context length is 496

[20:52:25 - 20:52:28]
token okay now what will happen so

[20:52:27 - 20:52:30]
whenever you are using any kinds of PDF

[20:52:28 - 20:52:32]
documents so if you extract all the data

[20:52:30 - 20:52:33]
that means all the documents okay from

[20:52:32 - 20:52:36]
the PDF you will see sometimes it would

[20:52:33 - 20:52:38]
be more than 4,096 token okay it would

[20:52:36 - 20:52:40]
be more more than 496 token at the time

[20:52:38 - 20:52:42]
if you give this particular input to the

[20:52:40 - 20:52:44]
model okay to the model your model will

[20:52:42 - 20:52:45]
throw input error so to prevent this

[20:52:44 - 20:52:47]
kinds of issue what I have to do I have

[20:52:45 - 20:52:48]
to create a chunks okay chunks means I

[20:52:47 - 20:52:50]
have to create a different different

[20:52:48 - 20:52:51]
chunks okay let's say this is your

[20:52:50 - 20:52:54]
entire text okay let's say this is your

[20:52:51 - 20:52:56]
entire

[20:52:54 - 20:52:57]
text okay this is your inter text so

[20:52:56 - 20:52:59]
what you will do you'll just take a

[20:52:57 - 20:53:02]
chance okay chunks of the text so this

[20:52:59 - 20:53:03]
is one chunks this is another chunks

[20:53:02 - 20:53:06]
okay this is another chunks okay that's

[20:53:03 - 20:53:07]
how you will be giving to the model okay

[20:53:06 - 20:53:08]
as in inut so different different chunks

[20:53:07 - 20:53:10]
actually you are giving instead of

[20:53:08 - 20:53:11]
taking all the text together you are

[20:53:10 - 20:53:12]
giving different different chunks so

[20:53:11 - 20:53:14]
that time you have to also Define the

[20:53:12 - 20:53:15]
Chun size okay and there is another

[20:53:14 - 20:53:17]
parameter we can also refine called

[20:53:15 - 20:53:19]
chunks overlap okay so this is the idea

[20:53:17 - 20:53:22]
of this chunin now once this chunks is

[20:53:19 - 20:53:24]
created now what I have to

[20:53:22 - 20:53:27]
do I have to download one embedding

[20:53:24 - 20:53:28]
model okay I have to download one

[20:53:27 - 20:53:30]
embedding

[20:53:28 - 20:53:32]
model so in this case I'm going to use

[20:53:30 - 20:53:34]
this Titan embedding model I already

[20:53:32 - 20:53:35]
showed you okay so embedding model Titan

[20:53:34 - 20:53:36]
embedding model with the help of this

[20:53:35 - 20:53:38]
particular embedding model I will

[20:53:36 - 20:53:41]
convert this particular data to Vector

[20:53:38 - 20:53:43]
embedding okay so Vector

[20:53:41 - 20:53:44]
embedding Vector embedding that means

[20:53:43 - 20:53:46]
numerical representation Vector

[20:53:44 - 20:53:47]
embedding then what I have to do I have

[20:53:46 - 20:53:48]
to store this particular Vector

[20:53:47 - 20:53:50]
embedding in a knowledge base that means

[20:53:48 - 20:53:54]
in a vector DV so here I'm going to use

[20:53:50 - 20:53:56]
something called FAS okay f is a vector

[20:53:54 - 20:54:00]
DB it's a vector

[20:53:56 - 20:54:02]
DB Vector DB okay so this is nothing but

[20:54:00 - 20:54:02]
this is my knowledge

[20:54:04 - 20:54:11]
base knowledge base okay now what will

[20:54:08 - 20:54:13]
happen user will ask some query so let's

[20:54:11 - 20:54:16]
say this is the

[20:54:13 - 20:54:19]
user so user will ask some query so

[20:54:16 - 20:54:21]
let's say this is the query user has

[20:54:19 - 20:54:23]
asked so what I have to do I have to

[20:54:21 - 20:54:25]
pass this particular query to my

[20:54:23 - 20:54:26]
knowledge base okay so it will do

[20:54:25 - 20:54:28]
something called semantic sear okay

[20:54:26 - 20:54:30]
semantic sear semantic index S I think

[20:54:28 - 20:54:31]
you already know what is semantic sear

[20:54:30 - 20:54:33]
inside Vector DB then it will also

[20:54:31 - 20:54:37]
return some of the rank results okay it

[20:54:33 - 20:54:39]
will return some rank results

[20:54:37 - 20:54:39]
rank

[20:54:40 - 20:54:44]
results okay so it will return this

[20:54:42 - 20:54:45]
particular rank results B on the K

[20:54:44 - 20:54:47]
parameter let's say if K is equal to

[20:54:45 - 20:54:49]
three so it will return only three

[20:54:47 - 20:54:50]
relevant answer okay with respect to the

[20:54:49 - 20:54:53]
query you have asked now what I have to

[20:54:50 - 20:54:56]
do I have to connect the LM so I'll be

[20:54:53 - 20:54:58]
collecting the llm so in this case I'm

[20:54:56 - 20:55:01]
using something called Lama

[20:54:58 - 20:55:04]
2 okay Lama 2 so I'll fit this

[20:55:01 - 20:55:06]
particular rank treasur to the llm okay

[20:55:04 - 20:55:07]
then I'll also give the query to the llm

[20:55:06 - 20:55:09]
so LM will try to understand the query

[20:55:07 - 20:55:11]
it will also try to understand the

[20:55:09 - 20:55:13]
results that means the answer then it

[20:55:11 - 20:55:14]
will process this particular query

[20:55:13 - 20:55:18]
answer and it will give you the actual

[20:55:14 - 20:55:20]
response okay actual response so

[20:55:18 - 20:55:22]
response okay so let's say you have

[20:55:20 - 20:55:23]
asked something related python so first

[20:55:22 - 20:55:24]
of all it will check in the knowledge

[20:55:23 - 20:55:27]
base whether I'm having answer related

[20:55:24 - 20:55:29]
python or not if it it is having so it

[20:55:27 - 20:55:31]
will take most relevant three output

[20:55:29 - 20:55:32]
okay from this particular knowledge base

[20:55:31 - 20:55:34]
then it will process okay based on the

[20:55:32 - 20:55:35]
query then it will give you the correct

[20:55:34 - 20:55:37]
response that means what is python

[20:55:35 - 20:55:39]
exactly okay this this is the idea and

[20:55:37 - 20:55:41]
this is called okay this is called rag

[20:55:39 - 20:55:42]
application okay rag pipeline this is

[20:55:41 - 20:55:44]
called rag

[20:55:42 - 20:55:46]
pipeline okay this called rag pipeline

[20:55:44 - 20:55:48]
that means retrieval augmented

[20:55:46 - 20:55:50]
generation so instead of fining the

[20:55:48 - 20:55:52]
model what I'm doing I'm just adding

[20:55:50 - 20:55:54]
some additional knowledge okay

[20:55:52 - 20:55:56]
additional information

[20:55:54 - 20:55:58]
in okay

[20:55:56 - 20:56:00]
information okay additional information

[20:55:58 - 20:56:02]
to the model okay so this is my

[20:56:00 - 20:56:03]
additional information so I'm just

[20:56:02 - 20:56:05]
processing this information I'm creating

[20:56:03 - 20:56:07]
the embeddings okay and I'm storing in a

[20:56:05 - 20:56:08]
knowledge base and I'm connecting okay

[20:56:07 - 20:56:10]
I'm connecting the llm to the knowledge

[20:56:08 - 20:56:13]
base and whatever user is asking this

[20:56:10 - 20:56:14]
kinds of query okay I'm just uh like

[20:56:13 - 20:56:15]
getting the response and I'm showing to

[20:56:14 - 20:56:18]
the user okay so this is called rag

[20:56:15 - 20:56:19]
Pipeline and what is fine tuning fine

[20:56:18 - 20:56:21]
tuning means whenever you will be like

[20:56:19 - 20:56:22]
say training that particular model that

[20:56:21 - 20:56:24]
means you will be changing the we

[20:56:22 - 20:56:26]
parameter that that is called actually

[20:56:24 - 20:56:28]
fine tuning and fine tuning is like very

[20:56:26 - 20:56:29]
hard task and it's like very costly task

[20:56:28 - 20:56:32]
okay so that's why you don't need to

[20:56:29 - 20:56:34]
perform this fine tuning every time okay

[20:56:32 - 20:56:35]
first of all you will be uh applying

[20:56:34 - 20:56:37]
this particular rag concept and if rag

[20:56:35 - 20:56:40]
is working fine then you'll be going to

[20:56:37 - 20:56:42]
going with the r rag concept and if rag

[20:56:40 - 20:56:43]
concept is failing somewhere that time

[20:56:42 - 20:56:45]
actually you have to perform the fine

[20:56:43 - 20:56:46]
tuning so feature actually be also

[20:56:45 - 20:56:48]
learning how we can perform the fine

[20:56:46 - 20:56:49]
tuning okay on top of the custom data

[20:56:48 - 20:56:51]
that thing we'll be also learning so yes

[20:56:49 - 20:56:53]
guys this is the entire architecture of

[20:56:51 - 20:56:55]
our like you can say application now I

[20:56:53 - 20:56:57]
need to code this particular example so

[20:56:55 - 20:56:59]
for this I'm going to again open up my

[20:56:57 - 20:57:01]
code editor now here I'm going to open

[20:56:59 - 20:57:03]
this particular m.p file so guys I think

[20:57:01 - 20:57:04]
you already got the idea how things are

[20:57:03 - 20:57:05]
working and how we can make the

[20:57:04 - 20:57:07]
connection with this particular bedro

[20:57:05 - 20:57:08]
and all so let me just quickly write all

[20:57:07 - 20:57:10]
the codes so first of all I need to

[20:57:08 - 20:57:12]
import some of the library here so let's

[20:57:10 - 20:57:14]
import all the library so these are the

[20:57:12 - 20:57:15]
libraries are required okay I'm

[20:57:14 - 20:57:17]
importing boto 3 because of that

[20:57:15 - 20:57:19]
particular you can say Bedrock I want to

[20:57:17 - 20:57:21]
access with the Bedrock streamly I need

[20:57:19 - 20:57:23]
because I'll be creating the web

[20:57:21 - 20:57:24]
application then I'm also importing

[20:57:23 - 20:57:25]
something called Bedrock embedding okay

[20:57:24 - 20:57:27]
because I already told you I'm going to

[20:57:25 - 20:57:29]
use one embedding model OKAY from the

[20:57:27 - 20:57:31]
Bedrock so Bedrock having also embedding

[20:57:29 - 20:57:33]
model so if I show you let's say Amazon

[20:57:31 - 20:57:36]
is also having one model called Amazon

[20:57:33 - 20:57:38]
Titan okay so let me show you

[20:57:36 - 20:57:40]
yeah Titan embedding G1 text okay this

[20:57:38 - 20:57:41]
is the model so this embedding model

[20:57:40 - 20:57:43]
actually I'm going to use okay that's

[20:57:41 - 20:57:46]
why I'm importing this particular

[20:57:43 - 20:57:47]
embedding from the uh you can say Lang

[20:57:46 - 20:57:49]
chain okay and this is the Bedrock eming

[20:57:47 - 20:57:51]
then I also need this llm that means

[20:57:49 - 20:57:53]
Bedrock then P PDF directory loader

[20:57:51 - 20:57:55]
because I'm going to keep some PDF okay

[20:57:53 - 20:57:57]
in the directory so let me create a

[20:57:55 - 20:58:01]
directory here I'm going to name it as

[20:57:57 - 20:58:03]
data okay and I can name it as PDF data

[20:58:01 - 20:58:04]
okay PDF data inside that I'm going to

[20:58:03 - 20:58:05]
keep my PDF so with the help of this

[20:58:04 - 20:58:07]
particular package I'm going to load

[20:58:05 - 20:58:09]
this particular PDF then character

[20:58:07 - 20:58:10]
recursive character text splitter so I

[20:58:09 - 20:58:12]
already told you something called

[20:58:10 - 20:58:14]
chunins so if you want to perform the

[20:58:12 - 20:58:15]
chunins you have to use this particular

[20:58:14 - 20:58:17]
method called character text splitter

[20:58:15 - 20:58:19]
okay recursive character text splitter

[20:58:17 - 20:58:21]
then I also need something called Vector

[20:58:19 - 20:58:22]
DV so Vector DV wise I'm going to use F

[20:58:21 - 20:58:24]
and it is already available inside

[20:58:22 - 20:58:26]
langen and prom template and retal

[20:58:24 - 20:58:27]
keyway because I'm going to perform then

[20:58:26 - 20:58:28]
I'm importing this particular retal

[20:58:27 - 20:58:30]
keyway okay this particular method

[20:58:28 - 20:58:32]
because as I already told you I'm going

[20:58:30 - 20:58:33]
to create this rag application and on

[20:58:32 - 20:58:35]
top of the knowledge base actually I'll

[20:58:33 - 20:58:37]
be performing the query operation okay

[20:58:35 - 20:58:38]
so that's why actually this is need it

[20:58:37 - 20:58:39]
now the first thing what you have to do

[20:58:38 - 20:58:41]
you have

[20:58:39 - 20:58:43]
to Define one prom template okay so this

[20:58:41 - 20:58:46]
is the default prom template I just

[20:58:43 - 20:58:48]
prepared okay so here I just written so

[20:58:46 - 20:58:50]
you human will ask some query okay based

[20:58:48 - 20:58:52]
on that you have to return the response

[20:58:50 - 20:58:55]
okay by taking the context okay context

[20:58:52 - 20:58:57]
means the knowledge base so this is the

[20:58:55 - 20:58:59]
prom template I have created now what

[20:58:57 - 20:59:01]
you have to do you have to collect the

[20:58:59 - 20:59:03]
you have to connect the client okay so I

[20:59:01 - 20:59:04]
think you know how to collect the client

[20:59:03 - 20:59:06]
so this is the code for the client so

[20:59:04 - 20:59:08]
boto three client and you have to

[20:59:06 - 20:59:09]
provide the service name and the region

[20:59:08 - 20:59:11]
name then what you have to do you have

[20:59:09 - 20:59:14]
to get the embedding model so to get the

[20:59:11 - 20:59:16]
embedding model what you can do you can

[20:59:14 - 20:59:17]
use this particular Bedrock embedding

[20:59:16 - 20:59:20]
okay Bedrock embedding to load the

[20:59:17 - 20:59:22]
embedding model so here is the

[20:59:20 - 20:59:23]
code okay so that's how you can load

[20:59:22 - 20:59:25]
this particular embedding model as you

[20:59:23 - 20:59:26]
can see Bedrock embedding here you have

[20:59:25 - 20:59:28]
to give the model ID so Amazon Titan

[20:59:26 - 20:59:31]
embed text V1 so this is the model

[20:59:28 - 20:59:33]
actually I'm using so Amazon Titan embed

[20:59:31 - 20:59:35]
text V1 okay so this is the model ID I'm

[20:59:33 - 20:59:37]
using let me show you yeah so this is

[20:59:35 - 20:59:39]
the model ID after that you have to also

[20:59:37 - 20:59:41]
assign the client okay the client

[20:59:39 - 20:59:43]
actually you have created then first of

[20:59:41 - 20:59:45]
all what I have to do I have to load

[20:59:43 - 20:59:46]
this particular PDF documents okay so I

[20:59:45 - 20:59:48]
don't have any PDFs so let me upload

[20:59:46 - 20:59:50]
some of the PDFs here so I'm going to

[20:59:48 - 20:59:52]
open up the folder and here I'm going to

[20:59:50 - 20:59:54]
keep this particular PDF okay so this is

[20:59:52 - 20:59:56]
one research paper actually as you can

[20:59:54 - 20:59:58]
see so let me show you this is one

[20:59:56 - 21:00:00]
research paper and uh the name of the

[20:59:58 - 21:00:02]
research paper is development of

[21:00:00 - 21:00:04]
multiple combined regation method for

[21:00:02 - 21:00:05]
rain rainfall measurement okay so this

[21:00:04 - 21:00:07]
is the research paper actually I have

[21:00:05 - 21:00:08]
have given here so you can give any

[21:00:07 - 21:00:10]
kinds of resarch paper any kinds of PDF

[21:00:08 - 21:00:12]
here any kinds of PDF documents it's up

[21:00:10 - 21:00:13]
to you okay so I already have this in my

[21:00:12 - 21:00:16]
system that's why I'm giving this

[21:00:13 - 21:00:18]
particular PDF now let's uh see how we

[21:00:16 - 21:00:20]
can extract these are the PDF text now

[21:00:18 - 21:00:23]
what I will do I have already created

[21:00:20 - 21:00:26]
one function so let me show you so

[21:00:23 - 21:00:28]
inside main. Pi here I can mention this

[21:00:26 - 21:00:30]
particular function called get documents

[21:00:28 - 21:00:31]
okay so first of all I will load this

[21:00:30 - 21:00:34]
particular PDF okay as you can see so

[21:00:31 - 21:00:36]
here I need to give the path of the PDF

[21:00:34 - 21:00:38]
copy the name

[21:00:36 - 21:00:39]
yeah so this is the folder inside that

[21:00:38 - 21:00:41]
actually whatever PDF actually you are

[21:00:39 - 21:00:43]
having it will load everything then

[21:00:41 - 21:00:44]
after that I'm performing this recursive

[21:00:43 - 21:00:45]
T splitter that means I'm performing

[21:00:44 - 21:00:47]
this chuning operation okay so as you

[21:00:45 - 21:00:49]
can see so this is the chunin actually

[21:00:47 - 21:00:51]
I'm doing I'm after extracting the

[21:00:49 - 21:00:52]
documents I'm performing this chuning

[21:00:51 - 21:00:53]
operation that means it will create the

[21:00:52 - 21:00:55]
chunks different different chunks and

[21:00:53 - 21:00:57]
this is the Chun size that means it will

[21:00:55 - 21:00:59]
take thousand character okay in one

[21:00:57 - 21:01:00]
chunks let me show you so let's say

[21:00:59 - 21:01:01]
whenever it will create this particular

[21:01:00 - 21:01:04]
chance it will consider thousands

[21:01:01 - 21:01:06]
character Okay thousands tokens in a one

[21:01:04 - 21:01:08]
chance okay so that's you have to give

[21:01:06 - 21:01:10]
this particular chunk size and chunk

[21:01:08 - 21:01:12]
overlap means how much overlap actually

[21:01:10 - 21:01:14]
you want from the previous okay from the

[21:01:12 - 21:01:15]
previous um like you can say chunks you

[21:01:14 - 21:01:18]
have created okay so this is called

[21:01:15 - 21:01:20]
chunks overlap now once this is done

[21:01:18 - 21:01:21]
then you have to uh apply this

[21:01:20 - 21:01:23]
particular split document that means it

[21:01:21 - 21:01:25]
will perform the chuning then after that

[21:01:23 - 21:01:27]
I'm just returning the documents then I

[21:01:25 - 21:01:29]
also need to load the vector okay so to

[21:01:27 - 21:01:33]
load the vector you can execute this

[21:01:29 - 21:01:33]
particular function let me show

[21:01:34 - 21:01:38]
you you can load this particular

[21:01:36 - 21:01:40]
function called get Vector store now it

[21:01:38 - 21:01:41]
will take the documents the documents

[21:01:40 - 21:01:43]
actually you have extracted now here I'm

[21:01:41 - 21:01:46]
using this F okay F Vector DV as you can

[21:01:43 - 21:01:48]
see FES and I'm initializing the files

[21:01:46 - 21:01:50]
I'm giving this particular documentation

[21:01:48 - 21:01:51]
the documentation I have extracted and

[21:01:50 - 21:01:52]
also giving the vector embedding okay

[21:01:51 - 21:01:55]
the vector embedding I have initialized

[21:01:52 - 21:01:56]
okay vrog embedding then what it will do

[21:01:55 - 21:01:57]
it will automatically take those other

[21:01:56 - 21:01:58]
the documents and it will convert to

[21:01:57 - 21:02:00]
Vector representation okay and it will

[21:01:58 - 21:02:02]
save inside my local system with the

[21:02:00 - 21:02:04]
help of this particular name okay F

[21:02:02 - 21:02:06]
index now once it is done I also need

[21:02:04 - 21:02:08]
the llm op okay so I have created

[21:02:06 - 21:02:11]
another function called get llm so here

[21:02:08 - 21:02:12]
I'm initializing this particular uh you

[21:02:11 - 21:02:15]
can say llm now if you see I'm using

[21:02:12 - 21:02:18]
metal Lama to okay so now if I show you

[21:02:15 - 21:02:20]
my Bedrock now if I go to the overview

[21:02:18 - 21:02:22]
and I'm using this Lama 2 and I'm using

[21:02:20 - 21:02:24]
this particular model say 7 billion

[21:02:22 - 21:02:26]
model okay now this is the model ID okay

[21:02:24 - 21:02:29]
just copy and here you can paste it okay

[21:02:26 - 21:02:30]
here you can mention now client and here

[21:02:29 - 21:02:33]
you can give the model arguments okay

[21:02:30 - 21:02:36]
now here I have given Max gen length

[21:02:33 - 21:02:38]
okay that means how much actually like

[21:02:36 - 21:02:40]
let's say tokens he want to get as a

[21:02:38 - 21:02:42]
output okay from the llm so here I've

[21:02:40 - 21:02:44]
given 512 okay that is 512 token it will

[21:02:42 - 21:02:46]
give me as a output and after that I'm

[21:02:44 - 21:02:49]
just returning the LM then what I have

[21:02:46 - 21:02:50]
to do I have to create the prom template

[21:02:49 - 21:02:52]
so I think you remember we already

[21:02:50 - 21:02:54]
defined the uh you can say prompt here

[21:02:52 - 21:02:56]
so prompt template now here I'm just

[21:02:54 - 21:02:57]
defining the template okay inside the

[21:02:56 - 21:02:59]
template I'm just defining these other

[21:02:57 - 21:03:00]
the thing now input variable should be

[21:02:59 - 21:03:03]
context and question because here I

[21:03:00 - 21:03:07]
mentioned okay question and context now

[21:03:03 - 21:03:07]
once it is done uh

[21:03:07 - 21:03:11]
I have to uh create the response

[21:03:10 - 21:03:13]
function because here it will take the

[21:03:11 - 21:03:14]
input and it will give you the response

[21:03:13 - 21:03:16]
okay so this is the simple respon

[21:03:14 - 21:03:17]
function so it will take the llm that

[21:03:16 - 21:03:19]
means large language model and Vector

[21:03:17 - 21:03:20]
destroy that means your F and query now

[21:03:19 - 21:03:22]
first of all it will create this

[21:03:20 - 21:03:25]
particular Ral object okay inside that

[21:03:22 - 21:03:26]
it will take the llm and chain type is

[21:03:25 - 21:03:28]
stop because I'm going to create a

[21:03:26 - 21:03:29]
simple chain that's why because in Lang

[21:03:28 - 21:03:32]
chain there are so many chain type you

[21:03:29 - 21:03:33]
can explore over the documentation now R

[21:03:32 - 21:03:35]
object means your knowledge base okay

[21:03:33 - 21:03:38]
here I'm using the f as you can see

[21:03:35 - 21:03:40]
store F and as reter and I'm performing

[21:03:38 - 21:03:42]
similarity s okay and this is the uh

[21:03:40 - 21:03:43]
this rank result parameter that means K

[21:03:42 - 21:03:46]
is equal to three it will return only

[21:03:43 - 21:03:48]
three okay relevant answer then I'm just

[21:03:46 - 21:03:50]
returning okay this particular Source

[21:03:48 - 21:03:51]
document as well then you also need to

[21:03:50 - 21:03:53]
give the promt template you have created

[21:03:51 - 21:03:55]
here then you need to ask the query okay

[21:03:53 - 21:03:57]
the query actually user will give and

[21:03:55 - 21:03:58]
whatever answer actually will get I'm

[21:03:57 - 21:04:00]
just returning this particular answer

[21:03:58 - 21:04:03]
okay then here I just need to create a

[21:04:00 - 21:04:05]
simple user application so first of all

[21:04:03 - 21:04:07]
I'm going to create a new main method

[21:04:05 - 21:04:10]
let me show you so this is the main

[21:04:07 - 21:04:13]
method so here first of all I've given

[21:04:10 - 21:04:15]
one title let a rag demo and here I've

[21:04:13 - 21:04:17]
given the name of the project into rag

[21:04:15 - 21:04:19]
application okay then here I'm just

[21:04:17 - 21:04:22]
giving one input okay

[21:04:19 - 21:04:23]
input text okay text input from the user

[21:04:22 - 21:04:25]
user will ask any of query from the PDF

[21:04:23 - 21:04:28]
itself now first of all what I have to

[21:04:25 - 21:04:29]
do okay let's say if you want to ask any

[21:04:28 - 21:04:30]
question on top of the knowledge based

[21:04:29 - 21:04:31]
first of all you have to build a

[21:04:30 - 21:04:33]
knowledge base that means you have to

[21:04:31 - 21:04:35]
execute this particular function called

[21:04:33 - 21:04:36]
get Vector store okay but before that

[21:04:35 - 21:04:38]
you have to execute this particular

[21:04:36 - 21:04:39]
function called get documents that means

[21:04:38 - 21:04:42]
it will extract the documents after that

[21:04:39 - 21:04:43]
it will store as a embedding okay so I

[21:04:42 - 21:04:45]
have to execute this two function so for

[21:04:43 - 21:04:48]
this I'm going to create one button here

[21:04:45 - 21:04:49]
okay so let me show you so here I'm

[21:04:48 - 21:04:52]
going to create one button as you can

[21:04:49 - 21:04:53]
see so here I'm Crea one slide but and

[21:04:52 - 21:04:56]
here I've given update or create a

[21:04:53 - 21:04:57]
vector store now if someone is clicking

[21:04:56 - 21:04:59]
on this particular button store Vector

[21:04:57 - 21:05:00]
first of all it will run this particular

[21:04:59 - 21:05:01]
document that means this particular

[21:05:00 - 21:05:03]
function and it will extract the

[21:05:01 - 21:05:06]
documentation and whatever documentation

[21:05:03 - 21:05:07]
actually I'm getting okay

[21:05:06 - 21:05:09]
sorry whatever documentation actually

[21:05:07 - 21:05:10]
I'm getting from here I'll be passing

[21:05:09 - 21:05:12]
inside this particular function called

[21:05:10 - 21:05:14]
get Vector restore okay as you can see

[21:05:12 - 21:05:15]
get Vector restore this documentation

[21:05:14 - 21:05:19]
I'm passing then once it is done I'm

[21:05:15 - 21:05:22]
just sending the success message then uh

[21:05:19 - 21:05:25]
if my uh knowledge base is created that

[21:05:22 - 21:05:28]
means Vector store is created now I'll

[21:05:25 - 21:05:30]
be performing the question answer of on

[21:05:28 - 21:05:32]
top of it okay so again I'm going to

[21:05:30 - 21:05:34]
create another

[21:05:32 - 21:05:36]
function I think it should be inside

[21:05:34 - 21:05:39]
this particular a yeah so again I I have

[21:05:36 - 21:05:41]
created another function called uh send

[21:05:39 - 21:05:43]
okay send button so whatever user will

[21:05:41 - 21:05:45]
give the query so whatever user will

[21:05:43 - 21:05:48]
give the quy here okay first of all what

[21:05:45 - 21:05:49]
I have to do I have to load my uh

[21:05:48 - 21:05:51]
knowledge base okay as you can see I'm

[21:05:49 - 21:05:53]
loading the knowledge base f. load

[21:05:51 - 21:05:54]
actually I'm doing and this is the index

[21:05:53 - 21:05:57]
name then I also need to give the

[21:05:54 - 21:05:58]
embedding object then you also need to

[21:05:57 - 21:05:59]
give this particular parameter called

[21:05:58 - 21:06:01]
allow dangerous der serialization is

[21:05:59 - 21:06:03]
equal to two Okay if you're using this F

[21:06:01 - 21:06:04]
so this is the uh parameter you have to

[21:06:03 - 21:06:06]
pass because I saw from the

[21:06:04 - 21:06:08]
documentation they are also using this

[21:06:06 - 21:06:10]
particular parameter then I I need to

[21:06:08 - 21:06:12]
load my llm okay that means I already

[21:06:10 - 21:06:14]
created one function to load the llm so

[21:06:12 - 21:06:17]
as you can see get llm object okay then

[21:06:14 - 21:06:20]
after that uh here is the final function

[21:06:17 - 21:06:22]
I'm calling so get llm response and it

[21:06:20 - 21:06:25]
will take this llm Vector store and

[21:06:22 - 21:06:27]
query so llm Vector store and query the

[21:06:25 - 21:06:28]
uh query actually user is asking and I'm

[21:06:27 - 21:06:29]
just writing the response okay whatever

[21:06:28 - 21:06:32]
response actually I'm getting I'm

[21:06:29 - 21:06:33]
writing on top of the stream L okay now

[21:06:32 - 21:06:35]
let's see whether it's working or not so

[21:06:33 - 21:06:36]
to execute this particular file you need

[21:06:35 - 21:06:38]
to run this command so let me also

[21:06:36 - 21:06:39]
mention this command so it should be

[21:06:38 - 21:06:42]
stream L

[21:06:39 - 21:06:44]
run main. Pi Okay because I'm going to

[21:06:42 - 21:06:47]
run this particular main main file now

[21:06:44 - 21:06:49]
let me copy the command and I'm going to

[21:06:47 - 21:06:49]
open up my

[21:06:56 - 21:07:02]
terminal so this is the terminal now I'm

[21:06:59 - 21:07:04]
going to stop the previous execution let

[21:07:02 - 21:07:07]
me clear and let me execute this

[21:07:04 - 21:07:09]
particular file

[21:07:07 - 21:07:11]
now again this is running so if I go

[21:07:09 - 21:07:14]
back and I will close the previous one

[21:07:11 - 21:07:14]
and this is the new one it has

[21:07:17 - 21:07:22]
loaded okay I'm not getting anything

[21:07:19 - 21:07:25]
because let me check my

[21:07:22 - 21:07:28]
code main. Pi okay so this main actually

[21:07:25 - 21:07:30]
I'm not calling okay so I need to also

[21:07:28 - 21:07:32]
Define this particular main function in

[21:07:30 - 21:07:35]
this particular if statement okay if

[21:07:32 - 21:07:38]
underscore name underscore mean then I'm

[21:07:35 - 21:07:39]
going to uh access these are the code

[21:07:38 - 21:07:42]
okay now I think it should work I'll go

[21:07:39 - 21:07:43]
back and run this particular code so

[21:07:42 - 21:07:45]
guys now as you can see I got my

[21:07:43 - 21:07:47]
interface now first of all I need to

[21:07:45 - 21:07:49]
store the vector okay because I need to

[21:07:47 - 21:07:50]
extract the documents I need to store

[21:07:49 - 21:07:52]
the knowledge base so let's click on

[21:07:50 - 21:07:55]
this particular store Vector so once it

[21:07:52 - 21:07:55]
is done you will see the success

[21:07:56 - 21:08:01]
message so guys as you can see the

[21:07:58 - 21:08:04]
execution is done now if I show you

[21:08:01 - 21:08:06]
my code left hand side you can see it

[21:08:04 - 21:08:07]
has created this particular index okay

[21:08:06 - 21:08:09]
that means here actually it has stored

[21:08:07 - 21:08:11]
all of my Vector but it is in a pckl

[21:08:09 - 21:08:12]
format okay because you can't visualize

[21:08:11 - 21:08:14]
these are the vector again it's a local

[21:08:12 - 21:08:16]
Vector DB okay if you want to see that

[21:08:14 - 21:08:18]
particular Vector you can use pine con

[21:08:16 - 21:08:19]
okay Pine we there actually you can

[21:08:18 - 21:08:21]
visualize these are the vector like how

[21:08:19 - 21:08:23]
it is look like and all now what I will

[21:08:21 - 21:08:24]
do I'll ask some of the query so let's

[21:08:23 - 21:08:26]
ask query with respect to the PDF

[21:08:24 - 21:08:29]
actually I'm having so let me open the

[21:08:26 - 21:08:31]
PDF so let's say I'll be asking related

[21:08:29 - 21:08:34]
uh this particular uh rainall

[21:08:31 - 21:08:35]
measurements okay so rainall

[21:08:34 - 21:08:40]
measurements I'll copy this particular

[21:08:35 - 21:08:45]
term and here I can ask so tell me

[21:08:40 - 21:08:46]
about rful measurements now if I just uh

[21:08:45 - 21:08:49]
I think I need to click on the send

[21:08:46 - 21:08:51]
button okay now I think it should

[21:08:49 - 21:08:55]
work now guys let me ask another qu so

[21:08:51 - 21:08:55]
I'll ask tell me about

[21:08:58 - 21:09:01]
uh tell be about

[21:09:04 - 21:09:07]
methology tell

[21:09:07 - 21:09:14]
me okay about methology of the

[21:09:19 - 21:09:23]
paper now guys here is the response I

[21:09:21 - 21:09:25]
got uh so guys here is the response I

[21:09:23 - 21:09:27]
got the paper compares the performance

[21:09:25 - 21:09:30]
of the various regression models for the

[21:09:27 - 21:09:31]
rainfall prediction and the matology

[21:09:30 - 21:09:32]
involves the comparing of the

[21:09:31 - 21:09:35]
performance of difference regession

[21:09:32 - 21:09:37]
model statical metrics such as R2 me and

[21:09:35 - 21:09:39]
MC and rmsc okay if you read this

[21:09:37 - 21:09:41]
particular paper you'll see the same

[21:09:39 - 21:09:42]
thing actually uh they're also

[21:09:41 - 21:09:44]
explaining okay about this particular

[21:09:42 - 21:09:46]
paper and all that means it is working

[21:09:44 - 21:09:48]
fine okay now not only this particular

[21:09:46 - 21:09:49]
paper you can uh place any kinds of

[21:09:48 - 21:09:51]
actually PDF here in this particular

[21:09:49 - 21:09:54]
folder okay any kinds of PDF any kinds

[21:09:51 - 21:09:56]
of PDF books and you can again uh click

[21:09:54 - 21:09:58]
on this particular button so let me show

[21:09:56 - 21:10:00]
you so this is my application you can

[21:09:58 - 21:10:02]
again click on this particular

[21:10:00 - 21:10:04]
button that means store Vector it will

[21:10:02 - 21:10:06]
again store those new Vector that means

[21:10:04 - 21:10:07]
new uh text and it will create a new

[21:10:06 - 21:10:09]
knowledge base and on top of that you

[21:10:07 - 21:10:10]
can perform the question answer okay so

[21:10:09 - 21:10:12]
this is like awesome application

[21:10:10 - 21:10:15]
actually you can create with the help of

[21:10:12 - 21:10:17]
this particular a uh Bedrock okay not

[21:10:15 - 21:10:18]
only this model you can also use mral AI

[21:10:17 - 21:10:20]
okay you can also use this particular uh

[21:10:18 - 21:10:22]
stability AI okay you can try these are

[21:10:20 - 21:10:24]
the model at least okay after this

[21:10:22 - 21:10:26]
particular uh you can say uh video you

[21:10:24 - 21:10:27]
can try with different different model

[21:10:26 - 21:10:29]
and you can create different different

[21:10:27 - 21:10:30]
application on top of it so yeah guys

[21:10:29 - 21:10:32]
this is all about from this particular

[21:10:30 - 21:10:34]
video I hope you got the entire

[21:10:32 - 21:10:36]
understanding how we can create our

[21:10:34 - 21:10:38]
different different application how we

[21:10:36 - 21:10:40]
can create a you can rag application

[21:10:38 - 21:10:42]
with the help of this particular AWS

[21:10:40 - 21:10:43]
Bedrock so here you can explore this

[21:10:42 - 21:10:44]
particular playground as well as the

[21:10:43 - 21:10:47]
model actually different different

[21:10:44 - 21:10:48]
Foundation model you can export and you

[21:10:47 - 21:10:50]
can create different different

[21:10:48 - 21:10:52]
application okay so yes guys uh this is

[21:10:50 - 21:10:54]
all about from this particular video and

[21:10:52 - 21:10:56]
uh this is like awesome actually

[21:10:54 - 21:10:58]
platform they have developed uh if you

[21:10:56 - 21:10:59]
see the inference execution time

[21:10:58 - 21:11:01]
actually it's like very fast although

[21:10:59 - 21:11:04]
I'm using like bigger bigger model let's

[21:11:01 - 21:11:05]
say I used metal model this particular 7

[21:11:04 - 21:11:07]
70 billion parameter model

[21:11:05 - 21:11:08]
and my execution time was like very fast

[21:11:07 - 21:11:10]
there okay but if you're loading this

[21:11:08 - 21:11:12]
particular model on your system you will

[21:11:10 - 21:11:14]
see uh you will get lots of difficulty

[21:11:12 - 21:11:15]
there okay so yes guys this is all about

[21:11:14 - 21:11:16]
from this particular video I hope you

[21:11:15 - 21:11:18]
like this particular video so thank you

[21:11:16 - 21:11:22]
so much guys for watching this video and

[21:11:18 - 21:11:22]
I'll see you next time

## „Ç≥„É°„É≥„Éà

### 1. @dswithbappy (üëç 296)
Thank you so much. I'm glad you found the course helpful. I hope this course will help many people with their Generative AI journey. Happy Learning!üòçüòç

> **@DhanNirankarSatkartar** (üëç 5): Is this for total beginners?

> **@premvishwakarma6409** (üëç 4): Ya let me know also plz

> **@streamsrs** (üëç 1): Tx bro

> **@sumitsingh-CANDY** (üëç 2): Bhai aap isko apne channel me hindi me upload kro, definetly benefit hoga. It help us to learn faster from native teacher than a second language teacher tutorial....if possible
agar na ho paye koi baat nahi
regards !!

> **@xade8381** (üëç 2): @@sumitsingh-CANDY He's from Bangladesh

### 2. @Saniya123ok (üëç 245)
For those judging and laughing at his accent, take a moment to look at yourselves and laugh even more.., because he is at least making an effort to explain and teach... He has taken the initiative to educate us on such a trending topic. Despite being younger than many of you, he is confidently standing there and teaching.

It takes time, effort, and courage to be in that position. Instead of judging, appreciate his dedication.

Thank you, sir, for this amazing video! I learned a lot!üòá

> **@aliakbaramirkhani3265** (üëç 6): God bless him... I wholeheartedly appreciate him and his efforts to release his knowledge to public.

> **@Saniya123ok** (üëç 2): @aliakbaramirkhani3265¬† Aameen

> **@judzam78** (üëç 6): Of what use is it to have a fancy accent and still be ignorant? People need to grow up and appreciate the kind gesture of sharing such invaluable info.

> **@javierleyba** (üëç 7): Man, if that guy wants to teach other people, he should understand that he is speaking for others outside his world. He has a very hard and closed accent that becomes worst because he speaks very fast. English is not my native language and I thought he was speaking japanese or zulu when started to watch the video. He should try to speak slowly and attenuate his accent to make it more acceptable for the world. If not, his effort (that I appreciate) is a waste of time.

> **@Saniya123ok** (üëç 0): @@javierleyba  Bro the problem is in you then, if you are not able to catch his words, fix yourself, or else watch in 0.75x speed. He didn't tell that his videos have to reach over the world.

### 3. @ElectricEric2030 (üëç 424)
00:00 üìö Course Overview
00:39 üíº Career Benefits
01:09 üìñ Course Content
02:05 ü§ñ Large Language Models
03:14 üìà Vector Databases
03:42 üìä Frameworks & Tools
04:11 üöÄ Deployment & LLM Ops
04:39 üëã Instructor Introduction
05:07 üìö Course Structure
06:04 ü§î What is Generative AI?
07:52 ü§ñ Generative AI generates new data based on training samples.
09:30 üìä Generative AI has various applications, including image, language, & audio models.
10:26 üìö Generative models learn from large amounts of data.
11:50 ü§î Why are generative models required?
12:04 üìä Understanding complex patterns from unstructured data.
12:32 üìù Content generation.
13:43 üìà Building powerful applications.
14:52 üìä The V diagram of artificial intelligence.
15:32 ü§ñ Generative AI models can generate new data from unstructured input data.
17:23 üìä Generative models are a subset of deep learning & are trained on huge amounts of data.
19:43 üìö Generative models are large language models that use deep learning algorithms to process & understand natural language.
20:52 üíª Large language models are multimodal, meaning they can perform multiple tasks.
21:49 üí° Large language models are powerful because they can perform multiple tasks with a single model.
22:46 üìà Large language models can perform multiple tasks with a single model.
23:14 ü§ñ Introduction to Generative AI
24:24 üìà Generative AI Pipeline
25:22 üìä Data Acquisition
28:27 üìà Data Collection Alternatives
29:51 üîÑ Data Augmentation
31:59 üîÑ Data Augmentation Techniques
35:40 üìà Data Acquisition Pipeline
36:08 üßπ Data Preprocessing
38:12 üìä Tokenization
39:23 üåé Language Detection
41:11 üí° Tokenization & Text Representation
42:45 üîç Steaming & Dimension Reduction
44:55 üî° Lower Casing & Text Preprocessing
46:35 üîß Advanced Preprocessing Techniques
49:51 üìà Feature Engineering & Text Vectorization
50:53 üíª Feature Engineering
51:47 üìà Modeling
52:15 ü§î Open-Source vs Paid Models
54:22 üìä Model Evaluation
55:18 üìà Extrinsic Evaluation
56:40 üìà Deployment
57:12 üìù Generative AI Pipeline
57:41 üìö Common Terms
59:38 üìä Data Preprocessing for Large Language Models
01:00:48 üìà IMDb Dataset Overview
01:02:12 üìÅ Uploading & Loading Data
01:03:35 üìä Data Shape & Columns
01:04:04 üìä Text Preprocessing Demo
01:04:46 üìù Text Preprocessing Techniques
01:05:13 ‚¨á Lower Case Operation
01:06:24 üìù HTML Tag Removal
01:07:06 üìù Notebook Template for Functionality
01:07:35 üîÑ Applying Functions to Data Sets
01:08:01 üö´ Removing HTML Tags & URLs
01:09:29 üí° Handling Punctuation
01:11:36 üìä Handling Chat Conversations
01:13:15 üìù Handling Incorrect Text
01:13:57 üö´ Handling Stop Words
01:14:25 üìù Understanding Stop Words
01:16:43 üöÆ Removing Stop Words
01:17:38 ü§ñ Handling Emojis
01:19:46 üìä Tokenization
01:20:29 üìÑ Sentence-Level Tokenization
01:21:54 üìù Using Tokenization in Code
01:22:08 üìù Text Preprocessing Techniques
01:24:08 üìä Importance of Text Preprocessing
01:25:04 üìà Data Representation
01:26:28 üìä Feature Extraction
01:27:41 üìä Why Feature Extraction is Necessary
01:29:19 üìä Challenges of Feature Extraction
01:30:13 üìä Tabular Data in Machine Learning
01:31:54 üì∏ Image Data in Computer Vision
01:34:40 üéµ Audio Data Representation
01:36:18 üìÑ Text Data Representation
01:38:24 üìä Converting Text to Numerical Representation
01:39:21 üìù One-Hot Encoding Technique
01:44:20 üìä One-Hot Encoding Example
01:46:36 üìà Creating a Neural Network with One-Hot Encoding
01:47:59 üìä One-Hot Encoding Drawbacks
01:52:26 üìà Bag of Words Technique
01:54:59 üìä Bag of Words Limitations
01:56:45 üìä Techniques for Text Representation
01:57:41 ü§ñ Transformer-Based Encoding Technique
01:58:09 üíª Practical Demonstration of Bag of Words
01:59:48 üìà CountVectorizer & Bag of Words
02:02:31 üìä N-Grams & Bag of Words
02:04:35 üìä Understanding N-Grams for Sentiment Analysis
02:06:37 üìà TF-IDF for Text Representation
02:09:06 ü§ñ Word2Vec for Deep Learning
02:10:05 üìä Word2Vec Feature Extraction
02:12:37 üìä Generating Vectors for Entities
02:15:07 üìà Visualizing Entity Relationships
02:17:04 üí° Understanding Semantic Information
02:18:28 üìä Experimenting with Word2Vec
02:19:09 üìä Practical Application of Word2Vec
02:20:56 üíª Importing Libraries & Loading Data
02:22:27 üìä Data Preprocessing & Tokenization
02:23:49 ü§ñ Similarity Analysis & Character Matching
02:25:02 üìà Visualizing Similarity & Relationships
02:27:09 üí° Understanding Semantic Relationships
02:27:52 ü§ñ Attention Mechanism in Transformer Architecture
02:28:20 üìö Preparing Data for Large Language Models
02:28:48 üìä Text Classification Project
02:29:29 üìä Introduction to Text Classification
02:30:14 üìà Data Import & Preprocessing
02:33:02 üöÆ Data Cleaning
02:35:08 üìä Data Preparation
02:36:05 üìà Feature Extraction
02:37:15 üìä Text Classification with Machine Learning
02:38:27 üìà Feature Selection
02:39:51 üìä N-Grams
02:40:31 üìä TF-IDF
02:41:41 üìö Text Classification with Machine Learning
02:42:10 ü§ñ Large Language Models
02:44:02 üíª Large Language Model Architecture
02:45:13 ü§ñ How Chat GPT was trained & works
02:46:10 üìà Transfer Learning
02:46:52 üìä Transformer Architecture
02:48:44 üíª Large Language Models
02:51:06 üìö Examples of Large Language Models
02:53:24 üìö Large Language Models & Their Characteristics
02:54:47 ü§ñ Transformer Architecture
02:55:30 üìù Encoder-Based Architectures
02:55:57 üíª Decoder-Based Architectures
02:56:25 üìä Models Using Both Encoder & Decoder Layers
02:56:40 üåê OpenAI Models
02:58:05 ü§ù Open-Source Large Language Models
02:59:41 üìù Applications of Large Language Models
03:00:10 üí° Prompt Engineering & Designing
03:01:05 üìù Types of Prompts in Large Language Models
03:02:59 üí° Importance of Prompt Engineering
03:03:14 üìä Transformer Architecture
03:05:05 üìà Understanding the Transformer Architecture
03:07:06 üìä Components of the Encoder Layer
03:08:02 üìù Text Preprocessing & Representation
03:08:44 ü§ñ How the input is encoded & passed through the self-attention layer
03:09:10 üìù Understanding the encoding process using a simple example
03:10:07 üìä Understanding self-attention at a high level
03:10:49 üîç Understanding how self-attention works
03:12:12 üìä Understanding the weight initialization & update process
03:13:05 üìù Understanding the generation of queries, keys, & values
03:14:02 üìä Understanding the calculation of the score
03:15:11 üìä Understanding the softmax operation
03:16:06 üìù Understanding the multiplication of the softmax output with the values
03:16:33 ü§ñ Self-Attention Layer Operation
03:17:54 üìä Single Head Attention Limitation
03:18:10 üîç Multi-Head Attention
03:20:05 üìà Multi-Head Attention in Transformer Architecture
03:22:41 üìä Positional Encoding
03:24:15 üïí Positional Encoding in Sequential Data
03:25:52 üìà Residual Blocks in Transformer Architecture
03:27:28 üîÑ Normalization in Transformer Architecture
03:28:38 üìä Entire Transformer Architecture
03:29:35 üíª Decoder Side of Transformer Architecture
03:31:16 üìù High-Level Understanding of Transformer Architecture
03:32:00 ü§ñ Transformer Architecture
03:32:54 üíª Large Language Models
03:33:37 üìä ChatGPT
03:34:47 üìà Training ChatGPT
03:37:19 üìä Generative Pre-training
03:38:17 üìà Supervised Fine-tuning
03:39:52 ü§ñ Training the SFT Char GPT Model
03:43:08 üí¨ Understanding the Chat GPT Model
03:43:50 üìä Introduction to Hugging Face
03:45:00 üìà Exploring the Hugging Face Platform
03:47:34 ü§ñ Hugging Face Platform for Generative AI
03:48:45 üìö Key Concepts in Hugging Face
03:49:57 üíª Hugging Face Services & Features
03:51:07 üìä Open-Source Large Language Models
03:51:49 üìö Learning Hugging Face & Generative AI
03:52:03 üìä Hugging Face Datasets & Libraries
03:53:26 üìà Hugging Face Spaces & Documentation
03:54:52 üìä Introduction to Hugging Face
03:55:18 ü§ñ Using Hugging Face with Python
03:56:16 üíª Setting up Google Colab
03:57:12 üìà Exploring Hugging Face Models
03:58:18 üìä Using the Pipeline Functionality
04:00:06 üí° Performing Sentiment Analysis

> **@lilithkarri4395** (üëç 6): ‚ù§

> **@stackash** (üëç 15): May God save you from hellfire

> **@AnshumanRathore** (üëç 3): Please share your notes taking app ??

> **@narayanansreenivasan2558** (üëç 3): Was this generated timelines??

> **@anurajshush4531** (üëç 3): please add more in your replies please!!

### 4. @amira_369 (üëç 120)
My baby steps progress as I'm busy
Day 1 (22 Nov 2024): reached 1:39:17
Day 2 (26 Nov 2024): reached 2:42:06
Day 3 (27 Nov 2024): reached 4:06:09
Day 4 (1 Dec 2024): reached 4:19:06
Day 5 (2 Dec 2024): reached 4:42:34
Day 6 (3 Dec 2024): reached 5:09:54 + 75% of Project 1 implementation
Day 7 (4 Dec 2024): reached 5:29:24
Day 8 (5 Dec 2024): Project Text to Speech done, still debugging Project 1
Day 9: (17 Dec 2024) reached 6:15:11 + Project text to Image + OpenAI demo code implementation

Coming back after a week from now!!

> **@ar3568row** (üëç 5): Keep updating, I'm seeing your progress üëÅÔ∏è

> **@cnnrsmth** (üëç 2): How're you finding it?

> **@amira_369** (üëç 0): @@cnnrsmth Very beneficial so far

> **@daipayanhati2347** (üëç 0): Dont stop broooo

> **@cnnrsmth** (üëç 0): Given up?

### 5. @eashajawad (üëç 15)
just completed this full course in 20 days my God so much time haha thanks

### 6. @evolutionarybiology7875 (üëç 53)
Thank you so much free code camp for everything you have blessed upon us. Humanity is indebted to you what you have done to educate compute science enthusiasts.

> **@visiion1998** (üëç 2): What are the prerequisites for learning this Generative AI course?

> **@technology_seekers** (üëç 0): Basics of python , ML , DL ‚Äã@visiion1998

> **@md02-99** (üëç 1): What should you know before starting this??

### 7. @PruthviRaj-z2g (üëç 254)
Great! Another video I'll add to watch later and never finish! 

Happy Deepawali folksüéâ‚ù§

> **@Vishal-ch7eb** (üëç 2): üòÇüòÇüòÇ

> **@xade8381** (üëç 2): Make a separate playlist for this channel, playlist containing less videos might help.
Just a Diwali tip.

> **@abhaypundora6841** (üëç 3): Happy deepawali ‚ù§

> **@swarupthipe2515** (üëç 0): That's soo true üò¢

> **@MrEdavid4108** (üëç 1): üòÇüòÇüòäüòÇüòä

### 8. @rafsanbhuiyan (üëç 8)
You will build our career!! Thank you so much üòä This is such a fantastic contribution to the tech community. You have no idea!!! I look forward to completing this course ASAP.

### 9. @MarkLewis00 (üëç 219)
Great video keep going! do explore the ecosystem of CrewAI, OpenAI or LLama & Composio & Helicone, it's my personal favorite

> **@md02-99** (üëç 1): What should you know before starting this??

### 10. @paulcatuna6949 (üëç 71)
First time I changed my playback speed to 0.75 and didn't regret it :)). Great content üëèüëè

> **@KonfliktProduktionz** (üëç 4): I saw this and you're right lol

> **@mimosveta** (üëç 1): because of dense accent, or dense content?

> **@KonfliktProduktionz** (üëç 3): @@mimosveta both

> **@TommyAlanRaines** (üëç 3): @@mimosvetaNot accent or content, it‚Äôs absolutely candy rush caffeine buzz talking fast. I typically will sped up some courses, this one I don‚Äôt have to.

> **@RexAnimus** (üëç 0): Saw this and set mine to 0.85. Couldn't keep up with how fast he was speaking.

### 11. @marktoledo6595 (üëç 17)
I completed the entire thing and it took me 7 days to complete this. I appreciated the simplicity of the projects, they're doable and practical. Each day during the christmas holiday season, I am devoting 2-4 hrs of learning time with x2 speed. Debugging in the project sections is a separate thing.

Kudos to you for curating this. It surprises me that this field is innovating really fast that the libraries become outdated within months considering this is a recent upload.

I spent around $0.40 throughout the implementation of all these. Not even a dollar! (i didn't try the Colab Enterprise tho so Im not sure of the costs there)

Thank you and good luck to all trying to complete this!!

> **@pushkarsinghadhikari6060** (üëç 3): I know c++ and flutter.... but I want to learn Ai gen .... can I learn from this video..without any prior knowledge of AI or ml...within 2 weeks... please answer.

> **@pushkarsinghadhikari6060** (üëç 0): @@marktoledo6595 reply pls

> **@clopezprogrammer** (üëç 0): do you find a new role job with this knowledge?

> **@marktoledo6595** (üëç 0): ‚Äã‚Äã@@clopezprogrammer im already in the industry as a data engineer but it gave a new dimension to what I do as an architect, AI and Data Engineering go really well together

> **@clopezprogrammer** (üëç 0): @@marktoledo6595 thanks. I'm also an architect, but I want to change my career to become an AI agent. I hope I can learn well this year.

### 12. @ScripturedMind (üëç 10)
Almost an hour in, and I'm loving it, thank you very much.

### 13. @Muhammad_Aftab_ahmad_97 (üëç 8)
Thank you so much, Bakhtiar for this wonderful course. I have completed this course within 7 days. I learned a lot from your course on Gen AI.

> **@jamesrelebohilemotaung583** (üëç 1): Me too

> **@AnilKumar-d6y1l** (üëç 0): is it worth doing , im thinking to start this video , it really helps your feedback , whether to continue with this course or not

### 14. @tarunsrinivas7614 (üëç 131)
please like so i could complete the course faster
Day 1: 27:00
Day2: 1:09:47

> **@penguin3245** (üëç 2): did you stop

> **@tarunsrinivas7614** (üëç 2): @penguin3245¬† learning NLP from another videoüòÅ

> **@harshavardan-w7z** (üëç 0): @@tarunsrinivas7614 from where

> **@jiaqi222** (üëç 0): @@tarunsrinivas7614 can you recommend itÔºü

> **@sameerhasanansari7797** (üëç 0): Which video?‚Äã@@tarunsrinivas7614

### 15. @Youbloompretty (üëç 13)
People in the comment section doesn't want to pay for expensive courses  and still cant appreciate the content they are getting for free and the efforts made for creating the video. Just pause the video if it's too long for you, and start from there again. And if it is too much of a thing for you then don't expect a playlist from the youtuber as well. üòÆ‚Äçüí®

### 16. @AK-ox3mv (üëç 16)
Yesterday I  wanted to learn about GenAI and I was looking in FCC but didn't find what i was looking for.
And here it isüëå

In "2 minutes paper" words:
What a time to be alive!

### 17. @ayudameme5203 (üëç 9)
Day0 03/11 00:00 - 49:51

1. Data Acquisition : 
Available Data (csv, pdf, txt)
Other Data (database, scraping)
No Data (create data using llm)
But in this scenario the data might be less and then you need to perform Data Augmentation
Data Augmentation - making small changes to the og data to create new data instances (replace with synonyms, bi-gram flipping (swap adjacent words), back Translate (translating to another language and then translating back), add additional data/noise)

2. Data Preprocessing:
Clean up (html, emoji, spelling correction)
Basic preprocessing (tokenization (sentence level, word level), stop word removal, stemming, lemmatization, punctuation removal, lowercase, language detection)
Advanced preprocessing (Parts of speech tagging, parsing, Coreference resolution)

3. Feature Engineering (text vectorization)

4. Modelling

### 18. @cicd (üëç 35)
Thanks!

### 19. @devinpatel7869 (üëç 10)
Best video on GEN-AI. Will see full video .

### 20. @hassani6955 (üëç 8)
Amazong Video! His way of explanation is great! Read some comments on his accent, thats a bengali accent, the tutor is a Bangladeshi tutor. His way of explanation is awesome. His speed is stressful but you can always watch it on 0.75 to understand easily.

