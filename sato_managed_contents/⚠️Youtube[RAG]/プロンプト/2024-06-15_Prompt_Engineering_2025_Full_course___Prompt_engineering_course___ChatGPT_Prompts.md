# Prompt Engineering 2025 Full course | Prompt engineering course | ChatGPT Prompts

**„ÉÅ„É£„É≥„Éç„É´:** Great Learning
**ÂÖ¨ÈñãÊó•:** 2024-06-15
**URL:** https://www.youtube.com/watch?v=5i2Hn8OG94o

## Ë™¨Êòé

üìö Learn the basics of prompt engineering, including components of a good prompt and defining a good prompt. Explore basic and advanced prompt techniques, common errors, and real-world applications. Elevate your skills with practical examples and unlock the full potential of prompt engineering! üöÄ

Learn the basics, advanced strategies, and practical applications to shape the future of AI-driven communication. Enrol for free and get a certificate of completion, click here.
https://www.mygreatlearning.com/academy/learn-for-free/courses/prompt-engineering-for-chatgpt?utm_source=CPV_YT&utm_medium=Desc&utm_campaign=HowtouseChatGPT4o_2024

Learn AI & ML from the University of Texas, Austin. To build a successful career enroll now!
https://www.mygreatlearning.com/pg-program-artificial-intelligence-course?utm_source=CPV_YT&utm_medium=Desc&utm_campaign=Prmptengflcrse_062024

Boost your resume with a Generative AI for Business certificate from Microsoft. Enroll now!
https://www.mygreatlearning.com/gen-ai-microsoft-azure-open-ai-online?utm_source=CPV_YT&utm_medium=Desc&utm_campaign=Prmptengflcrse_062024

üèÅ Topics Covered:
00:00:00 Introduction to Prompt Engineering
00:02:35 What is Prompt Engineering
00:07:12 Main Elements of Prompt Engineering
00:10:10 Components of a Good Prompt
00:12:49 Examples of the Components of a Good Prompt
00:17:37 How to Write a Good Prompt
00:23:08 Different Prompt Patterns
00:29:23 Common Prompting Errors
00:33:11 Applications of Prompt Engineering
00:38:06 Hands-on Basics of Prompt Engineering
00:45:05 Defining a Good Prompt by an Example of Text Summarization
00:57:38 Defining a Good Prompt by an Example of Code Generation
01:02:04 Zero-shot, Few-shot and Chain of Thought Process
01:05:42 Hands-on Zero-shot
01:07:37 Hands-on Few-shot
01:10:48 Hands-on Chain of Thought
01:14:16 Summary

#promptengineering #chatgpt #ai 

üî•1000+ Free Courses With Free Certificates: https://www.mygreatlearning.com/academy?utm_source=CPV_YT&utm_medium=Desc&utm_campaign=YTVids2024

‚ö° About Great Learning Academy:
Visit Great Learning Academy to get access to 1000+ free courses with free certificates on Data Science, Data Analytics, Digital Marketing, Artificial Intelligence, Big Data, Cloud, Management, Cybersecurity, Software Development, and many more. These are supplemented with free projects, assignments, datasets, and quizzes. You can earn a certificate of completion at the end of the course for free.

‚ö° About Great Learning:
With more than 10 Million+ learners in 170+ countries, Great Learning is a leading global edtech company for professional and higher education offering industry-relevant programs in the blended, classroom, and purely online modes across technology, data, and business domains. These programs are developed in collaboration with top institutions like Stanford Executive Education, MIT Professional Education, Wharton, University of Arizona, Northwestern University, The University of Texas at Austin, NUS, IIT Madras, Microsoft & more.

SOCIAL MEDIA LINKS:
üîπ For more interesting tutorials, don't forget to subscribe to our channel: https://glacad.me/YTsubscribe

üîπ For more updates on courses and tips follow us on:
‚úÖ Telegram: https://t.me/GreatLearningAcademy
‚úÖ Facebook: https://www.facebook.com/GreatLearningOfficial/
‚úÖ LinkedIn: https://www.linkedin.com/school/great-learning/mycompany/verification/
‚úÖ Follow our Blog: https://glacad.me/GL_Blog

## Â≠óÂπï

[00:00 - 00:04]
hello there are you ready to supercharge

[00:02 - 00:07]
your interactions with AI today we are

[00:04 - 00:09]
diving into the magic of prompt

[00:07 - 00:13]
engineering the key to making AI tools

[00:09 - 00:16]
like Char GPT do exactly what you want

[00:13 - 00:19]
and all you need to do is Master the art

[00:16 - 00:22]
of prompting effectively in this

[00:19 - 00:26]
beginner friendly Hands-On video we will

[00:22 - 00:29]
start from the basics what prompts are

[00:26 - 00:32]
why they matter and how to craft prompts

[00:29 - 00:35]
effectively to achieve accurate and

[00:32 - 00:38]
contextually relevant AI responsive we

[00:35 - 00:41]
will dive deep into numerous real world

[00:38 - 00:43]
examples demonstrating the Practical

[00:41 - 00:47]
applications of these techniques and we

[00:43 - 00:50]
will also tackle common challenges that

[00:47 - 00:52]
newcomers often face providing you with

[00:50 - 00:55]
practical tips and solutions to enhance

[00:52 - 00:58]
your prompting skills whether you are

[00:55 - 01:01]
looking to automate tasks generate

[00:58 - 01:04]
content or develop Innovative AI tools

[01:01 - 01:06]
the skills you require today are very

[01:04 - 01:08]
crucial by the end of this video you

[01:06 - 01:12]
will not only understand prompt

[01:08 - 01:15]
engineering but also make AI work

[01:12 - 01:17]
smarter for you so let's dive in and

[01:15 - 01:21]
start creating some AI

[01:17 - 01:21]
[Music]

[01:23 - 01:30]
[Music]

[01:27 - 01:32]
magic now let's understand what is

[01:30 - 01:35]
prompt

[01:32 - 01:40]
engineering prompt engineering is as

[01:35 - 01:41]
much an art as it is a science a very

[01:40 - 01:44]
creative

[01:41 - 01:47]
line we'll come back to this once we

[01:44 - 01:49]
understand what is actually prompt

[01:47 - 01:53]
engineering prompt engineering is made

[01:49 - 01:57]
up of two words prompt and Engineering

[01:53 - 02:00]
prompt is nothing but a detailed set of

[01:57 - 02:04]
guidelines or instructions given to the

[02:00 - 02:10]
llm or generative model to do a

[02:04 - 02:14]
task engineering is developing

[02:10 - 02:20]
iteratively a task specific prompt to

[02:14 - 02:23]
enable the generative models or llms to

[02:20 - 02:27]
Output a perfect or near

[02:23 - 02:31]
perfect outcome that you have focused

[02:27 - 02:36]
for so if you see prompt engineering is

[02:31 - 02:38]
an iterative process how first is the

[02:36 - 02:44]
idea that comes to you that you want

[02:38 - 02:44]
this then you have prompt you design a

[02:45 - 02:49]
prompt

[02:46 - 02:54]
then there are results you give that to

[02:49 - 02:57]
your model your chart GPT okay and then

[02:54 - 03:01]
you have to test you have a feedback

[02:57 - 03:05]
right so basically it's it's a

[03:01 - 03:07]
process a iterative process now once you

[03:05 - 03:10]
have the prompt and you have the results

[03:07 - 03:14]
you might be not very much satisfied

[03:10 - 03:18]
with the result this is where you

[03:14 - 03:21]
develop or you have a conversation with

[03:18 - 03:25]
your chat GPT with your model

[03:21 - 03:30]
and enforce or reinforce the model to

[03:25 - 03:34]
give you a good result a good out output

[03:30 - 03:37]
which is what you want for example if

[03:34 - 03:40]
you have a task on code

[03:37 - 03:45]
Generation

[03:40 - 03:47]
Now a specific problem statement can be

[03:45 - 03:51]
solved through various

[03:47 - 03:55]
methods for example you want to uh

[03:51 - 03:58]
output palindrome palindrome can be done

[03:55 - 04:00]
by Brute Force palindrome can also be

[03:58 - 04:02]
done by recursive

[04:00 - 04:06]
method

[04:02 - 04:09]
recursion for example when you give chat

[04:06 - 04:12]
GPT a prompt it'll first give you a

[04:09 - 04:15]
brute force method you have to keep on

[04:12 - 04:19]
instructing and providing

[04:15 - 04:22]
an attempt or providing a prompt to chat

[04:19 - 04:26]
GPT so that it gives you an optimized

[04:22 - 04:29]
version for your code this is an example

[04:26 - 04:32]
for code generation similarly suppose

[04:29 - 04:35]
you have content creation you want to

[04:32 - 04:38]
create a content and your content that

[04:35 - 04:41]
you want to create is directed towards a

[04:38 - 04:44]
specific target

[04:41 - 04:47]
audience now when you give chat gbt a

[04:44 - 04:50]
prompt the results it will show you that

[04:47 - 04:55]
might not be satisfying enough you have

[04:50 - 04:58]
to tell your chat GP or your generative

[04:55 - 05:02]
model iteratively what you want give

[04:58 - 05:05]
them a feedack back for example you have

[05:02 - 05:08]
not received a good output what you will

[05:05 - 05:14]
tell your chat GPT for

[05:08 - 05:14]
example this is not I want please

[05:15 - 05:23]
generate the output based on my target

[05:19 - 05:25]
audience or based on my feedback

[05:23 - 05:29]
provided right that's where your

[05:25 - 05:32]
feedback or test comes into picture you

[05:29 - 05:34]
have to have a conversation with your

[05:32 - 05:37]
generative model or for in this case if

[05:34 - 05:39]
you say chat GPT give them a feedback

[05:37 - 05:42]
constant feedback it is good it is bad

[05:39 - 05:47]
it is what specific part you want it to

[05:42 - 05:50]
be changed right all these things are an

[05:47 - 05:53]
iterative process that's why we say

[05:50 - 05:56]
prompt engineering is an iterative

[05:53 - 05:58]
process based on the guidelines or the

[05:56 - 06:01]
detailed set of instructions that you

[05:58 - 06:05]
provide for a specific

[06:01 - 06:08]
task now let's go back a bit we said

[06:05 - 06:13]
when we started about prompt engineering

[06:08 - 06:14]
that it is an art as it is a science how

[06:13 - 06:17]
it is an

[06:14 - 06:20]
art it is an art because when you

[06:17 - 06:24]
conceive an idea and when you write a

[06:20 - 06:25]
prompt it is your creativity which comes

[06:24 - 06:28]
into

[06:25 - 06:32]
picture however the science part comes

[06:28 - 06:36]
in when you provide your generative

[06:32 - 06:38]
model or llm or in this case chat GPT

[06:36 - 06:41]
The Prompt and it gives you the result

[06:38 - 06:43]
because in the back end there is

[06:41 - 06:45]
something called generative models there

[06:43 - 06:47]
is something called different

[06:45 - 06:49]
Transformers or architectures that are

[06:47 - 06:53]
going into picture where billions of

[06:49 - 06:55]
parameters are playing a role to give

[06:53 - 06:58]
you this

[06:55 - 07:02]
result that becomes your science part of

[06:58 - 07:06]
it that's why prompt engineering is

[07:02 - 07:08]
combination of both an art and

[07:06 - 07:11]
science now that you have understood

[07:08 - 07:16]
what is prompt

[07:11 - 07:20]
engineering let's go and see the vital

[07:16 - 07:24]
the main element of prompt engineering

[07:20 - 07:26]
that is prompts without which generative

[07:24 - 07:30]
model chat GPT will not

[07:26 - 07:34]
work prompts are cons stituted or it

[07:30 - 07:38]
contains two parts majorly that is

[07:34 - 07:40]
parameters and structure what will be

[07:38 - 07:42]
the structure and what will be the

[07:40 - 07:46]
parameters of your prompts that when you

[07:42 - 07:48]
design it you have to think so that you

[07:46 - 07:51]
have an optimized

[07:48 - 07:54]
result now structure is one thing that

[07:51 - 07:57]
we'll talk more about and parameters

[07:54 - 08:00]
here let me explain I have only Selected

[07:57 - 08:04]
Few parameters you can search more there

[08:00 - 08:07]
are more parameters on which uh prompts

[08:04 - 08:09]
work majorly here we are highlighting

[08:07 - 08:13]
only three parameters that is

[08:09 - 08:14]
temperature top p and max length

[08:13 - 08:18]
temperature

[08:14 - 08:21]
is the randomness that comes into

[08:18 - 08:22]
picture when you provide that parameter

[08:21 - 08:25]
to your

[08:22 - 08:29]
prompt it ranges from 0 to

[08:25 - 08:33]
1 and if you want your model to be

[08:29 - 08:36]
creative and generate creative answers

[08:33 - 08:40]
or generate creative outcomes your range

[08:36 - 08:45]
or you set your temperature to 0.7 to

[08:40 - 08:47]
0.8 however in tasks such as code

[08:45 - 08:49]
generation you don't need

[08:47 - 08:52]
creativity so you can set your

[08:49 - 08:54]
temperature to zero also where you do

[08:52 - 08:57]
not want

[08:54 - 09:02]
creativity now top

[08:57 - 09:06]
p is actually kind of same as

[09:02 - 09:09]
temperature it also has

[09:06 - 09:12]
creativity top p is top probability that

[09:09 - 09:15]
it selects from

[09:12 - 09:19]
so you have a generative model it

[09:15 - 09:22]
generates results based on your prompt

[09:19 - 09:26]
now there can be n number of results how

[09:22 - 09:28]
does that model decide what to put as a

[09:26 - 09:32]
output for

[09:28 - 09:35]
you here top P comes into picture more

[09:32 - 09:39]
the top P more you have different

[09:35 - 09:41]
creative answers right so low for

[09:39 - 09:45]
factual high for

[09:41 - 09:49]
diverse last is max length again it is

[09:45 - 09:53]
written manage your response length this

[09:49 - 09:56]
parameter is to control the cost of your

[09:53 - 10:00]
generative model as

[09:56 - 10:01]
well so now you have understood what is

[10:00 - 10:04]
prompt

[10:01 - 10:07]
engineering what is a prompt and what

[10:04 - 10:09]
are the two main components of your

[10:07 - 10:12]
prompt that is parameter and structure

[10:09 - 10:16]
now let's see components of a good

[10:12 - 10:19]
prompt what we mean by good prompt is

[10:16 - 10:23]
that your chat GPT your generative model

[10:19 - 10:26]
gives you a good output your good

[10:23 - 10:29]
outcome and you have less

[10:26 - 10:32]
feedbacks for your chat GPT or

[10:29 - 10:36]
generative model now let's

[10:32 - 10:40]
see the first or I would say the first

[10:36 - 10:42]
two are context and instruction these

[10:40 - 10:46]
are interchangeable how you want to

[10:42 - 10:49]
design your prompt if you want to keep

[10:46 - 10:51]
instruction first and then context in

[10:49 - 10:53]
your prompt you can do the same if you

[10:51 - 10:55]
want to keep the context first and then

[10:53 - 10:58]
instruction you can do the

[10:55 - 11:00]
same context is an additional

[10:58 - 11:03]
information that you want to provide to

[11:00 - 11:07]
your model instruction is a specific

[11:03 - 11:11]
task that you want your model to perform

[11:07 - 11:14]
for example if you want to summarize

[11:11 - 11:17]
some text that is your instruction

[11:14 - 11:20]
summarize your text summarize this text

[11:17 - 11:23]
context is why you want to summarize

[11:20 - 11:26]
what is the outcome you want to achieve

[11:23 - 11:27]
for example going back

[11:26 - 11:30]
to

[11:27 - 11:33]
Tesla there you are providing an

[11:30 - 11:35]
instruction to summarize but the context

[11:33 - 11:38]
is that you want

[11:35 - 11:42]
a business report from a business report

[11:38 - 11:45]
you want what is the profit from 2020 to

[11:42 - 11:48]
2023 right so that is the context that

[11:45 - 11:49]
you need to set why do you want this why

[11:48 - 11:54]
it is

[11:49 - 11:58]
needed next is the input data okay what

[11:54 - 12:00]
is your input data for the example Tesla

[11:58 - 12:02]
example example the input data is your

[12:00 - 12:06]
business report or business article that

[12:02 - 12:11]
you will provide to char GPT and output

[12:06 - 12:14]
indicator is what how what and how you

[12:11 - 12:17]
want as an output for example you want

[12:14 - 12:19]
in a CSV format your output suppose you

[12:17 - 12:23]
want in a tabular

[12:19 - 12:27]
format or you want in a graphical format

[12:23 - 12:32]
so you have to tell what kind of output

[12:27 - 12:34]
or what format of output you want so

[12:32 - 12:38]
these are the four components of a good

[12:34 - 12:41]
prompt if your prompt consists of these

[12:38 - 12:43]
four things you are enabling your

[12:41 - 12:46]
generative model your chat GPT to give

[12:43 - 12:49]
you better and good

[12:46 - 12:52]
results now let's see an example here we

[12:49 - 12:55]
will see um sentiment

[12:52 - 12:59]
analysis we are setting up a

[12:55 - 13:01]
context it is written act as a analyst

[12:59 - 13:05]
you're acting as you are asking your

[13:01 - 13:08]
chart GPT to act like an analyst working

[13:05 - 13:10]
for an OT platform you are saying your

[13:08 - 13:14]
chat gbt that you will have to perform

[13:10 - 13:17]
sentiment analysis based on the feedback

[13:14 - 13:20]
provided by the consumers you are

[13:17 - 13:23]
working for an OD platform your

[13:20 - 13:26]
consumers are the users that are seeing

[13:23 - 13:29]
your movies your web series now the

[13:26 - 13:32]
feedback that they provide on that you

[13:29 - 13:34]
have to do sentiment analysis this is

[13:32 - 13:35]
the context that you are giving to your

[13:34 - 13:38]
chat

[13:35 - 13:42]
GPT now giving

[13:38 - 13:45]
this your Char knows

[13:42 - 13:49]
that they need to think from an analyst

[13:45 - 13:52]
perspective they need to do sentiment

[13:49 - 13:55]
analysis now second is instruction you

[13:52 - 13:59]
are saying to chat GPT to

[13:55 - 14:02]
classify the feedback into neutral

[13:59 - 14:05]
negative

[14:02 - 14:08]
positive where you are instructing or

[14:05 - 14:11]
telling your chat GPT that what is

[14:08 - 14:15]
positive positive means your consumer is

[14:11 - 14:18]
your promoter negative means they are

[14:15 - 14:21]
demo neutral means they are neither

[14:18 - 14:22]
promoter or demo they are neutral

[14:21 - 14:25]
towards your

[14:22 - 14:28]
content this is the instruction that you

[14:25 - 14:30]
give what the chat GP or what generative

[14:28 - 14:34]
model needs to do

[14:30 - 14:38]
this is what it is doing

[14:34 - 14:41]
classifying next is your input data and

[14:38 - 14:44]
your output indicator before that let's

[14:41 - 14:47]
see an example a good

[14:44 - 14:48]
prompt while you're giving a good prompt

[14:47 - 14:52]
if you

[14:48 - 14:55]
give examples for your generative model

[14:52 - 14:59]
here in this case we are using chat GPT

[14:55 - 15:02]
if you give them an example they will

[14:59 - 15:09]
learn from this example

[15:02 - 15:12]
and train your input data to give the

[15:09 - 15:15]
output here we have given two examples

[15:12 - 15:17]
feedback first feedback is I think the

[15:15 - 15:20]
series was

[15:17 - 15:23]
okay second feedback is the acting of

[15:20 - 15:28]
each character in the series was

[15:23 - 15:32]
awesome so I think the series was okay

[15:28 - 15:33]
it took this is okay as neutral so this

[15:32 - 15:37]
is a sentiment

[15:33 - 15:40]
neutral here awesome it took as positive

[15:37 - 15:45]
so your sentiment becomes

[15:40 - 15:48]
positive now your input data is the

[15:45 - 15:53]
story line for the series was repetitive

[15:48 - 15:55]
and abysmal and your output indicator

[15:53 - 16:00]
here is sentiment what is the sentiment

[15:55 - 16:03]
for this you're asking your chat GPT

[16:00 - 16:07]
what will be the sentiment of this

[16:03 - 16:10]
entire prompt that is your context that

[16:07 - 16:14]
you have given which tells chib to act

[16:10 - 16:18]
as an analyst and do sentiment

[16:14 - 16:21]
analysis it gives an instruction to

[16:18 - 16:25]
classify the feedback provided that is

[16:21 - 16:30]
your input data and classify that

[16:25 - 16:34]
feedback into positive negative and

[16:30 - 16:37]
neutral here you and here you are giving

[16:34 - 16:43]
examples for the same so that your chat

[16:37 - 16:48]
GPT can understand learn and then act

[16:43 - 16:51]
accordingly now the output for this

[16:48 - 16:54]
particular feedback is

[16:51 - 16:58]
negative so if you copy paste this into

[16:54 - 17:02]
your chat GPT it gives you a output as

[16:58 - 17:02]
negative for this

[17:02 - 17:09]
sentence so this is how you should write

[17:07 - 17:12]
your prompt which is good these are the

[17:09 - 17:17]
components good components of for your

[17:12 - 17:19]
prompt so that the output that chat gbd

[17:17 - 17:21]
generates for you

[17:19 - 17:24]
is

[17:21 - 17:27]
exact for you to work

[17:24 - 17:30]
upon so this is what we understood about

[17:27 - 17:32]
components of a good prompt now that you

[17:30 - 17:36]
have seen what are the different

[17:32 - 17:39]
components of a good prompt let's have a

[17:36 - 17:44]
look at a good checklist that you can

[17:39 - 17:48]
keep in mind while designing a effective

[17:44 - 17:51]
prompt for better results so the first

[17:48 - 17:55]
one is defining the goal telling chat

[17:51 - 17:59]
gbt what exactly you want to do that is

[17:55 - 18:02]
called defining the goal

[17:59 - 18:06]
next is detail out the

[18:02 - 18:10]
format format is output format that you

[18:06 - 18:13]
want chat GPT to provide you for example

[18:10 - 18:17]
as I told you previously it can be table

[18:13 - 18:20]
paragraph list csvs anything that you

[18:17 - 18:22]
want and you can give it in a priority

[18:20 - 18:25]
order also ask chat to give you in a

[18:22 - 18:28]
priority order if you are working on

[18:25 - 18:31]
such uh content

[18:28 - 18:34]
next is creating a role if you remember

[18:31 - 18:36]
the previous prompt that we

[18:34 - 18:41]
discussed while learning about

[18:36 - 18:46]
components of a good prompt we told as a

[18:41 - 18:51]
context act like a

[18:46 - 18:55]
analyst that is creating a role so that

[18:51 - 18:58]
chat GPT assigns or processes based on

[18:55 - 19:00]
your request based on that role that you

[18:58 - 19:03]
are have

[19:00 - 19:07]
asked next is Clarity who the audience

[19:03 - 19:09]
is or clarify the who the audience is

[19:07 - 19:13]
basically you are telling chart GPT

[19:09 - 19:16]
please generate the output based on the

[19:13 - 19:20]
demography of my audience whom I am

[19:16 - 19:23]
catering to it can be beginner

[19:20 - 19:25]
level intermediate Advanced if you are

[19:23 - 19:30]
creating any content if you are creating

[19:25 - 19:34]
code it can be foundational functional

[19:30 - 19:37]
expert based on the audience it can also

[19:34 - 19:42]
if you a teacher and you are using chart

[19:37 - 19:47]
GPT you can specify I want to teach

[19:42 - 19:51]
fractions from a sixth class learner

[19:47 - 19:53]
perspective or if you want to create a

[19:51 - 19:56]
Content or if you are working on

[19:53 - 19:59]
something and you want to make someone

[19:56 - 20:03]
understand that particular concept for

[19:59 - 20:08]
example I want a 10-year-old to

[20:03 - 20:11]
understand what is prompt how would I

[20:08 - 20:15]
make that particular learner

[20:11 - 20:17]
understand that kind of clarity that

[20:15 - 20:21]
kind of clarifications when you put in

[20:17 - 20:22]
your prompt what is your target audience

[20:21 - 20:26]
it will

[20:22 - 20:30]
generate tailored feedbacks tailored

[20:26 - 20:30]
outputs for your prompt

[20:31 - 20:36]
next is giving context basically you are

[20:34 - 20:39]
giving every possible additional

[20:36 - 20:43]
information for chat GPT in your prompt

[20:39 - 20:47]
so that the purpose of your request is

[20:43 - 20:49]
clarified to chat GPT and the response

[20:47 - 20:52]
that it generates

[20:49 - 20:52]
is what you

[20:52 - 20:59]
want next is giving examples we saw in

[20:56 - 21:02]
the previous components while we were

[20:59 - 21:05]
understanding components that giving

[21:02 - 21:09]
example trains your chat GPT or makes it

[21:05 - 21:12]
understand that what you want and it

[21:09 - 21:16]
learns from it to produce accurate

[21:12 - 21:18]
results next is specifying the style it

[21:16 - 21:20]
can be communication style if you're

[21:18 - 21:23]
working with a brand it can be how your

[21:20 - 21:26]
brand Works communication style such as

[21:23 - 21:29]
informal formal what do you want to do

[21:26 - 21:30]
so it's suitable for

[21:29 - 21:33]
your

[21:30 - 21:37]
response next is defining the scope when

[21:33 - 21:39]
you outline the scope with

[21:37 - 21:43]
specifications besides giving context

[21:39 - 21:45]
and examples chat GPT operates within

[21:43 - 21:47]
those

[21:45 - 21:49]
parameters for

[21:47 - 21:51]
example temperature when you are telling

[21:49 - 21:57]
okay I want to be creative my

[21:51 - 22:00]
temperature is this I want my uh top P

[21:57 - 22:04]
to be this right you are defining the

[22:00 - 22:08]
scope for your chart

[22:04 - 22:10]
GPT applying restrictions restrictions

[22:08 - 22:14]
becomes your what

[22:10 - 22:17]
is supposing length that you

[22:14 - 22:20]
want the output length the token length

[22:17 - 22:23]
that you want a there is a restriction

[22:20 - 22:27]
but what is that you

[22:23 - 22:29]
want when you apply those

[22:27 - 22:32]
restrictions that

[22:29 - 22:35]
constraints will create right boundaries

[22:32 - 22:39]
for chart GPT to produce relevant

[22:35 - 22:41]
responses so all these are checklists

[22:39 - 22:44]
that you can keep in

[22:41 - 22:47]
mind again these all uh pointers in your

[22:44 - 22:49]
checklist revolves around all the

[22:47 - 22:53]
components of a good prompt that we have

[22:49 - 22:55]
already seen But as a checklist you can

[22:53 - 22:58]
keep in mind that okay these are my

[22:55 - 23:00]
pointers which I can follow when I'm

[22:58 - 23:04]
designing my

[23:00 - 23:08]
prompt so this is how you can write a

[23:04 - 23:12]
good prompt so now let's understand what

[23:08 - 23:12]
are the different prompt

[23:13 - 23:23]
patterns one is your persona

[23:16 - 23:27]
patterns act as X do the task as

[23:23 - 23:30]
y as a yoga instructor create a beginner

[23:27 - 23:35]
friendly routine for joint Mobility for

[23:30 - 23:35]
example this is your persona

[23:35 - 23:43]
pattern next is your audience Persona

[23:39 - 23:48]
pattern for example in the previous bit

[23:43 - 23:52]
I told explain this concept supposing

[23:48 - 23:56]
prompt explain prompt to me assume that

[23:52 - 24:00]
I am a 10year old

[23:56 - 24:03]
child or another example that is there

[24:00 - 24:05]
explain the importance of eating greens

[24:03 - 24:10]
assume I am a skeptical

[24:05 - 24:14]
child so you are trying to tell Chad GPT

[24:10 - 24:17]
that what is your audience

[24:14 - 24:20]
Persona and you are writing your prompt

[24:17 - 24:23]
or designing your prompt having the

[24:20 - 24:27]
correct bits explained to me assume I'm

[24:23 - 24:29]
this or previously Persona pattern act

[24:27 - 24:33]
like this

[24:29 - 24:37]
next is visualization generator

[24:33 - 24:41]
pattern now I have a tool I want

[24:37 - 24:46]
to generate a data for

[24:41 - 24:51]
example and provide that data to my

[24:46 - 24:54]
tool so it can be generate X that can be

[24:51 - 24:56]
provided to Tool y for visualization for

[24:54 - 25:00]
data analysis for anything it can

[24:56 - 25:04]
generate data in table table format it

[25:00 - 25:06]
can generate csvs that can be provided

[25:04 - 25:09]
that you can download and provide it to

[25:06 - 25:11]
your tool for visualization data

[25:09 - 25:13]
analysis task modeling uh machine

[25:11 - 25:18]
learning tasks

[25:13 - 25:20]
anything so these are the first three

[25:18 - 25:23]
prompt patterns Persona pattern audience

[25:20 - 25:27]
Persona pattern visualization generator

[25:23 - 25:30]
pattern now let's see the next pattern

[25:27 - 25:35]
that is recipe pattern pattern for

[25:30 - 25:38]
example you want to do X task but to

[25:35 - 25:41]
perform this x task there are steps or

[25:38 - 25:48]
subtasks a B and

[25:41 - 25:51]
C so I want chat GPT to have a complete

[25:48 - 25:54]
itenary generated for me if I'm

[25:51 - 25:57]
traveling from Bangalore to daring and

[25:54 - 25:59]
from there I can take a train or a cap

[25:57 - 26:02]
to

[25:59 - 26:04]
dodging now based on this I am telling

[26:02 - 26:07]
charj to complete my

[26:04 - 26:10]
itinary this is a recipe pattern where

[26:07 - 26:14]
you know you want to do X task and you

[26:10 - 26:18]
know that a b c are the sub uh tasks or

[26:14 - 26:21]
the steps that are necessary for you to

[26:18 - 26:25]
do that X task so this is the recipe

[26:21 - 26:28]
pattern next is your template pattern

[26:25 - 26:31]
where you provide or as a user I provide

[26:28 - 26:34]
the chat GPD or generative model with

[26:31 - 26:38]
placeholder with a template and a

[26:34 - 26:42]
placeholder so that my output chat GPT

[26:38 - 26:46]
fits my outputs in those placeholders

[26:42 - 26:49]
for example I want a day wise travel

[26:46 - 26:52]
itinary if I'm visiting to Paris I'm

[26:49 - 26:55]
telling chat GPT to generate day wise

[26:52 - 26:59]
travel itinary for visiting

[26:55 - 27:02]
Paris now my placeholders are day for

[26:59 - 27:06]
the day uh of the travel supposing

[27:02 - 27:07]
Monday location in Paris what location

[27:06 - 27:11]
I'm traveling

[27:07 - 27:13]
to activity what in that location I plan

[27:11 - 27:17]
to

[27:13 - 27:21]
do time what is the best time or best

[27:17 - 27:24]
part of the day to travel or to go

[27:21 - 27:28]
there this is my entire template and how

[27:24 - 27:35]
I want the uh output it's indicated for

[27:28 - 27:39]
for day visit location at time for

[27:35 - 27:44]
activity so if CH GPD generates it will

[27:39 - 27:48]
give you for Monday visit location X at

[27:44 - 27:54]
time noon for activity visiting museum

[27:48 - 27:57]
for example so this becomes your entire

[27:54 - 28:00]
output and you're giving the template

[27:57 - 28:03]
you're giving giving placeholders that

[28:00 - 28:06]
place my information in these and

[28:03 - 28:10]
generate output in the form of this line

[28:06 - 28:12]
for day visit location at time for

[28:10 - 28:17]
activity containing

[28:12 - 28:21]
everything so these are your five prompt

[28:17 - 28:25]
patterns that you can embibe while

[28:21 - 28:28]
designing your prompts so that you have

[28:25 - 28:31]
better responses from chart GPT and also

[28:28 - 28:34]
you understand what you want to do you

[28:31 - 28:36]
have a Clarity what you want to do

[28:34 - 28:40]
and work

[28:36 - 28:44]
accordingly if you want a pattern where

[28:40 - 28:49]
you want Chad jibi to act as a person

[28:44 - 28:51]
where or you want to give a idea to Chad

[28:49 - 28:54]
giib what audience you are catering to

[28:51 - 28:57]
or you're doing visualization or you're

[28:54 - 29:00]
doing data analysis what is your pattern

[28:57 - 29:02]
if you are doing a task which contains

[29:00 - 29:04]
subtasks or sub

[29:02 - 29:06]
steps what is the pattern you follow and

[29:04 - 29:09]
if you have a template in mind how you

[29:06 - 29:11]
want your output to be generated then

[29:09 - 29:14]
you have template pattern so all these

[29:11 - 29:18]
five patterns you can keep in mind along

[29:14 - 29:22]
with your checklist while designing your

[29:18 - 29:27]
prompts let's now see common prompting

[29:22 - 29:28]
errors so wake or ambiguous prompts when

[29:27 - 29:31]
you just write

[29:28 - 29:34]
what is joints what is prompt

[29:31 - 29:36]
engineering that is your vague and

[29:34 - 29:40]
ambiguous prompts where you do not have

[29:36 - 29:41]
any context instruction what to do just

[29:40 - 29:44]
vague

[29:41 - 29:48]
prompts then there are biased prompts

[29:44 - 29:50]
where you are designing the prompts

[29:48 - 29:53]
supposing you have two categories and

[29:50 - 29:54]
the data or the instructions that you

[29:53 - 29:59]
are providing the examples you are

[29:54 - 30:02]
providing is leaning towards one and now

[29:59 - 30:04]
the second category is left alone that

[30:02 - 30:08]
is your biased

[30:04 - 30:11]
prompts third is lack of contextual

[30:08 - 30:14]
information you have just said okay

[30:11 - 30:16]
generate the content uh

[30:14 - 30:20]
for

[30:16 - 30:23]
fractions but what is the target

[30:20 - 30:25]
audience that you have uh acting are you

[30:23 - 30:29]
a teacher that you are teaching is there

[30:25 - 30:31]
any template is there any FL

[30:29 - 30:34]
that you want to follow are you looking

[30:31 - 30:35]
at creating a course are you looking as

[30:34 - 30:38]
at

[30:35 - 30:43]
teaching uh fractions as a uh slide you

[30:38 - 30:46]
want or as paragraph you want anything

[30:43 - 30:50]
any contextual information is

[30:46 - 30:53]
missing then you have insufficient

[30:50 - 30:56]
examples you do not have examples for

[30:53 - 30:58]
example you just saying generate

[30:56 - 31:02]
synthetic data

[30:58 - 31:05]
for doing sentiment

[31:02 - 31:09]
analysis but what

[31:05 - 31:12]
on you need to provide some content some

[31:09 - 31:16]
information that okay this is my data

[31:12 - 31:19]
now based on this you generate synthetic

[31:16 - 31:24]
data in a CSV format for me to do

[31:19 - 31:27]
sentiment analysis that is lacking your

[31:24 - 31:28]
training data or examples insufficient

[31:27 - 31:32]
examples

[31:28 - 31:35]
then there is complex or confusing

[31:32 - 31:38]
prompts if you write F lengthy prompts

[31:35 - 31:42]
but it is very complex it has several

[31:38 - 31:43]
different informations such as you have

[31:42 - 31:46]
Target information also you are acting

[31:43 - 31:48]
as a uh target audience information you

[31:46 - 31:50]
are acting as a uh analyst and you have

[31:48 - 31:53]
target audience you have branding also

[31:50 - 31:56]
you have campaigning also in that it is

[31:53 - 31:59]
very confusing for chat GPT to pick one

[31:56 - 32:02]
Persona and act

[31:59 - 32:05]
or for example you are designing a

[32:02 - 32:07]
campaign but you have given a lot of

[32:05 - 32:11]
information you

[32:07 - 32:15]
know check out uh Coca-Cola uh campaign

[32:11 - 32:17]
that happened at this year or check out

[32:15 - 32:19]
this campaign and design my campaign it

[32:17 - 32:22]
is confusing when you give different

[32:19 - 32:25]
reference points you need to be very

[32:22 - 32:28]
clear you need to be less complex your

[32:25 - 32:32]
prompt needs to be very

[32:28 - 32:36]
simplified so that chat GP can

[32:32 - 32:38]
understand last is not testing prompts

[32:36 - 32:40]
thoroughly you have given a very good

[32:38 - 32:42]
prompt you have designed a very good

[32:40 - 32:46]
prompt and given to chart GPT it

[32:42 - 32:49]
generates something but you are not

[32:46 - 32:50]
reading it you are blindly following

[32:49 - 32:53]
what it

[32:50 - 32:55]
generates you're not giving it a

[32:53 - 32:59]
feedback you are not asking what it has

[32:55 - 33:02]
understood from your uh designed

[32:59 - 33:06]
prompt that is not testing prompt

[33:02 - 33:09]
thoroughly and you will have less

[33:06 - 33:12]
accurate uh responses and in some cases

[33:09 - 33:15]
wrong responses now let's see what are

[33:12 - 33:17]
the applications different applications

[33:15 - 33:21]
of prompt

[33:17 - 33:24]
engineering one is content generation

[33:21 - 33:27]
you want copywriting advertising

[33:24 - 33:30]
creative writing educational content you

[33:27 - 33:32]
can do anything and everything under

[33:30 - 33:37]
content generation based on your target

[33:32 - 33:41]
audience based on who you are catering

[33:37 - 33:44]
to next is customer support and

[33:41 - 33:48]
engagement there are various chatbots

[33:44 - 33:51]
and virtual assistance that can use

[33:48 - 33:54]
generative models and instructional

[33:51 - 33:58]
guides as well so that your customer is

[33:54 - 34:03]
engaged you do not need human

[33:58 - 34:05]
as resources to reply to your customers

[34:03 - 34:09]
there are generative models that can

[34:05 - 34:13]
help you with act as a human and reply

[34:09 - 34:13]
to your customers at all times

[34:14 - 34:21]
24/7 then there is data analysis and

[34:18 - 34:23]
science data cleaning data preparation

[34:21 - 34:28]
visualization as we talked about

[34:23 - 34:31]
whatever you want to do you can give an

[34:28 - 34:35]
input as your data there would be a size

[34:31 - 34:38]
limit you give and you tell to clean you

[34:35 - 34:41]
generate the code you can ask what to do

[34:38 - 34:43]
when you are doing statistical analysis

[34:41 - 34:46]
on this kind of data what tests uh

[34:43 - 34:49]
hypothesis testing to do so all these

[34:46 - 34:53]
come under data analysis and data

[34:49 - 34:55]
science then application comes under

[34:53 - 34:58]
code generation and software development

[34:55 - 35:01]
that is automating your code wrting

[34:58 - 35:06]
debugging document generation

[35:01 - 35:09]
documentation so all these using chat GT

[35:06 - 35:11]
or generative models you can they can

[35:09 - 35:14]
make your life easy they can generate a

[35:11 - 35:16]
code for you whatever you are looking at

[35:14 - 35:20]
but you have to be very specific you

[35:16 - 35:23]
have to be very clear what you want so

[35:20 - 35:26]
that your output your response from chat

[35:23 - 35:29]
GPT your generative models are

[35:26 - 35:32]
customized based on your

[35:29 - 35:34]
prompts next is research and information

[35:32 - 35:36]
retrieval like for example Tech

[35:34 - 35:40]
summarization question answering

[35:36 - 35:41]
anything and everything you can give

[35:40 - 35:45]
links as

[35:41 - 35:47]
a context and tell that okay these are

[35:45 - 35:51]
the specific researches done in this

[35:47 - 35:54]
field based on this give me your

[35:51 - 35:56]
hypothesis what next can be done for

[35:54 - 35:58]
example next is machine translation

[35:56 - 36:01]
information Shar sharing internal

[35:58 - 36:02]
communication anything related to

[36:01 - 36:05]
machine

[36:02 - 36:08]
translation then sentiment analysis

[36:05 - 36:10]
consumer feedback analysis brand

[36:08 - 36:14]
management marketing all these things

[36:10 - 36:17]
using sentiment analysis can be done and

[36:14 - 36:20]
prompt engineering is used to create

[36:17 - 36:20]
tools for

[36:20 - 36:26]
this other domains include Healthcare

[36:24 - 36:28]
where you can do diagnosis you can

[36:26 - 36:33]
create a system using generative model

[36:28 - 36:36]
to diagnosis for a disease and you can

[36:33 - 36:39]
prompt design prompts that okay my

[36:36 - 36:42]
patient is this it has a history of this

[36:39 - 36:44]
now these are the symptoms what is your

[36:42 - 36:46]
diagnosis

[36:44 - 36:48]
Manufacturing in manufacturing if you

[36:46 - 36:51]
want to supply your manufacturing and

[36:48 - 36:54]
your suppliers you create an llm you

[36:51 - 36:58]
create generative model where your users

[36:54 - 37:00]
your employees can ask if manufacturing

[36:58 - 37:04]
this if I have to transport here what to

[37:00 - 37:06]
do what not to do everything the mesh

[37:04 - 37:09]
the network that you have in

[37:06 - 37:13]
manufacturing industry it can intake and

[37:09 - 37:15]
give you output results based on your

[37:13 - 37:19]
prompts then comes

[37:15 - 37:22]
security security there are attacks they

[37:19 - 37:26]
can be a lot of AI tools that can be

[37:22 - 37:28]
used to prevent those attacks to prevent

[37:26 - 37:31]
your systems you know without

[37:28 - 37:32]
failing last is retail and shopping that

[37:31 - 37:35]
is

[37:32 - 37:38]
e-commerce in your OT platforms or

[37:35 - 37:41]
shopping e-commerce mintra different

[37:38 - 37:44]
websites Amazon they can

[37:41 - 37:46]
use generative models to intake all

[37:44 - 37:49]
these things and you prompt that okay I

[37:46 - 37:50]
want this and it helps you with retail

[37:49 - 37:53]
and

[37:50 - 37:55]
shopping so these are the various

[37:53 - 37:58]
applications for prompt

[37:55 - 38:01]
engineering now let's write a few

[37:58 - 38:06]
prompts so that you can understand what

[38:01 - 38:09]
are prompts how to write them so we are

[38:06 - 38:12]
on a prompt engineering course where you

[38:09 - 38:15]
understanding the outcome of this course

[38:12 - 38:18]
is for you to understand what is prompt

[38:15 - 38:22]
engineering how to write a good prompt

[38:18 - 38:26]
right so let's give chat GPT a simple

[38:22 - 38:28]
prompt that is what is prompt

[38:26 - 38:30]
engineering and let's let's see what it

[38:28 - 38:34]
tells

[38:30 - 38:37]
us it starts generating and it tells you

[38:34 - 38:41]
what prompt engineering refers to what

[38:37 - 38:44]
is crafting and refinement of prompts

[38:41 - 38:48]
and generates responses from AI language

[38:44 - 38:50]
model such as GPT then it's saying that

[38:48 - 38:53]
prompt engineering involves considering

[38:50 - 38:56]
various factors such as language used in

[38:53 - 38:58]
prompt structure of prompt context

[38:56 - 39:00]
effective prompt engineering can

[38:58 - 39:04]
significantly improve performance and

[39:00 - 39:06]
usefulness of a AI models in various

[39:04 - 39:10]
domains such as including natural

[39:06 - 39:13]
language understanding text generation

[39:10 - 39:16]
dialogue systems Etc if you see this is

[39:13 - 39:20]
a query that you have put which you can

[39:16 - 39:25]
also put on Google and get different

[39:20 - 39:27]
links not a text not a paragraph but

[39:25 - 39:31]
different links where you can open the

[39:27 - 39:34]
links and read it here on chat GPT when

[39:31 - 39:38]
you enter what is prompt engineering you

[39:34 - 39:42]
get this a definition a elaborated

[39:38 - 39:43]
explanation of what the generative model

[39:42 - 39:47]
that is chat

[39:43 - 39:49]
GPT that uses GPT as a generative model

[39:47 - 39:52]
understands about prompt engineering and

[39:49 - 39:54]
it tells you their perspective of it

[39:52 - 39:57]
based on the different parameters that

[39:54 - 40:00]
it is trained on

[39:57 - 40:05]
now let's see another

[40:00 - 40:05]
example suppose I want to

[40:07 - 40:12]
travel 5

[40:09 - 40:15]
days in

[40:12 - 40:18]
India please make

[40:15 - 40:18]
me

[40:21 - 40:28]
itinary I give this a

[40:24 - 40:29]
promt according to

[40:28 - 40:34]
chat

[40:29 - 40:38]
gbt understanding it'll give me

[40:34 - 40:41]
this arrival in Delhi I have not said

[40:38 - 40:46]
that where I'm arriving from it assumed

[40:41 - 40:49]
arrival in Delhi day two Delhi to Agra

[40:46 - 40:53]
day three Agra to japur day four japur

[40:49 - 40:57]
sightseeing day five jaur to Delhi and

[40:53 - 40:59]
it tells me when you are in that day you

[40:57 - 41:03]
arrive in Delhi for example it is

[40:59 - 41:05]
capital of India visit historic

[41:03 - 41:09]
landmarks like red

[41:05 - 41:14]
Fort explore bustling streets of old

[41:09 - 41:18]
Delhi experience optional visit is humay

[41:14 - 41:20]
Tomb or Kum Minar okay again day two

[41:18 - 41:22]
it's giving

[41:20 - 41:26]
different or day three it is giving

[41:22 - 41:29]
different options I have not said here

[41:26 - 41:33]
what I like I have not said whether I am

[41:29 - 41:36]
a beach person or a mountain person or a

[41:33 - 41:39]
normal uh I want to travel uh which kind

[41:36 - 41:42]
of places hot cold nothing it has not

[41:39 - 41:47]
asked also this is my random prompt that

[41:42 - 41:49]
I have given chat GP now let's see a

[41:47 - 41:50]
different kind of example I have a

[41:49 - 41:53]
passage of three four sentences I want

[41:50 - 41:57]
to summarize in one sentence right I am

[41:53 - 42:00]
giving an example that my example text

[41:57 - 42:03]
next is scientists have discovered a new

[42:00 - 42:06]
species of orchid in rainforests of

[42:03 - 42:10]
South America and the output that I'm

[42:06 - 42:15]
giving is a new species the entire

[42:10 - 42:18]
sentence okay now my sentence or my

[42:15 - 42:21]
passage is on prompt engineering it

[42:18 - 42:24]
involves crafting precise contest

[42:21 - 42:27]
Specific Instructions and queries and

[42:24 - 42:29]
these prompts provide guidance we can

[42:27 - 42:32]
can enhance model performance achieve

[42:29 - 42:35]
better control over generated output and

[42:32 - 42:37]
address limitations associated with

[42:35 - 42:40]
open-ended language generation and I

[42:37 - 42:43]
want to summarize this

[42:40 - 42:44]
into one or two sentences right this is

[42:43 - 42:49]
my

[42:44 - 42:52]
prompt I give this and this is what it

[42:49 - 42:58]
gives me however this is isn't it

[42:52 - 43:04]
feeling as same now if I say please

[42:58 - 43:07]
shorten this further for example I don't

[43:04 - 43:14]
want this much I want short and crisp it

[43:07 - 43:14]
still gives me this again I say B please

[43:14 - 43:17]
be

[43:20 - 43:25]
concise now it gives me prompt

[43:22 - 43:28]
engineering uses precise prompts to

[43:25 - 43:31]
guide language models improving

[43:28 - 43:34]
performance control and overcoming

[43:31 - 43:37]
limitations in generating responses

[43:34 - 43:39]
however the first one when I asked

[43:37 - 43:41]
please shorten this further it said

[43:39 - 43:44]
crafting precise instructions called

[43:41 - 43:47]
prompts to guide language models and

[43:44 - 43:50]
shape their output it enhances model

[43:47 - 43:53]
performance offers better control over

[43:50 - 43:56]
generated uh responses and addresses

[43:53 - 43:59]
limitations of open-ended language

[43:56 - 44:02]
generation

[43:59 - 44:06]
if you compare this output with this

[44:02 - 44:09]
output some information is

[44:06 - 44:14]
lost some information is retained while

[44:09 - 44:16]
making it concise so you have to see

[44:14 - 44:20]
what responses you are getting based on

[44:16 - 44:22]
your prompts and give them a feedback

[44:20 - 44:27]
what you want to

[44:22 - 44:29]
do so these are some examples of prompts

[44:27 - 44:31]
this is the first uh time you're looking

[44:29 - 44:35]
at prompts in this

[44:31 - 44:39]
course so we try to cover from

[44:35 - 44:41]
basic content generation basic query

[44:39 - 44:44]
based uh prompts

[44:41 - 44:47]
to traveling itary without any

[44:44 - 44:49]
information to text summarization where

[44:47 - 44:52]
you are given an example and asking to

[44:49 - 44:57]
summarize and giving chat GPT a feedback

[44:52 - 45:00]
on it right so this is your first prompt

[44:57 - 45:04]
now let's see different components and

[45:00 - 45:08]
further analyze what is a good

[45:04 - 45:10]
prompt now let's look at few examples so

[45:08 - 45:14]
that we can analyze what are good

[45:10 - 45:17]
prompts and the checklist that we have

[45:14 - 45:20]
seen the pattern Persona patterns we

[45:17 - 45:22]
have seen the components that we have

[45:20 - 45:25]
seen how to integrate that while

[45:22 - 45:28]
designing your prompts now let's see how

[45:25 - 45:31]
we have designed this prompt and what

[45:28 - 45:33]
all components we have

[45:31 - 45:36]
included in content

[45:33 - 45:39]
generation where where we have written

[45:36 - 45:43]
provide a comprehensive overview of tech

[45:39 - 45:45]
summarization which is our main topic or

[45:43 - 45:49]
concept that we want to understand

[45:45 - 45:52]
empowering Learners to grasp its

[45:49 - 45:54]
significance and potential applications

[45:52 - 45:57]
across diverse

[45:54 - 46:01]
domains so basically with this l we are

[45:57 - 46:04]
telling that we want our Learners to

[46:01 - 46:08]
grasp what is text memorization for

[46:04 - 46:09]
different domains it can be for

[46:08 - 46:11]
manufacturing domain it can be

[46:09 - 46:14]
Healthcare but what is Tech

[46:11 - 46:16]
summarization we want our Learners to

[46:14 - 46:19]
understand that now we have given some

[46:16 - 46:21]
guidelines also here you need to follow

[46:19 - 46:25]
below guidelines while answering we are

[46:21 - 46:30]
telling chart GPT provide an insight

[46:25 - 46:33]
into Tech some mization a tool for

[46:30 - 46:37]
condensing lengthy text into shorter and

[46:33 - 46:40]
more manageable versions second we say

[46:37 - 46:43]
explore various techniques like

[46:40 - 46:46]
extraction abstraction used to achieve

[46:43 - 46:49]
this and provide Clarity on how it

[46:46 - 46:52]
works third we are saying provide

[46:49 - 46:55]
relevant examples of different domains

[46:52 - 46:57]
and use cases where this text

[46:55 - 47:01]
summarization can be

[46:57 - 47:04]
SL fourth is explain te teex

[47:01 - 47:07]
summarization how it is evolving and

[47:04 - 47:09]
innovating with advancement in Ai and

[47:07 - 47:13]
machine learning offering customized

[47:09 - 47:16]
solutions for diverse needs we are also

[47:13 - 47:19]
giving extra instructions also that

[47:16 - 47:22]
while providing insights the Learners

[47:19 - 47:23]
are from different domains and have just

[47:22 - 47:26]
the

[47:23 - 47:27]
preliminary knowledge of tech

[47:26 - 47:30]
summarization

[47:27 - 47:32]
cover the basics so for that you cover

[47:30 - 47:34]
the basics of text summarization

[47:32 - 47:38]
techniques highlight key Concepts

[47:34 - 47:40]
without diving into overly technical

[47:38 - 47:43]
details what not to do we have also

[47:40 - 47:46]
specified this approach will cater to

[47:43 - 47:48]
our audience's level with familiarity of

[47:46 - 47:51]
the topic we can tell the level also

[47:48 - 47:54]
here but let's see how it

[47:51 - 47:57]
responds give explanation in clear

[47:54 - 48:00]
straight forward American English we are

[47:57 - 48:03]
telling the scope also we are telling

[48:00 - 48:06]
the communication style

[48:03 - 48:08]
also ensuring the accessibility and

[48:06 - 48:09]
understanding maintain a clear and

[48:08 - 48:13]
straightforward

[48:09 - 48:16]
tone ensuring accessibility and ease of

[48:13 - 48:19]
understanding for all Learners now let's

[48:16 - 48:24]
give this prompt to chart gbt and see

[48:19 - 48:24]
how it response

[48:28 - 48:34]
so it gives text summarization is a

[48:31 - 48:37]
powerful tool used to condense lengthy

[48:34 - 48:39]
text into shorter more manageable

[48:37 - 48:42]
versions it's basically taken what we

[48:39 - 48:44]
have provided and given as a definition

[48:42 - 48:46]
making it easier for leaders to grasp

[48:44 - 48:50]
main points without going through entire

[48:46 - 48:53]
document now this is now breaking a key

[48:50 - 48:56]
con uh aspects into better

[48:53 - 48:59]
understanding insights into Tech

[48:56 - 49:02]
summarizing ation where it tells that it

[48:59 - 49:05]
can be thought of a process similar to

[49:02 - 49:06]
what humans naturally do when they

[49:05 - 49:09]
summarize an

[49:06 - 49:12]
article a book or a conversation the

[49:09 - 49:14]
goal is to extract the most important

[49:12 - 49:16]
information and present in the concise

[49:14 - 49:19]
form that's okay that is the Insight

[49:16 - 49:23]
that it is giving now we also

[49:19 - 49:25]
highlighted that please ensure that you

[49:23 - 49:29]
are using extraction and abstraction

[49:25 - 49:33]
also to explain Tech

[49:29 - 49:36]
summarization and along with that use

[49:33 - 49:38]
examples and use cases also where it is

[49:36 - 49:40]
highlighting what are the

[49:38 - 49:43]
applications in various domains in news

[49:40 - 49:46]
aggregation academic

[49:43 - 49:48]
research legal documents that is

[49:46 - 49:51]
your

[49:48 - 49:54]
law in branding social

[49:51 - 49:57]
media in custom feedback analysis which

[49:54 - 50:00]
different companies uses

[49:57 - 50:03]
then it is giving the evolution and

[50:00 - 50:04]
advancements with time what it has done

[50:03 - 50:07]
customized

[50:04 - 50:10]
summaries multimodel

[50:07 - 50:13]
summarization realtime summarization

[50:10 - 50:18]
evaluation Matrix various things that

[50:13 - 50:21]
has evolved in Tex summarization now if

[50:18 - 50:23]
you want more insights on text

[50:21 - 50:26]
summarization where you want different

[50:23 - 50:28]
techniques for it to explain different

[50:26 - 50:30]
techniques you need to tell please

[50:28 - 50:34]
explain further more or elaborate

[50:30 - 50:37]
further more on techniques used on

[50:34 - 50:38]
extraction or abstraction or give me

[50:37 - 50:41]
more

[50:38 - 50:44]
examples not application examples so if

[50:41 - 50:46]
you see here it has given use cases the

[50:44 - 50:50]
applications across it has not given

[50:46 - 50:54]
examples so you can say this is my

[50:50 - 50:56]
feedback to you that the explanation

[50:54 - 51:00]
that you have generated is missing

[50:56 - 51:03]
example I'm not able to correlate what

[51:00 - 51:06]
is given here what you have generated

[51:03 - 51:09]
here right so you can tell the examples

[51:06 - 51:11]
are missing you can also tell that

[51:09 - 51:13]
Evolution and advancements does not tell

[51:11 - 51:16]
me when it started does not tell me a

[51:13 - 51:19]
history Evolution means history it is

[51:16 - 51:23]
not telling me that so all these are

[51:19 - 51:26]
your feedbacks so that you can have a

[51:23 - 51:30]
output you can have a response a fin fin

[51:26 - 51:32]
response that gives you what is Tech

[51:30 - 51:34]
summarization what is the significance

[51:32 - 51:36]
of tech summarization what are different

[51:34 - 51:38]
techniques of teex summarization what

[51:36 - 51:41]
are the different examples of TCH

[51:38 - 51:43]
summarization what are the applications

[51:41 - 51:46]
how it evolved when it started what are

[51:43 - 51:50]
the different things what are the

[51:46 - 51:55]
different advancements in using AI now

[51:50 - 51:58]
so you can definitely work further more

[51:55 - 52:04]
now this was chat GPT

[51:58 - 52:07]
3.5 let's now see in chart GPT 4 we

[52:04 - 52:11]
create a new chat and give the

[52:07 - 52:14]
same prompt to chat gbt 4 also and see

[52:11 - 52:16]
how it response what is the difference

[52:14 - 52:19]
between four and

[52:16 - 52:22]
three we have given the same prompt not

[52:19 - 52:26]
changed a single line

[52:22 - 52:29]
here so it has generated an output where

[52:26 - 52:32]
it generates a

[52:29 - 52:34]
content on text summarization if and if

[52:32 - 52:38]
you note the first

[52:34 - 52:40]
line it has not taken the same thing

[52:38 - 52:45]
that we have given as prompt it has

[52:40 - 52:47]
written and explained in its different

[52:45 - 52:49]
words or different explanation what is

[52:47 - 52:51]
text summarization which is a powerful

[52:49 - 52:54]
tool in the field of natural language

[52:51 - 52:58]
processing designed to condense long

[52:54 - 53:00]
pieces of text into shorter concise

[52:58 - 53:03]
summaries now it tells you the

[53:00 - 53:05]
techniques of text summarization which

[53:03 - 53:09]
is abstraction and

[53:05 - 53:11]
extraction with tools and various

[53:09 - 53:15]
examples of it various applications of

[53:11 - 53:18]
it now it tells you applications across

[53:15 - 53:21]
various domains as well which is closely

[53:18 - 53:24]
the same as 3.5 again this is also

[53:21 - 53:29]
missing your examples it has not given

[53:24 - 53:33]
you any example in evolution if you see

[53:29 - 53:37]
it has given how it has evolved you can

[53:33 - 53:41]
also give a feedback to chat GPT 4 that

[53:37 - 53:44]
I want a timeline Evolution for Tech

[53:41 - 53:48]
summarization and it has briefly

[53:44 - 53:50]
explained some advancement again as

[53:48 - 53:53]
compared to 3.5 that is missing which

[53:50 - 53:57]
you can give as a feedback and it can

[53:53 - 54:00]
improve upon so this is what cot

[53:57 - 54:05]
content generation example was in both

[54:00 - 54:08]
chat GPT 3.5 and chat GPT 4 now let's

[54:05 - 54:10]
see a different example that is text

[54:08 - 54:12]
summarization we learned about Tex

[54:10 - 54:15]
summarization now you have fairly a good

[54:12 - 54:17]
idea what is Tech summarization you give

[54:15 - 54:20]
what you want to understand and it

[54:17 - 54:23]
summarizes and gives you output

[54:20 - 54:27]
summaries basically of what you provide

[54:23 - 54:33]
now let's provide chart GPT

[54:27 - 54:33]
an article and ask it to summarize

[54:33 - 54:39]
it so we have the tech

[54:36 - 54:42]
summarization example here where we are

[54:39 - 54:45]
given an article on Indian Express based

[54:42 - 54:50]
on

[54:45 - 54:53]
Tesla policy and we have asked that use

[54:50 - 54:57]
pinto pyramid principle and we have

[54:53 - 54:59]
given the link also to that to structure

[54:57 - 55:02]
your communication from top down

[54:59 - 55:05]
ensuring Swift and clear message

[55:02 - 55:09]
delivery start with the conclusion

[55:05 - 55:12]
follow with key arguments and then

[55:09 - 55:14]
support with detailed information give

[55:12 - 55:18]
only relevant information that is

[55:14 - 55:19]
appropriate to understand business

[55:18 - 55:23]
outcomes

[55:19 - 55:26]
only use clear and straightforward

[55:23 - 55:30]
language for better understanding so we

[55:26 - 55:33]
have given a context an

[55:30 - 55:36]
instruction we have not given an example

[55:33 - 55:37]
here but we have given clear instruction

[55:36 - 55:40]
and we have

[55:37 - 55:44]
given restrictions also we have given a

[55:40 - 55:48]
style also that be straightforward right

[55:44 - 55:51]
you can further give that okay uh make

[55:48 - 55:56]
your word limit to this much only okay

[55:51 - 55:56]
so let's first see what it generates

[55:57 - 56:04]
so in pinto pyramid principle we write a

[56:02 - 56:07]
conclusion first then we write key

[56:04 - 56:09]
argument why we have concluded so

[56:07 - 56:12]
basically if you are having a

[56:09 - 56:14]
conversation and you want to conclude

[56:12 - 56:16]
that conversation you will write that

[56:14 - 56:18]
conclusion first then you'll write your

[56:16 - 56:21]
key arguments okay this is why I'm

[56:18 - 56:23]
telling and then you write the detailed

[56:21 - 56:27]
information that is related so basically

[56:23 - 56:30]
we want because we are

[56:27 - 56:33]
asking for business right business needs

[56:30 - 56:35]
conclusion first so we have concluded

[56:33 - 56:38]
this first that India's decision to

[56:35 - 56:42]
lower import taxes on EV could

[56:38 - 56:45]
potentially pave the way for Tesla LED

[56:42 - 56:48]
by Elon Musk to enter Indian market now

[56:45 - 56:51]
key arguments are lowering import uh

[56:48 - 56:55]
taxes Tesla entry into Indian market

[56:51 - 56:58]
boost for India's EV industry then we

[56:55 - 57:02]
have detailed inputs from that report

[56:58 - 57:05]
only that are mentioned here right so

[57:02 - 57:07]
this is a text summarization in a

[57:05 - 57:11]
structured way text summarization can

[57:07 - 57:13]
also be if you go back in the first

[57:11 - 57:16]
prompt that you have written where we

[57:13 - 57:19]
had four five lines and it summarized

[57:16 - 57:22]
for us that is also text summarization

[57:19 - 57:24]
this is a structured text summarization

[57:22 - 57:28]
where you do not need to go through this

[57:24 - 57:30]
whole article of Indian Express and it

[57:28 - 57:32]
gave you a conclusion it gave you key

[57:30 - 57:35]
arguments what it presented in the

[57:32 - 57:37]
article right so this is an example for

[57:35 - 57:40]
Tex

[57:37 - 57:44]
summarization now let's do an example on

[57:40 - 57:47]
code generation which mostly from people

[57:44 - 57:52]
from Tech domain or data domain will use

[57:47 - 57:57]
charity for right so the prompt has a

[57:52 - 58:00]
python recursion uh code for

[57:57 - 58:04]
calculating factorial where we are

[58:00 - 58:07]
defining a method to calculate factorial

[58:04 - 58:11]
if n is equal to 1 equal equal to 1

[58:07 - 58:13]
return n else return n into calculate

[58:11 - 58:16]
factorial we are doing recursively right

[58:13 - 58:18]
now the same calculating factorial we

[58:16 - 58:22]
have done with non-tail recursive

[58:18 - 58:27]
function right we are giving an example

[58:22 - 58:31]
on that as well now what we want us

[58:27 - 58:35]
to write a program with recursive

[58:31 - 58:39]
function to check if a string is pal

[58:35 - 58:42]
androme in python or not

[58:39 - 58:45]
right where we have given two examples

[58:42 - 58:48]
of recursion on factorial and now we are

[58:45 - 58:51]
asking chat GPT to generate code for

[58:48 - 58:51]
palandro

[58:56 - 59:03]
now this has given that okay with

[59:00 - 59:06]
comment that this is the base case if

[59:03 - 59:07]
the length of the string is zero or one

[59:06 - 59:10]
it's a

[59:07 - 59:14]
palr compare the first and last

[59:10 - 59:17]
characters of the string false okay

[59:14 - 59:21]
return false if it is not equal

[59:17 - 59:24]
recursive call check if the substring

[59:21 - 59:27]
excluding the first and last characters

[59:24 - 59:29]
right so this becomes your

[59:27 - 59:32]
output now this function works by

[59:29 - 59:34]
recursively checking if the first and

[59:32 - 59:38]
last characters of the strings are same

[59:34 - 59:41]
okay you can also uh in your prompt say

[59:38 - 59:43]
uh please uh explain line by line as

[59:41 - 59:45]
well if you want further elaborated

[59:43 - 59:49]
explanation as well though it has uh

[59:45 - 59:51]
given comments right you can further ask

[59:49 - 59:55]
give me further more explanation for

[59:51 - 59:58]
this now let's see the same thing in

[59:55 - 59:58]
chat jib 4

[01:00:04 - 01:00:12]
in chat gbt 4 it actually has

[01:00:09 - 01:00:18]
explained what is this function what it

[01:00:12 - 01:00:20]
does where Len is equals to Zer A Single

[01:00:18 - 01:00:23]
Character what it will do both cases

[01:00:20 - 01:00:28]
will be true it runs returns true okay

[01:00:23 - 01:00:30]
what is the cursive case first checks if

[01:00:28 - 01:00:34]
the first and last characters of the

[01:00:30 - 01:00:36]
string are same calls is pal androme it

[01:00:34 - 01:00:39]
is telling each and everything that the

[01:00:36 - 01:00:42]
function is doing this is equivalent

[01:00:39 - 01:00:46]
however this is a little bit optimized

[01:00:42 - 01:00:50]
version of 3.5 now you can see a

[01:00:46 - 01:00:53]
difference between how or what 3.5

[01:00:50 - 01:00:56]
generates code for a specific problem

[01:00:53 - 01:00:59]
statement and how four gener R so

[01:00:56 - 01:01:02]
basically four is more optimized for uh

[01:00:59 - 01:01:05]
code generation rather than

[01:01:02 - 01:01:08]
3.5 in 3.5 you

[01:01:05 - 01:01:10]
can iteratively ask please optimize

[01:01:08 - 01:01:14]
please optimize this please optimize

[01:01:10 - 01:01:16]
this right in four you can do once or

[01:01:14 - 01:01:18]
twice and then actually it will give you

[01:01:16 - 01:01:22]
an optimized version for the same and

[01:01:18 - 01:01:24]
you can write furthermore to uh refine

[01:01:22 - 01:01:27]
your prompt you can write please give me

[01:01:24 - 01:01:29]
the complexity time complexity storage

[01:01:27 - 01:01:32]
complexity for the same space complexity

[01:01:29 - 01:01:35]
for the same right so these are the

[01:01:32 - 01:01:37]
examples for a good prompt where you are

[01:01:35 - 01:01:39]
giving a context where you giving an

[01:01:37 - 01:01:42]
instruction where you are giving uh

[01:01:39 - 01:01:44]
restrictions we are doing where you are

[01:01:42 - 01:01:47]
following items from your checklist

[01:01:44 - 01:01:50]
where you are following a pattern uh to

[01:01:47 - 01:01:54]
provide a pattern to your uh chat GPT as

[01:01:50 - 01:01:56]
well so these are some of the examples

[01:01:54 - 01:02:02]
that you can refine more you can

[01:01:56 - 01:02:05]
experiment more with Advanced prompt

[01:02:02 - 01:02:08]
strategies these are different

[01:02:05 - 01:02:13]
prompts or different types of prompts

[01:02:08 - 01:02:18]
that exists we are taking only

[01:02:13 - 01:02:21]
three types zero short few short chain

[01:02:18 - 01:02:24]
of thought process that's it there are

[01:02:21 - 01:02:28]
several different more strategies that

[01:02:24 - 01:02:30]
exists like self-consistency

[01:02:28 - 01:02:31]
tree of

[01:02:30 - 01:02:36]
thought

[01:02:31 - 01:02:40]
respond rephrase Etc you can go and look

[01:02:36 - 01:02:44]
dive deeper into the same let's not see

[01:02:40 - 01:02:47]
what is zero short zero short is

[01:02:44 - 01:02:51]
directly instructing your model that is

[01:02:47 - 01:02:54]
chat GPT to perform a task without any

[01:02:51 - 01:02:57]
additional examples for example I just

[01:02:54 - 01:02:57]
say classify

[01:02:58 - 01:03:05]
my feedback into neutral positive and

[01:03:02 - 01:03:10]
negative and I give a

[01:03:05 - 01:03:11]
line that is the input and it outputs

[01:03:10 - 01:03:13]
the

[01:03:11 - 01:03:17]
sentiment that's it this is my zero

[01:03:13 - 01:03:21]
short few short is teaching with

[01:03:17 - 01:03:26]
examples that we saw previously where we

[01:03:21 - 01:03:28]
gave two examples and third is our input

[01:03:26 - 01:03:32]
where we are indicating how we want the

[01:03:28 - 01:03:37]
output and it gives the output for the

[01:03:32 - 01:03:39]
same so that is few short zero short is

[01:03:37 - 01:03:43]
without any

[01:03:39 - 01:03:44]
example any prompt without any example

[01:03:43 - 01:03:49]
where you are only telling the

[01:03:44 - 01:03:51]
instruction that's it no context F short

[01:03:49 - 01:03:54]
is giving

[01:03:51 - 01:03:56]
examples for chat GPT to learn and

[01:03:54 - 01:04:01]
produce your response

[01:03:56 - 01:04:04]
now Chain of Thought Chain of Thought is

[01:04:01 - 01:04:09]
designed for logical

[01:04:04 - 01:04:12]
tasks anything logical it is the best

[01:04:09 - 01:04:16]
prompt strategy to

[01:04:12 - 01:04:18]
follow you give in Chain of

[01:04:16 - 01:04:21]
Thought an

[01:04:18 - 01:04:23]
example how to do a process for example

[01:04:21 - 01:04:26]
you

[01:04:23 - 01:04:30]
are adding

[01:04:26 - 01:04:36]
you are given an example 2 + 2 is = 4

[01:04:30 - 01:04:38]
then you say 15 + 4 = 19 then you give

[01:04:36 - 01:04:38]
an

[01:04:38 - 01:04:46]
input okay I want

[01:04:43 - 01:04:49]
3 150

[01:04:46 - 01:04:49]
+

[01:04:49 - 01:04:56]
10,500 what will be my answer you're

[01:04:53 - 01:04:59]
telling how to do the process and then

[01:04:56 - 01:05:01]
you asking in your input what will be

[01:04:59 - 01:05:05]
the

[01:05:01 - 01:05:09]
output this is very basic there are

[01:05:05 - 01:05:13]
complex problems for example blood

[01:05:09 - 01:05:18]
relations X is related to Y so what will

[01:05:13 - 01:05:22]
be the relation for Zed with

[01:05:18 - 01:05:26]
X so all these logical questions all

[01:05:22 - 01:05:29]
these logical uh and complex bits is for

[01:05:26 - 01:05:33]
Chain of Thought now let's

[01:05:29 - 01:05:36]
see examples of these three prompt

[01:05:33 - 01:05:39]
strategies on chart GPT so that you

[01:05:36 - 01:05:43]
understand it better how to work with

[01:05:39 - 01:05:47]
these on actual playground let's now see

[01:05:43 - 01:05:49]
few examples on these Advanced prompt

[01:05:47 - 01:05:53]
strategies zero short few short and

[01:05:49 - 01:05:55]
Chain of Thought now zero shot is giving

[01:05:53 - 01:05:58]
no examples just giving the the

[01:05:55 - 01:06:03]
instruction just giving what it needs to

[01:05:58 - 01:06:05]
do so we'll take a simple example very

[01:06:03 - 01:06:07]
generalized example where we are

[01:06:05 - 01:06:08]
generating a passage in the style of

[01:06:07 - 01:06:13]
William

[01:06:08 - 01:06:13]
Shakespeare okay we are giving this

[01:06:14 - 01:06:23]
prompt based on what chart gbd would

[01:06:18 - 01:06:27]
have been trained on it has given a

[01:06:23 - 01:06:30]
passage from of William Shake spare

[01:06:27 - 01:06:34]
but from where it is from you can ask

[01:06:30 - 01:06:37]
from where this

[01:06:34 - 01:06:37]
passage is

[01:06:40 - 01:06:45]
from the passage I provided is an

[01:06:43 - 01:06:47]
original composition written in the

[01:06:45 - 01:06:51]
style of William Shakespeare while it

[01:06:47 - 01:06:55]
captures the language imagary and themes

[01:06:51 - 01:06:58]
often found in Shakespearean work it is

[01:06:55 - 01:07:03]
not directly derived from any specific

[01:06:58 - 01:07:06]
text by the B do did you want the

[01:07:03 - 01:07:10]
same right you need to give the feedback

[01:07:06 - 01:07:15]
now I did not want in this manner I

[01:07:10 - 01:07:21]
wanted a extract uh from his own plays

[01:07:15 - 01:07:25]
or his own uh poetry and given as an

[01:07:21 - 01:07:27]
example right or is it following what

[01:07:25 - 01:07:31]
you you want right you can give that as

[01:07:27 - 01:07:34]
a feedback as well now this is zero

[01:07:31 - 01:07:38]
short if you want to make this as a f

[01:07:34 - 01:07:40]
shot we need to give an example we have

[01:07:38 - 01:07:41]
given an example generate a passage in

[01:07:40 - 01:07:45]
the style of William Shakespeare example

[01:07:41 - 01:07:48]
is original text to be or not to be that

[01:07:45 - 01:07:53]
is the question Shakespeare in style

[01:07:48 - 01:07:56]
rewrite is WEA this's nobler in the mind

[01:07:53 - 01:08:01]
to suffer the

[01:07:56 - 01:08:05]
slings and arrows of Outrageous Fortune

[01:08:01 - 01:08:06]
similarly in example two we have given

[01:08:05 - 01:08:10]
all the

[01:08:06 - 01:08:16]
worlds is a stage and all the men and

[01:08:10 - 01:08:18]
women merely players right so now we say

[01:08:16 - 01:08:22]
this is few

[01:08:18 - 01:08:26]
short it has given an example out out

[01:08:22 - 01:08:30]
brief candle lives

[01:08:26 - 01:08:35]
but a walking Shadow a poor player that

[01:08:30 - 01:08:39]
struts and frits his R upon the stage

[01:08:35 - 01:08:41]
and then is heard no more right and

[01:08:39 - 01:08:45]
Shakespeare and style for

[01:08:41 - 01:08:48]
this so this is an example of zero shot

[01:08:45 - 01:08:52]
and this is an example of few shot

[01:08:48 - 01:08:54]
right let's take another

[01:08:52 - 01:08:58]
example where we

[01:08:54 - 01:08:59]
say charity to translate it's a lot of

[01:08:58 - 01:09:02]
William Shakespeare William Shakespeare

[01:08:59 - 01:09:05]
right let's take a simple more simpler

[01:09:02 - 01:09:07]
example where I say translate this

[01:09:05 - 01:09:10]
English sentence to Spanish I am a

[01:09:07 - 01:09:12]
Spanish reader I this is the English

[01:09:10 - 01:09:16]
sentence I want to translate into

[01:09:12 - 01:09:19]
Spanish I say this and it says it gives

[01:09:16 - 01:09:23]
the translation for this now if I want

[01:09:19 - 01:09:27]
to make this few short I'll add examples

[01:09:23 - 01:09:30]
I'll add um more examples for the same

[01:09:27 - 01:09:33]
I'll add uh say that okay this is my

[01:09:30 - 01:09:35]
article I can give an article also and

[01:09:33 - 01:09:37]
say please translate this these are my

[01:09:35 - 01:09:40]
examples now take this article and

[01:09:37 - 01:09:43]
Translate in Spanish for me I can do

[01:09:40 - 01:09:46]
that as well so that becomes few short

[01:09:43 - 01:09:49]
for the same in Char 4 there is an

[01:09:46 - 01:09:50]
option that we want to highlight is that

[01:09:49 - 01:09:53]
you

[01:09:50 - 01:09:55]
can click on this attachment add any

[01:09:53 - 01:10:00]
attachment it can be data set it can be

[01:09:55 - 01:10:03]
images and train your chat GPT that okay

[01:10:00 - 01:10:05]
for example you want to train these are

[01:10:03 - 01:10:08]
the picture of roses where you provide

[01:10:05 - 01:10:12]
different pictures of roses and in input

[01:10:08 - 01:10:16]
as an input data you give Lily and you

[01:10:12 - 01:10:19]
ask what is it is it a rose and it tells

[01:10:16 - 01:10:22]
you based on what images you have input

[01:10:19 - 01:10:24]
is it a rose or not just a random

[01:10:22 - 01:10:28]
example the same can be used for data

[01:10:24 - 01:10:31]
science or data analysis different

[01:10:28 - 01:10:35]
activities visualizations as well where

[01:10:31 - 01:10:38]
you can give the data and ask chat GPT

[01:10:35 - 01:10:41]
to analyze visualize the data and give

[01:10:38 - 01:10:47]
you outputs for the

[01:10:41 - 01:10:49]
same now let's see Chain of Thought

[01:10:47 - 01:10:54]
Chain of Thought is said to be logical

[01:10:49 - 01:10:56]
it works on logical bits right here in

[01:10:54 - 01:10:59]
this

[01:10:56 - 01:11:02]
prompt example we have designed few

[01:10:59 - 01:11:05]
question and answer that is on blood

[01:11:02 - 01:11:08]
relation where the first question is if

[01:11:05 - 01:11:11]
Michael says Patrick's mother is the

[01:11:08 - 01:11:14]
only daughter of my mother how is

[01:11:11 - 01:11:17]
Michael related to Patrick we are giving

[01:11:14 - 01:11:19]
the answer is Michael is saying that

[01:11:17 - 01:11:22]
Patrick's mother is Michael's own

[01:11:19 - 01:11:25]
Mother's only daughter this means

[01:11:22 - 01:11:29]
Patrick's mother is Michael's sister

[01:11:25 - 01:11:32]
making Michael Patrick's Uncle okay

[01:11:29 - 01:11:35]
second example we are giving Emma is

[01:11:32 - 01:11:38]
John's sister Mark is John's father

[01:11:35 - 01:11:40]
Linda is Mark's sister and Thomas is

[01:11:38 - 01:11:42]
Linda's son what is the relation between

[01:11:40 - 01:11:45]
Emma and

[01:11:42 - 01:11:48]
Thomas Emma is John's son making her

[01:11:45 - 01:11:52]
Mark's daughter Linda being Mark's

[01:11:48 - 01:11:56]
sister is Emma's aunt which makes Thomas

[01:11:52 - 01:11:59]
who is Linda's son Emma's cousin

[01:11:56 - 01:12:04]
right now our input question

[01:11:59 - 01:12:08]
is Alex introduces Brad to his friend as

[01:12:04 - 01:12:12]
the son of the only brother of his

[01:12:08 - 01:12:15]
mother how is Brad related to Alex

[01:12:12 - 01:12:15]
output

[01:12:17 - 01:12:24]
is Brad is the son of the only brother

[01:12:21 - 01:12:26]
of Alex's mother which means Brad is

[01:12:24 - 01:12:30]
Alex

[01:12:26 - 01:12:32]
cousin right logically it correlates the

[01:12:30 - 01:12:33]
Chain of Thought correlates based upon

[01:12:32 - 01:12:36]
your

[01:12:33 - 01:12:38]
examples Chain of Thought can be of

[01:12:36 - 01:12:41]
different types as well where you can

[01:12:38 - 01:12:44]
give different examples uh complex

[01:12:41 - 01:12:46]
examples as well and it works it is zero

[01:12:44 - 01:12:49]
short also it is few short also so

[01:12:46 - 01:12:53]
basically this comes under few short

[01:12:49 - 01:12:56]
Chain of Thought prompt okay zero short

[01:12:53 - 01:12:59]
is separate where you give

[01:12:56 - 01:13:03]
directly what you want without more

[01:12:59 - 01:13:05]
explanation in your prompt designs right

[01:13:03 - 01:13:08]
and then there is automatic Chain of

[01:13:05 - 01:13:12]
Thought as well so there are various

[01:13:08 - 01:13:16]
Chain of Thought prompts as well you can

[01:13:12 - 01:13:17]
explore more and deep dive there as well

[01:13:16 - 01:13:20]
apart from Chain of Thought we have

[01:13:17 - 01:13:21]
different prompting strategies as

[01:13:20 - 01:13:25]
highlighted earlier we have

[01:13:21 - 01:13:26]
self-consistency we have prompt chaining

[01:13:25 - 01:13:31]
we have

[01:13:26 - 01:13:34]
respond rephrase We have tree of thought

[01:13:31 - 01:13:39]
we have many Advanced prompt strategies

[01:13:34 - 01:13:43]
which you can deep dive and apply based

[01:13:39 - 01:13:46]
on your requirement your prompt design

[01:13:43 - 01:13:48]
what you want to do with your generative

[01:13:46 - 01:13:52]
models with chart

[01:13:48 - 01:13:55]
GPT hope you have understood these three

[01:13:52 - 01:13:58]
different Advanced prompt strategies

[01:13:55 - 01:14:01]
zero shot with where you do not provide

[01:13:58 - 01:14:04]
any examples few shot where you provide

[01:14:01 - 01:14:06]
where you teach AI with few examples and

[01:14:04 - 01:14:10]
Chain of Thought where it has three

[01:14:06 - 01:14:14]
versions and is for logical thinking is

[01:14:10 - 01:14:17]
used for logical thinking and logical

[01:14:14 - 01:14:20]
problems then we understood what are the

[01:14:17 - 01:14:24]
components of a good prompt what are the

[01:14:20 - 01:14:26]
different checklist that you can follow

[01:14:24 - 01:14:29]
to create a good prompt to design a good

[01:14:26 - 01:14:31]
prompt then we saw what are the

[01:14:29 - 01:14:34]
different Persona patterns that you can

[01:14:31 - 01:14:36]
think of while designing your prompt

[01:14:34 - 01:14:39]
following the

[01:14:36 - 01:14:42]
checklist then we understood different

[01:14:39 - 01:14:44]
Advanced strategies prompt strategies

[01:14:42 - 01:14:48]
which is zero uh short prompting few

[01:14:44 - 01:14:51]
short prompting Chain of Thought with

[01:14:48 - 01:14:55]
examples we saw what are the common

[01:14:51 - 01:14:57]
prompting errors that can happen

[01:14:55 - 01:15:00]
if you miss

[01:14:57 - 01:15:02]
something and at last we saw

[01:15:00 - 01:15:04]
applications of prompt engineering what

[01:15:02 - 01:15:05]
are the different fields in which prompt

[01:15:04 - 01:15:11]
engineering can be

[01:15:05 - 01:15:13]
used so the key to becoming a proficient

[01:15:11 - 01:15:16]
prompt engineer is to practice

[01:15:13 - 01:15:19]
experiment with different

[01:15:16 - 01:15:21]
prompts again and again give feedback to

[01:15:19 - 01:15:25]
your generative models be it chat GPT be

[01:15:21 - 01:15:27]
it Gemini be it any generative model

[01:15:25 - 01:15:29]
analyze your outcomes what the outcome

[01:15:27 - 01:15:32]
what response you are receiving and

[01:15:29 - 01:15:35]
telling giving them the feedback refine

[01:15:32 - 01:15:36]
your techniques refine your prompts

[01:15:35 - 01:15:39]
based on the checklist that is provided

[01:15:36 - 01:15:40]
based on the different strategies apply

[01:15:39 - 01:15:42]
read about different strategies and

[01:15:40 - 01:15:46]
apply them that is refining your

[01:15:42 - 01:15:50]
techniques keep practicing stay curious

[01:15:46 - 01:15:53]
explore various AI platforms to enhance

[01:15:50 - 01:15:56]
your skills this is how you can become a

[01:15:53 - 01:16:01]
proficient prompt engineer I hope you

[01:15:56 - 01:16:01]
enjoyed this course thank you

## „Ç≥„É°„É≥„Éà

### 1. @greatlearning (üëç 40)
Thanks for watching! If you enjoyed the video, explore our "Prompt Engineering for ChatGPT" course and earn a certificate upon completion. Check it out here! https://www.mygreatlearning.com/academy/learn-for-free/courses/prompt-engineering-for-chatgpt?utm_source=CPV_YT&utm_medium=Comment&utm_campaign=PromptEngineeringFullcourse_2024

> **@Krishna-mt8xs** (üëç 2): Mam can I get certificate of completion of this course for free as you've written but on the site, mentioned that I've to pay for the certificate, mam please reply certificate is one of the biggest motivation I've almost completed (1hr) this course please reply it's an humble request, btw take its as feedback I love your teaching style with simplicity, from today I became your huge fan and awaken subscriber

> **@nishadbapte2785** (üëç 1): The site is asking to pay.. But you have mentioned it's free, pls help to get the certificate.

### 2. @amilost22-v2f (üëç 209)
You did this for free instead of selling a course on how to do it. Salute and huge respect.

> **@greatlearning** (üëç 30): We're thrilled to hear that you enjoyed the video and found it detailed and well-delivered. Your feedback means a lot to us. Stay tuned for more informative content!

### 3. @dhakshusivaa (üëç 12)
the teaching is simple, clarity, understandable, correct speed, and more interesting.

### 4. @suryakhatri572 (üëç 7)
I just finished this and I‚Äôm blown away! ü§Ø You made prompt engineering feel both approachable and powerful. Your clear and precise definitions, smart examples, and that ‚Äúsecret sauce‚Äù for a great prompt really resonated with me. Beyond the content, your energy and teaching style are top-notch‚Äîso much fun to learn from! Thank you for sharing your expertise.‚ù§üá≥üáµ

### 5. @coolzets (üëç 48)
Who knew something called Prompt Engineering would ever exist. World is changing really rapidly. This channel has consistently enlightened me on the latest trends with in-depth insights.

> **@greatlearning** (üëç 3): Glad, you think so. For further enlightenment you can check out Great Learning Academy - https://www.mygreatlearning.com/academy?utm_source=CPV_YT&utm_medium=Comment_reply&utm_campaign=YTVids2024

### 6. @murthybcm9790 (üëç 21)
The section on defining a good prompt was eye-opening. I used to struggle with that, but now I have a clearer idea.

> **@greatlearning** (üëç 2): We're thrilled to hear that you enjoyed the video and found it detailed and well-delivered. Your feedback means a lot to us. Stay tuned for more informative content!

### 7. @vasudasari7677 (üëç 8)
Maa'm your style of explaining is simple and easy to understand and you are great because it's free for us. We are thankful to you

### 8. @ramakullaipapannagari2633 (üëç 0)
This is my first video to learn "Prompt Engineering". This is clear and understanding. Thank you.

### 9. @SandeepKumarIaspaper (üëç 6)
You did this for free instead of selling a course on how to do it. Salute and huge respect.

### 10. @kr.prince_00 (üëç 5)
Thank you ma'am for providing this  awesome prompt engineering course as free, i'm try to finding prompt engineering course for some times and now here  my search complete.

### 11. @zaidrajput5670 (üëç 1)
Thankyou for the course Ma'am. It was great learning from you. I recall my school days hearing your out. Would like to learn more advance prompt engineering techniques from you in the future.

### 12. @visheshmp (üëç 8)
She is processing what to speak and speaking at the same time.. and seriously getting stuck in between for few seconds like chatGPT. Nice video btw

### 13. @harishbhau6977 (üëç 4)
never stop making videos like this thank you

### 14. @DG_thescorpian (üëç 0)
Amazing ways of explanation, first time I am liking any online course related to prompt engineering. it detailed and concise both with simple way of explaining.

### 15. @raomuneeb8943 (üëç 1)
"Thank you for sharing this insightful vlog on prompt engineering! It was incredibly informative and has given me a deeper understanding of the topic. Looking forward to more content like this!"

### 16. @AmitKumar-dc7hg (üëç 2)
Its really great course and explanation given by teacher is 100/100.

### 17. @ogabophilomina138 (üëç 1)
I honestly enjoyed every bit of this video. Thank you so much.

### 18. @Justlikethat-sj4xz (üëç 4)
This video couldn't come at a better time! I'm eager to understand how prompt engineering can enhance productivity and efficiency. Thank you for providing valuable content‚ÄîI'm all in!

> **@greatlearning** (üëç 1): We're thrilled to hear that you enjoyed the video and found it detailed and well-delivered. Your feedback means a lot to us. Also check out Great Learning Academy for more such videos - https://www.mygreatlearning.com/academy?utm_source=CPV_YT&utm_medium=Comment_reply&utm_campaign=YTVids2024

> **@anoopjose.b9161** (üëç 0): üòäüòäüòäüòäüòäüòäüòäüòäüòäüòäüòäüòäüòäüòä0üòäüòä

### 19. @untextbook (üëç 0)
I like the way you explained..it's not really scripted.. original and you worked hard to prep up.

### 20. @mahuabiswas5514 (üëç 129)
Sorry to say, we are terrible in prompts. This is the reason we chose BeLikeNative. This is a simple no-prompt AI writing assistant. Presently, we are delivering fiction content in 11 different languages. It‚Äôs a unique no-prompt tool for paraphrasing and translating content with native level accuracy.

> **@Joker-df4gq** (üëç 5): Bot

> **@nocturnalardency** (üëç 4): Nice Try Diddy

> **@txlavagamer** (üëç 0): nise to bibi

