# Create Cinematic Ai Videos with Google VEO 3 (FULL COURSE)

**„ÉÅ„É£„É≥„Éç„É´:** Tao Prompts
**ÂÖ¨ÈñãÊó•:** 2025-05-30
**URL:** https://www.youtube.com/watch?v=1lktT4dVAT4

## Ë™¨Êòé

Here's a deep dive guide on how to use Google's new VEO 3 model to create cinematic ai videos. You can now create lifelike AI characters that talk with just a single text prompt. The animation quality is incredible and it even generates sound effects all at the same time!
 
üî•Try Google Veo 3: https://labs.google/fx/tools/flow

Other Tools I showed üëá
Elevenlabs (Ai Voice)
PixVerse (Ai Lip Sync)

1-on-1 Consultation with me:
https://calendly.com/taoprompts/consultation
FREE PDF Prompt Guides, Tutorials, etc:
https://taoprompts.gumroad.com/
My Instagram:
https://www.instagram.com/taoprompts/

Chapters:
00:00 Guide for Cinematic Ai Videos in Google VEO 3
00:46 Access & Getting Started
01:15 Make Lifelike Talking Characters
05:00 Consistent Characters
09:05 Control Camera Movement
14:36 Image-to-Video 
18:57 Make the Best Videos: Text-to-Video vs Image-to-Video
25:46 Ingredients: Combing Multiple Characters
27:29 Extend Videos with Scene Builder
29:40 Can We Make a Full Ai Movie?

## Â≠óÂπï

[00:00 - 00:06]
Google Veil 3 has completely changed the

[00:03 - 00:09]
AI filmmaking game with its ability to

[00:06 - 00:10]
create cinematic AI videos along with

[00:09 - 00:13]
realistic sound effects and character

[00:10 - 00:16]
voices all inside one platform. This

[00:13 - 00:18]
will be the last time you fail me. I

[00:16 - 00:21]
know it's frustrating to watch tutorials

[00:18 - 00:23]
which show clips of highquality videos

[00:21 - 00:26]
but when you go and try to create the AI

[00:23 - 00:27]
videos yourself, you get lower quality

[00:26 - 00:29]
clips like this one that look like

[00:27 - 00:31]
PowerPoint slides. That's why I made

[00:29 - 00:34]
this video specifically for people like

[00:31 - 00:36]
you who want the real advice. Not just a

[00:34 - 00:39]
surface level explanation, but a deep

[00:36 - 00:41]
dive into practical tips that will

[00:39 - 00:46]
actually help you with your AI films.

[00:41 - 00:46]
May the force be with you.

[00:46 - 00:51]
Google Veil 3 is accessed through Flow

[00:49 - 00:53]
which is Google's new film making

[00:51 - 00:56]
platform. So, let's go ahead and launch

[00:53 - 00:58]
it. Once we're inside, we can see a list

[00:56 - 01:01]
of our past projects. I'll go ahead and

[00:58 - 01:03]
create a new project right now. From

[01:01 - 01:05]
here, we can start creating our AI

[01:03 - 01:07]
videos. There's a couple different

[01:05 - 01:09]
options. Text to video, frames to video

[01:07 - 01:10]
ingredients to video. We're going to

[01:09 - 01:13]
cover all of them, but let's start with

[01:10 - 01:16]
text to video where we'll just enter a

[01:13 - 01:18]
prompt and it'll create a video for us.

[01:16 - 01:20]
What's new in Google Veil 3 is the

[01:18 - 01:23]
ability to directly generate talking

[01:20 - 01:26]
characters. So, I'll create a video of a

[01:23 - 01:28]
Jedi from a Star Wars movie. I'm going

[01:26 - 01:30]
to describe the appearance a little bit.

[01:28 - 01:33]
She has green skin, these geometric

[01:30 - 01:36]
tattoos across her face. Um, also give

[01:33 - 01:39]
her a yellow lightsaber, and we're going

[01:36 - 01:42]
to tell her to talk about how to use the

[01:39 - 01:44]
force inside this AI video. Let's go

[01:42 - 01:46]
ahead and generate

[01:44 - 01:48]
that. When you're generating the video

[01:46 - 01:51]
you need to make sure you've actually

[01:48 - 01:54]
selected the newest Google Vo3 model. If

[01:51 - 01:56]
we go to the settings tab right here

[01:54 - 01:58]
you can change the number of outputs per

[01:56 - 02:00]
prompt. I've set that to one to generate

[01:58 - 02:02]
one video at a time. But down here in

[02:00 - 02:05]
the quality, make sure you've selected

[02:02 - 02:07]
the highest quality with experimental

[02:05 - 02:10]
audio. That's the newest Veil 3 model.

[02:07 - 02:12]
The fast and quality options default to

[02:10 - 02:14]
the older Veil True model, so you won't

[02:12 - 02:16]
get the best looking videos if you use

[02:14 - 02:18]
these. Here's what the video turned out

[02:16 - 02:20]
to look like. The Force is a subtle

[02:18 - 02:23]
energy. You have to feel it, not just

[02:20 - 02:25]
see it. What's impressive about this is

[02:23 - 02:28]
that it animates a talking speaking

[02:25 - 02:31]
character just from a text prop. And the

[02:28 - 02:33]
quality of the lip sync and the emotions

[02:31 - 02:36]
in the video are very high. We can also

[02:33 - 02:38]
make the AI say specific words from a

[02:36 - 02:40]
script if we want. I'm using the same

[02:38 - 02:42]
prompt of a female Jedi from Star Wars

[02:40 - 02:44]
with green skin. I've described her

[02:42 - 02:46]
appearance a little bit closer. So this

[02:44 - 02:48]
time I also told her the specific

[02:46 - 02:50]
clothing to wear, which is a lightweight

[02:48 - 02:54]
brown and gold robe. And she's also

[02:50 - 02:56]
meditating inside a quiet swamp

[02:54 - 02:58]
illuminated by bol luminescent plants on

[02:56 - 03:00]
an alien world. This time I'm

[02:58 - 03:03]
specifically prompting for her to say

[03:00 - 03:05]
"The force doesn't scream, it hums.

[03:03 - 03:09]
Listen and you'll know which path is

[03:05 - 03:12]
open." The force doesn't scream, it

[03:09 - 03:14]
hums. Listen and you'll know which path

[03:12 - 03:16]
is open. Look at the way the hand

[03:14 - 03:18]
motions are joined together with the

[03:16 - 03:21]
speech and the facial expressions and

[03:18 - 03:23]
the wrinkles on the face all go together

[03:21 - 03:25]
very very well. Now I want to go a

[03:23 - 03:27]
little more in depth on this. How much

[03:25 - 03:29]
control do we have over the voices? Can

[03:27 - 03:32]
we actually change the way the

[03:29 - 03:35]
character's voice sound? So I rewrote

[03:32 - 03:39]
this prompt. This time I told her to

[03:35 - 03:41]
have a highpitched and nasal voice which

[03:39 - 03:44]
should sound like she kind of has a

[03:41 - 03:45]
stuffy nose a little bit. So then if we

[03:44 - 03:47]
generate the

[03:45 - 03:52]
video, here's what that character sounds

[03:47 - 03:55]
like. The force doesn't scream, it

[03:52 - 03:58]
hums. Listen and you'll know which path

[03:55 - 04:00]
is open. It's a great looking video, but

[03:58 - 04:02]
it didn't actually follow my prompt of

[04:00 - 04:05]
giving it a high-pitched and nasal tone

[04:02 - 04:08]
to her voice. The way Google Video3

[04:05 - 04:10]
generates the voices is dependent on the

[04:08 - 04:12]
way that the characters look. I

[04:10 - 04:15]
generated a video of a Sith. He's an

[04:12 - 04:16]
older weathered man. And if we listen to

[04:15 - 04:20]
his voice, it's going to have a deeper

[04:16 - 04:22]
grittier tone to it. Pain is not

[04:20 - 04:24]
punishment. It is

[04:22 - 04:28]
revelation. Feel it and you will

[04:24 - 04:30]
understand me. Depending on the video of

[04:28 - 04:33]
the character that you're generating

[04:30 - 04:36]
Veil 3 will match the voice to the way

[04:33 - 04:36]
that character looks.

[04:36 - 04:44]
Target acquired. Regret will be brief.

[04:42 - 04:46]
But unfortunately, there isn't a way to

[04:44 - 04:48]
actually change the way the character

[04:46 - 04:50]
sounds inside the prompt. This might not

[04:48 - 04:52]
seem like a huge problem, but sometimes

[04:50 - 04:56]
it does generate voices that don't match

[04:52 - 05:00]
the way the characters look at all.

[04:56 - 05:02]
Luke, I am your father. But sticking

[05:00 - 05:04]
with the theme of characters, can we

[05:02 - 05:06]
actually generate videos of the same

[05:04 - 05:09]
character inside different scenes? The

[05:06 - 05:11]
answer is yeah, you can get pretty darn

[05:09 - 05:13]
close as long as the description of the

[05:11 - 05:15]
character's appearance matches closely.

[05:13 - 05:18]
I've written down the way her skin

[05:15 - 05:20]
looks, the patterns on her face, also

[05:18 - 05:22]
the clothing that she's wearing. When we

[05:20 - 05:24]
go and generate a new video of this

[05:22 - 05:26]
character using text to video, it'll

[05:24 - 05:28]
actually give someone that looks really

[05:26 - 05:32]
really close.

[05:28 - 05:35]
Control is not the absence of fear. It's

[05:32 - 05:36]
the choice not to let fear decide. We

[05:35 - 05:39]
can render them inside different scenes

[05:36 - 05:42]
as well. We've spent so long guarding

[05:39 - 05:45]
peace that we forgot how heavy peace can

[05:42 - 05:46]
be. The more specific we are in the

[05:45 - 05:48]
prompt in describing the way the

[05:46 - 05:50]
character looks, the more consistent

[05:48 - 05:52]
they'll look in the videos that we

[05:50 - 05:54]
generate. For this prompt of the Sith

[05:52 - 05:57]
I'm extremely specific in the way that

[05:54 - 05:59]
he looks. He's tall. He's lean. He has

[05:57 - 06:02]
pale white ashy skin and dark veins on

[05:59 - 06:04]
his gaunt face. I also specify the

[06:02 - 06:07]
hairstyle. He has gray hair tied in a

[06:04 - 06:08]
bun, and he wears a raggedy black cloak

[06:07 - 06:11]
with sharp edge plating on the

[06:08 - 06:13]
shoulders. Here's a bunch of videos I

[06:11 - 06:15]
generated of this specific Sith Lord.

[06:13 - 06:17]
The main thing you'll notice that is

[06:15 - 06:19]
kind of different is the shoulder pads

[06:17 - 06:20]
he's wearing. For some of them, they

[06:19 - 06:22]
look like plates. For other ones

[06:20 - 06:24]
there's some sharp needles pointing out

[06:22 - 06:26]
but we could have just removed that part

[06:24 - 06:28]
of the prop that talks about the plating

[06:26 - 06:31]
on his shoulders. At this point, I'm

[06:28 - 06:33]
sure you've noticed that Veil 3 also

[06:31 - 06:35]
generates sound effects that go along

[06:33 - 06:37]
with the characters, the lightsabers

[06:35 - 06:39]
the steps that he's taken as he's

[06:37 - 06:41]
walking. Although, from what I can tell

[06:39 - 06:43]
you don't actually have that much

[06:41 - 06:46]
control over what specific sound effects

[06:43 - 06:48]
are generated. The amount of voice

[06:46 - 06:51]
control you have is limited to a certain

[06:48 - 06:53]
extent. For example, in this prompt of

[06:51 - 06:56]
the Sith, I specifically said that he

[06:53 - 06:57]
reaches out with his hand and yells no.

[06:56 - 07:00]
I want him to be kind of screeching out

[06:57 - 07:04]
and screaming with a very exaggerated

[07:00 - 07:04]
facial expression. No. Oh

[07:09 - 07:14]
okay. So, we do hear him screaming a bit

[07:12 - 07:18]
at the end, but the part where he says

[07:14 - 07:21]
no happens at the beginning

[07:18 - 07:24]
and we don't even see his mouth moving

[07:21 - 07:26]
along with that word. So, for super

[07:24 - 07:28]
super expressive voice control, it

[07:26 - 07:31]
doesn't seem like it's quite there just

[07:28 - 07:33]
yet, but the video animations do look

[07:31 - 07:36]
incredible. If you want to adding the

[07:33 - 07:37]
sounds later in by yourself, these are

[07:36 - 07:40]
8second videos, by the way. There's a

[07:37 - 07:42]
few different options to download, you

[07:40 - 07:44]
can get a GIF, the original size, or

[07:42 - 07:46]
upscale it to high definition. I found

[07:44 - 07:48]
that the upscaler did seem to get stuck

[07:46 - 07:50]
a bunch of times, so maybe it's not

[07:48 - 07:53]
working correctly right now. We can also

[07:50 - 07:54]
add in multiple characters into the same

[07:53 - 07:57]
scene and have them interact with each

[07:54 - 08:00]
other. In this prompt, I copied in the

[07:57 - 08:02]
full description of the female Jedi and

[08:00 - 08:05]
I also copied in the full description of

[08:02 - 08:08]
the Sith. And I have them talking to

[08:05 - 08:10]
each other. So, the male Sith says

[08:08 - 08:12]
"Tell me Jedi, how many died while you

[08:10 - 08:13]
meditated?" And the female Jedi says

[08:12 - 08:14]
"And how many screamed while you

[08:13 - 08:17]
searched for meaning in their

[08:14 - 08:20]
suffering?" You can't specifically tell

[08:17 - 08:22]
each character the script that they're

[08:20 - 08:25]
going to be saying inside the video.

[08:22 - 08:27]
Tell me, Jedi, how many died while you

[08:25 - 08:28]
meditated and how many screamed while

[08:27 - 08:31]
you searched for meaning in their

[08:28 - 08:33]
suffering? And using this same

[08:31 - 08:35]
technique, we can create the two of them

[08:33 - 08:39]
interacting together, for example, in a

[08:35 - 08:39]
lightsaber battle.

[08:44 - 08:50]
So, this battle isn't exactly as dynamic

[08:47 - 08:52]
as a real movie. This video clip does

[08:50 - 08:54]
start off a little slow. There's not

[08:52 - 08:56]
that much motion at the start, but as we

[08:54 - 08:58]
get later on into the video and they

[08:56 - 08:59]
start swinging their lightsabers. It's a

[08:58 - 09:01]
pretty epic looking battle. I mean

[08:59 - 09:04]
there's sparks flying everywhere. The

[09:01 - 09:06]
sound effects also sound realistic to

[09:04 - 09:08]
me. So, what about when it comes to

[09:06 - 09:11]
directing the camera inside the AI

[09:08 - 09:13]
videos? You do have quite a bit of

[09:11 - 09:16]
control over how the camera motion

[09:13 - 09:18]
moves. To start off, let's go with a

[09:16 - 09:20]
shot of a Sith temple. We're going to

[09:18 - 09:22]
prompt for a slow crane shot behind a

[09:20 - 09:25]
cloaked figure walking up the steps to

[09:22 - 09:27]
an ancient Sith temple in Star Wars. The

[09:25 - 09:30]
cameras flies above and slowly tilts

[09:27 - 09:34]
down to reveal the Sith temple. Red

[09:30 - 09:34]
lightning inside a thunderstorm.

[09:41 - 09:45]
So, what happened here? That wasn't

[09:43 - 09:48]
exactly the video that I prompted for.

[09:45 - 09:50]
The Sith is actually walking down the

[09:48 - 09:53]
steps instead of walking up the step

[09:50 - 09:55]
like I asked for inside the prompt. Just

[09:53 - 09:58]
like any other AI image generator or AI

[09:55 - 10:00]
video, there is some randomness in VO3

[09:58 - 10:02]
which means every time you run the same

[10:00 - 10:04]
prompt, you won't get the same results.

[10:02 - 10:06]
So, sometimes it's a good idea to run

[10:04 - 10:08]
the prompt multiple times. Here's

[10:06 - 10:11]
another video generated of me running

[10:08 - 10:13]
the exact same prompt again. And this

[10:11 - 10:15]
time, we'll see him walking up the steps

[10:13 - 10:15]
like I asked

[10:17 - 10:22]
for. There's some pretty cool camera

[10:19 - 10:24]
movement effects you can create. Here's

[10:22 - 10:26]
an example where I asked for the video

[10:24 - 10:29]
to start with a close-up shot on a

[10:26 - 10:30]
gloved finger hovering over a blaster.

[10:29 - 10:33]
And then the camera is going to tilt up

[10:30 - 10:37]
and reveal a bounty hunter with a helmet

[10:33 - 10:37]
on. This was one of my favorite video

[10:40 - 10:44]
generations. I can't get over how good

[10:42 - 10:46]
this looks. In the prompt, I

[10:44 - 10:48]
specifically told the camera to quickly

[10:46 - 10:50]
tilt up, and you see the movement

[10:48 - 10:52]
flashing from the blaster to the helmet

[10:50 - 10:55]
of the Dante Hunter. Here's more of an

[10:52 - 10:58]
advanced tip. When you prompt for

[10:55 - 11:00]
specific subjects in the video, a lot of

[10:58 - 11:02]
the times that can override the camera

[11:00 - 11:04]
movement and the camera angle that you

[11:02 - 11:09]
ask for. For example, I want to generate

[11:04 - 11:11]
an over theshoulder shot of a rebel

[11:09 - 11:13]
flying inside a spaceship. I want it to

[11:11 - 11:16]
be looking outside the cockpit window

[11:13 - 11:18]
where we can see other fighter jets

[11:16 - 11:21]
flying by. Here's the overthe-shoulder

[11:18 - 11:23]
view that I'm actually looking for. The

[11:21 - 11:25]
camera is placed behind the pilot. We

[11:23 - 11:26]
can see his shoulder and the back of his

[11:25 - 11:28]
head, but we're looking outside the

[11:26 - 11:30]
window. If I run that prompt inside of

[11:28 - 11:32]
V3, though, you'll see that the video

[11:30 - 11:35]
actually starts with a medium body shot

[11:32 - 11:38]
showing the pilot's face and body before

[11:35 - 11:38]
switching to an over-the-shoulder

[11:42 - 11:47]
shot. That's not what I asked for. The

[11:45 - 11:50]
reason is because we included the words

[11:47 - 11:53]
the rebel pilot inside the prompt. And

[11:50 - 11:57]
so Veil 3 wants to show that subject in

[11:53 - 12:00]
the video. However, if I remove that

[11:57 - 12:03]
phrase, rebel pilot, and just say over

[12:00 - 12:05]
the shoulder shot inside a cockpit of a

[12:03 - 12:08]
spaceship, here's what we get. Because I

[12:05 - 12:10]
didn't add the subject of rebel fighter

[12:08 - 12:12]
inside the video, it prioritizes the

[12:10 - 12:14]
camera angle that I'm asking for and

[12:12 - 12:17]
gives me a perfect overthe-shoulder shot

[12:14 - 12:19]
for the entire video. Here's another

[12:17 - 12:22]
clip I generated where I asked her to

[12:19 - 12:24]
start from the feet of stormtroopers

[12:22 - 12:29]
marching through a town and then pan up

[12:24 - 12:29]
to reveal the body and helmets of those

[12:32 - 12:36]
stormtroopers. What are the limitations

[12:34 - 12:38]
of what it can do as far as camera

[12:36 - 12:41]
motion is concerned? If you try to add

[12:38 - 12:44]
in too much movement, the quality of the

[12:41 - 12:46]
videos will degrade. In a prompt, if I

[12:44 - 12:48]
ask for it to start with a shot of a

[12:46 - 12:50]
Star Wars droid making some beeping

[12:48 - 12:53]
noises and then pan towards the Jedi

[12:50 - 12:54]
character that we described earlier

[12:53 - 12:56]
what's going to happen is that there's

[12:54 - 12:59]
just too much going on inside this

[12:56 - 13:02]
prompt for it to animate it properly.

[12:59 - 13:02]
Let's take a look.

[13:04 - 13:08]
I know, I

[13:05 - 13:11]
know, quit your whining. While the

[13:08 - 13:13]
emotion does look pretty good, the voice

[13:11 - 13:15]
gets mixed up. It doesn't read the words

[13:13 - 13:19]
that I asked her to say properly. I

[13:15 - 13:21]
know. I know. Qui, quit your whining.

[13:19 - 13:24]
Here's another example where I asked for

[13:21 - 13:26]
the Sith to reach out with his palm, say

[13:24 - 13:28]
some words, and then use the force to

[13:26 - 13:31]
send a bounty hunter flying through the

[13:28 - 13:36]
air.

[13:31 - 13:36]
This will be the last time you fail me.

[13:37 - 13:41]
This video doesn't make any sense at

[13:38 - 13:44]
all. It looks like the Sith does some

[13:41 - 13:47]
kind of a 360 flip and then the bounty

[13:44 - 13:49]
hunter appears out of nowhere. So, if

[13:47 - 13:51]
you want to create more dynamic scenes

[13:49 - 13:54]
like this, it's better to animate it in

[13:51 - 13:56]
smaller chunks separately. So, I'll

[13:54 - 13:57]
create a video of the Sith reaching out

[13:56 - 14:00]
with his palm and then a separate one

[13:57 - 14:05]
for the bounty hunter. This will be the

[14:00 - 14:05]
last time you fail me.

[14:06 - 14:09]
Think about the exact textures

[14:07 - 14:11]
patterns, and materials that you want

[14:09 - 14:13]
inside your videos. Here's a video I

[14:11 - 14:17]
generated of our Jedi earlier, and she's

[14:13 - 14:19]
riding on top of a speeder. But the

[14:17 - 14:21]
chrome metallic silver look on the

[14:19 - 14:24]
speeder, it doesn't fit a Star Wars

[14:21 - 14:27]
movie. So instead, in this prompt, I

[14:24 - 14:30]
specifically told the AI video generator

[14:27 - 14:33]
the textures of the speeder that I want

[14:30 - 14:36]
should be rusty, made out of old metal

[14:33 - 14:38]
scraps, and have some plants growing on

[14:36 - 14:40]
the side of it. And we get a scene

[14:38 - 14:43]
that's much more visually aligned

[14:40 - 14:45]
overall. So far we've covered text to

[14:43 - 14:47]
video, but we can also do frames to

[14:45 - 14:49]
video in which case we upload a

[14:47 - 14:51]
reference image first and then Google

[14:49 - 14:53]
will create a video for us based on that

[14:51 - 14:56]
reference image. You might be thinking

[14:53 - 14:59]
if the text to video is so good, why do

[14:56 - 15:02]
we still need image to video? The reason

[14:59 - 15:04]
is because text to video is limited a

[15:02 - 15:06]
lot of the times in its ability to

[15:04 - 15:08]
generate the specific characters or

[15:06 - 15:10]
scenes you want. For example, this is a

[15:08 - 15:13]
character from Star Wars called Jar Jar

[15:10 - 15:15]
Binks. If you're not familiar with him

[15:13 - 15:17]
he's basically an alien that looks like

[15:15 - 15:19]
this guy. Kind of a pretty well-known

[15:17 - 15:23]
character. But if I try to generate him

[15:19 - 15:25]
inside Google V3 using only the text

[15:23 - 15:28]
box, it gives me a character that

[15:25 - 15:30]
doesn't look like Jar Jar Binks at all.

[15:28 - 15:33]
Twist in the minds. You are just too

[15:30 - 15:37]
blind to see. And that's where frames to

[15:33 - 15:40]
video comes in. So let's go to frames to

[15:37 - 15:43]
video and we'll have an option to upload

[15:40 - 15:46]
some images. So we can upload our image

[15:43 - 15:48]
or generate an image directly inside 3.

[15:46 - 15:53]
So let's generate an image and enter a

[15:48 - 15:58]
prompt. Jar Binks from Star Wars

[15:53 - 16:02]
as a Sith. He's wearing a black cloak

[15:58 - 16:04]
and holding a red lightsaber cinematic

[16:02 - 16:07]
film.

[16:04 - 16:09]
Then we can run this prompt and create

[16:07 - 16:11]
the images and it'll generate a

[16:09 - 16:14]
character image that looks much much

[16:11 - 16:17]
closer to Jar Jar. We can go ahead and

[16:14 - 16:20]
use this image to generate a video of

[16:17 - 16:23]
it. And inside the prompt, we can ask

[16:20 - 16:28]
for anything. For example, the camera

[16:23 - 16:30]
zooms zooms in as he waves his

[16:28 - 16:33]
lightsaber.

[16:30 - 16:35]
Let's try and generate that and it'll

[16:33 - 16:37]
create a decent looking video from the

[16:35 - 16:40]
reference image that we uploaded. Now

[16:37 - 16:43]
when it comes to using the image frames

[16:40 - 16:46]
to video feature, I don't recommend it

[16:43 - 16:48]
as much as just trying to use text to

[16:46 - 16:50]
video. So, let me explain. There are

[16:48 - 16:54]
some decent features you can get from

[16:50 - 16:57]
image to video. For example, if we

[16:54 - 17:00]
upload a reference image, let's say

[16:57 - 17:03]
we'll put in this photo of a spaceship.

[17:00 - 17:06]
We do have the option of adding in some

[17:03 - 17:09]
camera movements, but there's a bunch of

[17:06 - 17:12]
options here. You can dialing in on the

[17:09 - 17:13]
character. You can tilt the camera down.

[17:12 - 17:15]
Um, there's a bunch of them. I'm not

[17:13 - 17:18]
sure why they're not all displaying

[17:15 - 17:21]
right now properly, but let's go with

[17:18 - 17:23]
orbiting left around the subject. and

[17:21 - 17:25]
let's put in the prompt the camera

[17:23 - 17:27]
circles around the spaceship. Now, if we

[17:25 - 17:31]
look inside the settings, you can see

[17:27 - 17:34]
that I have selected the Google V3 model

[17:31 - 17:37]
for the video

[17:34 - 17:41]
generation. However, if we try to

[17:37 - 17:43]
actually run this prompt, you'll see

[17:41 - 17:46]
this pop up which says switching you to

[17:43 - 17:48]
a compatible model for this feature.

[17:46 - 17:50]
This is because a lot of the

[17:48 - 17:53]
imagetovideo

[17:50 - 17:55]
features only work with the Ve2 model.

[17:53 - 17:57]
For example, adding in the camera

[17:55 - 18:00]
motions, which means you won't be able

[17:57 - 18:02]
to use the most advanced video model for

[18:00 - 18:04]
this feature. But let's generate it

[18:02 - 18:07]
anyways and see what it looks like. The

[18:04 - 18:10]
camera movements do work pretty well.

[18:07 - 18:12]
The only thing is that, like I said, the

[18:10 - 18:14]
video model isn't going to be the newest

[18:12 - 18:16]
V3 model. Depending on the scene that

[18:14 - 18:18]
you need, I think a lot of these will

[18:16 - 18:20]
work perfectly fine. The camera

[18:18 - 18:21]
movements do look pretty smooth and

[18:20 - 18:24]
follow what you ask

[18:21 - 18:27]
for. But if you want to use camera

[18:24 - 18:28]
motions with the new Veil 3 model

[18:27 - 18:30]
you'll need to directly add them into

[18:28 - 18:33]
the prompt by yourself. Here's a example

[18:30 - 18:35]
where I told the camera to pull back

[18:33 - 18:39]
while the Jedi walks forward and waves

[18:35 - 18:39]
her white lightsaber.

[18:39 - 18:44]
Here's another example where I prompted

[18:41 - 18:46]
for the camera to circle around the

[18:44 - 18:48]
subject. You do have a decent amount of

[18:46 - 18:51]
control over the camera motion in just

[18:48 - 18:54]
the prompt itself. Here's one of the

[18:51 - 18:56]
camera tilting down while this hunter

[18:54 - 18:58]
jumps down from the

[18:56 - 19:01]
ledge. Circling back to what I said

[18:58 - 19:03]
previously, I do think the text to video

[19:01 - 19:06]
works better than using a reference

[19:03 - 19:09]
image inside Veo 2. So, if possible, try

[19:06 - 19:13]
to create the videos using just the text

[19:09 - 19:14]
prompt if you can. So, I've got this

[19:13 - 19:17]
reference image of the bounty hunter

[19:14 - 19:19]
and I told him to jump down from the

[19:17 - 19:22]
ledge onto the ground. It's kind of a

[19:19 - 19:24]
smaller hop, not exactly a dynamic jump

[19:22 - 19:27]
from a tall ledge onto the ground. So

[19:24 - 19:30]
instead, I directly used just a text

[19:27 - 19:32]
prompt where I described the visuals of

[19:30 - 19:34]
the scene. I wanted to start with a

[19:32 - 19:35]
front view of a bounty hunter from Star

[19:34 - 19:38]
Wars. He's wearing a rusty helmet and

[19:35 - 19:40]
rusty armor and the camera tilts down as

[19:38 - 19:42]
he jumps down from a tall ledge into a

[19:40 - 19:44]
rock pit and lands on the ground. It

[19:42 - 19:46]
should be a bright sunlit rocky

[19:44 - 19:48]
environment with brown rocks and some

[19:46 - 19:50]
sand just like the image that I showed

[19:48 - 19:52]
earlier. And let's see what the video

[19:50 - 19:52]
looks

[19:58 - 20:04]
like if we compare it to using a

[20:01 - 20:06]
reference image. The motion is way more

[20:04 - 20:09]
dynamic and I think the sound effects in

[20:06 - 20:09]
general are better.

[20:10 - 20:16]
Also, here's another limitation. If you

[20:13 - 20:19]
use reference images, you can't actually

[20:16 - 20:21]
create the lifelike talking characters.

[20:19 - 20:24]
So, I started with this reference image

[20:21 - 20:27]
of a woman sitting on a jade throne. And

[20:24 - 20:29]
I prompted for her to stand up, pick up

[20:27 - 20:31]
a lightsaber, and say the words, "May

[20:29 - 20:34]
the force be with you." But one problem

[20:31 - 20:35]
with using uh image reference is that

[20:34 - 20:37]
when you try to animate a talking

[20:35 - 20:39]
character, it can make the character

[20:37 - 20:42]
move their mouth around like they're

[20:39 - 20:44]
talking, but they won't actually say the

[20:42 - 20:46]
words you want them to. You do see these

[20:44 - 20:47]
subtitles on the screen. This is

[20:46 - 20:49]
something that they need to fix cuz we

[20:47 - 20:51]
don't need those. However, if you have

[20:49 - 20:53]
an image of a character that you really

[20:51 - 20:56]
really want to use, for example, this

[20:53 - 20:57]
Asian woman sitting on a jade throne, I

[20:56 - 20:59]
mean, I think this looks really, really

[20:57 - 21:02]
amazing. You can generate the video

[20:59 - 21:05]
inside VA3 and use a lip sync tool on

[21:02 - 21:08]
another platform. Uh so I created this

[21:05 - 21:10]
video of the female Jedi using the image

[21:08 - 21:12]
frames to video. She doesn't say

[21:10 - 21:15]
anything inside here, but we're going to

[21:12 - 21:19]
go to an AI voice generator. I'm using

[21:15 - 21:22]
11 Labs here. And we can enter a speech

[21:19 - 21:23]
that we wanted to say. May the force be

[21:22 - 21:26]
with you. There's a bunch of voices you

[21:23 - 21:29]
can pick from here. I'm selecting Jen.

[21:26 - 21:32]
Then we can generate the AI speech. May

[21:29 - 21:35]
the force be with you. We have the voice

[21:32 - 21:38]
and the video from Google Veil. We can

[21:35 - 21:41]
use a tool like Pix for example which

[21:38 - 21:44]
does have AI lip sync. Hit this speech

[21:41 - 21:47]
button right here. And inside here I've

[21:44 - 21:49]
uploaded the video from Google V3 and

[21:47 - 21:53]
also the audio file we just generated

[21:49 - 21:55]
using 11 Labs. And we can create the lip

[21:53 - 21:57]
sync.

[21:55 - 21:58]
This isn't the ideal solution. I'm sure

[21:57 - 22:01]
Google at some point will update their

[21:58 - 22:03]
Veil 3 model to also allow you to create

[22:01 - 22:06]
talking characters using reference

[22:03 - 22:07]
images, but for now, this is kind of

[22:06 - 22:10]
what you got to do. And this is what our

[22:07 - 22:13]
lipsync character looks like. May the

[22:10 - 22:16]
force be with you. Again, let's try to

[22:13 - 22:19]
replicate this scene using just text to

[22:16 - 22:21]
video. Here's the prompt I'll use. An

[22:19 - 22:24]
Asian female Jedi from Star Wars. She

[22:21 - 22:25]
has two small ram horns on her head and

[22:24 - 22:28]
is wearing a white sleeveless dress with

[22:25 - 22:30]
gold ornaments. She sits on a circular

[22:28 - 22:32]
jade throne in Saturn Asian Palace. She

[22:30 - 22:34]
stands up, pulls out a green lightsaber.

[22:32 - 22:36]
She says, "May the force be with you.

[22:34 - 22:38]
Star Wars cinematic film." I tried to

[22:36 - 22:40]
describe the image I showed earlier as

[22:38 - 22:44]
closely as possible. Let's see what the

[22:40 - 22:44]
video looks like.

[22:46 - 22:52]
May the force be with you.

[22:50 - 22:54]
All right. So, let's be honest here.

[22:52 - 22:56]
That's not a very visually appealing

[22:54 - 22:58]
video. She does stand up and swing the

[22:56 - 23:01]
lightsaber around and say the words I

[22:58 - 23:03]
prompted for exactly, but I don't think

[23:01 - 23:04]
this is a cinematic looking shot. I

[23:03 - 23:08]
mean, the colors, the horns on her head

[23:04 - 23:10]
look kind of weird. And the colors just

[23:08 - 23:12]
look really, really bland. So, when it

[23:10 - 23:14]
comes to writing the text prompts

[23:12 - 23:16]
sometimes it'll generate a really great

[23:14 - 23:18]
looking video with a small amount of

[23:16 - 23:21]
effort, but sometimes you need to

[23:18 - 23:23]
describe the exact cinematic shot that

[23:21 - 23:25]
you want, including the colors and the

[23:23 - 23:28]
environment. So, let's update this

[23:25 - 23:30]
prompt a little bit. This time, I'm

[23:28 - 23:32]
going to describe the visual look of the

[23:30 - 23:34]
shot a bit more. So, again, we're going

[23:32 - 23:35]
with an Asian female Jedi from Star

[23:34 - 23:38]
Wars. She's wearing a white sleeveless

[23:35 - 23:41]
dress with gold ornaments. She sits on a

[23:38 - 23:43]
glowing dark jade throne inside a dark

[23:41 - 23:46]
Asian palace. She stands up and pulls

[23:43 - 23:49]
out a green lightsaber. Muted dark

[23:46 - 23:51]
colors, high contrast between the dark

[23:49 - 23:53]
green jade throne and the darker palace

[23:51 - 23:56]
with intricate Asian designs and dragon

[23:53 - 23:58]
statues behind the Jedi. Now, if we

[23:56 - 23:59]
generate the video, I think we'll get

[23:58 - 24:02]
something that looks a lot more visually

[23:59 - 24:07]
aesthetic and cinematic.

[24:02 - 24:07]
May the force be with you.

[24:10 - 24:15]
If we compare the two video clips I

[24:12 - 24:17]
generated, I mean, the before and after

[24:15 - 24:19]
is enormous. So, you really need to

[24:17 - 24:21]
describe the visual aesthetic you're

[24:19 - 24:23]
going for inside the prompt more closely

[24:21 - 24:26]
to get the best looking

[24:23 - 24:28]
shots. When you're using image frames to

[24:26 - 24:30]
video, it does also limit your

[24:28 - 24:32]
creativity quite a bit. I'm starting

[24:30 - 24:34]
with this image frame of a woman who's

[24:32 - 24:36]
holding a lightsaber. And in the prompt

[24:34 - 24:39]
I'm saying the camera pans left and

[24:36 - 24:42]
tilts up to reveal a giant AT&T vehicle

[24:39 - 24:46]
from Star Wars cinematic film. If we

[24:42 - 24:46]
generate this, here's what

[24:47 - 24:51]
happens. Okay, so you see that? You see

[24:49 - 24:54]
how it suddenly switches from the

[24:51 - 24:57]
initial image frame to this like weird

[24:54 - 24:59]
animation of her and like a black AT&T

[24:57 - 25:02]
in the background. But instead, if we

[24:59 - 25:04]
just use the text prompt by itself and

[25:02 - 25:06]
describe the cinematic shot that we

[25:04 - 25:08]
want, a close-up shot on a female Jedi

[25:06 - 25:10]
from Star Wars with a white lightsaber

[25:08 - 25:13]
on a dusty battlefield. The camera pans

[25:10 - 25:15]
left and tilts up to reveal a giant AT&T

[25:13 - 25:18]
vehicle from Star Wars. Dark orange dust

[25:15 - 25:22]
and color toss. If we generate this

[25:18 - 25:22]
without any reference

[25:24 - 25:30]
image, the AT&T robot doesn't look

[25:28 - 25:33]
exactly like it would inside a Star Wars

[25:30 - 25:35]
movie, but you can see that the amount

[25:33 - 25:36]
of creativity that you have and the

[25:35 - 25:39]
control you have over the cinematic

[25:36 - 25:41]
camera movements is way higher when

[25:39 - 25:44]
using just the text prompt.

[25:41 - 25:47]
There is another feature that I think is

[25:44 - 25:51]
worth mentioning inside VO3 and that is

[25:47 - 25:54]
this ingredients to video feature. Now

[25:51 - 25:57]
what this does is let you combine

[25:54 - 25:59]
multiple characters or ingredients

[25:57 - 26:02]
inside the same scene. So for example

[25:59 - 26:05]
if I go to ingredients to video down

[26:02 - 26:07]
here, I can upload three images inside

[26:05 - 26:09]
the video generator. And so I've got a

[26:07 - 26:12]
couple of different characters. Uh, I

[26:09 - 26:15]
have this this woman with blue skin, got

[26:12 - 26:20]
this guy, uh, a bounty hunter with red

[26:15 - 26:22]
skin, and I'm also going to go with this

[26:20 - 26:25]
landscape image. And in the prompt, we

[26:22 - 26:27]
can go with the woman with blue skin and

[26:25 - 26:30]
the man with red skin walk together on a

[26:27 - 26:32]
rocky landscape. using this image def

[26:30 - 26:36]
feature again. Uh it's not going to let

[26:32 - 26:40]
you use the newest Veil 3 model and

[26:36 - 26:43]
instead it'll force you to use an older

[26:40 - 26:45]
Veo2 model. The quality isn't going to

[26:43 - 26:48]
be as high. Uh it's also not going to

[26:45 - 26:52]
give you the sound effects. This one was

[26:48 - 26:54]
actually particularly bad. So I just ran

[26:52 - 26:56]
this prompt again, except this time at

[26:54 - 26:59]
the end I specifically told it to give

[26:56 - 27:02]
it muted colors. um and also use the

[26:59 - 27:05]
words cinematic film and we get

[27:02 - 27:07]
something that's a bit more reasonable.

[27:05 - 27:09]
So, this is a cool way that you can

[27:07 - 27:11]
create videos with multiple of your own

[27:09 - 27:13]
characters inside of them. Now, the

[27:11 - 27:18]
characters aren't always going to match

[27:13 - 27:20]
your reference images exactly. Um, this

[27:18 - 27:23]
guy with the blue skin doesn't look

[27:20 - 27:25]
quite like the reference image that I

[27:23 - 27:27]
used, but I do think this is worth

[27:25 - 27:30]
mentioning. Now, there are some more

[27:27 - 27:34]
features inside Google Flow. You can use

[27:30 - 27:37]
add to scene inside of a video. And what

[27:34 - 27:40]
this will do is actually let you extend

[27:37 - 27:44]
the video if you want. So, here was a

[27:40 - 27:49]
clip I generated of the woman uh and the

[27:44 - 27:51]
AT&T robot. So, uh we can jump to which

[27:49 - 27:53]
is supposed to generate a different

[27:51 - 27:55]
angle of the scene. It doesn't actually

[27:53 - 27:57]
work that well based on what I've seen.

[27:55 - 28:00]
We can extend the video though. The

[27:57 - 28:04]
camera passed to an army of storm

[28:00 - 28:08]
troopers marching. And again, uh this is

[28:04 - 28:13]
limited to the Veil 2 quality video.

[28:08 - 28:13]
Let's see what the extended clip looks

[28:13 - 28:20]
like. And uh the camera does pan to this

[28:16 - 28:23]
droid army marching behind. So it's

[28:20 - 28:26]
okay. The quality will be a little bit

[28:23 - 28:30]
lower in the extended video um because

[28:26 - 28:32]
it's using a lower quality model, but it

[28:30 - 28:35]
works okay for what it

[28:32 - 28:38]
is. Here's a video clip I generated of

[28:35 - 28:39]
the female Jedi standing up uh wielding

[28:38 - 28:42]
a

[28:39 - 28:45]
lightsaber. And this time, let's try the

[28:42 - 28:48]
jump to feature, which which should give

[28:45 - 28:51]
me a jump cut to a new video clip of the

[28:48 - 28:52]
scene from a different camera angle. So

[28:51 - 28:57]
The

[28:52 - 29:01]
Jedi walks down the hallway

[28:57 - 29:04]
uh with her green lightsaber. And let's

[29:01 - 29:07]
change this to follow. So we see her

[29:04 - 29:09]
from behind. Now let's generate that and

[29:07 - 29:09]
see what

[29:13 - 29:19]
happens. Okay, so this basically just

[29:16 - 29:22]
extended the video. Um, the jump to

[29:19 - 29:25]
feature is kind of hit or miss.

[29:22 - 29:28]
Sometimes it just extends the video. Um

[29:25 - 29:31]
but I did also try it on this clip of

[29:28 - 29:33]
the bounty hunter where we pan from his

[29:31 - 29:35]
blaster to his helmet and then I used

[29:33 - 29:37]
the jump to feature to generate him

[29:35 - 29:40]
walking away from a spaceship. So

[29:37 - 29:42]
sometimes it does work.

[29:40 - 29:44]
So, I got this email from someone asking

[29:42 - 29:47]
me if I could help them create a lawn

[29:44 - 29:50]
1.5 hour AI movie, and they want to

[29:47 - 29:52]
create something epic, like a Braveheart

[29:50 - 29:55]
type of movie. Now, this sounds pretty

[29:52 - 29:57]
cool. So, here's what I responded with.

[29:55 - 29:59]
Oh, wow. For a 1.5 hour film, that's

[29:57 - 30:01]
something you need a team for. I

[29:59 - 30:03]
specialize in creating AI videos, but

[30:01 - 30:06]
you need sound design, maybe voice

[30:03 - 30:08]
actors, cinematographers, video editors.

[30:06 - 30:11]
While AI is very powerful for high

[30:08 - 30:12]
quality work, you still definitely need

[30:11 - 30:15]
people with traditional film making

[30:12 - 30:17]
experience. I actually wrote a longer

[30:15 - 30:18]
email with more details trying to

[30:17 - 30:21]
explain that you don't want to

[30:18 - 30:23]
overestimate what AI can do. And you're

[30:21 - 30:26]
going to love this. Here's the oneliner

[30:23 - 30:29]
response I got. Hi, Veil 3 has all that.

[30:26 - 30:31]
Thank you. So, I was a little irritated

[30:29 - 30:33]
when I first read this because I don't

[30:31 - 30:35]
think this person has experience, you

[30:33 - 30:37]
know, working with AI and film. But, it

[30:35 - 30:39]
got me thinking and I want to know what

[30:37 - 30:41]
you think. Do you agree or do you

[30:39 - 30:44]
disagree with me? Do you think that we

[30:41 - 30:47]
could create a full Star Wars type of

[30:44 - 30:49]
movie using the capabilities that VO3

[30:47 - 30:51]
has? Let me know. I'm really curious to

[30:49 - 30:54]
know what you think. As far as the cost

[30:51 - 30:55]
goes, it is expensive. It's like 125 a

[30:54 - 30:58]
month and then after 3 months that's

[30:55 - 31:00]
going to go up to 250. Now, whether the

[30:58 - 31:02]
cost is worth it, that's up to you. What

[31:00 - 31:04]
do I think? I think nice things cost

[31:02 - 31:06]
money and you pay for the quality that

[31:04 - 31:08]
you get. Now, there's tons of other

[31:06 - 31:10]
awesome AI video generators out there

[31:08 - 31:12]
with awesome features like lip sync

[31:10 - 31:15]
making longer video clips, things like

[31:12 - 31:17]
that. I did a complete breakdown between

[31:15 - 31:20]
the other best AI video generators that

[31:17 - 31:21]
I've seen and created a same animation

[31:20 - 31:23]
using each of them to see which one is

[31:21 - 31:28]
the best. If you want to see that video

[31:23 - 31:28]
go watch this tutorial right here.

## „Ç≥„É°„É≥„Éà

### 1. @elijahkurdi4277 (üëç 147)
A tip for getting consistant characters is by explaining to the generator that you want consistency and making a locked detailed description of the character or object. Furthermore you can remind the generator on your next prompt to keep it the same. Ive been pretty successful using this method

> **@NituOrao** (üëç 4): I will try it

> **@truepilgrimm** (üëç 7): WOW. WOW. WOW. Greatly appreciate this nugget of wisdom - something so simple but very very effective. Thanks again buddy. I AM not going to try this, I AM going to DO this.

> **@ErdemleIlahiveKantlMucizeler** (üëç 6): Veo3 cant remember your old prompts; I think. Did you success with this way?

> **@PrasanKariyapperuma** (üëç 1): nope..while it keeps some traits like wardrobe , hair and some type of similarity its not the same character at all. it fails at that only. on the other hand runway, flux bfl and mj omni is the only one right now can help to create some what similar characters to use on frames to video

> **@elijahkurdi4277** (üëç 0): ‚Äã@@PrasanKariyapperumatry getting more detailed with the details

### 2. @fabianoperes2155 (üëç 14)
Man, you simple make the BEST AI videos on the WHOLE youtube.
Thanks for that!

### 3. @markwicklander6837 (üëç 0)
This is the future of entertainment. Content created on the spot based on individual taste. Almost like a dream.

### 4. @sentrycoder (üëç 9)
THIS is ABSOLUTELY Insane and AWESOME. yo, the motion, body movement and subtle realistic human gestures.

> **@taoprompts** (üëç 2): Yeah it's a super powerful video generator, and it's also super fast from my experience

### 5. @TheRealDealAbdullah (üëç 27)
It is just a matter of time when AI will become self contained and have multiple features required for AI Filmmaking. Google Veo 3 is a game changer and just the beginning.

> **@taoprompts** (üëç 6): There's some amazing features already! Runway's character and scene reference feature is a great step

> **@Farrahkhan789** (üëç 0): How to find Google veo 3 there are alots of link on Google kindly give authentic link please‚Äã@@taoprompts

### 6. @Dantehhhhh (üëç 0)
This was extremely useful, thanks.

I'd love for even more tutorial videos focused on Veo 3 (and possibly Runway, it's a good tool too), I truly believe this is gonna change the whole film industry in the world in general, so I want to be as good as possible with it!

### 7. @richtoonsTV (üëç 3)
Great to watch and for you to give us realistic expectations around some of these generative AI platforms. This is a really expensive one, but doesn't seem to be any more "perfect" than other platforms. It's all about how you creatively use them. We appreciate all the tips.

> **@taoprompts** (üëç 0): Thank you! It's got some really great new features, although unfortunately the image-to-video is still lacking.

### 8. @Immix_AI (üëç 0)
Great video. Thanks for taking the time to make this detailed video. Well done!

### 9. @MichagravesAI (üëç 0)
Wow! ü§© Veo 3 looks absolutely incredible! The cinematic quality and the realistic character voices are a game-changer. Huge props to the creator of this video for such a detailed and insightful walkthrough! You made understanding Veo 3 so easy and exciting. üî•

### 10. @andersgraham5852 (üëç 0)
This was actually an amazing and straightforward how to without any of the fluff. Thanks big dawg

### 11. @SahakSahakian (üëç 8)
Thank you for putting the cash and sharing your findings with us!

> **@DP-hy4vh** (üëç 0): Google has a 1 month free trial where you can cancel after you use up your credits (1200 credits).

> **@taoprompts** (üëç 2): I'm glad this helps! Veo 3 is definitely worth keeping up with

> **@thewordmasterblog** (üëç 0): @@taoprompts I was thinking the #same thing....thank you....that must have cost a pretty penny to do all this!

### 12. @ethanmarquez6448 (üëç 1)
your tutorials are the best! glad i found you early in my ai generation journey üôåüèº

### 13. @gewickG (üëç 0)
I agree with you - it takes a hybrid workflow in a real video editor to get the higher quality we want for a real quality movie.

### 14. @AICinematicShorts0 (üëç 0)
The quality of these videos are so good.

### 15. @fabianoperes2155 (üëç 3)
8:57, maybe if you could specify the distance they are from each other the fight would be a little better. Also saying in the prompt they are really afraid of being hit by the light saber and they should avoid it at any cost protecting their body by putting the light saber in front of the hit. Even adding jumping and running a little to scape the lightsaber hit.

### 16. @memorybloke9256 (üëç 0)
Another very good video. Thanks! You could prompt scenes minus the main actor; then green screen a  Runway consistent character into it.

### 17. @abbyzellweger (üëç 0)
Really impress me. I always got problem in controlling camera movement.  I've seen a lot of use cases of Veo 3. All of them are soso great. Definitely gonna try it.

### 18. @willroske8406 (üëç 0)
This was incredibly helpful! Can you please make more videos on Veo 3? I love seeing what you are able to make.

### 19. @crazykatze (üëç 1)
Tao this is the next level VEO3 bro thanks

### 20. @SlopbotMedia (üëç 0)
Your skills are sick! I made a Veo 3 video with a robot doing beach girls interviews. It's definitely a fun program.

