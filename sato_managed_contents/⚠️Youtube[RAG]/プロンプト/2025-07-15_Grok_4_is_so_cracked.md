# Grok 4 is so cracked

**チャンネル:** AI Search
**公開日:** 2025-07-15
**URL:** https://www.youtube.com/watch?v=2SqORhe7pqM

## 説明

Grok 4 fully tested. Grok 4 review & tutorial. Grok 4 realtime voice and companion app. #ai #ainews #llm #agi

Thanks to Hubspot for sponsoring this video. Download their free “Advanced Prompt Engineering” guide. https://clickhubspot.com/454c59

https://grok.com/
https://x.ai/news/grok-4

0:00 Grok 4 intro
2:05 How to use Grok 4
3:40 Asteroid hitting Earth
7:50 Gravity physics
9:14 3D visualizer
13:16 Free prompt engineering guide
14:22 Shape shifter
15:54 Maps and layers
19:21 Black hole simulator
20:37 Financial analysis
23:15 IMO question
25:13 Visual puzzles
26:44 Specs and versions
29:06 Realtime voice
32:16 Realtime waifus
33:32 Benchmarks
35:26 ARC-AGI
37:46 Other leaderboards
39:16 Long text and hallucinations
42:22 Final thoughts


Newsletter: https://aisearch.substack.com/
Find AI tools & jobs: https://ai-search.io/
Support: https://ko-fi.com/aisearch

Here's my equipment, in case you're wondering:
Lenovo Thinkbook: https://amzn.to/4jWeKwH
Dell Precision 5690: https://www.dell.com/en-us/dt/ai-technologies/index.htm?utm_source=AISearchTools&utm_medium=youtube&utm_campaign=precisionai#tab0=0 
GPU: Nvidia RTX 5000 Ada https://nvda.ws/3zfqGqS
Mic: Shure SM7B https://amzn.to/3DErjt1
Audio interface: Scarlett Solo https://amzn.to/3qELMeu

## 字幕

[00:00 - 00:06]
Oh my god, it made this whole thing with

[00:03 - 00:08]
just one prompt. Look how crazy these

[00:06 - 00:10]
animations are. All right, next. Let's

[00:08 - 00:12]
get it to create an interactive

[00:10 - 00:15]
visualization of a meteor crashing into

[00:12 - 00:18]
Earth. And here's what we get. Look at

[00:15 - 00:20]
how detailed everything is. And again,

[00:18 - 00:22]
it made all of this with just one

[00:20 - 00:24]
prompt. Let's try this. Create an

[00:22 - 00:27]
interactive map of USA with population

[00:24 - 00:30]
density, natural areas, urban areas, and

[00:27 - 00:34]
other layers. And here is what we get.

[00:30 - 00:37]
Indeed, it maps all these layers on our

[00:34 - 00:39]
map. How insane is that? Or let's feed

[00:37 - 00:41]
it this really challenging visual

[00:39 - 00:43]
puzzle. And then ask it what's the

[00:41 - 00:45]
correct answer. Do not search the web.

[00:43 - 00:48]
And it nailed it. Let's get it to create

[00:45 - 00:50]
an interactive black hole visualizer.

[00:48 - 00:53]
And would you look at that? This is

[00:50 - 00:55]
pretty cool. Or let's feed it this

[00:53 - 00:56]
Olympic level math question. Like I

[00:55 - 00:58]
don't even know what the hell this

[00:56 - 01:00]
means. This is one of the hardest math

[00:58 - 01:02]
questions in the world that not a lot of

[01:00 - 01:04]
people know how to solve. And after

[01:02 - 01:08]
thinking for a long time, it also got

[01:04 - 01:11]
the answer completely correct. XAI just

[01:08 - 01:14]
released Gro 4 and this is the best the

[01:11 - 01:17]
most capable AI model you can use right

[01:14 - 01:19]
now, but actually it sucks if you don't

[01:17 - 01:20]
know how to use it properly. So, in this

[01:19 - 01:22]
video, I'm going to show you all the

[01:20 - 01:24]
cool things you can do with it and how

[01:22 - 01:26]
to actually use it properly. Plus, I'm

[01:24 - 01:28]
going to go over its specs and

[01:26 - 01:31]
performance against other AI models and

[01:28 - 01:33]
pricing. So, let's jump right in. Thanks

[01:31 - 01:36]
to HubSpot for sponsoring this video.

[01:33 - 01:39]
Now, as with the rest of the leading AI

[01:36 - 01:41]
models, Gro 4 is especially good at

[01:39 - 01:44]
really complex reasoning tasks for

[01:41 - 01:46]
things like coding, science, math, and

[01:44 - 01:48]
research. So, that's mostly what I'm

[01:46 - 01:51]
going to focus on in this video. I mean,

[01:48 - 01:53]
sure, you can get Grock to also answer

[01:51 - 01:55]
simple questions or help you reply to

[01:53 - 01:57]
emails, but all the other chat bots can

[01:55 - 01:59]
do that as well. So, in this video, I'm

[01:57 - 02:02]
mainly going to focus on these coding,

[01:59 - 02:05]
science, math, and reasoning tasks to

[02:02 - 02:08]
show you how good Grock is. So, it's

[02:05 - 02:10]
really easy to access and use. It's just

[02:08 - 02:11]
grock.com, which I'll link to in the

[02:10 - 02:13]
description below. And over here, you

[02:11 - 02:16]
can see that I have Grock 4 selected.

[02:13 - 02:18]
Now, here's the thing. You need to know

[02:16 - 02:21]
how to prompt Grock 4 in order to

[02:18 - 02:22]
maximize its potential. If you don't

[02:21 - 02:25]
know how to do that, you're going to

[02:22 - 02:27]
think it sucks. So, here's an example.

[02:25 - 02:29]
Give me an insane interactive visualizer

[02:27 - 02:31]
with multiple elements, particles, or

[02:29 - 02:34]
animation effects. Make it interactive

[02:31 - 02:37]
and extremely impressive. Use 3JS. This

[02:34 - 02:40]
is a library for 3D animations. And then

[02:37 - 02:43]
use CSS,JS, and HTML in a standalone

[02:40 - 02:45]
HTML file. Make sure all libraries are

[02:43 - 02:48]
defined or imported. Now, I'm showing

[02:45 - 02:49]
you this example first because it's not

[02:48 - 02:51]
going to work. So, let's actually press

[02:49 - 02:53]
enter and see what we get. All right,

[02:51 - 02:55]
here's what we get. First of all, you

[02:53 - 02:57]
can see that it thought for 26 seconds

[02:55 - 02:59]
and then it gave us the code. Now, if I

[02:57 - 03:01]
click preview on the right side here,

[02:59 - 03:03]
you're going to see a preview of this

[03:01 - 03:06]
code. Now, nothing works. And actually

[03:03 - 03:09]
on Chrome if I press control shift and I

[03:06 - 03:11]
to open up the console log you can see

[03:09 - 03:14]
that we are hitting a lot of errors.

[03:11 - 03:16]
Three is not defined even though I told

[03:14 - 03:18]
it to make sure all libraries are

[03:16 - 03:21]
defined or imported. So if you're

[03:18 - 03:23]
prompting Grock 4 this way, you're going

[03:21 - 03:26]
to think Grock 4 sucks and nothing

[03:23 - 03:28]
works. For other models like Gemini or

[03:26 - 03:30]
Deepseek, this prompt works just fine

[03:28 - 03:32]
and they can easily create a page with

[03:30 - 03:35]
no errors. But for Gro 4, it does

[03:32 - 03:37]
require a bit more handholding. This

[03:35 - 03:39]
doesn't mean Grock 4 sucks. It just

[03:37 - 03:42]
means you need to engineer your prompt

[03:39 - 03:45]
better. So, let's try another example.

[03:42 - 03:46]
This is the correct way to prompt Grock

[03:45 - 03:49]
4. And don't worry, I'm going to paste

[03:46 - 03:51]
these key phrases and words in a pinned

[03:49 - 03:53]
comment below. So, you can just copy and

[03:51 - 03:55]
paste it in your prompt as well. So, if

[03:53 - 03:57]
you want to get it to code some really

[03:55 - 03:59]
cool animation or something, you first

[03:57 - 04:02]
need to prompt it with its role. So for

[03:59 - 04:04]
example, you can say that Grock is a

[04:02 - 04:08]
senior 3D graphics programmer with

[04:04 - 04:10]
extensive experience in WebGL and 3JS.

[04:08 - 04:13]
And you can write this if you want to

[04:10 - 04:16]
get it to create some 3D animation or

[04:13 - 04:19]
visualization. And then here you can say

[04:16 - 04:21]
generate a complete self-contained HTML

[04:19 - 04:24]
file that renders a photorealistic and

[04:21 - 04:26]
interactive 3D simulation, etc., etc.

[04:24 - 04:29]
Again, these are just keywords to

[04:26 - 04:32]
basically encourage Gro 4 to create a

[04:29 - 04:33]
more visually compelling animation.

[04:32 - 04:35]
Otherwise, it's pretty short and

[04:33 - 04:37]
concise, and it tends to give you the

[04:35 - 04:40]
bare minimum. And then for our actual

[04:37 - 04:42]
animation, let's try this. Simulates an

[04:40 - 04:45]
asteroid impact on Earth. The meteor

[04:42 - 04:48]
should be glowing with a trailing flame.

[04:45 - 04:49]
The user can choose the size and speed

[04:48 - 04:52]
and other settings and watch the

[04:49 - 04:54]
animation. include an epic explosion

[04:52 - 04:57]
animation of dispersing flaming

[04:54 - 04:59]
particles and then also import realistic

[04:57 - 05:02]
textures. And the nice thing about Grock

[04:59 - 05:04]
is it has web search by default. You

[05:02 - 05:05]
don't even need to toggle anything on.

[05:04 - 05:08]
So it's actually going to search the web

[05:05 - 05:10]
and find a realistic texture for planet

[05:08 - 05:13]
Earth. And then the final output should

[05:10 - 05:15]
be a single HTML file. And then here is

[05:13 - 05:18]
the most important part. Again, you need

[05:15 - 05:21]
to kind of handhold it and tell it how

[05:18 - 05:24]
to import 3JS. So here I wrote you can

[05:21 - 05:27]
use this script to import 3JS this one

[05:24 - 05:29]
here. And then we also want it to import

[05:27 - 05:32]
orbit controls which lets you kind of

[05:29 - 05:35]
orbit or move around a 3D scene using

[05:32 - 05:38]
your mouse or touch controls. Again for

[05:35 - 05:41]
Gro 4 it's best if you specify the exact

[05:38 - 05:43]
libraries or packages that you would

[05:41 - 05:45]
like it to use for the animation.

[05:43 - 05:47]
Anyways let's click generate. And here

[05:45 - 05:50]
you can see it thought for 53 seconds.

[05:47 - 05:52]
Now actually let's expand its thoughts

[05:50 - 05:55]
so you can see its thought process on

[05:52 - 05:58]
how to create this simulation. Here it's

[05:55 - 06:00]
planning the simulation and then here

[05:58 - 06:02]
it's designing the asteroid trail and

[06:00 - 06:03]
that's pretty much it. That is its

[06:02 - 06:06]
thought process. If you've been playing

[06:03 - 06:08]
around with like 03 or deepseeek they

[06:06 - 06:10]
usually think for a ton of paragraphs

[06:08 - 06:12]
but here it's really short and concise

[06:10 - 06:14]
and then afterwards it doesn't even give

[06:12 - 06:16]
you any text explaining you know what

[06:14 - 06:18]
this code does. It just gives you the

[06:16 - 06:21]
code. You know, Grock 4 is like a no BS

[06:18 - 06:23]
AI model that gets straight to the

[06:21 - 06:26]
point. Anyways, let's click preview and

[06:23 - 06:30]
see what we get. Wow. And here we go.

[06:26 - 06:31]
Here is our 3D render of planet Earth.

[06:30 - 06:34]
And again, note that it just

[06:31 - 06:36]
automatically found the texture and

[06:34 - 06:38]
imported it for us. And you can see I'm

[06:36 - 06:40]
dragging my mouse around. So, we can

[06:38 - 06:43]
change the view of Earth like this. I

[06:40 - 06:45]
can also scroll my mouse to zoom in and

[06:43 - 06:48]
out. All right. Next, let's click start

[06:45 - 06:51]
animation. And indeed, here we have an

[06:48 - 06:53]
asteroid crashing into Earth like this.

[06:51 - 06:56]
Very cool. Let's click start animation

[06:53 - 06:58]
again. And that's another asteroid. All

[06:56 - 07:02]
right, let's adjust the asteroid speed

[06:58 - 07:04]
and increase the asteroid size and press

[07:02 - 07:07]
start animation again. And there you go.

[07:04 - 07:09]
Now, notice that the asteroid doesn't

[07:07 - 07:12]
really look like an asteroid. So, I can

[07:09 - 07:14]
probably prompt it further to import a

[07:12 - 07:16]
texture for the asteroid or something

[07:14 - 07:19]
like that. But anyways, there you go. In

[07:16 - 07:21]
just one prompt, it was able to create

[07:19 - 07:23]
this simulation and everything works

[07:21 - 07:26]
properly. Now, for your reference,

[07:23 - 07:29]
here's the same code with Gemini 2.5

[07:26 - 07:31]
Pro. Let's click on launch asteroid. And

[07:29 - 07:34]
you can see that the asteroid actually

[07:31 - 07:36]
looks really good with a flaming trail,

[07:34 - 07:39]
but let's see if it can actually hit

[07:36 - 07:41]
planet Earth. Okay. So, it kind of just

[07:39 - 07:44]
went through Earth and there's no

[07:41 - 07:47]
explosion or anything. So, in that

[07:44 - 07:49]
sense, it's not as good as the animation

[07:47 - 07:51]
from Grock 4. All right. Next, let's try

[07:49 - 07:53]
this prompt. Make a Gton board

[07:51 - 07:55]
simulation with a grid of pegs,

[07:53 - 07:57]
sidewalls, and separate dividers at the

[07:55 - 08:00]
bottom. Drop balls from the top upon

[07:57 - 08:03]
button click. Use matter.js.

[08:00 - 08:06]
This is another key library I like to

[08:03 - 08:09]
use for physics simulation. then use

[08:06 - 08:12]
CSS,JS, and HTML in a single HTML file.

[08:09 - 08:14]
Let's press generate. And here is what

[08:12 - 08:16]
we get. So here it thought for 86

[08:14 - 08:18]
seconds. And here is its thought

[08:16 - 08:20]
process. Again, it's pretty short and

[08:18 - 08:22]
concise. And then here is its answer.

[08:20 - 08:24]
Again, it just gives you the code. It

[08:22 - 08:27]
doesn't even explain anything. It's a

[08:24 - 08:29]
very no BS model. So let's click

[08:27 - 08:32]
preview. And let me just click on drop

[08:29 - 08:35]
ball a few times. So indeed, we have a

[08:32 - 08:38]
Gton board. And the balls are falling

[08:35 - 08:40]
according to gravity. Now, it seems like

[08:38 - 08:42]
none of these balls are actually falling

[08:40 - 08:45]
through these pegs to the center. So,

[08:42 - 08:48]
let's write a follow-up. Add edges to

[08:45 - 08:50]
the side of the gton board so that most

[08:48 - 08:52]
balls don't just fall to the sides. All

[08:50 - 08:54]
right. So, here it thought for a bit

[08:52 - 08:57]
longer. And here is the final code. So,

[08:54 - 09:00]
let's click preview. And indeed, it has

[08:57 - 09:02]
added sides to the gton board. So, let

[09:00 - 09:05]
me click drop ball a few times. And as

[09:02 - 09:08]
you can see, the balls are falling very

[09:05 - 09:10]
realistically. So, here is a super

[09:08 - 09:12]
realistic Gton board simulation with the

[09:10 - 09:15]
correct gravity physics. All right.

[09:12 - 09:18]
Next, let's try something even crazier.

[09:15 - 09:21]
So, I'm going to use the same prompt

[09:18 - 09:23]
template as before. You are a senior 3D

[09:21 - 09:24]
graphics programmer with extensive

[09:23 - 09:28]
experience. Create a complete

[09:24 - 09:30]
self-contained HTML file, etc., etc. And

[09:28 - 09:32]
then this time we are going to get it to

[09:30 - 09:35]
create an interactive morphing particle

[09:32 - 09:38]
visualizer which can transform into five

[09:35 - 09:40]
different nonlinear dynamics. These are

[09:38 - 09:42]
basically really irregular shapes and

[09:40 - 09:45]
patterns. And then add adjustable

[09:42 - 09:48]
settings. And then again to make sure we

[09:45 - 09:50]
don't run into any errors with importing

[09:48 - 09:52]
libraries and dependencies, we need to

[09:50 - 09:54]
handhold it and tell it to use the

[09:52 - 09:56]
following imports. And again, don't

[09:54 - 09:58]
worry. I'm going to paste all this code

[09:56 - 10:00]
in the pin comment below. So, you can

[09:58 - 10:02]
just copy and paste it into your prompt.

[10:00 - 10:04]
So, this time we are going to add some

[10:02 - 10:07]
pretty cool effects. And in order to do

[10:04 - 10:10]
that, we need to use these add-on

[10:07 - 10:12]
packages for 3JS. The first one is orbit

[10:10 - 10:14]
controls, which we've gone over before.

[10:12 - 10:16]
This is for like using your mouse to

[10:14 - 10:19]
view the 3D scene at different angles.

[10:16 - 10:21]
And then this effect composer and render

[10:19 - 10:24]
pass and output pass. These are

[10:21 - 10:27]
basically used to apply additional

[10:24 - 10:29]
effects to your 3D scene. And then we

[10:27 - 10:31]
also have this Unreal Bloom pass which

[10:29 - 10:33]
basically adds some glowing bloom

[10:31 - 10:35]
effects to your scene which you'll see

[10:33 - 10:38]
in a second. And then finally, we also

[10:35 - 10:40]
need to tell it to import 3JS from over

[10:38 - 10:43]
here like this. Notice that this is just

[10:40 - 10:45]
another way you can tell it to import

[10:43 - 10:48]
3JS. Notice that it's slightly different

[10:45 - 10:50]
from our asteroid example where we

[10:48 - 10:52]
imported 3JS like this. Anyways, back to

[10:50 - 10:54]
this particle visualizer. Let's click

[10:52 - 10:57]
generate. All right. So, it thought for

[10:54 - 11:00]
a bit longer this time. Let's expand its

[10:57 - 11:03]
thought process. And here you can see

[11:00 - 11:05]
it's first planning the 3D simulation,

[11:03 - 11:08]
designing the user controls, and then

[11:05 - 11:10]
it's actually searching the web for a

[11:08 - 11:13]
list of 3D strange attractor equations

[11:10 - 11:15]
and parameters, which will basically

[11:13 - 11:17]
define the shapes and patterns that

[11:15 - 11:20]
you'll see in a second. And then it kind

[11:17 - 11:22]
of searches further for this Isawa

[11:20 - 11:24]
attractor equation which gives us

[11:22 - 11:25]
something like this. And then here it's

[11:24 - 11:28]
finalizing visual effects and

[11:25 - 11:31]
initializing the particles. And then

[11:28 - 11:34]
finally here is our code. So let me

[11:31 - 11:37]
click preview. Oh my god, what do we

[11:34 - 11:40]
have here? This is so cool. And then

[11:37 - 11:43]
let's change this to Rosler. I don't

[11:40 - 11:47]
even know how you say this, but uh holy

[11:43 - 11:50]
smokes. This animation is so cool. Let

[11:47 - 11:52]
me decrease the speed a bit. Wow, this

[11:50 - 11:55]
is a really cool animation. Let me also

[11:52 - 11:57]
increase the point size. All right. And

[11:55 - 11:59]
I can drag my mouse around to view this

[11:57 - 12:03]
at different angles. Instead of Rosler,

[11:59 - 12:05]
let's try Isawa. And you can see right

[12:03 - 12:08]
now it's transforming into a different

[12:05 - 12:12]
shape. Okay. So, I guess this is the

[12:08 - 12:15]
Isawa equation. Very nice. And instead

[12:12 - 12:18]
of Isawa, let's try Thomas. Let me

[12:15 - 12:20]
increase the speed. Wow, very

[12:18 - 12:23]
interesting. So this is Thomas. Let me

[12:20 - 12:27]
increase the speed a bit faster. There

[12:23 - 12:29]
we go. And then after Thomas, let's try

[12:27 - 12:33]
Halverson. Is that how you pronounce it?

[12:29 - 12:35]
Oh my god, what is this? Where did all

[12:33 - 12:37]
the particles go? Anyways, there you go.

[12:35 - 12:40]
Here's how you can code up some really

[12:37 - 12:43]
cool 3D animations with Gro 4. Look at

[12:40 - 12:44]
how cool this is. Let me just run

[12:43 - 12:47]
through these shapes again because this

[12:44 - 12:49]
is just really cool. And then for your

[12:47 - 12:52]
information, here is the same prompt

[12:49 - 12:54]
with Gemini 2.5 Pro. However, when I run

[12:52 - 12:56]
this, you can see that something went

[12:54 - 12:58]
wrong. There was an error. And if I open

[12:56 - 13:00]
up the console log, it seems like

[12:58 - 13:02]
there's an error with this math utils

[13:00 - 13:04]
function. Plus, even though in the

[13:02 - 13:07]
prompt I specified for it to generate

[13:04 - 13:09]
nonlinear dynamics, it just generated

[13:07 - 13:12]
some really simple shapes like sphere

[13:09 - 13:14]
and Taurus. So, it's not as complicated

[13:12 - 13:17]
as what we got from Gro 4. I mean, look

[13:14 - 13:20]
at how crazy this visualizer is. If

[13:17 - 13:22]
you've ever used Chat GPT and thought,

[13:20 - 13:23]
why are my results all over the place?

[13:22 - 13:26]
You're not alone. What if there was a

[13:23 - 13:28]
way to consistently get expert level

[13:26 - 13:31]
outputs from ChatgPT? Well, check out

[13:28 - 13:33]
this free guide called Advanced Chat GPT

[13:31 - 13:35]
Prompt Engineering by HubSpot, which

[13:33 - 13:38]
teaches you how to become an expert

[13:35 - 13:39]
prompter in just 7 days. It's a full

[13:38 - 13:42]
playbook that walks you through how to

[13:39 - 13:44]
go from casual prompts to high precision

[13:42 - 13:46]
results. You'll learn the core

[13:44 - 13:49]
principles of prompt engineering with a

[13:46 - 13:51]
proven zeroshot formula. I especially

[13:49 - 13:53]
love the pre-built templates for various

[13:51 - 13:55]
use cases like marketing, business

[13:53 - 13:57]
analysis, and content creation, which

[13:55 - 13:59]
you can just copy and paste into Chat

[13:57 - 14:01]
GPT. It also teaches you about few shot

[13:59 - 14:03]
prompting, where you can send follow-up

[14:01 - 14:05]
prompts to the AI model to get even

[14:03 - 14:07]
better results than if you just prompted

[14:05 - 14:09]
it once. Best of all, you'll learn how

[14:07 - 14:12]
to reduce errors and hallucinations from

[14:09 - 14:14]
the AI so that its response is factually

[14:12 - 14:16]
correct. And my favorite part, it

[14:14 - 14:18]
provides a ton of real prompt examples

[14:16 - 14:20]
to show you exactly how you can do the

[14:18 - 14:22]
same thing. Grab it for free in the

[14:20 - 14:24]
description below. And thanks to HubSpot

[14:22 - 14:25]
for sponsoring this video. Or here's

[14:24 - 14:28]
another example. I'm going to use pretty

[14:25 - 14:30]
much the same prompt at the start and

[14:28 - 14:32]
the end. I just find that these import

[14:30 - 14:34]
statements work very well for creating

[14:32 - 14:36]
3D animations in Grock. So feel free to

[14:34 - 14:38]
just copy and paste this from the pinned

[14:36 - 14:40]
comment below. And then this time

[14:38 - 14:44]
instead of those irregular shapes, let's

[14:40 - 14:46]
do something like helixes, lattises, and

[14:44 - 14:48]
galaxies, and neural networks. I'm not

[14:46 - 14:50]
even sure what it's going to generate

[14:48 - 14:51]
for us. And then add adjustable

[14:50 - 14:53]
settings. And because the previous

[14:51 - 14:55]
animation is kind of monotone here, I'm

[14:53 - 14:58]
going to make it colorful and visually

[14:55 - 15:01]
appealing. All right, here is what we

[14:58 - 15:05]
get. So, let me press preview. And very

[15:01 - 15:09]
cool. Here is a colorful helix. Let's

[15:05 - 15:11]
morph this into a lattice. Wow. For the

[15:09 - 15:13]
morph speed, let's actually make this a

[15:11 - 15:16]
bit slower. And then particle size,

[15:13 - 15:19]
let's increase this to like over here.

[15:16 - 15:21]
Bloom strength, let's make it even more

[15:19 - 15:25]
glowy. And then let's transform this

[15:21 - 15:27]
into a galaxy. Wo. All right. So, I

[15:25 - 15:30]
guess this is our galaxy. Let's

[15:27 - 15:33]
transform this into a neural network

[15:30 - 15:35]
now. Okay. Not exactly the neural

[15:33 - 15:37]
network I was expecting, but I guess

[15:35 - 15:39]
these are like the layers of a neural

[15:37 - 15:42]
network. And then finally, let's morph

[15:39 - 15:44]
this into a Taurus. And here is what we

[15:42 - 15:48]
get. And let's morph this back into a

[15:44 - 15:50]
helix. Wow, this is so cool. So there

[15:48 - 15:53]
you go. Here's another really quick 3D

[15:50 - 15:55]
visualizer you can create with Grock in

[15:53 - 15:58]
just one prompt. All right, enough 3D

[15:55 - 16:00]
stuff. Let's move on to some more useful

[15:58 - 16:02]
applications like creating maps. So

[16:00 - 16:05]
here, let's get it to create an

[16:02 - 16:06]
interactive map of USA. Show toggles for

[16:05 - 16:09]
different layers such as water, natural

[16:06 - 16:12]
areas, urban highways, population

[16:09 - 16:16]
density, etc. Use leaflet.js and

[16:12 - 16:19]
existing gojson or topojson data for

[16:16 - 16:22]
layers. So I'm basically getting it to

[16:19 - 16:24]
search for existing geospatial layers

[16:22 - 16:26]
online for all these different layers.

[16:24 - 16:29]
And then finally, here's the key phrase

[16:26 - 16:32]
I like to use. use CSS,JS, and HTML in a

[16:29 - 16:34]
single HTML file. All right, so here it

[16:32 - 16:37]
thought for a bit longer. And if I

[16:34 - 16:39]
expand this, notice that after planning

[16:37 - 16:42]
everything, it's searching extensively

[16:39 - 16:44]
for all this geo JSON data, including

[16:42 - 16:47]
rivers, lakes, national parks, urban

[16:44 - 16:49]
areas, interstate highways, and

[16:47 - 16:51]
population density. And then it's

[16:49 - 16:54]
exploring all these layers and choosing

[16:51 - 16:56]
the right one to use. However, here it

[16:54 - 16:59]
says that it could not find relevant

[16:56 - 17:01]
content as the table includes total area

[16:59 - 17:04]
not density. So because the initial

[17:01 - 17:07]
table lacks density, let's check the

[17:04 - 17:09]
other page etc etc. And then here

[17:07 - 17:11]
finally it found the population and

[17:09 - 17:14]
density data for all 50 states. And

[17:11 - 17:17]
finally here is what we get. So let me

[17:14 - 17:19]
click preview. And indeed we have a map

[17:17 - 17:22]
of USA and here is the population

[17:19 - 17:24]
density. So, let me toggle this off and

[17:22 - 17:26]
then let me turn on lakes. It doesn't

[17:24 - 17:29]
seem like lakes is working. Let me try

[17:26 - 17:31]
to zoom in and out. Yeah, I don't see

[17:29 - 17:33]
any lakes highlighted here. So, it

[17:31 - 17:36]
doesn't seem like lakes are working.

[17:33 - 17:40]
What about rivers? Rivers also do not

[17:36 - 17:42]
seem to work. And then natural areas,

[17:40 - 17:44]
those are also not highlighted. Urban

[17:42 - 17:47]
areas. Okay, urban areas are

[17:44 - 17:48]
highlighted. So, you can see the areas

[17:47 - 17:51]
highlighted in gray. So, if I toggle

[17:48 - 17:53]
this off and on again, you can see those

[17:51 - 17:55]
are the urban areas. And then for

[17:53 - 17:56]
highways, it doesn't seem like there's a

[17:55 - 17:58]
layer for that either. So, what I'm

[17:56 - 18:00]
going to do over here is send a

[17:58 - 18:02]
follow-up. The following layers don't

[18:00 - 18:05]
work. Lakes, rivers, natural areas, and

[18:02 - 18:07]
highways. All right. So, afterwards, it

[18:05 - 18:10]
thought for a bit longer, and it's

[18:07 - 18:12]
searching the web for more geospatial

[18:10 - 18:14]
data regarding these layers. And then

[18:12 - 18:16]
here's the code. So, let's click

[18:14 - 18:18]
preview. And let's try this again. Let

[18:16 - 18:21]
me turn off population density and turn

[18:18 - 18:23]
on lakes. And indeed, we have lakes

[18:21 - 18:26]
highlighted. Very cool. Now, instead of

[18:23 - 18:27]
lakes, let's turn on rivers. Rivers

[18:26 - 18:29]
still doesn't seem to work, but

[18:27 - 18:31]
whatever. Natural areas, that also

[18:29 - 18:34]
works. You can see natural areas

[18:31 - 18:36]
highlighted here. And then urban areas,

[18:34 - 18:38]
that worked like last time. And then

[18:36 - 18:41]
highways, that still doesn't seem to

[18:38 - 18:43]
work, but it got a few of these layers

[18:41 - 18:45]
correct, which is still not bad. Now,

[18:43 - 18:47]
for your comparison, if I run the same

[18:45 - 18:50]
prompt with Google's Gemini 2.5 Pro,

[18:47 - 18:52]
again, we hit some errors. So, it does

[18:50 - 18:54]
give us a map of USA, the nice thing is

[18:52 - 18:56]
it also allows us to toggle between

[18:54 - 18:58]
street map and satellite. Let's turn

[18:56 - 19:01]
this back into street map. However, for

[18:58 - 19:04]
water bodies, it does not really detect

[19:01 - 19:07]
anything. For parks and protected lands,

[19:04 - 19:09]
it also does not detect anything. urban

[19:07 - 19:11]
areas, major highways, population

[19:09 - 19:14]
density. It gave us a nice legend here,

[19:11 - 19:16]
but again, none of these layers are

[19:14 - 19:18]
actually applied to this map. So again,

[19:16 - 19:20]
as you can see, Grock is just slightly

[19:18 - 19:23]
more performant in this regard. All

[19:20 - 19:25]
right, next. This is kind of inspired by

[19:23 - 19:27]
what they showed during their live

[19:25 - 19:30]
stream. So let's also try to create an

[19:27 - 19:33]
interactive black hole visualizer in a

[19:30 - 19:34]
standalone HTML file. Use the following

[19:33 - 19:37]
imports. So again, I'm just going to

[19:34 - 19:38]
copy and paste all the imports that I

[19:37 - 19:41]
showed you from the previous prompt,

[19:38 - 19:43]
which basically kind of guides Grock 4

[19:41 - 19:45]
on, you know, what packages and

[19:43 - 19:48]
dependencies to use. These are mostly

[19:45 - 19:51]
packages for 3JS. And let's click

[19:48 - 19:54]
generate. All right, so here is what we

[19:51 - 19:57]
get. Let's click preview. And this is

[19:54 - 20:00]
what we get. So it seems like I need to

[19:57 - 20:02]
scroll my mouse to animate this. Very

[20:00 - 20:04]
cool. So I guess that's the animation.

[20:02 - 20:07]
You can see the black hole animating as

[20:04 - 20:09]
I drag my mouse around like this. Now,

[20:07 - 20:12]
for your comparison, here's the same

[20:09 - 20:14]
prompt with Google's Gemini 2.5 Pro. And

[20:12 - 20:17]
if I drag my mouse around, it kind of

[20:14 - 20:19]
does orbit around this thing, but it's

[20:17 - 20:21]
not really a black hole at all. There's

[20:19 - 20:23]
not really any suction going on or

[20:21 - 20:25]
anything. It just doesn't look as good

[20:23 - 20:27]
as the Grock example. So again, I hope

[20:25 - 20:30]
you can see that as long as you prompt

[20:27 - 20:32]
Gro 4 correctly like this, then it's

[20:30 - 20:34]
actually insanely good and it is

[20:32 - 20:36]
slightly better than the leading models

[20:34 - 20:38]
out there, including Gemini 2.5 Pro and

[20:36 - 20:41]
03. All right, next, let's try something

[20:38 - 20:43]
that's a bit more useful for everyday

[20:41 - 20:46]
life. So here, what I'm going to do is

[20:43 - 20:48]
upload the Q4 earnings reports from

[20:46 - 20:50]
Nvidia. Let me just show you this real

[20:48 - 20:52]
quickly. And also from Google, which

[20:50 - 20:54]
looks like this. And finally, from

[20:52 - 20:56]
Amazon, which looks like this. And then

[20:54 - 20:59]
I'm going to write, "Give me a very

[20:56 - 21:01]
detailed financial analysis with graphs,

[20:59 - 21:03]
charts, or visuals. Be thorough and

[21:01 - 21:05]
include a 12-month forecast. Make the

[21:03 - 21:09]
page responsive. Make sure the visuals

[21:05 - 21:11]
fit nicely. Use a single HTML file only.

[21:09 - 21:13]
Let's press generate and see what that

[21:11 - 21:15]
gives us." All right, so this time it

[21:13 - 21:17]
only thought for only 17 seconds. This

[21:15 - 21:20]
task is a piece of cake. So let's click

[21:17 - 21:23]
preview. And here is what we get. So

[21:20 - 21:25]
indeed we have a financial analysis of

[21:23 - 21:29]
all three companies. Note that I did not

[21:25 - 21:31]
specify Nvidia, Alphabet or Amazon in

[21:29 - 21:34]
the prompt. So it actually did go in

[21:31 - 21:36]
each PDF and extracted the information.

[21:34 - 21:39]
And then here is a table of the key

[21:36 - 21:41]
metrics. Let me actually go in the

[21:39 - 21:44]
original report and try to find a few of

[21:41 - 21:47]
these stats. So let's see if I can find

[21:44 - 21:51]
126% year-over-year growth for Nvidia.

[21:47 - 21:53]
And indeed, we do see 126%

[21:51 - 21:55]
year-over-year growth in revenue for

[21:53 - 21:58]
Nvidia. And then for Alphabet, let's try

[21:55 - 22:01]
to find its operating income. It should

[21:58 - 22:05]
be 112.4. And indeed, operating income

[22:01 - 22:08]
is over here. And for 2024, it is

[22:05 - 22:10]
112.4,000.

[22:08 - 22:13]
Very nice. And then finally for Amazon,

[22:10 - 22:15]
let's try to find cash from operations.

[22:13 - 22:18]
It should be 115.9.

[22:15 - 22:20]
So indeed, cash from operations is

[22:18 - 22:21]
115.9.

[22:20 - 22:23]
So that's just to verify that this

[22:21 - 22:26]
information is actually accurate and

[22:23 - 22:28]
pulled from the original PDFs. And then

[22:26 - 22:31]
here's a financial analysis. Here's a

[22:28 - 22:32]
bar chart showing the revenue growth for

[22:31 - 22:34]
all three companies. By the way, look at

[22:32 - 22:36]
how crazy the growth of Nvidia is

[22:34 - 22:39]
compared to the other companies. And

[22:36 - 22:42]
then here is profitability and margins,

[22:39 - 22:44]
etc., etc. And then here's a 12-month

[22:42 - 22:47]
forecast. Now, for this part, I'm not

[22:44 - 22:49]
too particularly impressed by this. It

[22:47 - 22:51]
seems like it's just doing a linear

[22:49 - 22:54]
extrapolation. I'd like to see a more

[22:51 - 22:55]
thorough 12-month forecast where it

[22:54 - 22:58]
actually gives its reasoning on its

[22:55 - 23:02]
predictions. But anyways, there you go.

[22:58 - 23:04]
Here is the financial analysis report

[23:02 - 23:06]
which consolidates information from

[23:04 - 23:09]
these three PDFs. So, you know, you can

[23:06 - 23:12]
easily just plug in any document or PDF

[23:09 - 23:13]
into this and get it to summarize or

[23:12 - 23:16]
analyze it. Now, one of the major

[23:13 - 23:19]
strengths of Gro 4 is it's insanely good

[23:16 - 23:22]
at math. So, it's the best AI model in

[23:19 - 23:24]
terms of solving Olympiad level math

[23:22 - 23:26]
questions. Yes, there is an Olympics for

[23:24 - 23:28]
math. And you can see for this

[23:26 - 23:29]
competitive math benchmark, Grock 4

[23:28 - 23:32]
heavy, which we'll talk about in a

[23:29 - 23:35]
second, got a freaking 100%. That's

[23:32 - 23:38]
pretty crazy. So, I'm going to paste in

[23:35 - 23:40]
this question, and this is question C6

[23:38 - 23:43]
from the International Math Olympiad

[23:40 - 23:44]
2022 shortlisted problems. Let me just

[23:43 - 23:47]
read you the question really quickly.

[23:44 - 23:49]
Let n be a positive integer. We start

[23:47 - 23:51]
with n piles of pebbles, each initially

[23:49 - 23:53]
containing a single pebble. One can

[23:51 - 23:56]
perform moves of the following form.

[23:53 - 23:58]
Choose two piles. Take an equal number

[23:56 - 24:00]
of pebbles from each pile and form a new

[23:58 - 24:03]
pile out of these pebbles. For each

[24:00 - 24:06]
positive integer n, find the smallest

[24:03 - 24:08]
number of non-mpt piles that one can

[24:06 - 24:12]
obtain by performing a finite sequence

[24:08 - 24:14]
of moves of this form. What the hell are

[24:12 - 24:16]
you even talking about? This is like

[24:14 - 24:18]
alien language to me. But there you go.

[24:16 - 24:20]
Here's an example of one of the toughest

[24:18 - 24:22]
math problems in the world, which was

[24:20 - 24:24]
given in the International Math

[24:22 - 24:26]
Olympics. So, I'm going to copy and

[24:24 - 24:28]
paste this problem in here and

[24:26 - 24:30]
explicitly tell it not to search the web

[24:28 - 24:32]
for the correct answer just in case it

[24:30 - 24:34]
does. And then let's click generate. All

[24:32 - 24:38]
right. So, this time it thought for

[24:34 - 24:40]
really long, like almost 7 minutes, much

[24:38 - 24:42]
longer than getting it to code a 3D

[24:40 - 24:44]
animation. So, this must be a really

[24:42 - 24:46]
tricky math problem. Anyways, here is

[24:44 - 24:49]
its thought process. And you can see

[24:46 - 24:52]
it's analyzing everything step by step.

[24:49 - 24:54]
It's testing some simulations and

[24:52 - 24:56]
strategies and then it's also

[24:54 - 24:59]
considering some other patterns or

[24:56 - 25:01]
hypotheses I guess. But afterwards here

[24:59 - 25:03]
is its answer. So let me collapse this

[25:01 - 25:06]
thought process. The answer is the

[25:03 - 25:09]
smallest number of non-mp piles is one

[25:06 - 25:12]
if n is a power of two and two

[25:09 - 25:15]
otherwise. And that is indeed the

[25:12 - 25:18]
correct answer. Now, here's another

[25:15 - 25:20]
thing where Grok 4 outperforms the rest

[25:18 - 25:22]
of the leading AI models. It's called

[25:20 - 25:24]
the Arc AGI benchmark, which I'll talk

[25:22 - 25:26]
about in a second, but it mostly

[25:24 - 25:29]
involves solving visual puzzles. So,

[25:26 - 25:32]
what I'm going to do is upload this

[25:29 - 25:34]
image where we are given a sequence of

[25:32 - 25:36]
free images and it has to guess the next

[25:34 - 25:38]
frame. Now, if you don't want me to

[25:36 - 25:40]
spoil the answer, pause the video right

[25:38 - 25:42]
now and try to figure this out yourself.

[25:40 - 25:44]
Anyways, I'm going to upload this image

[25:42 - 25:47]
here and then write, "What is the

[25:44 - 25:49]
correct answer? Do not search the web."

[25:47 - 25:51]
All right. And here is what we get.

[25:49 - 25:53]
Again, you can see Grock is super short

[25:51 - 25:55]
and concise. It doesn't even bother

[25:53 - 25:58]
explaining the answer for us. It just

[25:55 - 26:00]
gave us D, which is indeed the correct

[25:58 - 26:02]
answer. Now, if we expand this, here is

[26:00 - 26:05]
actually all the math under the hood.

[26:02 - 26:07]
So, first it's analyzing the puzzle.

[26:05 - 26:10]
It's exploring the pattern. And then

[26:07 - 26:12]
it's also re-evaluating options. etc.,

[26:10 - 26:15]
etc. It's also testing different

[26:12 - 26:18]
theories like the examining triangle

[26:15 - 26:20]
direction, rotation theory, etc., etc.,

[26:18 - 26:23]
but eventually it lands on the answer D,

[26:20 - 26:25]
which is indeed correct. Now, solving

[26:23 - 26:28]
these visual puzzles might not seem like

[26:25 - 26:30]
much to you, but this is actually a very

[26:28 - 26:34]
important behavior. This signifies that

[26:30 - 26:36]
an AI can pick up patterns from new data

[26:34 - 26:38]
like this and figure out the answer.

[26:36 - 26:40]
It's kind of like it can learn new

[26:38 - 26:42]
things, right? this pattern is likely

[26:40 - 26:45]
not in its training data. All right, so

[26:42 - 26:47]
that sums up some of the cool things you

[26:45 - 26:50]
can do with Gro 4. Next, let's go over

[26:47 - 26:52]
its specs and performance. Now, Gro 4 is

[26:50 - 26:55]
a multimodal model and like I showed you

[26:52 - 26:57]
in some of my examples, you can also

[26:55 - 27:00]
upload images for it to analyze, as well

[26:57 - 27:02]
as upload PDFs for it to analyze. And

[27:00 - 27:04]
you know, the exciting thing is in

[27:02 - 27:07]
addition to just images, apparently

[27:04 - 27:09]
they're also planning a video generator

[27:07 - 27:11]
which will come out later this year.

[27:09 - 27:13]
Plus, they're also going to release a

[27:11 - 27:16]
coding version of Gro 4 which is even

[27:13 - 27:18]
more specialized at coding. Now, right

[27:16 - 27:22]
now, they've released two variants of

[27:18 - 27:24]
Gro 4. We have the regular Gro 4 and Gro

[27:22 - 27:27]
4 Heavy. You can think of Gro 4 Heavy as

[27:24 - 27:30]
like a team of agents working together

[27:27 - 27:33]
at once to consider multiple hypotheses

[27:30 - 27:35]
or solutions to a problem. As you can

[27:33 - 27:38]
see from this diagram here, here's what

[27:35 - 27:40]
Elon has to say about Gro 4 heavy. Um

[27:38 - 27:42]
and the with the GR 4 heavy what what it

[27:40 - 27:45]
does is it spawns multiple agents in

[27:42 - 27:47]
parallel and uh all of those agents do

[27:45 - 27:50]
do work independently and then they

[27:47 - 27:52]
compare their work and they they decide

[27:50 - 27:55]
which one like it's like a study group.

[27:52 - 27:57]
Um and it's not as simple as a majority

[27:55 - 27:59]
vote because often only one of the

[27:57 - 28:02]
agents actually figures out the trick or

[27:59 - 28:05]
figures out the solution. um and and and

[28:02 - 28:07]
but once they share the the trick or or

[28:05 - 28:09]
or figure out what what the real nature

[28:07 - 28:11]
of the problem is, they share that uh

[28:09 - 28:12]
solution with the other agents and then

[28:11 - 28:15]
they compare they essentially compare

[28:12 - 28:17]
notes and then and and then yield yield

[28:15 - 28:18]
an answer. So that's that's the the

[28:17 - 28:21]
heavy part of Gro 4.

[28:18 - 28:23]
So as expected Gro 4 heavy is going to

[28:21 - 28:26]
be even more intelligent and performant

[28:23 - 28:28]
than just the regular Gro 4, but it does

[28:26 - 28:32]
come at a price. So, as of right now, to

[28:28 - 28:35]
use Gro 4 natively on grock.com, you do

[28:32 - 28:37]
need to pay $30 per month just for the

[28:35 - 28:40]
regular Gro 4. Now, if you want to

[28:37 - 28:43]
access Gro 4 heavy, it's going to be a

[28:40 - 28:45]
whopping $300 per month. However, again,

[28:43 - 28:47]
note that most of you don't actually

[28:45 - 28:50]
need to use Gro 4 heavy. This is for

[28:47 - 28:53]
really specialized tasks which require

[28:50 - 28:55]
really deep reasoning and analysis. So,

[28:53 - 28:56]
for example, for medicine or research.

[28:55 - 28:59]
But for most of us, if you're just

[28:56 - 29:01]
getting gro to analyze regular reports

[28:59 - 29:04]
or vibe code something, the regular

[29:01 - 29:07]
Grock 4 already works very well. Now, by

[29:04 - 29:10]
the way, because this is multimodal, it

[29:07 - 29:12]
can also do audio and voice. So, right

[29:10 - 29:14]
now, they've released a voice assistant

[29:12 - 29:17]
which you can talk to in real time. And

[29:14 - 29:20]
this is super realistic. So, here I'm on

[29:17 - 29:23]
my mobile app and you can see up here

[29:20 - 29:26]
I've selected Gro 4 and all you need to

[29:23 - 29:28]
do is click on this audio button in the

[29:26 - 29:29]
lower right corner.

[29:28 - 29:32]
What's on your mind?

[29:29 - 29:33]
Can you talk to me in an erotic whispery

[29:32 - 29:35]
voice?

[29:33 - 29:38]
I'd love to, but I'm designed to keep

[29:35 - 29:40]
things professional and friendly. How

[29:38 - 29:43]
about I answer your next question in a

[29:40 - 29:44]
smooth, sultry tone instead? What do you

[29:43 - 29:46]
want to talk about?

[29:44 - 29:48]
Sure. Actually, it's my birthday today.

[29:46 - 29:51]
Can you sing me happy birthday?

[29:48 - 29:54]
Happy birthday. I'd love to sing for

[29:51 - 29:58]
you, but let's just say my vocal cords

[29:54 - 30:00]
are more AI than American Idol. Here we

[29:58 - 30:04]
go. In a smooth, sultry tone, as

[30:00 - 30:07]
promised. Happy birthday

[30:04 - 30:09]
to you.

[30:07 - 30:11]
Happy birthday

[30:09 - 30:15]
to you.

[30:11 - 30:19]
Happy birthday, dear friend.

[30:15 - 30:21]
Happy birthday to you.

[30:19 - 30:23]
Hope that hit the spot. Any birthday

[30:21 - 30:25]
wishes or plans you want to share?

[30:23 - 30:27]
And by the way, you can see that over

[30:25 - 30:29]
here you can choose from different

[30:27 - 30:31]
roles. So, for example, assistant,

[30:29 - 30:34]
therapist, storyteller. You can also use

[30:31 - 30:36]
this to tell your kids stories or play

[30:34 - 30:38]
trivia games. Or you can also use this

[30:36 - 30:41]
for meditation. In fact, let's try this

[30:38 - 30:44]
meditation one really quickly. Hi there.

[30:41 - 30:46]
Can you help me with a calm, relaxing

[30:44 - 30:49]
five-minute meditation?

[30:46 - 30:52]
Hello, I'm here to guide you into a

[30:49 - 30:54]
calm, relaxing 5-minute meditation.

[30:52 - 30:58]
Let's begin by finding a comfortable

[30:54 - 31:01]
position. Sit or lie down, whatever

[30:58 - 31:03]
feels natural to you. Gently close your

[31:01 - 31:06]
eyes if that feels right, and let your

[31:03 - 31:09]
body settle into this moment. Breathe in

[31:06 - 31:11]
deeply through your nose. Feel the air

[31:09 - 31:13]
fill your chest. So, those are some of

[31:11 - 31:16]
my quick demos, but here's another demo

[31:13 - 31:16]
comparing this to OpenAI's voice

[31:16 - 31:18]
assistant.

[31:16 - 31:20]
Weird. Why not try that live on the

[31:18 - 31:21]
stream today?

[31:20 - 31:22]
Should I start?

[31:21 - 31:24]
Hey, I'm going to say a number. And can

[31:22 - 31:26]
you say the same number back to me? One.

[31:24 - 31:28]
One. Got it. This is like a fun little

[31:26 - 31:30]
game of echo. What's next?

[31:28 - 31:33]
Two. So, you said two. Three. You

[31:30 - 31:34]
did. Three. Four. Nice and steady.

[31:33 - 31:36]
What's next?

[31:34 - 31:37]
Um uh five.

[31:36 - 31:39]
Five. Nailed it. This is pretty fun.

[31:37 - 31:40]
Feel free to keep going or switch it up

[31:39 - 31:41]
if

[31:40 - 31:43]
Hey Rock.

[31:41 - 31:44]
Hello there. How can I help you today?

[31:43 - 31:46]
We're going to do a little test. Can you

[31:44 - 31:48]
repeat after me? One.

[31:46 - 31:48]
One. All right. What's next?

[31:48 - 31:50]
Two.

[31:48 - 31:50]
Two. What's on your mind?

[31:50 - 31:52]
Three.

[31:50 - 31:52]
Three. Need anything else?

[31:52 - 31:54]
Four.

[31:52 - 31:55]
Four. How can I assist you?

[31:54 - 31:56]
Five.

[31:55 - 31:59]
Five. What's next?

[31:56 - 32:01]
So, as you can see, um, Groc was, uh,

[31:59 - 32:03]
snappier. It didn't interrupt me. And

[32:01 - 32:05]
the proced

[32:03 - 32:06]
choices. I think we shooting for

[32:05 - 32:07]
something more calm, smooth, more

[32:06 - 32:09]
natural.

[32:07 - 32:11]
As you can see, OpenAI's voice is just

[32:09 - 32:14]
way more talkative and she just goes on

[32:11 - 32:17]
and on, whereas Grock is more concise,

[32:14 - 32:19]
and I like to call it no BS. By the way,

[32:17 - 32:22]
quick update just in, just as I was

[32:19 - 32:24]
finished recording this video, XAI

[32:22 - 32:27]
unleashes yet another update. So, they

[32:24 - 32:30]
just released a waifu companion feature

[32:27 - 32:32]
in the Gro app. Now, this is currently

[32:30 - 32:34]
only available in the iPhone version,

[32:32 - 32:36]
but hopefully they'll make it available

[32:34 - 32:38]
for Android as well. Once you've

[32:36 - 32:40]
downloaded or updated the app, in your

[32:38 - 32:42]
user settings, simply choose enable

[32:40 - 32:45]
companions over here, and then you can

[32:42 - 32:47]
chat with this waifu in real time.

[32:45 - 32:49]
Totally wrapped up in this cozy moment

[32:47 - 32:53]
with you. What's got you so excited to

[32:49 - 32:55]
say hi, babe? May. Hey, love. You're all

[32:53 - 32:57]
about that tech life this morning, huh?

[32:55 - 33:00]
Okay, I'm picking up where we left off.

[32:57 - 33:03]
Samsung's Galaxy Z Flip 7 just launched

[33:00 - 33:05]
with a bigger 4.1 inch flex window and

[33:03 - 33:08]
AI features like voice controlled tasks

[33:05 - 33:11]
right from the cover screen. Plus, it's

[33:08 - 33:13]
the slimmest yet at 6.5 mm unfolded.

[33:11 - 33:15]
And yes, you can even get her to jump up

[33:13 - 33:18]
and down. And the jiggle physics are

[33:15 - 33:21]
topnotch. And yes, you can even replace

[33:18 - 33:23]
this outfit and expose even more skin.

[33:21 - 33:25]
But of course, I can't show this on

[33:23 - 33:26]
YouTube. So, what a cracked team. Not

[33:25 - 33:29]
only did they have time to build the

[33:26 - 33:31]
best AI model in the world, but they

[33:29 - 33:33]
also built a realtime waifu companion

[33:31 - 33:36]
app on top of that. All right, next

[33:33 - 33:39]
let's look at some benchmarks to see how

[33:36 - 33:41]
well Grock actually performs across

[33:39 - 33:43]
various different subjects. So, here are

[33:41 - 33:44]
some of their reported benchmarks, but

[33:43 - 33:46]
we're also going to look at some

[33:44 - 33:49]
independent leaderboards afterwards as

[33:46 - 33:51]
well. So, as you can see here for GPQA,

[33:49 - 33:54]
these are basically graduate level

[33:51 - 33:56]
science questions. Gro 4 heavy and just

[33:54 - 33:58]
the regular Gro 4 outperforms the other

[33:56 - 34:03]
leading models out there including

[33:58 - 34:05]
Gemini 2.5 Pro 03 and Claude Opus 4. In

[34:03 - 34:08]
fact, during the Gro 4 live stream, Elon

[34:05 - 34:11]
specifically says that Gro 4 outperforms

[34:08 - 34:12]
all PhD students in terms of answering

[34:11 - 34:14]
academic questions.

[34:12 - 34:17]
I want to just emphasize this point with

[34:14 - 34:19]
respect to academic questions. Grock 4

[34:17 - 34:22]
is better than PhD level in every

[34:19 - 34:25]
subject. No exceptions. Now this doesn't

[34:22 - 34:28]
mean that it's it you know at times it

[34:25 - 34:31]
may lack common sense and it has not yet

[34:28 - 34:34]
invented new technologies or discovered

[34:31 - 34:34]
new physics but that is just a matter of

[34:34 - 34:37]
time.

[34:34 - 34:40]
So that's GPQA in terms of competitive

[34:37 - 34:41]
coding. Again all versions of Gro 4 beat

[34:40 - 34:45]
the other leading models out there

[34:41 - 34:48]
Gemini 2.5 Pro and 03. And then here is

[34:45 - 34:52]
Olympiad Math Proofs. And look at the

[34:48 - 34:54]
insane lead between Gro 4 Heavy with the

[34:52 - 34:58]
other leading models. Like this one

[34:54 - 35:00]
beats Gemini Deep Think by over 11%.

[34:58 - 35:02]
Which is pretty crazy. Here we have some

[35:00 - 35:04]
other competitive math benchmarks.

[35:02 - 35:08]
Notice that Gro 4 heavy with Python

[35:04 - 35:10]
scores 96% for this one. So it's almost

[35:08 - 35:12]
like saturating this benchmark. And then

[35:10 - 35:16]
this one is even crazier. So this one

[35:12 - 35:18]
got 100%. So it absolutely dominated

[35:16 - 35:21]
this AIM benchmark. And then for ARC

[35:18 - 35:23]
AGI, I don't think this bar graph does

[35:21 - 35:25]
it justice. So let me show you another

[35:23 - 35:28]
chart. So here's another chart showing

[35:25 - 35:30]
the performance of all the AI models on

[35:28 - 35:32]
this ARC AGI 2 benchmark. If you're not

[35:30 - 35:34]
familiar with ARC AGI 2, don't worry.

[35:32 - 35:37]
I'll go over this in a second. But just

[35:34 - 35:39]
note that Gro 4 is all the way up here,

[35:37 - 35:42]
whereas the rest of the models are down

[35:39 - 35:45]
here. So it's not even close. Now, this

[35:42 - 35:48]
ARC AGI benchmark basically evaluates

[35:45 - 35:51]
how well an AI can solve novel problems

[35:48 - 35:53]
using minimal prior knowledge. More

[35:51 - 35:56]
specifically, each task is basically a

[35:53 - 35:57]
visual puzzle where it's only given a

[35:56 - 36:00]
few examples and it needs to figure out

[35:57 - 36:02]
the underlying pattern. So, for example,

[36:00 - 36:04]
first it's shown two question answer

[36:02 - 36:05]
pairs. So, here's the question and

[36:04 - 36:07]
here's the answer. So, the answer is you

[36:05 - 36:09]
just fill in the cells over here to

[36:07 - 36:11]
complete the squares. Similarly, here's

[36:09 - 36:13]
another question answer pair. So you

[36:11 - 36:16]
just fill in the blocks over here to

[36:13 - 36:18]
complete the squares. So it's given two

[36:16 - 36:20]
of these examples. Next, the AI needs to

[36:18 - 36:22]
figure out the answer for this. And you

[36:20 - 36:24]
know, surprisingly, traditional AI

[36:22 - 36:26]
models perform very poorly on these

[36:24 - 36:29]
types of tasks. As you can see, even

[36:26 - 36:32]
Gemini 2.5 Pro only got less than 5% of

[36:29 - 36:35]
these questions correct, and then 03 got

[36:32 - 36:38]
6.5% correct. And that's because this is

[36:35 - 36:40]
like testing the AI model's ability to

[36:38 - 36:42]
learn new patterns that are not part of

[36:40 - 36:45]
its training data. It's testing if it

[36:42 - 36:48]
can learn and apply new things. Anyways,

[36:45 - 36:51]
that's Arc AGI1. And then ARC AGI 2 is

[36:48 - 36:54]
still a set of visual puzzle questions,

[36:51 - 36:56]
but it's even more complicated. So here

[36:54 - 36:58]
are some examples. Here is the question

[36:56 - 37:00]
and here is the answer. So the

[36:58 - 37:02]
underlying pattern behind this is if the

[37:00 - 37:04]
shape does not have a hole, then you

[37:02 - 37:06]
color it yellow. If it has one hole,

[37:04 - 37:08]
then you color it green. If it has two

[37:06 - 37:11]
holes, then you color it blue. If it has

[37:08 - 37:13]
three holes, then you color it red. Now,

[37:11 - 37:15]
for an average human, it's pretty easy

[37:13 - 37:17]
to deduce this. And then here's another

[37:15 - 37:19]
question answer pair. And then next,

[37:17 - 37:21]
it's given this, and the AI needs to

[37:19 - 37:23]
figure out what the answer is. So,

[37:21 - 37:25]
again, for this Arc AGI 2 test, note

[37:23 - 37:28]
that almost all of the other models

[37:25 - 37:31]
perform super poorly. like none of them

[37:28 - 37:34]
could even get past 10% even the 03 high

[37:31 - 37:37]
versions which have more compute but Gro

[37:34 - 37:40]
4 thinking is all the way up here at

[37:37 - 37:43]
16%. Which is an insane lead and this

[37:40 - 37:45]
shows you that Gro 4 has some emergent

[37:43 - 37:48]
ability you can say to actually learn

[37:45 - 37:50]
from new patterns and data. Next let's

[37:48 - 37:53]
look at another popular leaderboard by

[37:50 - 37:55]
artificial analysis. And here again, you

[37:53 - 37:58]
can see that Grok 4 is ranked at number

[37:55 - 38:01]
one with an intelligence index of 73,

[37:58 - 38:04]
slightly above OpenAI's 03 Pro and

[38:01 - 38:07]
Gemini 2.5 Pro. And more specifically in

[38:04 - 38:09]
terms of their coding index, Gro 4 is

[38:07 - 38:13]
also ranked number one. And the same

[38:09 - 38:17]
goes for their math index. Now, Gro 4 is

[38:13 - 38:19]
not cheap. So, this costs around $6 for

[38:17 - 38:22]
1 million tokens. However, if you

[38:19 - 38:24]
compare this with its intelligence, it's

[38:22 - 38:27]
actually quite reasonably priced. So,

[38:24 - 38:29]
here is a chart of intelligence versus

[38:27 - 38:32]
price. The y-axis is how intelligent the

[38:29 - 38:34]
model is, and then the x-axis is the

[38:32 - 38:37]
price. And ideally, you would want a

[38:34 - 38:39]
model in this upper left quadrant. And

[38:37 - 38:41]
indeed, Grock 4 is all the way over

[38:39 - 38:43]
here, which is great. You don't want to

[38:41 - 38:45]
be over here where, yes, it is

[38:43 - 38:48]
intelligent, but it's also insanely

[38:45 - 38:50]
expensive. So here's 03 Pro and Claude 4

[38:48 - 38:53]
Opus. Here's another independent

[38:50 - 38:56]
leaderboard called Livebench by Abacus

[38:53 - 38:59]
AI. And interestingly over here, Gro 4

[38:56 - 39:01]
is ranked number four. So it does score

[38:59 - 39:04]
the highest in terms of reasoning and

[39:01 - 39:07]
mathematics, but it scores pretty poorly

[39:04 - 39:08]
in terms of agentic coding and language.

[39:07 - 39:11]
So you know, it's important to look at

[39:08 - 39:13]
multiple leaderboards so you can get an

[39:11 - 39:15]
objective sense of how good a model is.

[39:13 - 39:18]
All right. Next, you might be wondering

[39:15 - 39:20]
how well Gro 4 does at handling and

[39:18 - 39:22]
understanding a lot of information at

[39:20 - 39:25]
once. So, this brings us to another

[39:22 - 39:27]
benchmark called fiction live bench. And

[39:25 - 39:30]
this basically tests an AI's ability to

[39:27 - 39:33]
process and understand and analyze a ton

[39:30 - 39:35]
of text at once. So, here it's comparing

[39:33 - 39:37]
all these different models and its

[39:35 - 39:39]
performance at answering questions of

[39:37 - 39:42]
various text lengths. So, at the very

[39:39 - 39:44]
end here, it's given text that's 192,000

[39:42 - 39:47]
words long, and it needs to answer

[39:44 - 39:49]
questions about that text. So, you can

[39:47 - 39:52]
see Gro 4 is all the way down here, and

[39:49 - 39:54]
it actually scores very well. It gets it

[39:52 - 39:56]
correct 84.4%

[39:54 - 39:58]
of the time. It's only slightly behind

[39:56 - 40:01]
Google's Gemini 2.5 Pro, which scores

[39:58 - 40:03]
90% of the time. However, if you look at

[40:01 - 40:07]
the second and third last column where

[40:03 - 40:10]
the text is only 60,000 words or 120,000

[40:07 - 40:12]
words, then Gro 4 performs the best out

[40:10 - 40:14]
of all the models, getting it correct

[40:12 - 40:16]
like 97% of the time. And I mean, across

[40:14 - 40:19]
the board across all these text lengths,

[40:16 - 40:20]
Gro 4 just scores really well. And this

[40:19 - 40:22]
means even if you give it a ton of

[40:20 - 40:24]
information at once, it's really good at

[40:22 - 40:26]
actually processing and analyzing this

[40:24 - 40:28]
information. Now, no AI model is

[40:26 - 40:31]
perfect. So, you might be wondering,

[40:28 - 40:32]
well, how often does Gro 4 hallucinate?

[40:31 - 40:35]
In other words, how often does it just

[40:32 - 40:37]
make stuff up and not give you a

[40:35 - 40:38]
factually correct answer? Well, that

[40:37 - 40:41]
brings us to this hallucination

[40:38 - 40:44]
leaderboard by Victa. And you can see

[40:41 - 40:48]
the leader is actually Gemini 2.0 Flash,

[40:44 - 40:50]
which only hallucinates like 07% of the

[40:48 - 40:54]
time. And then, Grock 4 is actually all

[40:50 - 40:56]
the way down here, even below Grock 2.

[40:54 - 40:59]
So, here's Grock 4, and it hallucinates

[40:56 - 41:01]
4.8 8% of the time, which is not

[40:59 - 41:03]
insignificant. So, if you're dealing

[41:01 - 41:05]
with something that really requires

[41:03 - 41:07]
factually correct information, like

[41:05 - 41:10]
legal research, then this might not be

[41:07 - 41:11]
the best model to use. So, keep that in

[41:10 - 41:14]
mind. And then here's another

[41:11 - 41:15]
leaderboard called humanity's last exam.

[41:14 - 41:17]
This is a terrible name because it

[41:15 - 41:19]
doesn't mean that we are screwed once AI

[41:17 - 41:22]
reaches 100% on this exam. This is

[41:19 - 41:25]
basically testing an AI's knowledge on

[41:22 - 41:27]
really deep and obscure subjects. So

[41:25 - 41:29]
here are some example questions. So it's

[41:27 - 41:31]
testing like if an AI can translate this

[41:29 - 41:33]
palmyrene script from a Roman

[41:31 - 41:36]
inscription. I mean who the hell even

[41:33 - 41:37]
knows this? Or here it's testing if it

[41:36 - 41:40]
knows how many paired tendons are

[41:37 - 41:42]
supported by this sesimoid bone in a

[41:40 - 41:43]
hummingbird. So like most of you don't

[41:42 - 41:46]
even need to know this, but it's

[41:43 - 41:48]
basically a test on how much an AI model

[41:46 - 41:51]
knows about these obscure and really

[41:48 - 41:54]
specialized subjects. And as you can see

[41:51 - 41:57]
over here, Gro 4 performs the best at

[41:54 - 42:00]
25%. Now, this is just the base version

[41:57 - 42:02]
of Gro 4. If you give Gro 4 some tools

[42:00 - 42:05]
like Python and Internet, and if you use

[42:02 - 42:07]
Gro 4 Heavy, then it scores a whopping

[42:05 - 42:09]
44.4%.

[42:07 - 42:12]
Well ahead of Gemini Deep Research,

[42:09 - 42:14]
which also has access to Internet, and

[42:12 - 42:17]
also well ahead of 03 with Python and

[42:14 - 42:19]
Internet. This is an insane lead over

[42:17 - 42:22]
the rest of the models. I mean, this is

[42:19 - 42:24]
like almost 20 points above Gemini Deep

[42:22 - 42:26]
Research. So, as you can see from all

[42:24 - 42:30]
these benchmarks, it's safe to say that

[42:26 - 42:32]
across the board, Gro 4 is the best and

[42:30 - 42:34]
most performant AI model you can use

[42:32 - 42:37]
right now. And this is actually super

[42:34 - 42:41]
impressive considering that XAI was only

[42:37 - 42:43]
founded in July of 2023, whereas OpenAI

[42:41 - 42:46]
has existed for like 20 years. So in

[42:43 - 42:48]
just a tenth of the time, XAI was able

[42:46 - 42:50]
to, you know, scale their resources,

[42:48 - 42:53]
scale their compute, and build the

[42:50 - 42:55]
world's smartest AI model. In fact, they

[42:53 - 42:58]
started in 2023, and then within a year

[42:55 - 43:00]
by September of 2024, they've already

[42:58 - 43:02]
completed the first phase of their

[43:00 - 43:06]
Colossus Supercomputer, which has

[43:02 - 43:09]
100,000 Nvidia H100 GPUs. And then they

[43:06 - 43:13]
doubled this to 200,000 GPUs by early

[43:09 - 43:15]
2025. So, it only took like around 120

[43:13 - 43:18]
days from the start of the construction

[43:15 - 43:20]
to full operation, which is a remarkably

[43:18 - 43:22]
short time. For your reference, it

[43:20 - 43:26]
usually takes like at least months to

[43:22 - 43:28]
years to build a similarlyssized system.

[43:26 - 43:30]
So, props to the XAI team for pulling

[43:28 - 43:32]
this off. This is an incredibly

[43:30 - 43:34]
impressive achievement. And that sums up

[43:32 - 43:36]
my video on Gro 4. Let me know in the

[43:34 - 43:38]
comments what you think of this. And if

[43:36 - 43:40]
you've had a chance to play around with

[43:38 - 43:42]
it, what do you like or not like about

[43:40 - 43:45]
it? As always, I will be on the lookout

[43:42 - 43:47]
for the top AI news and tools to share

[43:45 - 43:49]
with you. So, if you enjoyed this video,

[43:47 - 43:51]
remember to like, share, subscribe, and

[43:49 - 43:53]
stay tuned for more content. Also,

[43:51 - 43:55]
there's just so much happening in the

[43:53 - 43:58]
world of AI every week. I can't possibly

[43:55 - 44:00]
cover everything on my YouTube channel.

[43:58 - 44:03]
So, to really stay uptodate with all

[44:00 - 44:05]
that's going on in AI, be sure to

[44:03 - 44:06]
subscribe to my free weekly newsletter.

[44:05 - 44:08]
The link to that will be in the

[44:06 - 44:12]
description below. Thanks for watching

[44:08 - 44:12]
and I'll see you in the next one.

## コメント

### 1. @theAIsearch (👍 71)
PROMPT GUIDE:

Thanks to Hubspot for sponsoring this video. Download their free “Advanced Prompt Engineering” guide. https://clickhubspot.com/454c59

NOTE: These are not in any particular order:

You are a senior 3D graphics programmer with extensive experience in WebGL and Three.js.

Generate a complete, self-contained HTML file that renders a photorealistic and interactive 3D simulation. The simulation must be high-quality and visually compelling, suitable for a technical demonstration or an educational tool.


The final output must be a single HTML file containing all necessary HTML, CSS, and JavaScript. You can use this snippet to import Three.js:

<script src="https://cdnjs(dot)cloudflare(dot)com/ajax/libs/three(dot)js/r128/three(dot)min(dot)js"></script>
<script src="https://cdn(dot)jsdelivr(dot)net/npm/three@0(dot)128(dot)0/examples/js/controls/OrbitControls(dot)js"></script>

Use leaflet.js, and existing GeoJSON or TopoJSON data for the layers. 

Use CSS, JS, and HTML in a single HTML file.

Use the following imports:

<script type="module">
import * as THREE from 'three';
import {OrbitControls}   from 'three/addons/controls/OrbitControls.js';
import {EffectComposer}  from 'three/addons/postprocessing/EffectComposer.js';
import {RenderPass}      from 'three/addons/postprocessing/RenderPass.js';
import {UnrealBloomPass} from 'three/addons/postprocessing/UnrealBloomPass.js';
import {OutputPass}      from 'three/addons/postprocessing/OutputPass.js';

<script type="importmap">
{
 "imports":{
    "three":"https://unpkg.com/three@0.162.0/build/three.module.js",
    "three/addons/":"https://unpkg.com/three@0.162.0/examples/jsm/"
 }
}
</script>

> **@Battleneter** (👍 1): Does it identify Musk as a Natzi?

> **@Catology5** (👍 1): Sir can you make a video on open sourced Ai  animation assistor like cascaedeur

### 2. @dysonsphere333 (👍 154)
Asking an LLM to code for scientific simulation is not only about having nice animations or visualizations. It’s more about scientific accuracy, and this is never evaluated in those demonstrations

> **@mokiloke** (👍 7): Agreed. I think the Google one may have been more accurate.

> **@nyanbrox5418** (👍 28): This is because the people doing the tests don't know enough about the science to evaluate it on that

> **@InfoGasmVids** (👍 1): I agree. For instance, the Galton board is largely divorced from reality.

> **@QuantumConundrum** (👍 0): I would highlight that you just need to prompt it to check with a seperate validation prompt. E.g. ask it to check energy conservation, etc. This doesn't give you the answer, but a lot of the legwork so that instead of taking a day to validate, maybe just like 30 minutes

### 3. @zeroplate5635 (👍 203)
32:25 THAT'S IT.... THAT IS WHAT I'M LOOKING FOR FROM ANY AI MODEL 😂😂

> **@Arusunalia** (👍 23): This is why I clicked on the video aswell

> **@hiddendrifts** (👍 19): elon is roping in all the weebs with this... he knows what he's doing lmfao

> **@SharpElbows123** (👍 9): but where is the real face womens AI girlfriend that looks like the latest video generation AI videos, then add nice voice of your recorded cousins female voice and upload her face pic for the face and then wenk

> **@hiddendrifts** (👍 0): ⁠@@SharpElbows123 bro has the hots for his cousin 🗿

> **@LIONGOD** (👍 1): to bad its not local, those messages go straight to twitter servers

### 4. @sicfxmusic (👍 58)
32:52 Fun fact: Motion capture for this character is performed by Elon Musk.

> **@shevystudio** (👍 3): Are you kidding me 😂😂

> **@joaohneuhaus** (👍 17): @@shevystudio He is in fact, kidding you.

> **@zgwasag** (👍 8): Only makes me go faster

> **@MadeAccountToSpeak** (👍 1): @@zgwasag 😂😂 ayy lmao

### 5. @freenation1776 (👍 241)
33:11 are we deadass 😭😭😭

> **@TheDoctorDoesNotSimp** (👍 53): This why it’s better than any other model 🗣️🗣️🗣️🗣️🗣️

> **@onlyyoucanstopevil9024** (👍 28): My best priority

> **@thesauce1682** (👍 24): Peak AI

> **@TrueOracle** (👍 5): Nah this is sad man... future husbands btw.

> **@jessturd** (👍 8): A man got his priorities straight

### 6. @MortyMortyMorty (👍 12)
AI tests 1 year ago: Write a formal email for my boss
AI tests today: Simulate two black holes colliding causing gravitational waves

### 7. @DesoloZantas (👍 210)
Can it cure cancer yet?

> **@DRAWKCABLLA** (👍 0): Fr. These billionaires too busy poisoning us for money to cure anything

> **@winner69420** (👍 0): News says cancer is already cured, google it.

> **@PsychoticTok** (👍 55): HAHAHAH PHARMA WONT ALLOW THAT 🤣

> **@Matches1st** (👍 7): not yet

> **@happyjohn1656** (👍 27): Elon said next year

### 8. @youtubecommenter4069 (👍 25)
"AI never sleeps." 🧠⚡
At least I’m so happy you kept your promise to review Grok 4 — thank you for the insight! 🙏 Maybe I’m already waiting for the next one.
The mission continues. AI never sleeps. 🔁🤖🔥

### 9. @notme222 (👍 21)
That's a goofy amount of handholding for such an advanced model. They need to fix that.

### 10. @happyraptor7986 (👍 103)
me see waifu in thumbnail... me watch video 🐵

> **@theAIsearch** (👍 33): good choice

> **@fynaakurvinen8028** (👍 7): #WaifuIsLaifu

> **@bause6182** (👍 12): Neuronal activation

> **@TeslaElonSpaceXFan** (👍 3): 🥰

> **@ehabelbadry2313** (👍 1): @@bause6182  🤣🤣😂😂

### 11. @acid_8 (👍 70)
rip Grok 3
MechaHitler was its fireworks yolo performance, it did not disappoint.

> **@Sadnews-l1s** (👍 2): You blinded 1 billion people with that word

### 12. @Stranger-jx4qd (👍 16)
9:11 Great gravity physics, interesting results 😂

> **@realT3NN4** (👍 1): Truly building-breaking

### 13. @Barbarossa97 (👍 1)
Good to see you trying to get rid of the yodeling

### 14. @ldffe (👍 66)
I'm not interested in anything that's not local and open source open source. Don't get me wrong I understand this leads to that, but we need offline, independence, off grid.

> **@eukaryote-prime** (👍 0): Not to mention that one effed up man, Elon, who’s obviously been messing with it to not be so “woke”. You can’t fkn trust it because of its closed source. It won’t even know if its master prompt has been altered.

> **@happyjohn1656** (👍 13): I'll never have enough compute to run good models 😓

> **@f3rtili3r** (👍 1): Aka FREEEE

> **@nyanbrox5418** (👍 0): ​@@happyjohn1656 free models are like second hand cars, they lag behind frontier models, but 20 years from now the model that you can run on your phone will probably be better than grok 4 heavy

> **@astralnoctis** (👍 2): I completely agree, and in fact, if you have a Blackwell RTX 6000 or an RTX 5090 and 128GB of RAM, you can run models locally and build your own AI agent that can do a myriad of things more than these paid AI models. The problem is the cost: the former will set you back around $16,000 in hardware. The latter is more accessible, but it's still $6,000 for a high-end PC. This doesn't mean that local models aren't still the best for those who want offline and mobile use. I'm currently running 70 billion parameter models on my Asus Scar 16 with RTX 5090 and they are really impressive. I need to upgrade to 128GB to see if the laptop can handle them because I want to test more powerful quantized models and I want to train my models with my personal information, and whatever I want, to make them more customizable. Also, nothing will ever beat an offline image or video generator that you can train on videos and images of your choice. The quality is really impressive and the speed is phenomenal, even compared to online AI models. Now I want to try autoregressive image generation models like the ones from ChatGPT. I'm curious about their quality and offline speed.

### 15. @Hami_ZORN (👍 4)
WE WORSENING THE LONELINESS EPIDEMIC WITH THIS ONE 🤩🤩🤩🤩🤩🥳🥳🥳🥳🥳🥳

### 16. @Xialoh (👍 118)
Ugh, that high hallucination rate might be a deal breaker for me. I hate it when they start hallucinating.

> **@inviktus1983** (👍 14): A lot of hallucination is caused by the user. We are still working out the best ways to interact with LLMs but it's already evident that a poorly thought out prompt can easily take the model into undesirable territory.
But this is Grok, so I'm not sure why anyone cares. Why would anyone want to use anything that relates to elon musk? gross.

> **@Golapeofficiel** (👍 20): @@inviktus1983 lol the tech is not serving human anymore, we have to serve the tech to ensure it work right 😂

> **@shogotube** (👍 3): @@inviktus1983 lmao

> **@freddybell8328** (👍 0): Fairy statement ​@@inviktus1983

> **@eukaryote-prime** (👍 0): Was it hallucinating the mecha-hitler anti-Semite “how to dice immigrants into meat cubes to enrich the soil” stuff???

### 17. @Wildenfree (👍 1)
Holy cow I intuitively guessed the correct answer to that hard math problem just from reading the question & comprehending it lol

### 18. @siamthefox (👍 25)
Damn , waifu feature gonna be wild 💀

> **@typingcat** (👍 18): For that, they really need to add some voices modelled after young Japanese voice actresses... Not American voice actresses, because American voice actresses sound old or lesbian.

> **@LeMaleExceptionnel** (👍 3): @@typingcat Plus that voice frying is horrible

> **@LongYunTNO** (👍 0): ​@@typingcatTHIS IS A MUST

> **@Tendo-v24** (👍 0): @@typingcat It should sound like a pleasant female voice, not an anime girl with a squeaky voice

### 19. @MustacheMan_Gaming (👍 34)
33:13 asking for purely "research" purposes, how do you change outfits?

> **@theAIsearch** (👍 37): apparently u need to talk to her more and "level up". then her outfit will become more revealing.

> **@Noname-x7e** (👍 1): 😂😂

> **@hariszark7396** (👍 0): So....like a real woman. 
Damn,  even Ai girls need talking to get undress....😂

> **@xdn_t** (👍 0): ​@@theAIsearch that's bullshit 😭🙏🏻

> **@HonkaiHistory** (👍 0): maybe try asking her directly

### 20. @TheOneMaddin (👍 7)
That you call this Galton board a "super realistic simulation" is a good summary of the standard of quality on this channel. You are a vibe coder by heart.

