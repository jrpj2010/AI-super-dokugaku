# ZettelkastenとObsidianを使ったAI・Techトピックの学習法

## 概要
本動画は、Mischa van den Burg氏が自身の**Zettelkasten**（セトルカステン）ノートテーキングシステムを使ってAIやTechトピックを学習し、知識を管理する具体的なプロセスを実演するものです。手書きのメモを**Obsidian**に取り込み、自分の言葉で整理し、関連するノートとリンクさせる方法を紹介。特にAIの定義や関連概念（機械学習、ディープラーニング）の理解を深める過程を示し、**Claude**のようなAIツールを学習補助に活用する例も示されています。このメソッドは、時間をかけて質的に深い理解を得ることで、知識を定着させ、将来の執筆などに応用できるメリットを強調しています。

## 主要なポイント
- **Zettelkasten**メソッドは、情報を単に保存するのではなく、自分の言葉で処理し、構造化することに重点を置く。
- **Obsidian**は、ノート間のリンクやグラフ表示機能により、**Zettelkasten**システムの実装に適している。
- メモを処理する際は、オリジナルの情報源と自分の言葉での表現を比較検討することが重要。
- **AI**ツール（例: **Claude**）は、複雑な概念の理解を助ける教師として活用できる。
- ゆっくり時間をかけ、深く思考することが、長期的な知識定着と学習速度の向上につながる。

## 詳細内容

### 導入：ZettelkastenとAI学習 [00:00:00]
動画の冒頭で、Mischa氏は彼のノートテーキング動画への反響として、**Zettelkasten**システムを実際にどのように構築・運用しているのかという質問が多いことを述べます。現在AIを学習しており、その学習過程で使用しているメモを処理しながら、具体的なシステムへの組み込み方を見せると説明します。これは4000件以上のメモを含む彼のシステムを舞台裏から見せる機会であるとしています。
Mischa van den Burg [00:00:00] - [00:38:41]

### ノート処理の具体的なプロセス [00:42:00]
AIに関する書籍（物理版とPDF版）を読みながら手書きしたメモを元に、**Obsidian**で新しいノートを作成し、処理する手順を実演します。理想的には読書後すぐにメモを処理すべきだが、忙しさのためメモが溜まってしまっている状況から始めます。
Mischa van den Burg [00:42:00] - [01:49:00]

#### レイ・カーツワイルのシンギュラリティ定義の処理 [01:51:00]
最初のメモとして、**Ray Kurzweil**によるシンギュラリティの定義を取り上げます。「AIが人間の知能に到達し、自己学習と自己改善によりそれを超えること」という手書きメモを基に、**Obsidian**で新しいノートを作成します。ノート名は「Ray Kurzweil's Definition of Singularity」とします。書籍のPDFで元の文章を確認し、自分のメモが元の意味を保ちつつ、自分の言葉で表現されていることを確認します。**Zettelkasten**メソッドの鍵は、単なる引用ではなく、自分の言葉で思考を整理することにあると強調します。出典として書籍のページ番号を含めることで、後で参照可能にします。Singularityという既存の概念に関するノートへのリンクを作成します。
Mischa van den Burg [01:51:00] - [07:32:00]

#### AIの定義に関するメモの処理 [07:34:00]
次に、AIの定義に関するメモを処理します。基礎から学ぶ上で定義が重要であると考え、既に存在する「Artificial Intelligence」というインデックスノートに「定義」セクションを追加します。AIという用語がJohn McCarthyによって1956年に発明されたというメモを処理し、これもAIインデックスノートに追加します。McCarthy自身については深掘りしないため、独立した人物ノートは作成しません。AIの公式な定義として「知能を統合することによって知能の特性を研究するコンピュータサイエンスの一分野」という書籍からの引用をノートに追加します。この引用は委員会の報告書からのものであるため、そのまま引用として使用することが適切であると考えます。出典として報告書のリンクも追加します。
Mischa van den Burg [07:34:00] - [20:42:00]

#### 機械学習とディープラーニングの区別の処理 [20:45:00]
AIの定義に続き、機械学習とディープラーニングの区別に関するメモを処理します。著者が大衆メディアでのAIとディープラーニングの混同を指摘している点をノートに反映させます。AIが「知能を持つ機械を作ることを目標とした分野」であること、ディープラーニングが「機械学習の分野における多くの方法の一つ」であることを自分の言葉で整理し、ノートを作成します。機械学習は「機械がデータや自身の経験から学習するAIのサブフィールド（分野）」と定義し、関連ノートを作成します。
Mischa van den Burg [20:45:00] - [35:16:00]

#### AIツール（Claude）を使った概念理解の深化 [35:16:00]
機械学習の定義に出てくる「経験」という言葉に引用符がついている点に注目し、その意味を理解するために**Claude**（AIチャットボット）に質問します。**Claude**は、機械の「学習」や「経験」が人間のそれとは異なり、統計的パターン認識やデータ処理であることを示唆するために引用符が使われていると説明します。これは、人間的な言葉を使って計算的なプロセスを説明する際の認識論的謙虚さであると**Claude**が解説します。Mischa氏は、**Claude**のこの説明が非常に有用であり、AIツールを「教師」として活用する例として示します。この**Claude**との対話内容も、必要に応じてノートに追加することで、概念理解の深化を記録します。
Mischa van den Burg [35:16:00] - [43:00:00]

### ノートシステムの構造化と視覚化 [43:08:00]
作成した個別のノートをシステム内で構造化する方法を示します。日々のメモを起点とし、AIインデックスノート、そして読んでいる書籍の入力ノートに、新しい個別ノートをリンクさせます。これにより、情報の発生源（書籍、日付）から関連するトピック（AI、機械学習）へと辿れるようになります。**Obsidian**のローカルグラフ機能やExcaliBrainプラグインを使って、ノート間の関連性や構造を視覚的に確認できる利点を説明します。これは、知識間のつながりを発見し、理解を深めるのに役立ちます。
Mischa van den Burg [43:08:00] - [48:41:00]

### Zettelkastenメソッドの哲学と効果 [20:59:00] (繰り返し)
動画全体を通して、**Zettelkasten**メソッドは急いで行うものではなく、時間をかけて深く思考するプロセスであると繰り返し強調されます。ゆっくりと時間をかけて自分の言葉で情報を処理することが、表面的な理解ではなく、同僚よりも遥かに速く（10倍速く）深く学習できる鍵であると述べます。このシステムを通じて整理された知識は、将来の執筆活動（ブログ記事、エッセイなど）に直接活用できるリソースとなります。
Mischa van den Burg [20:59:00] - [21:40:00], [33:29:00] - [33:34:00], [41:01:00] - [41:18:00]

## 結論
Mischa氏は、**Zettelkasten**メソッドと**Obsidian**、そしてAIツールを組み合わせることで、AIやTechといった複雑なトピックを効率的かつ深く学習できることを示しました。重要なのは、情報を自分の言葉で咀嚼し、関連付け、時間をかけて知識を構造化することです。これにより、単なる情報の蓄積ではなく、生きた知識システムを構築し、将来の創造的な活動やキャリアに活かすことが可能になります。
Mischa van den Burg (まとめとして動画の内容全体から抽出)

---

# How I Use Obsidian Zettelkasten to Study AI & Tech Topics

**チャンネル:** Mischa van den Burg
**公開日:** 2024-11-07
**URL:** https://www.youtube.com/watch?v=L2z7j7Jho4E

## 説明

Want to become a highly-paid DevOps engineer? Go here: https://www.skool.com/kubecraft
Want FREE DevOps courses? Go here: https://www.skool.com/mischa

If you're new to my channel, I'm Mischa van den Burg. I help ambitious professionals break into tech and scale their DevOps careers. Our community brings together over 400 paying members who are transforming their careers in tech.

How I got here...

28 yrs old: Left my nursing career to start from scratch in tech
29 yrs old: Taught myself DevOps while working full-time
30 yrs old: Landed my first junior DevOps position in just 6 months
31 yrs old: Doubled my salary by securing my first consulting role
32 yrs old: Built an advanced Kubernetes homelab, started sharing online
33 yrs old: Became a Microsoft MVP, grew to 34,000+ YouTube subscribers
34 yrs old: Built the fastest-growing DevOps community on Skool
Today: Running multiple 6-figure DevOps contracts while teaching others

Our community now has:

• 400+ paying members
• 40+ hours of premium courses
• 92% success rate in career transitions
• Members doubling their salaries in less than 12 months

Want proof this works? Google me. 
Check my GitHub (400+ stars). 
Look up my Microsoft MVP status.
Thousands of 5 star reviews on several platforms.

To all the career changers and ambitious engineers: Your past doesn't determine your future. I went from nurse to highly-paid DevOps consultant in 18 months. The worse the struggle, the better the comeback.

You either level up your career or get an epic story trying. Both mean you win.

Keep building,

Mischa

FULL DISCLOSURE

I create content to build trust with ambitious professionals. The best ones join our premium community, where we help them accelerate their careers. Simple as that.

## 字幕

[00:00 - 00:04]
私のメモ動画に最も多く寄せられるコメントは、

[00:04 - 00:08]
実際にどのようにやっているのか、

[00:06 - 00:10]
セトルキャストノートをどのように作成し、どのように

[00:08 - 00:12]
システムに実装するのかというものです。そこでこの

[00:10 - 00:14]
動画では、具体的な例を挙げて説明します。

[00:12 - 00:16]
私は現在人工知能を勉強していて、

[00:16 - 00:21]
この本を読んでいます。この本を読み

[00:19 - 00:24]
ながら取ったメモを処理していきます。

[00:21 - 00:25]
その

[00:24 - 00:28]
ため、時間をかけて、私がどのように、そしてどれくらい時間をかけて処理しているのかを正確にお見せします。

[00:28 - 00:33]
これは、現在4,000件のメモが収録されている

[00:33 - 00:38]
ミシャのtcasとシステムで実際に何が行われているのか、舞台裏を覗くチャンスです。

[00:42 - 00:47]
それでは早速見ていきましょう。ご覧の通り、私は物理的なコピーを持っていて、それで

[00:44 - 00:50]
読みましたが、PDF版も購入しました。

[00:47 - 00:54]
これは

[00:50 - 00:57]
すべて合法です。

[00:54 - 01:00]
購入したので、内容の一部をお見せしながら進めていきます。

[01:05 - 01:11]
人工知能の重要な概念を理解してもらうことが非常に重要だからです。  TCASの知能についてです。

[01:08 - 01:13]
ええと、人工知能について学んでいるので、

[01:11 - 01:16]
この

[01:13 - 01:19]
本を読んでいて、最初はこの小さなノートにメモを取り

[01:16 - 01:21]
、その後

[01:19 - 01:25]
別のノートにメモを取りました。

[01:21 - 01:28]
普段なら、

[01:25 - 01:30]
同じ日か翌日に処理するのですが、ここ

[01:30 - 01:35]
数週間は非常に忙しく、

[01:34 - 01:37]
夜に少しだけ

[01:35 - 01:40]
読書をする時間があったので、

[01:37 - 01:43]
読書とメモを取ることを優先しました。つまり、積み重なったメモを整理しているところです。

[01:43 - 01:49]
理想的には

[01:46 - 01:51]
同じ日に終わらせたいので、これを読みながら

[01:49 - 01:54]
どれだけ記憶が鮮明かは分かりませんが、まあ、始めましょう。

[01:51 - 01:58]
これが私がメモ

[01:54 - 02:01]
したメモです。

[01:58 - 02:04]
まずは

[02:01 - 02:07]
最初の

[02:04 - 02:11]
メモから始めましょう。レイ・カーツは

[02:07 - 02:14]
シンギュラリティの定義として、「AIが

[02:11 - 02:15]
人間の知能に到達し、それを超えること。

[02:15 - 02:18]
自己学習によって、自律的に学習し

[02:17 - 02:21]
、

[02:18 - 02:23]
自己改善することで実現する」と書いています。これが

[02:21 - 02:25]
私が最初に思いついたことです。 まず

[02:23 - 02:29]
最初に、

[02:25 - 02:31]
この

[02:29 - 02:35]
Settle Casting Systemのすべてが

[02:31 - 02:39]
モジュール性、つまりモジュラーノードに関するものなので、

[02:35 - 02:41]
Obsidianかコマンドラインから始めることができます。簡単に始めるには

[02:41 - 02:47]
Obsidianから始めます。

[02:43 - 02:50]
新しいノードを作成します。これは

[02:47 - 02:52]
Ray

[02:50 - 02:55]
CordtsのSingularityの定義に関するメモです。Ray

[02:52 - 03:01]
Cordts

[02:55 - 03:01]
WildsのSingularityの定義、つまり

[03:02 - 03:08]
メモの名前です。

[03:05 - 03:11]
また、

[03:08 - 03:14]
キーを表示して、操作中に

[03:11 - 03:16]
どのキーを押したかを確認できるようにしておくといいでしょう。さあ、これで何を

[03:18 - 03:26]
しているのかわかるはずです。

[03:22 - 03:28]
ここにあるAppleキーはSuperキーです。Ray CWによる

[03:26 - 03:30]
Singularityの定義です。既に間違いを犯してしまいましたね。わかりました。では、Ray CSWによるSingularityの定義を見

[03:30 - 03:37]
てみましょう。AIが人間の

[03:34 - 03:37]
知能に

[03:43 - 03:48]
到達し、それを超えるとき、

[04:05 - 04:10]
これは私がノートに書き留めたメモです。AIが

[04:10 - 04:15]
人間の知能に到達し、それを超えるとき、

[04:12 - 04:18]
自律学習と

[04:15 - 04:21]
自己改善によって駆動されます。私はいつも

[04:18 - 04:24]
自分の 自分の言葉でメモしています。常に

[04:21 - 04:27]
自分の言葉ですが、

[04:24 - 04:31]
似たような言葉がないわけではありません。

[04:27 - 04:35]
ここで自分の本を開いて、

[04:31 - 04:39]
Ray または Kurts を検索してみてください。

[04:35 - 04:42]
これは元の引用です。Ray

[04:42 - 04:49]
Kurtwell のシン

[04:45 - 04:51]
ギュラリティのビジョン、つまりAIが

[04:51 - 04:56]
自律的に学習し、改善する能力によって強化され、人間の知能に急速に到達し、そしてそれを

[04:54 - 04:57]
超えるというものです。まあ、そのまま引用します。

[04:57 - 05:06]
上は私の

[05:02 - 05:10]
メモ、下は元のテキストです。ここで

[05:06 - 05:14]
私が

[05:10 - 05:16]
行った変更点の一つは、

[05:14 - 05:19]
最後に「

[05:16 - 05:21]
人間の知能を超える」と書く代わりに、「

[05:19 - 05:24]
AIが自律的に学習することで人間の知能に到達し、それを

[05:21 - 05:25]
超える」と書きました。

[05:25 - 05:31]
ここでは「

[05:34 - 05:42]
自律的に学習し、

[05:38 - 05:45]
自己改善する能力によって強化される」と書きました。つまり、同じ意味を保ちながら、自分の言葉で表現したということです。

[05:45 - 05:52]
自分の言葉で表現することで、自分の考えが

[05:49 - 05:55]
より

[05:52 - 05:58]
明確になります。 考えてみると、これが

[05:55 - 06:02]
ttle Castenメソッドの重要な点です。

[05:58 - 06:05]
ただこれを

[06:02 - 06:08]
コピーしてシステムに取り込んで終わり、それで

[06:05 - 06:09]
終わり、といったことは全く価値がありません。

[06:08 - 06:14]
例えば、後で使える素敵な引用文があるかもしれません

[06:09 - 06:17]
が、それは価値がありません。これは

[06:14 - 06:21]
価値があります。なぜなら、これは

[06:17 - 06:24]
後で自分の文章に使えるメモだからです。

[06:21 - 06:26]
自分の文章として使うことができます。

[06:26 - 06:30]
これらのメモをいくつかつなぎ合わせる必要があります。エッセイがある

[06:29 - 06:33]
ので、

[06:30 - 06:36]
ここに

[06:33 - 06:39]
使用したページ番号の参照を含めるかもしれません。プロローグのXXページ

[06:39 - 06:45]
から引用したという参照も含めます。

[06:48 - 06:54]
後でSingularity

[06:51 - 06:57]
の定義をもう一度探したい場合、

[06:54 - 07:00]
どこを見ればよいかがわかります。

[06:57 - 07:03]
これが最初のメモで、このメモに必要なのは

[07:00 - 07:05]
これだけです。

[07:03 - 07:08]
このメモでは、単に

[07:05 - 07:11]
Rord WellのSingularityの定義を記録したいだけです。

[07:08 - 07:13]
今のところは、Singularity

[07:11 - 07:15]
へのリンクを作成すればいいのですが、

[07:15 - 07:20]
実際には

[07:17 - 07:21]
Singularityは私が知っているからです。

[07:20 - 07:23]
他のノートに

[07:23 - 07:29]
もリンクを貼る予定なので、このリンクを作成しました。これでこの

[07:26 - 07:32]
ノードは完了です。

[07:29 - 07:32]
次のノートに進みましょう。

[07:34 - 07:42]
これを読んでいて、実は

[07:37 - 07:44]
AIの定義にとても興味がありました。

[07:46 - 07:52]
私の意見では、すべては定義から始まるべきだと思っています。私は今AIを勉強しています。Kubernetesを

[07:52 - 07:57]
ある程度習得し、必要なことを学び、

[07:57 - 08:01]
必要な用途に使用し、実際に活用できるようになったと感じているからです。

[07:59 - 08:04]
次は人工知能に関する知識を深めたいと考えています。

[08:04 - 08:09]
そのためには、

[08:06 - 08:13]
まずは定義などの基礎から始め

[08:09 - 08:16]
、そこから進めていきます。

[08:13 - 08:20]
既に「人工知能」というノートがあります。これを

[08:20 - 08:26]
開くと、「人工知能」という項目があります。

[08:26 - 08:32]
キーをもう一度表示して、

[08:36 - 08:40]
これが私の人工知能ノートです。

[08:44 - 08:51]
このノートに定義セクションを追加しようと思います。なぜなら、

[08:47 - 08:54]
私はすべてのSettle Castと作業にインデックスノートを使用しているからです。

[08:54 - 09:00]
これをコンテンツのマップと呼ぶ人もいるかもしれませんが、私は

[08:57 - 09:03]
インデックスという用語の方が好きです。

[09:00 - 09:05]
ここに「定義」という新しい見出しを作成し、「

[09:11 - 09:16]
人工

[09:14 - 09:20]
知能の定義」を追加します。さらに、「

[09:16 - 09:24]
AI」という単語も追加します。検索しやすくなるためです。

[09:20 - 09:28]
これを毎日のノードにも追加します。

[09:24 - 09:30]
ご覧のとおり、

[09:28 - 09:32]
これらのノードはすべて毎日のメモから作成しています。

[09:30 - 09:34]
なぜそうするのかは後で説明します。

[09:32 - 09:37]
少しお待ちください。

[09:34 - 09:38]
まずはこれらのメモを処理し、

[09:37 - 09:41]
次に

[09:38 - 09:44]
これらのメモをどのように構造化し、

[09:41 - 09:49]
互いに参照するかを示します。

[09:44 - 09:51]
次のメモは

[09:49 - 09:56]
次のとおりです。これはまさに私が書いたものです。AIという

[09:51 - 09:56]
用語は、…によって発明されました。

[10:40 - 10:47]
さて、これは

[10:44 - 10:50]
私が

[10:47 - 10:53]
ここに書いたメモです。さて、

[10:50 - 10:56]
続けましょう。ここに座って、

[10:53 - 10:59]
そこに書いたことと、それをどのように分解するかを振り返ります。

[10:59 - 11:06]
これで十分だと思います。繰り返しますが、これらは

[11:02 - 11:08]
すべて私の言葉で書かれていますが、

[11:06 - 11:13]
この部分、つまり

[11:08 - 11:16]
このメモを取ったのは

[11:13 - 11:18]
おそらく1、2週間前なので、もう

[11:16 - 11:21]
記憶に新しいものではありません。

[11:21 - 11:26]
これらのメモを

[11:24 - 11:28]
同じ日か翌日に処理する習慣をつけることが非常に重要です。そうすれば

[11:26 - 11:31]
文脈を思い出せるからです。私はもう

[11:28 - 11:34]
文脈をあまり覚えていないので、マッカーシー

[11:31 - 11:37]
についてもう一度読んでみようと思います。マッカーシーについてです。

[11:41 - 11:49]
ここに

[11:44 - 11:52]
マッカーシーについて書かれています。彼は基本的に「

[11:49 - 11:54]
人工知能」という言葉を思いつきました。

[11:52 - 11:57]
マッカーシーは後に、目標が本物だった

[11:54 - 11:59]
後、誰もその名前を気に入らなかったと認めました。「

[11:57 - 12:01]
人工

[11:59 - 12:03]
知能ではない」と。でも、

[12:01 - 12:05]
何か名前をつけなければならなかったので「人工知能」と名付けました。つまり、その

[12:07 - 12:15]
言葉を思いついたのは彼です。ここには、1956年の夏に

[12:12 - 12:17]
10人による2ヶ月間の人工知能研究を実施すると書かれています。「

[12:19 - 12:25]
人工知能」という言葉は

[12:22 - 12:27]
マッカーシーの発明です。ここには

[12:25 - 12:32]
文字通り彼がその言葉を思いついたと書いてあります。だから

[12:27 - 12:35]
私はこうして書き留めたのです。つまり、

[12:36 - 12:44]
この行の出典は基本的に

[12:40 - 12:48]
マッカーシーによって1956年に発明されました。

[12:44 - 12:52]
彼は1960年代初頭にスタンフォードAIプロジェクトを設立しました。

[12:48 - 12:55]
つまり、後のことです。

[12:52 - 12:59]
このMC McCarthyという人物についてメモを作成しようとしたの

[12:55 - 13:01]
ですが、本を読み進めていくうちに、

[12:59 - 13:03]
彼については

[13:01 - 13:06]
あまり触れられなくなりました。

[13:03 - 13:10]
彼についてもっと知りたいとは思っていませんが、

[13:10 - 13:15]
例えばBrian Johnsonのような人物についてはメモを作成しています。その人物についてのメモを作成し

[13:15 - 13:23]
、その

[13:23 - 13:28]
メモからその人物のメモへのリンクを作成したいのですが、今回は

[13:26 - 13:30]
そうする必要はありません。McCarthyは

[13:28 - 13:35]
私にとってそれほど興味深い人物ではないからです。ただ、誰が

[13:30 - 13:37]
その用語を発明したのかを記録したいだけなので、

[13:40 - 13:44]
これで満足しています。この

[13:42 - 13:47]
[Music]の

[13:44 - 13:50]
設定は、

[13:50 - 13:57]
AIの定義がどこから来たのかを示す、すっきりとした文章です。次は

[13:55 - 14:00]
実際の

[13:57 - 14:03]
定義です。ここでは引用符を使用しています。これは

[14:00 - 14:04]
興味深いので、次に[Music]の文書

[14:04 - 14:09]
で実際にどのように表現されているかを見てみましょう。AIとは、

[14:37 - 14:42]
知能を統合することによって知能の特性を研究するコンピュータサイエンスの一分野です。ここでは、

[14:40 - 14:45]
著者が最近の

[14:42 - 14:47]
AIの現状に関する報告書で言及している

[14:45 - 14:49]
委員会について説明しています。 著名な研究者たちは、この

[14:47 - 14:51]
分野を、知能を統合することによって知能の特性を研究するコンピュータサイエンスの一分野と定義しました。

[14:54 - 15:01]
これは本書

[14:56 - 15:04]
でも使われている定義です。

[15:01 - 15:08]
ここでは、

[15:04 - 15:09]
より

[15:09 - 15:14]
詳細に説明されていますが、

[15:12 - 15:16]
著者が立場を明確にして定義を

[15:14 - 15:20]
与えているところです。

[15:16 - 15:22]
この定義は、

[15:22 - 15:30]
私自身の言葉で表現していないことにお気づきかもしれません。Cube

[15:30 - 15:34]
prefコミュニティに参加することで入手できるSettle Castコース（リンクは

[15:32 - 15:37]
下にあります）では、Obsidian

[15:34 - 15:40]
でTtle Castenを作成する方法についての完全なコースを提供しています。

[15:37 - 15:42]
このコースでは、

[15:42 - 15:47]
Ttle Castメソッドの発明者であるNicholas Lumenが引用

[15:45 - 15:50]
符をほとんど使用しないことを強調しました。引用符は控えめに使用すべきです。

[15:47 - 15:53]
私も控えめに使用しています

[15:50 - 15:55]
が、控えめだからといって、決して

[15:53 - 15:59]
使用すべきではないという意味ではありません。

[15:55 - 16:02]
この場合、委員会が

[15:59 - 16:05]
定義を策定しました。

[16:02 - 16:06]
ここでは、その定義の

[16:06 - 16:14]
特定の文言を使用するのは良い判断だと思います。

[16:16 - 16:23]
少し変更しました。省略しました。

[16:19 - 16:26]
少し

[16:23 - 16:29]
ですが、実は今

[16:26 - 16:33]
もう一度見直して、テキスト全体を取り上げたいと思います。

[16:36 - 16:42]
全部書き出したわけではなく、手書きで書きたくなかったので、省略したかもしれ

[16:49 - 16:57]
ません。文脈は、

[16:54 - 17:00]
著名な研究者の委員会が

[17:00 - 17:04]
最近の報告書でこの分野を定義したことです。それで、その報告書の内容を確認しましょう。100e

[17:11 - 17:18]
人工知能に関する研究は興味深いものです。その報告書は

[17:15 - 17:18]
見つかりますか？さて、

[17:38 - 17:43]
これがその報告書です。

[17:40 - 17:48]
出典資料です。

[17:53 - 17:57]
この報告書をここに含めたいのですが、あっ、このリンクを注記に追加しておき

[18:19 - 18:23]
ましょう。出典資料は 100e 人工知能に関する研究から来ているので、このリンクをここに含めます。その名前をコピーして、

[18:27 - 18:33]
文脈を自分で書きます。

[18:34 - 18:45]
著者は、第 6 章で人工知能の定義について立場をとっています。第

[19:26 - 19:30]
6 章の定義と進め方のページです。

[19:35 - 19:38]
著者は、第 6 ページ

[19:36 - 19:43]
で人工知能の定義について立場をとっています。

[19:43 - 19:47]
何と呼ぶか​​知らないけど、

[19:49 - 19:54]
著名な

[19:52 - 19:57]
研究者による研究委員会で、AIの現状に関する最近の報告書で、

[20:02 - 20:05]
彼女が

[20:05 - 20:12]
提示した定義を使って、スタンフォード大学によるAIの

[20:08 - 20:15]
現状に関する報告書で使用されている定義を提示している。100e

[20:15 - 20:22]
人工

[20:19 - 20:24]
知能研究は、知能を

[20:24 - 20:29]
統合することで知能の特性を研究するコンピュータサイエンスの一分野だ。

[20:31 - 20:42]
さて、これを

[20:36 - 20:45]
自分の言葉で表現してみよう。定義そのものについて、

[20:45 - 20:51]
そして彼女がどのように表現したかについて、振り返っている。

[20:49 - 20:53]
おそらく動画はもう10分ほど経過していると思うが、

[20:51 - 20:56]
私はまだ2番目の音符を弾い

[20:53 - 20:59]
ているところだ。苦労して、私が

[20:59 - 21:05]
何をしているかを正確に示している。視聴回数を稼ぐために急いでやっているわけではない。

[21:01 - 21:08]
この

[21:05 - 21:11]
動画は、

[21:08 - 21:15]
私がとても遅いので、おそらくひどい視聴時間になるだろう。しかし、

[21:11 - 21:17]
Settle Castメソッドのポイントは、

[21:15 - 21:20]
ゆっくり進めることだ。急いでやるとうまくいかない。

[21:17 - 21:22]
ここで示しているのは、

[21:20 - 21:26]
私が実際に行っている思考プロセスだ。

[21:31 - 21:35]
深く関わることで、同僚よりも10倍速く学習できる実際のプロセスだ。 ほとんどの人が我慢できない素材を使って、

[21:35 - 21:40]
セトルキャスト法はそれを可能にする手段です。

[21:52 - 21:59]
後で

[21:56 - 22:00]
この定義について考察する他のメモで拡張するかもしれませんが、

[21:59 - 22:02]
今のところこの定義に満足しています。知能を統合することによって知能の特性を研究する

[22:00 - 22:04]
コンピュータサイエンスの一分野のようなもので、これは

[22:08 - 22:13]
基本的に人工知能という

[22:11 - 22:15]
用語の非常に明確で簡潔な定義です。

[22:15 - 22:20]
しかし、後でAIは知能を持つ機械を

[22:18 - 22:22]
作ることを目標とする分野であると書きました。

[22:25 - 22:32]
どこから得たのかを書き留めておけばよかったのです

[22:30 - 22:34]
が、これは

[22:32 - 22:37]
ただのメモで、

[22:34 - 22:40]
私自身の言葉です。

[22:37 - 22:41]
引用はしていません。これは基本的に私自身の言葉です。

[22:41 - 22:46]
おそらくAIの分野は、ええと、

[23:04 - 23:09]
AIは知能を

[23:08 - 23:12]
持つ機械を作ることを目標とする分野です。

[23:20 - 23:26]
ああ、

[23:23 - 23:30]
ここにあります、ここにあります、これは

[23:26 - 23:33]
方法のエンチです。これは

[23:30 - 23:33]
実際には前に出てきたものです。

[23:35 - 23:40]
見てみましょう。

[23:37 - 23:42]
実際、多くの一般的な

[23:40 - 23:46]
メディアでは、人工知能という言葉

[23:42 - 23:48]
自体がディープラーニングを意味するようになりました。

[23:46 - 23:50]
これは残念ながら不正確であり、

[23:50 - 23:56]
区別を明確にする必要があります。AIは

[23:56 - 24:01]
知能を持つ機械を作ることを目標とした幅広いアプローチ、

[23:59 - 24:04]
これが基本的なものです。これが

[24:01 - 24:08]
私たちがやっていることの広い定義です。ディープラーニングは

[24:04 - 24:11]
一つのサブアプローチに過ぎません。ディープ

[24:08 - 24:14]
ラーニング自体は機械学習の分野における多くの手法の一つです。これは

[24:14 - 24:20]
AIのサブフィールドで、機械が

[24:17 - 24:20]
データや自身の

[24:20 - 24:26]
経験から学習します。さて、これは少し後で出てきます。

[24:23 - 24:28]
はい、これが

[24:26 - 24:29]
定義です。

[24:28 - 24:33]
さて、続きは

[24:29 - 24:33]
次章です。

[24:34 - 24:42]
私はこの章が

[24:38 - 24:44]
とても気に入っています。AIについてですが、本当に細かく分けて説明されていて、AIとは

[24:42 - 24:49]
何か、何ではないのかが非常に明確にされています。AIは

[24:44 - 24:51]
分野です。わかり

[24:51 - 24:58]
やすくするために、少し分解してみましょう。

[24:55 - 25:01]
これをコピーして

[24:58 - 25:04]
少し分解します。これが

[25:01 - 25:08]
私が書いたものです。AIは知能を持つ機械を作ることを目標とした分野です。

[25:11 - 25:17]
少し引用しました。

[25:20 - 25:24]
引用を少し省略しているので、ここでは言い換えていると言えます。つまり、自分の言葉で表現しました。つまり、

[25:32 - 25:40]
AI分野の目標は、知能を持つ機械を作ることです。

[25:47 - 25:51]
次の

[25:49 - 25:55]
章で

[25:51 - 25:59]
著者はいくつかの非常に

[25:55 - 26:01]
重要な区別をしています。

[25:59 - 26:06]
彼女は、

[26:01 - 26:06]
大衆

[26:06 - 26:15]
メディアでは「AI」という言葉が

[26:10 - 26:15]
ディープラーニングと同義になっていることを強調しています。これは

[26:22 - 26:27]
残念なことです。そして、

[26:25 - 26:29]
これは

[26:27 - 26:31]
残念な

[26:29 - 26:33]
正確さです。実際、多くの大衆

[26:31 - 26:36]
メディアでは「AI」という言葉自体が

[26:33 - 26:39]
ディープラーニングを意味するようになっています。

[26:36 - 26:42]
これは私が記憶から書きました。

[26:39 - 26:47]
読んだばかりですが、

[26:42 - 26:47]
次の章では少し違う書き方をしました。

[26:49 - 26:53]
章の

[26:51 - 26:58]
名前は「

[26:53 - 26:58]
方法の無秩序」としています。

[27:01 - 27:05]
著者はいくつかの非常に重要な

[27:03 - 27:06]
区別をしています。彼女は、

[27:05 - 27:08]
大衆メディアでは「AI」という言葉が

[27:06 - 27:10]
ディープラーニングと同義になっていることを強調しています。ここでは「

[27:10 - 27:16]
ディープラーニング」を意味するようになったと言っています。

[27:13 - 27:18]
言い方は違いますが、

[27:16 - 27:21]
意味は同じです。これは

[27:18 - 27:23]
私の言葉です。私はこれを

[27:21 - 27:25]
自分の言葉として公開しても著作権を侵害することはありません。まあ、

[27:25 - 27:31]
私は

[27:28 - 27:32]
意味を著者に帰属させているので、作家として行う

[27:31 - 27:35]
必要がある非常に慎重なバランス調整です

[27:32 - 27:37]
が、これは私が

[27:37 - 27:43]
出版準備が整ったかのように書くということです。ニコラス・ルーメンはこうしました。

[27:43 - 27:48]
このように短いメモを書くときは、出版されるかのように書く必要があります。

[27:46 - 27:51]
私が

[27:48 - 27:54]
ここで書いているのは、基本的に

[27:51 - 27:56]
ブログ記事やエッセイの一章分です。

[27:54 - 27:58]
これを完全なメモやリソースとして使うこともできます。

[28:00 - 28:08]
彼女はまたもや

[28:05 - 28:08]
ディープラーニングと同義語になってしまいました。これは

[28:09 - 28:18]
残念なことです。彼女は続けて、

[28:15 - 28:21]
AI分野の目標は

[28:22 - 28:28]
知能を持った機械を作ることだと説明しています。ディープ

[28:25 - 28:30]
ラーニングとは、

[28:30 - 28:38]
ここでは何と呼ぶのでしょうか？彼女は、それはそのようなアプローチの一つに過ぎないと言っています。

[28:38 - 28:44]
機械

[28:41 - 28:46]
学習の分野における多くの方法の一つです。ディープラーニングは

[28:46 - 28:49]
方法であり、

[28:50 - 28:54]
アプローチです。私は「方法」という言葉が好きです。ディープ

[29:02 - 29:07]
ラーニング自体は、

[29:05 - 29:10]
機械学習の分野における多くの方法の一つであり、

[29:20 - 29:24]
AIのサブフィールドです。ディープラーニングは

[29:23 - 29:31]
実際には

[29:24 - 29:31]
機械学習の一部である方法であり、ディープラーニングは

[29:45 - 29:52]
人工知能の一種であり、AIそのものではありません。これは気に入っています。

[29:49 - 29:54]
そして、後で機械

[29:52 - 29:58]
学習についてですが、もう

[29:54 - 30:01]
一つメモを書き留めました。

[29:58 - 30:01]
ここには、私が

[30:02 - 30:06]
書き留めたものが書かれています。

[30:11 - 30:17]
これは私が書き留めたもので、

[30:14 - 30:23]
AIのサブフィールドです。 どの機械が

[30:17 - 30:23]
データや自身の経験から学習するか、

[30:35 - 30:40]
そうですね。これは間違いなく

[30:40 - 30:46]
機械学習に関する新しいメモになり、

[30:43 - 30:51]
私のシステムの新しいインデックスになります。機械

[30:46 - 30:51]
学習はAIではないので、

[30:52 - 31:00]
機械

[30:56 - 31:00]
学習はAIのサブフィールドです。

[31:05 - 31:10]
サブフィールドという言葉が好きですが、あえて「サブフィールド」と呼ぶことにします。「

[31:21 - 31:28]
サブフィールド」という言葉をコピーします。これは、おそらく

[31:24 - 31:28]
シソーラスでしょ

[31:38 - 31:43]
う。これは、私が

[31:45 - 31:48]
時々クロードに尋ねる時かもしれません。行き詰まったら

[31:48 - 31:53]
助けます。

[31:53 - 31:58]
英語は私の母国語ではないので、

[31:58 - 32:06]
シソーラスを使うのが好きですが、時々、AIを使って単語の

[32:06 - 32:16]
同義語を探すので、

[32:10 - 32:16]
別の言い方を考えてみましょう。

[32:21 - 32:30]
ここでは、サブフィールドとは、AI内のドメインの分野です。AI内のドメイン

[32:25 - 32:30]
です。

[32:34 - 32:38]
ディープラーニング自体が、AIの分野を

[32:37 - 32:41]
使用する分野における多くの方法の1つであるという点が気に入っています。「分野」という表現は気に入っています。「

[32:41 - 32:50]
分野」です。ここでは、

[32:45 - 32:52]
これを「機械学習」と言い換えます。これは、

[32:53 - 33:00]
機械が自身の

[32:57 - 33:00]
データや

[33:01 - 33:07]
経験から学習するAIの分野です。 これ

[33:04 - 33:09]
はAIのサブフィールドで、機械が

[33:07 - 33:12]
データや自身の経験から学習するものです。私は

[33:09 - 33:14]
これを少し

[33:12 - 33:18]
別の言い方で表現しました。つまり、概念は理解していますし、

[33:14 - 33:22]
AIとの関係も理解していますが、

[33:18 - 33:24]
別の言葉を使って、

[33:22 - 33:26]
このプロセスを行うことで頭の中で整理し

[33:24 - 33:29]
、より深く

[33:26 - 33:32]
心に刻み込むことができました。だからこそ、

[33:29 - 33:34]
時間をかけてじっくり考え、質の高い時間を費やすことが重要なのです。これは

[33:51 - 33:56]
機械

[33:53 - 33:59]
学習に属しますが、ディープラーニングは

[33:56 - 33:59]
人工知能の一種であり、AIそのものでは

[34:06 - 34:10]
ありません。機械学習については別のメモで説明

[34:12 - 34:19]
できます。これは機械学習

[34:16 - 34:20]
の定義です。これはここにある定義

[34:23 - 34:29]
に追加しますが、

[34:29 - 34:36]
ご覧のとおり、これは

[34:32 - 34:38]
私がAIを定義しているこのメモから派生しています。このように、

[34:36 - 34:44]
機械学習が

[34:38 - 34:44]
AIのサブフィールドであるという事実は、このメモに反映されています。

[34:47 - 34:51]
彼女は

[34:54 - 35:01]
説明を続けます。はい、

[34:58 - 35:04]
このメモでは、

[35:01 - 35:06]
機械学習は

[35:04 - 35:09]
AIの一分野であり、機械が

[35:06 - 35:09]
自身のデータや

[35:10 - 35:16]
経験から学習すると述べています。これで

[35:13 - 35:16]
小さなノートの別のページが完成しましたが、

[35:24 - 35:31]
何も書きませんでした。

[35:28 - 35:33]
機械学習について

[35:31 - 35:37]
これ以上詳しくは知りたくありませんが、今は

[35:33 - 35:43]
ちょっと興味があります

[35:37 - 35:46]
著者が「経験」という言葉を引用しているのですが、

[35:46 - 35:51]
この経験

[36:12 - 36:21]
についてもっと知りたいです。この文ではクロードの言葉を

[36:17 - 36:25]
使います。著者は「経験」を引用符で囲んでいます。「私は

[36:32 - 36:41]
努力しています。学んでいます。AIを

[36:37 - 36:45]
根本から研究しています。著者がこれを引用符で囲むことで何を示唆していると

[36:41 - 36:48]
思いますか？

[36:55 - 37:01]
機械は

[36:58 - 37:05]
実際には何も経験できないことは分かっていますが、説明していただけますか？

[37:07 - 37:11]
クロードの言うことを聞いてみましょう。

[37:12 - 37:17]
興味深く哲学的に豊かな問題に触れていますね。

[37:17 - 37:22]
学習に関する引用符の使用は、

[37:19 - 37:25]
それらの類推や

[37:22 - 37:27]
近似を示しています。機械が学習すると言うとき、

[37:25 - 37:28]
それは人間の学習とは根本的に異なります。

[37:28 - 37:32]
実際に起こっているのは

[37:30 - 37:35]
統計的パターン認識です。まさにその通りです。

[37:32 - 37:37]
彼女は本の後半でその点に触れています。「

[37:37 - 37:45]
数の最適化」です。つまり、

[37:45 - 37:48]
人間が

[37:48 - 37:53]
学習するような意味での学習ではありません。同様に、機械の経験は

[37:51 - 37:55]
意識的な経験ではありません。

[37:53 - 37:57]
現象学的には、それらは実際には

[37:55 - 38:00]
単なる入力データポイント、トレーニング例、

[37:57 - 38:03]
記録された相互作用または

[38:00 - 38:03]
結果です。

[38:04 - 38:11]
クロードの説明の仕方が

[38:23 - 38:28]
とても気に入りました。引用符は、人間の認知と意識から用語を借りて、本質的に数学的および計算的なプロセスであるものを説明することを認める、一種の認識論的謙虚さとして機能します。これは素晴らしいです。自分で書けばよかったのに。

[38:30 - 38:36]
サーモスタットがいつ暖房をつけるべきかを知っているのと似ています。

[38:33 - 38:38]
便利な比喩ですが、

[38:36 - 38:40]
サーモスタットが

[38:38 - 38:43]
人間と同じように実際に知識を持っていると主張する人はいないでしょう。この

[38:40 - 38:45]
区別は、

[38:43 - 38:48]
AI倫理と心の哲学の議論において特に重要になります。

[38:48 - 38:52]
これは素晴らしいです。

[38:52 - 38:57]
クロード、本当にありがとうございます。AIシステムは

[38:55 - 39:00]
情報を処理して行動を調整できますが、

[38:57 - 39:02]
データに基づいて行動しますが、

[39:03 - 39:07]
生物学的実体のように真の経験や意識を持つことができるかどうかについては依然として疑問が残ります。

[39:07 - 39:12]
これは本当に便利です。

[39:10 - 39:15]
また、私は

[39:12 - 39:18]
クロードをメンターや教師としてこのようによく利用しているので、これをお見せしています

[39:18 - 39:23]
。AIを使って

[39:21 - 39:27]
AIを使ってAIについて学んでいるというのは興味深いことです。それ

[39:23 - 39:31]
自体が非常に興味深いのです

[39:27 - 39:35]
が、クロードの表現はとても気に入っています。

[39:35 - 39:42]
実は、

[39:37 - 39:44]
AIをコピーしたり、AIから直接テキストをコピーしたりするのは好きではありません。

[39:42 - 39:47]
これは絶対に

[39:44 - 39:52]
出版しませんが、これは非常に素晴らしいので、

[39:52 - 40:01]
無駄にするつもりはありません。

[39:55 - 40:05]
本の中で著者は「学習」と「

[40:01 - 40:07]
経験」を引用符で囲んでいます。これは、

[40:10 - 40:17]
機械が

[40:13 - 40:21]
実際には学習したり

[40:17 - 40:21]
経験したりしないという意味ではありません。しかし、

[40:25 - 40:30]
コミュニケーションのために、これらの言葉を使う必要があります。

[40:30 - 40:39]
機械学習は、時間の

[40:39 - 40:43]
経過とともに機械がタスクをより良く実行できるようになることを意味します。

[40:48 - 40:57]
私たちはこれを人間の用語である「学習」として使用しています

[40:57 - 41:06]
が、実際には、

[41:01 - 41:07]
モデルがより

[41:06 - 41:10]
正確な

[41:07 - 41:10]
統計

[41:13 - 41:18]
データを取得しているということです。これは基本的に私自身の

[41:16 - 41:22]
表現です。はい、私は

[41:18 - 41:25]
ここでAIのテキストを再利用しています。そして、

[41:25 - 41:35]
CLAにこれについて尋ねると、CLAは

[41:30 - 41:35]
この興味深いテキストを生成しました。

[41:40 - 41:48]
通常、メモをこれほど長くすることは好みませんが、

[41:45 - 41:51]
この場合は、

[41:48 - 41:54]
私が 偶然見つけたのですが、

[41:51 - 41:56]
クロードの説明がとても気に入りました。

[41:54 - 41:59]
これは

[41:56 - 42:01]
クロードが作成したものだということを明記しておきます。

[41:59 - 42:04]
このメモは、後で

[42:04 - 42:10]
機械がどのように学習したり

[42:06 - 42:13]
経験したりするのかをもっと深く掘り下げたい場合に活用できます。私が

[42:10 - 42:17]
気に入っている点は、

[42:13 - 42:20]
機械は実際には

[42:17 - 42:23]
学習しない、単なる統計的なパターン

[42:20 - 42:25]
認識であるという点です。現在の研究段階では、これだけの

[42:25 - 42:30]
知識があれば十分です。

[42:28 - 42:33]
機械がどのように

[42:30 - 42:36]
学習するのか、これらのモデルがどのように機能するのかを必ずしも深く掘り下げたいわけではありませんが、それについてはさらにメモを

[42:33 - 42:38]
取りました。

[42:38 - 42:45]
次のセクションで詳しく説明します。このメモは、うーん、私が掘り下げ

[42:43 - 42:48]
たい範囲です。

[42:45 - 42:52]
これは後で参照するためのデータとして使います。また、

[42:48 - 42:55]
クローリンクもここに含めておけば、

[42:52 - 43:00]
後で簡単に見つけることができます。

[42:55 - 43:00]
これでこのメモは完成です。さて、これで

[43:08 - 43:15]
いくつかメモが作成されたので、

[43:12 - 43:19]
実際にどのように構成するかをお見せできます。これは、

[43:21 - 43:28]
毎日のメモとこのメモの両方に追加しているからです。 人工

[43:25 - 43:31]
知能ノートですが、

[43:31 - 43:40]
入力ノードを作成するのも好きです。

[43:36 - 43:45]
この本を表すノートを作成し

[43:40 - 43:45]
、「人工

[43:47 - 43:52]
知能：考える

[43:55 - 44:01]
人間のためのガイド」を見てみましょう。これはこの本を表すノートです。

[43:58 - 44:03]
これを「入力書籍」に移動しています。

[44:03 - 44:09]
読んだ本はすべてメモを

[44:07 - 44:09]
取っていて、

[44:14 - 44:21]
システム内にエントリがあります。このノートからこれらも

[44:21 - 44:28]
追加していきます。箇条書き

[44:28 - 44:34]
リストにしてみましょう。

[44:32 - 44:38]
見た目が気に入っているので。それでは始めましょう。

[44:34 - 44:42]
これで何が

[44:38 - 44:45]
達成されるのか、そしてなぜ私がこれを行うのかをお見せしたいので、これをすべてお見せします。

[44:48 - 44:54]
毎日のノートから人工

[44:50 - 44:57]
知能ノートを追加し、本の

[44:54 - 45:00]
ノートを作成することで何が達成されるのか、これらのノートの元となるのは、

[44:57 - 45:03]
例えば人工知能の定義ノートに移動できます。

[45:03 - 45:09]
そして、このノートの後ろのリンクに移動すると、どこ

[45:06 - 45:13]
から来たのかがわかります。

[45:09 - 45:18]
ローカルグラフを

[45:13 - 45:22]
開いてローカルグラフを開くと、

[45:18 - 45:24]
このノートが複数のノートにリンクされていることがわかります。このノートが

[45:24 - 45:30]
この日に作成されたことがわかります。 そこから

[45:28 - 45:32]
生成したので、そこをクリックすると、

[45:32 - 45:37]
その日に何をしていたかを見ることができます。

[45:37 - 45:44]
その日に既にさまざまなAI関連のノートを作成していることがわかります。これは興味深いものです。

[45:40 - 45:46]
次に、

[45:44 - 45:49]
人工

[45:46 - 45:52]
知能とAiというインデックスノードの一部であることがわかります。これにはすでに

[45:49 - 45:55]
多くの異なるノートがあります。

[45:55 - 46:02]
知能の定義に戻ると、このノートが

[45:59 - 46:06]
実際に別のノートを生成していることもわかります。

[46:02 - 46:10]
これが私がこのように行う理由です。excal

[46:10 - 46:16]
excalibrateもできるかもしれません。開いていますか？はい、

[46:16 - 46:21]
これが別の方法です。excal

[46:21 - 46:28]
brainを使用するときにこれを行うのが好きなもう1つの理由です。これを使用すると

[46:25 - 46:30]
さらに明確になります。ここに

[46:28 - 46:32]
人工知能のノートがありますが、これは私のアート

[46:30 - 46:34]
人工知能の定義です。

[46:32 - 46:39]
ここでさらに明確になります。

[46:34 - 46:43]
このノートの親ノートは、ええと、

[46:43 - 46:50]
ここにあるDailyノートとブックノートです。

[46:47 - 46:54]
このノートはそこから来ていることがわかります。そして、このノートはこのノート

[46:50 - 46:55]
につながっています。機械学習は

[46:55 - 47:03]
AIの分野です。この

[46:58 - 47:07]
ノートの親もここにあります。

[47:03 - 47:09]
このDailyノートはブックにあり、

[47:12 - 47:19]
他のノートとの関連ですが、

[47:16 - 47:22]
この本のノートを見ると、

[47:19 - 47:24]
この日付から作成されていることがわかります。つまり、

[47:22 - 47:28]
私がこの本について書き始めた日です。これは

[47:24 - 47:30]
興味深いデータポイントになります

[47:28 - 47:34]
が、Excal Brainのレンダリング方法により、

[47:30 - 47:38]
このノートが以下のノートと関連していることが分かります。

[47:34 - 47:40]
そして、

[47:38 - 47:43]
それらの

[47:40 - 47:44]
相互関係も確認できます。例えば、

[47:44 - 47:52]
特異点の定義のRayコードを

[47:47 - 47:52]
機械学習のノートにリンクすると、

[48:01 - 48:09]
ここでそれがわかるはずです。ええ、この

[48:04 - 48:12]
リンクがこのノートに接続されているのがわかります。

[48:09 - 48:14]
以前はここにはありませんでした。

[48:12 - 48:17]
実際には接続したくないのです

[48:14 - 48:20]
が、これは単なる例です。私は、

[48:20 - 48:25]
tcastの視覚的な探索を使用するのが好きです。

[48:23 - 48:28]
これをさらに深く掘り下げていくと、どの

[48:25 - 48:31]
ノートが何に関連しているかを視覚的に確認したいので、

[48:28 - 48:34]
ブランチの数などを展開できます。

[48:31 - 48:36]
これは非常に

[48:34 - 48:39]
便利です。

[48:36 - 48:41]
これらは、

[48:39 - 48:43]
このトピックで私が作成した最初のノートです。

[48:41 - 48:46]
次のセクションでは、Neovimワークフローを使用して、

[48:43 - 48:48]
私も

[48:46 - 48:48]
それをどのように使っている

[48:55 - 48:59]
か

## コメント

### 1. @mischavandenburg (👍 3)
I'm hosting a FREE note-taking workshop in 1-2 weeks.

Join my FREE community if you want to be a part of it 
👉 https://www.skool.com/mischa

### 2. @Idyll_Insomniac (👍 7)
Ok, I seriously do not put anywhere near enough effort into my maths degree or studying in general. No wonder why I can't make anything stick.
Thanks for the informative video, real-life examples are always good to learn from.

> **@mischavandenburg** (👍 2): You vastly underperform until you meet someone functioning on a more advanced level and see what's possible. Best of luck mate.

### 3. @JeanPaulDosher (👍 4)
I saw it entirely. I was really doubting my methods and thought that I was wasting time in my Obisidian, but definitely I wasn't.
One main concept that I will take from here is that; Zettelkasten is not about copying things. 
But surely I'll revisit my source notes method.

> **@mischavandenburg** (👍 0): glad it was helpful to you Jean. There are more free resources for you here.

https://skool.com/mischa

### 4. @mrnezbitt (👍 2)
This is a great video to see the note-taking process take place as it happens. This and the previous videos about note-taking in this channel have really helped me to develop my own note-taking system which is benefiting me in my PhD but also my life.

> **@mischavandenburg** (👍 4): Thank you for letting me know how valuable these teachings are to you. I'm honored to hear that I'm benefiting science indirectly!

### 5. @marco_peluso (👍 3)
Great video, exactly what I've been waiting for for a long time! Thank you Mischa!

> **@mischavandenburg** (👍 0): Thanks Marco!

### 6. @victorariasvanegas7407 (👍 0)
I'm a machine learning engineer who introduced me to the Zettelkasten way of living, I need more of these videos, thank you very much.

> **@mischavandenburg** (👍 0): Great to hear!

### 7. @JamesKaupert (👍 0)
So great to see this process. Your course was awesome, and this is a great extension of it for more reinforcement with a real life follow-along!

### 8. @jamesbarrow (👍 0)
While I was listening to the part around spending "quality time" reflecting on the content, it made me wonder about quality vs. quantity. I immediately create a note in my own system around quality time vs. quantity time. Quantity time being available for a duration, and quality time having a meaningful experience during that time. Yay :)

> **@mischavandenburg** (👍 0): Love it!

### 9. @zenvanriel (👍 5)
That's a great book on top of the practical tips in this video 😉

> **@mischavandenburg** (👍 0): A great book recommended by a great person! :) I'm really enjoying it, thank you for the recommendation.

People who read this: check out @zenvanriel 's channel if you want to learn more about AI

### 10. @БогданПономарев-х7ч (👍 0)
От души за уроки Мишаня

### 11. @dinjem (👍 0)
Thank you for sharing your content. Is it possible to tell which keyboard you use ?

### 12. @the_flushjackson (👍 0)
Great video, thank you.

> **@mischavandenburg** (👍 0): Glad you liked it!

### 13. @AustinJohnson-zv5hy (👍 2)
"the point of the zettelkasten method is to take it slow... it allows me to learn 10X faster than my peers." That's a tweet.

> **@mischavandenburg** (👍 2): It has hereby been tweeted

### 14. @Pedro-Chang (👍 0)
Quick question Mischa..What theme do you use 😂

> **@mischavandenburg** (👍 0): gruvbox

### 15. @RameshBaburbabu (👍 1)
Thanks for sharing, I spend so much time like you. then I found PDF ++  plugins, please looks some clip ,  also excalidraw alos added PDF++ support

### 16. @notaras1985 (👍 0)
Why not notion

> **@douglasdrumond** (👍 1): Obsidian is faster, more private (notes are local) and suited for knowledge management. Backlinks are useful and easy to use in Obsidian. Obsidian also has a large dedicated community. Maybe not as big as Notion’s, but still nice.

> **@mischavandenburg** (👍 0): Obsidian reigns supreme. I have a video on that too. 

https://skool.com/kubecraft

