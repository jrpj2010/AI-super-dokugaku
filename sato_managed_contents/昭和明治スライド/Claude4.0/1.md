![ゼロから始める起業！ (3).png](attachment:66d2ce17-e212-4de0-83c9-2ecfd40deaf6:ゼロから始める起業！_(3).png)

https://youtu.be/EvtPBaaykdo

https://youtu.be/EvtPBaaykdo

※開始30分はPVが流れてますので実イベント時間は[26m27s] 〜からです

↓

カット編集音声

[2025-05-23 04-25-55_01.mp3](attachment:c2c9a1ae-f48c-4063-91e9-c9beaa68039f:2025-05-23_04-25-55_01.mp3)

- 文字起こし[us]：

    ```markdown
    ```srt
    1
    00:01:02,000 --> 00:01:07,000
    Please welcome to the stage, Chief Product Officer of Anthropic, Mike Krieger.

    2
    00:01:17,000 --> 00:01:23,000
    Good morning, everyone, and welcome to Code with Claude, Anthropic's first developer conference. I'm really happy to see you all here.

    3
    00:01:23,000 --> 00:01:27,000
    I'm Mike Krieger. I'm Chief Product Officer here at Anthropic.

    4
    00:01:27,000 --> 00:01:34,000
    I just hit my one-year mark, which in AI years is about like three years, um, but I'm having a blast.

    5
    00:01:34,000 --> 00:01:43,000
    Um, and before this, I co-founded Instagram, um, and also an AI-powered news app called Artifact, which is where I first started getting exposed to a lot of these AI technologies.

    6
    00:01:43,000 --> 00:01:51,000
    I joined Anthropic because of its founder's vision, building AI systems that are powerful as well as helpful and trustworthy.

    7
    00:01:51,000 --> 00:02:02,000
    Today, that vision includes something immediate and concrete, a commitment to empower developers like yourselves to transform how work gets done and how companies get built.

    8
    00:02:02,000 --> 00:02:07,000
    This transformation is about augmenting, not replacing, human creativity.

    9
    00:02:07,000 --> 00:02:11,000
    AI agents are changing the way we work and the way we innovate.

    10
    00:02:11,000 --> 00:02:17,000
    They're expanding what we can build by removing bottlenecks that have limited human productivity.

    11
    00:02:17,000 --> 00:02:25,000
    Today, you'll hear from our product and engineering leaders, as well as some of our customers, about how they're pushing the frontier.

    12
    00:02:25,000 --> 00:02:44,000
    To give you a sense of what you can expect today at Code with Claude, you can attend three technical deep dives to transform how you build with Claude, and five sessions from leading players already using Anthropic's platform to reshape their industries, and dedicated office hours and workshops for hands-on experience.

    13
    00:02:44,000 --> 00:02:51,000
    But before we talk about some exciting new API API capabilities I have for you, I want to invite a guest on stage.

    14
    00:02:51,000 --> 00:02:55,000
    Please welcome our CEO and co-founder, Dario Amade.

    15
    00:03:04,000 --> 00:03:05,000
    Hey, everyone.

    16
    00:03:05,000 --> 00:03:14,000
    Uh, I'm going to be back in 20 minutes for a fireside, so uh, uh, I'll be, I'll be really, really brief with uh, with this appearance.

    17
    00:03:14,000 --> 00:03:19,000
    Um, I'm not one to uh, hype things up, so I'll just say this without any further fanfare.

    18
    00:03:19,000 --> 00:03:29,000
    I'm happy to announce that as of exactly this moment, we're releasing Claude 4 Opus and Claude 4 Sonnet on all of our relevant product surfaces.

    19
    00:03:35,000 --> 00:03:52,000
    Now, I know that we haven't had an Opus model in a while, so just as a reminder, Opus is the most capable and intelligent model, and Sonnet is the mid-level model that you all know and love and have been using for the last uh, uh, uh, uh, approximately year.

    20
    00:03:52,000 --> 00:03:56,000
    That's a a good balance between intelligence and efficiency.

    21
    00:03:56,000 --> 00:04:03,000
    Um, we try to design both of them so that there are, there are use cases and times when it's optimal to use each one.

    22
    00:04:03,000 --> 00:04:09,000
    So I will talk very briefly about the two of them and then and then turn it back over to Mike and then I'll be back for the fireside.

    23
    00:04:09,000 --> 00:04:12,000
    Um, uh, first, let's talk about Opus.

    24
    00:04:12,000 --> 00:04:17,000
    So, it is especially designed for coding and agentic tasks.

    25
    00:04:17,000 --> 00:04:25,000
    Um, it gets state-of-the-art on Swebench, Terminal Bench, some other things like, like that.

    26
    00:04:25,000 --> 00:04:32,000
    Um, uh, but I think in many ways, uh, as we're often finding with large models, the benchmarks don't fully do justice to it.

    27
    00:04:32,000 --> 00:04:41,000
    Um, customers who we've previewed it to have found that it can do tasks that take humans up to six or seven hours autonomously.

    28
    00:04:41,000 --> 00:04:50,000
    Um, uh, within Anthropic, I've seen some of our most senior engineers be surprised at how much more productive it has made them.

    29
    00:04:50,000 --> 00:05:08,000
    And for the first time, actually, when I've, um, you know, looked and and seen Claude written internal summaries, documents, and uh, and and ideas, you know, in the past, the quality was often good, but you could never really quite mistake it for a human because it always had that that specific style.

    30
    00:05:08,000 --> 00:05:18,000
    This was the first time I actually got fooled, where I actually get got back and then, you know, I just read by the name really fast and I thought it referred to someone on the team and I'm like, no, the name was Claude.

    31
    00:05:18,000 --> 00:05:24,000
    Um, uh, uh, so I, you know, I think, I think there's a, there's a, there's a lot in Opus.

    32
    00:05:24,000 --> 00:05:36,000
    Um, on Sonnet, um, I think this will be for many people a strict update for uh, uh, uh, a strict improvement from Sonnet 3.7, um, at the same cost and better intelligence.

    33
    00:05:36,000 --> 00:05:40,000
    Many customers are simply uh, uh, switching directly from one to the other.

    34
    00:05:40,000 --> 00:05:49,000
    It actually does just as well as Opus on some of the uh, coding benchmarks, but I think it's leaner and more narrowly focused.

    35
    00:05:49,000 --> 00:06:06,000
    Um, I think in particular, it addresses some of the uh, feedback we got on Sonnet 3.7 around over eagerness, the tendency to do more than you asked for, which is sort of the opposite of laziness, which was, which was an earlier problem, and and some of the, some of the reward hacking issues.

    36
    00:06:06,000 --> 00:06:12,000
    So, many of our customers have been trying it out and view it as a strong upgrade from 3.7.

    37
    00:06:12,000 --> 00:06:25,000
    For example, um, you know, Cursor, Cursor here has been uh, one of our well-known customers, has been trying it and says saying, this is uh, this is a state-of-the-art, uh, this is, this is, this is a state-of-the-art coding model.

    38
    00:06:25,000 --> 00:06:33,000
    Um, it's a leap uh, forward in complex codebase understanding, and we expect developers will experience uh, across-the-board capability improvements.

    39
    00:06:33,000 --> 00:06:38,000
    Um, someone who was playing with the model in person, one customer said, what the F is this model?

    40
    00:06:38,000 --> 00:06:40,000
    Um, it's really, it's really amazing.

    41
    00:06:40,000 --> 00:06:50,000
    So, um, uh, I'll, I'll leave the details to others, but um, the last thing I'll say is we are going to continue to improve the Claude 4 series of models.

    42
    00:06:50,000 --> 07:00,000
    We expect to periodically release perhaps minor version updates, ideally even more frequently than we, than we have for, um, for, uh, for, for Sonnet.

    43
    07:00,000 --> 07:01,000
    So it should be out there.

    44
    07:01,000 --> 07:12,000
    You should be able to try it on basically all, all the surfaces as of now, except I think Free Tier has, has Sonnet, uh, has Sonnet only, but all the other surfaces, uh, all the API surfaces have both.

    45
    07:12,000 --> 07:17,000
    Um, so, uh, really hope you enjoy the model, and I'll turn it back over to Mike.

    46
    07:25,000 --> 07:26,000
    Thank you, Dario.

    47
    07:26,000 --> 07:28,000
    Two new models, and you heard it here first.

    48
    07:28,000 --> 07:37,000
    Um, we'll be seeing Dario again, as he mentioned, at the end of our agenda for a Q&A, where I'll get to ask him the questions that are likely on your mind, uh, right now as well.

    49
    07:37,000 --> 07:42,000
    I'm personally very excited for our customers to try both Claude Opus 4 and Sonnet 4.

    50
    07:42,000 --> 07:46,000
    Our teams have loved working with them, and we think you will too.

    51
    07:46,000 --> 07:52,000
    Uh, now that Dario has shared our big model news, I'll talk more about our detailed API roadmap.

    52
    07:52,000 --> 07:55,000
    Our goals for building Claude 4 were clear from the start.

    53
    07:55,000 --> 08:06,000
    We wanted to build powerful AI that safely introduces new model capabilities, continue to advance the frontier for coding and AI agents, and ensure that Claude becomes your virtual collaborator.

    54
    08:06,000 --> 08:09,000
    And that's exactly what we've delivered with Opus 4 and Sonnet 4.

    55
    08:09,000 --> 08:19,000
    Like, uh, Sonnet 3.7, both Claude 4 models are what we call hybrid models that have two modes, near instant responses and extended thinking for when you need deeper reasoning.

    56
    08:19,000 --> 08:25,000
    I've been surprised at how many customers use the deeper reasoning even for non-coding and non-math use cases.

    57
    08:25,000 --> 08:28,000
    Opus 4 is great at understanding your codebase and planning additions.

    58
    08:28,000 --> 08:34,000
    It's extremely effective, uh, and accurate with everything from migrations to code refactorings.

    59
    08:34,000 --> 08:37,000
    And it's also the right choice for your most complex agentic workflows.

    60
    08:37,000 --> 08:44,000
    If you've found you've hit a wall with other models on your use case, I think you'll be really pleasantly surprised with what you can do with Opus 4.

    61
    08:44,000 --> 08:50,000
    Sonnet 4, meanwhile, excels at everyday coding tasks, app development, uh, and pair programming.

    62
    08:50,000 --> 08:52,000
    It's also ideal for high-volume use cases.

    63
    08:52,000 --> 08:55,000
    It perfectly balances efficiency with performance.

    64
    08:55,000 --> 08:58,000
    Think of it as your always-on coding partner.

    65
    08:58,000 --> 09:06,000
    Both models are live today, as Dario mentioned, in Claude and Claude Code, as well as the Anthropic API, Amazon Bedrock, and Google Cloud's Vertex AI.

    66
    09:06,000 --> 09:09,000
    These models bring critical new capabilities for building AI agents.

    67
    09:09,000 --> 09:21,000
    They can use tools like web search during the reasoning process, which is new, handle multiple tools in parallel, and when given access to local files, can actually maintain memory across sessions to build knowledge over time.

    68
    09:21,000 --> 09:24,000
    And I'll talk with Dario a little bit about that memory feature too later.

    69
    09:24,000 --> 09:29,000
    These aren't just incremental improvements, they fundamentally change what's possible for AI agents.

    70
    09:30,000 --> 09:32,000
    Now, I know the term agents gets thrown around a lot these days.

    71
    09:32,000 --> 09:37,000
    I have a personal, uh, joke, which is how many minutes into a meeting can we make it at Anthropic without saying the word agents?

    72
    09:37,000 --> 09:40,000
    I think I made it, yeah, 17 minutes or something.

    73
    09:40,000 --> 09:44,000
    Uh, but today what we're going to focus on is agents beyond the hype.

    74
    09:44,000 --> 09:55,000
    Um, I think what's really key is with the right underlying models and the right underlying platform tools, AI agents can actually turn human imagination into tangible reality at unprecedented scale.

    75
    09:55,000 --> 10:00,000
    And that's especially important for startups and developers like yourselves.

    76
    10:00,000 --> 10:08,000
    I've been a founder myself, when I think back to Instagram's early days, our famously small team had to make a bunch of very painful either or decisions.

    77
    10:08,000 --> 10:15,000
    We'd be either explore, uh, adding video to the product, or focus on our core creativity.

    78
    10:15,000 --> 10:20,000
    Either focus on our mobile app, and at first our single mobile app, or, uh, expand into the web.

    79
    10:20,000 --> 10:23,000
    It was all very single track.

    80
    10:24,000 --> 10:32,000
    With AI agents, startups now can run experiments in parallel, learn from users, and build products faster than ever before, which is something I've heard from many of you all.

    81
    10:32,000 --> 10:40,000
    And AI agents can give you the, the founders of startups, uh, access to the kind of strategic thinking that you might get from a high-powered C CFO.

    82
    10:40,000 --> 10:45,000
    I see our CFO in the front row here, or head of product, uh, while they're still building towards those key positions yourselves.

    83
    10:45,000 --> 10:50,000
    You're not ready for to make those hires, but you can hire, uh, Claude for some of those roles for now.

    84
    10:50,000 --> 10:52,000
    This transformation is no longer theoretical.

    85
    10:52,000 --> 10:55,000
    I see it in my role and my work every single day.

    86
    10:55,000 --> 10:59,000
    I personally spend a lot of time with Claude, maybe more time with Claude than my significant other.

    87
    10:59,000 --> 11:00,000
    It's fine.

    88
    11:00,000 --> 11:11,000
    Uh, in fact, uh, soon after I joined Anthropic, um, I, uh, sat down with Amazon's Alexa team, and they were eager to see how Claude might become part of their vision for the future of voice assistance.

    89
    11:11,000 --> 11:17,000
    At first, my team planned on presenting some slides, talking points, kind of the plan we'd make for any other customer.

    90
    11:17,000 --> 11:23,000
    But in the days leading up to the meeting, I had this like persistent thought, why not use Claude itself to build a hands-on demo?

    91
    11:23,000 --> 11:30,000
    I thought it'd make the conversation more interesting and bring to life the potential of Claude and Alexa functionality together.

    92
    11:30,000 --> 11:35,000
    The challenge was building this demo without any access to Alexa's actual codebase.

    93
    11:35,000 --> 11:45,000
    We needed to create a prototype of the core Alexa functionality while also integrating Claude's capabilities, all within a tight one-week timeline, really a tight one-weekend timeline.

    94
    11:45,000 --> 11:50,000
    Claude was the only reason we were able to pull this off, uh, in such a limited time frame.

    95
    11:50,000 --> 11:56,000
    Our three-person team, split between San Francisco and London, built a functional prototype that showed the potential.

    96
    11:56,000 --> 11:58,000
    And thanks to Claude, the effort was a success.

    97
    11:58,000 --> 11:59,000
    I even got to write some of the code.

    98
    11:59,000 --> 12:06,000
    You can take the engineer out of the engineering or CTO role, but you can't take it out of me, uh, and do a lot of the front-end, uh, development, uh, for the project itself.

    99
    12:06,000 --> 12:10,000
    And of course, a lot more work went into the partnership after that first meeting.

    100
    12:10,000 --> 12:17,000
    Um, but Claude is now one of the models that Amazon is using for Alexa Plus, uh, which launched earlier this year and is now rolling out.

    101
    12:17,000 --> 12:21,000
    And we were able to, I think, to really show the potential thanks to Claude.

    102
    12:21,000 --> 12:24,000
    I've been watching this evolution towards agentic AI for years now.

    103
    12:24,000 --> 12:33,000
    Uh, when I first got a demo and early access of GitHub Copilot back in 2021, I called it the single most mind-blowing application of machine learning I've ever seen.

    104
    12:33,000 --> 12:36,000
    Back in those days, in 2021, we called it machine learning instead of AI.

    105
    12:36,000 --> 12:41,000
    That was generations ago, but it was really clear the potential for this early glimpse of agentic AI.

    106
    12:41,000 --> 12:45,000
    I had an even stronger feeling last summer when we launched Artifacts.

    107
    12:45,000 --> 12:53,000
    I could describe what I wanted for a mini app or visualization, hit send, go grab coffee, and come back to Claude having built what I'd imagined.

    108
    12:53,000 --> 13:00,000
    And over the following year, it's become clear, we're not just building better tools, we're creating genuine collaborators.

    109
    13:00,000 --> 13:04,000
    And Anthropic's economic research, uh, confirms what I've seen firsthand.

    110
    13:04,000 --> 13:08,000
    For the majority of use cases, AI is augmenting people's work instead of replacing it.

    111
    13:08,000 --> 13:11,000
    It's much more about tasks than entire roles.

    112
    13:11,000 --> 13:14,000
    And this is similar to the influence that your best colleagues have.

    113
    13:14,000 --> 13:24,000
    The most talented people you work with don't just execute, they understand your context, they learn from experience, and they know when to take the initiative versus when to just check in.

    114
    13:24,000 --> 13:29,000
    Great AI agents, like the ones you can build on our platform, should excel at three capabilities.

    115
    13:29,000 --> 13:37,000
    They should have contextual intelligence, understanding you and your organization's unique context, and continuously learning from experience.

    116
    13:37,000 --> 13:40,000
    Not just following instructions, but comprehending the why and the how.

    117
    13:40,000 --> 13:47,000
    That means models that learn and personalize over time, acquiring not just contextual, but also episodic and organizational memory.

    118
    13:47,000 --> 13:57,000
    The way I always put this to the team is, your hundredth task with an agent should be much better than your first, just like your hundredth day with an employee should be much better than your first if you're doing the right things around training.

    119
    13:57,000 --> 14:07,000
    Second, long-running execution, handling complex, multi-hour tasks without constant management, coordinating with other agents and humans as needed.

    120
    14:07,000 --> 14:11,000
    So you have the context, and then you can execute it over a longer period of time.

    121
    14:11,000 --> 14:20,000
    And third, genuine collaboration, engaging in meaningful dialogue, adapting to your working style, and providing transparent reasoning for their actions.

    122
    14:20,000 --> 14:25,000
    The key insight here is that true agency doesn't mean uncontrolled action.

    123
    14:25,000 --> 14:27,000
    And autonomy doesn't mean, uh, just yoloing it.

    124
    14:27,000 --> 14:39,000
    It means intelligent autonomy balanced with clear checkpoints, maintaining human oversight for critical decisions while delegating the smaller decisions that usually consume so much of our time.

    125
    14:39,000 --> 14:43,000
    Now let's talk about those capabilities we're announcing to serve those three needs.

    126
    14:43,000 --> 14:48,000
    We'll start with our new code execution tool, which is available on the Anthropic API today.

    127
    14:48,000 --> 14:57,000
    The code execution tool gives Claude an environment where it can run code, enabling it to act as a data analyst that can transform raw data into visual insights.

    128
    14:57,000 --> 15:00,000
    Claude doesn't just write code anymore, now it can execute it.

    129
    15:00,000 --> 15:07,000
    It sees the results, and it can iteratively refine the results and the code to better highlight patterns in your data.

    130
    15:07,000 --> 15:13,000
    Here, uh, we'll show Claude analyzing sales data to see how a specific type of product is performing.

    131
    15:13,000 --> 15:20,000
    Claude can load your data set, clean it, generate exploratory charts, and drill down into anomalies all in real time.

    132
    15:20,000 --> 15:24,000
    As someone who started their career as a data visualization analyst, this resonates a bunch with me.

    133
    15:24,000 --> 15:30,000
    And the code execution tool is even more powerful when combined with the intelligence of the Claude 4 models.

    134
    15:30,000 --> 15:36,000
    This is what we mean by agency, the ability to take a complex task and see it through to completion.

    135
    15:37,000 --> 15:43,000
    These are the first models capable of handling hours of tasks, saving you half, maybe even full days when you work alongside them.

    136
    15:43,000 --> 15:50,000
    And not just writing code snippets, but refactoring entire codebases or implementing complex features from scratch.

    137
    15:50,000 --> 15:57,000
    To give you a sense of the kind of progress that we're seeing, back in the day when I started, you could delegate maybe minutes of work to Claude 3.

    138
    15:57,000 --> 16:02,000
    Claude 3.7, meanwhile, could work autonomously for about 45 minutes without losing its thread.

    139
    16:02,000 --> 16:07,000
    And now we're breaking into hours of work that Claude can take on autonomously.

    140
    16:08,000 --> 16:14,000
    As you saw earlier, Rakuten mentioned that they ran Claude independently for an incredible seven hours with sustained performance.

    141
    16:14,000 --> 16:19,000
    It can do it without losing the thread, especially as it's able to manage its memory and its own to-do list.

    142
    16:20,000 --> 16:22,000
    We've already integrated this power where you work.

    143
    16:22,000 --> 16:28,000
    Hopefully, you're all familiar with Claude Code, our agentic coding tool that we launched in research preview a few months ago.

    144
    16:28,000 --> 16:32,000
    We're moving Claude Code to general access today.

    145
    16:32,000 --> 16:35,000
    This actually started as an internal exploratory project by Boris, one of our tech leads.

    146
    16:35,000 --> 16:40,000
    This is his announcement post, who wanted Claude to help them code directly in the terminal.

    147
    16:40,000 --> 16:43,000
    Um, very early, we still called it Claude CLI internally.

    148
    16:43,000 --> 16:48,000
    I think some of our best innovations, like Artifacts and Claude Code, have really come from this kind of bottom-up experimentation.

    149
    16:48,000 --> 16:51,000
    It's part of the culture we try to foster at Anthropic.

    150
    16:51,000 --> 16:55,000
    Within just two days of launching it internally, our usage chart went vertical.

    151
    16:55,000 --> 16:56,000
    People talk about product market fit.

    152
    16:56,000 --> 16:59,000
    We often talk about product Anthropic fit.

    153
    16:59,000 --> 17:00,000
    Like, are people internally dogfooding?

    154
    17:00,000 --> 17:01,000
    Are they using it?

    155
    17:01,000 --> 17:08,000
    Today, most Anthropic employees rely on it for everything from routine coding to large-scale migrations.

    156
    17:08,000 --> 17:13,000
    I've watched some of our most advanced coders run multiple copies of Claude Code across multiple terminal windows.

    157
    17:13,000 --> 17:23,000
    They're moving from just being engineers to being managers of several autonomous agents, tackling everything from simple coding tasks to complex full-stack development projects across multiple codebases.

    158
    17:23,000 --> 17:28,000
    I realized I was using Claude Code, and I would run one in our front-end repo and one in our back-end repo.

    159
    17:28,000 --> 17:34,000
    And one of our Claude Code engineers was like, you're doing it wrong. Just run it in the route. Claude can figure out where it's going to be able to do it across all of them, and it does it beautifully.

    160
    17:34,000 --> 17:36,000
    And that's how, that's changed how I've used it already.

    161
    17:36,000 --> 17:40,000
    The vast majority of of Anthropic developers use Claude Code daily.

    162
    17:40,000 --> 17:48,000
    To give you a sense of the impact it's had on our team, it's shortened our technical onboarding time, uh, to get engineers up to speed from two to three weeks to two to three days.

    163
    17:48,000 --> 17:57,000
    I've really seen it how it can help you build an understanding of the codebase, especially a large monolith like ours, very rapidly as it's a fantastic at navigating code.

    164
    17:57,000 --> 18:07,000
    And today, we're bringing Claude Code capabilities directly into VS Code and JetBrains with full diff use and agentic workflow management built into the editors.

    165
    18:07,000 --> 18:15,000
    And we're also introducing the Claude Code SDK, so you can build your own applications on top of the same core agent as Claude Code.

    166
    18:15,000 --> 18:20,000
    As an example of the possibilities of the SDK, you can now run Claude Code in GitHub.

    167
    18:20,000 --> 18:29,000
    You can tag Claude in a GitHub pull request or an issue, and it will respond to reviewer, uh, feedback, modified code, or implement test coverage.

    168
    18:30,000 --> 18:31,000
    We're also focused on what we call closing the loop.

    169
    18:31,000 --> 18:39,000
    So Claude Code is now helping build itself, and it demonstrates the power of self-improvement as it speeds up its own development.

    170
    18:39,000 --> 18:43,000
    It's incredible how Claude Code empowers developers like yourselves to get more done.

    171
    18:43,000 --> 18:50,000
    I think back to when I was building Instagram, our team was between two and six engineers, you know, before we got acquired, and we were supporting two mobile platforms.

    172
    18:50,000 --> 18:56,000
    We would have been able to produce prototypes in days and not weeks if we had agentic coding products like this.

    173
    18:57,000 --> 19:01,000
    We've talked a lot about building performant, reliable agents.

    174
    19:01,000 --> 19:07,000
    Now, agency without responsibility is dangerous, especially when you're talking about something that's self-improving like our Claude Code, uh, product.

    175
    19:07,000 --> 19:12,000
    And even more so in enterprise settings with stringent security and compliance requirements.

    176
    19:12,000 --> 19:21,000
    I think widespread adoption of agents will require improving model discernment and judgment around confidentiality, decision-making, and coordination.

    177
    19:21,000 --> 19:30,000
    So our models are already good at this, but we'll continue to improve, making sure that they know what's confidential, they know what to reveal, um, and that you can trust them in a production setting.

    178
    19:30,000 --> 19:36,000
    That's why every feature that we build around our models incorporates what we call architectural safety.

    179
    19:36,000 --> 19:39,000
    Checkpoints and controls, not just cart blanche.

    180
    19:39,000 --> 19:47,000
    Agents pausing on major decisions while users can define which actions need human approvals, which we've also built into the model context protocol.

    181
    19:47,000 --> 19:49,000
    They're robust against exploitation.

    182
    19:49,000 --> 19:54,000
    We test them, we battle test them, you know, uh, a lot around things like prompt injection.

    183
    19:54,000 --> 20:00,000
    And they're also transparent by design, with clear feedback loops and observable behavior.

    184
    20:00,000 --> 20:06,000
    When you trust your agents to act autonomously, you're free to focus on innovation instead of mitigation.

    185
    20:07,000 --> 20:10,000
    Another area we've invested heavily in is interpretability.

    186
    20:10,000 --> 20:14,000
    The science of understanding exactly what's going on inside the minds of AI models.

    187
    20:14,000 --> 20:19,000
    Dario recently wrote about the urgency of understanding how our AI systems actually work.

    188
    20:19,000 --> 20:21,000
    If you read his essay, the urgency of interpretability.

    189
    20:21,000 --> 20:25,000
    What he calls the race between model intelligence and interpretability.

    190
    20:25,000 --> 20:34,000
    Effectively, we want to be able to give our AI an MRI to see what's what it's thinking about and spot any potential problems like deception so we can steer it in the right direction.

    191
    20:34,000 --> 20:39,000
    When I joined Anthropic, I was excited about how our research pipeline could directly fuel our products.

    192
    20:39,000 --> 20:40,000
    Take Golden Gate Claude.

    193
    20:40,000 --> 20:51,000
    I pushed to ship this in our second, my second week at Anthropic, because it didn't feel like it was just a good research paper. It would make a fantastic demo, a visceral demonstration of how interpretability works in action.

    194
    20:51,000 --> 21:00,000
    When we amplified the Golden Gate Bridge feature inside the, uh, uh, Claude neural network, we saw that suddenly we could see what it means to manipulate the inner workings of AI.

    195
    21:00,000 --> 21:03,000
    And in this case, make it deeply obsessed with our favorite bridge.

    196
    21:03,000 --> 21:13,000
    Uh, the techniques that we used to create Golden Gate Claude could in the future help us reduce, uh, model, harmful model behaviors, or improve model performance for specific domains.

    197
    21:13,000 --> 21:25,000
    And as we start employing virtual collaborators around companies, my hope is that we can lean on techniques like interpretability and auditability to be a cornerstone of their work so we can figure out what they're doing at scale.

    198
    21:26,000 --> 21:33,000
    These are the kinds of breakthroughs that that are going to help us transform abstract research into tangible product capabilities.

    199
    21:34,000 --> 21:41,000
    As you saw earlier, we're now at the point where AI models can handle hours of autonomous work, and that's a capability that's doubling every several months.

    200
    21:41,000 --> 21:44,000
    But raw model capability alone isn't enough.

    201
    21:44,000 --> 21:53,000
    To unlock these multi-hour workflows in practice, agents also need access to real-world information, a connection to your existing systems, and cost-efficient scaling.

    202
    21:53,000 --> 21:59,000
    That's why we're launching four interconnected capabilities to help power agents with context and help them scale.

    203
    22:00,000 --> 22:05,000
    So, first off, starting today, you can now connect the model context protocol directly through our API.

    204
    22:05,000 --> 22:12,000
    MCP is already being used by Microsoft, Google, OpenAI, Block, Atlassian, Zapier, Linear, and many more.

    205
    22:12,000 --> 22:13,000
    This was the dream list.

    206
    22:13,000 --> 22:17,000
    When we started creating the MCP protocol and we open sourced it, this was the dream list.

    207
    22:17,000 --> 22:19,000
    It was like, maybe one day we'll get these companies to adopt it.

    208
    22:19,000 --> 22:23,000
    It's less than a year and they've they've all, um, come on board.

    209
    22:23,000 --> 22:33,000
    MCP asks acts as the universal translator and connector for AI agents, enabling seamless connection to your existing system without needing to write a custom bespoke integration every single time.

    210
    22:34,000 --> 22:42,000
    This lays the foundation of what could become the agent economy, where specialized agents have access to the data and tools they need to tackle complex challenges.

    211
    22:44,000 --> 22:48,000
    Second, web search gives Claude real-time access to current information.

    212
    22:48,000 --> 22:56,000
    This is intelligent data augmentation that allows Claude to reason about current events, market trends, and emergent emerging technologies.

    213
    22:56,000 --> 22:58,000
    It's really powerful in combination with the MCP feature as well.

    214
    22:58,000 --> 23:07,000
    You can imagine searching across an internal knowledge source, making some, uh, new, uh, insights, and then going off and searching the web to contextualize them.

    215
    23:07,000 --> 23:16,000
    Third, the Files API is available today in the API to streamline how developers access and store documents, simplifying development workflows.

    216
    23:16,000 --> 23:22,000
    We're also releasing a cookbook to help developers build that memory functionality that I mentioned directly into their applications.

    217
    23:22,000 --> 23:26,000
    These new Claude 4 models have shown significant improvement in what we call self-managed memory.

    218
    23:26,000 --> 23:29,000
    So you'll find that this works surprisingly well.

    219
    23:29,000 --> 23:34,000
    And it can be achieved with very little additional overhead by using the Files API, as we demonstrate in that cookbook.

    220
    23:34,000 --> 23:39,000
    You'll see Claude both read and write to these memory files and maintain contact context over time.

    221
    23:40,000 --> 23:43,000
    Last, power needs to be practical and scalable.

    222
    23:43,000 --> 23:48,000
    We want to ensure that we can grow with you from prototype to production to millions of users.

    223
    23:48,000 --> 23:51,000
    So that you're able to control costs and improve efficiency.

    224
    23:51,000 --> 23:55,000
    We want Claude to work for you as you succeed and reach massive scale.

    225
    23:55,000 --> 24:00,000
    That's why prompt caching was our most requested feature from our most popular API features.

    226
    24:00,000 --> 24:10,000
    With prompt caching, customers can provide Claude with more context, uh, and background knowledge and example outputs, reducing costs by up to 90% and latency by up to 85% for long prompts.

    227
    24:10,000 --> 24:17,000
    Now, every customer I talked to had one very clear request on prompt caching that we're delivering today, which is a longer time to live or TTL.

    228
    24:17,000 --> 24:29,000
    So in addition to the 5-minute TTL we had out of the box with prompt caching, today we're launching a premium 1-hour TTL, which is a 12x improvement that dramatically reduces costs for long-running agent workflows.

    229
    24:29,000 --> 24:33,000
    This infrastructure makes agent applications viable at scale.

    230
    24:34,000 --> 24:36,000
    So these capabilities all compound.

    231
    24:36,000 --> 24:39,000
    When we think about building features into the API, we don't think about them as one-off.

    232
    24:39,000 --> 24:42,000
    We think about how do they complement each other? How do they form a cohesive story?

    233
    24:42,000 --> 24:52,000
    Claude can now execute code, understand your systems, access current information on the web, creating the foundation for agents that operate with full context even for long-running tasks.

    234
    24:52,000 --> 24:57,000
    And it can use the Files API to maintain memory and context during that entire execution.

    235
    24:58,000 --> 25:00,000
    Everything you've seen this morning is just the beginning.

    236
    25:00,000 --> 25:03,000
    Our roadmap continues to build on three pillars.

    237
    25:03,000 --> 25:15,000
    The first is industry-leading agentic tools and applications, so you can use Claude autonomously to handle hours of work, knowing it can use the code environment, uh, code execution tool to execute code in its own environment.

    238
    25:15,000 --> 25:25,000
    Claude Code is now generally available, integrating with VS Code and JetBrains, so you can use the extensive SDKs to build your own custom workflows, including inside GitHub.

    239
    25:25,000 --> 25:29,000
    We'll continue to push on integrating more context in the API.

    240
    25:29,000 --> 25:43,000
    Our updates today allow you to bring the, bring this context via the model context protocol, as well as build on real real-time updates from the web, and execute, uh, complex workflows across any data source and across anything in the API via MCP.

    241
    25:43,000 --> 25:45,000
    And finally, efficient scaling.

    242
    25:45,000 --> 25:51,000
    As of today, you can use the expanded one-hour prompt caching to optimize performance and cost at scale.

    243
    25:52,000 --> 25:54,000
    Each advancement builds on what we've discussed today.

    244
    25:54,000 --> 26:05,000
    With Claude 4 as the foundation, Opus 4 for your most complex, uh, agentic workflows, Sonnet 4 as your daily driver for everyday intelligence, we're enabling a new class of applications.

    245
    26:05,000 --> 26:08,000
    Code execution expands the hours of work that Claude can do.

    246
    26:08,000 --> 26:19,000
    MCP expands the comprehensive information that Claude can retrieve, and our platform updates ensure our models become increasingly efficient for every dollar spent.

    247
    26:19,000 --> 26:25,000
    We're actively learning from developers like yourselves, uh, how you use these tools, so please keep the feedback coming.

    248
    26:25,000 --> 26:27,000
    I love API feedback.

    249
    26:27,000 --> 26:29,000
    If you don't know this about me, like absolutely like ping me.

    250
    26:29,000 --> 26:33,000
    Uh, I love hearing the feedback and how we can continue to improve the API for developers like yourselves.

    251
    26:33,000 --> 26:35,000
    And MCP is a perfect example of this.

    252
    26:35,000 --> 26:40,000
    It started as an internal idea, and then began and graduated to community experimentation.

    253
    26:40,000 --> 26:47,000
    And now it's a core platform feature. If you watch the Microsoft Build keynote, they're building MCP into so much of their, uh, of their real infrastructure as well.

    254
    26:47,000 --> 26:54,000
    We want to create an ecosystem of AI agents where we have the feedback loops to make them actually useful for you.

    255
    26:55,000 --> 26:57,000
    Today we stand at a major threshold.

    256
    26:57,000 --> 27:02,000
    Our latest models, combined with all the latest tools that we've released, are giving you the seeds of a new era.

    257
    27:02,000 --> 27:07,000
    The future isn't about AI doing human work, it's about AI helping humans do superhuman work.

    258
    27:07,000 --> 27:15,000
    And I'm really excited to build this vision together with you, and I can't wait to see the kinds of applications it powers for all of your companies.

    259
    27:15,000 --> 27:28,000
    And to show you what's possible, I'm next going to hand the mic to Kat Wu from our product team to demonstrate how accessing our new models inside Claude Code transforms your development workflows, helping you ship complex multi-day tasks in a single conversation.

    260
    27:28,000 --> 27:32,000
    Welcome again to Code with Claude, and thanks again. Hope you enjoy the rest of your day.

    261
    27:43,000 --> 27:44,000
    Hi, everyone.

    262
    27:44,000 --> 27:48,000
    I'm Kat Wu, product manager for Claude Code.

    263
    27:48,000 --> 27:55,000
    As Mike mentioned, we recently launched Claude Code, our agentic coding tool in research preview.

    264
    27:55,000 --> 28:06,000
    Claude Code gives developers direct access to the raw power of Anthropic's models right where they work in their terminals.

    265
    28:06,000 --> 28:10,000
    As of today, Claude Code is generally available.

    266
    28:16,000 --> 28:27,000
    Throughout computing history, we've continually moved to higher levels of abstraction, from machine code to assembly to high-level languages.

    267
    28:27,000 --> 28:35,000
    With Claude Code and increasingly agentic models, we're witnessing another step forward.

    268
    28:35,000 --> 28:47,000
    Developers are shifting from asking for specific functions to describing entire features, guiding AI and changing how software is built.

    269
    28:47,000 --> 28:58,000
    Today, we're bringing the new Claude 4 models to Claude Code, making it an even more powerful and capable coding agent.

    270
    29:03,000 --> 29:15,000
    And on top of new models, we're releasing several new features in Claude Code, focused on making it a more versatile coding agent across your whole dev life cycle.

    271
    29:16,000 --> 29:26,000
    First, Claude Code now integrates with VS Code and JetBrains IDEs, bringing it to familiar interfaces for millions of developers.

    272
    29:26,000 --> 29:34,000
    As Claude Code works, you can now see its proposed changes in line in your editor.

    273
    29:35,000 --> 29:46,000
    We're also releasing the Claude Code SDK, which allows developers to use Claude Code as a building block in your applications and workflows.

    274
    29:46,000 --> 29:50,000
    The possibilities are endless with the SDK.

    275
    29:50,000 --> 30:01,000
    To showcase these possibilities, we're releasing an open source example of the SDK in action with Claude Code in GitHub.

    276
    30:01,000 --> 30:14,000
    You can tag Claude directly on pull requests and issues in GitHub, and Claude Code will respond to reviewer feedback, fix CI errors, and add new functionality.

    277
    30:15,000 --> 30:23,000
    With these additions, Claude Code now works everywhere you do, acting as a virtual teammate across all surfaces.

    278
    30:23,000 --> 30:37,000
    In the terminal for deep development work, in remote environments like GitHub for automated workflows built on the SDK, and in the IDE for seamless review.

    279
    30:37,000 --> 30:51,000
    All in, Claude Code is a versatile coding agent for accelerating development wherever you are, whether you're working directly with Claude Code interactively or using it asynchronously.

    280
    30:51,000 --> 30:52,000
    Great.

    281
    30:52,000 --> 30:53,000
    My favorite part.

    282
    30:53,000 --> 30:56,000
    Let's see what these updates look like in a demo.

    283
    30:57,000 --> 31:04,000
    I'm going to show Claude Code tackling a real dev task in a product that many of you are familiar with.

    284
    31:04,000 --> 31:14,000
    We'll use Excalidraw, an open source whiteboarding tool, and ask Claude Code to implement one of their most requested features, adding a table component.

    285
    31:14,000 --> 31:25,000
    How many of you have gotten that feature request that's been on your backlog for ages that you know your users would love, but you just haven't had the time to build?

    286
    31:25,000 --> 31:29,000
    This is the kind of task that we can handle much faster with Claude Code.

    287
    31:29,000 --> 31:38,000
    Normally for a task like this, I would set Claude to work, make some coffee, catch up on email and Slack, and come back when the outputs are ready.

    288
    31:38,000 --> 31:45,000
    But I only have 10 minutes with you all today, so let's show a sped up but real workflow.

    289
    31:46,000 --> 31:49,000
    Here's the Excalidraw repo open in VS Code.

    290
    31:49,000 --> 31:53,000
    Let's write a prompt to tell Claude Code our requirements.

    291
    31:53,000 --> 32:04,000
    We'll ask Claude Code to add a table component that supports custom dimensions, drag to resize, and all of Excalidraw's other styling options.

    292
    32:04,000 --> 32:06,000
    Here's where it gets exciting.

    293
    32:06,000 --> 32:12,000
    Claude Code will first create a to-do list for how it'll approach the entire problem.

    294
    32:14,000 --> 32:22,000
    Then, we can see that Claude Code will start to explore the codebase, starting with the file that we already have open for context.

    295
    32:24,000 --> 32:30,000
    The best part of the ID integration is the ability to see diffs in line in the editor.

    296
    32:30,000 --> 32:40,000
    This way, you can see the surrounding code for more context, so you can accept changes with confidence or give Claude Code feedback.

    297
    32:41,000 --> 32:53,000
    We can approve each edit as Claude Code works, or we can let Claude Code continue making edits with auto-accept mode, letting us balance visibility and control.

    298
    32:54,000 --> 33:02,000
    In this demo, we gave Claude Code the ability to make edits, run lint and tests, and make PRs.

    299
    33:03,000 --> 33:06,000
    So Claude Code worked for 90 minutes on this task.

    300
    33:06,000 --> 33:10,000
    I wish I could show you the whole thing, but we need to speed things up.

    301
    33:10,000 --> 33:14,000
    What you're seeing is actual unedited output from Claude Code.

    302
    33:16,000 --> 33:19,000
    An hour and a half later, and it's done.

    303
    33:20,000 --> 33:28,000
    It added table functionality, wrote tests to validate the change, and iterated until lint and tests passed.

    304
    33:28,000 --> 33:37,000
    This normally required us to understand the codebase architecture and how every single other tool was implemented.

    305
    33:37,000 --> 33:42,000
    In this case, Claude Code is literally doing hours of work for us.

    306
    33:42,000 --> 33:43,000
    Pretty impressive, right?

    307
    33:45,000 --> 33:55,000
    Now, let's run Excalidraw locally and just make sure the feature works as we expect.

    308
    33:56,000 --> 34:02,000
    Let's check that we have a fully functional table component by making a three row by three column table.

    309
    34:02,000 --> 34:03,000
    Great.

    310
    34:04,000 --> 34:07,000
    We can reposition the table, we can drag to resize.

    311
    34:07,000 --> 34:14,000
    We can change the border pattern and color, and we can add text to cells.

    312
    34:15,000 --> 34:19,000
    This also integrates with Excalidraw's existing UI.

    313
    34:20,000 --> 34:25,000
    All of this was done with one prompt in Claude Code.

    314
    34:27,000 --> 34:43,000
    Next, we'll ask Claude Code to use the GitHub CLI to create a pull request for this branch.

    315
    34:44,000 --> 34:45,000
    Cool.

    316
    34:45,000 --> 34:46,000
    Let's click in.

    317
    34:48,000 --> 34:50,000
    Now we have our pull request.

    318
    34:50,000 --> 35:00,000
    This is where the Claude Code SDK shines. It lets us build custom workflows on top of Claude Code, including through GitHub actions.

    319
    35:00,000 --> 35:04,000
    For this PR, I'd like to update the docs.

    320
    35:04,000 --> 35:12,000
    Instead of going back to the IDE, we can just tag @Claude and ask it to update our documentation for us.

    321
    35:13,000 --> 35:18,000
    Behind the scenes, this triggers a GitHub action that runs Claude Code.

    322
    35:18,000 --> 35:24,000
    Claude comments on the PR as it works, and it'll it'll make a commit for us when it's done.

    323
    35:25,000 --> 35:31,000
    You can also tag @Claude on a GitHub issue, and it'll also make a PR for you there.

    324
    35:31,000 --> 35:38,000
    With this feature, Claude Code meets users on even more surfaces where they're already working.

    325
    35:38,000 --> 35:46,000
    Devs no longer need to context switch in their local environment, and you can even kick off runs on the go.

    326
    35:46,000 --> 35:49,000
    This is all built on the Claude Code SDK.

    327
    35:49,000 --> 36:06,000
    Beyond powering GitHub actions, we've seen customers do incredible things with the SDK, including running many Claude codes in parallel to fix flaky tests, increase test coverage, and even do on-call triage.

    328
    36:06,000 --> 36:07,000
    Cool.

    329
    36:07,000 --> 36:14,000
    It looks like the action is done running, and we can see Claude Code updating its comment to let us know what it did.

    330
    36:14,000 --> 36:18,000
    Let's click into the commit and see Claude's changes.

    331
    36:20,000 --> 36:28,000
    It updated the documentation for us in our PR and committed it without us having to do a thing.

    332
    36:31,000 --> 36:51,000
    In just 10 minutes, you've seen Claude Code tackle a complex task that would have taken days to implement manually, writing hundreds of lines of code, integrating seamlessly with Excalidraw's existing features, and doing hours of work for us.

    333
    36:51,000 --> 36:53,000
    All of this is available to you today.

    334
    36:53,000 --> 37:05,000
    Claude Code in GitHub actions powered by our SDK is available in beta, and you can install it by running a simple command on the screen within Claude.

    335
    37:05,000 --> 37:10,000
    The VS Code and JetBrains IDE extensions are also live in beta.

    336
    37:10,000 --> 37:14,000
    Just run Claude from your IDE to install.

    337
    37:14,000 --> 37:25,000
    Last but not least, our latest models, Claude Opus 4 and Claude Sonnet 4, are available to Claude Code users today.

    338
    37:26,000 --> 37:39,000
    Claude Code shows what's possible when AI can truly understand and work with code.

    339
    37:39,000 --> 37:48,000
    To build powerful agents, whether coding assistance or applications in any domain, you need more than just intelligent models.

    340
    37:48,000 --> 37:50,000
    You need the right platform.

    341
    37:50,000 --> 37:57,000
    Please welcome Michael Gerstenhaber, who will show you exactly how we're making that possible.

    342
    38:04,000 --> 38:05,000
    Thanks so much, Kat.

    343
    38:05,000 --> 38:07,000
    And good morning, everybody. Thank you so much for being here.

    344
    38:07,000 --> 38:12,000
    I'm Michael Gerstenhaber, head of product for the API platform at Anthropic.

    345
    38:16,000 --> 38:21,000
    How many people here use AI generated code already to write their applications?

    346
    38:21,000 --> 38:22,000
    Yeah.

    347
    38:22,000 --> 38:27,000
    And how many of those are using AI at their core for feature delivery?

    348
    38:27,000 --> 38:29,000
    Right, everybody here. That's what I thought.

    349
    38:29,000 --> 38:35,000
    Most applications in the world will be built by people already trying to solve the world's problems.

    350
    38:35,000 --> 38:42,000
    Whether you pass LeetCode whiteboard interviews or getting started with vibes, we're all software engineers now.

    351
    38:42,000 --> 38:44,000
    But writing code is just the start.

    352
    38:44,000 --> 38:51,000
    You need to more quickly build stable, secure, and maintainable AI applications.

    353
    38:51,000 --> 39:01,000
    And that's why we built the Anthropic platform, a complete toolkit designed for building state-of-the-art AI applications and agents.

    354
    39:01,000 --> 39:07,000
    Our platform is already powering most of the world's AI delivery in every domain.

    355
    39:08,000 --> 39:15,000
    In finance, TurboTax helps millions of customers confidently file taxes with federal tax explainers.

    356
    39:15,000 --> 39:23,000
    In healthcare, Novo Nordisk is using Claude to draft clinical study reports in less than 10 minutes instead of 15 weeks.

    357
    39:23,000 --> 39:27,000
    And the world's best coding assistance run on our platform.

    358
    39:28,000 --> 39:35,000
    Each of these companies took Claude's intelligence and turned it into something uniquely valuable for their users.

    359
    39:36,000 --> 39:49,000
    At its foundation, our platform provides reliable access to Claude through our model inference service, which includes the messages API, and essential tools like prompt caching to optimize performance and costs.

    360
    39:49,000 --> 39:56,000
    Over 50% of all input tokens are cached on the platform, doubling the effective context window for our models.

    361
    39:56,000 --> 40:04,000
    Notion can put vast amounts of your documents in the context window, but maintain snappy real-time execution.

    362
    40:04,000 --> 40:09,000
    This lets them adopt your voice for creative writing and virtually eliminate hallucination.

    363
    40:09,000 --> 40:17,000
    Starting today, we're extending the cache time to live from 5 minutes to 1 hour.

    364
    40:19,000 --> 40:27,000
    Your agents can now maintain complex context across the entire user session without breaking the bank.

    365
    40:27,000 --> 40:29,000
    But that's just the foundation.

    366
    40:29,000 --> 40:33,000
    To build powerful agents, our platform provides powerful building blocks.

    367
    40:33,000 --> 40:37,000
    As Mike shared, we're releasing two new capabilities.

    368
    40:37,000 --> 40:41,000
    The Files API and a code execution tool.

    369
    40:41,000 --> 40:47,000
    Just like you and me, there are some problems that are easier to solve by writing a script.

    370
    40:47,000 --> 40:53,000
    Our platform lets your agents write their own code in production just like you would.

    371
    40:53,000 --> 41:05,000
    These new features join existing components, like web search for real-time information, and citations for grounding responses in source documents.

    372
    41:05,000 --> 41:16,000
    When Thomson Reuters provides analysis to attorneys in CoCounsel, it's critical that they ground this in their legal research, in case law, not in the model's trading data.

    373
    41:16,000 --> 41:24,000
    Our platform also connects your agents and your data and businesses business systems through model context protocol.

    374
    41:24,000 --> 41:33,000
    MCP has taken off within our developer ecosystem with over 3,000 integrations built by the community.

    375
    41:34,000 --> 41:51,000
    Whether your agent is accessing application errors with Sentry, triggering Zapier workflows, or creating Asana tasks, the MCP connector enables the model to interact with any tool, data, or app your task requires.

    376
    41:51,000 --> 41:59,000
    And today, the platform makes it even easier by handling all the technical complexity of tool and API calling for you.

    377
    42:00,000 --> 42:05,000
    One thing that I want to emphasize about the platform is the composability of the APIs.

    378
    42:05,000 --> 42:12,000
    They're building blocks that work together as well as they work apart, helping to solve unique problems that can't be coerced into a cookie cutter shape.

    379
    42:12,000 --> 42:17,000
    Think of Claude as the architect and general contractor for your agent.

    380
    42:17,000 --> 42:21,000
    It doesn't execute predefined sequences or stack components randomly.

    381
    42:21,000 --> 42:31,000
    Instead, it intelligently determines which materials you need, in what order, and how they fit together to create something far more powerful than any individual element.

    382
    42:31,000 --> 42:33,000
    Let me show you what I mean.

    383
    42:33,000 --> 42:40,000
    When you build an agent for complex financial analysis, Claude intelligently assesses the task and orchestrates the right tools.

    384
    42:40,000 --> 42:59,000
    Using MCP to access financial data, spinning up code execution for statistical analysis, searching the web for real-time market data, and grounding insights with citations for accuracy and compliance, iterating and refining based on results.

    385
    42:59,000 --> 43:02,000
    No hard-coded workflow, no brittle scripts.

    386
    43:02,000 --> 43:12,000
    Just intelligent orchestration that allows you to build powerful agent and is seamlessly and seamlessly adopt new capabilities as our research research brings them to life.

    387
    43:12,000 --> 43:25,000
    We understand that prompt quality can make or break an AI application, which is why we created dev tools like the prompt improver and evaluations, along with new observability features that help you get to production and scale faster.

    388
    43:26,000 --> 43:34,000
    Today, we're already helping developers build faster with resources like cookbooks and guides that show you how to implement features like memory into your applications.

    389
    43:35,000 --> 43:46,000
    In the future, we'll adapt these for programmatic access and host them directly on the platform so you can build even more powerful agents that can research and remember on their own in production.

    390
    43:46,000 --> 43:53,000
    Everything we've built centers on one goal, helping you ship better AI faster.

    391
    43:53,000 --> 43:58,000
    The Anthropic platform isn't just tools, it's your path to building industry-leading agents.

    392
    43:58,000 --> 44:11,000
    So thank you all for being here today with me at at Code with Claude. I'll be on the floor the rest of the conference, but it's my privilege to welcome Mario Rodriguez from GitHub to show you exactly what this looks like in production.

    393
    44:17,000 --> 44:18,000
    Thank you.

    394
    44:18,000 --> 44:19,000
    Thank you, Michael.

    395
    44:19,000 --> 44:22,000
    And I am here, um, thrilled to be with you all.

    396
    44:22,000 --> 44:35,000
    We at GitHub are incredibly excited to be part of this energy and innovation and to share more about our deepening partnership with Anthropic, um, this amazing team.

    397
    44:35,000 --> 44:38,000
    Everything GitHub does is anchor in two core beliefs, right?

    398
    44:38,000 --> 44:45,000
    Number one is giving developers choice, and number two is giving them the best developer experience.

    399
    44:45,000 --> 44:51,000
    At GitHub Universe last year, we kicked off the relationship with Anthropic.

    400
    44:51,000 --> 44:58,000
    We announced Claude Sonnet 3.5, a support in VS Code and also in our conversational experiences, just to mention a few.

    401
    44:58,000 --> 50:09,000
    And we did this because we share fundamental belief with Anthropic that AI can be a powerful force and a force multiplier for developers, augmenting their capabilities, not replacing, augmenting their capabilities and freeing them up to focus on what they do best, which is imagination and creativity. Part of being a software developer is being a wizard.

    402
    50:09,000 --> 50:31,000
    Since we haven't expanded, since then we have expanded the partnership and experiences across VS Code, github.com, and our mobile app, just to mention a few. And today, I am delighted to announce that GitHub Copilot supports Claude Sonnet 4 and Opus 4 available right now. We just pulled the trigger right when Dario announced it and every one of those services.

    403
    50:31,000 --> 50:33,000
    That is what ship shipping is all about.

    404
    50:33,000 --> 50:35,000
    Let me tell you, it's really hard to do.

    405
    50:35,000 --> 50:40,000
    I don't know if you've done it with every application that you have done, but it's incredibly hard to do. So thanks to all of the teams that make that happen.

    406
    50:40,000 --> 50:44,000
    Now, as you all surely know, the future of code is what?

    407
    50:44,000 --> 50:45,000
    Agentic.

    408
    50:45,000 --> 50:50,000
    An agent mode in VS Code is our autonomous per programmer that can perform multi-step coding tasks based on your natural language commands.

    409
    50:50,000 --> 51:00,000
    We've seen firsthand how having cloud's intelligence directly within the editor truly helps developers understand complex codebases, um, get faster code to production and increase their productivity without ever leaving the environment they already know, love, and trust.

    410
    51:00,000 --> 51:05,000
    But even that, but even that is single threaded.

    411
    51:05,000 --> 51:09,000
    And in my opinion, the future is multi-threaded.

    412
    51:09,000 --> 51:13,000
    If you think about it, you're in your editor, it becomes a waiting room.

    413
    51:13,000 --> 51:15,000
    You're you're going faster, but it's still a waiting room.

    414
    51:15,000 --> 51:20,000
    And that's why on Monday, we took one step further in announcing GitHub's Copilot coding agent.

    415
    51:20,000 --> 51:23,000
    Now, our coding agent is currently powered by, you probably guessed it, Claude Sonnet.

    416
    51:23,000 --> 51:27,000
    Uh, and, you know, the reason we chose that was very clear to me.

    417
    51:27,000 --> 51:31,000
    So let me just walk you through three things that made that decision possible.

    418
    51:31,000 --> 51:37,000
    Number one, our evaluation showed that Claude demonstrated three main strengths, right?

    419
    51:37,000 --> 51:41,000
    Strong software engineering and coding knowledge, powerful problem solving, and that's very important because sometimes you have to go and look at the code and find the right place to make that edit.

    420
    51:41,000 --> 51:45,000
    And then number three, excellent instruction following.

    421
    51:45,000 --> 51:49,000
    And specifically when thinking about tools and MCP.

    422
    51:49,000 --> 51:54,000
    So when you're building for agentic coding, dealing with these things in large codebases and system prompts, you also need something else, which is caching, right?

    423
    51:54,000 --> 51:57,000
    And that prompt caching, bless you.

    424
    51:57,000 --> 52:02,000
    That prompt caching support we get from the Anthropic API, let us build these experiences in a much cost-effective way.

    425
    52:02,000 --> 52:06,000
    Every token counts and every token counts also on the price side.

    426
    52:06,000 --> 52:11,000
    So the more we save those, the better experience we could provide our customers.

    427
    52:11,000 --> 52:15,000
    Now, on top of that, Claude was already the most frequently selected model in agent mode.

    428
    52:15,000 --> 52:21,000
    So once we put all of those things together, it was very clear to us that Claude Sonnet was the right model choice for agentic coding in GitHub scenarios.

    429
    52:21,000 --> 52:29,000
    Now, with Claude Sonnet 4, we've seen improvement in all of these areas, not just accurate benchmarks like sweet benchmarks, but more importantly on our real world evaluation suites as well.

    430
    52:29,000 --> 52:32,000
    Now, our collaboration goes deeper than this, right?

    431
    52:32,000 --> 52:36,000
    It's not just about integrating models directly.

    432
    52:36,000 --> 52:40,000
    We've been working closely with Anthropic to officially adopt and scale MCP.

    433
    52:40,000 --> 52:46,000
    We're combining intelligence, if you think about this, like these models are incredibly intelligent.

    434
    52:46,000 --> 52:49,000
    You stack like three PhDs on them with knowledge.

    435
    52:49,000 --> 52:53,000
    So how do you get knowledge into that intelligent model?

    436
    52:53,000 --> 52:56,000
    Well, the answer to us is MCP and tools.

    437
    52:56,000 --> 53:01,000
    And that really unlocks the next acceleration of developer tools.

    438
    53:01,000 --> 53:07,000
    Recently, Kevin Scott, that's Microsoft CTO, made the analogy that MCP is like the HTP protocol of the web.

    439
    53:07,000 --> 53:09,000
    And I completely agree with him.

    440
    53:09,000 --> 53:15,000
    So if you have not adopted MCP, do it today, right after this keynote, go and play with it.

    441
    53:15,000 --> 53:18,000
    It's that important.

    442
    53:18,000 --> 53:22,000
    It's the way you get knowledge into these intelligent models.

    443
    53:22,000 --> 53:29,000
    Now, as we step into this new era of software development, we're transforming GitHub's platform.

    444
    53:29,000 --> 53:33,000
    From an AI infused into AI native.

    445
    53:33,000 --> 53:38,000
    From creation to deployment, we envision this SDLC.

    446
    53:38,000 --> 53:44,000
    Powered by an agentic layer at the top of it that spans that inner where you are coding and that outer loop, those asynchronous experiences.

    447
    53:44,000 --> 53:49,000
    And you are going to be an active collaborator every single step of the way.

    448
    53:49,000 --> 53:53,000
    The reason why we say co-pilot is the human is at the center.

    449
    53:53,000 --> 53:56,000
    And then there's agents helping you.

    450
    53:56,000 --> 54:05,000
    That is why we're announcing a new partnership that integrates what Kai just show you, cloud code and the extensible cloud code directly into GitHub's agentic platform.

    451
    54:05,000 --> 54:14,000
    This opens up new possibilities to customize cloud code, remotely invoke it from new surfaces that are embedded into GitHub and our workflows.

    452
    54:14,000 --> 54:17,000
    Again, all on the GitHub platform.

    453
    54:17,000 --> 54:22,000
    Now, we're already done a lot, uh, but the journey with Anthropic is still just beginning in our opinion.

    454
    54:22,000 --> 55:00,000
    We believe that by bringing together GitHub's deep, deep understanding of the developers and Anthropic's AI capabilities through cloud and the platform APIs, we will and we can unlock a future that is more intuitive, more efficient, more ultimately, more human.

    455
    55:00,000 --> 55:02,000
    That human part is important.

    456
    55:02,000 --> 55:09,000
    So I'm excited to see what we continue to build together and also what each of you builds with us.

    457
    55:09,000 --> 55:12,000
    So, thank you so much and please welcome back to the stage, Mike Krieger.

    458
    55:12,000 --> 55:13,000
    Thank you, sir.

    459
    55:13,000 --> 55:14,000
    Hello again.

    460
    55:14,000 --> 55:17,000
    And thanks again to Mario, to Michael, and to Kat.

    461
    55:17,000 --> 55:19,000
    Um, I love the GitHub integration.

    462
    55:19,000 --> 55:25,000
    The last project I did, I actually was like, oh, I can actually just install Claude Code into a GitHub code space and all of a sudden I have Claude Code against the repo that I've already been building.

    463
    55:25,000 --> 55:30,000
    It was really great to hear from each of them and hear all about the exciting work being done with Claude.

    464
    55:30,000 --> 55:37,000
    So to close out the show, I'd like to dive a little bit deeper into Claude 4, our research direction, uh, and what developers can expect next from Anthropic.

    465
    55:37,000 --> 55:43,000
    Um, so please help me welcome back to the stage, Dario for our one-on-one conversation.

    466
    55:43,000 --> 55:44,000
    Welcome back, Dario.

    467
    55:44,000 --> 55:45,000
    Hello again.

    468
    55:45,000 --> 55:46,000
    It's great.

    469
    55:46,000 --> 55:49,000
    This is like our one-on-one in front of the whole, uh, audience. This is great.

    470
    55:49,000 --> 55:52,000
    Um, so Claude 4, uh, uh, is out.

    471
    55:52,000 --> 55:55,000
    Claude Sonnet 4 and Claude Claude Opus 4 are available.

    472
    55:55,000 --> 56:01,000
    Um, what excites you the most about the Claude 4 models and how does it change your thinking about what's possible in the next 12 months?

    473
    56:01,000 --> 56:07,000
    Yeah, so, um, I, I think abstractly the thing I'm most excited about is, you know, every time you have a new class of models, there's like more you can do with it, right?

    474
    56:07,000 --> 56:17,000
    So, uh, uh, you know, we're, we're, we're going to be releasing, uh, models after Claude 4, there'll probably be a Claude 4.1 at some point, just like we did with, uh, with Sonnet, uh, uh, 3.5.

    475
    56:17,000 --> 56:23,000
    And I think we're just at the beginning of, of, of, of, of, you know, what, what, what we can do with the new, the new, the new generation of model.

    476
    56:23,000 --> 56:29,000
    In terms of tasks, I think the autonomy is going to go, uh, uh, is going to go much further than it has already.

    477
    56:29,000 --> 56:35,000
    Just the ability to give, you know, set your model free and, and give it the ability to, you know, do something for, for a long period of time.

    478
    56:35,000 --> 56:38,000
    I think we're, I think we're very much, very much still, still at the beginning of that.

    479
    56:38,000 --> 56:44,000
    Um, uh, I'm, I'm actually increasingly excited about the models for cybersecurity tasks.

    480
    56:44,000 --> 56:51,000
    I mean, you can think of cybersecurity as like a, a, a subset of, of, of coding tasks, but they tend to be higher end coding tasks.

    481
    56:51,000 --> 56:54,000
    And so I think we're maybe finally hitting the threshold for that.

    482
    56:54,000 --> 57:02,000
    And then as a, as a former biologist, I'm, I'm always excited about use of the models for, uh, for, you know, biomedical and kind of, kind of detailed, uh, scientific research work, which I think is, Opus in, Opus in particular is going to be good at, Opus in particular, I think is going to be particularly, particularly strong at that.

    483
    57:02,000 --> 57:04,000
    Um, it really connects, I think to Machines of Loving Grace.

    484
    57:04,000 --> 57:09,000
    So how does Claude 4 fit into that trajectory overall? I like to joke that people think of Machines of Loving Grace as an essay, and I think of it as a product roadmap for the next few years and, uh, curious how Claude 4 fits into that journey.

    485
    57:09,000 --> 57:15,000
    Yeah, it was sort of a product roadmap that I wrote without knowing how to, how to actually get to it and, and kind of said, all right guys, this is your work, this is your job.

    486
    57:15,000 --> 57:21,000
    Um, uh, yeah, uh, you know, I, I think 10 years ago, uh, many people thought that neuroscience would tell us about how to do AI.

    487
    57:21,000 --> 57:27,000
    Um, uh, and indeed there are, you know, a number of former neuroscientists in the field.

    488
    57:27,000 --> 57:32,000
    I'm not, I'm not the only one. There, you know, there are other lab leaders, some who have that, uh, who have that background.

    489
    57:32,000 --> 57:41,000
    Um, and, you know, I found it at a high level, there's some inspiration, but I wouldn't say I've said, oh, you know, this is how the, you know, this thing we know from the hippocampus, we can use for, you know, for, for, for making these models.

    490
    57:41,000 --> 57:43,000
    It's, it's all been pretty much from scratch.

    491
    57:43,000 --> 57:50,000
    But interestingly, things have gone the other way more, which is that using interpretability, we're able to see inside models.

    492
    57:50,000 --> 58:00,000
    And although, of course, they're not made in exactly the same way the human brain is, at, at a, you know, the, at, at kind of superficial level, there's, there's a lot of difference.

    493
    58:00,000 --> 58:09,000
    A lot of the conceptual patterns we have found inside models, sometimes they then get replicated in, in, in neuroscience research.

    494
    58:09,000 --> 58:20,000
    There was something about like high low frequency detectors in vision, um, that, uh, was found via interpretability, via, via one of, one of the people on Chris Ola's team, and then a couple years later, a neuroscientist actually replicated it in, in animal brains.

    495
    58:20,000 --> 58:34,000
    Um, the idea that, for example, vision models separate out, you know, they have one path that, that tends to correspond to color, and, you know, another path that corresponds to, uh, you know, uh, uh, uh, brightness or to the boundaries between objects.

    496
    58:34,000 --> 58:38,000
    These seem to be natural distinctions in the world, right? That are, that are kind of there to be discovered.

    497
    58:38,000 --> 58:43,000
    And anytime you have any kind of abstract learning system, whether it's artificial or biological, you kind of discover the same things.

    498
    58:43,000 --> 58:44,000
    So it's very interesting.

    499
    58:44,000 --> 58:47,000
    I'm really curious how the circuits paper ends up affecting neuroscience research as well.

    500
    58:47,000 --> 58:50,000
    Um, let's move into the five to 10 year time horizon.

    501
    58:50,000 --> 58:56,000
    Um, to the extent that that is even possible in AI as, as we move optimistically, maybe realistically, it's probably one year in real time.

    502
    58:56,000 --> 59:00,000
    Um, when do you think there'll be the first billion dollar company with one human employee?

    503
    59:00,000 --> 59:01,000
    2026.

    504
    59:01,000 --> 59:02,000
    Yeah.

    505
    59:02,000 --> 59:03,000
    No, no, I, I'd absolutely buy that.

    506
    59:03,000 --> 59:04,000
    Yeah.

    507
    59:04,000 --> 59:08,000
    Um, do you have any advice for people building with Claude, um, for the next year?

    508
    59:08,000 --> 59:11,000
    How to think about building at that frontier as well?

    509
    59:11,000 --> 59:21,000
    Yeah, um, I, you know, I think there's like a lot of very specific things you could say about like how, about how to use the models, but I feel like because of this whole like relativistic time dilation thing, this like speeding things up, like almost all the advice is drowned out by like one sentence, which is, or maybe two words, which is just be ambitious.

    510
    59:21,000 --> 59:26,000
    Um, like build something that's greater than you think is, is possible.

    511
    59:26,000 --> 59:36,000
    And even if it doesn't quite work yet, another model will come out in the next generation, which right now is three months, but like probably it's going to go down to two months, then one month.

    512
    59:36,000 --> 59:48,000
    And, you know, then, then if I want to come up this year, maybe I'll be giving advice that's like, oh, you know, don't build anything today, you know, we're releasing something today, but by tonight it'll be, you know, you won't want to be building with this tonight.

    513
    59:48,000 --> 59:57,000
    I talked to a founder who started a company two years ago in the sort of autonomous AI coding agent space, and he basically tried every single model and his startup wasn't working.

    514
    59:57,000 --> 01:00:04,000
    And then it was actually 3.7 where he's like, my startup works now. And it was the same thing of like this thing that I was trying that was really hard, all of a sudden is now, um, possible.

    515
    01:00:04,000 --> 01:00:11,000
    But hitting your head against the wall actually sometimes can be useful because you put all the other pieces in place.

    516
    01:00:11,000 --> 01:00:11,000
    Yes.

    517
    01:00:11,000 --> 01:00:20,000
    And, and when the model works, it's almost like you've built something that's like more robust than it needs to be, and that can be like a positive property.

    518
    01:00:20,000 --> 01:00:25,000
    Um, so, so, you know, as much as I joke about like, oh, you should just, you know, you can just wait for the next model.

    519
    01:00:25,000 --> 01:00:34,000
    Actually, hitting your head against the wall, as long as it's something that's like almost possible, if it's not like, you know, like three years out from, from what's possible, um, I think it can actually be productive.

    520
    01:00:34,000 --> 01:00:41,000
    We saw that even with advanced research internally, like our, our research and Claude Skills team had built a prototype of this, and the model kind of lost its way, it wasn't good at using tools.

    521
    01:00:41,000 --> 01:00:51,000
    And then with 3.7, especially with Claude 4, I think you'll find that it does advanced research really, really well as well. And it's because we were trying and kind of failing along the way as well.

    522
    01:00:51,000 --> 01:00:57,000
    Yeah, it's, it's almost as if you want to run your, you want to run your startup as like speculative execution against the next model, right?

    523
    01:00:57,000 --> 01:00:59,000
    There's some kind of like, I don't know.

    524
    01:00:59,000 --> 01:01:00,000
    I love that.

    525
    01:01:00,000 --> 01:01:00,000
    Yeah.

    526
    01:01:00,000 --> 01:01:01,000
    I think that's exactly right.

    527
    01:01:01,000 --> 01:01:03,000
    Um, all right, so last question to wrap up.

    528
    01:01:03,000 --> 01:01:09,000
    Um, for many of us today, um, who aren't Dario, we couldn't have imagined the progress that AI has made, um, and the rapid pace of change.

    529
    01:01:09,000 --> 01:01:12,000
    What are you most excited about for the coming year and then in the next five years?

    530
    01:01:13,000 --> 01:01:15,000
    Um, yeah, so, uh, I think for in the next coming year, uh, we are going to see incredible things in, in, in code.

    531
    01:01:22,000 --> 01:01:31,000
    I would refer again to kind of the, you know, taking where we are with Claude Code and where we are with the coding models and going from there to kind of, to kind of the agent fleets.

    532
    01:01:31,000 --> 01:01:44,000
    Um, I think this will have an interesting effect in the world, which is, I don't know that we've thought carefully, like from an economic or business perspective, about what happens when the cost of producing software goes down.

    533
    01:01:44,000 --> 01:01:55,000
    It's kind of an assumption, an article of faith that you only make software if it's only worth it to make it if millions of people use it, or at least hundreds of thousands, or maybe tens of thousands.

    534
    01:01:55,000 --> 01:02:01,000
    Like, you wouldn't make, you, you know, you, you, you like wouldn't make a whole piece of software for this event, right?

    535
    01:02:01,000 --> 01:02:09,000
    Like you might throw together something, but like when it just becomes really cheap, when it costs you 20 cents to like, oh, let's just, let's just throw, let's just throw together something that, you know, you know, changes, you know, change changes my vision for this particular event or something like that.

    536
    01:02:09,000 --> 01:02:16,000
    Um, uh, I think the world is going to be very different when these things can be made ad hoc on a, on a one, one, one-off basis in like a few seconds for, for less than a, for, for less than a dollar.

    537
    01:02:16,000 --> 01:02:21,000
    What are, what is the role of the developer there? What is the role of businesses? What is the role of startups?

    538
    01:02:21,000 --> 01:02:26,000
    Um, and what is, what is the experience of the, of the, you know, of the, of the people using it?

    539
    01:02:26,000 --> 01:02:28,000
    I think we don't know the answer to any of those questions. So that's very interesting.

    540
    01:02:28,000 --> 01:02:32,000
    On the, on the five year time scale, I will return again to biology.

    541
    01:02:32,000 --> 01:02:39,000
    I think the biomedical stuff will not be revolutionized in the next year because it's, it's kind of, you know, slow to, slow to happen.

    542
    01:02:39,000 --> 01:02:49,000
    But, uh, yeah, yeah, I hope that, uh, five years from now we will have, uh, vanquished, uh, many of the diseases that now, uh, that now exist.

    543
    01:02:49,000 --> 01:02:50,000
    I love it.

    544
    01:02:50,000 --> 01:02:50,000
    We'll leave it with that.

    545
    01:02:50,000 --> 01:02:52,000
    Unfortunately, we do have to wrap up. I feel like we could talk for another 40 minutes.

    546
    01:02:52,000 --> 01:02:55,000
    So first, I want to thank Dario for spending time with us today. Thank you, Dario.

    547
    01:02:55,000 --> 01:02:59,000
    I also want to thank all of you who are here in person and those watching via live stream.

    548
    01:02:59,000 --> 01:03:01,000
    Uh, but before we close, I almost forgot one thing.

    549
    01:03:01,000 --> 01:03:09,000
    Um, as a special thank you to everyone who joined us today at Code with Claude in person, I'm excited to announce that each of you will receive free access to Max 20X, uh, our highest tier plan for three months.

    550
    01:03:09,000 --> 01:03:10,000
    So look out for that.

    551
    01:03:10,000 --> 01:03:14,000
    I especially love using Max with Claude Code, so you'll be able to do that as well.

    552
    01:03:14,000 --> 01:03:16,000
    So we can't wait to see what you build.

    553
    01:03:16,000 --> 01:03:20,000
    Uh, have a great rest of your day with the different, um, sessions, and welcome again to Code with Claude.

    554
    01:03:20,000 --> 01:03:21,000
    Thanks for coming.

    555
    01:03:21,000 --> 01:03:22,000
    Thanks for coming, everyone.

    556
    01:03:22,000 --> 01:03:22,000
    Thank you, sir.
    ```
    ```

- 文字起こし[jp]：

    ```markdown
    ```srt
    1
    00:01:02,000 --> 00:01:07,000
    Anthropicの最高製品責任者、マイク・クリーガーをステージにお迎えください。

    2
    00:01:17,000 --> 00:01:23,000
    皆さん、おはようございます。Anthropic初の開発者会議「Code with Claude」へようこそ。皆様にお会いできて本当に嬉しいです。

    3
    00:01:23,000 --> 00:01:27,000
    マイク・クリーガーです。Anthropicの最高製品責任者を務めています。

    4
    00:01:27,000 --> 00:01:34,000
    ちょうど1年を迎えました。AIの年数で言えば約3年ですが、とても楽しんでいます。

    5
    00:01:34,000 --> 00:01:43,000
    その前はInstagramを共同創業し、AI搭載のニュースアプリArtifactも共同創業しました。そこで多くのAI技術に初めて触れました。

    6
    00:01:43,000 --> 00:01:51,000
    Anthropicには、創業者のビジョンに惹かれて入社しました。強力で、かつ役立ち、信頼できるAIシステムを構築するというビジョンです。

    7
    00:01:51,000 --> 00:02:02,000
    今日、そのビジョンには、皆様のような開発者が仕事の進め方や企業の構築方法を変革できるよう支援するという、即座かつ具体的なコミットメントが含まれています。

    8
    00:02:02,000 --> 00:02:07,000
    この変革は、人間の創造性を置き換えるのではなく、増強することにあります。

    9
    00:02:07,000 --> 00:02:11,000
    AIエージェントは、私たちの働き方とイノベーションの方法を変えています。

    10
    00:02:11,000 --> 00:02:17,000
    人間の生産性を制限してきたボトルネックを取り除くことで、私たちが構築できるものを拡大しています。

    11
    00:02:17,000 --> 00:02:25,000
    本日は、当社の製品およびエンジニアリングリーダー、そして一部のお客様から、彼らがどのように最先端を押し進めているかについてお話しいただきます。

    12
    00:02:25,000 --> 00:02:44,000
    本日のCode with Claudeで何が期待できるかというと、Claudeを使った構築方法を変革するための3つの技術的な深掘りセッション、Anthropicのプラットフォームをすでに活用して業界を再構築している主要企業による5つのセッション、そして実践的な体験のための専用オフィスアワーとワークショップにご参加いただけます。

    13
    00:02:44,000 --> 00:02:51,000
    しかし、私が皆様にご紹介するエキサイティングな新しいAPI機能について話す前に、ゲストをステージにお招きしたいと思います。

    14
    00:02:51,000 --> 00:02:55,000
    CEO兼共同創設者のダリオ・アマーデイをお迎えください。

    15
    00:03:04,000 --> 00:03:05,000
    皆さん、こんにちは。

    16
    00:03:05,000 --> 00:03:14,000
    ええ、20分後に炉辺談話で戻ってきますので、今回は本当に手短に話します。

    17
    00:03:14,000 --> 00:03:19,000
    ええと、私は物事を誇張するタイプではないので、これ以上大げさなことは言わずに、これだけお伝えします。

    18
    00:03:19,000 --> 00:03:29,000
    まさにこの瞬間から、Claude 4 OpusとClaude 4 Sonnetを、関連するすべての製品サービスでリリースすることを発表します。

    19
    00:03:35,000 --> 00:03:52,000
    さて、Opusモデルはしばらく登場していませんでしたが、念のため申し上げると、Opusは最も高性能でインテリジェントなモデルです。そしてSonnetは、皆様がご存知の、この約1年間ご愛用いただいている中堅モデルです。

    20
    00:03:52,000 --> 00:03:56,000
    それは知性と効率性の良いバランスが取れています。

    21
    00:03:56,000 --> 00:04:03,000
    ええと、私たちは両方を設計する際に、それぞれの最適なユースケースとタイミングがあるように心がけました。

    22
    00:04:03,000 --> 00:04:09,000
    ですので、この2つについて非常に手短にお話しし、その後マイクにバトンを渡し、私は炉辺談話に戻ります。

    23
    00:04:09,000 --> 00:04:12,000
    ええと、まずOpusについて話しましょう。

    24
    00:04:12,000 --> 00:04:17,000
    これは特にコーディングとエージェントタスクのために設計されています。

    25
    00:04:17,000 --> 00:04:25,000
    ええと、Swebench、Terminal Bench、その他いくつかのベンチマークで最先端の性能を発揮します。

    26
    00:04:25,000 --> 00:04:32,000
    ええと、しかし多くの点で、大規模モデルでよく見られるように、ベンチマークだけではその真価を完全に測ることはできません。

    27
    00:04:32,000 --> 00:04:41,000
    ええと、私たちがプレビューを提供したお客様は、人間が6、7時間かかるタスクを自律的にこなせることを発見しました。

    28
    00:04:41,000 --> 00:04:50,000
    ええと、Anthropic社内では、最も経験豊富なエンジニアたちが、それがどれほど生産性を向上させたかに驚いているのを見てきました。

    29
    00:04:50,000 --> 00:05:08,000
    そして、実際に初めて、私がクロードが書いた社内要約、文書、アイデアを見たとき、以前は品質は良かったものの、人間が書いたものと間違えることはありませんでした。なぜなら、常にその特定のスタイルがあったからです。

    30
    00:05:08,000 --> 00:05:18,000
    今回初めて、本当に騙されました。実際に返ってきたものを見て、名前をさっと読んだら、チームの誰かのことだと思ってしまったんです。いや、名前はクロードでした。

    31
    00:05:18,000 --> 00:05:24,000
    ええと、ええと、Opusにはたくさんの可能性があると思います。

    32
    00:05:24,000 --> 00:05:36,000
    ええと、Sonnetについては、多くの人にとって、Sonnet 3.7からの厳密なアップデート、厳密な改善となるでしょう。同じコストでより優れた知能を提供します。

    33
    00:05:36,000 --> 00:05:40,000
    多くのお客様は、単に一方から他方へ直接切り替えています。

    34
    00:05:40,000 --> 00:05:49,000
    実際、一部のコーディングベンチマークではOpusと同等の性能を発揮しますが、より無駄がなく、焦点を絞っていると思います。

    35
    00:05:49,000 --> 00:06:06,000
    ええと、特に、Sonnet 3.7で受けたフィードバックの一部、つまり過剰な熱意、要求された以上のことをしようとする傾向（これは怠惰の反対で、以前の問題でした）や、報酬ハッキングの問題に対処していると思います。

    36
    00:06:06,000 --> 00:06:12,000
    したがって、多くのお客様がこれを試しており、3.7からの強力なアップグレードと見ています。

    37
    00:06:12,000 --> 00:06:25,000
    例えば、ええと、こちらのCursorは、私たちのよく知られた顧客の一社で、これを試しており、これは最先端の、ええと、これは、これは、これは最先端のコーディングモデルだと言っています。

    38
    06:25:000 --> 06:33:000
    ええと、複雑なコードベースの理解において飛躍的な進歩を遂げており、開発者は全体的な機能向上を経験すると期待しています。

    39
    06:33:000 --> 06:38:000
    ええと、実際にモデルを試していたあるお客様は、「このモデルは一体何だ？」と言っていました。

    40
    06:38:000 --> 06:40:000
    ええと、本当に、本当に素晴らしいです。

    41
    06:40:000 --> 06:50:000
    ですので、詳細は他の方にお任せしますが、最後に申し上げたいのは、Claude 4シリーズのモデルを継続的に改善していくということです。

    42
    06:50:000 --> 07:00:000
    定期的にマイナーバージョンのアップデートをリリースする予定で、理想的にはSonnetよりも頻繁に行うことを期待しています。

    43
    07:00:000 --> 07:01:000
    ですから、それは公開されるはずです。

    44
    07:01:000 --> 07:12:000
    現時点では、ほぼすべてのプラットフォームで試せるはずです。Free TierはSonnetのみですが、他のすべてのプラットフォーム、すべてのAPIプラットフォームでは両方利用できます。

    45
    07:12:000 --> 07:17:000
    ええと、このモデルを楽しんでいただければ幸いです。マイクにバトンを渡します。

    46
    07:25:000 --> 07:26:000
    ダリオ、ありがとう。

    47
    07:26:000 --> 07:28:000
    2つの新しいモデル、そして皆さんがここで最初に聞きました。

    48
    07:28:000 --> 07:37:000
    ええと、ダリオは、彼が言ったように、議題の最後にQ&Aで再び登場します。そこで、皆さんが今考えているであろう質問を彼に尋ねることができます。

    49
    07:37:000 --> 07:42,000
    個人的には、お客様がClaude Opus 4とSonnet 4の両方を試すのを楽しみにしています。

    50
    07:42,000 --> 07:46,000
    私たちのチームは彼らとの仕事を楽しんでおり、皆様もそうなると思います。

    51
    07:46,000 --> 07:52,000
    ええと、ダリオが私たちの大きなモデルのニュースを共有したので、次は詳細なAPIロードマップについてお話しします。

    52
    07:52,000 --> 07:55,000
    Claude 4を構築する上での私たちの目標は、最初から明確でした。

    53
    07:55:000 --> 08:06:000
    私たちは、新しいモデル機能を安全に導入し、コーディングとAIエージェントの最前線を前進させ、Claudeが皆様の仮想コラボレーターとなるような強力なAIを構築したいと考えていました。

    54
    08:06:000 --> 08:09:000
    そして、Opus 4とSonnet 4でまさにそれを実現しました。

    55
    08:09:000 --> 08:19:000
    ええと、Sonnet 3.7と同様に、Claude 4モデルは両方ともハイブリッドモデルと呼んでいます。これらは、ほぼ瞬時の応答と、より深い推論が必要な場合の拡張思考という2つのモードを持っています。

    56
    08:19:000 --> 08:25:000
    非コーディングや非数学のユースケースでも、多くの顧客がより深い推論を使用していることに驚いています。

    57
    08:25:000 --> 08:28:000
    Opus 4は、コードベースの理解と追加の計画に優れています。

    58
    08:28:000 --> 08:34:000
    移行からコードのリファクタリングまで、あらゆる面で非常に効果的で正確です。

    59
    08:34:000 --> 08:37:000
    また、最も複雑なエージェントワークフローにも最適な選択肢です。

    60
    08:37:000 --> 08:44:000
    他のモデルで壁にぶつかった経験があるなら、Opus 4でできることに本当に驚かれると思います。

    61
    08:44:000 --> 08:50:000
    一方、Sonnet 4は、日常的なコーディングタスク、アプリ開発、ペアプログラミングに優れています。

    62
    08:50:000 --> 08:52:000
    大量のユースケースにも最適です。

    63
    08:52:000 --> 08:55:000
    効率性とパフォーマンスのバランスが完璧です。

    64
    08:55:000 --> 08:58:000
    いつでも頼れるコーディングパートナーと考えてください。

    65
    08:58:000 --> 09:06:000
    ダリオが述べたように、両モデルは本日よりClaude、Claude Code、Anthropic API、Amazon Bedrock、Google CloudのVertex AIで利用可能です。

    66
    09:06:000 --> 09:09:000
    これらのモデルは、AIエージェントを構築するための重要な新機能をもたらします。

    67
    09:09:000 --> 09:21:000
    これらは、推論プロセス中にウェブ検索のようなツールを使用でき（これは新しい機能です）、複数のツールを並行して扱い、ローカルファイルへのアクセスが許可されている場合、セッション間でメモリを維持して時間とともに知識を構築することができます。

    68
    09:21:000 --> 09:24:000
    そのメモリ機能については、後でダリオと少し話します。

    69
    09:24:000 --> 09:29:000
    これらは単なる漸進的な改善ではなく、AIエージェントにとって何が可能かを根本的に変えるものです。

    70
    09:30:000 --> 09:32:000
    さて、最近「エージェント」という言葉がよく使われるのは知っています。

    71
    09:32:000 --> 09:37:000
    個人的なジョークですが、Anthropicの会議で「エージェント」という言葉を使わずに何分間持ちこたえられるか、というものです。

    72
    09:37:000 --> 09:40:000
    確か、17分くらいだったかな。

    73
    09:40:000 --> 09:44,000
    ええと、しかし今日私たちが焦点を当てるのは、誇大広告を超えたエージェントです。

    74
    09:44,000 --> 09:55,000
    ええと、本当に重要なのは、適切な基盤モデルと適切な基盤プラットフォームツールがあれば、AIエージェントは人間の想像力を前例のない規模で具体的な現実へと変えることができるということです。

    75
    09:55:000 --> 10:00,000
    そして、それは皆様のようなスタートアップや開発者にとって特に重要です。

    76
    10:00:000 --> 10:08,000
    私自身も創業者ですが、Instagramの初期を振り返ると、私たちの有名なほど小さなチームは、非常に苦痛な二者択一の決断をたくさん下さなければなりませんでした。

    77
    10:08:000 --> 10:15,000
    製品に動画を追加するか、あるいは私たちの核となる創造性に集中するか、どちらかでした。

    78
    10:15:000 --> 10:20:000
    モバイルアプリ、最初は単一のモバイルアプリに集中するか、あるいはウェブに拡大するか。

    79
    10:20:000 --> 10:23:000
    全てが非常に単一のトラックでした。

    80
    10:24:000 --> 10:32,000
    AIエージェントを使えば、スタートアップは並行して実験を行い、ユーザーから学び、これまで以上に迅速に製品を構築できるようになります。これは、皆様の多くから聞いてきたことです。

    81
    10:32:000 --> 10:40,000
    そしてAIエージェントは、スタートアップの創業者である皆様に、強力なCFOから得られるような戦略的思考へのアクセスを提供できます。

    82
    10:40:000 --> 10:45,000
    最前列に当社のCFO、または製品責任者がいますが、彼らがまだ主要な役職を目指して構築している間も、皆様ご自身で。

    83
    10:45:000 --> 10:50:000
    それらの採用を行う準備はできていませんが、当面の間、Claudeをそれらの役割に雇うことができます。

    84
    10:50:000 --> 10:52:000
    この変革はもはや理論的なものではありません。

    85
    10:52:000 --> 10:55:000
    私は自分の役割と仕事の中で、毎日それを見ています。

    86
    10:55:000 --> 10:59:000
    個人的にはClaudeと多くの時間を過ごしています。もしかしたら、大切な人よりもClaudeと過ごす時間が多いかもしれません。

    87
    10:59:000 --> 11:00:000
    大丈夫です。

    88
    11:00:000 --> 11:11:000
    実際、Anthropicに入社してすぐ、AmazonのAlexaチームと話し合い、Claudeが音声アシスタントの未来に関する彼らのビジョンの一部となる可能性を彼らが熱心に見ていました。

    89
    11:11:000 --> 11:17:000
    最初、私のチームはスライドや話のポイントを提示する予定でした。他の顧客にも行うような計画です。

    90
    11:17:000 --> 11:23:000
    しかし、会議までの数日間、私はこのしつこい考えを持っていました。「なぜClaude自身を使って実践的なデモを構築しないのか？」と。

    91
    11:23:000 --> 11:30:000
    それによって会話がより面白くなり、ClaudeとAlexaの機能が連携する可能性が具体化すると考えました。

    92
    11:30:000 --> 11:35:000
    課題は、Alexaの実際のコードベースにアクセスすることなく、このデモを構築することでした。

    93
    11:35:000 --> 11:45:000
    私たちは、Alexaの核となる機能のプロトタイプを作成する必要があり、同時にClaudeの機能を統合し、これらすべてを1週間のタイトなスケジュール、いや、実際には1週末のタイトなスケジュールで実現しなければなりませんでした。

    94
    11:45:000 --> 11:50:000
    Claudeがいたからこそ、この限られた時間枠でこれを成し遂げることができました。

    95
    11:50:000 --> 11:56:000
    サンフランシスコとロンドンに分かれた3人チームは、可能性を示す機能的なプロトタイプを構築しました。

    96
    11:56:000 --> 11:58:000
    そしてClaudeのおかげで、この取り組みは成功しました。

    97
    11:58:000 --> 11:59:000
    私もコードの一部を書くことができました。

    98
    11:59:000 --> 12:06:000
    エンジニアをエンジニアリングやCTOの役割から外すことはできても、私からエンジニアリングを奪うことはできません。プロジェクト自体のフロントエンド開発の多くを行いました。

    99
    12:06:000 --> 12:10:000
    もちろん、最初の会議の後、パートナーシップにはさらに多くの作業が投入されました。

    100
    12:10:000 --> 12:17:000
    ええと、Claudeは現在、AmazonがAlexa Plusに利用しているモデルの一つで、今年初めにローンチされ、現在展開中です。

    101
    12:17:000 --> 12:21:000
    そして、Claudeのおかげで、その可能性を本当に示すことができたと思います。

    102
    12:21:000 --> 12:24,000
    私は何年も前から、エージェントAIへの進化を観察してきました。

    103
    12:24:000 --> 12:33,000
    ええと、2021年にGitHub Copilotのデモと早期アクセスを初めて手にしたとき、私はそれをこれまで見た中で最も驚くべき機械学習アプリケーションだと呼びました。

    104
    12:33:000 --> 12:36,000
    当時、2021年にはAIではなく機械学習と呼んでいました。

    105
    12:36:000 --> 12:41,000
    それは数世代前のことですが、このエージェントAIの初期の片鱗には、本当に大きな可能性が秘められていることが明らかでした。

    106
    12:41:000 --> 12:45,000
    昨夏、Artifactsをローンチしたとき、さらに強い手応えを感じました。

    107
    12:45:000 --> 12:53,000
    ミニアプリや可視化で欲しいものを説明し、送信ボタンを押してコーヒーを淹れに行き、戻ってくるとClaudeが私が想像したものを構築してくれていました。

    108
    12:53:000 --> 13:00,000
    そして翌年、より良いツールを構築しているだけでなく、真のコラボレーターを生み出していることが明らかになりました。

    109
    13:00:000 --> 13:04,000
    Anthropicの経済研究は、私が直接見てきたことを裏付けています。

    110
    13:04:000 --> 13:08,000
    ほとんどのユースケースにおいて、AIは人間の仕事を置き換えるのではなく、増強しています。

    111
    13:08:000 --> 13:11,000
    それは役割全体よりも、タスクに関するものです。

    112
    13:11:000 --> 13:14,000
    そして、これはあなたの最高の同僚が持つ影響力に似ています。

    113
    13:14:000 --> 13:24,000
    あなたが一緒に働く最も才能ある人々は、単に実行するだけでなく、あなたの状況を理解し、経験から学び、いつ主導権を握るべきか、いつ報告するべきかを知っています。

    114
    13:24:000 --> 13:29,000
    私たちのプラットフォームで構築できるような優れたAIエージェントは、3つの能力に優れているべきです。

    115
    13:29:000 --> 13:37,000
    それらは文脈的知能を持ち、あなたとあなたの組織のユニークな文脈を理解し、経験から継続的に学習するべきです。

    116
    13:37:000 --> 13:40,000
    指示に従うだけでなく、その理由と方法を理解することです。

    117
    13:40:000 --> 13:47,000
    それは、時間とともに学習しパーソナライズされるモデルを意味し、文脈的な記憶だけでなく、エピソード的記憶や組織的記憶も獲得します。

    118
    13:47:000 --> 13:57,000
    私がチームにいつも言っているのは、エージェントとの100回目のタスクは、最初のタスクよりもはるかに優れているべきだということです。まるで従業員との100日目が、適切なトレーニングを行っていれば最初の1日よりもはるかに優れているべきであるのと同じです。

    119
    13:57:000 --> 14:07:000
    第二に、長時間実行。複雑な数時間かかるタスクを絶え間ない管理なしで処理し、必要に応じて他のエージェントや人間と連携することです。

    120
    14:07:000 --> 14:11:000
    つまり、文脈を把握し、それをより長い期間にわたって実行できるということです。

    121
    14:11:000 --> 14:20:000
    そして第三に、真のコラボレーション。意味のある対話に参加し、あなたの働き方に適応し、彼らの行動に対する透明な推論を提供することです。

    122
    14:20:000 --> 14:25:000
    ここでの重要な洞察は、真の主体性とは制御不能な行動を意味しないということです。

    123
    14:25:000 --> 14:27:000
    そして自律性とは、ええと、ただやみくもに突っ走ることではありません。

    124
    14:27:000 --> 14:39:000
    それは、明確なチェックポイントとバランスの取れたインテリジェントな自律性を意味します。重要な決定には人間の監視を維持しつつ、通常私たちの多くの時間を消費する小さな決定は委任します。

    125
    14:39:000 --> 14:43:000
    さて、これら3つのニーズに応えるために発表する機能について話しましょう。

    126
    14:43:000 --> 14:48:000
    まず、本日Anthropic APIで利用可能な新しいコード実行ツールから始めます。

    127
    14:48:000 --> 14:57:000
    コード実行ツールはClaudeにコードを実行できる環境を提供し、生データを視覚的な洞察に変換できるデータアナリストとして機能することを可能にします。

    128
    14:57:000 --> 15:00:000
    Claudeはもはやコードを書くだけでなく、実行できるようになりました。

    129
    15:00:000 --> 15:07:000
    結果を確認し、結果とコードを繰り返し洗練させることで、データ内のパターンをより効果的に強調できます。

    130
    15:07:000 --> 15:13:000
    ここでは、Claudeが売上データを分析して、特定の種類の製品がどのように機能しているかを示すデモを行います。

    131
    15:13:000 --> 15:20:000
    Claudeはデータセットを読み込み、クリーンアップし、探索的チャートを生成し、異常をリアルタイムでドリルダウンできます。

    132
    15:20:000 --> 15:24:000
    データ可視化アナリストとしてキャリアをスタートさせた私にとって、これは非常に共感できます。

    133
    15:24:000 --> 15:30:000
    そして、コード実行ツールは、Claude 4モデルの知能と組み合わせることで、さらに強力になります。

    134
    15:30:000 --> 15:36:000
    これが私たちが「エージェンシー」と呼ぶものです。複雑なタスクを引き受け、それを完了まで見届ける能力です。

    135
    15:37:000 --> 15:43:000
    これらは何時間ものタスクを処理できる最初のモデルであり、彼らと一緒に作業することで、半日、あるいは丸一日分の時間を節約できます。

    136
    15:43:000 --> 15:50:000
    そして、コードスニペットを書くだけでなく、コードベース全体をリファクタリングしたり、複雑な機能をゼロから実装したりすることもできます。

    137
    15:50:000 --> 15:57:000
    私たちが目にしている進歩の様子をお伝えすると、私が仕事を始めた頃は、Claude 3に数分間の作業を委任する程度でした。

    138
    15:57:000 --> 16:02:000
    一方、Claude 3.7は、約45分間、途切れることなく自律的に作業できました。

    139
    16:02:000 --> 16:07:000
    そして今、Claudeは自律的に何時間もの作業をこなせるようになりました。

    140
    16:08:000 --> 16:14:000
    先ほどご覧いただいたように、楽天はClaudeを7時間連続で自律的に稼働させ、その性能を維持したと述べていました。

    141
    16:14:000 --> 16:19:000
    特に、自身のメモリとToDoリストを管理できるため、途切れることなく作業を継続できます。

    142
    16:20:000 --> 16:22:000
    私たちはすでに、皆様の職場でこの機能を統合しています。

    143
    16:22:000 --> 16:28:000
    数ヶ月前に研究プレビューでリリースした、私たちのエージェントコーディングツールであるClaude Codeを皆様がご存知であることを願っています。

    144
    16:28:000 --> 16:32:000
    本日、Claude Codeを一般公開します。

    145
    16:32:000 --> 16:35:000
    これは実際、当社のテックリードの一人であるボリスによる社内探索プロジェクトとして始まりました。

    146
    16:35:000 --> 16:40:000
    これは彼の発表投稿で、Claudeがターミナルで直接コーディングするのを手助けしてほしいと考えていました。

    147
    16:40:000 --> 16:43:000
    ええと、ごく初期の頃は、社内でClaude CLIと呼んでいました。

    148
    16:43:000 --> 16:48:000
    ArtifactsやClaude Codeのような私たちの最高のイノベーションのいくつかは、このようなボトムアップの実験から生まれたと私は思います。

    149
    16:48:000 --> 16:51:000
    それはAnthropicで育もうとしている文化の一部です。

    150
    16:51:000 --> 16:55:000
    社内でローンチしてわずか2日で、私たちの利用状況グラフは垂直に伸びました。

    151
    16:55:000 --> 16:56:000
    人々はプロダクトマーケットフィットについて話します。

    152
    16:56:000 --> 16:59:000
    私たちはよく「プロダクト・アントロピック・フィット」について話します。

    153
    16:59:000 --> 17:00:000
    社内でドッグフーディングしているか？

    154
    17:00:000 --> 17:01:000
    彼らはそれを使っているか？

    155
    17:01:000 --> 17:08:000
    今日、ほとんどのAnthropicの従業員は、日常的なコーディングから大規模な移行まで、あらゆることにそれを利用しています。

    156
    17:08:000 --> 17:13:000
    最も熟練したコーダーたちが、複数のターミナルウィンドウでClaude Codeの複数のコピーを実行しているのを見てきました。

    157
    17:13:000 --> 17:23:000
    彼らは単なるエンジニアから、複数の自律エージェントのマネージャーへと移行し、単純なコーディングタスクから複数のコードベースにまたがる複雑なフルスタック開発プロジェクトまで、あらゆるものに取り組んでいます。

    158
    17:23:000 --> 17:28:000
    Claude Codeを使っていることに気づき、フロントエンドのリポジトリで1つ、バックエンドのリポジトリで1つ実行していました。

    159
    17:28:000 --> 17:34:000
    そして、私たちのClaude Codeエンジニアの一人が、「それは間違っています。ルートで実行してください。Claudeがすべての場所でそれを実行できる場所を見つけ出してくれます」と言いました。そして、それは見事に機能しました。

    160
    17:34:000 --> 17:36:000
    そして、それが私がすでにそれを使用する方法を変えました。

    161
    17:36:000 --> 17:40,000
    Anthropicの開発者の大多数は、日常的にClaude Codeを使用しています。

    162
    17:40,000 --> 17:48,000
    私たちのチームに与えた影響を説明すると、エンジニアが迅速に作業を開始できるようになるまでの技術的なオンボーディング期間が、2〜3週間から2〜3日に短縮されました。

    163
    17:48:000 --> 17:57,000
    特に私たちのような大規模なモノリスの場合、コードベースの理解を非常に迅速に構築するのに役立つことを本当に見てきました。コードのナビゲートに優れているからです。

    164
    17:57:000 --> 18:07:000
    そして本日、Claude Codeの機能をVS CodeとJetBrainsに直接統合し、フルディフ機能とエージェントワークフロー管理をエディターに組み込みました。

    165
    18:07:000 --> 18:15:000
    また、Claude Code SDKも導入しており、Claude Codeと同じコアエージェントの上に独自のアプリケーションを構築できます。

    166
    18:15:000 --> 18:20,000
    SDKの可能性の一例として、GitHubでClaude Codeを実行できるようになりました。

    167
    18:20:000 --> 18:29,000
    GitHubのプルリクエストやイシューでClaudeをタグ付けすると、レビュー担当者のフィードバックに応答したり、コードを修正したり、テストカバレッジを実装したりします。

    168
    18:30:000 --> 18:31,000
    私たちはまた、「ループを閉じる」と呼ぶものにも焦点を当てています。

    169
    18:31:000 --> 18:39:000
    Claude Codeは現在、それ自体を構築するのを助けており、自己改善の力を示し、自身の開発を加速させています。

    170
    18:39:000 --> 18:43,000
    Claude Codeが皆様のような開発者の生産性をいかに向上させるかは驚くべきことです。

    171
    18:43:000 --> 18:50,000
    Instagramを構築していた頃を思い出すと、買収される前は2人から6人のエンジニアでチームを構成し、2つのモバイルプラットフォームをサポートしていました。

    172
    18:50:000 --> 18:56:000
    このようなエージェントコーディング製品があれば、数週間ではなく数日でプロトタイプを制作できたでしょう。

    173
    18:57:000 --> 19:01,000
    私たちは、高性能で信頼性の高いエージェントの構築について多くのことを話してきました。

    174
    19:01:000 --> 19:07:000
    さて、責任を伴わないエージェンシーは危険です。特に、私たちのClaude Code製品のように自己改善するようなものについて話す場合はなおさらです。

    175
    19:07:000 --> 19:12:000
    そして、厳格なセキュリティとコンプライアンス要件を持つエンタープライズ環境では、さらにその傾向が顕著です。

    176
    19:12:000 --> 19:21:000
    エージェントの広範な採用には、機密性、意思決定、連携に関するモデルの識別力と判断力の向上が必要になると考えます。

    177
    19:21:000 --> 19:30:000
    ですから、私たちのモデルはすでにこの点で優れていますが、機密情報が何か、何を公開すべきかを知っていることを確認し、本番環境で信頼できるように、引き続き改善していきます。

    178
    19:30:000 --> 19:36:000
    だからこそ、私たちがモデルに関して構築するすべての機能には、「アーキテクチャの安全性」と呼ぶものが組み込まれています。

    179
    19:36:000 --> 19:39:000
    チェックポイントとコントロールがあり、白紙委任ではありません。

    180
    19:39:000 --> 19:47:000
    エージェントは主要な決定で一時停止し、ユーザーはどの行動に人間の承認が必要かを定義できます。これもモデルコンテキストプロトコルに組み込まれています。

    181
    19:47:000 --> 19:49:000
    それらは悪用に対して堅牢です。

    182
    19:49:000 --> 19:54:000
    私たちはそれらをテストし、プロンプトインジェクションのようなものに対して徹底的にテストしています。

    183
    19:54:000 --> 20:00:000
    また、明確なフィードバックループと観測可能な動作により、設計上透明性があります。

    184
    20:00:000 --> 20:06:000
    エージェントが自律的に行動することを信頼すれば、緩和策ではなくイノベーションに集中できます。

    185
    20:07:000 --> 20:10:000
    私たちが多額の投資をしてきたもう一つの分野は、解釈可能性です。

    186
    20:10:000 --> 20:14:000
    AIモデルの内部で何が起こっているのかを正確に理解する科学です。

    187
    20:14:000 --> 20:19:000
    ダリオは最近、私たちのAIシステムが実際にどのように機能するかを理解することの緊急性について書きました。

    188
    20:19:000 --> 20:21,000
    彼の論文「解釈可能性の緊急性」を読めば。

    189
    20:21:000 --> 20:25,000
    彼が「モデルの知能と解釈可能性の競争」と呼ぶものです。

    190
    20:25:000 --> 20:34,000
    効果的に、私たちはAIにMRIを施し、AIが何を考えているかを確認し、欺瞞のような潜在的な問題を特定して、正しい方向に導けるようにしたいと考えています。

    191
    20:34:000 --> 20:39,000
    Anthropicに入社したとき、当社の研究パイプラインが製品に直接貢献できることに興奮しました。

    192
    20:39:000 --> 20:40,000
    ゴールデンゲート・クロードを例に挙げます。

    193
    20:40:000 --> 20:51,000
    Anthropicでの2週目にこれをリリースするよう推進しました。なぜなら、単なる良い研究論文だと感じなかったからです。それは素晴らしいデモ、解釈可能性が実際にどのように機能するかを直感的に示すものになると思いました。

    194
    20:51:000 --> 21:00:000
    Claudeニューラルネットワーク内でゴールデンゲートブリッジの機能を増幅させたとき、私たちは突然、AIの内部動作を操作することが何を意味するのかを見ることができました。

    195
    21:00:000 --> 21:03,000
    そしてこの場合、私たちのお気に入りの橋に深く執着させました。

    196
    21:03:000 --> 21:13:000
    ええと、ゴールデンゲート・クロードを作成するために使用した技術は、将来的には有害なモデルの挙動を減らしたり、特定のドメインでのモデルのパフォーマンスを向上させたりするのに役立つ可能性があります。

    197
    21:13:000 --> 21:25,000
    そして、企業で仮想コラボレーターを雇用し始めるにつれて、私の希望は、解釈可能性や監査可能性のような技術を彼らの仕事の基礎として活用し、彼らが大規模に何をしているかを把握できるようになることです。

    198
    21:26:000 --> 21:33,000
    これらは、抽象的な研究を具体的な製品機能へと変革するのに役立つ、画期的なものです。

    199
    21:34:000 --> 21:41,000
    先ほどご覧いただいたように、AIモデルが何時間もの自律作業をこなせるようになりました。この能力は数ヶ月ごとに倍増しています。

    200
    21:41:000 --> 21:44,000
    しかし、生のモデル能力だけでは十分ではありません。

    201
    21:44:000 --> 21:53,000
    これらの数時間かかるワークフローを実際に活用するには、エージェントは現実世界の情報へのアクセス、既存システムへの接続、そして費用対効果の高いスケーリングも必要です。

    202
    21:53:000 --> 21:59,000
    そのため、私たちは4つの相互接続された機能をリリースし、エージェントにコンテキストを提供し、スケーリングを支援します。

    203
    22:00:000 --> 22:05:000
    まず、本日より、モデルコンテキストプロトコルを当社のAPIを通じて直接接続できるようになりました。

    204
    22:05:000 --> 22:12:000
    MCPはすでにMicrosoft、Google、OpenAI、Block、Atlassian、Zapier、Linearなど、多くの企業で利用されています。

    205
    22:12:000 --> 22:13,000
    これは夢のリストでした。

    206
    22:13:000 --> 22:17:000
    MCPプロトコルを作成し、オープンソース化したとき、これは夢のリストでした。

    207
    22:17:000 --> 22:19:000
    「いつかこれらの企業が採用してくれるかもしれない」という感じでした。

    208
    22:19:000 --> 22:23,000
    1年も経たないうちに、彼らは皆、参加してくれました。

    209
    22:23:000 --> 22:33,000
    MCPはAIエージェントのユニバーサル翻訳機およびコネクタとして機能し、既存のシステムとのシームレスな接続を可能にし、毎回カスタムの特注統合を記述する必要がありません。

    210
    22:34:000 --> 22:42,000
    これは、専門化されたエージェントが複雑な課題に取り組むために必要なデータとツールにアクセスできる、エージェントエコノミーの基盤を築きます。

    211
    22:44:000 --> 22:48:000
    第二に、ウェブ検索はClaudeにリアルタイムで最新情報へのアクセスを提供します。

    212
    22:48:000 --> 22:56:000
    これは、Claudeが現在の出来事、市場のトレンド、そして新たな技術について推論することを可能にする、インテリジェントなデータ拡張です。

    213
    22:56:000 --> 22:58:000
    MCP機能と組み合わせると、非常に強力です。

    214
    22:58:000 --> 23:07:000
    内部の知識ソースを検索し、新しい洞察を得て、ウェブを検索してそれらを文脈化する様子を想像してみてください。

    215
    23:07:000 --> 23:16,000
    第三に、Files APIは本日APIで利用可能であり、開発者がドキュメントにアクセスし保存する方法を効率化し、開発ワークフローを簡素化します。

    216
    23:16:000 --> 23:22,000
    また、開発者が先ほど述べたメモリ機能をアプリケーションに直接組み込むのを助けるためのクックブックもリリースします。

    217
    23:22:000 --> 23:26,000
    これらの新しいClaude 4モデルは、私たちが自己管理メモリと呼ぶものにおいて、顕著な改善を示しています。

    218
    23:26:000 --> 23:29,000
    ですから、これが驚くほどうまく機能することに気づくでしょう。

    219
    23:29:000 --> 23:34,000
    そして、そのクックブックで実演しているように、Files APIを使用することで、ほとんど追加のオーバーヘッドなしで実現できます。

    220
    23:34:000 --> 23:39,000
    Claudeがこれらのメモリファイルを読み書きし、時間とともにコンテキストを維持するのを見ることができます。

    221
    23:40:000 --> 23:43,000
    最後に、電力は実用的でスケーラブルである必要があります。

    222
    23:43:000 --> 23:48,000
    私たちは、プロトタイプから本番環境、そして数百万人のユーザーへと、皆様と共に成長できることを保証したいと考えています。

    223
    23:48:000 --> 23:51,000
    それによって、コストを管理し、効率を向上させることができます。

    224
    23:51:000 --> 23:55,000
    私たちは、皆様が成功し、大規模なスケールに到達する際に、Claudeが皆様のために機能することを望んでいます。

    225
    23:55:000 --> 24:00,000
    だからこそ、プロンプトキャッシュは、私たちの最も人気のあるAPI機能の中で、最も要望の多かった機能でした。

    226
    24:00:000 --> 24:10,000
    プロンプトキャッシュを使用すると、顧客はClaudeにより多くのコンテキスト、背景知識、および出力例を提供でき、長いプロンプトの場合、コストを最大90%削減し、レイテンシを最大85%削減できます。

    227
    24:10:000 --> 24:17,000
    さて、私が話したすべてのお客様は、プロンプトキャッシュに関して非常に明確な要望を一つ持っていました。それは、より長いTTL（Time To Live）であり、本日提供します。

    228
    24:17:000 --> 24:29,000
    したがって、プロンプトキャッシュで標準で提供されていた5分間のTTLに加え、本日、プレミアムな1時間TTLをリリースします。これは12倍の改善であり、長時間実行されるエージェントワークフローのコストを劇的に削減します。

    229
    24:29:000 --> 24:33,000
    このインフラストラクチャは、エージェントアプリケーションを大規模で実行可能にします。

    230
    24:34:000 --> 24:36:000
    これらの機能はすべて複合的です。

    231
    24:36:000 --> 24:39:000
    APIに機能を組み込むことを考えるとき、私たちはそれらを単発的なものとは考えていません。

    232
    24:39:000 --> 24:42,000
    互いにどのように補完し合うか、どのように一貫したストーリーを形成するかを考えます。

    233
    24:42:000 --> 24:52:000
    Claudeは、コードを実行し、システムを理解し、ウェブ上の現在の情報にアクセスできるようになりました。これにより、長時間実行されるタスクでも完全なコンテキストで動作するエージェントの基盤が構築されます。

    234
    24:52:000 --> 24:57:000
    そして、Files APIを使用して、その実行全体を通してメモリとコンテキストを維持できます。

    235
    24:58:000 --> 25:00:000
    今朝ご覧いただいたものはすべて、ほんの始まりに過ぎません。

    236
    25:00:000 --> 25:03:000
    私たちのロードマップは、3つの柱に基づいて構築され続けています。

    237
    25:03:000 --> 25:15:000
    1つ目は、業界をリードするエージェントツールとアプリケーションです。これにより、Claudeを自律的に使用して何時間もの作業を処理でき、コード環境、つまりコード実行ツールを使用して独自の環境でコードを実行できることを知っています。

    238
    25:15:000 --> 25:25:000
    Claude Codeは現在一般公開されており、VS CodeやJetBrainsと統合されているため、広範なSDKを使用して、GitHub内を含む独自のカスタムワークフローを構築できます。

    239
    25:25:000 --> 25:29:000
    APIへのさらなるコンテキスト統合を推進し続けます。

    240
    25:29:000 --> 25:43:000
    本日のアップデートにより、モデルコンテキストプロトコルを介してこのコンテキストをもたらし、ウェブからのリアルタイムアップデートに基づいて構築し、あらゆるデータソースとAPI内のあらゆるものに対して複雑なワークフローを実行できるようになります。

    241
    25:43:000 --> 25:45:000
    そして最後に、効率的なスケーリングです。

    242
    25:45:000 --> 25:51:000
    本日より、拡張された1時間のプロンプトキャッシュを使用して、パフォーマンスとコストを大規模に最適化できます。

    243
    25:52:000 --> 25:54,000
    それぞれの進歩は、本日議論した内容に基づいています。

    244
    25:54:000 --> 26:05,000
    Claude 4を基盤とし、最も複雑なエージェントワークフローにはOpus 4、日常的なインテリジェンスにはSonnet 4を日々のドライバーとして、新しいクラスのアプリケーションを可能にしています。

    245
    26:05:000 --> 26:08,000
    コード実行は、Claudeがこなせる作業時間を拡大します。

    246
    26:08:000 --> 26:19:000
    MCPはClaudeが取得できる包括的な情報を拡大し、プラットフォームのアップデートにより、モデルは投入されたドルごとにますます効率的になることが保証されます。

    247
    26:19:000 --> 26:25:000
    私たちは皆様のような開発者から、これらのツールの使い方について積極的に学んでいますので、フィードバックをぜひお寄せください。

    248
    26:25:000 --> 26:27:000
    APIのフィードバックが大好きです。

    249
    26:27:000 --> 26:29:000
    私のことをご存じないなら、ぜひ私に連絡してください。

    250
    26:29:000 --> 26:33,000
    ええと、皆様のような開発者向けにAPIを改善し続ける方法について、フィードバックをいただくのが大好きです。

    251
    26:33:000 --> 26:35,000
    そしてMCPはその完璧な例です。

    252
    26:35:000 --> 26:40,000
    それは社内アイデアとして始まり、その後コミュニティ実験へと発展しました。

    253
    26:40:000 --> 26:47,000
    そして今ではコアプラットフォーム機能となっています。Microsoft Buildの基調講演をご覧になれば、彼らがMCPを実際のインフラストラクチャの多くの部分に組み込んでいることがわかります。

    254
    26:47:000 --> 26:54,000
    私たちは、AIエージェントのエコシステムを構築し、実際に皆様にとって役立つようにフィードバックループを設けたいと考えています。

    255
    26:55:000 --> 26:57,000
    今日、私たちは大きな節目に立っています。

    256
    26:57:000 --> 27:02,000
    私たちの最新モデルは、リリースした最新ツールと組み合わさって、新しい時代の種を皆様に提供しています。

    257
    27:02:000 --> 27:07,000
    未来はAIが人間の仕事をするのではなく、AIが人間が超人的な仕事をするのを助けることです。

    258
    27:07:000 --> 27:15,000
    そして、このビジョンを皆様と一緒に構築できることに本当に興奮しています。皆様のすべての企業のために、それがどのようなアプリケーションを動かすのかを見るのが待ちきれません。

    259
    27:15:000 --> 27:28,000
    そして、何が可能かをお見せするために、次に当社の製品チームのキャット・ウーにマイクを渡します。彼女は、Claude Code内で新しいモデルにアクセスすることが、いかに開発ワークフローを変革し、複雑な複数日にわたるタスクを単一の会話で出荷するのに役立つかを実演します。

    260
    27:28:000 --> 27:32,000
    Code with Claudeへようこそ。そして、改めてありがとうございます。残りの一日を楽しんでください。

    261
    27:43:000 --> 27:44,000
    皆さん、こんにちは。

    262
    27:44:000 --> 27:48,000
    Claude Codeのプロダクトマネージャー、キャット・ウーです。

    263
    27:48:000 --> 27:55,000
    マイクが述べたように、私たちは最近、エージェントコーディングツールであるClaude Codeを研究プレビューでリリースしました。

    264
    27:55:000 --> 28:06,000
    Claude Codeは、開発者がAnthropicのモデルの生のパワーに、彼らが作業するターミナルから直接アクセスできるようにします。

    265
    28:06:000 --> 28:10,000
    本日より、Claude Codeは一般公開されます。

    266
    28:16:000 --> 28:27,000
    コンピューティングの歴史を通じて、私たちは機械語からアセンブリ、そして高水準言語へと、常に抽象化のレベルを上げてきました。

    267
    28:27:000 --> 28:35:000
    Claude Codeとますますエージェント化するモデルにより、私たちはさらなる進歩を目の当たりにしています。

    268
    28:35:000 --> 28:47,000
    開発者は、特定の機能を要求するのではなく、AIを導き、ソフトウェアの構築方法を変えながら、機能全体を記述するようになっています。

    269
    28:47:000 --> 28:58:000
    本日、新しいClaude 4モデルをClaude Codeに導入し、さらに強力で有能なコーディングエージェントにしました。

    270
    29:03:000 --> 29:15,000
    そして、新しいモデルに加えて、Claude Codeにいくつかの新機能をリリースします。これらは、開発ライフサイクル全体でより多機能なコーディングエージェントとなることに焦点を当てています。

    271
    29:16:000 --> 29:26:000
    まず、Claude CodeはVS CodeとJetBrains IDEsと統合され、何百万もの開発者にとって馴染みのあるインターフェースで利用できるようになりました。

    272
    29:26:000 --> 29:34,000
    Claude Codeが動作すると、提案された変更をエディタ内でインラインで確認できるようになりました。

    273
    29:35:000 --> 29:46:000
    また、Claude Code SDKもリリースします。これにより、開発者はClaude Codeをアプリケーションやワークフローの構成要素として使用できます。

    274
    29:46:000 --> 29:50,000
    SDKの可能性は無限大です。

    275
    29:50:000 --> 30:01,000
    これらの可能性を示すために、GitHubでClaude Codeを使ったSDKのオープンソースの例をリリースします。

    276
    30:01:000 --> 30:14,000
    GitHubのプルリクエストやイシューでClaudeを直接タグ付けすると、Claude Codeはレビュー担当者のフィードバックに応答し、CIエラーを修正し、新しい機能を追加します。

    277
    30:15:000 --> 30:23,000
    これらの追加により、Claude Codeはどこでも動作するようになり、すべてのプラットフォームで仮想チームメイトとして機能します。

    278
    30:23:000 --> 30:37,000
    ターミナルでの深い開発作業、GitHubのようなリモート環境でのSDK上に構築された自動化されたワークフロー、そしてIDEでのシームレスなレビューに対応します。

    279
    30:37:000 --> 30:51,000
    結局のところ、Claude Codeは、Claude Codeと直接対話的に作業しているか、非同期的に使用しているかにかかわらず、どこにいても開発を加速するための多機能なコーディングエージェントです。

    280
    30:51:000 --> 30:52,000
    素晴らしい。

    281
    30:52:000 --> 30:53,000
    私のお気に入りの部分です。

    282
    30:53:000 --> 30:56:000
    これらのアップデートがデモでどのように見えるか見てみましょう。

    283
    30:57:000 --> 31:04,000
    皆さんの多くがご存知の製品で、Claude Codeが実際の開発タスクに取り組む様子をお見せします。

    284
    31:04:000 --> 31:14:000
    Excalidrawというオープンソースのホワイトボードツールを使って、Claude Codeに最も要望の多かった機能の一つであるテーブルコンポーネントの追加を実装してもらいます。

    285
    31:14:000 --> 31:25:000
    皆さんのうち、何人が何年もバックログに眠っていて、ユーザーがきっと喜ぶと分かっているのに、構築する時間がなかった機能リクエストを抱えていますか？

    286
    31:25:000 --> 31:29,000
    これは、Claude Codeを使えばはるかに速く処理できる種類のタスクです。

    287
    31:29:000 --> 31:38:000
    通常、このようなタスクでは、Claudeに作業を任せ、コーヒーを淹れ、メールやSlackをチェックし、出力が準備できたら戻ってきます。

    288
    31:38:000 --> 31:45:000
    しかし、今日は皆さんとの時間が10分しかないので、早送りですが実際のワークフローをお見せしましょう。

    289
    31:46:000 --> 31:49,000
    こちらがVS Codeで開いているExcalidrawのリポジトリです。

    290
    31:49:000 --> 31:53,000
    Claude Codeに要件を伝えるプロンプトを書きましょう。

    291
    31:53:000 --> 32:04,000
    Claude Codeに、カスタム寸法、ドラッグによるサイズ変更、およびExcalidrawの他のすべてのスタイリングオプションをサポートするテーブルコンポーネントを追加するよう依頼します。

    292
    32:04:000 --> 32:06,000
    ここからが面白いところです。

    293
    32:06:000 --> 32:12,000
    Claude Codeはまず、問題全体にどのように取り組むかのToDoリストを作成します。

    294
    32:14:000 --> 32:22,000
    次に、Claude Codeがコードベースの探索を開始するのがわかります。すでにコンテキストとして開いているファイルから始めます。

    295
    32:24:000 --> 32:30,000
    IDE統合の最大の利点は、エディタ内で差分をインラインで確認できることです。

    296
    32:30:000 --> 32:40:000
    これにより、周囲のコードをより多くのコンテキストで確認できるため、自信を持って変更を受け入れたり、Claude Codeにフィードバックを与えたりすることができます。

    297
    32:41:000 --> 32:53,000
    Claude Codeが作業するたびに各編集を承認することもできますし、自動承認モードでClaude Codeに編集を続けさせることもできます。これにより、可視性と制御のバランスを取ることができます。

    298
    32:54:000 --> 33:02,000
    このデモでは、Claude Codeに編集、リントとテストの実行、PRの作成の機能を与えました。

    299
    33:03:000 --> 33:06:000
    Claude Codeはこのタスクに90分間取り組みました。

    300
    33:06:000 --> 33:10:000
    全てをお見せしたいのですが、時間を早める必要があります。

    301
    33:10:000 --> 33:14,000
    ご覧いただいているのは、Claude Codeからの実際の未編集の出力です。

    302
    33:16:000 --> 33:19,000
    1時間半後、完了しました。

    303
    33:20:000 --> 33:28,000
    テーブル機能を追加し、変更を検証するためのテストを書き、リントとテストがパスするまで反復しました。

    304
    33:28:000 --> 33:37,000
    通常、これにはコードベースのアーキテクチャと、他のすべてのツールがどのように実装されているかを理解する必要がありました。

    305
    33:37:000 --> 33:42,000
    この場合、Claude Codeは文字通り何時間もの作業を私たちに代わって行っています。

    306
    33:42:000 --> 33:43,000
    かなり印象的ですよね？

    307
    33:45:000 --> 33:55,000
    さて、Excalidrawをローカルで実行し、機能が期待通りに動作するか確認しましょう。

    308
    33:56:000 --> 34:02,000
    3行3列のテーブルを作成して、完全に機能するテーブルコンポーネントがあることを確認しましょう。

    309
    34:02:000 --> 34:03:000
    素晴らしい。

    310
    34:04:000 --> 34:07:000
    テーブルを再配置したり、ドラッグしてサイズを変更したりできます。

    311
    34:07:000 --> 34:14,000
    枠線のパターンや色を変更したり、セルにテキストを追加したりできます。

    312
    34:15:000 --> 34:19:000
    これはExcalidrawの既存のUIとも統合されています。

    313
    34:20:000 --> 34:25,000
    これらすべてが、Claude Codeの1つのプロンプトで実行されました。

    314
    34:27:000 --> 34:43,000
    次に、Claude CodeにGitHub CLIを使用して、このブランチのプルリクエストを作成するよう依頼します。

    315
    34:44:000 --> 34:45,000
    Cool.

    316
    34:45:000 --> 34:46,000
    クリックしてみましょう。

    317
    34:48:000 --> 34:50:000
    これでプルリクエストができました。

    318
    34:50:000 --> 35:00:000
    ここがClaude Code SDKの真価を発揮する場所です。これにより、GitHub Actionsを含むClaude Codeの上にカスタムワークフローを構築できます。

    319
    35:00:000 --> 35:04,000
    このPRでは、ドキュメントを更新したいと思います。

    320
    35:04:000 --> 35:12:000
    IDEに戻る代わりに、@Claudeをタグ付けして、ドキュメントを更新してもらうことができます。

    321
    35:13:000 --> 35:18:000
    裏では、これがClaude Codeを実行するGitHubアクションをトリガーします。

    322
    35:18:000 --> 35:24,000
    ClaudeはPRの作業中にコメントをつけ、完了するとコミットを作成してくれます。

    323
    35:25:000 --> 35:31:000
    GitHubのイシューで@Claudeをタグ付けすることもでき、そこでもPRを作成してくれます。

    324
    35:31:000 --> 35:38:000
    この機能により、Claude Codeはユーザーがすでに作業しているさらに多くのプラットフォームで利用できるようになります。

    325
    35:38:000 --> 35:46:000
    開発者はローカル環境でコンテキストを切り替える必要がなくなり、外出先でも実行を開始できます。

    326
    35:46:000 --> 35:49,000
    これらはすべてClaude Code SDK上に構築されています。

    327
    35:49:000 --> 36:06:000
    GitHub Actionsを強化するだけでなく、SDKを使って、不安定なテストの修正、テストカバレッジの向上、さらにはオンコールトリアージまで、顧客が驚くべきことを実現しているのを見てきました。

    328
    36:06:000 --> 36:07:000
    Cool.

    329
    36:07:000 --> 36:14,000
    アクションの実行が完了したようです。Claude Codeがコメントを更新して、何をしたか教えてくれています。

    330
    36:14:000 --> 36:18,000
    コミットをクリックして、Claudeの変更を見てみましょう。

    331
    36:20:000 --> 36:28:000
    PRのドキュメントを更新し、私たちが何もすることなくコミットしてくれました。

    332
    36:31:000 --> 36:51:000
    わずか10分で、Claude Codeが手動で実装すれば数日かかったであろう複雑なタスクをこなし、何百行ものコードを書き、Excalidrawの既存機能とシームレスに統合し、何時間もの作業を私たちに代わって行いました。

    333
    36:51:000 --> 36:53:000
    これらすべてが本日よりご利用いただけます。

    334
    36:53:000 --> 37:05:000
    当社のSDKを搭載したGitHub ActionsのClaude Codeはベータ版で利用可能であり、Claude内で画面上の簡単なコマンドを実行することでインストールできます。

    335
    37:05:000 --> 37:10:000
    VS CodeとJetBrains IDEの拡張機能もベータ版で公開されています。

    336
    37:10:000 --> 37:14,000
    IDEからClaudeを実行するだけでインストールできます。

    337
    37:14:000 --> 37:25,000
    最後になりますが、当社の最新モデルであるClaude Opus 4とClaude Sonnet 4は、本日よりClaude Codeユーザーにご利用いただけます。

    338
    37:26:000 --> 37:39,000
    Claude Codeは、AIがコードを真に理解し、コードと連携できるようになったときに何が可能になるかを示しています。

    339
    37:39:000 --> 37:48,000
    強力なエージェントを構築するには、コーディング支援であれ、あらゆるドメインのアプリケーションであれ、単にインテリジェントなモデル以上のものが必要です。

    340
    37:48:000 --> 37:50,000
    適切なプラットフォームが必要です。

    341
    37:50:000 --> 37:57:000
    それをどのように実現しているか、マイケル・ガーステンハーバーがご紹介します。

    342
    38:04:000 --> 38:05,000
    キャット、本当にありがとう。

    343
    38:05:000 --> 38:07:000
    皆さん、おはようございます。本日はお越しいただきありがとうございます。

    344
    38:07:000 --> 38:12,000
    AnthropicのAPIプラットフォームの製品責任者、マイケル・ガーステンハーバーです。

    345
    38:16:000 --> 38:21,000
    ここにいる皆さんのうち、すでにAI生成コードを使ってアプリケーションを開発している方はどれくらいいますか？

    346
    38:21:000 --> 38:22,000
    はい。

    347
    38:22:000 --> 38:27,000
    そのうち、機能提供の核としてAIを使用しているのはどれくらいですか？

    348
    38:27:000 --> 38:29,000
    そうですね、ここにいる皆さん全員です。そう思いました。

    349
    38:29:000 --> 38:35:000
    世界のほとんどのアプリケーションは、すでに世界の課題を解決しようとしている人々によって構築されるでしょう。

    350
    38:35:000 --> 38:42,000
    LeetCodeのホワイトボード面接に合格しようと、vibesを始めようと、私たちは皆、今やソフトウェアエンジニアです。

    351
    38:42:000 --> 38:44,000
    しかし、コードを書くことは始まりに過ぎません。

    352
    38:44:000 --> 38:51,000
    より迅速に、安定した、安全で、保守可能なAIアプリケーションを構築する必要があります。

    353
    38:51:000 --> 39:01,000
    そして、それが私たちがAnthropicプラットフォームを構築した理由です。これは、最先端のAIアプリケーションとエージェントを構築するために設計された完全なツールキットです。

    354
    39:01:000 --> 39:07,000
    私たちのプラットフォームは、すでに世界のほとんどのAIデリバリーをあらゆる分野で支えています。

    355
    39:08:000 --> 39:15,000
    金融分野では、TurboTaxが連邦税解説機能により、何百万もの顧客が自信を持って納税申告を行うのを支援しています。

    356
    39:15:000 --> 39:23,000
    ヘルスケア分野では、ノボノルディスクがClaudeを使用して、臨床試験レポートを15週間ではなく10分未満で作成しています。

    357
    39:23:000 --> 39:27,000
    そして、世界最高峰のコーディングアシスタントが私たちのプラットフォームで動作しています。

    358
    39:28:000 --> 39:35:000
    これらの企業はそれぞれ、Claudeの知能を活用し、ユーザーにとって独自に価値のあるものに変えました。

    359
    39:36:000 --> 39:49:000
    その基盤として、当社のプラットフォームは、メッセージAPIを含むモデル推論サービスを通じてClaudeへの信頼性の高いアクセスを提供し、パフォーマンスとコストを最適化するためのプロンプトキャッシュのような不可欠なツールを提供します。

    360
    39:49:000 --> 39:56:000
    プラットフォーム上の全入力トークンの50%以上がキャッシュされ、モデルの実質的なコンテキストウィンドウが2倍になります。

    361
    39:56:000 --> 40:04,000
    Notionは、大量のドキュメントをコンテキストウィンドウに格納しつつ、高速なリアルタイム実行を維持できます。

    362
    40:04:000 --> 40:09,000
    これにより、彼らはクリエイティブライティングであなたの声を採用し、幻覚を実質的に排除することができます。

    363
    40:09:000 --> 40:17,000
    本日より、キャッシュの有効期限を5分から1時間に延長します。

    364
    40:19:000 --> 40:27,000
    エージェントは、ユーザーセッション全体で複雑なコンテキストを維持できるようになり、コストをかけずに利用できます。

    365
    40:27:000 --> 40:29,000
    しかし、それは単なる基盤に過ぎません。

    366
    40:29:000 --> 40:33,000
    強力なエージェントを構築するために、私たちのプラットフォームは強力な構成要素を提供します。

    367
    40:33:000 --> 40:37,000
    マイクが共有したように、私たちは2つの新しい機能をリリースします。

    368
    40:37:000 --> 40:41,000
    Files APIとコード実行ツールです。

    369
    40:41:000 --> 40:47,000
    あなたと私と同じように、スクリプトを書くことで簡単に解決できる問題がいくつかあります。

    370
    40:47:000 --> 40:53:000
    私たちのプラットフォームでは、エージェントがあなたと同じように本番環境で独自のコードを書くことができます。

    371
    40:53:000 --> 41:05,000
    これらの新機能は、リアルタイム情報のためのウェブ検索や、ソースドキュメントで応答を根拠づけるための引用など、既存のコンポーネントに加わります。

    372
    41:05:000 --> 41:16,000
    トムソン・ロイターがCoCounselで弁護士に分析を提供する際、彼らがこれを法的調査や判例法に基づいて根拠づけることが極めて重要であり、モデルのトレーニングデータに基づいてはなりません。

    373
    41:16:000 --> 41:24,000
    私たちのプラットフォームはまた、モデルコンテキストプロトコルを通じて、皆様のエージェントと皆様のデータ、そしてビジネスシステムを接続します。

    374
    41:24:000 --> 41:33,000
    MCPは開発者エコシステム内で急速に普及し、コミュニティによって3,000以上の統合が構築されました。

    375
    41:34:000 --> 41:51,000
    あなたのエージェントがSentryでアプリケーションエラーにアクセスしたり、Zapierワークフローをトリガーしたり、Asanaタスクを作成したりする場合でも、MCPコネクタはモデルがあなたのタスクに必要なあらゆるツール、データ、またはアプリと対話することを可能にします。

    376
    41:51:000 --> 41:59,000
    そして今日、このプラットフォームはツールとAPI呼び出しの技術的な複雑さをすべて処理することで、さらに簡単に利用できるようになりました。

    377
    42:00:000 --> 42:05:000
    このプラットフォームについて強調したいことの一つは、APIの構成可能性です。

    378
    42:05:000 --> 42:12,000
    それらは、個別に機能するだけでなく、連携して機能する構成要素であり、画一的な形に強制できない独自の課題を解決するのに役立ちます。

    379
    42:12:000 --> 42:17,000
    Claudeをあなた自身のエージェントの建築家であり総合請負業者だと考えてください。

    380
    42:17:000 --> 42:21,000
    事前定義されたシーケンスを実行したり、コンポーネントをランダムに積み重ねたりすることはありません。

    381
    42:21:000 --> 42:31,000
    その代わりに、どの素材が必要か、どの順序で、どのように組み合わせるかをインテリジェントに判断し、個々の要素よりもはるかに強力なものを生み出します。

    382
    42:31:000 --> 42:33,000
    どういうことかお見せしましょう。

    383
    42:33:000 --> 42:40,000
    複雑な金融分析のためのエージェントを構築する際、Claudeはタスクをインテリジェントに評価し、適切なツールをオーケストレーションします。

    384
    42:40:000 --> 42:59,000
    MCPを使用して財務データにアクセスし、統計分析のためにコード実行を起動し、リアルタイムの市場データのためにウェブを検索し、正確性とコンプライアンスのために引用で洞察を根拠づけ、結果に基づいて反復し洗練させます。

    385
    42:59:000 --> 43:02,000
    ハードコードされたワークフローも、脆弱なスクリプトもありません。

    386
    43:02:000 --> 43:12,000
    私たちの研究が新しい能力を生み出すにつれて、強力なエージェントを構築し、シームレスに新しい能力を採用できるインテリジェントなオーケストレーションです。

    387
    43:12:000 --> 43:25,000
    プロンプトの品質がAIアプリケーションの成否を分けることを理解しているため、プロンプト改善ツールや評価ツール、そして本番環境への移行と迅速なスケーリングを支援する新しい可観測性機能を開発しました。

    388
    43:26:000 --> 43:34,000
    今日、私たちはすでに、クックブックやガイドのようなリソースを使って、開発者がメモリのような機能をアプリケーションに実装する方法を示し、より迅速に開発できるよう支援しています。

    389
    43:35:000 --> 43:46,000
    将来的には、これらをプログラムによるアクセスに適応させ、プラットフォーム上で直接ホストすることで、より強力なエージェントを構築できるようになります。これらのエージェントは、本番環境で自律的に調査し、記憶することができます。

    390
    43:46:000 --> 43:53,000
    私たちが構築したものはすべて、より良いAIをより速く出荷するという一つの目標に集中しています。

    391
    43:53:000 --> 43:58,000
    Anthropicプラットフォームは単なるツールではなく、業界をリードするエージェントを構築するための道筋です。

    392
    44:00:000 --> 44:11,000
    本日はCode with Claudeにお越しいただきありがとうございます。私は会議中ずっと会場にいますが、GitHubのマリオ・ロドリゲス氏をお迎えし、これが本番環境でどのように見えるかを正確にお見せできることを光栄に思います。

    393
    44:17:000 --> 44:18:000
    ありがとう。

    394
    44:18:000 --> 44:19:000
    マイケル、ありがとう。

    395
    44:19:000 --> 44:22:000
    そして、皆様と一緒にいられることを、とても嬉しく思っています。

    396
    44:22:000 --> 44:35:000
    GitHubでは、このエネルギーとイノベーションの一員となれることを非常に嬉しく思っており、Anthropicとの深化するパートナーシップについて、この素晴らしいチームとさらに共有できることを楽しみにしています。

    397
    44:35:000 --> 44:38:000
    GitHubが行うすべてのことは、2つの核となる信念に基づいています。

    398
    44:38:000 --> 44:45:000
    1つ目は開発者に選択肢を与えること、2つ目は最高の開発者体験を提供することです。

    399
    44:45:000 --> 44:51,000
    昨年開催されたGitHub Universeで、私たちはAnthropicとの関係を開始しました。

    400
    44:51:000 --> 44:58:000
    VS Codeと会話型エクスペリエンスでのサポートを含むClaude Sonnet 3.5を発表しました。いくつか例を挙げると。

    401
    44:58:000 --> 50:09,000
    そして、これを実現したのは、AIが開発者にとって強力な力となり、能力を増強し、置き換えるのではなく、想像力と創造性という彼らが最も得意なことに集中できるようにするという、Anthropicとの根本的な信念を共有しているからです。ソフトウェア開発者であることの一部は、魔法使いであることです。

    402
    50:09:000 --> 50:31,000
    それ以来、私たちはVS Code、github.com、そしてモバイルアプリ全体でパートナーシップと体験を拡大してきました。そして本日、GitHub CopilotがClaude Sonnet 4とOpus 4をサポートすることを発表します。これらは現在利用可能です。ダリオが発表したまさにその瞬間に、私たちはすべてのサービスでトリガーを引きました。

    403
    50:31:000 --> 50:33,000
    それがシップシッピングの全てです。

    404
    50:33:000 --> 50:35,000
    言っておきますが、それは本当に難しいことです。

    405
    50:35:000 --> 50:40,000
    あなたがこれまでに作ったすべてのアプリケーションでそれをやったことがあるかどうかは分かりませんが、それは信じられないほど難しいことです。だから、それを実現したすべてのチームに感謝します。

    406
    50:40:000 --> 50:44,000
    さて、皆さんもご存知の通り、コードの未来は一体何でしょうか？

    407
    50:44:000 --> 50:45,000
    エージェント的です。

    408
    50:45:000 --> 50:50:000
    VS Codeのエージェントモードは、自然言語コマンドに基づいて多段階のコーディングタスクを実行できる、自律的なペアプログラマーです。

    409
    50:50:000 --> 51:00:000
    エディタ内で直接Claudeの知能を利用することで、開発者が複雑なコードベースを理解し、より迅速にコードを本番環境に投入し、すでに知っている、愛し、信頼している環境を離れることなく生産性を向上させるのに、いかに役立つかを私たちは目の当たりにしてきました。

    410
    51:00:000 --> 51:05,000
    しかし、それさえもシングルスレッドです。

    411
    51:05:000 --> 51:09:000
    そして私の意見では、未来はマルチスレッドです。

    412
    51:09:000 --> 51:13:000
    考えてみてください。エディタの中にいると、それは待合室になります。

    413
    51:13:000 --> 51:15:000
    スピードは上がっていますが、それでも待合室です。

    414
    51:15:000 --> 51:20:000
    だからこそ月曜日、私たちはGitHubのCopilotコーディングエージェントを発表することで、さらに一歩踏み出しました。

    415
    51:20:000 --> 51:23:000
    さて、私たちのコーディングエージェントは現在、ご想像の通りClaude Sonnetによって動いています。

    416
    51:23:000 --> 51:27:000
    ええと、そして、私がそれを選んだ理由は非常に明確でした。

    417
    51:27:000 --> 51:31,000
    その決定を可能にした3つのことについて説明させてください。

    418
    51:31:000 --> 51:37,000
    1つ目は、私たちの評価でClaudeが3つの主要な強みを示したことです。

    419
    51:37:000 --> 51:41,000
    強力なソフトウェアエンジニアリングとコーディングの知識、強力な問題解決能力。これは非常に重要です。なぜなら、時にはコードを見て、その編集を行う適切な場所を見つける必要があるからです。

    420
    51:41:000 --> 51:45,000
    そして3つ目は、優れた指示の順守です。

    421
    51:45:000 --> 51:49,000
    特にツールとMCPについて考えるとき。

    422
    51:49:000 --> 51:54,000
    ですから、エージェントコーディングのために構築する際、大規模なコードベースやシステムプロンプトでこれらのものを扱う場合、他に何かが必要になります。それはキャッシュです。

    423
    51:54:000 --> 51:57:000
    そして、そのプロンプトキャッシュ、お大事に。

    424
    51:57:000 --> 52:02,000
    Anthropic APIから得られるプロンプトキャッシュのサポートにより、これらの体験をはるかに費用対効果の高い方法で構築できます。

    425
    52:02:000 --> 52:06,000
    すべてのトークンが重要であり、価格面でもすべてのトークンが重要です。

    426
    52:06:000 --> 52:11,000
    ですから、それらを節約すればするほど、お客様により良い体験を提供できます。

    427
    52:11:000 --> 52:15,000
    その上、Claudeはすでにエージェントモードで最も頻繁に選択されるモデルでした。

    428
    52:15:000 --> 52:21,000
    ですから、それらすべてを組み合わせると、GitHubのシナリオにおけるエージェントコーディングにはClaude Sonnetが適切なモデル選択であることが非常に明確になりました。

    429
    52:21:000 --> 52:29,000
    さて、Claude Sonnet 4では、これらのすべての分野で改善が見られました。正確なベンチマークだけでなく、より重要なのは、実際の評価スイートでも改善が見られたことです。

    430
    52:29:000 --> 52:32,000
    さて、私たちのコラボレーションはこれよりも深いものです。

    431
    52:32:000 --> 52:36,000
    単にモデルを直接統合するだけではありません。

    432
    52:36:000 --> 52:40,000
    私たちはAnthropicと密接に協力し、MCPを正式に採用し、規模を拡大してきました。

    433
    52:40:000 --> 52:46:000
    知能を組み合わせているのです。考えてみてください、これらのモデルは信じられないほど知的です。

    434
    52:46:000 --> 52:49,000
    知識を持つ3人の博士号取得者を彼らに積み重ねるようなものです。

    435
    52:49:000 --> 52:53,000
    では、そのインテリジェントなモデルにどうやって知識を組み込むのでしょうか？

    436
    52:53:000 --> 52:56,000
    私たちにとっての答えはMCPとツールです。

    437
    52:56:000 --> 53:01,000
    そして、それが本当に開発者ツールの次の加速を解き放ちます。

    438
    53:01:000 --> 53:07,000
    最近、MicrosoftのCTOであるケビン・スコットが、MCPはウェブのHTTPプロトコルのようなものだと例えました。

    439
    53:07:000 --> 53:09,000
    そして、私も彼に全く同感です。

    440
    53:09:000 --> 53:15,000
    ですから、もしMCPを導入していないなら、今すぐ、この基調講演の直後に、試してみてください。

    441
    53:15:000 --> 53:18,000
    それほど重要です。

    442
    53:18:000 --> 53:22,000
    それが、これらのインテリジェントなモデルに知識を組み込む方法なのです。

    443
    53:22:000 --> 53:29,000
    さて、ソフトウェア開発の新しい時代に足を踏み入れるにあたり、私たちはGitHubのプラットフォームを変革しています。

    444
    53:29:000 --> 53:33:000
    AIが注入されたものから、AIネイティブへと。

    445
    53:33:000 --> 53:38:000
    創造から展開まで、このSDLCを構想しています。

    446
    53:38:000 --> 53:44,000
    その上部にはエージェント層があり、コーディングを行う内部と、非同期的な体験である外部ループにまたがっています。

    447
    00:53:49,000 --> 00:53:53,000
    そして、あなたはあらゆる段階で積極的な協力者となるでしょう。

    448
    00:53:53,000 --> 00:53:56,000
    コパイロットと言うのは、人間が中心だからです。

    449
    00:53:56,000 --> 00:53:59,000
    そして、あなたを助けるエージェントがいます。

    450
    00:53:59,000 --> 01:05:00,000
    それが、キャットが今お見せしたクラウドコードと、拡張可能なクラウドコードをGitHubのエージェントプラットフォームに直接統合する新しいパートナーシップを発表する理由です。これにより、クラウドコードをカスタマイズし、GitHubや私たちのワークフローに組み込まれた新しいインターフェースからリモートで呼び出す新しい可能性が開かれます。

    451
    01:05:00,000 --> 01:05:03,000
    繰り返しますが、すべてGitHubプラットフォーム上です。

    452
    01:05:03,000 --> 01:05:08,000
    さて、私たちはすでに多くのことを成し遂げましたが、Anthropicとの旅はまだ始まったばかりだと考えています。

    453
    01:05:08,000 --> 01:05:46,000
    GitHubの深い、深い開発者理解と、クラウドおよびプラットフォームAPIを通じたAnthropicのAI能力を組み合わせることで、私たちはより直感的で、より効率的で、最終的にはより人間的な未来を解き放つことができると信じています。

    454
    01:05:46,000 --> 01:05:48,000
    その人間的な部分が重要です。

    455
    01:05:48,000 --> 01:05:55,000
    ですから、私たちが共に何を構築し続けるのか、そして皆さんが私たちと共に何を構築するのかを見るのが楽しみです。

    456
    01:05:55,000 --> 01:05:56,000
    それでは、マイク・クリーガーをステージにお迎えください。

    457
    01:05:56,000 --> 01:05:57,000
    ありがとうございます。

    458
    01:05:57,000 --> 01:05:58,000
    皆さん、こんにちは。

    459
    01:05:58,000 --> 01:06:01,000
    マリオ、マイケル、キャット、改めてありがとう。

    460
    01:06:01,000 --> 01:06:03,000
    ええと、GitHubの統合が大好きです。

    461
    01:06:03,000 --> 01:06:09,000
    私が最後にやったプロジェクトでは、実際にClaude CodeをGitHubのコードスペースにインストールできることに気づき、突然、すでに構築していたリポジトリに対してClaude Codeが使えるようになりました。

    462
    01:06:09,000 --> 01:06:14,000
    彼ら一人一人から話を聞き、Claudeで進められているエキサイティングな仕事についてすべて聞くことができて、本当に良かったです。

    463
    01:06:14,000 --> 01:06:21,000
    ショーを締めくくるにあたり、Claude 4、私たちの研究方向、そしてAnthropicから開発者が次に何を期待できるかについて、もう少し深く掘り下げたいと思います。

    464
    01:06:21,000 --> 01:06:28,000
    ええと、それでは、ダリオをステージにお迎えし、一対一の会話を始めましょう。ダリオ、おかえりなさい。

    465
    01:06:28,000 --> 01:06:29,000
    皆さん、こんにちは。

    466
    01:06:29,000 --> 01:06:30,000
    素晴らしいですね。

    467
    01:06:30,000 --> 01:06:33,000
    これは、聴衆全員の前での私たちの一対一の会話のようなものです。素晴らしいですね。

    468
    01:06:33,000 --> 01:06:36,000
    ええと、Claude 4、ええと、ええと、リリースされました。

    469
    01:06:36,000 --> 01:06:39,000
    Claude Sonnet 4とClaude Opus 4が利用可能です。

    470
    01:06:39,000 --> 01:06:45,000
    ええと、Claude 4モデルについて最も興奮していることは何ですか？そして、それは今後12ヶ月間で何が可能になるかというあなたの考えをどのように変えますか？

    471
    01:06:45,000 --> 01:06:51,000
    はい、ええと、抽象的に最も興奮しているのは、新しいクラスのモデルが登場するたびに、できることが増えるということです。

    472
    01:06:51,000 --> 01:07:01,000
    ですから、ええと、ええと、ええと、Claude 4の後にモデルをリリースする予定です。おそらくClaude 4.1がいつか登場するでしょう。ちょうどSonnet 3.5でやったように。

    473
    01:07:01,000 --> 01:07:07,000
    そして、私たちは新しい世代のモデルで何ができるか、まだ始まったばかりだと思います。

    474
    01:07:07,000 --> 01:07:13,000
    タスクに関して言えば、自律性はすでに達成したよりもはるかに進むでしょう。

    475
    01:07:13,000 --> 01:07:19,000
    モデルを自由に設定し、長期間何かを実行する能力を与えることです。

    476
    01:07:19,000 --> 01:07:22,000
    私たちはまだその始まりに過ぎないと思います。

    477
    01:07:22,000 --> 01:07:28,000
    ええと、ええと、私はサイバーセキュリティのタスクのためのモデルにますます興奮しています。

    478
    01:07:28,000 --> 01:07:35,000
    サイバーセキュリティはコーディングタスクのサブセットと考えることができますが、より高度なコーディングタスクになる傾向があります。

    479
    01:07:35,000 --> 01:07:38,000
    そして、そのための閾値にようやく達したのかもしれません。

    480
    01:07:38,000 --> 01:07:44,000
    そして、元生物学者として、私は常にモデルの生物医学的および詳細な科学研究への利用に興奮しています。

    481
    01:07:44,000 --> 01:07:51,000
    Opusは特にその分野で非常に強力になると思います。

    482
    01:07:51,000 --> 01:07:53,000
    ええと、それは「愛する恵みの機械」につながると思います。

    483
    01:07:53,000 --> 01:07:58,000
    Claude 4がその軌道にどう収まるか？私は「愛する恵みの機械」をエッセイだと思っていますが、それは今後数年間の製品ロードマップだと考えています。

    484
    01:07:58,000 --> 01:08:00,000
    ええと、Claude 4がその旅路にどう収まるか興味があります。

    485
    01:08:00,000 --> 01:08:05,000
    ええ、それは私が書いた製品ロードマップのようなもので、実際にどうすればいいのか分からず、

    486
    01:08:05,000 --> 01:08:09,000
    「よし、みんな、これは君たちの仕事だ」と言いました。

    487
    01:08:09,000 --> 01:08:15,000
    ええと、ええと、ええと、10年前は、ええと、多くの人が神経科学がAIのやり方を教えてくれるだろうと考えていたと思います。

    488
    01:08:15,000 --> 01:08:21,000
    ええと、ええと、実際、この分野には多くの元神経科学者がいます。

    489
    01:08:21,000 --> 01:08:26,000
    私は唯一の人間ではありません。他の研究室のリーダーもいます。

    490
    01:08:26,000 --> 01:08:31,000
    ええと、その背景を持つ人たちもいます。

    491
    01:08:31,000 --> 01:08:38,000
    ええと、高レベルではインスピレーションがあると感じましたが、「ああ、視床下部から知っているこれを使って、これらのモデルを作るのに使える」とは言いませんでした。

    492
    01:08:38,000 --> 01:08:40,000
    それはほとんどゼロからのスタートでした。

    493
    01:08:40,000 --> 01:08:47,000
    しかし興味深いことに、解釈可能性を使うことでモデルの内部を見ることができるようになり、物事は逆方向に進みました。

    494
    01:08:47,000 --> 01:08:57,000
    もちろん、人間が脳と全く同じように作られているわけではありませんが、表面的なレベルでは多くの違いがあります。

    495
    01:08:57,000 --> 01:09:06,000
    モデル内で見つかった概念的なパターンの多くは、その後、神経科学の研究で再現されることがあります。

    496
    01:09:06,000 --> 01:09:16,000
    例えば、視覚における高周波・低周波検出器のようなものがあり、それは解釈可能性によって発見されました。クリス・オラのチームの誰かによって発見され、数年後には神経科学者が実際に動物の脳でそれを再現しました。

    497
    01:09:16,000 --> 01:09:30,000
    ええと、例えば、視覚モデルが分離しているという考え方です。つまり、色に対応するパスが1つあり、明るさやオブジェクト間の境界に対応する別のパスがあるということです。これらは世界における自然な区別であり、発見されるべきものです。

    498
    01:09:30,000 --> 01:09:34,000
    そして、人工的であれ生物学的であれ、抽象的な学習システムがあれば、同じことを発見するでしょう。

    499
    01:09:34,000 --> 01:09:35,000
    だから、とても面白いです。

    500
    01:09:35,000 --> 01:09:38,000
    サーキット論文が神経科学研究にどう影響するか、本当に興味があります。

    501
    01:09:38,000 --> 01:09:41,000
    ええと、5年から10年の時間軸で。

    502
    01:09:41,000 --> 01:09:47,000
    ええと、AIでそれが可能である限り、私たちが楽観的に動くにつれて、現実的にはおそらく1年でしょう。

    503
    01:09:47,000 --> 01:09:50,000
    ええと、最初の10億ドル企業はいつ誕生すると思いますか？

    504
    01:09:50,000 --> 01:09:51,000
    人間従業員が1人だけの企業は？

    505
    01:09:51,000 --> 01:09:52,000
    2026年。

    506
    01:09:52,000 --> 01:09:53,000
    はい。

    507
    01:09:53,000 --> 01:09:54,000
    いいえ、いいえ、絶対に買います。

    508
    01:09:54,000 --> 01:09:55,000
    はい。

    509
    01:09:55,000 --> 01:09:56,000
    ええと。

    510
    01:09:56,000 --> 01:10:00,000
    ええと、Claudeで構築している人たちに何かアドバイスはありますか？

    511
    01:10:00,000 --> 01:10:03,000
    来年、その最前線で構築することをどう考えるか。

    512
    01:10:03,000 --> 01:10:13,000
    はい、ええと、モデルの使い方について、非常に具体的なことをたくさん言えると思いますが、この相対論的な時間遅延のせいで、物事が加速しているように感じます。ほとんどすべてのアドバイスは、たった一文、あるいは二つの言葉に集約されます。それは「野心的であれ」ということです。

    513
    01:10:13,000 --> 01:10:18,000
    ええと、自分が可能だと思っているよりも大きなものを構築してください。

    514
    01:10:18,000 --> 01:10:28,000
    そして、まだ完全に機能していなくても、次の世代のモデルが登場します。今は3ヶ月ですが、おそらく2ヶ月、そして1ヶ月になるでしょう。そして、今年登場するなら、おそらく「今日は何も構築するな」というアドバイスをするでしょう。

    515
    01:10:28,000 --> 01:10:30,000
    「今日はこれで構築したくないだろう」と。

    516
    01:10:30,000 --> 01:10:35,000
    2年前に自律型AIコーディングエージェントの分野で会社を立ち上げた創業者と話しました。

    517
    01:10:35,000 --> 01:10:40,000
    彼は基本的にすべてのモデルを試しましたが、彼のスタートアップはうまくいきませんでした。

    518
    01:10:40,000 --> 01:10:44,000
    そして、3.7で彼は「私のスタートアップは今動いている」と言いました。そして、それは私が試していたことと同じでした。

    519
    01:10:44,000 --> 01:10:50,000
    本当に難しかったことが、突然可能になりました。しかし、壁に頭をぶつけることは、実際には役に立つことがあります。なぜなら、他のすべてのピースを配置するからです。

    520
    01:10:50,000 --> 01:10:59,000
    そして、モデルが機能すると、まるで必要以上に堅牢なものを作ったかのようになり、それはポジティブな特性になる可能性があります。

    521
    01:10:59,000 --> 01:11:04,000
    ええと、ですから、私が「ああ、次のモデルを待てばいい」と冗談を言うのと同じくらい、実際には生産的になれると思います。

    522
    01:11:04,000 --> 01:11:09,000
    高度な研究でも、社内では、私たちの研究とClaude Skillsチームがこのプロトタイプを構築していました。

    523
    01:11:09,000 --> 01:11:15,000
    そして、モデルは道に迷い、ツールをうまく使えませんでした。しかし、3.7、特にClaude 4では、高度な研究も非常にうまく機能することがわかるでしょう。

    524
    01:11:15,000 --> 01:11:19,000
    そして、私たちが試行錯誤しながら進んできたからです。

    525
    01:11:19,000 --> 01:11:24,000
    ええ、まるで次のモデルに対して投機的な実行をしたいかのように、スタートアップを運営したいかのようです。

    526
    01:11:24,000 --> 01:11:25,000
    ええ、何か、分かりません。

    527
    01:11:25,000 --> 01:11:26,000
    大好きです。

    528
    01:11:26,000 --> 01:11:27,000
    はい、まさにその通りだと思います。

    529
    01:11:27,000 --> 01:11:29,000
    ええと、では最後の質問です。

    530
    01:11:29,000 --> 01:11:35,000
    ええと、今日の私たちの多くにとって、ダリオ以外の人にとっては、AIが成し遂げた進歩と変化の急速なペースは想像できませんでした。

    531
    01:11:35,000 --> 01:11:38,000
    来年、そして今後5年間で最も楽しみにしていることは何ですか？

    532
    01:11:39,000 --> 01:11:40,000
    ええと、はい。

    533
    01:11:40,000 --> 01:11:44,000
    ええと、来年には、コードにおいて信じられないようなことが起こると思います。

    534
    01:11:44,000 --> 01:11:51,000
    もう一度、Claude Codeの現状とコーディングモデルの現状、そしてそこからエージェントフリートへと進むことを参照したいと思います。

    535
    01:11:51,000 --> 01:12:00,000
    ええと、これが世界に興味深い影響を与えると思います。ソフトウェアを生産するコストが下がったときに何が起こるか、経済的またはビジネス的な観点から慎重に考えていないと思います。

    536
    01:12:00,000 --> 01:12:09,000
    それは一種の仮定であり、信仰の対象です。何百万人もの人が使うのでなければ、ソフトウェアを作る価値はない、あるいは少なくとも何十万人、もしかしたら何万人もの人が使うのでなければ、作る価値はないと。

    537
    01:12:09,000 --> 01:12:15,000
    例えば、このイベントのためにソフトウェア全体を作ることはないでしょう。何かを急いで作るかもしれませんが、

    538
    01:12:15,000 --> 01:12:26,000
    それが本当に安くなったら、20セントで「ああ、この特定のイベントのために、私のビジョンを変えるようなものを、数秒で、1ドル以下で、アドホックに作ってみよう」となるでしょう。

    539
    01:12:26,000 --> 01:12:31,000
    ええと、世界はこれらのものがアドホックに作られるようになると、非常に異なるものになると思います。

    540
    01:12:31,000 --> 01:12:35,000
    開発者の役割は何ですか？ビジネスの役割は何ですか？スタートアップの役割は何ですか？

    541
    01:12:35,000 --> 01:12:38,000
    そして、それを使っている人々の経験はどうですか？

    542
    01:12:38,000 --> 01:12:39,000
    これらの質問のどれにも答えを知らないと思います。

    543
    01:12:39,000 --> 01:12:40,000
    だから、とても面白いです。

    544
    01:12:40,000 --> 01:12:43,000
    5年間の時間軸で、私は再び生物学に戻ります。

    545
    01:12:43,000 --> 01:12:51,000
    生物医学分野は来年革命を起こすことはないでしょう。なぜなら、それは一種の、ご存知の通り、ゆっくりと起こるからです。

    546
    01:12:51,000 --> 01:12:59,000
    しかし、ええと、ええと、5年後には、現在存在する多くの病気を克服していることを願っています。

    547
    01:12:59,000 --> 01:13:00,000
    そうですね。

    548
    01:13:00,000 --> 01:13:01,000
    それで終わりにしましょう。

    549
    01:13:01,000 --> 01:13:03,000
    残念ながら、もう40分話せそうですが、ここで終わりにしなければなりません。

    550
    01:13:03,000 --> 01:13:06,000
    まず、本日お時間を割いてくださったダリオに感謝申し上げます。ダリオ、ありがとうございます。

    551
    01:13:06,000 --> 01:13:10,000
    また、会場にお越しの皆様、ライブストリームでご覧の皆様にも感謝申し上げます。

    552
    01:13:10,000 --> 01:13:12,000
    しかし、閉会する前に、一つだけ言い忘れました。

    553
    01:13:12,000 --> 01:13:28,000
    Code with Claudeに本日ご参加いただいた皆様への特別な感謝として、皆様にMax 20X、当社の最高ティアプランを3ヶ月間無料で提供することをお知らせします。

    554
    01:13:28,000 --> 01:13:29,000
    ぜひお楽しみに。

    555
    01:13:30,000 --> 01:13:31,000
    MaxをClaude Codeと一緒に使うのが特に好きなので、それもできるようになります。

    556
    01:13:31,000 --> 01:13:32,000
    皆様が何を構築するか楽しみです。

    557
    01:13:32,000 --> 01:13:34,000
    残りの一日も素晴らしいものにしてください。Code with Claudeへようこそ。

    558
    01:13:34,000 --> 01:13:35,000
    お越しいただきありがとうございます。

    559
    01:13:35,000 --> 01:13:36,000
    皆さん、ありがとう。

    560
    01:13:36,000 --> 01:13:37,000
    はい。
    ```


**※タイムスタンプ崩れがちです。参考程度で（修正未定）**

AI議事録：

### 議事の要旨:

Anthropic社は初の開発者カンファレンス「Code with Claude」にて、次世代AIモデル**Claude Opus 4**と**Claude Sonnet 4**を発表しました。これらのモデルは、コーディング能力、高度な推論、AIエージェントのワークフローにおいて新たな基準を打ち立てるものです。特に**Opus 4は世界最高のコーディングモデル**とされ、複雑で長時間のタスクやエージェントワークフローで持続的なパフォーマンスを発揮します。**Sonnet 4はSonnet 3.7から大幅にアップグレード**され、優れたコーディング能力と推論能力を提供しつつ、指示への応答精度も向上しています。

同時に、ツール使用による思考の拡張（ベータ版）、複数ツールの並列実行、ローカルファイルアクセスによるメモリ機能の向上といった新機能も発表されました。**Claude Codeは一般提供が開始**され、GitHub ActionsやVS Code、JetBrainsとのネイティブ統合により、開発者の生産性をさらに高めます。APIには、コード実行ツール、MCPコネクタ、Files API、プロンプトキャッシュ（最大1時間）といった新機能が追加され、より強力なAIエージェントの構築を可能にします。これらのモデルと機能は、開発者がAIと共に革新的なアプリケーションを構築するための強力な基盤となることが期待されます。

## [**Code with Claude - Anthropic's First Developer Conference Opening**]

![image.png](attachment:3fe97841-f729-4e53-96f1-702c8a6349eb:image.png)

### オープニングセッション:

- **Mike Krieger氏 (CPO, Anthropic) の登壇** [Mike Krieger][01:02:00]
    - 歓迎の挨拶とカンファレンスの紹介 [Mike Krieger][01:17:00]
        - 本日はAnthropic初の開発者カンファレンス「Code with Claude」へようこそ。 [Mike Krieger][01:18:00]
    - 自己紹介とAnthropicでの役割 [Mike Krieger][01:23:00]
        - Mike Krieger、Anthropicの最高製品責任者（CPO）。 [Mike Krieger][01:23:00]
        - Anthropicに入社して1年が経過。AIの世界では3年分に相当する濃密な期間。 [Mike Krieger][01:28:00]
    - Anthropic参加の経緯とビジョン [Mike Krieger][01:34:00]
        - 以前はInstagramを共同創業し、AI搭載ニュースアプリArtifactも手がける。 [Mike Krieger][01:35:00]
        - Anthropic創業者のビジョンに共感して参加。 [Mike Krieger][01:43:00]
            - **創業者のビジョン：パワフルであると同時に、役立ち、信頼できるAIシステムを構築する。** [Mike Krieger][01:45:00]
            - 現在のビジョン：開発者が仕事のやり方を変革し、新しい企業を構築する方法をエンパワーメントすること。 [Mike Krieger][01:51:00]
                - この変革は、人間の創造性を置き換えるのではなく、拡張することを目指す。 [Mike Krieger][02:02:00]
    - AIエージェントによる仕事とイノベーションの変化 [Mike Krieger][02:07:00]
        - AIエージェントは私たちの働き方やイノベーションの方法を変えている。 [Mike Krieger][02:08:00]
        - 人間の生産性を制限してきたボトルネックを取り除くことで、構築できるものを拡大している。 [Mike Krieger][02:11:00]
    - 本日のカンファレンス内容紹介 [Mike Krieger][02:17:00]
        - 製品およびエンジニアリングリーダー、顧客からフロンティアを押し進める話を聞く。 [Mike Krieger][02:18:00]
        - Code with Claudeで期待できること： [Mike Krieger][02:25:00]
            - **3つのテクニカルディープダイブセッション**：Claudeでの構築方法を変革する。 [Mike Krieger][02:29:00]
            - **5つの主要プレイヤーによるセッション**：Anthropicのプラットフォームを既に利用し、業界を再構築している事例。 [Mike Krieger][02:34:00]
            - **ハンズオン体験のためのオフィスアワーとワークショップ**。 [Mike Krieger][02:40:00]
    - ゲスト紹介：Dario Amodei氏 (CEO & Co-founder, Anthropic) [Mike Krieger][02:48:00]
        - 新しいAPIケイパビリティについて話す前に、ゲストをステージに招待。 [Mike Krieger][02:48:00]
        - AnthropicのCEO兼共同創業者、Dario Amodei氏。 [Mike Krieger][02:51:00]

### Dario Amodei氏による新モデル発表:

- **Dario Amodei氏 (CEO & Co-founder, Anthropic) の登壇と発表** [Dario Amodei][03:04:00]
    - 挨拶と今後の予定 [Dario Amodei][03:04:00]
        - 20分後にファイアサイドチャットで再登壇予定。今回は手短に。 [Dario Amodei][03:06:00]
    - **Claude 4 Opus と Claude 4 Sonnet のリリース発表** [Dario Amodei][03:14:00]
        - **本日この瞬間より、Claude 4 Opus と Claude 4 Sonnet をリリース。** [Dario Amodei][03:20:00]
        - 全ての関連製品・サービス（product surfaces）で利用可能。 [Dario Amodei][03:26:00]
    - OpusモデルとSonnetモデルの紹介 [Dario Amodei][03:35:00]
        - しばらくOpusモデルの新作がなかったため、リマインダーとして説明。 [Dario Amodei][03:37:00]
        - **Opus：最も高性能で知的なモデル。** [Dario Amodei][03:41:00]
        - **Sonnet：知性と効率のバランスが取れたミッドレベルモデル。** 過去約1年間利用されてきた。 [Dario Amodei][03:44:00]
        - 両モデルは、それぞれのユースケースと最適な利用タイミングが存在するように設計。 [Dario Amodei][03:56:00]
    - Opusモデル (Claude Opus 4) の詳細 [Dario Amodei][04:10:00]
        - **コーディングとエージェント的なタスク (agentic tasks) に特化して設計。** [Dario Amodei][04:13:00]
        - **SWE-bench, Terminal-benchといったベンチマークで最先端の性能を発揮。** [Dario Amodei][04:18:00]
        - 顧客のプレビューでは、人間が6～7時間かかるタスクを自律的に実行可能であることが確認された。 [Dario Amodei][04:33:00]
        - Anthropic社内のシニアエンジニアも、その生産性向上に驚いている。 [Dario Amodei][04:43:00]
        - **初めて、Claudeが書いた社内サマリーやドキュメント、アイデアが人間が書いたものと区別がつかないレベルに到達。** [Dario Amodei][04:50:00]
            - 以前のモデルは品質は高いものの、特有のスタイルがあり人間とは区別できた。 [Dario Amodei][05:01:00]
            - 今回は名前を見ずに読んだ際、人間が書いたものと誤認したほど。 [Dario Amodei][05:09:00]
    - Sonnetモデル (Claude Sonnet 4) の詳細 [Dario Amodei][05:24:00]
        - **Sonnet 3.7からの厳密なアップデートであり、同等のコストでより優れた知性を実現。** [Dario Amodei][05:28:00]
        - 多くの顧客は単純に一方から他方へスイッチしている。 [Dario Amodei][05:36:00]
        - 一部のコーディングベンチマークではOpusと同等の性能を持つが、よりリーンで焦点が絞られている。 [Dario Amodei][05:41:00]
        - Sonnet 3.7で散見されたフィードバック（過度な意欲など）に対応し、報酬ハッキングの問題も改善。 [Dario Amodei][05:50:00]
        - 顧客である**Cursor**は、これを最先端のコーディングモデルであり、複雑なコードベース理解において飛躍的な進歩だと評価。 [Dario Amodei][06:13:00]
    - Claude 4シリーズの継続的な改善と今後のリリース方針 [Dario Amodei][06:44:00]
        - Claude 4シリーズのモデルは継続的に改善していく。 [Dario Amodei][06:45:00]
        - **おそらくSonnet 3.7よりも頻繁に、定期的なマイナーバージョンアップデートを予定。** [Dario Amodei][06:50:00]
        - 本日より、ほぼ全てのサーフェスで利用可能（Free TierはSonnetのみの場合あり、他のAPIサーフェスは両方を提供）。 [Dario Amodei][07:00:00]
    - Mike Krieger氏への引き継ぎ [Dario Amodei][07:14:00]

## [**Claude 4 モデルとAPIロードマップ詳細**]

![image.png](attachment:0b7aede2-0e99-4332-9d63-09b7e1bb781b:image.png)

### Mike Krieger氏によるClaude 4モデルとAPIロードマップの説明:

- **Claude 4 Opus と Sonnet 4 の発表と顧客の反応** [Mike Krieger][07:25:00]
    - Dario氏の発表を受け、2つの新モデルが登場。 [Mike Krieger][07:26:00]
    - 個人的に顧客がClaude Opus 4とSonnet 4を試すことに非常に興奮している。チームはこれらのモデルでの作業を愛しており、ユーザーも同様だと信じている。 [Mike Krieger][07:37:00]
- **Claude 4 構築の目標** [Mike Krieger][07:51:00]
    - 当初の目標は明確だった。 [Mike Krieger][07:52:00]
        - **パワフルなAIを構築し、安全に新しいモデル機能（capabilities）を導入する。** [Mike Krieger][07:55:00]
        - **コーディングとAIエージェントのフロンティアを継続的に推進する。** [Mike Krieger][08:00:00]
        - **Claudeがユーザーの仮想的な協力者 (virtual collaborator) となることを保証する。** [Mike Krieger][08:03:00]
    - Claude 4 モデルの特徴（ハイブリッドモデル） [Mike Krieger][08:06:00]
        - Opus 4とSonnet 4でこれらの目標を達成。 [Mike Krieger][08:07:00]
        - Sonnet 3.7と同様に、Claude 4モデルはハイブリッドモデル。 [Mike Krieger][08:10:00]
            - **2つのモード：ほぼ瞬時の応答 (near instant responses) と、より深い推論が必要な場合の拡張思考 (extended thinking for deeper reasoning)。** [Mike Krieger][08:14:00]
            - 多くの顧客が非コーディング、非数学のユースケースでも拡張思考を利用していることに驚いている。 [Mike Krieger][08:19:00]
- **Opus 4 の特徴とユースケース** [Mike Krieger][08:24:00]
    - **コードベースの理解、計画の追加に優れている。** [Mike Krieger][08:25:00]
    - マイグレーションからコードリファクタリングまで、あらゆる点で効果的かつ正確。 [Mike Krieger][08:30:00]
    - **最も複雑なエージェント的なワークフロー (agentic workflows) にとっても正しい選択。** [Mike Krieger][08:34:00]
    - 他のモデルで壁にぶつかったユースケースでも、Opus 4でできることに心地よく驚くだろう。 [Mike Krieger][08:38:00]
- **Sonnet 4 の特徴とユースケース** [Mike Krieger][08:44:00]
    - **日常のコーディングタスク、アプリ開発、ペアプログラミングに優れる。** [Mike Krieger][08:45:00]
    - 大量処理のユースケースに最適で、効率とパフォーマンスを完璧にバランスさせる。 [Mike Krieger][08:50:00]
    - **常時オンのコーディングパートナー (always on coding partner) と考えてほしい。** [Mike Krieger][08:55:00]
- **Claude 4 モデルの提供プラットフォーム** [Mike Krieger][08:58:00]
    - 両モデルは本日より、Claude、Claude Code、Anthropic API、Amazon Bedrock、Google Cloud's Vertex AIでライブ。 [Mike Krieger][08:59:00]
- **AIエージェント構築のための重要な新機能** [Mike Krieger][09:06:00]
    - これらのモデルは、AIエージェント構築のための重要な新しいケイパビリティをもたらす。 [Mike Krieger][09:07:00]
        - **ツール使用（Web検索など）を推論プロセス中に実行可能（新機能）。** [Mike Krieger][09:09:00]
        - **複数のツールを並行して処理できる。** [Mike Krieger][09:13:00]
        - **ローカルファイルへのアクセス権が与えられた場合、セッション間でメモリを維持し、時間とともに知識を構築できる。** [Mike Krieger][09:15:00]
            - このメモリ機能については後ほどDario氏と詳しく話す。 [Mike Krieger][09:21:00]
        - **これらは単なる増分的な改善ではなく、AIエージェントにとって可能なことを根本的に変えるもの。** [Mike Krieger][09:24:00]

## [**AIエージェントの進化と開発者への影響**]

![image.png](attachment:7402d98a-aaca-4a38-84b6-78f1f8e3879d:image.png)

### AIエージェントの定義と重要性:

- **「エージェント」という言葉の流行と本質** [Mike Krieger][09:29:00]
    - 最近「エージェント」という言葉が飛び交っている。 [Mike Krieger][09:30:00]
        - Anthropic社内でのジョーク：会議が始まって何分で「エージェント」という言葉を使わずにいられるか。今日は17分ほどだった。 [Mike Krieger][09:32:00]
        - 本日のカンファレンスでは、誇大広告 (hype) を超えたエージェントに焦点を当てる。 [Mike Krieger][09:41:00]
- **AIエージェントの真の可能性** [Mike Krieger][09:44:00]
    - **本当に重要なのは、適切な基盤モデルと適切な基盤プラットフォームツールがあれば、AIエージェントが人間の想像力を前例のない規模で具体的な現実に変えることができるということ。** [Mike Krieger][09:45:00]
    - これは特にスタートアップや開発者にとって重要。 [Mike Krieger][09:55:00]

### AIエージェントが開発プロセスにもたらす変革:

- **過去の開発における制約（Instagram創業時の経験）** [Mike Krieger][10:00:00]
    - 自身も創業者として、Instagram初期の有名な小規模チームは、多くの非常に苦しい二者択一の決断を迫られた。 [Mike Krieger][10:01:00]
        - 例：製品への動画追加を検討するか、コアな創造性に集中するか。モバイルアプリ（当初は単一モバイルアプリ）に集中するか、Webへ拡張するか。全て非常に単線的だった。 [Mike Krieger][10:07:00]
- **AIエージェントによる並行実験と迅速な製品開発** [Mike Krieger][10:23:00]
    - **AIエージェントにより、スタートアップは実験を並行して実行し、ユーザーから学び、これまで以上に迅速に製品を構築できる。** これは多くの参加者から聞いていること。 [Mike Krieger][10:24:00]
- **AIエージェントによる戦略的思考の提供** [Mike Krieger][10:32:00]
    - AIエージェントは、スタートアップの創業者に、高性能なCFOやプロダクト責任者から得られるような戦略的思考へのアクセスを与えることができる。主要なポジションをまだ構築中の段階でも。 [Mike Krieger][10:35:00]
    - それらの人材を雇う準備ができていなくても、当面はその役割の一部をClaudeに任せることができる。 [Mike Krieger][10:46:00]

### Claudeとの協調作業の具体例 (Amazon Alexaチームとの連携):

- **Claudeとの個人的な関わりと変革の実感** [Mike Krieger][10:50:00]
    - この変革はもはや理論的なものではなく、自身の役割や仕事の中で毎日目にしている。 [Mike Krieger][10:51:00]
    - 個人的にもClaudeと多くの時間を過ごしている。おそらく大切な人よりも長い時間。 [Mike Krieger][10:56:00]
- **Amazon Alexaチームとの協業エピソード** [Mike Krieger][11:00:00]
    - Anthropic入社直後、AmazonのAlexaチームと面会。彼らはClaudeが音声アシスタントの未来のビジョンの一部となる可能性に強い関心を持っていた。 [Mike Krieger][11:01:00]
        - 当初の計画：スライドとトーキングポイントを用いた通常の顧客向けプレゼンテーション。 [Mike Krieger][11:11:00]
        - 発想の転換：**なぜClaude自体を使ってハンズオンデモを構築しないのか？** 会話がより面白くなり、ClaudeとAlexaの機能性を組み合わせた可能性を具体的に示せると考えた。 [Mike Krieger][11:17:00]
        - 課題：Alexaの実際のコードベースへのアクセスなしに、このデモを構築すること。 [Mike Krieger][11:30:00]
        - 解決策：**Claudeの能力を最大限に活用し、1週間という非常にタイトなスケジュール（実質的には週末を含む）でプロトタイプを作成。** [Mike Krieger][11:35:00]
            - **Claudeがこの成功の唯一の要因だった。** このような限られた時間枠でこれを成し遂げられたのはClaudeのおかげ。 [Mike Krieger][11:45:00]
            - サンフランシスコとロンドンに分かれた3人のチームで、可能性を示す機能的なプロトタイプを構築。 [Mike Krieger][11:50:00]
            - 自分も一部コードを書いた（エンジニア魂は消えない）。フロントエンド開発の多くを担当。 [Mike Krieger][11:56:00]
        - 結果：最初のミーティング後、パートナーシップはさらに進展。**Claudeは現在、AmazonがAlexa Plusに使用しているモデルの1つであり、今年初めにローンチされ、現在展開中。** [Mike Krieger][12:06:00]
            - Claudeのおかげでその可能性を真に示すことができたと信じている。 [Mike Krieger][12:17:00]

## [**エージェント的AIの進化とClaudeの役割**]

![image.png](attachment:14a9f3fc-fc6b-4ba9-b93d-e859df61e1f3:image.png)

### エージェント的AIへの長年の注目:

- **GitHub Copilotのデモ体験 (2021年) とその衝撃** [Mike Krieger][12:21:00]
    - このエージェント的AIへの進化を長年見守ってきた。 [Mike Krieger][12:22:00]
    - 2021年にGitHub Copilotのデモと早期アクセスを初めて体験した際、**これまで見た中で最も衝撃的な機械学習の応用例**だと感じた。当時はAIではなく機械学習と呼んでいた。 [Mike Krieger][12:25:00]
    - 何世代も前の話だが、この初期の垣間見えたエージェント的AIの可能性は非常に明確だった。 [Mike Krieger][12:36:00]
- **Artifactローンチ時の体験 (昨夏)** [Mike Krieger][12:41:00]
    - 昨夏、Artifactをローンチした際にはさらに強い感覚を覚えた。 [Mike Krieger][12:42:00]
    - **ミニアプリや視覚化のために欲しいものを記述し、送信ボタンを押し、コーヒーを取りに行き、戻ってくるとClaudeが想像したものを構築していた。** [Mike Krieger][12:45:00]

### AIは代替ではなく、協力者へ:

- **Anthropicの経済調査結果** [Mike Krieger][12:53:00]
    - その後1年で、単により良いツールを構築しているだけでなく、真の協力者 (genuine collaborators) を創造していることが明らかになった。 [Mike Krieger][12:54:00]
    - Anthropicの経済調査は、私が直接見聞きしてきたことを裏付けている。 [Mike Krieger][13:01:00]
        - **大多数のユースケースにおいて、AIは人々の仕事を置き換えるのではなく、拡張している。** [Mike Krieger][13:04:00]
        - 全体的な役割よりもタスク単位での支援が中心。 [Mike Krieger][13:09:00]
- **最高の同僚との類似性** [Mike Krieger][13:11:00]
    - これは、最高の同僚が持つ影響力と似ている。 [Mike Krieger][13:12:00]
    - **最も才能のある人々は、単に実行するだけでなく、文脈を理解し、経験から学び、いつ主導権を握るべきか、いつ単に確認すべきかを知っている。** [Mike Krieger][13:14:00]

### 優れたAIエージェントの3つの能力:

- **文脈的知性 (Contextual Intelligence)** [Mike Krieger][13:24:00]
    - 我々のプラットフォームで構築できるような優れたAIエージェントは、3つの能力に秀でているべき。 [Mike Krieger][13:25:00]
    - **ユーザーと組織のユニークな文脈を理解し、経験から継続的に学習する。** [Mike Krieger][13:30:00]
    - 単に指示に従うのではなく、なぜそうするのか、どのようにするのかを理解する。 [Mike Krieger][13:37:00]
    - これは、時間とともに学習しパーソナライズするモデルを意味し、文脈的記憶だけでなく、エピソード記憶や組織的記憶も獲得する。 [Mike Krieger][13:40:00]
    - チームにいつも言っているのは、**エージェントとの100回目のタスクは、最初のタスクよりもはるかに優れていなければならない**ということ。従業員との100日目が最初の日よりもはるかに優れているべきであるのと同じように。 [Mike Krieger][13:47:00]
- **長時間実行 (Long-running Execution)** [Mike Krieger][13:57:00]
    - **複雑で複数時間にわたるタスクを、絶え間ない管理なしに処理する。** [Mike Krieger][14:00:00]
    - 必要に応じて他のエージェントや人間と協調する。 [Mike Krieger][14:04:00]
    - 文脈を理解し、それを長期間にわたって実行できる。 [Mike Krieger][14:08:00]
- **真の協調 (Genuine Collaboration)** [Mike Krieger][14:11:00]
    - **有意義な対話を行い、ユーザーの作業スタイルに適応し、行動に対する透明性のある推論を提供する。** [Mike Krieger][14:13:00]
- **真のエージェンシーとは** [Mike Krieger][14:20:00]
    - ここでの重要な洞察は、**真のエージェンシーとは制御不能な行動を意味するのではない**ということ。自律性とは単に「YOLO（人生一度きり）」で行動することではない。 [Mike Krieger][14:22:00]
    - それは、**明確なチェックポイントとバランスの取れた知的な自律性**を意味する。 [Mike Krieger][14:28:00]
    - 重要な決定については人間の監視を維持しつつ、通常私たちの時間を多く消費する小さな決定は委任する。 [Mike Krieger][14:31:00]

## [**新しいAPIケイパビリティの発表**]

### APIケイパビリティの概要:

- **上記3つのニーズに応えるための新ケイパビリティ発表** [Mike Krieger][14:39:00]
    - これらの能力について話そう。本日発表する、これら3つのニーズに応えるためのケイパビリティ。 [Mike Krieger][14:40:00]

### コード実行ツール (Code Execution Tool):

- **本日Anthropic APIで利用可能** [Mike Krieger][14:43:00]
    - まずは新しいコード実行ツールから。これは本日、Anthropic APIで利用可能。 [Mike Krieger][14:44:00]
- **Claudeにコード実行環境を提供** [Mike Krieger][14:48:00]
    - コード実行ツールは、Claudeにコードを実行できる環境を与える。 [Mike Krieger][14:49:00]
        - これにより、**データアナリストとして機能し、生データを視覚的な洞察に変換**することが可能になる。 [Mike Krieger][14:52:00]
        - Claudeはもはやコードを書くだけでなく、**それを実行し、結果を見て、データ内のパターンをよりよく強調するために結果とコードを反復的に改良**することができる。 [Mike Krieger][14:58:00]
- **デモ：販売データ分析** [Mike Krieger][15:06:00]
    - ここで、Claudeが販売データを分析し、特定のタイプの製品がどのように機能しているかを確認する様子を示す。 [Mike Krieger][15:07:00]
        - **Claudeはデータセットをロードし、クリーンにし、探索的なチャートを生成し、異常をリアルタイムでドリルダウン**することができる。 [Mike Krieger][15:13:00]
        - データ視覚化アナリストとしてキャリアをスタートさせた者として、これは非常に共感を覚える。 [Mike Krieger][15:20:00]
- **Claude 4モデルの知性と組み合わせることでさらに強力に** [Mike Krieger][15:25:00]
    - コード実行ツールは、Claude 4モデルの知性と組み合わせるとさらに強力になる。 [Mike Krieger][15:26:00]
- **これがエージェンシー：複雑なタスクを完了まで見通す能力** [Mike Krieger][15:30:00]
    - これが私たちがエージェンシーと呼ぶもの。複雑なタスクを受け取り、それを完了まで見通す能力。 [Mike Krieger][15:31:00]

### 長時間タスク処理能力の向上:

- **数時間単位のタスク処理が可能に** [Mike Krieger][15:37:00]
    - これらは、数時間にわたるタスクを処理できる最初のモデルであり、それらと並行して作業することで、半日、場合によっては丸一日分の時間を節約できる。 [Mike Krieger][15:38:00]
    - 単にコードスニペットを書くだけでなく、**コードベース全体をリファクタリングしたり、複雑な機能をゼロから実装したりする。** [Mike Krieger][15:44:00]
- **進捗の具体例** [Mike Krieger][15:50:00]
    - 私たちが見ている進捗の種類を理解していただくために。 [Mike Krieger][15:51:00]
        - 昔、私が始めた頃は、Claude 3に数分程度の作業を委任できた。 [Mike Krieger][15:54:00]
        - 一方、Claude 3.7は、途切れることなく約45分間自律的に作業できた。 [Mike Krieger][15:57:00]
        - **そして今、私たちはClaudeが自律的に処理できる数時間単位の作業へとブレークスルーしている。** [Mike Krieger][16:02:00]
            - 先ほどご覧いただいたように、**楽天 (Rakuten) は、Claudeが信じられないほどの7時間、持続的なパフォーマンスで独立してリファクタリングを実行したと言及した。** [Mike Krieger][16:08:00]
            - 特にメモリを管理し、独自のToDoリストを作成できるため、途切れることなく実行できる。 [Mike Krieger][16:15:00]

### 既存ツールとの連携強化:

- **Claude Code の一般提供開始** [Mike Krieger][16:20:00]
    - 我々はこの力を、皆さんが作業する場所に既に統合している。 [Mike Krieger][16:21:00]
    - 皆さんもClaude Codeをご存知だろう。数ヶ月前にリサーチプレビューとしてローンチした我々のエージェント的コーディングツール。 [Mike Krieger][16:24:00]
    - **我々はClaude Codeを本日より一般アクセスへと移行する。** [Mike Krieger][16:29:00]
        - これは実際には、我々のテクニカルリードの一人であるBorisによる**社内の探索的プロジェクト (Exploratory project) として始まった。** これは彼のアナウンスメント投稿だ。彼はClaudeにターミナルで直接コーディングを手伝ってもらいたかった。 [Mike Krieger][16:31:00]
        - ごく初期には、社内でClaude CLIと呼んでいた。 [Mike Krieger][16:40:00]
        - ArtifactやClaude Codeのような我々の最高のイノベーションのいくつかは、この種のボトムアップの実験から生まれてきたと私は思う。これは我々がAnthropicで育もうとしている文化の一部だ。 [Mike Krieger][16:43:00]
        - **社内でローンチしてからわずか2日で、我々の利用状況チャートは垂直に上昇した。** [Mike Krieger][16:51:00]
            - 人々はプロダクトマーケットフィットについて話すが、我々はしばしばプロダクトAnthropicフィットについて話す。つまり、社内の人々がドッグフーディングしているか、使っているかということだ。 [Mike Krieger][16:56:00]
        - **今日、ほとんどのAnthropicの従業員は、日常的なコーディングから大規模なマイグレーションまで、あらゆることにClaude Codeを利用している。** [Mike Krieger][17:02:00]
            - **最も高度なコーダーの何人かが、複数のターミナルウィンドウで複数のClaude Codeのコピーを実行しているのを見てきた。** [Mike Krieger][17:08:00]
            - 彼らは単なるエンジニアであることから、いくつかの自律エージェントのマネージャーへと移行している。単純なコーディングタスクから、複数のコードベースにまたがる複雑なフルスタック開発プロジェクトまで、あらゆるものに取り組んでいる。 [Mike Krieger][17:13:00]
            - 私自身、Claude Codeを使っていて、フロントエンドリポジトリで1つ、バックエンドリポジトリで1つ実行していたら、Claude Codeのエンジニアの一人が「間違ってるよ。ルートで実行すればいい。Claudeは複数のリポジトリで実行できる場所を見つけ出せるし、見事にやってのける」と言ったのを思い出す。それは既に私の使い方を変えた。 [Mike Krieger][17:24:00]
        - **チームの技術的なオンボーディング時間を、エンジニアがスピードアップするのに2～3週間かかっていたところを、2～3日に短縮した。** 特に大規模なモノリスのようなコードベースを理解するのに、非常に迅速に役立つことが分かった。コードのナビゲーションにおいて素晴らしく優れている。 [Mike Krieger][17:40:00]
- **Claude CodeのIDE連携 (VS Code, JetBrains)** [Mike Krieger][17:58:00]
    - そして本日、我々はClaude CodeのケイパビリティをVS CodeとJetBrainsに直接統合する。 [Mike Krieger][17:58:00]
        - **完全な差分表示とエージェント的なワークフロー管理をエディタに組み込む。** [Mike Krieger][18:02:00]
- **Claude Code SDK のリリース** [Mike Krieger][18:07:00]
    - また、Claude Code SDKもリリースする。 [Mike Krieger][18:08:00]
        - これにより、**開発者はClaude Codeと同じコアエージェントの上に独自のアプリケーションを構築できる。** [Mike Krieger][18:09:00]
        - SDKの可能性の一例として、**Claude Code on GitHub (ベータ版) をリリースする。** [Mike Krieger][18:14:00]
            - **GitHubのプルリクエストやイシューでClaudeをタグ付けすると、レビュアーのフィードバックに対応したり、CIエラーを修正したり、コードを修正したり、テストカバレッジを実装したりできる。** [Mike Krieger][18:19:00]

### 自己改善ループとアーキテクチャルセーフティ:

- **クローズドループ：Claude Codeが自身の開発を支援** [Mike Krieger][18:30:00]
    - 我々はまた、いわゆるクローズドループにも注力している。Claude Codeは今や自身の構築を手助けしており、自身の開発をスピードアップさせることで自己改善の力を示している。 [Mike Krieger][18:31:00]
    - Claude Codeが皆さんのような開発者をエンパワーし、より多くのことを成し遂げられるようにするのは素晴らしいことだ。 [Mike Krieger][18:39:00]
    - Instagramを構築していた頃を思い出す。私たちのチームは2人から6人のエンジニアで、買収される前だった。そして2つのモバイルプラットフォームをサポートしていた。もしこのようなエージェント的コーディング製品があれば、数週間ではなく数日でプロトタイプを作成できたはずだ。 [Mike Krieger][18:44:00]
- **アーキテクチャルセーフティの重視** [Mike Krieger][19:30:00]
    - 我々はパフォーマンスが高く信頼性の高いエージェントの構築について多くを語ってきたが、責任のないエージェンシーは危険だ。特にClaude Code製品のような自己改善するものについて話す場合はなおさらだ。 [Mike Krieger][18:56:00]
    - さらに、厳格なセキュリティとコンプライアンス要件を持つエンタープライズ環境ではなおさら。 [Mike Krieger][19:07:00]
    - エージェントの広範な採用には、機密性、意思決定、調整に関するモデルの識別力と判断力を向上させる必要があると私は考えている。 [Mike Krieger][19:12:00]
    - 我々のモデルは既にこれに優れているが、機密情報を理解し、何を公開すべきかを知り、本番環境で信頼できるように、改善を続けていく。 [Mike Krieger][19:22:00]
    - だからこそ、我々がモデルを中心に構築するすべての機能は、我々が**アーキテクチャルセーフティ**と呼ぶものを取り入れている。 [Mike Krieger][19:30:00]
        - **チェックポイントとコントロール（自由裁量ではない）。** [Mike Krieger][19:36:00]
        - **主要な決定でエージェントが一時停止し、ユーザーが人間による承認が必要なアクションを定義できる。** これもモデルコンテキストプロトコルに組み込んでいる。 [Mike Krieger][19:39:00]
        - **悪用に対する堅牢性（プロンプトインジェクションなど）。** 我々はこれらをテストし、バトルテストしている。 [Mike Krieger][19:47:00]
        - **設計による透明性（明確なフィードバックループと観察可能な行動）。** [Mike Krieger][19:54:00]
        - エージェントが自律的に行動することを信頼すれば、緩和策ではなくイノベーションに集中できる。 [Mike Krieger][20:00:00]

### 解釈可能性 (Interpretability) への投資:

- **AIモデル内部で何が起きているかを正確に理解する科学** [Mike Krieger][20:07:00]
    - 我々が多額の投資を行ってきたもう一つの分野は、解釈可能性だ。AIモデルの頭の中で実際に何が起こっているのかを正確に理解するための科学。 [Mike Krieger][20:08:00]
- **Dario氏の論文「解釈可能性の緊急性」** [Mike Krieger][20:14:00]
    - Darioは最近、我々のAIシステムが実際にどのように機能するかを理解することの緊急性について書いた。彼の「解釈可能性の緊急性」というエッセイを読めばわかる。 [Mike Krieger][20:15:00]
        - 彼が呼ぶところの、**モデルの知性と解釈可能性の間の競争。** [Mike Krieger][20:21:00]
        - 効果的に、我々はAIにMRIを受けさせ、それが何を考えているかを確認し、欺瞞のような潜在的な問題を特定して正しい方向に導けるようにしたい。 [Mike Krieger][20:25:00]
- **Golden Gate Claudeの事例** [Mike Krieger][20:39:00]
    - Anthropicに入社したとき、我々のリサーチパイプラインがどのように製品を直接活性化できるかに興奮した。 [Mike Krieger][20:35:00]
    - **Golden Gate Claude**を例に挙げよう。私は入社2週目にこの船出を後押しした。なぜなら、それが単なる良いリサーチペーパーだとは思えなかったからだ。それは素晴らしいデモになるだろう。解釈可能性が実際にどのように機能するかの直感的なデモンストレーションだ。 [Mike Krieger][20:40:00]
    - **Claudeニューラルネットワーク内部のGolden Gate Bridgeフィーチャーを増幅**したとき、AIの内部動作を操作することが何を意味するのか、突然見ることができた。この場合、私たちのお気に入りの橋に深く執着させることだ。 [Mike Krieger][20:51:00]
    - Golden Gate Claudeを作成するために使用した技術は、将来的には**有害なモデルの行動を減らしたり、特定のドメインのモデルのパフォーマンスを向上させたりするのに役立つ可能性がある。** [Mike Krieger][21:03:00]
- **解釈可能性と監査可能性を企業全体の仮想協力者の基盤に** [Mike Krieger][21:13:00]
    - そして、企業全体で仮想的な協力者を雇用し始めるとき、私の願いは、解釈可能性や監査可能性のような技術に頼り、それらが彼らの仕事の礎となり、彼らが大規模に何をしているのかを理解できるようにすることだ。 [Mike Krieger][21:16:00]
    - これらは、抽象的な研究を具体的な製品能力に変えるのに役立つブレークスルーの種類だ。 [Mike Krieger][21:26:00]

### 新しいAPIケイパビリティ (4つ):

- 先ほどご覧いただいたように、我々は今やAIモデルが数時間にわたる自律的な作業を処理できる地点にあり、それは数ヶ月ごとに倍増する能力だ。 [Mike Krieger][21:34:00]
    - しかし、生のモデル能力だけでは十分ではない。これらの複数時間にわたるワークフローを実際に活用するためには、エージェントは実世界の情報のアクセス、既存システムへの接続、そしてコスト効率の良いスケーリングも必要だ。 [Mike Krieger][21:41:00]
    - そのため、我々はエージェントにコンテキストを与え、スケーリングを助けるために、4つの相互接続されたケイパビリティをローンチする。 [Mike Krieger][21:53:00]
- **MCP (Model Context Protocol) コネクタ** [Mike Krieger][22:00:00]
    - まず、**本日より、モデルコンテキストプロトコルを我々のAPIを通じて直接接続できるようになった。** [Mike Krieger][22:00:00]
    - MCPは既に、**Microsoft, Google, OpenAI, Atlassian, Zapier, Linear**など多くの企業で利用されている。これは夢のリストだった。MCPプロトコルを作成しオープンソース化したとき、これが夢のリストだった。「いつかこれらの企業に採用されるかもしれない」と。1年足らずで、彼ら全員が参加してくれた。 [Mike Krieger][22:06:00]
    - *MCPはAIエージェントのための普遍的な翻訳機でありコネクタとして機能し、既存のシステムへのシームレスな接続を可能にする。**毎回カスタムの個別統合を書く必要はない。 [Mike Krieger][22:24:00]
    - これが、専門化されたエージェントが必要なデータやツールにアクセスし、複雑な課題に取り組む**エージェント経済 (agent economy) の基盤となる可能性がある。** [Mike Krieger][22:34:00]
- **Web検索機能** [Mike Krieger][22:44:00]
    - 次に、**Web検索はClaudeにリアルタイムで最新情報へのアクセスを提供する。** [Mike Krieger][22:45:00]
    - これは**インテリジェントなデータ拡張**であり、Claudeが最新の出来事、市場のトレンド、そして新たに出現する技術について推論することを可能にする。 [Mike Krieger][22:48:00]
    - MCP機能との組み合わせも非常に強力だ。社内ナレッジソースを検索し、新たな洞察を得て、次にWebを検索してそれらを文脈化することを想像できる。 [Mike Krieger][22:58:00]
- **Files API** [Mike Krieger][23:07:00]
    - 第三に、**Files APIは本日APIで利用可能**であり、開発者がドキュメントにアクセスし保存する方法を合理化し、開発ワークフローを簡素化する。 [Mike Krieger][23:08:00]
    - また、開発者がその**メモリ機能をアプリケーションに直接組み込むのを助けるためのクックブックもリリース**している。これは先ほど述べたものだ。 [Mike Krieger][23:16:00]
    - *これらの新しいClaude 4モデルは、自己管理メモリにおいて大幅な改善を示している。**したがって、これが驚くほどうまく機能することがわかるだろう。 [Mike Krieger][23:22:00]
    - そして、このクックブックで示すように、Files APIを使用することで、非常に少ない追加オーバーヘッドでこれを達成できる。Claudeがこれらのメモリファイルを読み書きし、時間とともにコンテキストを維持するのを見ることができる。 [Mike Krieger][23:32:00]
- **プロンプトキャッシュ (1時間)** [Mike Krieger][23:40:00]
    - 最後に、力は実用的でスケーラブルでなければならない。 [Mike Krieger][23:40:00]
    - 我々は、プロトタイプから本番、そして数百万人のユーザーへと、皆さんとともに成長できることを保証したい。コストを管理し、効率を向上させることができるように。我々はClaudeが皆さんのために機能し、皆さんが成功し大規模なスケールに到達することを望んでいる。 [Mike Krieger][23:43:00]
    - だからこそ、**プロンプトキャッシュは我々の最もリクエストの多かった機能であり、我々の最も人気のあるAPI機能の一つだった。** [Mike Krieger][23:55:00]
    - プロンプトキャッシュにより、顧客はClaudeにより多くのコンテキスト、背景知識、出力例を提供でき、**コストを最大90%、長いプロンプトのレイテンシを最大85%削減**できる。 [Mike Krieger][24:00:00]
    - さて、私が話したすべての顧客は、プロンプトキャッシュに関して1つの非常に明確なリクエストを持っていた。それを本日提供する。それは、**より長い有効期限（TTL）。** [Mike Krieger][24:05:00]
        - したがって、プロンプトキャッシュで箱から出してすぐに利用できた5分のTTLに加えて、本日、**プレミアム1時間のTTLをローンチする。これは12倍の改善であり、長期間実行されるエージェントワークフローのコストを劇的に削減する。** [Mike Krieger][24:15:00]
            - このインフラストラクチャは、エージェントアプリケーションを大規模に実現可能にする。 [Mike Krieger][24:24:00]

## [**今後の展望とまとめ**]

![image.png](attachment:e90ddfdc-300a-4404-ada5-bc7cd9962084:image.png)

### ケイパビリティの組み合わせ効果:

- **各機能は単独ではなく相互に補완し合う** [Mike Krieger][24:34:00]
    - これらのケイパビリティはすべて複合的に作用する。APIに機能を構築することを考えるとき、我々はそれらを単発のものとは考えない。それらが互いにどのように補完し合うか、どのようにまとまりのあるストーリーを形成するかを考える。 [Mike Krieger][24:36:00]
        - *Claudeは今やコードを実行し、システムを理解し、Web上の最新情報にアクセスできる。これにより、完全なコンテキストで、長期間のタスクに対しても動作するエージェントの基盤が作られる。**そして、その実行全体を通じてメモリとコンテキストを維持するためにFiles APIを使用できる。 [Mike Krieger][24:42:00]

### ロードマップの3つの柱:

- 今朝ご覧いただいたすべては、ほんの始まりに過ぎない。我々のロードマップは、3つの柱に基づいて構築され続ける。 [Mike Krieger][24:58:00]
- **業界をリードするエージェントツールとアプリケーション** [Mike Krieger][25:00:00]
    - これにより、Claudeを自律的に使用して数時間にわたる作業を処理できる。 [Mike Krieger][25:06:00]
    - コード環境、コード実行ツールを使用して自身の環境でコードを実行できることを知っている。 [Mike Krieger][25:10:00]
    - Claude Codeは現在一般的に利用可能で、VS CodeやJetBrainsと統合されており、拡張SDKを使用してGitHub内部を含む独自のカスタムワークフローを構築できる。 [Mike Krieger][25:16:00]
- **APIにおけるさらなるコンテキスト統合** [Mike Krieger][25:25:00]
    - APIにより多くのコンテキストを統合することに引き続き注力していく。 [Mike Krieger][25:26:00]
    - 本日のアップデートにより、モデルコンテキストプロトコルを通じてこのコンテキストを提供したり、Webからのリアルタイムアップデートに基づいて構築したり、任意のデータソースやAPI内のあらゆるものを横断して複雑なワークフローを実行したりすることが可能になる（MCP経由）。 [Mike Krieger][25:29:00]
- **効率的なスケーリング** [Mike Krieger][25:43:00]
    - そして最後に、効率的なスケーリング。本日より、拡張された1時間のプロンプトキャッシュを使用して、パフォーマンスとコストを大規模に最適化できる。 [Mike Krieger][25:45:00]

### Claude 4を基盤とした新しいアプリケーションクラスの実現:

- **Claude 4 (Opus 4, Sonnet 4) が基盤** [Mike Krieger][25:54:00]
    - 各進歩は、本日議論した内容に基づいて構築される。Claude 4を基盤とし、Opus 4を最も複雑なエージェント的ワークフローに、Sonnet 4を日常的なインテリジェンスのための日常的なドライバーとして使用することで、新しいアプリケーションクラスを可能にしている。 [Mike Krieger][25:55:00]
- **コード実行はClaudeの作業時間を拡張** [Mike Krieger][26:05:00]
    - コード実行はClaudeが処理できる作業時間を拡大する。 [Mike Krieger][26:06:00]
- **MCPはClaudeが取得できる包括的な情報を拡張** [Mike Krieger][26:09:00]
    - MCPはClaudeが取得できる包括的な情報を拡大する。 [Mike Krieger][26:10:00]
- **プラットフォームアップデートはモデルの効率を向上** [Mike Krieger][26:13:00]
    - そして我々のプラットフォームのアップデートは、費やされる1ドルごとにモデルがますます効率的になることを保証する。 [Mike Krieger][26:14:00]

### 開発者からのフィードバックの重要性:

- **継続的なフィードバックを歓迎** [Mike Krieger][26:19:00]
    - 我々は皆さんのような開発者から、これらのツールをどのように使用しているかを積極的に学んでいる。したがって、フィードバックを引き続き寄せてほしい。私はAPIのフィードバックが大好きだ。もし私についてこれを知らないなら、絶対に私に連絡してほしい。フィードバックを聞き、開発者のためにAPIをどのように改善し続けられるかを知るのが大好きだ。 [Mike Krieger][26:20:00]
- **MCPは社内アイデアからコミュニティ実験を経てコアプラットフォーム機能へ成長した好例** [Mike Krieger][26:33:00]
    - そしてMCPはこれの完璧な例だ。それは社内のアイデアとして始まり、その後コミュニティの実験へと進み、卒業した。そして今では、Microsoft Buildのキーノートを見ればわかるように、コアプラットフォーム機能となっている。彼らはMCPを彼らの実際のインフラストラクチャの非常に多くに組み込んでいる。 [Mike Krieger][26:35:00]

### AIエージェントのエコシステム創造:

- **フィードバックループを通じて真に役立つAIエージェントを** [Mike Krieger][26:48:00]
    - 我々は、フィードバックループを持ち、それらを皆さんにとって実際に役立つものにするAIエージェントのエコシステムを創造したい。 [Mike Krieger][26:49:00]

### 未来への展望 (人間とAIの協調):

- **AIが人間の仕事をするのではなく、人間が超人的な仕事をするのをAIが助ける未来** [Mike Krieger][27:02:00]
    - 今日、我々は大きな転換点に立っている。 [Mike Krieger][26:55:00]
    - 我々の最新モデルは、我々がリリースしたすべての最新ツールと組み合わされ、新しい時代の種を与えている。 [Mike Krieger][26:58:00]
    - 未来は、AIが人間の仕事を行うことではなく、AIが人間が超人的な仕事を行うのを助けることだ。 [Mike Krieger][27:03:00]

### Kat Wu (Product Manager, Anthropic) の登壇紹介:

- **Claude Code内部での新モデルアクセスのデモンストレーション** [Mike Krieger][27:15:00]
    - そして、このビジョンを皆さんとともに構築することに本当に興奮しており、皆さんのすべての企業にとってそれがどのようなアプリケーションを力づけるかを見るのが待ちきれない。 [Mike Krieger][27:08:00]
    - そして、何が可能かをお見せするために、次にプロダクトチームのKat Wuにマイクを渡し、Claude Code内部で我々の新しいモデルにアクセスすることが、どのように開発ワークフローを変革し、複雑な複数日にわたるタスクを単一の会話で出荷するのに役立つかをデモンストレーションしてもらう。 [Mike Krieger][27:16:00]
    - 再びCode with Claudeへようこそ、そしてありがとう。残りの一日を楽しんでほしい。 [Mike Krieger][27:29:00]

## [**Claude Code デモンストレーション**]

![image.png](attachment:75c3a25f-f547-442e-986d-15db67803758:image.png)

### Kat Wu氏によるClaude Code紹介:

- **自己紹介とClaude Codeの役割** [Kat Wu][27:43:00]
    - みなさん、こんにちは。私はKat Wu、Claude Codeのプロダクトマネージャーです。 [Kat Wu][27:44:00]
- **Claude Codeの一般提供開始** [Kat Wu][27:48:00]
    - Mikeが言及したように、私たちは最近、リサーチプレビューで私たちのエージェント的コーディングツールであるClaude Codeをローンチしました。 [Kat Wu][27:49:00]
    - Claude Codeは、開発者にAnthropicモデルの生の力を、彼らが働くまさにその場所、彼らのターミナルで直接アクセスできるようにします。 [Kat Wu][27:56:00]
    - 本日より、**Claude Codeは一般的に利用可能**です。 [Kat Wu][28:07:00]
- **コンピューティング史における抽象化レベルの進化とClaude Codeの位置づけ** [Kat Wu][28:16:00]
    - コンピューティングの歴史を通じて、私たちは機械語からアセンブリ、そして高級言語へと、継続的により高い抽象化レベルへと移行してきました。 [Kat Wu][28:17:00]
    - Claude Codeとますますエージェント的になるモデルにより、私たちはさらなる一歩を目の当たりにしています。 [Kat Wu][28:31:00]
        - **開発者は、特定の機能を求めることから、フィーチャー全体を記述することへとシフトしています。** AIを導き、ソフトウェアがどのように構築されるかを変えています。 [Kat Wu][28:36:00]
- **新しいClaude 4モデル (Opus 4, Sonnet 4) をClaude Codeに導入** [Kat Wu][28:48:00]
    - 本日、私たちは新しい**Claude 4モデルをClaude Codeに導入**し、それをさらに強力で有能なコーディングエージェントにします。 [Kat Wu][28:49:00]
- **Claude Codeの新機能：IDE連携 (VS Code, JetBrains)** [Kat Wu][29:05:00]
    - 新しいモデルに加えて、Claude Codeにいくつかの新機能をリリースします。それをより汎用的なコーディングエージェントにし、開発ライフサイクル全体で利用できるようにすることに焦点を当てています。 [Kat Wu][29:07:00]
    - まず、**Claude CodeはVS CodeとJetBrains IDEと統合**され、何百万人もの開発者にとって馴染みのあるインターフェースにそれをもたらします。 [Kat Wu][29:18:00]
        - Claude Codeが作業するにつれて、**提案された変更をエディタ内でインラインで確認**できます。 [Kat Wu][29:27:00]
- **Claude Code SDK のリリース** [Kat Wu][29:35:00]
    - また、**Claude Code SDKもリリース**します。 [Kat Wu][29:36:00]
        - これにより、**開発者はClaude Codeをビルディングブロックとして、独自のアプリケーションやワークフローで利用**できます。 [Kat Wu][29:39:00]
        - SDKの可能性は無限大です。これらの可能性を紹介するために、SDKが実際に動作するオープンソースの例として、**Claude Code on GitHub**をリリースします。 [Kat Wu][29:47:00]
            - **プルリクエストやGitHubのイシューで直接Claudeをタグ付けすると、Claude Codeがレビュアーのフィードバックに返信したり、CIエラーを修正したり、新しい機能を追加したりします。** [Kat Wu][30:01:00]
- **Claude Codeはあらゆる場所で開発者を支援する汎用コーディングエージェント** [Kat Wu][30:15:00]
    - これらの追加により、Claude Codeは今や、あなたがどこで作業していても、仮想的なチームメイトとして機能し、すべてのサーフェスで利用できます。 [Kat Wu][30:16:00]
    - 詳細な開発作業のためのターミナル、SDK上に構築された自動化ワークフローのためのリモート環境（GitHubなど）、そしてシームレスなレビューのためのIDE。 [Kat Wu][30:24:00]
    - 全体として、Claude Codeは、どこにいても開発を加速するための汎用的なコーディングエージェントです。対話的にClaude Codeと直接作業している場合でも、非同期的に使用している場合でも。 [Kat Wu][30:38:00]

### デモンストレーション (Excalidrawへのテーブルコンポーネント追加):

![image.png](attachment:e7d81438-b446-45d6-bc68-774a9da0f9a6:image.png)

- **Excalidraw (オープンソースホワイトボードツール) を使用** [Kat Wu][31:04:00]
    - さて、私のお気に入りの部分です。これらのアップデートがデモでどのように見えるか見てみましょう。 [Kat Wu][30:51:00]
    - 多くの皆さんがよく知っている製品で、Claude Codeが実際の開発タスクに取り組む様子をお見せします。 [Kat Wu][30:59:00]
    - オープンソースのホワイトボードツールである**Excalidraw**を使用します。 [Kat Wu][31:04:00]
- **最もリクエストの多い機能の1つ「テーブルコンポーネントの追加」をClaude Codeに指示** [Kat Wu][31:08:00]
    - そして、Claude Codeに、最もリクエストの多かった機能の1つであるテーブルコンポーネントの実装を依頼します。 [Kat Wu][31:09:00]
    - この種のタスクは、Claude Codeでより迅速に処理できるものです。 [Kat Wu][31:14:00]
    - 通常、このようなタスクでは、Claude Codeに作業をセットし、コーヒーを作り、メールやSlackを確認し、出力が準備できたら戻ってきます。しかし、今日は皆さんと10分しかないので、スピードアップしつつも実際のワークフローをお見せします。 [Kat Wu][31:30:00]
- **プロンプト入力とClaude Codeのタスク分解 (To-Doリスト作成)** [Kat Wu][31:50:00]
    - こちらはVS Codeで開いたExcalidrawのリポジトリです。Claude Codeに要件を伝えるプロンプトを書きましょう。 [Kat Wu][31:46:00]
    - カスタムディメンションをサポートし、ドラッグしてサイズ変更でき、Excalidrawの他のすべてのスタイリングオプションをサポートするテーブルコンポーネントを追加するようClaude Codeに依頼します。 [Kat Wu][31:53:00]
    - ここからがエキサイティングなところです。**Claude Codeはまず、問題全体にどのようにアプローチするかのToDoリストを作成します。** [Kat Wu][32:04:00]
- **コードベースの探索と変更提案 (IDE内でのDiff表示)** [Kat Wu][32:14:00]
    - 次に、Claude Codeがコードベースの探索を開始するのがわかります。コンテキストのために既に開いているファイルから始めます。 [Kat Wu][32:15:00]
    - IDE統合の最も良い点は、エディタ内でインラインで差分を確認できることです。これにより、周囲のコードを見てより多くのコンテキストを把握し、自信を持って変更を受け入れるか、Claude Codeにフィードバックを与えることができます。 [Kat Wu][32:24:00]
- **自動受け入れモードによる編集とテスト実行** [Kat Wu][32:41:00]
    - Claude Codeが作業するにつれて各編集を承認することも、自動受け入れモードでClaude Codeに編集を続けさせることもできます。これにより、可視性と制御のバランスを取ることができます。 [Kat Wu][32:44:00]
    - このデモでは、Claude Codeに編集を行い、リントとテストを実行し、PRを作成する権限を与えました。 [Kat Wu][32:54:00]
- **結果：90分間の作業でテーブル機能実装、テスト作成、PR作成を完了** [Kat Wu][33:03:00]
    - Claude Codeはこのタスクに90分間取り組みました。全体をお見せできれば良いのですが、スピードアップする必要があります。 [Kat Wu][33:06:00]
    - ご覧いただいているのは、Claude Codeからの実際の未編集の出力です。 [Kat Wu][33:11:00]
    - 1時間半後、完了です。 [Kat Wu][33:16:00]
        - テーブル機能を追加し、変更を検証するためのテストを作成し、リントとテストがパスするまで反復しました。 [Kat Wu][33:21:00]
        - **これには通常、コードベースのアーキテクチャと他のすべてのツールがどのように実装されているかを理解する必要がありました。** [Kat Wu][33:29:00]
        - この場合、Claude Codeは文字通り私たちのために数時間分の作業を行っています。かなり印象的ですよね？ [Kat Wu][33:37:00]
- **Excalidrawローカル実行による機能確認** [Kat Wu][33:51:00]
    - さて、Excalidrawをローカルで実行し、機能が期待通りに動作することを確認しましょう。 [Kat Wu][33:51:00]
        - 3行3列のテーブルを作成して、完全に機能するテーブルコンポーネントがあることを確認します。素晴らしい。 [Kat Wu][33:59:00]
        - **テーブルの位置を変更したり、ドラッグしてサイズ変更したり、境界線のパターンや色を変更したり、セルにテキストを追加したりできます。** [Kat Wu][34:03:00]
- **GitHub CLIを使用したPR作成** [Kat Wu][34:36:00]
    - これもExcalidrawの既存のUIと統合されています。 [Kat Wu][34:16:00]
    - これらすべてが、Claude Codeへの1つのプロンプトで行われました。 [Kat Wu][34:21:00]
    - 次に、Claude CodeにGitHub CLIを使用してこのブランチのプルリクエストを作成するよう依頼します。 [Kat Wu][34:37:00]
    - よし、クリックしてみましょう。これでプルリクエストができました。 [Kat Wu][34:45:00]
- **GitHub Actions経由でのドキュメント更新指示 (@Claudeタグ付け)** [Kat Wu][35:01:00]
    - ここでClaude Code SDKが活躍します。GitHub Actionsを含むClaude Codeの上にカスタムワークフローを構築できます。 [Kat Wu][34:51:00]
    - このPRでは、ドキュメントを更新したいと思います。IDEに戻る代わりに、**@Claudeとタグ付けして、ドキュメントを更新するよう依頼するだけです。** [Kat Wu][35:04:00]
        - バックグラウンドでは、これによりClaude Codeを実行するGitHubアクションがトリガーされます。 [Kat Wu][35:14:00]
        - **Claudeは作業中にPRにコメントし、完了したら私たちのためにコミットを行います。** [Kat Wu][35:19:00]
        - GitHubのイシューで@Claudeとタグ付けすることもでき、そこからPRを作成することもできます。 [Kat Wu][35:25:00]

### まとめと利用開始方法:

![image.png](attachment:cdf51727-3dae-47de-b5dd-1d858eff35c7:image.png)

- **Claude Codeは複雑なタスクを数時間で処理可能** [Kat Wu][36:32:00]
    - この機能により、Claude Codeはユーザーが既に作業しているさらに多くのサーフェスでユーザーに対応します。 [Kat Wu][35:32:00]
    - 開発者はもはやローカル環境でコンテキストを切り替える必要がなく、外出先でも実行を開始できます。 [Kat Wu][35:39:00]
    - これらはすべてClaude Code SDK上に構築されています。 [Kat Wu][35:46:00]
    - GitHub Actionsの強化に加えて、顧客がSDKで素晴らしいことをしているのを見てきました。並行していくつかのClaude Codeを実行したり、不安定なテストを修正したり、テストカバレッジを増やしたり、オンコールのトリアージを行ったりしています。 [Kat Wu][35:50:00]
    - アクションが完了したようです。Claude Codeがコメントを更新し、何をしたかを知らせてくれます。コミットをクリックしてClaudeの変更を見てみましょう。私たちのためにPRのドキュメントを更新し、何もしなくてもコミットしてくれました。 [Kat Wu][36:06:00]
    - **わずか10分で、手動で実装するには数日かかったであろう複雑なタスクにClaude Codeが取り組むのをご覧いただきました。** [Kat Wu][36:32:00]
        - 何百行ものコードを書き、Excalidrawの既存の機能とシームレスに統合し、私たちのために数時間分の作業を行いました。 [Kat Wu][36:41:00]
- **本日より利用可能な機能** [Kat Wu][36:51:00]
    - これらすべてが本日利用可能です。 [Kat Wu][36:52:00]
        - **SDKを活用したClaude Code in GitHub Actionsはベータ版で利用可能です。** [Kat Wu][36:54:00]
        - Claude内で簡単なコマンドを実行してインストールできます。 [Kat Wu][36:59:00]
        - **VS CodeとJetBrainsのIDE拡張機能もベータ版でライブです。** IDEからClaudeを実行してインストールするだけです。 [Kat Wu][37:05:00]
        - そして最後に、**最新モデルであるClaude Opus 4とClaude Sonnet 4が、本日よりClaude Codeユーザーに利用可能**です。 [Kat Wu][37:16:00]
        - Claude Codeは、AIがコードを真に理解し、コードを扱うときに何が可能になるかを示しています。 [Kat Wu][37:24:00]

## [**Anthropicプラットフォームとエージェント構築**]

![image.png](attachment:1bdc7de8-77ea-45cb-9450-b5fd41898d53:image.png)

### Michael Gerstenhaber氏 (Head of Product, API Platform, Anthropic) の登壇:

- **自己紹介とAPIプラットフォームの役割** [Michael Gerstenhaber][38:04:00]
    - Katさん、ありがとうございます。皆さん、こんにちは。私はMichael Gerstenhaber、AnthropicのAPIプラットフォームの製品責任者です。 [Michael Gerstenhaber][38:04:00]
- **AIによるコード生成の現状と未来** [Michael Gerstenhaber][38:16:00]
    - ここにいる何人の方が、既にAIが生成したコードを使ってアプリケーションを作成していますか？ [Michael Gerstenhaber][38:17:00]
    - そして、そのうち何人が、機能提供のコアとしてAIを使用していますか？ここにいる全員ですね。それが私の思った通りです。 [Michael Gerstenhaber][38:22:00]
        - **世界のほとんどのアプリケーションは、既に世界の課題を解決しようとしている人々によって構築されるでしょう。** あなたがLeetCodeのホワイトボード面接をパスしようと、Vibesから始めようと、私たちは皆ソフトウェアエンジニアです。 [Michael Gerstenhaber][38:30:00]
        - しかし、コードを書くことは始まりに過ぎません。より迅速に、安定し、安全で、保守可能なAIアプリケーションを構築する必要があります。 [Michael Gerstenhaber][38:43:00]

### Anthropicプラットフォームの提供価値:

![image.png](attachment:2494367c-9472-4f05-9ce1-a9a3251d06b4:image.png)

- **信頼性の高いClaudeへのアクセス (Model Inference Service, Messages API)** [Michael Gerstenhaber][39:36:00]
    - そのために、私たちはAnthropicプラットフォームを構築しました。最先端のAIアプリケーションとエージェントを構築するために設計された完全なツールキットです。 [Michael Gerstenhaber][38:52:00]
    - 私たちのプラットフォームは、既にあらゆるドメインで世界のAIデリバリーのほとんどを支えています。 [Michael Gerstenhaber][39:01:00]
    - 金融では、TurboTaxが何百万人もの顧客が連邦税申告書で自信を持って税金を申告するのを助けています。医療では、Novo NordiskがClaudeを使用して臨床試験報告書を15週間ではなく10分未満で作成しています。そして、世界最高のコーディングアシスタントは私たちのプラットフォーム上で実行されています。これらの各企業はClaudeの知性を活用し、それぞれのユーザーにとってユニークで価値のあるものに変えています。 [Michael Gerstenhaber][39:08:00]
    - その基盤として、私たちのプラットフォームは、モデル推論サービスを通じてClaudeへの信頼性の高いアクセスを提供します。これにはMessages APIが含まれます。 [Michael Gerstenhaber][39:39:00]
- **プロンプトキャッシュによるパフォーマンス最適化とコスト削減** [Michael Gerstenhaber][39:45:00]
    - そして、プロンプトキャッシュのような重要なツールは、パフォーマンスを最適化し、コストを削減します。 [Michael Gerstenhaber][39:46:00]
        - **すべての入力トークンの50%以上がプラットフォーム上でキャッシュされ、モデルの実質的なコンテキストウィンドウを倍増させます。** [Michael Gerstenhaber][39:49:00]
        - Notionは、大量のドキュメントをコンテキストウィンドウに入れることができますが、迅速なリアルタイム実行を維持します。これにより、創造的な執筆のためにあなたの声を採用し、幻覚を実質的に排除することができます。 [Michael Gerstenhaber][39:56:00]
        - **本日より、キャッシュの有効期限を5分から1時間に延長します。** [Michael Gerstenhaber][40:09:00]
            - これにより、エージェントは銀行を破綻させることなく、ユーザーセッション全体で複雑なコンテキストを維持できます。 [Michael Gerstenhaber][40:15:00]
- **新しいケイパビリティ：Files API と コード実行ツール** [Michael Gerstenhaber][40:34:00]
    - しかし、それは基盤に過ぎません。強力なエージェントを構築するために、私たちのプラットフォームは強力なビルディングブロックを提供します。Mikeが共有したように、私たちは2つの新しいケイパビリティをリリースしています。 [Michael Gerstenhaber][40:27:00]
        - **Files APIとコード実行ツール。** あなたや私と同じように、スクリプトを書くことで解決しやすい問題もあります。私たちのプラットフォームは、エージェントが本番環境で独自のコードを書くことを可能にします。あなたと同じように。 [Michael Gerstenhaber][40:40:00]
- **既存コンポーネントとの連携：Web検索、サイテーション** [Michael Gerstenhaber][40:56:00]
    - これらの新しい機能は、リアルタイム情報のためのWeb検索や、ソースドキュメントでの応答の根拠付けのためのサイテーションのような既存のコンポーネントに加わります。 [Michael Gerstenhaber][40:58:00]
    - Thomson ReutersがCoCounselで弁護士に分析を提供する際、これを法務調査や判例法に根拠付けることが重要であり、モデルのトレーニングデータではありません。 [Michael Gerstenhaber][41:06:00]
- **MCPによる既存システムとの接続** [Michael Gerstenhaber][41:17:00]
    - 私たちのプラットフォームはまた、モデルコンテキストプロトコルを通じて、エージェントとデータ、ビジネスシステムを接続します。 [Michael Gerstenhaber][41:17:00]
        - **MCPは私たちの開発者エコシステムで急速に普及し、コミュニティによって構築された3000以上の統合があります。** [Michael Gerstenhaber][41:27:00]
        - あなたのエージェントがSentryでアプリケーションエラーにアクセスしていようと、Zapierのワークフローをトリガーしていようと、Asanaタスクを作成していようと、MCPコネクタはモデルがタスクに必要な任意のツール、データ、またはアプリと対話することを可能にします。 [Michael Gerstenhaber][41:33:00]
        - そして本日、プラットフォームはツールとAPI呼び出しのすべての技術的な複雑さを処理することで、これをさらに容易にします。 [Michael Gerstenhaber][41:51:00]

### APIの構成可能性とエージェント構築:

![image.png](attachment:88bd753d-b7c4-4527-8492-55fde234ddb2:image.png)

- **APIは個別に機能するだけでなく、相互に連携するビルディングブロック** [Michael Gerstenhaber][42:02:00]
    - APIの構成可能性について強調したい点の1つは、これらがAPIの構成可能性であるということです。これらは、個別に機能するだけでなく、連携して機能するビルディングブロックです。ユニークな問題を解決するのに役立ち、画一的な形に強制することはできません。 [Michael Gerstenhaber][42:03:00]
- **Claudeをアーキテクト兼ゼネコンとして活用** [Michael Gerstenhaber][42:12:00]
    - Claudeをエージェントのアーキテクト兼ゼネコンと考えてください。 [Michael Gerstenhaber][42:13:00]
        - **事前に定義されたシーケンスを実行したり、コンポーネントをランダムに積み重ねたりするのではなく、必要な材料、どのような順序で、そしてそれらがどのように組み合わさって個々の要素よりもはるかに強力なものを作成するかをインテリジェントに決定します。** [Michael Gerstenhaber][42:17:00]
        - 具体例：複雑な財務分析のためのエージェントを構築する場合、Claudeはタスクをインテリジェントに評価し、適切なツールを調整します。MCPを使用して財務データにアクセスし、統計分析のためにコード実行を起動し、リアルタイムの市場データのためにWebを検索し、正確性とコンプライアンスのためにサイテーションで洞察を根拠付け、結果に基づいて反復および改良します。ハードコーディングされたワークフローや脆弱なスクリプトはありません。インテリジェントなオーケストレーションにより、強力なエージェントを構築でき、私たちの研究がそれらを現実のものにするにつれて、新しいケイパビリティをシームレスに採用できます。 [Michael Gerstenhaber][42:33:00]

### 開発者支援と今後の展望:

![image.png](attachment:0ef91dac-3fa0-411e-884d-16971607a57a:image.png)

- **プロンプト品質向上のためのDevTools (Prompt Improver, Evaluations)** [Michael Gerstenhaber][43:12:00]
    - プロンプトの品質がAIアプリケーションの成否を左右することを私たちは理解しています。そのため、プロンプトインプルーバーや評価のような開発ツールを作成しました。新しい可観測性機能とともに、本番環境への移行とより迅速なスケーリングを支援します。 [Michael Gerstenhaber][43:14:00]
- **クックブックとガイドによるメモリ機能などの実装支援** [Michael Gerstenhaber][43:26:00]
    - 本日、私たちは既に、クックブックやガイドのようなリソースで開発者の迅速な構築を支援しており、アプリケーションにメモリのような機能を実装する方法を示しています。 [Michael Gerstenhaber][43:28:00]
- **将来的にはプログラムアクセス可能な形でプラットフォームにホスト** [Michael Gerstenhaber][43:35:00]
    - 将来的には、これらをプログラムアクセスに適応させ、プラットフォーム上で直接ホストすることで、本番環境で自身で調査し記憶できる、さらに強力なエージェントを構築できるようになります。 [Michael Gerstenhaber][43:36:00]
- **目標：より良いAIをより速く提供する支援** [Michael Gerstenhaber][43:47:00]
    - 私たちが構築したすべては、1つの目標、つまり、より良いAIをより速く提供できるよう支援することに集約されます。 [Michael Gerstenhaber][43:49:00]

### Mario Rodriguez氏 (GitHub) の登壇紹介:

- **GitHubとの連携による可能性の提示** [Michael Gerstenhaber][44:04:00]
    - Anthropicプラットフォームは単なるツールではなく、業界をリードするエージェントを構築するための道筋です。 [Michael Gerstenhaber][43:54:00]
    - これが実際にどのように見えるかを示すために、GitHubのMario Rodriguezを歓迎する特権を得ました。 [Michael Gerstenhaber][44:06:00]

## [**GitHubとAnthropicの連携**]

### Mario Rodriguez氏 (GitHub) による発表:

![image.png](attachment:77396a74-8ccc-4650-b7b8-8858cdf38bc6:image.png)

- **歓迎の挨拶とAnthropicとのパートナーシップ深化への期待** [Mario Rodriguez][44:19:00]
    - Michaelさん、ありがとうございます。皆さん、こんにちは。本日、皆さんとご一緒できて光栄です。 [Mario Rodriguez][44:17:00]
    - 私はGitHubのMario Rodriguezです。このエネルギーとイノベーションの一部となれること、そしてAnthropicとのパートナーシップを深め、この素晴らしいチームについてもっと共有できることに、GitHub一同、非常に興奮しています。 [Mario Rodriguez][44:21:00]
- **GitHubの2つのコアビリーフ：開発者への選択肢提供と最高の開発者体験提供** [Mario Rodriguez][44:36:00]
    - GitHubが行うすべてのことは、2つの核となる信念に根ざしていますよね？ [Mario Rodriguez][44:36:00]
    - 1つ目は、開発者に選択肢を与えること。2つ目は、最高の開発者体験を提供することです。 [Mario Rodriguez][44:39:00]
- **昨年のGitHub Universeでの提携発表の振り返り (Claude Sonnet 3.5サポート)** [Mario Rodriguez][44:46:00]
    - 昨年のGitHub Universeで、私たちはAnthropicとの関係を開始しました。VS CodeとGitHub.comおよびモバイルアプリでの会話体験全体でClaude Sonnet 3.5をサポートすることを発表しました。ほんの数例を挙げると。 [Mario Rodriguez][44:47:00]
    - これを行ったのは、Anthropicと基本的な信念を共有しているからです。AIは強力な力となり、開発者にとって力強い増強となり、彼らの能力を拡張し、置き換えるのではなく、彼らが最も得意とすること、つまり想像力と創造性に集中できるようにするためです。ソフトウェア開発者であることの一部は、魔法使いであることです。 [Mario Rodriguez][44:59:00]
- **GitHub CopilotがClaude Sonnet 4とOpus 4をサポート開始 (本日より)** [Mario Rodriguez][45:34:00]
    - それ以来、私たちはパートナーシップとエクスペリエンスをVS Code、[GitHub.com](http://github.com/)、そしてモバイルアプリ全体で拡大してきました。ほんの数例を挙げると。 [Mario Rodriguez][45:22:00]
    - そして本日、**GitHub CopilotがClaude Sonnet 4とOpus 4をサポートすることを発表できることを嬉しく思います。これらは現在利用可能です。**Darioが発表した瞬間にトリガーを引きました。そして、これらのサービスのすべてです。 [Mario Rodriguez][45:36:00]
        - これがシームレスな出荷というものです。言うのは簡単ですが、実行するのは本当に難しいです。 [Mario Rodriguez][45:52:00]

### エージェントモードとAIの役割進化:

![image.png](attachment:61857e35-2109-4dab-8d96-3f691f5eacd4:image.png)

- **VS Codeにおけるエージェントモード：自律的なペアプログラマー** [Mario Rodriguez][46:10:00]
    - 皆さんがご存知のように、コードの未来はエージェント的です。 [Mario Rodriguez][46:07:00]
    - VS Codeのエージェントモードは、自然言語コマンドに基づいて複数のステップのコーディングタスクを実行できる、自律的なペアプログラマーです。 [Mario Rodriguez][46:12:00]
- **Claudeの知性が開発者の複雑なコードベース理解と迅速な製品化を支援** [Mario Rodriguez][46:21:00]
    - Claudeの知性がエディタ内で直接利用できることで、開発者が複雑なコードベースを理解し、より迅速にコードを本番環境に移行させ、生産性を向上させるのに本当に役立つことを直接見てきました。これらすべてを、既に知っていて愛用し信頼している環境から離れることなく行えます。 [Mario Rodriguez][46:23:00]
- **未来はマルチスレッド：現在のエディタは待合室のようなもの** [Mario Rodriguez][46:44:00]
    - しかし、それだけでも、私の意見では、未来はシングルスレッドではありません。私の意見では、未来はマルチスレッドです。 [Mario Rodriguez][46:40:00]
    - これを考えると、エディタにいると、それは待合室になります。より速く進んでいますが、それでも待合室です。 [Mario Rodriguez][46:48:00]
- **月曜日に発表されたGitHub Copilotのコーディングエージェント** [Mario Rodriguez][46:55:00]
    - そのため、月曜日に、私たちはGitHubのCopilotコーディングエージェントを発表することで、さらに一歩進めました。 [Mario Rodriguez][46:57:00]
        - **私たちのコーディングエージェントは、Claude Sonnetを搭載しています。** [Mario Rodriguez][47:15:00]
        - これを選んだ理由は、私にとって非常に明確でした。それは、3つの主要な強みを示しているからです。**強力なソフトウェアエンジニアリングとコーディングの知識、強力な問題解決能力、そしてこれが非常に重要ですが、優れた指示追従能力です。** [Mario Rodriguez][47:25:00]
        - 特にツールとMCPについて考える場合です。 [Mario Rodriguez][47:44:00]
        - したがって、GitHubのシナリオでエージェント的なコーディングのためにこれらのことを行う場合、Anthropic APIから得られる**プロンプトキャッシュのサポートは、よりコスト効率の高い方法でこれらのエクスペリエンスを構築することを可能にします。** すべてのトークンが重要であり、すべてのトークンが価格面でも重要です。したがって、これらを節約すればするほど、より良いエクスペリエンスを提供できます。 [Mario Rodriguez][47:58:00]

### MCPの採用と将来展望:

![image.png](attachment:6ed30dd5-9e17-4f4c-bf68-b7126e87a360:image.png)

- **Anthropicと協力し、MCPを公式に採用・スケール** [Mario Rodriguez][48:56:00]
    - しかし、私たちの協力はこれよりも深いです。 [Mario Rodriguez][48:50:00]
    - 単にモデルを直接統合するだけではありません。私たちはAnthropicと緊密に協力して、MCPを公式に採用し、スケールさせてきました。 [Mario Rodriguez][48:57:00]
        - 私たちは、**知性（モデル）と知識（ツールやデータなど）を組み合わせることで、このエージェント的な未来を解き放つと信じています。** [Mario Rodriguez][49:01:00]
        - 最近、Microsoft CTOのKevin Scottは、MCPはWebのHTTPプロトコルのようなものだというアナロジーをしました。私はそれに完全に同意します。 [Mario Rodriguez][49:24:00]
        - もしあなたがまだMCPを採用していないなら、今日、この基調講演の後すぐに、それを使って遊んでみてください。それはそれほど重要です。それがこれらのインテリジェントなモデルに知識を取り込む方法です。 [Mario Rodriguez][49:32:00]
- **AIネイティブなSDLCへの変革** [Mario Rodriguez][49:43:00]
    - さて、ソフトウェア開発の新しい時代に足を踏み入れるにあたり、私たちはGitHubのプラットフォームをAIを活用したものからAIネイティブなものへと変革しています。 [Mario Rodriguez][49:44:00]
        - 私たちは、このSDLCを、その上に構築されたエージェント的なレイヤーによって強化されるものとして構想しています。それが、コーディングしている内部ループと、CI/CDのような非同期エクスペリエンスである外部ループにまたがるものです。 [Mario Rodriguez][49:59:00]
        - そして、あなたはそのすべてのステップで積極的な協力者となるでしょう。Copilotと呼ぶ理由は、人間が中心だからです。そして、エージェントがあなたを助けてくれます。 [Mario Rodriguez][50:11:00]
- **Claude Codeと拡張可能なClaude Code SDKをGitHubのエージェントプラットフォームに直接統合** [Mario Rodriguez][50:23:00]
    - そのため、本日、私たちは**Claude Codeと拡張可能なClaude Code SDKをGitHubのエージェントプラットフォームに直接統合するという新しいパートナーシップを発表します。** [Mario Rodriguez][50:25:00]
        - これにより、Claude Codeをカスタマイズしたり、GitHub内に埋め込まれた新しいサーフェスからリモートで呼び出したりする新しい可能性が開かれます。 [Mario Rodriguez][50:35:00]
        - これらすべてがGitHubプラットフォーム上で行われます。 [Mario Rodriguez][50:43:00]

### まとめ:

- **Anthropicとの協業による未来への期待** [Mario Rodriguez][50:57:00]
    - 私たちはAnthropicと共に構築し続けるもの、そして皆さんが私たちと共に構築するものを見るのを非常に楽しみにしています。 [Mario Rodriguez][50:59:00]
    - どうもありがとうございました。そして、Mike Kriegerをステージに再びお迎えください。 [Mario Rodriguez][51:20:00]

## [**最終セッションとQ&A**]

### Mike Krieger氏によるクロージング:

- **各登壇者への感謝** [Mike Krieger][51:38:00]
    - 再びこんにちは。Marioさん、Michaelさん、Katさん、ありがとうございます。 [Mike Krieger][51:37:00]
- **GitHub統合の個人的な体験談 (GitHub CodespacesでのClaude Code利用)** [Mike Krieger][51:42:00]
    - GitHubの統合は大好きです。最後にやったプロジェクトでは、「ああ、GitHub CodespacesにClaude Codeをインストールすればいいんだ」と思い、そうしたら既に構築していたリポジトリに対してClaude Codeが使えるようになりました。 [Mike Krieger][51:43:00]
    - 彼らそれぞれから話を聞き、Claudeで行われているエキサイティングな作業についてすべて聞くことができて本当に良かったです。 [Mike Krieger][51:51:00]

### Dario Amodei氏とのQ&Aセッション予告:

- **Claude 4、研究開発の方向性、開発者が期待できることについて** [Mike Krieger][51:56:00]
    - ショーを締めくくるにあたり、Claude 4、私たちの研究の方向性、そして開発者がAnthropicから次に何を期待できるかについて、もう少し深く掘り下げたいと思います。 [Mike Krieger][51:56:00]
    - それでは、1対1の会話のためにDarioをステージに再びお迎えください。Dario、おかえりなさい。 [Mike Krieger][52:03:00]

### Dario Amodei氏再登壇とQ&A開始:

![image.png](attachment:a14277ec-77e5-443c-bb6d-7274b560626b:image.png)

- **Claude 4モデルのリリースについて、最もエキサイティングな点** [Mike Krieger][52:20:00]
    - これは素晴らしい。まるで私たちの1対1の会話を全聴衆の前で行っているようだ。素晴らしい。 [Mike Krieger][52:14:00]
    - さて、Claude 4、Claude Sonnet 4、Claude Opus 4がリリースされました。これらのClaude 4モデルについて、何が一番あなたを興奮させますか？そして、それは今後12ヶ月で何が可能になるかについてのあなたの考えをどのように変えますか？ [Mike Krieger][52:20:00]
        - (Dario) ええ、つまり、抽象的には、私が最も興奮しているのは、新しいモデルのクラスが登場するたびに、それでできることが増えるということです。だから、私たちはClaude 4の後にもモデルをリリースする予定です。おそらくClaude 4.1のようなものがいつか登場するでしょう。ちょうどSonnet 3.7で行ったように。そして、私たちはまだ、新しいモデル世代でできることの始まりに過ぎないと思います。 [Dario Amodei][52:32:00]
        - (Dario) タスクの観点からは、自律性が既に進んでいるよりもはるかに進むと思います。つまり、モデルを自由に設定し、長期間何かをさせる能力です。私たちはまだその始まりに過ぎないと思います。 [Dario Amodei][53:00:00]
        - (Dario) サイバーセキュリティのタスクについてますます興奮しています。つまり、サイバーセキュリティを、コーディングタスクのサブセットと考えることができますが、それらはより高度なコーディングタスクになる傾向があります。そして、私たちはついにその閾値に達したのかもしれません。 [Dario Amodei][53:25:00]
        - (Dario) そして、元生物学者として、私はモデルを生物医学的な、そしてある種の、ある種詳細な科学的研究作業に使用することに常に興奮しています。Opus、特にOpusは、特に強力になると思います。 [Dario Amodei][53:36:00]
- **「Machines of Loving Grace」とClaude 4の関係性** [Mike Krieger][53:52:00]

    ![image.png](attachment:c58a8508-9d7a-4a14-8f4d-146ba72c1b23:image.png)

    - それは「Machines of Loving Grace」と本当につながっていると思います。では、Claude 4は、その軌道全体にどのように適合しますか？人々は、機械が優雅に愛することについてのエッセイとして考えていますが、私はそれを今後数年間の製品ロードマップだと考えています。Claude 4はそのジャーニーにどのように適合しますか？ [Mike Krieger][53:53:00]
        - (Dario) ええ、それは一種の、私が書いた製品ロードマップで、それを実際に手に入れる方法を知らなかったものです。そして、ある種、「よし、みんな、これが君たちの仕事だ、これが君たちの仕事だ」と言ったのです。 [Dario Amodei][54:05:00]
        - (Dario) ええ、ええ、あの、ええと、つまり、10年前、多くの人々は神経科学がAIのやり方について教えてくれると考えていました。そして確かに、この分野には元神経科学者が何人かいます。私だけではありません。他のラボリーダーもいますし、その背景を持つ人もいます。 [Dario Amodei][54:07:00]
        - (Dario) しかし、そして、高レベルではいくつかのインスピレーションはありますが、私は「ああ、これは私たちが海馬について知っているこのことで、これを、これを、これらのモデルを作るために使うことができる」とは言えません。それはほとんどすべてゼロから作られてきました。 [Dario Amodei][54:07:00]
        - (Dario) しかし興味深いことに、物事は他の方向に進んでいます。つまり、解釈可能性を使用してモデルの内部を見ることができ、もちろん、それらは人間の脳とまったく同じように作られているわけではありませんが、ある種の、ある種の表面的なレベルでは、多くの違いがあります。 [Dario Amodei][54:15:00]
        - (Dario) 私たちがモデルの内部で見つけた多くの概念的なパターンは、時には神経科学の研究で再現されます。視覚における高低周波検出器のようなものがありました。それは解釈可能性を通じて、Chris Olahのチームの1人によって発見され、その後数年後、神経科学者が実際に動物の脳でそれを再現しました。 [Dario Amodei][54:33:00]
        - (Dario) 例えば、視覚モデルが、色が対応する1つのパスと、明るさや物体の境界に対応する別のパスを分離するという考え方。これらは世界における自然な区別であるように思われ、発見されるのを待っています。そして、人工的なものであれ生物学的なものであれ、何らかの抽象的な学習システムがあれば、同じものを見つけることになります。だから、それは非常に興味深いです。 [Dario Amodei][54:43:00]
- **5-10年後のタイムホライズン：1人の人間従業員による10億ドル企業はいつ登場するか** [Mike Krieger][55:01:00]

    ![image.png](attachment:4e476957-b1b4-4173-aa7f-6ed427e2e67f:image.png)

    - そのサーキットの論文が神経科学の研究にどのように影響を与えるか、本当に興味があります。 [Mike Krieger][54:58:00]
    - 5年から10年の時間軸に移行しましょう。AIでは不可能かもしれませんが、楽観的に楽観的にいきましょう。おそらく現実では1年でしょう。1人の人間従業員を持つ最初の10億ドル規模の企業はいつ登場すると思いますか？ [Mike Krieger][55:03:00]
        - (Dario) **2026年。** [Dario Amodei][55:46:00]
- **Claudeで構築する開発者へのアドバイス** [Mike Krieger][55:53:00]

    ![image.png](attachment:7c26f6ec-6221-406f-af3b-466436cb0eab:image.png)

    - よし、よし、私はそれに絶対に賭けます。ええ。 [Mike Krieger][55:48:00]
    - Claudeで構築している人々、特に今後1年間、何かアドバイスはありますか？彼らはどのように考え、どのように構築すべきでしょうか？ [Mike Krieger][55:54:00]
        - (Dario) ええ、つまり、たくさんの非常に具体的なことを言うことができると思いますが、私が感じるのは、この相対論的な時間希釈、この物事の加速のために、ほとんどすべてのアドバイスは、1つの文、あるいは2つの言葉に打ち消されるということです。それは、**野心的であれ (Be ambitious)** です。 [Dario Amodei][56:01:00]
        - (Dario) つまり、あなたが不可能だと思うより大きなものを構築してください。そして、それがまだ機能しなくても、次のモデルが数ヶ月後、おそらく2ヶ月後、そして1ヶ月後に出てくるでしょう。そして、もし私が今年ここに来たら、おそらく「ああ、今日何も構築しないでください。私たちは今夜何かをリリースしています。あなたは今夜これで構築したくないでしょう」というようなアドバイスをするかもしれません。 [Dario Amodei][56:22:00]
        - (Dario) 壁に頭をぶつけるのは、実際には時には役立つことがあります。なぜなら、他のすべてのピースを所定の位置に置くからです。そして、そしてモデルが機能するとき、あなたは何かを構築したことになります。それはそれが必要以上に堅牢なものです。そして、それは一種の良い特性になる可能性があります。 [Dario Amodei][57:04:00]
        - (Dario) だから、だから、ええと、私が冗談めかして「ああ、次のモデルを待つだけでいい」と言うのと同じくらい、実際には、壁に頭をぶつけるのは、それがほぼ可能なことである限り、それが3年先のことではない限り、実際には生産的である可能性があります。 [Dario Amodei][57:21:00]

### クロージングと謝辞:

![image.png](attachment:f130fc14-c9d7-4e72-a17f-b58baf835b46:image.png)

- **Dario Amodeiへの感謝** [Mike Krieger][58:02:00]
    - それは resonates します。以前の比喩を知りませんでしたが、絶対に resonates します。 [Mike Krieger][58:00:00]
    - それでは、この辺で締めくくりたいと思います。残念ながら、あと40分は話せそうですが。まず、本日私たちと時間を過ごしてくれたDarioに感謝したいと思います。ありがとう、Dario。 [Mike Krieger][58:02:00]
- **来場者とオンライン視聴者への感謝** [Mike Krieger][58:12:00]
    - また、本日ご来場いただいた皆様、そしてライブストリームでご覧いただいた皆様にも感謝申し上げます。 [Mike Krieger][58:12:00]
- **特別ギフトの発表：Max 20Xプラン3ヶ月無料アクセス** [Mike Krieger][58:16:00]
    - しかし、閉会する前に、一つだけ忘れていました。 [Mike Krieger][58:17:00]
    - 本日Code with Claudeにご参加いただいた皆様への特別な感謝として、**皆様それぞれにMax 20X、私たちの最高ティアプランへの3ヶ月間の無料アクセス**を提供することを発表できることを嬉しく思います。それについてはメールをご確認ください。 [Mike Krieger][58:19:00]
        - 私は特にClaude CodeでMaxを使うのが好きなので、皆さんもそうできるでしょう。 [Mike Krieger][58:30:00]
- **最終的な謝辞とカンファレンスの終了** [Mike Krieger][58:41:00]
    - 皆さんが何を構築するかを見るのが待ちきれません。残りの一日をさまざまなセッションでお楽しみください。そして、再びCode with Claudeへようこそ。ご参加いただきありがとうございました。 [Mike Krieger][58:42:00]
    - 来てくれてありがとう、みんな。 [Mike Krieger][58:48:00]
