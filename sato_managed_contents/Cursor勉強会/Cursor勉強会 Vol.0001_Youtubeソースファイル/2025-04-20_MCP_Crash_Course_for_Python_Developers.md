# MCP Crash Course for Python Developers

**チャンネル:** Dave Ebbelaar
**公開日:** 2025-04-19
**URL:** https://www.youtube.com/watch?v=5xqFjh56AwM

## 説明

Learn AI Engineering from first principles: https://academy.datalumina.com/genai-accelerator
Want to start freelancing? Let me help: https://www.datalumina.com/data-freelancer

💼 Need help with a project? 
Work with me: https://solutions.datalumina.com/

🔗 GitHub Repository
https://github.com/daveebbelaar/ai-cookbook/tree/main/mcp/crash-course

🛠️ My VS Code / Cursor Setup
https://youtu.be/mpk4Q5feWaw

⏱️ Timestamps
00:00 Introduction
2:06 Understanding MCP Basics
8:03 Technical Aspects of MCP
12:29 Setting Up Your MCP Server
16:56 Simple Server Setup
25:48 Connecting Your Python Application
33:39 Integrating LLMs with MCP
49:29 MCP vs Function Calling
51:07 Running MCP Servers with Docker
54:19 Lifecycle Management in MCP
56:29 Conclusion and Next Steps

📌 Description
In this video, I go over the Model Context Protocol (MCP) for Python developers, taking you from basic concepts to building functional AI systems with MCP servers. I share my hands-on approach to connecting Python applications with different data sources, complete with practical code examples from my GitHub repository.

👋🏻 About Me
Hi! I'm Dave, AI Engineer and founder of Datalumina®. On this channel, I share practical tutorials that teach developers how to build production-ready AI systems that actually work in the real world. Beyond these tutorials, I also help people start successful freelancing careers. Check out the links above to learn more!

## 字幕

[00:00 - 00:03]
Python 開発者であり、

[00:01 - 00:05]
LLM を使用して開発を行っており、

[00:03 - 00:07]
モデル コンテキスト プロトコルである MCP を統合する方法を学習したい場合は、

[00:05 - 00:09]
このビデオが最適です。

[00:14 - 00:17]
Genai 開発者として MCP で何ができるのかを実際に学べるように私がまとめた短期集中講座全体を説明していきます。 さて、このビデオでは、

[00:17 - 00:21]
単純なサーバーを構築して

[00:19 - 00:22]
それを Claw Desktop に統合する方法だけを紹介するつもりはありません。

[00:21 - 00:24]
まさにそれについて解説したチュートリアルをたくさん見てきました

[00:22 - 00:26]
。 これは本当に開発者向けの最初の

[00:24 - 00:28]
チュートリアルです。 ここでは、Python SDK を使用して

[00:26 - 00:30]
独自の MCP サーバーをセットアップする方法と、

[00:30 - 00:33]
それらのサーバーを独自の

[00:32 - 00:35]
Python アプリケーションとバックエンドに統合して、

[00:35 - 00:39]
その周りに AI システムとエージェントを構築できるようにする方法を学習します。 さて、このチャンネルを初めてご覧になる方のために

[00:37 - 00:40]
、私の名前は Dave Ablar です。 私は

[00:39 - 00:42]
Data Lumininaの創設者です。 私たちは過去 6 年間にわたり、クライアント向けに

[00:40 - 00:43]
カスタム データと AI ソリューションを構築してきました

[00:43 - 00:47]
。 つまり、Chat GBT を始める前から、私は

[00:47 - 00:50]
人工知能の学士号と修士号を取得していました。

[00:49 - 00:52]
これらのビデオで私が目指すのは、常に、

[00:50 - 00:54]
雑音を排除し、本番環境に対応した AI システムとエージェントを構築するために

[00:52 - 00:57]
実際に使用できるものに集中できるように支援することです

[00:57 - 01:01]
。 それでは始めましょう。よし。

[00:59 - 01:02]
このチュートリアルでは、

[01:01 - 01:03]
この GitHub

[01:02 - 01:05]
リポジトリについて説明します。 リンクは

[01:03 - 01:07]
説明にあります。 これは、

[01:10 - 01:14]
このチャンネルで私が作成するすべてのビデオのチュートリアルをすべてまとめた AI クックブックの一部である MCP クラッシュ コースです

[01:11 - 01:16]
。 それでは、このビデオで説明する内容を簡単に説明しましょう

[01:14 - 01:18]
。 まず

[01:16 - 01:20]
最初に理論から始めましょう。

[01:18 - 01:21]
そこで、このビデオの下にタイムスタンプの概要を説明します

[01:20 - 01:23]
。 したがって、

[01:21 - 01:25]
すぐにコードを読みたい場合は、自由に

[01:23 - 01:27]
そちらに進んでください。ただし、

[01:25 - 01:29]
MC MCP を初めて使用する場合は、そうすることはお勧めしません。

[01:27 - 01:31]
最初に

[01:29 - 01:33]
それが何であるかを理解する必要があるためです。そうしないと、

[01:31 - 01:35]
多くのことが意味をなさなくなります。 それでは、

[01:33 - 01:37]
7 つの章を順に説明していきます

[01:35 - 01:39]
。 第 1 章と第 2 章では、

[01:37 - 01:40]
MCP とは何かを理解し

[01:39 - 01:42]
、その後サーバーをセットアップする方法について説明します

[01:40 - 01:44]
。 私たちはオープンな AAI 統合を行っています。

[01:42 - 01:46]
MCP と関数呼び出しを比較してみましょう

[01:44 - 01:48]
。

[01:46 - 01:49]
サーバーをセットアップして Docker で実行し、

[01:48 - 01:51]
実際にこれを

[01:49 - 01:52]
アプリケーションに組み込む方法を説明します。最後に、アプリケーションのすべての接続を適切に処理するための

[01:51 - 01:54]
ライフサイクル管理について説明します

[01:54 - 01:57]
。

[01:56 - 01:59]
一緒に進めたい場合は、この

[01:57 - 02:01]
リポジトリのクローンを作成し、開発環境をセットアップして、

[01:59 - 02:03]
インストールの要件は

[02:01 - 02:04]
簡単なはずです。その後、ここで

[02:04 - 02:08]
説明する基礎となるコード例はすべて、ここにあるフォルダー内にあります

[02:06 - 02:09]
。 さて、それでは準備が整ったので、

[02:08 - 02:13]
パート 1 の紹介と背景に直接進みましょう

[02:09 - 02:14]
。  MCP

[02:13 - 02:16]
を初めて知る方のために説明すると

[02:14 - 02:18]
、MCP はモデル コンテキスト

[02:16 - 02:20]
プロトコルの略です。 そして、ここ数週間、数

[02:18 - 02:23]
か月にわたって、かなりの人気を集めてきました

[02:20 - 02:26]
が、すでに

[02:23 - 02:28]
2024年11月25日から発売されています。これは、

[02:26 - 02:30]
Entropicによって開発されました。 そして、このブログ投稿では、

[02:35 - 02:38]
コンテンツ リポジトリ、ビジネス ツール、

[02:36 - 02:39]
開発環境など、データが存在するシステムに AI アシスタンスを接続するための新しい標準として MCP を紹介しました。 そして、

[02:38 - 02:41]
11月にこのブログ記事を初めて読んだとき、それが正確に何なのかを理解するのが

[02:39 - 02:43]
かなり難しかったことを覚えています

[02:41 - 02:45]
。

[02:43 - 02:46]
これは新しいモデルですか？ これらは

[02:45 - 02:49]
何か新しい機能なのでしょうか? これはクラウドの一部ですか

[02:46 - 02:50]
?  OpenAI と統合できますか? 開発者

[02:49 - 02:52]
として私が抱いたこれらの疑問はすべて、

[02:54 - 02:56]
現在取り組んでいるクライアント プロジェクトにこれをどのように文字通り反映できるかを知るためのものでした。

[02:56 - 03:00]
AI の世界では、約

[02:58 - 03:02]
2 週間ごとに大きな新機能やアップデートが登場するため、私は

[03:00 - 03:03]
このような新しいものに飛び込むことに常に非常に躊躇しています。 したがって、私は

[03:02 - 03:05]
すべての

[03:03 - 03:07]
魅力的なオブジェクトを追いかけることを避け、プロジェクトの

[03:05 - 03:09]
構造とアーキテクチャを約 1 か

[03:07 - 03:11]
月ごとに変更したいと考えていますが、私にとって MCP はそのような魅力的なオブジェクトの 1 つでした

[03:09 - 03:12]
。 それでしばらく無視していました

[03:11 - 03:14]
。 しかしその後にこんなことが起こったのです。 これは、Google におけるキーワード MCP への関心の推移を

[03:12 - 03:16]
確認できる Google トレンドです

[03:16 - 03:21]
。 そして、

[03:18 - 03:23]
2025 年 3 月初旬からこれが

[03:21 - 03:25]
急激に増加し、MCP があらゆる場所で見られるようになったことがわかります

[03:23 - 03:27]
。  YouTubeで見ました。 私は

[03:25 - 03:29]
ブログ投稿のXと

[03:27 - 03:30]
コミュニティデータフリーランサーでそれを見ました。 それが

[03:29 - 03:32]
どこにでも現れ始め、私はもはや

[03:30 - 03:34]
これを無視することができなくなりました。 では、2 月に何が起こり、

[03:34 - 03:38]
MCP への関心が突然大きく高まったのでしょうか。その

[03:36 - 03:40]
ためには、まず

[03:38 - 03:41]
MCP がどのようなものであるかを大まかに理解する必要があります。 したがって、

[03:40 - 03:43]
簡単に Google 検索を行えば、これが

[03:41 - 03:45]
実際に何であるかを説明しようとしている図がたくさん見つかります

[03:43 - 03:47]
。 そこで私は dcope.com でこれを見つけました。

[03:45 - 03:49]
これは

[03:47 - 03:51]
私たち全員が

[03:49 - 03:53]
同じ認識を持ち、

[03:51 - 03:55]
エントロピーの定義を思い出すための非常に良い出発点だと思います。  MCP は、データが存在するシステムに

[03:53 - 03:57]
AI アシスタンスを接続するための新しい標準であり、

[03:57 - 04:02]
この画像はそれを完璧に示しています

[03:59 - 04:04]
。 左側は

[04:02 - 04:06]
MCP 前の状況です。

[04:04 - 04:08]
これが、私たち開発者が

[04:06 - 04:11]
2 年半、いや 3

[04:08 - 04:13]
年も前から行ってきたことです。 そこで私たちは LLM を中心にアプリケーションを構築し、

[04:15 - 04:20]
Slack、Google Drive、GitHub などの外部サーフェスにアプリを接続するときに、

[04:17 - 04:22]
独自の API レイヤーを作成します。このレイヤーには、たとえば Slack の場合、

[04:22 - 04:27]
メッセージを送信する関数があり、それを使用して

[04:24 - 04:28]
Slack と通信できます。 そして、

[04:27 - 04:31]
これを LLM と統合する場合、

[04:28 - 04:32]
カスタム ロジックを作成し、

[04:31 - 04:35]
アプリケーションのある時点で

[04:32 - 04:38]
すべてのデータを取得したらそれを送信するか、

[04:35 - 04:40]
LLM にそのツールを動的に使用させたい場合には、

[04:38 - 04:42]
fun 関数呼び出しや、

[04:40 - 04:45]
たとえばツール定義を使用して

[04:42 - 04:47]
それを LLM に提供することでそれを行うことができます。

[04:45 - 04:50]
これが私たちがすでにかなり長い間行ってきたことです

[04:47 - 04:52]
。 そして、これが

[04:50 - 04:55]
まさに私が

[04:52 - 04:57]
MCP に取り組むことを最初に非常に躊躇した重要な理由です。なぜなら、

[04:55 - 05:00]
後でわかるように、MCP は基本的に、

[05:00 - 05:04]
大規模言語モデルや、過去数年間

[05:02 - 05:08]
にできなかった AI システムの構築に新しい機能を導入しないからです

[05:04 - 05:09]
。 それはむしろ、

[05:08 - 05:11]
物事を行う新しい方法にすぎません。

[05:09 - 05:13]
まさにこれが右側に見えているもので、

[05:11 - 05:15]
中央に

[05:13 - 05:19]
このレイヤーがあります。このプロトコルは、

[05:19 - 05:26]
LLM で利用できるようにする API を統合するものです。

[05:22 - 05:27]
この利点は、

[05:26 - 05:29]
世界中の開発者がそれぞれ

[05:29 - 05:34]
Slack と

[05:31 - 05:36]
Google Drive やあらゆる種類のシステムを統合する方法について独自の定義を作成するのではなく、

[05:39 - 05:43]
スキーマや関数、さらにはドキュメント

[05:41 - 05:46]
や引数を指定する方法を正確に定義した標準プロトコルが存在することです。

[05:43 - 05:49]
したがって、これを MCP レイヤーに渡すと、

[05:46 - 05:51]
AI アプリケーションは

[05:49 - 05:53]
統合 API を介してシームレスに統合できるようになります。

[05:51 - 05:55]
これで、MCP は

[05:53 - 05:58]
基本的に

[05:55 - 06:00]
LLM の操作に新しい機能を追加するもので

[05:58 - 06:02]
はなく、LLM でツールとリソースを利用できるようにするための標準化された方法にすぎないことが理解できました

[06:02 - 06:07]
。  2月に何が起こったのかが見えてきます

[06:05 - 06:09]
。  MCP は技術的に

[06:07 - 06:11]
非常に堅牢かつ軽量なプロトコルであり、

[06:09 - 06:14]
多くの企業や開発者が

[06:11 - 06:16]
これを認識し始めています。時間の経過とともに、

[06:14 - 06:18]
MCP を使用する人が増えれば

[06:16 - 06:21]
標準化が進み、たとえば

[06:23 - 06:27]
AI

[06:25 - 06:28]
サービスを Slack や GitHub、Google

[06:27 - 06:30]
Drive などに接続したいときに毎回車輪の再発明をする必要がなくなり、開発者の作業が大幅に楽になります。この傾向は

[06:28 - 06:32]
広がり始め、現在では

[06:32 - 06:38]
大手テクノロジー企業によって公式にサポートされているサーファーが数百存在し、MCP サーバー

[06:35 - 06:41]
経由で API を公開するさまざまなツールやアプリが存在するため、

[06:41 - 06:45]
開発者が

[06:43 - 06:47]
AI システム

[06:45 - 06:48]
やエージェントを、たとえばここに表示されているツールと統合することが非常に簡単になりました

[06:47 - 06:50]
。 そして、この誇大宣伝は

[06:48 - 06:52]
続き、AAI

[06:50 - 06:55]
Entropic の最大の競合相手が

[06:52 - 06:57]
エージェント SDK で MCP をサポートするようになり、結果として

[06:55 - 06:59]
MCP が実質的に勝利しました。これは、

[06:59 - 07:03]
Leighton Space によるこちらの優れたブログ記事で概説されていますが、現在

[07:01 - 07:05]
ソーシャル メディア上ではこの誇大宣伝をめぐるあらゆる批判にもかかわらずです

[07:03 - 07:07]
。 ここでは、

[07:05 - 07:09]
MCP を使用して車を

[07:07 - 07:12]
遠隔操作し、食料品店に行ってソーセージパンを購入する人の例を紹介します

[07:09 - 07:13]
。  LLM は飛行機の Wi-Fi で MCP を使用して運転しました

[07:12 - 07:15]
。 つまり、MCP を本当に必要としない LLM 関連のさまざまな問題を解決するために、

[07:13 - 07:17]
誰もが MCP を MCP のために使用しているだけである、という説明になります

[07:17 - 07:21]
。 しかし、

[07:20 - 07:23]
それにもかかわらず、

[07:21 - 07:25]
MCP が現在行っている最大のことは、

[07:23 - 07:28]
あらゆる

[07:25 - 07:30]
新しいプロトコルの力がその適応、つまり

[07:28 - 07:31]
エコシステムから生まれるという適応率です。 また、LLM を使用してアプリの構築を簡素化する

[07:31 - 07:35]
他の一般的な AI フレームワークや

[07:33 - 07:37]
ライブラリの GitHub スター履歴を見ると、

[07:37 - 07:41]
MCP が現在急激な伸びを見せていることがはっきりとわかります。これは、

[07:41 - 07:44]
これまでに見てきたものと比べれば何でもありません。 そして、

[07:42 - 07:45]
おそらく今後数か月以内にそれらすべてを追い抜くことになるでしょう

[07:44 - 07:47]
。 さて、これで

[07:45 - 07:48]
MCP が何をするのかを大まかに理解できました。

[07:47 - 07:50]
また、

[07:48 - 07:52]
将来のエンジニアが HTTP について

[07:50 - 07:54]
学んだのと同じように学ぶかもしれない歴史についても少し説明しました

[07:52 - 07:56]
。 しかし、いずれにしても、あなたは今、

[07:54 - 07:58]
「わかりました、デイブ、私はそれをある程度理解しました

[07:56 - 08:00]
、しかし、開発者として私たちは

[07:58 - 08:01]
それで何ができるのでしょうか?」と疑問に思っているかもしれません。 それでは、今すぐその点について説明しましょう

[08:00 - 08:03]
。 さて、パート

[08:01 - 08:05]
2 では、MCP を技術的なレベルで理解するところから始めましょう

[08:03 - 08:06]
。 そしてもしあなたが「おい、もうしゃべるのはやめて、

[08:05 - 08:08]
ヤギを見せてくれ」と言うなら、 繰り返しになりますが、

[08:06 - 08:10]
次のセクションに進んでいただいても結構です。

[08:08 - 08:12]
これは最後の理論的な部分です。

[08:10 - 08:14]
これについては簡単に説明しますが、MCP を効果的に

[08:14 - 08:18]
使用するには、MCP について理解しておく必要がある基本的な事項がいくつかあります

[08:16 - 08:20]
。 したがって、これから説明する

[08:18 - 08:21]
いくつかの一般的な用語を理解する必要があります。

[08:20 - 08:23]
これ

[08:21 - 08:24]
については、

[08:23 - 08:26]
公式の MCP ドキュメントからコピーしたこの画像を使用して説明します

[08:24 - 08:28]
。 これらの用語は、

[08:26 - 08:29]
ドキュメント全体、また

[08:29 - 08:35]
私がここに持っているビデオ チュートリアル全体で見つかります。 それでは

[08:32 - 08:38]
ホストから始めましょう。 ホストは、

[08:35 - 08:40]
Claw Desktop IDEES などのプログラム、あるいは

[08:40 - 08:44]
開発者にとってより興味深い Python アプリケーションなどですが、

[08:44 - 08:48]
MCP プロトコルを介してデータにアクセスするプログラムです。そして、MCP クライアントがあります。MCP

[08:46 - 08:50]
クライアントは、サーバーとの

[08:48 - 08:52]
1 対 1 の接続を維持するプロトコル クライアントです。

[08:50 - 08:54]
これが

[08:52 - 08:57]
次の MCP サーバーの部分につながります。

[08:54 - 08:59]
したがって、MCP サーバーは、

[08:59 - 09:02]
標準化されたモデル コンテキスト

[09:01 - 09:05]
プロトコルを通じてそれぞれ特定の機能を公開する軽量プログラムです。 公開できるのは

[09:02 - 09:06]
ツール、リソース、プロンプトです。 それについては後ほど詳しく説明します

[09:05 - 09:08]
。 したがって、これら 3 つのコンポーネントが

[09:08 - 09:13]
MCP のコア アーキテクチャを構成します。 ただし、MCP を使用すると、API などを使用して、インターネット経由で

[09:11 - 09:16]
ローカル データ ソースやリモート サービスに接続することもできます

[09:16 - 09:20]
。

[09:18 - 09:22]
これまでのところこのビデオが気に入っていただけたら、ぜひ「いいね！」を押して

[09:20 - 09:23]
チャンネル登録も検討してください。また、

[09:22 - 09:25]
チームメンバーと共有して、

[09:26 - 09:30]
作業中のプロジェクトに MCP を効果的に統合する方法をチームメンバーも学べるようにしてください。

[09:30 - 09:34]
それをもっとよく理解するために、次の図を見てみましょう。

[09:32 - 09:36]
ここの一番左には、MCP クライアントを備えたホストがあります

[09:34 - 09:38]
。 繰り返しになりますが、これは、

[09:36 - 09:40]
Claw デスクトップ IDE ツール

[09:38 - 09:42]
やカスタム Python バックエンド、

[09:40 - 09:44]
アプリケーションなど、あらゆるものになります。 そして、ここの中間層には

[09:42 - 09:46]
サーバーがあります。 ここでは、

[09:46 - 09:51]
それぞれ異なる目的を持つサーバー A、B、C があることがわかります。 これらには

[09:49 - 09:52]
さまざまなツールと定義があり、

[09:51 - 09:55]
使用できるさまざまなユーティリティがあります

[09:52 - 09:58]
。 これで、ホストは

[09:55 - 10:00]
MCP プロトコル経由の MCP クライアントを介して

[09:58 - 10:02]
そのサーバーに接続し、対話できるようになります

[10:00 - 10:04]
。 このように通信が

[10:02 - 10:06]
設定され、ホスト アプリケーション内では

[10:04 - 10:09]
基本的に

[10:06 - 10:10]
MCP サーバーからデータを取得できます。 そして今では、

[10:10 - 10:14]
サーバーをセットアップして

[10:12 - 10:16]
クラウド デスクトップと統合する方法を紹介するチュートリアルがオンラインで多数あります。

[10:14 - 10:18]
私がオンラインで見つけた初期のチュートリアルは、すべて

[10:16 - 10:20]
クラウド デスクトップに関するものでした。 そして、

[10:20 - 10:25]
開発者の観点からは、これを完全に理解することはできませんでした。

[10:23 - 10:27]
現在、本当に考慮すべきことは、

[10:31 - 10:35]
個人用 AI アシスタンスとして使用するローカル ツールに MCP を使用することと、

[10:33 - 10:37]
ユーザーが

[10:35 - 10:40]
クラウド デスクトップやカーソル、

[10:37 - 10:42]
ウィンドサーフィンなどのアプリケーションで使用すること、または開発者が

[10:40 - 10:44]
サーファーを作成し、

[10:44 - 10:47]
そのサーバーに接続するクライアント アプリケーションを独自に作成することとの間には、非常に明確な違いがあるということです。 これは本当に

[10:45 - 10:49]
重要な違いであり、

[10:47 - 10:51]
このビデオでさらに詳しく説明します。 そして、

[10:49 - 10:53]
MPC サーバー上で

[10:51 - 10:55]
アプリケーション固有のロジックを定義できるようになります。 そして、これは

[10:53 - 10:57]
何でも可能です。 しかし、このコンテキストでは、

[10:55 - 10:58]
開発者としてよりよく理解するために、

[10:57 - 11:01]
文字通りこれを任意の Python 関数として考えることができます

[10:58 - 11:03]
。 あらゆる種類の機能を入れることができます

[11:01 - 11:05]
。 結果が何であれ、

[11:03 - 11:07]
単純な計算でも、

[11:05 - 11:08]
文字列を大文字にしたり、

[11:07 - 11:10]
データベースに接続したりしても、それは

[11:08 - 11:12]
問題ではありません。 関数を作成すると、それ

[11:10 - 11:14]
が

[11:12 - 11:16]
そのサーバー上に配置するロジックであるユーティリティとなり、

[11:14 - 11:18]
ホスト

[11:16 - 11:19]
アプリケーションで使用できるようになります。 したがって、開発者として MCP を扱う場合には、

[11:19 - 11:23]
次の 3 つのことを理解する必要があります。  1 つ目は、

[11:23 - 11:27]
サーバーをどのようにセットアップするかを理解することです。 これは、このビデオで紹介する

[11:25 - 11:28]
カスタム ロジックを使用して独自に構築したサーバーにすることもできますし、

[11:34 - 11:38]
ここにリストされている企業やアプリ、または

[11:36 - 11:40]
オンラインで見つかるいくつかの企業やアプリで既に利用可能なサンプル サーバーの一部をコピーして貼り付けることもできます。 これが

[11:38 - 11:42]
サーバーのセットアップのパート 1 です。 次に

[11:40 - 11:44]
理解する必要があるのは、

[11:42 - 11:46]
ホスト アプリケーションをセットアップし、クライアントを

[11:44 - 11:48]
介してサーバーに接続する方法です

[11:46 - 11:49]
。 これも新しい機能であり、

[11:49 - 11:53]
もちろんこのビデオでも取り上げる予定です。

[11:51 - 11:54]
この場合のクライアントは、

[11:53 - 11:56]
独自のカスタム Python バックエンドになります。

[11:54 - 11:57]
最後に

[11:56 - 11:59]
理解しておく必要があるのは、ここにあるこのレイヤーです。

[11:57 - 12:01]
これは、Python 経由でローカル

[11:59 - 12:03]
データ ソースまたはリモート サービスを

[12:01 - 12:04]
サーバーに接続する方法です。 そしてこれは何も新しいことではありません

[12:03 - 12:06]
。 これは、必要なロジックを実装するための単純な Python 関数を記述するだけです

[12:06 - 12:09]
。 よし。  MCP について

[12:07 - 12:11]
理解する必要があることがもう 1 つあり、

[12:09 - 12:13]
これはおそらく開発者として

[12:11 - 12:15]
このプロトコル全体について理解する上で最も重要なことです

[12:13 - 12:17]
。 そして、

[12:15 - 12:19]
これが何であるかを完全に理解するまで、私は

[12:19 - 12:23]
MCP の有用性を理解するのに苦労しました。 この

[12:21 - 12:26]
概念は、

[12:23 - 12:29]
MCP で使用できる 2 つのトランスポート メカニズム、

[12:26 - 12:31]
つまり標準 IO とサーバー送信

[12:29 - 12:33]
イベントに関するものです。 それを理解するには、

[12:31 - 12:36]
まずここにあるこの画像に戻りましょう。

[12:33 - 12:38]
ここでは、リモート サービスを除いてすべてが同じマシン上で実行されています

[12:38 - 12:44]
が、MCP サーバーと

[12:41 - 12:46]
CL MCP クライアントを備えた MCP ホストはすべて同じコンピューター上に存在します

[12:44 - 12:48]
。 したがって、これは

[12:46 - 12:50]
ラップトップである可能性もありますが、これを展開するサーバーである可能性もあります

[12:48 - 12:53]
。 私が初めて

[12:50 - 12:56]
MCP を調べ始めたとき、すべてが同じマシン上にあるのに、

[12:56 - 13:00]
専用サーバーをセットアップして

[12:58 - 13:03]
それをアプリケーションに接続する意味があるのか​​という疑問が本当にありました

[13:00 - 13:05]
。

[13:03 - 13:09]
私にとって、これは、

[13:15 - 13:19]
単純な Python ファイルを用意して

[13:16 - 13:21]
tools.py、Pi と呼んでそれをインポートするのではなく、LLM 用のツールを定義し、AI アプリケーションを定義し、サーバーを起動して接続を行うという非常に面倒な方法のように感じました

[13:19 - 13:24]
。

[13:24 - 13:28]
自分のコンピュータで実行するだけなのに、なぜ物事をこんなに複雑にするのか、まったく理解できませんでした。

[13:26 - 13:29]
確かに、

[13:29 - 13:33]
定義済みのサーバーがすべて用意されていて、それをプロジェクト

[13:31 - 13:35]
にコピー＆ペーストして、

[13:35 - 13:38]
開発時間を少し節約できるというのは理解できます

[13:37 - 13:40]
が、少なくとも私たちが取り組んでいたプロジェクトでは、

[13:40 - 13:43]
使用していたツールのほとんどは 1 つ 2 つ 3 つに限られていて、

[13:42 - 13:45]
これらは 1 つのプロンプト

[13:45 - 13:50]
で Cloth や Cursor を使って起動できる単純な Python 関数でした。

[13:47 - 13:53]
そのため、これを実際に設定できる

[13:53 - 13:58]
さまざまな方法を学ぶまで、その有用性を完全に理解することはできませんでした。

[13:56 - 14:00]
なぜなら、

[13:58 - 14:02]
クイック スタートや

[14:02 - 14:07]
オンラインで見つかるほとんどのチュートリアルに従うと、すべてがローカル マシン上に存在する

[14:05 - 14:10]
標準的な IO 方式が使用されているからです

[14:07 - 14:12]
。

[14:10 - 14:15]
これを起動して、1 つの Python

[14:12 - 14:17]
ファイルからサーバーに接続して

[14:15 - 14:19]
実行します。 そして、

[14:19 - 14:25]
実装する必要がある複雑さがさらに増すことになります。 ただし、

[14:23 - 14:27]
サーバーを

[14:25 - 14:28]
別の場所に置くこともできます。 したがって、これはまったく別のマシン上のリモート サーバー上にある可能性があります

[14:28 - 14:36]
。 そして、

[14:31 - 14:40]
HTTP を使用してサーバー イベント経由で接続できます。 これで、

[14:36 - 14:43]
MCP サーバーに API 経由でアクセスできるようになりました

[14:40 - 14:46]
。 ここではさまざまなメカニズムが

[14:43 - 14:48]
視覚化されており、

[14:46 - 14:50]
リモート開発に焦点を当てると、対話元のマシンやサーバーが異なることを

[14:48 - 14:51]
異なる色で強調表示しています

[14:51 - 14:55]
。 したがって、

[14:53 - 14:57]
開発者は

[14:55 - 14:59]
すべてのツールを管理する 1 つのサーバーを持ち、

[14:59 - 15:05]
同じサーバーに接続するさまざまなクライアント アプリケーションを持つことができます

[15:02 - 15:08]
。 そのため、構築中のさまざまなプロジェクトやアプリケーション

[15:05 - 15:10]
全体で、複数のリソースやツールを共有できるようになりました

[15:10 - 15:14]
。 また、

[15:12 - 15:16]
複数のサーバーを並行して起動することもできます。 したがって、

[15:14 - 15:19]
複数のサーバー、複数のクライアントを持つことができます

[15:16 - 15:22]
。 これは開発者

[15:19 - 15:25]
として理解すべき基本的なコンポーネントです。

[15:25 - 15:30]
標準の IO トランスポートを使用している場合、すべてが

[15:28 - 15:32]
ローカル開発に制限されるからです。 そして私は

[15:30 - 15:35]
今でも、それが LLM 向けの

[15:32 - 15:37]
ツールを提供するための非常に面倒な方法であると信じています

[15:35 - 15:39]
。 これに関して簡単に注意しておきたいのは

[15:37 - 15:42]
、私は独自のカスタム Python バックエンドで MCP を使用することについて言及しているということです

[15:39 - 15:44]
。

[15:42 - 15:46]
たとえば、クラウド デスクトップや

[15:44 - 15:48]
その他のアプリケーションを使用する場合はそうではありません。その場合、

[15:46 - 15:50]
ローカル マシンで標準 IO を使用するのが

[15:48 - 15:51]
依然として非常に効果的です。

[15:50 - 15:53]
サーバーを作成するだけで、ローカル マシン

[15:51 - 15:54]
上のこれらのツールは、複雑な統合を

[15:53 - 15:57]
行うことなく、非常に効果的にそれらを使用できるからです

[15:54 - 16:00]
。 しかし、これが実際に

[15:57 - 16:01]
最も有用性が高いと私が考える部分です。したがって、

[16:00 - 16:03]
これについてもここで

[16:01 - 16:05]
取り上げます。 また、

[16:03 - 16:07]
実際に

[16:07 - 16:11]
これをアプリケーションに組み込む方法、

[16:09 - 16:13]
Docker 経由でサーバーをセットアップする方法、サーバーに接続して

[16:11 - 16:15]
実際のアプリケーションを構築する方法などについて詳しく説明しているチュートリアルはあまり見たことがありません。 したがって、

[16:13 - 16:18]
これは理解すべき非常に重要な違いです

[16:15 - 16:20]
。 さて、理論はすべて理解できたので

[16:18 - 16:22]
、次は実践的な例をいくつか見ていきましょう。

[16:20 - 16:24]
ここでは、

[16:24 - 16:28]
標準 IO と HTTP の使用の違いも明確に示します。 そして今、

[16:26 - 16:30]
Python 開発者である私たちにとって嬉しいのは、

[16:30 - 16:35]
MCP 用の公式 Python SDK が存在することです。

[16:35 - 16:40]
この SDK を使用すると、ほんの数行の Python コード

[16:37 - 16:43]
でサーファーを作成して接続できるため、作業がずっと楽になります

[16:40 - 16:45]
。

[16:43 - 16:48]
本当に必要なのは、次の

[16:45 - 16:51]
pip パッケージ MCP CLI を環境に追加することだけです。

[16:48 - 16:53]
これで準備完了です。 したがって、

[16:53 - 16:56]
基盤となる SDK について、たとえば、微

[16:54 - 16:58]
調整できるパラメータなど、さらに詳しく知りたい場合は

[16:56 - 17:00]
、このリソースを

[16:58 - 17:02]
参照してください。 では、

[17:00 - 17:04]
最初のサーバーをセットアップしましょう。 さて、私はここにあるリポジトリにいます。

[17:04 - 17:10]
これからパート 3 から作業を進めていきます。

[17:06 - 17:12]
シンプルなサーバーセットアップ。 このクラッシュ コースの最上位には

[17:10 - 17:14]
、requirements.txt があります

[17:12 - 17:16]
。 したがって、

[17:14 - 17:19]
仮想環境が設定されていることを確認してください。 これをインストールします

[17:16 - 17:20]
。 最近はUVでこれを行っています。

[17:19 - 17:22]
UV が何であるか分からない場合は、実際に調べてみる必要があります

[17:20 - 17:23]
。 すごいですね。

[17:22 - 17:25]
単に pip を使用するよりもはるかに優れています。

[17:23 - 17:27]
さて、それでは、

[17:25 - 17:30]
このコードを実行できるかどうか確認しましょう。 それでは、

[17:27 - 17:32]
この非常にシンプルなサーバーに入ってみましょう。

[17:30 - 17:34]
ご覧のとおり、これは約 31 行の

[17:32 - 17:37]
Python コードです。 とても簡単です。 何が起こっているのかを

[17:34 - 17:39]
理解するために、これらを一つずつ見ていきましょう

[17:37 - 17:42]
。 この

[17:39 - 17:44]
リポジトリの目的は、サーバーの設定方法を教えるだけでなく、

[17:48 - 17:51]
新しいサーバーを構築する際の定型文または出発点として機能することです。 それで私はそれを

[17:50 - 17:53]
やってきたんです。 だから、これらのテンプレートが手元にあるんです

[17:51 - 17:54]
。 だから構文を覚える必要はありません

[17:53 - 17:58]
。 ここに来て

[17:54 - 18:00]
コピー＆ペーストするだけです。 したがって、これを設定するには、

[17:58 - 18:01]
MCP サーバーを作成するために実際に必要なのは、

[18:00 - 18:03]
次の操作を実行することだけです。 文字通り

[18:01 - 18:06]
これだけ簡単です。 これは、

[18:06 - 18:12]
インストールした Python SDK のおかげで可能になりました。 そして、すぐに

[18:08 - 18:13]
わかるのは、たとえば高速 API を使用した場合に表示されるものと非常によく似ているということです

[18:13 - 18:18]
。 そして、これこそが、MCP

[18:17 - 18:22]
について真剣に考え始めるきっかけでもあります

[18:18 - 18:24]
。 したがって、高速 API を使用して Python

[18:22 - 18:26]
バックエンドを作成し、API を作成する必要があります。また、

[18:24 - 18:28]
高速 API をインポートして

[18:26 - 18:30]
アプリを作成する必要があります。 これは文字通り

[18:28 - 18:33]
同じです。 おそらく彼らは高速

[18:30 - 18:35]
API を参考にして、そこからいくつかの設計原則をコピーしたのでしょう。

[18:35 - 18:40]
これは偶然ではないと思います。 したがって、

[18:37 - 18:41]
現時点で本当に必要なのは、

[18:40 - 18:45]
名前を付けることだけですが、これはすべて

[18:41 - 18:48]
オプションです。 空のままにしておくこともできますが、デモ用に

[18:45 - 18:50]
ホストとポートを既にここに入力してあります

[18:48 - 18:54]
。 ここでは、

[18:50 - 18:57]
詳細に立ち入ることはしませんが、

[18:54 - 18:59]
サーバーを HTTP 経由で使用したい場合、つまり

[18:57 - 19:01]
別のマ​​シンに配置する場合は、

[18:59 - 19:03]
ホストとポートを指定する必要があります

[19:01 - 19:05]
。 しかし、オンラインで見つかるほとんどのチュートリアルで見られるような標準 IO を実行する場合、

[19:09 - 19:14]
ローカル ファイル システムを介して接続し、

[19:11 - 19:16]
パスを指定するだけなので、これは必要ありません。 しかし、それは

[19:14 - 19:18]
サーバーをセットアップする最初のステップです。

[19:16 - 19:20]
高速 MPC と呼んでおり、ここにこの瞬間があります

[19:18 - 19:22]
。 次に

[19:20 - 19:25]
おそらくやりたいことは、サーバーにツールを追加することですが、

[19:22 - 19:28]
これも

[19:25 - 19:30]
非常に簡単に実行できます。

[19:28 - 19:32]
このデコレータを使用すると、ツールを簡単に追加できます。 したがって、

[19:30 - 19:35]
MCP がこの名前を参照しているときに、MCP を呼び出すことができます

[19:32 - 19:37]
。 したがって、これに

[19:35 - 19:39]
別の名前がある場合、これを as

[19:37 - 19:40]
と呼び、これも ass である必要があります。 つまり、

[19:39 - 19:43]
そこに含まれているのは単なる参考資料です。

[19:40 - 19:45]
そして、ツールを呼び出し、

[19:43 - 19:48]
このデコレータを使用して基本的に

[19:45 - 19:52]
関数を取得し、これが MCP サーバーのツールになったと言うことができ

[19:48 - 19:55]
ます。これをコピーして貼り付けるだけで、

[19:52 - 19:57]
3 つになり

[19:55 - 20:00]
、ここに別の関数を追加できます

[19:57 - 20:02]
。 これは関数を

[20:00 - 20:04]
定義する方法としては最も単純なものですが、

[20:02 - 20:06]
これは何でも可能です。 これにより、

[20:04 - 20:08]
データベースに接続できます。

[20:06 - 20:11]
Slack に接続してメッセージを送信することもできます

[20:08 - 20:13]
。  Python 関数であれば、ここでは何でも実行できます

[20:11 - 20:15]
。

[20:13 - 20:18]
ここに入れる引数があり、デコレータを追加します

[20:15 - 20:21]
。 これを実行し、

[20:18 - 20:24]
その構文に従うと、MCP サーバーは

[20:21 - 20:26]
それを利用できるようになり、実際に使用できるリソースとしてリストされます

[20:26 - 20:31]
。 さて、このスクリプトの一番下まで進みます

[20:28 - 20:33]
。 ここが

[20:31 - 20:35]
このサーバーを実行する部分です。

[20:33 - 20:38]
ここには if else ロジックが少しありますが、これは、先ほど

[20:41 - 20:48]
説明した 2 つの異なるトランスポート メカニズムでサーバーを実行することを区別するためだけのものです。

[20:44 - 20:50]
したがって、SSC または標準 IO は、実

[20:48 - 20:51]
稼働環境または本格的な

[20:50 - 20:53]
アプリケーションでは、環境変数からこれを読み込む必要がある可能性が高くなります

[20:51 - 20:55]
。 しかし、単に

[20:53 - 20:58]
デモンストレーションのために、

[20:55 - 21:00]
ここではハードコードしただけなので、後でさまざまなクライアント実装を

[20:58 - 21:01]
示すときに、このチュートリアル内で簡単に切り替えることができます

[21:01 - 21:05]
。 それで、実際には、トランスポートが

[21:03 - 21:07]
標準 IO であるため、

[21:05 - 21:08]
この if ステートメントがヒットする

[21:07 - 21:10]
標準 IO メカニズムから始めます。

[21:08 - 21:11]
ここで、これがどのように実行されるかを確認できます

[21:10 - 21:14]
。 これは

[21:11 - 21:18]
MCP.run であり、トランスポートがあり、

[21:14 - 21:21]
標準 IO を配置します。 ここでも、MCP は

[21:18 - 21:24]
作成した MCP サーバーを指します。 したがって、これは

[21:24 - 21:28]
MCP サーバーをセットアップするときに必要な最小限の作業です。 また、この

[21:26 - 21:30]
ドキュメントでは、標準の IO メソッドを使用する場合のさらに簡単な例を見ることができます

[21:30 - 21:34]
。 したがって、すべてが 1 台のコンピューター上のマシン上にある場合は、これを簡単に実行できることを覚えておいてください

[21:34 - 21:38]
。 名前を付けるだけで

[21:36 - 21:40]
、あとは簡単に実行できます。 これで、

[21:38 - 21:42]
サーバー

[21:40 - 21:45]
server.py ができたので、

[21:42 - 21:48]
これを開発モードで実行できるようになりました。 これは、

[21:45 - 21:50]
MCP サーバーを検査してテストするための非常に優れた方法です

[21:48 - 21:52]
。 したがって、

[21:50 - 21:54]
MCP インスペクターを使用してこれを実行できます。 それで、

[21:52 - 21:55]
プロジェクトに来たら何ができるかというと、私は

[21:54 - 21:57]
カーソルの中にいます。 ターミナルを開きました

[21:55 - 22:00]
。 正しいフォルダにいることを確認してください

[21:57 - 22:02]
。 したがって、シンプルなサーバー セットアップに cd する必要があります

[22:00 - 22:05]
。 これが

[22:02 - 22:06]
実行したいサーバーです。 そして、

[22:06 - 22:12]
mcp devaf を実行してから server.py を実行すると、

[22:12 - 22:16]
サーバーが起動します。 まず、

[22:15 - 22:18]
初めて行う場合は、

[22:18 - 22:22]
インスペクターをダウンロードするように求められます。 そこで、ダウンロードするには y を押しました

[22:21 - 22:24]
。 ダウンロードが

[22:22 - 22:26]
完了すると、追跡できるサーバーが起動します

[22:24 - 22:29]
。 ここで、

[22:26 - 22:32]
MCP インスペクター内にいることがわかります。 つまり、「

[22:29 - 22:33]
接続」をクリックして

[22:32 - 22:36]
サーバーに接続することができます。 ここで、

[22:36 - 22:41]
アクセスできるすべてのものを見ることができます。 そして、そのほとんどは現在空っぽです

[22:39 - 22:43]
。 しかし、1 つ問題があります。それは

[22:41 - 22:46]
ツールです。これは、ツールが

[22:43 - 22:48]
1 つしかない非常にシンプルなサーバーがあるためです

[22:46 - 22:50]
。 ここで、

[22:48 - 22:52]
ツールの一覧を表示することができます。  「

[22:50 - 22:55]
add」と呼ばれるツールが 1 つあることがわかります。

[22:52 - 22:56]
2 つの数字を足し合わせます。 ここで、

[22:55 - 22:59]
すべての情報が単純にコピーされていることがわかります

[22:56 - 23:00]
。 したがって、関数または

[22:59 - 23:02]
ツールは関数名に基づいて add と呼ばれます

[23:00 - 23:04]
。 そして、ここには

[23:02 - 23:06]
単純にドック文字

[23:04 - 23:08]
列である説明が追加されています。

[23:06 - 23:10]
そして、パラメータ A と B があります。

[23:08 - 23:13]
これを代入してテストすると

[23:10 - 23:15]
、結果 6 が返されます。 さて、

[23:13 - 23:18]
これは、

[23:18 - 23:23]
実際に

[23:20 - 23:25]
コンポーネントごとにコードを書いてテストする必要がなく、サーバーを構成するさまざまなコンポーネントをテストするための非常に優れた方法だと思います

[23:23 - 23:27]
。 したがって、このインスペクターは

[23:25 - 23:28]
デバッグにも非常に役立ち、

[23:30 - 23:36]
プロンプトやリソースなど、サーバーに実装できる他のいくつかの機能を調査するのにも役立ちます。これらの機能の

[23:33 - 23:38]
使用例は

[23:36 - 23:39]
今のところあまり見当たりませんが、たとえば、ツールを介して

[23:38 - 23:42]
データやローカル データを

[23:39 - 23:43]
利用できるようにすることもできるためです。 ただし、

[23:42 - 23:45]
たとえば

[23:43 - 23:48]
ここにあるリソースのドキュメントにアクセスすると、ツールを追加する方法

[23:45 - 23:51]
と同様に、サーバー上の Python 実装を確認でき、

[23:51 - 23:56]
リソースを一覧表示したり、リソースを読み取ったり、

[23:54 - 23:58]
ここでローカル ファイル ポットを指定したりすることもできます。

[23:56 - 24:00]
たとえば、サーバーがあり、

[23:58 - 24:02]
そこにデータをダンプして、

[24:00 - 24:04]
それを AI アプリケーションで利用できるようにしたいとします

[24:02 - 24:07]
。 これがやり方です。

[24:04 - 24:08]
しかし、今日では典型的には、

[24:08 - 24:13]
ファクター データベース内の ragp パイプラインのようなものを介してこれを行うことになります

[24:10 - 24:15]
。 したがって、現時点でこれを使用する

[24:13 - 24:17]
ケースはあまり見当たりませんが、サーバー経由でローカル ファイルにアクセスできる

[24:15 - 24:18]
ようにすでに実装されているのは良いことです

[24:18 - 24:24]
。 プロンプトについても基本的に同じです

[24:21 - 24:26]
。 プロンプトを登録できます

[24:24 - 24:27]
。 ここでは、

[24:26 - 24:30]
利用可能なプロンプトを定義し、

[24:27 - 24:32]
サーバーにアクセスして、これらのプロンプトを保存するリストを作成できます

[24:30 - 24:35]
。 繰り返しになりますが、

[24:32 - 24:37]
現時点では、長期

[24:35 - 24:40]
的に見て MCP エコシステム内に完全に統合したい場合は

[24:37 - 24:42]
、

[24:42 - 24:45]
さまざまなプロジェクトで再利用できるプロンプトをここに用意しておくと便利になると思います。

[24:44 - 24:47]
しかし、現時点では、プロジェクト内で実行

[24:45 - 24:49]
したり、Langfuse などのツールを使用したりなど、これを行う方法は他にもたくさんあります

[24:49 - 24:54]
。 繰り返しになりますが、これは

[24:52 - 24:56]
私たちがすでに

[24:54 - 24:59]
できていることとほぼ同じです。 そして、現時点で最も付加価値があるのは、まさにツールにあると私は考えています

[24:59 - 25:03]
。 しかし、私はこれを完全な集中講座にしたいと思っています

[25:01 - 25:05]
。 したがって、ここでもドキュメントを参照できます

[25:03 - 25:07]
。 これは

[25:05 - 25:09]
パート 2、Readme ファイルです。 これらは

[25:07 - 25:10]
すべて公式ドキュメントへのリンクです。プロンプトを

[25:12 - 25:16]
そこに保存したり、ローカル ファイルに保存したりするユース ケースがある場合は、これが適切な方法です

[25:14 - 25:17]
。

[25:16 - 25:19]
Genai を真剣に学習し、本番環境に

[25:19 - 25:23]
対応した AI システムとエージェントの構築方法を学びたいが、

[25:21 - 25:25]
役割やバック

[25:23 - 25:26]
グラウンドが異なる場合や AI の初心者の場合は、説明の

[25:25 - 25:28]
最初のリンクを確認することをお勧めします

[25:26 - 25:30]
。 これは、

[25:28 - 25:32]
私の会社がどのようにお客様を支援できるかについて説明しているビデオです

[25:30 - 25:34]
。 私たちは Gen

[25:32 - 25:35]
AI アクセラレータ プログラムをリリースします。これは、

[25:37 - 25:41]
現在

[25:39 - 25:42]
Data luminina で取り組んでいるクライアント プロジェクトに取り組む社内開発者をトレーニングするために使用するトレーニング プログラムです。 そして、

[25:41 - 25:44]
それを一般の方にも公開しています

[25:42 - 25:45]
。 したがって、本当にこれを専門的に行いたい場合、

[25:44 - 25:47]
そして AI

[25:45 - 25:48]
エンジニアリングを第一原理から学びたい場合は、

[25:47 - 25:50]
調べてみるとよいかもしれません。 さて、

[25:50 - 25:55]
シンプルなサーバーを作成し、それを起動して、

[25:52 - 25:57]
MCP インスペクター経由で接続する方法を確認しました。 しかし、

[25:55 - 26:00]
ここでもう一歩進んで、

[25:57 - 26:03]
このクライアント標準の io.py ファイルを使用して、Python アプリケーション内

[26:00 - 26:06]
からこのサーバーに接続する方法を確認しましょう

[26:03 - 26:08]
。

[26:06 - 26:11]
これに Python SDK も使用します

[26:08 - 26:13]
。 ですから、これは私たちにとって本当に簡単なことなのです

[26:11 - 26:16]
。 ここでも、ほんの

[26:13 - 26:18]
数行のコードを見ることができます。 これがどのように見えるか見てみましょう

[26:16 - 26:20]
。 そこで、これを対話型の Python セッションで実行してみます

[26:18 - 26:22]
。

[26:20 - 26:24]
私はいつもこのようにコードを実行します。

[26:24 - 26:28]
すべてのデータ変数のデバッグとチェックに非常に役立ちます。 つまり、

[26:26 - 26:30]
基本的には舞台裏で Jupyter セッションを使用するので、

[26:28 - 26:32]
私はこの nest_ynio.apply を使用します

[26:32 - 26:36]
。 普通の人のようにターミナルでこれを実行するだけなら、これは

[26:36 - 26:39]
必要ありません。これは、Jupiter 経由の

[26:38 - 26:41]
この対話型

[26:39 - 26:44]
セッションでは、そのままでは非同期プロセスを処理できないため

[26:41 - 26:45]
、ここに非同期関数があるからです

[26:44 - 26:47]
。 だからここにそれがあるんです

[26:45 - 26:48]
。 しかし、それがどのようなものかお見せしましょう

[26:47 - 26:50]
。 ちなみに、

[26:48 - 26:51]
このコードの実行方法について詳しく知りたい場合は、

[26:51 - 26:55]
説明にあるリンクを確認してください。そこには、開発環境の設定方法を説明した完全なビデオがあります

[26:55 - 26:59]
。 そこでこれをカバーします。

[26:57 - 27:01]
それではここで何をしているのか説明しましょう

[26:59 - 27:04]
。 まず、単純なメイン関数から始めて

[27:01 - 27:06]
、まずサーバーのパラメータを定義します

[27:04 - 27:09]
。 これは非常に

[27:06 - 27:11]
簡単です。 このサーバーを Python で実行します。このサーバー

[27:11 - 27:17]
に渡す引数は server.py

[27:14 - 27:19]
ファイル内の ser です。 したがって、ここでは文脈が常に重要です

[27:17 - 27:22]
。 つまり、すべてをこのフォルダ内から実行していることになります

[27:19 - 27:25]
。 つまり、

[27:22 - 27:27]
サーバーとクライアントの両方がここにあります。

[27:25 - 27:29]
そのため、

[27:29 - 27:34]
このファイルを参照する server.py を参照し、python コマンドを使用するだけです

[27:31 - 27:37]
。 そこでpython server.pyを実行します。 つまり、

[27:34 - 27:38]
このサーバーはバックグラウンドで起動されることになります

[27:37 - 27:41]
。 標準 IO になっているので

[27:38 - 27:43]
、mcp.run を呼び出して

[27:43 - 27:48]
サーバーを起動します。 ここでもう一度、背景を説明すると、私たち全員が

[27:46 - 27:50]
同じコンピューター上でこの操作を行っています。

[27:48 - 27:52]
基本的にはホスト アプリケーションを通じて

[27:50 - 27:54]
サーバーを呼び出しますが、

[27:54 - 27:59]
最初にサーバーを起動してからアプリケーションを呼び出す必要がないような方法で実行できます

[27:57 - 28:01]
。

[27:59 - 28:04]
ここにコマンドを入力するだけで、Python SDK が

[28:01 - 28:06]
それを処理します。 これは、

[28:04 - 28:08]
これを操作するのに非常に便利な方法です。

[28:06 - 28:10]
ここで、

[28:08 - 28:13]
サーバーに接続する方法を見てみましょう。これは

[28:10 - 28:15]
SDK からの構文で、

[28:13 - 28:18]
接続を設定し、基本的に

[28:15 - 28:20]
セッションを作成して初期化し、

[28:22 - 28:27]
接続を確立するためにサーバー パラメーターを実行または使用します。 では、

[28:24 - 28:30]
これをメモリに保存するとどうなるか見てみましょう。

[28:27 - 28:33]
ここにサーバーのパラメータがあり、

[28:30 - 28:34]
セッションを設定できます。これを実行しても

[28:33 - 28:37]
何も起こりません。

[28:34 - 28:40]
セッションが初期化されたことを確認するだけです。

[28:37 - 28:41]
それではここで何ができるか見てみましょう。

[28:40 - 28:44]
私たちができることの 1 つは、

[28:41 - 28:46]
利用可能なツールを一覧表示し、

[28:44 - 28:48]
それによって基本的にセッションを使用し

[28:46 - 28:50]
、メソッド list tools を呼び出すことができることです。

[28:48 - 28:53]
ここでも、

[28:50 - 28:55]
リソースとプロンプトについて同じことを行うことができますが、

[28:55 - 29:00]
ここではツールのみに焦点を当てます。 これは実際には

[28:57 - 29:03]
セッションであり、幅を使用するため、

[29:03 - 29:07]
コンテキストをオープンのままにするためにすべてを一緒に実行する必要があります。 したがって、

[29:06 - 29:10]
これらすべてを選択して実行すると、

[29:10 - 29:14]
ツールをリストして

[29:11 - 29:16]
印刷する操作をすぐに実行できます。 利用可能なツールが追加され、

[29:18 - 29:21]
インスペクターでも確認できたシンプルな計算ツールもここに表示されます。 右？ したがって、

[29:19 - 29:24]
これが利用可能な唯一のツールです。

[29:21 - 29:26]
次のステップでは、

[29:24 - 29:28]
計算ツールが表示されます。 これを使用すれば、

[29:30 - 29:36]
このプロセス全体を通じてセッションを使用し、呼び出し

[29:32 - 29:39]
ツールを実行し、at を使用して

[29:36 - 29:41]
次の引数を入力することができます。 これが私たち

[29:39 - 29:43]
の計算ツールの使い方です。 それでは

[29:41 - 29:45]
ここで何ができるか見てみましょう。

[29:43 - 29:47]
ここでは、印刷するツールがあり

[29:45 - 29:49]
、ツールも呼び出されていることがわかります

[29:47 - 29:52]
。 これをもう一度閉じて、

[29:49 - 29:55]
このプロセス全体を使用して

[29:52 - 29:57]
もう一度実行すると、同じ

[29:55 - 30:00]
操作が表示されます。 つまり、私たちが

[29:57 - 30:02]
本質的にやったことは、サーバーを効果的に

[30:00 - 30:05]
作成したということです。

[30:05 - 30:12]
標準 IO を使用して、クライアント アプリケーションでこれらのサーバー パラメータを定義しました。

[30:09 - 30:14]
そのサーバーへの接続を作成します。 私たちはそれを使用しており

[30:12 - 30:16]
、それをセッションと呼んでいます。 そして、

[30:14 - 30:18]
ここにあるセッション オブジェクトを使用して、

[30:20 - 30:24]
ここで利用できるさまざまなメソッドを使用してサーバーと対話することができます。 たとえば、ツールをリストし、ツールを呼び出します

[30:22 - 30:25]
。 おそらくあなたはこう思っているでしょう。

[30:24 - 30:27]
「わかりました、デイブ。でも、

[30:25 - 30:30]
これって同じプロジェクト内の別のファイルで関数を使えるようにするには、まだかなり面倒な方法のように思えます

[30:30 - 30:34]
。

[30:33 - 30:36]
どうしてインポートしないのですか？」 そしてあなたは

[30:34 - 30:39]
完全に正しいです。

[30:36 - 30:42]
この例では、AI や LLM の統合もありません。 そして、

[30:39 - 30:44]
それが基本的に MCP の目的なのです

[30:42 - 30:47]
。 これは、

[30:47 - 30:53]
ツール、プロンプト、データの形式で情報をある場所から

[30:49 - 30:54]
別の場所に転送するための標準化された方法にすぎませんが、

[30:54 - 30:57]
大規模な言語モデルから簡単にアクセスできる方法で転送されます。

[30:56 - 30:59]
したがって、次のセクションでは、

[30:57 - 31:00]
さらに詳しく説明し、

[30:59 - 31:02]
LLM を MCP と統合する方法を紹介します

[31:00 - 31:05]
。 しかし、現時点では、

[31:02 - 31:06]
HTTP 経由の SSE トランスポート メカニズムをまだカバーする必要があります。

[31:05 - 31:08]
これを設定するには、

[31:06 - 31:11]
サーバーに戻り、

[31:08 - 31:14]
トランスポート モードを SSE に設定します。 それを設定してください。

[31:11 - 31:17]
そして、ここでクライアントを開くことができます

[31:14 - 31:20]
。 そこで、今私たちにできるのは、

[31:17 - 31:22]
別のクライアントを用意することです。 これは標準の IO メカニズムで見たものと非常に似ています

[31:22 - 31:28]
が、

[31:25 - 31:30]
サーバーに接続する方法が異なります。

[31:28 - 31:32]
ここでは、

[31:30 - 31:35]
同じローカル マシン上で実行しているため、ローカル ホストに接続し

[31:32 - 31:37]
、

[31:35 - 31:38]
ここでセットアップ時に指定したポートを使用していることがわかります。

[31:37 - 31:42]
これはローカルホストを指し、

[31:38 - 31:45]
ここにポートがあります。 したがって、

[31:42 - 31:47]
今すぐクライアントの標準 IO 内でここに来ると、

[31:45 - 31:51]
これを実行でき、

[31:47 - 31:53]
サーバーを起動する必要はありません。これは、Python

[31:51 - 31:55]
SDK が

[31:53 - 31:58]
アプリごとにサーバーを使用してセッションを作成することでこれを処理するためです。 しかし、

[31:55 - 32:00]
ここに来て

[31:58 - 32:03]
これを実行しようとすると、ここで作成しようとしているセッションがサーバーに接続できないため、さまざまなエラーが発生します

[32:05 - 32:09]
。 それは、

[32:07 - 32:12]
現在このアドレスでは何も起こっていないからです

[32:09 - 32:14]
。 そのため、

[32:12 - 32:17]
ここではサーバーが実行中であることを確認するようにも書かれています。

[32:14 - 32:19]
それを実行するには、

[32:17 - 32:21]
再度ターミナルを開く必要があります。

[32:19 - 32:24]
このフォルダ内にいる必要があります。 また、 u runser.py を呼び出すこと

[32:21 - 32:26]
も、 python server.py を実行することもできます

[32:24 - 32:29]
。 つまり、どのように実行したいかによって異なります

[32:26 - 32:32]
。 それでは、新しいターミナルを開きましょう

[32:29 - 32:33]
。 それで、見てみましょう。  MCP/クラッシュ コースに進みましょう。

[32:36 - 32:42]
まだ第 3 章の段階です。

[32:40 - 32:43]
ここにサーバーがあります。 これで、

[32:42 - 32:46]
uv

[32:43 - 32:46]
run

[32:46 - 32:51]
server.py を呼び出すことができ、サーバーが起動します

[32:49 - 32:54]
。 これで、これが現在

[32:51 - 32:56]
localhost ポート 8050 で実行されていることがわかります。そして、

[32:54 - 32:57]
これが実行されたら、

[32:56 - 32:59]
ここにあるこのウィンドウを閉じると、このファイル全体を実行することができ、

[32:59 - 33:03]
文字通り

[33:01 - 33:06]
同じことを実行しているため、ここにまったく同じ出力が表示されます。 つまり、

[33:03 - 33:09]
今は

[33:06 - 33:11]
SSE 経由の別のトランスポート メカニズムを介してセッションを開いて

[33:09 - 33:13]
セッションを作成し、

[33:11 - 33:15]
その後はまったく同じになります。 それは単にセッションを

[33:13 - 33:17]
確立する異なる方法です

[33:15 - 33:19]
。 ここでもう一度これを強調したいと思います

[33:17 - 33:21]
。 つまり、これは、標準の IO が可能な

[33:19 - 33:24]
ローカル開発で作業しているかどうかという問題に戻ります

[33:24 - 33:29]
が、

[33:29 - 33:34]
基本的に API

[33:31 - 33:35]
と HTTP リクエストを使用する、ここで説明したこの方法でも実行できます。 しかし、

[33:34 - 33:37]
これを別のサーバー

[33:35 - 33:39]
または別のマシンに配置する場合は、これが唯一の

[33:37 - 33:41]
方法です。 さて、ここ

[33:39 - 33:43]
までで、MCP の操作に関して知っておく

[33:41 - 33:45]
必要のある最も基本的な側面をすでに理解できました

[33:43 - 33:46]
。 そして、この

[33:45 - 33:48]
知識だけでも、あなたはおそらくすでに

[33:46 - 33:51]
開発者や MCP に携わる人々の上位 5% に入るでしょう

[33:48 - 33:53]
。 ここで、もう

[33:51 - 33:54]
一歩踏み込んで、

[33:54 - 34:00]
MCP を使用して LLM を中心としたアプリケーションを実際に構築する方法を見てみましょう。 そのために、

[33:57 - 34:02]
新しいサーバーを立ち上げる予定です。 さて、

[34:00 - 34:05]
ここは部品番号 4 の内部です。

[34:02 - 34:07]
これが OpenAI の統合です。

[34:05 - 34:08]
サーバーファイルを下にスクロールします。

[34:07 - 34:11]
とてもシンプルだということがわかります。 再度、

[34:08 - 34:13]
サーバーをセットアップします。 すべて

[34:11 - 34:15]
同じ設定を使用し、ツールは 1 つだけです。

[34:13 - 34:17]
これは非常に単純化されたツールであり、

[34:17 - 34:22]
ラックをエミュレートするためのデモとしてのみ使用されます。 つまり、検索拡張

[34:20 - 34:23]
世代です。 ここでやっていることは、

[34:22 - 34:27]
ここにデータ フォルダーを作成し、

[34:23 - 34:29]
そこに JSON ファイルを配置することです。

[34:29 - 34:33]
架空の会社のナレッジベースから 5 つの質問と回答のペアが生まれます。

[34:31 - 34:36]
たとえば、私たちの会社の

[34:33 - 34:38]
休暇ポリシーは何でしょうか? 通常、

[34:36 - 34:39]
AI アプリケーション内では、

[34:38 - 34:41]
これをファクター データベースに配置し、

[34:39 - 34:43]
ラックを通じて最も

[34:41 - 34:46]
関連性の高いチャンクまたは結果を取得し、それを

[34:43 - 34:47]
LLM に提供して、

[34:46 - 34:50]
アプリケーションにドメイン固有の

[34:47 - 34:52]
知識を提供します。 ここで、

[34:50 - 34:54]
この非常に単純な例でそれをエミュレートしてみます

[34:52 - 34:56]
。 これは

[34:54 - 34:58]
ナレッジベースを取得するツールです。 したがって、このツールの目的は、

[34:56 - 35:00]
ナレッジ

[34:58 - 35:02]
ベース全体をフォーマットされた文字列として取得することです。 したがって、

[35:00 - 35:03]
フィルタリングや選択は行いません。

[35:02 - 35:06]
私たちはそれをすべて取り上げて

[35:03 - 35:09]
、LLM に提供することになります。 ただし、

[35:06 - 35:12]
この例をコピーして、ここで行っていることの代わりに、

[35:12 - 35:18]
類似性検索または

[35:15 - 35:21]
ハイブリッド検索を実行するロジックを実装し、たとえば上位 K 位から

[35:18 - 35:23]
上位 5 位までの結果を取得することもできます。 どれも

[35:21 - 35:24]
同じです。 それは単に

[35:23 - 35:26]
それを実装する方法が異なるというだけです。 これらは、これらのツールを使用する

[35:24 - 35:27]
ときに必ず念頭に置いておくべきことです

[35:26 - 35:30]
。 ここでは

[35:27 - 35:33]
簡単な例を示しましたが、これは任意の関数にすることができます

[35:30 - 35:35]
。 そして最後に、

[35:35 - 35:41]
サーバーを実行する run ステートメントがあり、

[35:38 - 35:42]
この場合は

[35:41 - 35:44]
すべてローカル マシン上にあるため、

[35:42 - 35:46]
設定が少し簡単になるという理由で、標準の IO の例を使用します

[35:44 - 35:48]
。 よし。 つまり、サーバー側には何も新しいことはありません

[35:46 - 35:50]
。 さて、今度はクライアントを見てみましょう

[35:48 - 35:53]
。

[35:50 - 35:57]
これにはもう少しコードが必要です。現時点では、

[35:53 - 35:59]
クライアントは接続を作成して

[35:57 - 36:00]
ツールをリストし

[35:59 - 36:02]
、単純な計算を実行するだけではありません

[36:00 - 36:04]
。 これは実際には、

[36:07 - 36:12]
MCP サーバーと統合または接続して、そこからツールを取得し、

[36:10 - 36:15]
実際にそれらを使用して AI と統合できるクライアントをどのように構築するかという問題です

[36:12 - 36:18]
。 そこで、私はこの MCP OpenAI クライアントを作成しました

[36:15 - 36:20]
。これはクラスです。このクライアントで

[36:23 - 36:27]
何ができるのかを示すために、ここで使用しているさまざまな関数について順に説明していきます。 では、まず

[36:24 - 36:29]
下にスクロールして、

[36:27 - 36:31]
ここで何が起こっているかをすべて見てみましょう。

[36:29 - 36:34]
それでは一番下まで降りていきましょう

[36:31 - 36:38]
。 このファイルでできることは、

[36:34 - 36:41]
基本的に、

[36:41 - 36:45]
作成したこのクラスの新しいインスタンスを作成してクライアントを確立し、

[36:47 - 36:52]
ここで実装した関数を通じてサーバーに接続できることです。 これで、クライアント

[36:49 - 36:54]
上の接続部分を確認できます

[36:52 - 36:56]
。 私はそれを単純にサーバーに置いただけです

[36:54 - 36:58]
。 改めて見ると、これらはすべて

[36:56 - 37:00]
似たようなものだということがわかります。 サーバーのパラメータがあります

[36:58 - 37:02]
。  Python 経由で実行します。

[37:02 - 37:06]
ここでは、ローカルで同じ

[37:04 - 37:08]
マシン、標準 IO で作業しているため、サーバー スクリプトをリンクするだけです。 これで、

[37:06 - 37:10]
この物質がどのように機能するかが分かりました。 サーバーは同じフォルダーにあります

[37:08 - 37:13]
。 これが、server.py と呼ばれる理由です

[37:10 - 37:15]
。 次に、

[37:13 - 37:18]
これに接続してセッションを作成し

[37:15 - 37:22]
、ツールを一覧表示する方法について説明します。 これが、

[37:18 - 37:24]
実際に作業を開始するための最初のステップです

[37:22 - 37:26]
。 これで、このクライアントを作成できます

[37:24 - 37:29]
。 このサーバーに接続できます。

[37:26 - 37:31]
これで、質問を開始できるようになります。

[37:29 - 37:33]
これは、

[37:31 - 37:36]
作成したこのクライアントに

[37:33 - 37:37]
プロセス クエリ機能も備わっているためです。ここで、

[37:37 - 37:44]
AI コンポーネントの統合を開始できる場所を確認できます。 したがって、

[37:41 - 37:46]
このプロセス クエリを呼び出すときに、

[37:44 - 37:48]
文字列であるクエリを挿入することができます。 それで、問題はどれですか

[37:46 - 37:50]
。 さて、

[37:48 - 37:52]
開発者として

[37:50 - 37:54]
AI システムを構築していて、

[37:52 - 37:56]
ユーザーから何らかの情報が入ってくることを想像してみましょう。

[37:54 - 37:58]
チャットボットを構築していて、

[37:56 - 38:00]
その回答を取得して、

[38:00 - 38:03]
ラック パイプラインのように実行し、

[38:02 - 38:05]
情報を取得して結果を合成したいとします

[38:03 - 38:07]
。 ここで起こっているのはそういうことだ

[38:05 - 38:10]
。 しかし、すべてをハードコーディングするのではなく、

[38:10 - 38:14]
サーバー上に作成したこのツール、

[38:12 - 38:16]
つまりナレッジベースを取得します。 私たちは、

[38:14 - 38:19]
そのツールを大規模言語モデルで利用できるようにします

[38:16 - 38:21]
。 そして、私たちは

[38:19 - 38:24]
それを MCP を通じて実行するつもりです。 ここで紹介した

[38:21 - 38:26]
ツールの操作にすでに慣れている場合は、

[38:26 - 38:30]
さまざまなオプションを比較し始めることができますよね? 繰り返しますが、

[38:28 - 38:32]
これは何も新しいことではありません。 これも

[38:30 - 38:35]
このファイル内で実行できるものです

[38:32 - 38:37]
。 したがって、この client.py では、

[38:35 - 38:40]
単にそのツールを作成して

[38:37 - 38:43]
ここで利用できるようにすることもできましたが、

[38:43 - 38:47]
前述した MCP に関するすべての利点を考慮して、サーバーからロードします。

[38:45 - 38:50]
しかし、もう一度言いますが、

[38:50 - 38:54]
MCP を使用していなかった場合と

[38:52 - 38:55]
現在の状態を比較することが常に重要です。 アプリケーションで適切な設計選択とアーキテクチャ選択を行う

[38:54 - 38:58]
には、開発者としてこれを十分に理解する必要があります。

[38:59 - 39:05]
なぜなら、それが毎回必要になるわけではないからです

[39:01 - 39:08]
。 したがって、このプロセス クエリの最初のステップは、

[39:05 - 39:09]
MCP ツールを取得することです。

[39:08 - 39:11]
これは、

[39:09 - 39:14]
ここで実装した別の関数であり、

[39:11 - 39:17]
既に確認したとおり、セッションがあり

[39:14 - 39:18]
、ツールを一覧表示できます。 これは

[39:17 - 39:21]
前の例で行ったことと同じです

[39:18 - 39:24]
。 この

[39:21 - 39:25]
例では、OpenAI を使用しているため、

[39:24 - 39:27]
そのツールを使用して

[39:25 - 39:30]
データ スキーマを確認し、

[39:30 - 39:36]
OpenAI API に必要な正確な構文で入力するだけです。 これはツールが

[39:34 - 39:39]
実際にどのようなものであるかを示す関数定義であり

[39:36 - 39:42]
、

[39:39 - 39:44]
OpenAI によって指定されたものです。 したがって、私たちはこれを順守して、

[39:44 - 39:50]
ツールをこの構造に配置すると、

[39:47 - 39:52]
それを OpenAI に送信でき、OpenAI が

[39:50 - 39:54]
それをどのように操作するかを認識できるようになります。 ですから、

[39:52 - 39:56]
ここでそれを念頭に置くことが重要です。

[39:54 - 39:57]
私たちがやっているのはまさにそれです。 それでは、ここで何ができるのかを示して、これをもう少し実践的にしてみましょう

[39:57 - 40:02]
。 再び

[39:59 - 40:04]
セッションを開始し、

[40:04 - 40:09]
このコード実行方法の便利さをここで再度確認できます。

[40:06 - 40:11]
ここでは基本的にサーバーを作成して

[40:09 - 40:13]
これを実行すると、

[40:11 - 40:15]
サーバーに接続されたことが示され、

[40:13 - 40:17]
ツールが一覧表示されます。 つまり、

[40:15 - 40:21]
知識ベースを取得できるわけです。 これで、

[40:17 - 40:22]
MCP サーバーがこのツールにアクセスできることがわかりました。 さて、

[40:21 - 40:25]
ここに来て、この

[40:22 - 40:28]
クエリを実行します。 それでは、我が社の休暇ポリシーについてお尋ねします

[40:25 - 40:31]
。 したがって、これはナレッジ ベース内の

[40:28 - 40:34]
この要素を使用して回答できる質問です

[40:31 - 40:36]
。

[40:34 - 40:38]
次のステップでは何が起こるかというと、

[40:36 - 40:41]
クライアントに戻ると、

[40:41 - 40:44]
この応答を作成して印刷することがわかります。 これが

[40:42 - 40:46]
私たち

[40:44 - 40:49]
のシステムから返される最終的な答えです。 それでは

[40:46 - 40:52]
ここで何が起こっているのか簡単に見てみましょう。

[40:49 - 40:54]
そこで私たちはツールを入手し、それを

[40:54 - 41:01]
OpenAI が期待する適切な形式に変換し、LLM を作成するか

[40:58 - 41:03]
、OpenAI への API 呼び出しを行います。 したがって、

[41:01 - 41:05]
OpenAI で働いたことがある人にとっては、これは

[41:03 - 41:08]
何も新しいことではありません。 チャット補完 API を使用します

[41:05 - 41:10]
。

[41:10 - 41:16]
このクラスの初期化で先ほど指定したモデルをプラグインします。 したがって、

[41:13 - 41:18]
この場合は GPT40 を使用します。 下にスクロールします。

[41:16 - 41:20]
次に、システム プロンプトがないメッセージ オブジェクトを作成します

[41:18 - 41:22]
。

[41:20 - 41:23]
ユーザーコンテンツと言って、質問を入力します

[41:22 - 41:26]
。 それで、会社の

[41:23 - 41:29]
休暇ポリシーは何ですか? さて、ここからが

[41:26 - 41:31]
面白くなってくる。 さて、今私たちがしていることは、

[41:31 - 41:36]
MCP サーバーで利用できるツールがあり、

[41:36 - 41:44]
MCP ツールを使用して OpenAI が期待する適切な形式に変換したので、それを

[41:39 - 41:46]
呼び出しに追加できるようになったことです。

[41:44 - 41:48]
これと舞台裏で何が起こっているかを理解するために、

[41:48 - 41:52]
必ずしも MCP について何かを理解する必要はありませんが、

[41:52 - 41:56]
ツールと関数呼び出しが

[41:54 - 41:57]
大規模な言語モデルでどのように機能するかを理解する必要があります。 さて、

[41:56 - 41:59]
これがまったく初めてという方のために、これについて説明した他のビデオも用意しています

[41:57 - 42:02]
が、

[41:59 - 42:04]
基本的には LLM が

[42:02 - 42:06]
あなたのリクエスト全体を検討するだけです。 つまり、

[42:04 - 42:07]
質問、プロンプトの送信内容

[42:06 - 42:10]
、API に送信する内容、

[42:07 - 42:12]
そして利用可能なツールです。 また、

[42:12 - 42:19]
ツール内の説明によって、そのツールを「はい」と呼ぶか「いいえ」と呼ぶかを決定できます

[42:15 - 42:21]
。 ツールを呼び出すという

[42:19 - 42:22]
ことは、単に

[42:21 - 42:25]
スキーマまたは関数と

[42:22 - 42:27]
その関数内で必要なパラメータを確認し、

[42:27 - 42:32]
ユーザーの質問のコンテキストを確認して、アプリケーションで

[42:32 - 42:37]
実行できる関数にプラグインするために必要なパラメータを提供することを意味します

[42:35 - 42:38]
。 そして今、私は、これが初めての場合、初めて理解するのは

[42:37 - 42:40]
かなり難しくて抽象的であるということを完全に理解しています

[42:40 - 42:44]
。 それでは、

[42:42 - 42:46]
例を最初から最後までお見せし、

[42:44 - 42:48]
その後、これを段階的に分解して、

[42:49 - 42:55]
ここで組み合わされているさまざまな構成要素のすべてを実際に確認したいと思います。 これは

[42:53 - 42:58]
再び MCP OpenAI クライアント内にあります。

[42:55 - 43:00]
これらはすべてクラス内にあるため、

[42:58 - 43:02]
これをすべて一度にきれいに実行することができます。

[43:00 - 43:05]
それで、我が社の休暇ポリシーは何ですか

[43:02 - 43:06]
? これを実行します。

[43:05 - 43:09]
ツールがリストされます。

[43:06 - 43:12]
クエリが実行され、その後、バックグラウンドで

[43:09 - 43:14]
LLM がツールを使用して

[43:14 - 43:19]
MCP レイヤー経由で適切な情報を取得し、それを OpenAI に返して

[43:16 - 43:21]
最終的な

[43:19 - 43:23]
応答を返します。 当社の休暇ポリシーは

[43:21 - 43:26]
以下のとおりです。これは当社のナレッジ ベースから取得したもの

[43:26 - 43:30]
で、

[43:28 - 43:32]
ファイルは隣接しています

[43:30 - 43:35]
が、基本的にはサーバー経由でアクセスされます。

[43:32 - 43:37]
さて、先ほど言ったように、

[43:35 - 43:39]
ここにあるこのシンプルな実装に戻りましょう。

[43:37 - 43:41]
私がやったことは、本質的には、

[43:39 - 43:44]
この素晴らしく整然としたクライアントをすべて、

[43:45 - 43:50]
たとえば実稼働環境で使用する優れたクラスにまとめ、

[43:47 - 43:52]
それを個別の関数に分割したということです。

[43:50 - 43:54]
これの良いところは、

[43:54 - 43:57]
右側でいつも使用しているインタラクティブな Python ウィンドウを使用すれば、

[43:55 - 44:00]
これを

[43:57 - 44:02]
1 つずつステップごとに実行できることです。 それでは、それが

[44:00 - 44:04]
どのように見えるかをお見せしましょう。ここでは操作

[44:02 - 44:07]
の順序に完全に従うことができます

[44:04 - 44:09]
。 再び

[44:07 - 44:11]
サーバーができました。 つまり、これを行う方法は既にわかっています

[44:09 - 44:14]
。

[44:11 - 44:16]
同じマシンの標準 IO を使用してサーバーに再度接続します。 私たちの

[44:14 - 44:19]
会社の休暇規定がどのようなものかという質問があります

[44:16 - 44:21]
。 ここで

[44:19 - 44:23]
この関数を実行すると、

[44:21 - 44:25]
全体が実行されます。 しかし、ここでできることは、ここに

[44:23 - 44:28]
来て、

[44:25 - 44:31]
このプロセス クエリに入ると、

[44:28 - 44:34]
クエリがメモリに格納されていることがわかることです。 これ

[44:31 - 44:36]
で、グローバル セッションの OpenAI

[44:34 - 44:39]
クライアントとモデルを取得して、

[44:36 - 44:41]
利用可能なツールを取得できるようになりました。 これで、

[44:39 - 44:44]
ここを見て、この関数が実際に何を

[44:41 - 44:45]
しているかを確認できるようになりました。 先ほど

[44:44 - 44:47]
コードをお見せしましたよね？ しかし、今では

[44:45 - 44:50]
出力も見ることができます。 ここでは、

[44:53 - 44:58]
Open AAI に送信できる、実際に定義されているスキーマまたはツールを確認できます。 さて、ここで

[44:55 - 45:00]
再びチャット補完の部分に戻り、

[44:58 - 45:02]
これを初めて実行します。ここでは

[45:00 - 45:05]
ツールでこれを提供し、

[45:02 - 45:07]
ツールの選択を自動にしておきます。 そこで、

[45:05 - 45:10]
これを実行して

[45:07 - 45:12]
OpenAI に送信し、メッセージを確認してみましょう

[45:10 - 45:14]
。 ここで

[45:12 - 45:17]
右にスクロールすると、

[45:14 - 45:21]
ツール呼び出しがあることがわかります。 そこで

[45:17 - 45:23]
OpenAI は、質問に対する回答を直接提供するのではなく、ツールを使用することを決定しました

[45:23 - 45:28]
。 さて、これを基に

[45:26 - 45:31]
アプリケーションを構築するために必要なことは何でしょうか。

[45:28 - 45:33]
これは MC MCP に

[45:31 - 45:34]
固有のものではありません。 これは、アプリケーション内でツールを統合する方法に特有のものです

[45:34 - 45:40]
。 基本的にはメッセージを再度作成します

[45:37 - 45:42]
が、今度はこれに中間アシスタント メッセージも追加します。このメッセージでは、

[45:42 - 45:46]
最初に

[45:45 - 45:49]
ユーザーからの質問がありましたが、今度は

[45:46 - 45:51]
ツール呼び出しを実行して次の

[45:49 - 45:53]
情報が利用可能になったことを指定します。 したがって、

[45:51 - 45:55]
get knowledge base という名前があり

[45:53 - 45:57]
、引数もありますが、

[45:55 - 46:00]
この場合は、

[45:57 - 46:03]
この関数には引数がないため、存在しません

[46:00 - 46:04]
。 ただし、

[46:03 - 46:06]
通常は、たとえばラックに

[46:04 - 46:09]
使用するキーや質問も提供されます

[46:06 - 46:13]
。 しかし、戻って、

[46:09 - 46:16]
次にできることは別のループを実行することです。 アシスタントからのメッセージを

[46:13 - 46:18]
基本的にループする別の反復処理を実行します

[46:18 - 46:22]
。 ツール呼び出しが含まれているかどうかを確認します

[46:20 - 46:26]
。 そして、そうであれば、私たちは

[46:22 - 46:29]
ツールを呼び出します。 ここで、これを実行するとこれが true になることがわかります。

[46:29 - 46:34]
これは、ツール呼び出しがあるために存在するためであり

[46:32 - 46:37]
、アシスタント メッセージ内のツール呼び出しに対して

[46:37 - 46:42]
結果を取得できると言えます。 それでは、それがどのように見えるか見てみましょう

[46:39 - 46:46]
。 そしてここで結果を得ることができます

[46:42 - 46:49]
。

[46:46 - 46:51]
ここで実際のデータがあることがわかります。 それは、

[46:49 - 46:54]
私たちにセッションがあるからです。

[46:51 - 46:57]
これはツールを呼び出すために使用できる MCP セッションであることに注意してください

[46:54 - 47:00]
。 そして、function.name

[46:57 - 47:02]
というツールを取得することで適切なツールが取得されます

[47:00 - 47:04]
。 これが

[47:02 - 47:06]
OpenAI から返ってきた結果です。 そして、現在空になっている

[47:04 - 47:09]
引数をそこにロードすることもできます

[47:06 - 47:11]
。 しかし、

[47:09 - 47:13]
これは本当に

[47:11 - 47:14]
理解する必要がある基本的なことであり、初めてこれを経験する

[47:13 - 47:16]
場合、現時点では非常に抽象的に思えるかもしれません

[47:14 - 47:18]
。

[47:16 - 47:21]
しかし、この例では、

[47:18 - 47:25]
操作の順序とデータの流れを実際に学ぶことができます

[47:21 - 47:27]
。 そこで OpenAI はツールを使用することを決定し、

[47:25 - 47:30]
パラメータを提供します。

[47:27 - 47:32]
アプリケーションでそれを解析し、サーバー上

[47:30 - 47:35]
にある実際の関数を呼び出す必要があります

[47:32 - 47:38]
。 次に、その結​​果を取得し、

[47:35 - 47:40]
メッセージ オブジェクトに再度追加します。

[47:38 - 47:42]
これで、

[47:40 - 47:44]
AI モデルの完全なコンテキストが得られたことがわかります。 それで、

[47:42 - 47:46]
当社の企業方針がどのようなものかがわかります

[47:44 - 47:49]
。 これが

[47:46 - 47:52]
元々の質問です。 ここで、ここにあるツールを

[47:49 - 47:54]
呼び出すことを決定したアシスタントがあり、

[47:54 - 47:58]
そのツールの結果であるコンテンツは

[47:56 - 48:00]
取得されたナレッジ ベースです。 ここでは、

[48:00 - 48:05]
コンテキスト内にある JSON ファイル全体を確認できます。LLM を

[48:02 - 48:08]
使用して構築している場合は、

[48:05 - 48:11]
このメッセージ オブジェクトがあり、

[48:08 - 48:12]
これを OpenAI に送信すると、

[48:11 - 48:15]
すべてのコンポーネントが含まれているため、解決方法がわかることがわかっています。

[48:12 - 48:18]
また、

[48:15 - 48:19]
この 2 番目の操作では、

[48:18 - 48:23]
それらを省略することも、

[48:19 - 48:25]
ツールの選択肢を none にすることもできます。 つまり、

[48:23 - 48:28]
現時点では

[48:25 - 48:32]
すべての情報が揃っており、

[48:28 - 48:35]
これを実行して、OpenAI への 2 回目の API 呼び出しを行って

[48:32 - 48:37]
最終結果を取得することができます。

[48:35 - 48:40]
ここで結果を取得すると、返される

[48:37 - 48:42]
最終的な回答が得られていることがわかります

[48:40 - 48:44]
。 さて、ここで舞台裏で行われているすべての処理である

[48:42 - 48:46]
クライアントの適切な実装に戻ります

[48:46 - 48:50]
。 したがって、

[48:48 - 48:53]
このコードを実行すると、サーバーに接続し

[48:50 - 48:55]
、クエリを実行して OpenAI に送信します

[48:53 - 48:57]
。 これが舞台裏で起こっていることのすべてです

[48:55 - 48:58]
。  AI システム

[48:57 - 49:00]
でさらに多くのツールを使用できるようにしたい場合は、それらのツールを

[49:00 - 49:05]
サーバーに実装し、

[49:02 - 49:06]
ここでロジックをチェックして、

[49:05 - 49:09]
それらのツール呼び出しをキャッチできることを確認するだけです

[49:06 - 49:11]
。 では、LLM が

[49:09 - 49:14]
そのツールを呼び出すことにした場合、何が起こるのでしょうか。また、

[49:11 - 49:16]
そのツールをコンテキストに何をどのように追加する

[49:14 - 49:17]
必要があるのでしょうか。あるいは、そのツールで何を行う必要があるのでしょうか。

[49:16 - 49:19]
また、そのツールをどのように呼び出す必要があるのでしょうか。

[49:17 - 49:20]
はい、それではあなたがまだ私と一緒にいてくれることを願います。

[49:19 - 49:22]
これが間違いなく、

[49:20 - 49:24]
この短期集中講座全体の中で、

[49:22 - 49:26]
これを完全に理解することの最も難しい部分でした。 実際に使い方を理解するには、おそらく

[49:24 - 49:28]
例を試して調整し

[49:26 - 49:30]
、独自の例を作成して実行する必要があります

[49:28 - 49:32]
。

[49:30 - 49:33]
最後に、MCP で構築する際に役立つ、理解しておく必要のある実用的なヒントと例をいくつか紹介したいと思います

[49:35 - 49:39]
。 さて、

[49:37 - 49:40]
パート5に進みましょう。  MCP と関数

[49:39 - 49:42]
呼び出し。 これは非常に短いものです。

[49:40 - 49:44]
このビデオ全体を通して、私が

[49:42 - 49:47]
これについてすでに数回言及しているのを聞いたことがあるでしょう。

[49:44 - 49:49]
MCP は何も新しいものを追加しません。 これは

[49:47 - 49:50]
私たちがすでに 2 年間にわたって実行してきたことです

[49:49 - 49:52]
。 こちらにある短いファイルでは、

[49:55 - 50:01]
同じファイル内で関数を指定する単純なツール呼び出しの概要が強調されています。

[49:58 - 50:02]
ここで、OpenAI チャット補完があることがわかります

[50:01 - 50:04]
。 ツールの

[50:02 - 50:08]
呼び出しを処理し、それをもう一度 OpenAI に送信します

[50:04 - 50:10]
。 これをすべて実行すると、

[50:08 - 50:11]
まったく同じセットアップになります。

[50:10 - 50:13]
唯一の違いは、

[50:11 - 50:15]
MCP サーバーからツールを取得するのではなく、

[50:13 - 50:17]
ファイルに直接ツールを取得することです。 そして、

[50:15 - 50:19]
この例は、「

[50:19 - 50:25]
既存の AI プロジェクトをすべて MCP に移行する必要があるか?」という疑問への答えを見つけるのにも役立つはずです。

[50:22 - 50:27]
そして、答えはおそらく「ノー」です。 したがって、

[50:25 - 50:29]
関数呼び出しやツールをすでに使用していて、

[50:27 - 50:32]
それが

[50:29 - 50:34]
今のところ完璧に動作している場合は、MCP を追加しても

[50:32 - 50:35]
何も変わりません。 最初は

[50:34 - 50:38]
物事が少し複雑になるだけです

[50:35 - 50:40]
。 しかし、

[50:40 - 50:46]
長期的に見れば、ツールの使用に

[50:42 - 50:49]
大きく依存する新しいプロジェクトの場合は、

[50:49 - 50:54]
MCP 標準サーフェスを参照するか、

[50:52 - 50:57]
独自のツールを作成してそれを統合することが合理的である可能性があることを、今ではご理解いただいているはずです

[50:54 - 50:59]
。 しかし、

[50:57 - 51:01]
現在のプロジェクトを実際に移行する必要も必要性もありません

[50:59 - 51:02]
。 よし。 さて、あなたがまだ私と一緒にいてくれることを願っています

[51:01 - 51:04]
。 これは長いですが

[51:02 - 51:06]
、

[51:06 - 51:11]
開発者にとって本当に完全な短期集中講座にするためには、あと 2 つの概念を説明する必要があります。

[51:08 - 51:14]
次に、Docker を使用した MCP サーバーの実行について説明します。

[51:14 - 51:19]
これは、現実世界では、

[51:22 - 51:26]
ローカル マシン上に存在せず、

[51:24 - 51:28]
実際にどこかに展開して

[51:26 - 51:30]
他のアプリケーションで再利用できる MCP サーバーを使用する最も実用的な方法になると思われるためです

[51:28 - 51:32]
。 プロジェクトに余分な複雑さが加わるのではなく、まさにここから

[51:30 - 51:34]
M MCP のメリットを享受し始めることができます

[51:34 - 51:39]
。 そこで、

[51:37 - 51:41]
その方法を示すために簡単なセットアップを作成しました。

[51:39 - 51:43]
それで、ここにあるコードに戻ると、

[51:41 - 51:46]
新しいものは何もありません。

[51:43 - 51:48]
シンプルなサーバーがあります。 これは、

[51:46 - 51:51]
すでに説明したサーバーとまったく同じです。

[51:51 - 51:55]
実行できる非常にシンプルなクライアントもあります。 繰り返しますが、これはすべて

[51:53 - 51:58]
同じです。 ここで新しいのは

[51:55 - 52:00]
Docker ファイルがあることだけです。 そして、その

[51:58 - 52:04]
docker ファイルは基本的に、この

[52:00 - 52:06]
server.py ファイルを、実行可能な適切な docker

[52:04 - 52:08]
コンテナにラップし、

[52:06 - 52:10]
その環境内で

[52:08 - 52:12]
要件をインストールしてサーバーを

[52:10 - 52:15]
実行し、サーバーが

[52:12 - 52:17]
利用可能になるようにします。 そのため

[52:15 - 52:19]
の手順はここに概説されています。

[52:17 - 52:21]
指示に従って、まず

[52:19 - 52:24]
最初に

[52:21 - 52:26]
これを構築する必要があります。 そのため、

[52:24 - 52:28]
このフォルダーに移動して、

[52:26 - 52:30]
ここでターミナルを開くことでこれを実行できます。 ここでできることは、

[52:28 - 52:33]
ここに来て、

[52:30 - 52:35]
docker build tmcp server コマンドを貼り付けることです。

[52:33 - 52:37]
これは、

[52:35 - 52:39]
docker を使用して docker コンテナを構築するというものです。

[52:37 - 52:41]
したがって、

[52:39 - 52:42]
システム上で docker デーモンが実行されていることを確認してください。

[52:41 - 52:44]
これを実行すると、Docker イメージがビルドされ、

[52:44 - 52:48]
ローカル マシン上の Docker 経由で使用できるようになります

[52:46 - 52:50]
。 そして、あなたにできることは、

[52:48 - 52:52]
私にこれを明らかにしてもらうことです。

[52:50 - 52:54]
次のコマンド、docker

[52:52 - 52:57]
run を実行できます。 次に、

[52:54 - 52:59]
MCP サーバーを作成したイメージを参照して、

[52:57 - 53:01]
正しいポートで実行されていることを確認します。 それでは

[52:59 - 53:04]
始めましょう。 そして今、

[53:01 - 53:07]
これがこちらで実行されていることがわかります。 したがって、

[53:04 - 53:09]
これは、

[53:07 - 53:12]
以前に

[53:09 - 53:15]
サーバーをセットアップして、

[53:12 - 53:17]
uvun server.py または python server.py のいずれかを使用してサーバーを実行し、

[53:17 - 53:23]
SSE 経由で接続していたときに行っていた操作と非常によく似ていることを覚えておいてください。 これは

[53:20 - 53:25]
まったく同じものですが、今は

[53:23 - 53:28]
Docker コンテナー内にあるだけで、このポート

[53:28 - 53:33]
でローカルホストに公開されているため、まったく同じようにクライアントを使用できます。

[53:30 - 53:35]
これを再度実行すると、

[53:33 - 53:37]
サーバーに完全に接続され、

[53:35 - 53:39]
計算が実行されます。

[53:37 - 53:40]
これが Docker コンテナーにパッケージ化されると、

[53:40 - 53:45]
仮想マシンを作成したり、

[53:42 - 53:47]
HNER AWS または Azure でリソースを管理したりすることが

[53:45 - 53:49]
でき、

[53:47 - 53:52]
システム上のリポジトリをクローンしたりすることができます

[53:49 - 53:54]
。 起動コマンドを実行して

[53:52 - 53:56]
Docker イメージを起動し、サーバーにリモートで接続します。

[53:56 - 54:01]
ローカル ホスト経由ではなく、

[53:58 - 54:04]
サーバーまたは管理対象サーバーが配置されているドメインまたは IP アドレスに対して実行します。

[54:01 - 54:07]
これで、

[54:04 - 54:09]
すべてのサーバーと

[54:07 - 54:11]
ツールが別の場所に存在するようになり、

[54:09 - 54:13]
ワールドまたはマシン内の他のアプリケーションから

[54:11 - 54:16]
接続できるようになります。

[54:13 - 54:18]
よし。 これで、

[54:16 - 54:20]
この短期集中講座の最後、パート

[54:18 - 54:23]
7「ライフサイクル管理」まで終わりました。

[54:20 - 54:26]
これについて、またその他の点についても簡単に説明しておきたいと思いますので、

[54:26 - 54:32]
後で参照できるようにこのリソースを紹介します。 そして、

[54:29 - 54:33]
これを使用して実際のアプリケーションを構築し、

[54:32 - 54:35]
それを本番環境に導入し、

[54:33 - 54:39]
たとえば

[54:35 - 54:42]
さまざまなデータ ソースや他の外部

[54:39 - 54:44]
サーフェスに接続する場合、特にデータベースなどとの

[54:42 - 54:45]
すべての接続とライフ サイクルを適切に管理することが重要です

[54:45 - 54:50]
。 この

[54:47 - 54:52]
ファイルでは、まず

[54:52 - 54:57]
初期化、操作、そして

[54:54 - 54:59]
終了時のライフサイクル管理の概要を説明しました。  Python では実際に width 演算子を使用しているため、これはすべて、

[54:57 - 55:02]
コード例で設定した方法ですでに処理されています

[55:02 - 55:05]
。 これにより、

[55:04 - 55:09]
一部のセッションが自動的に処理されます

[55:05 - 55:11]
。 ただし、より高度なライフ

[55:09 - 55:14]
サイクル管理アプローチの場合は、

[55:11 - 55:16]
ライフスパン オブジェクトを作成できます。 以下は、

[55:14 - 55:18]
MCP 公式ドキュメントからの例です

[55:16 - 55:20]
。 ここまでスクロールしてみましょう

[55:18 - 55:23]
。 そう、MCP サーバーを作成するときに

[55:20 - 55:26]
、これにライブ スポーンを追加することもできます

[55:23 - 55:29]
。 これは、

[55:26 - 55:32]
たとえばデータベースに接続するときに役立ちます

[55:29 - 55:34]
。 したがって、

[55:32 - 55:37]
接続を閉じるときに、

[55:43 - 55:48]
単にシャットダウンするのではなく、データベースから切断するための何かを適切に実装することで、そのデータベースへの接続も正常にシャットダウンされ、適切に処理されることを実際に確認する必要があります

[55:45 - 55:50]
。 これをもう一度ここに掲載して、MCP の操作に関する

[55:48 - 55:53]
完全な

[55:50 - 55:55]
ガイド、完全な短期集中講座にしたいと思いました。

[55:55 - 55:59]
サーファーやクライアントを操作し、

[55:57 - 56:02]
さまざまな

[55:59 - 56:04]
コンポーネントを操作する場合、サーバーが成長し、サーファーと連携するクライアントも成長するにつれて、すべてのコンポーネントの適切な

[56:02 - 56:06]
ライフサイクルを確保することが

[56:04 - 56:08]
長期的に非常に重要になるからです

[56:08 - 56:13]
。

[56:11 - 56:15]
したがって、最初は

[56:13 - 56:16]
これについてあまり心配する必要はありませんが、

[56:15 - 56:19]
たとえば

[56:16 - 56:22]
会社や企業で働いていて、

[56:19 - 56:23]
チームが複数のサーバーや

[56:22 - 56:26]
複数のクライアントを構築し、データベースに接続している場合は、

[56:23 - 56:28]
間違いなくこれについて

[56:26 - 56:30]
検討する必要があります。 さて、

[56:28 - 56:32]
これでこの短期集中

[56:30 - 56:35]
講座は終了です。 ここまでで、

[56:32 - 56:36]
MCP とは何か、

[56:35 - 56:39]
そして Python 開発者として MCP をどのように使用して

[56:39 - 56:44]
Claw デスクトップやカーソルに統合するかだけでなく、実際に

[56:41 - 56:46]
独自のバックエンドで使用して AI システム

[56:44 - 56:48]
やエージェントを構築するかについて、しっかりと理解していただけたと思います。  AI エンジニアリングを根本から学びたいのであれば、説明にある

[56:46 - 56:49]
Genai Accelerator の最初のリンクを必ずチェックしてください

[56:51 - 56:54]
。 そして、もしあなたがすでに

[56:53 - 56:56]
熟練した AI エンジニアであり、

[56:54 - 56:58]
しばらく LLM を使用して開発を行ってきたものの、

[56:58 - 57:03]
アプリを本番環境にリリースするためのよりよい方法を必要としているのであれば、Data luminina 内のすべてのプロジェクトで使用している本番環境フレームワークである

[57:00 - 57:04]
Genai Launchpad をチェックしてみるといいでしょう

[57:06 - 57:11]
。 したがって、この一環として、

[57:08 - 57:13]
このリポジトリにアクセスできるようになります。 そして、私たちは

[57:11 - 57:15]
これを、私たちが行うすべてのクライアント プロジェクトを開始するための定型文として使用します

[57:13 - 57:16]
。

[57:15 - 57:18]
これにより、文字通り、

[57:16 - 57:21]
あらゆるプロジェクトでセットアップ時間を約 2 ～ 3 週間節約できます

[57:18 - 57:22]
。 これは、プロジェクトを迅速に立ち上げるために使用できる完全な AI バックエンドと

[57:21 - 57:24]
インフラストラクチャです

[57:22 - 57:26]
。

[57:24 - 57:27]
はい、それではこの

[57:26 - 57:29]
ビデオはこれで終わりです。

[57:27 - 57:30]
この

[57:29 - 57:32]
短期集中講座全体にお時間を割いてご注目いただき、ありがとうございました。 役に立ったと思ったら、「いい

[57:30 - 57:34]
ね！」を押してください。また、

[57:32 - 57:36]
まだ登録していない場合は登録も検討してください。

[57:34 - 57:39]
次に、このビデオをチェックすることをお勧めします。この

[57:36 - 57:41]
ビデオでは、フレームワークを必要とせずに純粋な Python で

[57:39 - 57:43]
効果的な AI エージェントを構築するために使用できるいくつかのパターンについて説明しています

[57:43 - 57:47]
。

## コメント

### 1. @daveebbelaar (👍 41)
It's been a while since you've heard from me! Q1 has been crazy busy for me working on all the projects going on behind the scenes at Datalumina. I hope you enjoy this full crash course on MCP!

> **@SanSha2100** (👍 1): Hi Dave, I can’t find the link you mentioned about  “how you set up your Dev environment”

> **@vkphoenixfr** (👍 1): Hi ! I’m in France and I’d like to buy your formation. In France we have CPF, which is money dedicated to learning that we have from government. I’d like to know how to use it with you. Did you already do that ?

> **@ExcelMasterAI** (👍 1): If you need the complete slides, I shared them in the comments of my LearnWise video

> **@yashs1962** (👍 0): Hi could you make a video showing the difference of how the same example  was executed before mcp?

> **@johnperaltaCFA** (👍 0): This video is nuts 🥜

### 2. @martindawson (👍 10)
This is excellent. I will be watching this again over the next week or two. It’s so good to have this practical approach to these subjects and concepts. In the fast moving world of AI, there is so much poor information out there created by people with little to no experience. Thank goodness for people like you who are generous and skilled enough to be able to provide such quality explanations and tutorials. Thanks so much!

### 3. @soraz9702 (👍 10)
finally a productive video regarding MCP servers and their deployments in custom hosts.. Everyone is only taking about integrating MCPs in either Claude's Desktop or IDEs. Thanks Dave for covering all the concepts of MCPs and its uses in our custom models.

> **@ExcelMasterAI** (👍 0): If you need the complete slides, I shared them in the comments of my  LearnWise video

### 4. @nehaapulipati (👍 0)
This is one of the best and most comprehensive MCP courses I came across! Thank you, Dave!

### 5. @Bowtieeffect (👍 16)
First and foremost, Dave, your work is fantastic! Secondly, I absolutely love your training. It has personally helped me advance in my career. Your videos always go beyond just showing how to do something; they also explain how to do it correctly, which is very MLOps-oriented. One day, I will take the plunge and work independently.

> **@ExcelMasterAI** (👍 0): If you need the complete slides, I shared them in the comments of my  LearnWise video

### 6. @harjos78 (👍 2)
The best tutorial i have seen in a while . Focused towards developers. Clean, crisp and consice. Good work Dave!. Thanks

> **@Bokarma11** (👍 0): and very importantly it's already 1.5x playback speed. I can't stand slow speech at all but Dave's is perfect

### 7. @ruzma (👍 7)
Hi! (Very) Great content. Just so you know: for the timestamps to appear on the YouTube progress bar, the first one needs to start exactly at 00:00 — for example, “00:00 Introduction”. Otherwise, YouTube won’t display them on the timeline, even if the rest are correct.

> **@daveebbelaar** (👍 2): Ohh wow. Three years on YouTube and I didn't know this lol. Thanks!

### 8. @SunilM15 (👍 0)
Great content about MCP. Loved your extensive examples and the explanation. Lots of stuff to grab from this video. Thank you as always 💯

### 9. @LandRoverDiscovery2Fan (👍 1)
At first, I was very skeptical of MCP for the same reasons you outlined. But I stayed patient (because I love your videos and have built things from your trainings before) and now I get it. But man, you have to stay through the whole thing. If anybody’s on the fence about MCP, I would recommend sticking with him all the way through this one and I think you’ll get it too. As he says, it’s not going to necessarily be something you always use but my mind’s already spinning on how I can use it for a problem. I have right now.

### 10. @kirandeshmukh6907 (👍 2)
I literally had every questions you have answered .. its like godsent crash course honestly

### 11. @leobeeson1 (👍 6)
Excellent video, Dave. As you say, MCP's underlying concepts and patterns have been around for some time. MCP is basically an implementation of RPC (Remote Procedure Call); the `Stdio` transport mechanism would be equivalent to local Inter-Process Communication RPC, while the `SSE` transport mechanism would be equivalent to networked, HTTP-based RPC. That's not to criticise MPC; I think it's a great new mechanism for enabling RPC by LLM, just not a nove; concept per se.

> **@ExcelMasterAI** (👍 0): If you need the complete slides, I shared them in the comments of my  LearnWise video

### 12. @gustavosaidler (👍 2)
This is the video I was waiting for.... I also found myself wondering about how to integrate MCP with my AI applications and not only use it in Claude or Cursor.
Thank you so much for this, great work as usual

### 13. @lol2876 (👍 0)
hi dave. Thanks a lot. This is gold 🙏

### 14. @LukTarPL (👍 1)
I've just subscribed you after watching this one. It's the most valuable vlogs about ai latest technologies I saw.
Thanks man.

> **@ExcelMasterAI** (👍 0): Want to revisit the key slides from the demo? I’ve shared the authentic slides extracted from the original video in the comment section of my first video on ExcelMasterAI!

### 15. @rogerguess926 (👍 0)
Thanks!

### 16. @swxin9 (👍 0)
Finally, a video which clearly unwrapped what MCP is.

### 17. @jonm691 (👍 0)
Excellent use of time. There are so many videos regurgitating script-kiddy-level content, and it's frustrating, but this one made up for all the time wasted on them. Great detail, great developmental and architectural thinking. Great knowledge transfer

### 18. @WirelessGus (👍 0)
I appreciate you sharing your knowledge. After watching your video crash course, I was able to fill in the gaps in my MCP server. Just three days later, I successfully built an MCP SSE that connects a group of seven agents, allowing them to interact and hand off tasks among themselves! It was truly a magical moment, and I couldn’t have done it without your video. Cheers! 

BTW, open to collaborate 🎉

### 19. @ArturSantos-h2z (👍 0)
This is truly amazing, congrats for the quality content!

### 20. @gabrielmoreira2423 (👍 0)
Dave, first of all, thanks for this video!
It really helped me understand and apply MCP in a project I’m working on, it’s been extremely useful.
Thanks again for your time and for your remarkable way of teaching, you turn something cumbersome into something truly understandable!

