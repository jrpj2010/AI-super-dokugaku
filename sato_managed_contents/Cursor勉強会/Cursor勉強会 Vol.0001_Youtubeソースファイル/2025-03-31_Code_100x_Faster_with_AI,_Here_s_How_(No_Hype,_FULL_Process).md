# Code 100x Faster with AI, Here's How (No Hype, FULL Process)

**チャンネル:** Cole Medin
**公開日:** 2025-03-31
**URL:** https://www.youtube.com/watch?v=SS5DYx6mPw8

## 説明

Everyone knows that if you aren’t using an AI coding assistant, you are going to fall behind no matter what you are developing. But what people usually don’t know is how to actually use AI coding assistants (Windsurf, Cursor, Cline, Roo Code, etc.) effectively.

Having a well defined process for coding with AI is crucial to consistently get high quality output, and in this video I’ll walk you through my FULL process as we use it to build a Supabase MCP server step by step as our example - all the way from ideation to deploying it. 

This process will apply no matter what you are building or which AI IDE you are using, and I’ve got some resources to share to save you a ton of time setting this all up yourself.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Check out Global GPT as the most cost-effective way to get access to all the best LLMs in a single place:

https://glbgpt.com/?inviter=Cole

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The waitlist is now OPEN for Dynamous AI Mastery - an exclusive community for early AI adopters like you to master AI & AI Agents and transform your career and business:

https://dynamous.ai

Google Doc for my full AI coding process:

https://docs.google.com/document/d/12ATcyjCEKh8T-MPDZ-VMiQ1XMa9FUvvk2QazrsKoiR8

Check out the Supabase MCP server I built in this video here:

https://github.com/coleam00/supabase-mcp

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

00:00 - Introducing My Process for Coding with AI
02:04 - The Golden Rules for AI Coding
05:47 - The All Powerful PLANNING.md and TASK.md
09:10 - Using Multiple LLMs to Plan (GlobalGPT Example)
10:32 - Global Rules for AI IDEs
13:20 - Integrating MCP Servers
16:53 - The Initial Prompt for Our Project
20:43 - AI Literally One-Shot My Supabase MCP Server
24:01 - Project Backups with Git
25:29 - Using AI to Test Our Code
29:11 - Deploying Our Project
31:38 - Outro

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Join me as I push the limits of what is possible with AI. I'll be uploading videos at least two times a week - Sundays and Wednesdays at 7:00 PM CDT!

## 字幕

[00:00 - 00:04]
AI コーディング アシスタントを使用していなければ、何を開発していても遅れをとることになるのは誰もが知っています

[00:05 - 00:10]
。 しかし、人々が通常

[00:07 - 00:12]
知らないのは、これらの AI コーディング

[00:10 - 00:13]
アシスタントを効果的に使用する方法です。 確かに、

[00:13 - 00:19]
Windsurf や Cursor のような AI IDE に好きなものを

[00:16 - 00:21]
何でも投入すれば良い結果が得られるとは限りません。

[00:19 - 00:22]
しかし、

[00:21 - 00:25]
それらを操作するための明確なプロセスがなければ、

[00:22 - 00:27]
常にそうなるとは限りません。

[00:25 - 00:29]
そして、LLM が

[00:27 - 00:31]
上級ソフトウェア エンジニアから、

[00:31 - 00:36]
キーボードを叩いたり、コードの一部を削除したり、不要な

[00:34 - 00:38]
機能を実装したりする霊長類の群れのような存在に変わったとき、それは非常にイライラさせられます。

[00:36 - 00:39]
その苦痛はご存じのとおりです。

[00:42 - 00:46]
高品質の出力を

[00:44 - 00:49]
一貫して得たい場合、AI を使用してコーディングするときには明確に定義されたプロセスが必要です。 そして、もしあなたが

[00:46 - 00:51]
まだその洗練されたプロセスを持っていないなら、

[00:49 - 00:53]
このビデオの最後までには、AI を使った

[00:51 - 00:55]
開発のまったく新しい次元に到達していることを保証します。

[00:53 - 00:57]
なぜなら、私は

[00:55 - 00:59]
ワークフロー全体をステップごとに説明し

[00:57 - 01:01]
、細かい

[00:59 - 01:05]
詳細に触れるつもりだからです。そうすれば、私のプロセスをコピーするだけで、AI を使った開発の

[01:01 - 01:07]
生産性を 10 倍、さらには 100 倍に高めることができます

[01:05 - 01:08]
。 そして、これを

[01:07 - 01:10]
あなたの時間の価値あるものにするために、

[01:08 - 01:11]
私はあなたに 3 つのことを約束します。

[01:10 - 01:13]
まず、AIDS の場合、多くの人が設定を複雑にしすぎるのを目にしますが、私たちは設定を複雑にしすぎないようにしています

[01:13 - 01:18]
。  2 つ

[01:16 - 01:20]
目は、私たちは単なるおもちゃを作っているのではないということです。

[01:18 - 01:22]
このワークフローを使用して、

[01:22 - 01:27]
スーパーベース MCP サーバーを使用した完全な実用的かつ便利な例を構築します。

[01:25 - 01:28]
詳細は、このビデオをご覧ください。

[01:27 - 01:30]
3 つ目は、このプロセスは、

[01:28 - 01:32]
何を

[01:30 - 01:34]
開発しているか、どの AI IDE を

[01:32 - 01:36]
使用しているかに関係なく機能するということです。 最後にちょっとだけ。

[01:34 - 01:38]
AI

[01:36 - 01:40]
コーディングのワークフローだけでなく、AI スキル

[01:38 - 01:42]
全体をレベルアップしたい場合、最適なものをご用意しています。

[01:40 - 01:44]
dynamis.ai をチェックしてください。 これは

[01:42 - 01:46]
私が体重リストを公開した限定コミュニティです

[01:44 - 01:48]
。 ここでは、

[01:46 - 01:50]
私が YouTube で常に提供している専門知識を、

[01:50 - 01:55]
コース、ライブ ワークショップ、毎週のセッション、

[01:53 - 01:56]
毎日のサポート、そして最も素晴らしい

[01:55 - 01:59]
点である

[01:56 - 02:01]
他の A​​I 早期導入者と参加できるコミュニティを通じて、さらに深いレベルにまで高めています。 それでは、リンクをチェックして、

[01:59 - 02:03]
ウェイトリストに参加し

[02:01 - 02:04]
、

[02:03 - 02:06]
AI を使用したコーディングの完全なプロセスについて詳しく見ていきましょう。

[02:04 - 02:08]
ここでご覧いただいているのは、

[02:06 - 02:10]
このビデオの説明にリンクを貼った Google ドキュメントです。AI を

[02:10 - 02:14]
使用したコーディングの全プロセスが説明されています。 これをあなた自身のリソースとして活用してください

[02:12 - 02:16]
。 これがすべてなので、ビデオ全体を通じて

[02:14 - 02:18]
これを頻繁に参照します

[02:18 - 02:22]
。 これは、最上位の黄金律から始まる、私たちの全プロセスです

[02:22 - 02:26]
。 それでは、これらについて簡単に説明し、

[02:30 - 02:34]
実際にプロジェクトを開始するステップ 2 から始めて、これらがプロセスの残りの部分にどのように影響するかを見ていきます。 ですから、一番

[02:32 - 02:36]
最初の黄金律、これは

[02:34 - 02:39]
非常に重要です。

[02:39 - 02:44]
インストール、

[02:42 - 02:47]
ドキュメント、計画、およびタスクの手順が記載された、より高レベルのマークダウン ドキュメントを使用したいと考えています。 これらを使用して、

[02:44 - 02:49]
LLM にコンテキストを与えます。 そこで

[02:47 - 02:51]
私たちは、プロジェクトの作成全体を通じて AI を使用してこれらを作成および管理する予定です

[02:51 - 02:55]
。 そして、

[02:53 - 02:58]
次の 3 つのルールはすべて、LLM に過大な負担をかけないことに関するものです。LLM

[02:58 - 03:02]
に与えるコンテキストが長くなるほど、

[03:00 - 03:03]
幻覚を起こす可能性が高くなるためです。 たとえば

[03:02 - 03:07]
、すべての

[03:03 - 03:09]
コード ファイルを 500 行未満に保つとします。 会話が長くなると LLM の学習が停滞する可能性がある

[03:07 - 03:11]
ため、頻繁に新しい会話を始める必要があります

[03:11 - 03:16]
。 また、

[03:14 - 03:18]
LLM に同時に多くのことを要求して、LLM に負担をかけないようにする必要があります

[03:16 - 03:20]
。 実際、私は

[03:18 - 03:22]
通常、プロンプトごとに

[03:20 - 03:25]
1 つの新しい機能を実行したり、

[03:22 - 03:28]
新しいことを 1 つ実装するように要求するのが最善であると考えています。

[03:25 - 03:30]
はるかに良い結果です。 ファイルが非常に

[03:28 - 03:32]
長く、会話も長い場合、

[03:30 - 03:33]
同時に多くのことを要求していると、

[03:33 - 03:39]
どの LLM または

[03:36 - 03:41]
AI IDE を使用していても、ひどい結果が出始めます。 また、

[03:39 - 03:43]
誰もがテストを好むわけではありません。 ほとんどの人はそうしません。

[03:41 - 03:46]
しかし、AI に

[03:43 - 03:48]
コードのテストを書いてもらうことは非常に重要です。 理想的には、

[03:46 - 03:50]
新しい機能が実装されるたびに、

[03:48 - 03:52]
一貫した出力が得られるようになります

[03:50 - 03:54]
。 また、リクエストは具体的にしてください

[03:52 - 03:55]
。 したがって、ここでは、

[03:54 - 03:57]
少しだけ追加のコンテキストを提供するほうが実際に適しています

[03:55 - 04:00]
。 したがって、

[03:57 - 04:02]
LLM に負担をかけたくない一方で、

[04:00 - 04:04]
LLM が独力で対処できないようにすることも望ましくありません。

[04:02 - 04:06]
何を探しているのかを非常に具体的にする必要があります

[04:04 - 04:07]
。 つまり、

[04:06 - 04:09]
構築したいものを高レベルで説明するだけでなく、

[04:11 - 04:15]
使用したいテクノロジー、さまざまなライブラリ、

[04:13 - 04:17]
出力をどのようにしたいかなどの詳細にまで踏み込んでください。

[04:15 - 04:19]
具体的に記述すると、非常に役立ちます。

[04:17 - 04:21]
そして、最後の 2 つのルールは、作業を

[04:19 - 04:23]
進めながらドキュメントとコメントを書くことです。

[04:21 - 04:25]
LLM には、

[04:23 - 04:27]
これらの

[04:25 - 04:30]
高レベルのコア ファイルだけでなく、

[04:27 - 04:32]
コード内のコメントも含めてドキュメントを継続的に更新してもらう必要があります。 これにより、

[04:30 - 04:34]
自分自身が何を

[04:32 - 04:37]
しているのか理解しやすくなり、また、

[04:34 - 04:39]
後の会話でこれらのファイルを参照するときにも役立ちます。 そして

[04:37 - 04:42]
最後に、

[04:39 - 04:44]
環境変数を自分で実装します。

[04:42 - 04:46]
API キーやデータベースのセキュリティ保護など、LLM に任せてはいけません。LLM の

[04:44 - 04:48]
ような

[04:48 - 04:51]
人になりたくないでしょうから。 本当に面白いと思ったので、ここにこのリンクを貼っておきます

[04:50 - 04:53]
。 これは、

[04:53 - 04:58]
バイブコードを実行すると深刻な問題が発生する可能性がある例です。 この人は、

[04:56 - 05:01]
完全な SAS を Cursor で構築しました。 彼は

[04:58 - 05:02]
コーディングを一切していないのに、

[05:01 - 05:04]
ここで大興奮しています。 今日は3月15日です。 彼はこう言います。「AIは

[05:02 - 05:06]
単なるアシスタントではありません。

[05:04 - 05:08]
今やAIはビルダーなのです。」 しかし、これを見てください。  2

[05:06 - 05:10]
日後、彼はハッキングされる。 ランダムな

[05:08 - 05:12]
ことが起こります。  API キーの使用量が最大限に達し

[05:10 - 05:14]
、人々がサブスクリプションをバイパスしていますが

[05:12 - 05:16]
、おそらく

[05:14 - 05:18]
データベースのセキュリティが適切でなかったことが原因です。

[05:16 - 05:20]
これらすべてがうまくいかなかったのは、彼が

[05:18 - 05:22]
環境

[05:20 - 05:25]
変数、データベースのセキュリティ、

[05:22 - 05:27]
セキュリティに関するすべてのものを AI に管理させていたからです。

[05:25 - 05:28]
自分自身が理解していることを確認する必要があります。 そして

[05:27 - 05:30]
実際、AI が生成するすべてのコードを理解する必要があります

[05:28 - 05:32]
。 一般的に、

[05:30 - 05:34]
バイブコーディングはお勧めしませんが、

[05:32 - 05:37]
バイブコーディングを行う場合であっても、少なくとも

[05:34 - 05:39]
プロジェクトが

[05:37 - 05:41]
安全かどうかを必ず理解してください。 それはとても重要です。

[05:39 - 05:43]
さて、これらの黄金律をすべて理解した上で

[05:41 - 05:44]
、

[05:43 - 05:46]
このドキュメントの残りの部分でもこれらを頻繁に見ていきますので、

[05:46 - 05:50]
計画から始めてプロジェクトを開始しましょう。 つまり、

[05:48 - 05:52]
計画段階ではかなりシンプルです。

[05:50 - 05:54]
計画ファイルとタスクファイルを作成したいだけです

[05:52 - 05:55]
。 そして、私たちはコーディングを始める前にこれを実行します。1

[05:58 - 06:02]
行のコードも書く前に、より高レベルの指示を得たいからです。 私たちの

[06:01 - 06:04]
計画文書には、LLM にコンテキストとして提供したい

[06:02 - 06:07]
高レベルのビジョン、アーキテクチャ、

[06:04 - 06:08]
制約、これらすべての

[06:07 - 06:11]
情報が記載されています

[06:08 - 06:13]
。 また、プロセス全体を通じて

[06:11 - 06:16]
AI コーディング アシスタントである LLM に

[06:13 - 06:18]
このファイルを参照するように依頼できます。

[06:16 - 06:20]
これは、

[06:18 - 06:22]
新しい会話の開始時に特に役立ち、

[06:22 - 06:25]
プロジェクトで行っているすべてのことを LLM がすぐに理解できるようになります。 したがって、

[06:25 - 06:29]
それを理解するためにさまざまなコード ファイルを分析する必要はありません。

[06:27 - 06:31]
そして、少し下のレベルには、

[06:29 - 06:34]
タスク マークダウン ファイルがあります。 ここで、

[06:31 - 06:36]
完了したタスクとまだ完了していないタスクをすべて追跡します

[06:34 - 06:38]
。 そして

[06:36 - 06:41]
会話全体を通して、

[06:38 - 06:43]
LLM を更新して新しいタスクを作成したり、

[06:41 - 06:45]
タスクを削除したり、タスクを完了としてマークしたり、

[06:43 - 06:48]
その他便利な機能をすべて実行できます。 これにより、

[06:45 - 06:50]
私たちは AI コーディング アシスタントのプロジェクト マネージャーになることができます。

[06:48 - 06:52]
これは、AI コーディング アシスタントが行う

[06:50 - 06:53]
すべてのことを指示したいため、重要です

[06:52 - 06:56]
。 これは、

[06:53 - 06:57]
私たちがそれをうまく行うためのリソースであり、

[06:56 - 07:00]
AI コーディング アシスタントもそのプロセスに役立ちます

[06:57 - 07:02]
。 そのため、これらのファイルを作成する場合

[07:00 - 07:05]
、通常は AI IDE でこれを行うことはありません

[07:02 - 07:07]
。 たとえば、Claw Desktop のようなチャットボットを使用します

[07:05 - 07:09]
。

[07:07 - 07:11]
ここに、作成する Superbase MCP サーバーのサンプル プロンプトがあります

[07:11 - 07:15]
。 そこで、MCP をコネクタとして使用します

[07:13 - 07:18]
。 そのため、Claw Desktop などのアプリや

[07:15 - 07:20]
独自の AI エージェントを使用して Superbase に接続し、

[07:20 - 07:25]
データベース内で処理を実行するツールを利用できるようになります。

[07:23 - 07:27]
そのための計画としては、Brave MCP サーバーをセットアップして

[07:25 - 07:29]
いるので、Brave API を使用するように指示するだけです

[07:27 - 07:31]
。 これ

[07:29 - 07:32]
については、

[07:32 - 07:37]
このビデオの範囲外なので、あまり詳しく説明しません。 これを例として使用して、

[07:37 - 07:43]
planning.md ファイルと task.md ファイルの両方を迅速に計画するように依頼します

[07:41 - 07:45]
。 そこでこのプロンプトを送信する

[07:43 - 07:48]
と、Web が検索されます。 そのため、これを

[07:45 - 07:50]
許可し、

[07:48 - 07:51]
両方のファイルが作成されたら戻ってきます

[07:50 - 07:53]
。 さあ、始めましょう。  Claw

[07:51 - 07:55]
デスクトップが両方のファイルを作成しました。 また、

[07:55 - 07:59]
そのための MCP サーバーも持っているため、ファイル システム内でそれが実行されました

[07:57 - 08:01]
。 つまり、彼はこのディレクトリに載っていることになります

[07:59 - 08:03]
。 これを Windsurf で開くと、

[08:01 - 08:05]
あらゆる AI コーディング アシスタントを使用できます

[08:03 - 08:07]
。 それを覚えておいてください。 私は

[08:05 - 08:09]
Windsurf を使用していますが、これは

[08:07 - 08:11]
カーソル クライアントのルート コードでも機能します。 それは問題ではありません

[08:09 - 08:13]
。 このプロセスはすべての人に適用されます。

[08:11 - 08:16]
ここに計画ファイルがあります。 それで、

[08:13 - 08:17]
ここでプレビューを開いて

[08:16 - 08:20]
これを確認する必要があります。 概要はわかりました

[08:17 - 08:22]
。 私たちは、プロジェクトの範囲、

[08:20 - 08:24]
技術アーキテクチャ、テクノロジー

[08:22 - 08:26]
スタックなどを把握しており、

[08:24 - 08:28]
AI コーディング

[08:26 - 08:29]
アシスタントがプロジェクトを開始するときに、これらすべてをコンテキストとして提供して、プロジェクトが

[08:28 - 08:31]
確実に正しい方向から開始されるようにすることができます

[08:29 - 08:33]
。 これは確かに

[08:31 - 08:36]
完璧な文書ではありません。 たとえば、

[08:33 - 08:37]
MCP とは何か、スーパーベースとは何かという

[08:36 - 08:39]
セクションは、本当に必要ありません。 私たちはそれについてはあまり気にしません

[08:37 - 08:40]
。 それで、私はこれをカメラの外で編集し

[08:39 - 08:42]
、退屈な

[08:40 - 08:43]
詳細はここでは省略することにします。 しかし、これは良い

[08:42 - 08:46]
出発点です。 そして、通常は、

[08:46 - 08:49]
チャットボット内、または

[08:47 - 08:50]
このファイルで作業している場所で、これを何度も繰り返すことになります。 そして私たちに

[08:49 - 08:52]
もタスクがあります。 これでプレビューを開くことができます

[08:50 - 08:54]
。 設定されたさまざまなタスクをすべて見ることができます

[08:52 - 08:56]
。

[08:54 - 08:58]
そして、AI コーディング アシスタントに

[08:56 - 09:00]
これらを 1 つずつ削除させ、必要に応じて新しいものも追加します

[08:58 - 09:02]
。 そしてこれは

[09:00 - 09:04]
かなりやり過ぎです。 したがって、もう一度、

[09:02 - 09:06]
これらのことを繰り返し実行する必要があります。

[09:04 - 09:09]
これにはそんなに多くのタスクは必要ありません。

[09:06 - 09:10]
これはかなりクレイジーだ。 うーん、でもそうですね、

[09:09 - 09:12]
これは良い出発点だと思います。

[09:12 - 09:15]
計画段階について最後にお伝えしたいヒントは、

[09:15 - 09:20]
Claude のように単一の LLM を使用するのではなく、複数の

[09:18 - 09:22]
異なる大規模言語モデルを使用して

[09:20 - 09:24]
プロジェクトの計画に役立てることです。 したがって、

[09:22 - 09:26]
それぞれに同じプロンプトを与え、

[09:24 - 09:27]
最後にすべてを組み合わせます。 ここで

[09:26 - 09:29]
重要なのは、複数のサブスクリプション料金を支払うことなく、

[09:29 - 09:32]
これらのさまざまな LLM を 1 か所で操作できる優れたプラットフォームを用意することです

[09:32 - 09:35]
。 そして、

[09:34 - 09:37]
そのためにはさまざまなアプリが存在します。 しかし、

[09:37 - 09:42]
このビデオのスポンサーであり、私がよく利用しているお気に入りの 1 つは

[09:39 - 09:43]
Global GPT です。

[09:42 - 09:46]
価格が非常に手頃だからです。  Deepseek、03、Claude などの最高の LLM すべてに無料でアクセスして始めることができます

[09:46 - 09:51]
。 さらに、

[09:51 - 09:55]
たとえば Deep Research や Perplexity などのツールも追加されています。

[09:54 - 09:57]
本当に綿密に

[09:55 - 09:59]
計画を立てたい場合は、Global GPT を利用できます

[09:57 - 10:00]
。 また、プロジェクトのアセットを計画するのに役立つ ideoggram や midjourney など、他のツールも多数あります

[10:02 - 10:05]
。

[10:04 - 10:07]
これらすべてを行うことができます。 つまり、

[10:07 - 10:12]
先ほど見たように、Claude Desktop と非常によく似たインターフェースが用意されますが、

[10:12 - 10:16]
さまざまな LLM に非常に簡単にアクセスして、

[10:14 - 10:18]
詳細な調査などを行うことができます。 ですから、

[10:20 - 10:24]
プロジェクトの計画を本当に深く掘り下げたい場合は、ぜひこのようなプラットフォームを使用してください。 そこで、

[10:22 - 10:26]
説明に Global GPT へのリンクを貼っておきます。

[10:24 - 10:27]
ぜひチェックしてみることをお勧めします。

[10:26 - 10:29]
はい、これはプロジェクトの

[10:27 - 10:31]
計画について私がお伝えしたい最後の簡単なヒントです

[10:29 - 10:33]
。 さて、次の段階に進みましょう

[10:31 - 10:35]
。 計画と

[10:33 - 10:38]
タスクが完了したので、次はグローバル ルールに移ります

[10:35 - 10:40]
。 これは基本的に、

[10:38 - 10:42]
AI コーディング アシスタントのシステム プロンプトです。

[10:40 - 10:44]
したがって、AI コーディング アシスタントに与える高レベルの指示はすべて

[10:44 - 10:49]
グローバル ルール内で実行されるため、

[10:49 - 10:53]
毎回明示的に入力する必要はありません。 たとえば、

[10:51 - 10:55]
グローバル ルールでは、

[10:53 - 10:57]
新しい会話の開始時に常に計画ファイルを読み取るように指定できます

[10:55 - 10:59]
。 そうすれば、私たち自身が会話を始めるときに、

[10:59 - 11:04]
明示的にそうするように依頼する必要がなくなります。 そのため、

[11:04 - 11:08]
さまざまなリクエストごとに大量の入力をする手間が省けます。「

[11:06 - 11:10]
これを実装して、

[11:08 - 11:12]
テストを書いて、タスクをチェックしてください」と言う代わりに、タスクを

[11:12 - 11:16]
チェックして、

[11:14 - 11:18]
すべての

[11:16 - 11:21]
新機能のテストを確実に記述するなどのグローバル ルールでそうするように指示するだけで済みます。 これらすべてが、

[11:18 - 11:23]
LLM への一種のシステム プロンプトとして利用できるようになりました。 これは、

[11:23 - 11:27]
AI コーディング アシスタントで設定したグローバル ルールです。 あなた自身でもこれを使えます

[11:25 - 11:28]
。

[11:27 - 11:30]
テクノロジースタックやその他の要件に応じて、ニーズに合わせて調整します

[11:28 - 11:31]
。

[11:30 - 11:32]
しかし、そうですね、これはあなたにとって本当に良い出発

[11:31 - 11:35]
点です。 さらに、

[11:32 - 11:39]
最も人気のある 4 つの

[11:35 - 11:41]
AI アイデアについて、これをセットアップする方法についての説明もあります。

[11:39 - 11:42]
それで具体的には、これをコピーします。

[11:44 - 11:49]
このビデオでは AI IDE である Windsurf を使用しているため、Windsurf でこれを行う方法を説明します。 これをコピーして、

[11:46 - 11:51]
Windsurf に移動し、

[11:51 - 11:56]
右上にある追加オプションをクリックしてメモリを管理すると、

[11:54 - 11:58]
グローバル ルールが表示されます。 これは、

[11:56 - 12:00]
どのディレクトリにいる場合でも適用されます

[11:58 - 12:02]
。そして、ワークスペース固有のルールがあります

[12:00 - 12:04]
。 したがって、現在のプロジェクトにのみルールを適用したい場合は

[12:02 - 12:06]
、ここで設定します

[12:04 - 12:08]
。 通常、

[12:06 - 12:10]
ワークスペース ルールを設定することをお勧めします。これは、使用するテクノロジーなどの

[12:08 - 12:12]
さまざまな要素がプロジェクト

[12:12 - 12:16]
に固有のものであることが多いためです

[12:14 - 12:18]
。 したがって、私は通常、

[12:16 - 12:20]
ワークスペースのルールを推奨します。

[12:18 - 12:22]
ここに進んで、Google ドキュメント

[12:20 - 12:24]
からコピーした内容をすべて貼り付けるだけです

[12:22 - 12:26]
。 そして、

[12:24 - 12:28]
他のマークダウン ファイルと同様に、

[12:26 - 12:30]
プレビューを開いて、

[12:28 - 12:32]
AI コーディング アシスタント用にこれらのルールが設定されていることを確認します

[12:30 - 12:34]
。 そこで、

[12:32 - 12:36]
これらのさまざまなマークダウン ファイルをどのように使用するかを指定します。 こうする

[12:34 - 12:39]
ことで、常に

[12:36 - 12:40]
計画を確認して

[12:39 - 12:42]
右側のプロンプトでタスクにマークを付けるように指示しなくても、

[12:40 - 12:44]
これらのファイルを操作する方法がわかるようになります

[12:42 - 12:45]
。 そして、500 行を超えるファイルを

[12:44 - 12:48]
作成しないなど、その他の黄金律についても伝えます

[12:45 - 12:50]
。

[12:48 - 12:52]
それぞれの機能のテストを作成する方法について説明します

[12:50 - 12:54]
。 ええと、そして生成されるコードがクリーンであることを確認

[12:52 - 12:56]
するために、スタイル ガイドラインもいくつか提供します

[12:56 - 13:00]
。 ドキュメントを

[12:58 - 13:02]
維持できるように、readme ファイルの操作方法を指定します

[13:00 - 13:04]
。 そして、下部には、

[13:04 - 13:08]
これを支援するためのさまざまなルールをいくつか用意しておくのが好きです。

[13:06 - 13:11]
これが私たちの全体的なルールです。 そして、

[13:08 - 13:13]
LLM へのプロンプトを非常にシンプルに保つことができるようになりました。LLM に実行させようとしている

[13:13 - 13:16]
さまざまな事柄があり、

[13:14 - 13:18]
それが確実に実行されているか確認しているからです。ただし、その

[13:16 - 13:19]
たびにプロンプ​​トを尋ねる必要はありません。 さて、

[13:18 - 13:21]
これがグローバルルールの重要な部分です

[13:19 - 13:23]
。 これで、グローバル ルールが

[13:21 - 13:24]
設定されました。

[13:23 - 13:27]
ほんの数分で済むはずです。 次に、

[13:24 - 13:29]
MCP サーバーの構成に進みます。 したがって、

[13:27 - 13:31]
MCP についてよく知らない場合は、

[13:32 - 13:37]
包括的な概要を説明した上記のリンク先のビデオを確認することを強くお勧めしますが、実際には、これは

[13:34 - 13:39]
AI IDE にさらに多くのツールを提供して、Brave で Web

[13:37 - 13:42]
検索などの操作を実行できるようにするための方法にすぎません

[13:39 - 13:43]
。 これらは

[13:42 - 13:46]
私がいつも使用しているコアとなる 3 つのサーバーです

[13:43 - 13:48]
。これについては後ほど詳しく説明します。 それぞれをインストールするためのリンクがあります

[13:46 - 13:50]
。

[13:50 - 13:55]
さまざまな AIDes で MCP を設定する方法についての説明と、

[13:52 - 13:56]
他の MCP サーバーのリストへのリンクもここにあります。

[13:55 - 13:58]
ここにアクセスして、他に含めたいものがあればダウンロードできます

[13:56 - 14:00]
。

[13:58 - 14:03]
これらのリンクのいずれかをクリックすると、

[14:00 - 14:05]
AI IDE 内での設定方法を詳しく確認できます

[14:03 - 14:07]
。 したがって、構成を設定するための手順が示されます

[14:05 - 14:10]
。 したがって、

[14:07 - 14:11]
私が常に使用するコアの 3 つのサーバーでは、

[14:10 - 14:14]
AI IDE が、

[14:14 - 14:19]
現在のプロジェクトだけでなく、コンピューター上の他のフォルダーを含むファイル システムとも対話できるようにする必要があります

[14:16 - 14:20]
。 たとえば、画像フォルダがあるかもしれません

[14:19 - 14:22]
。

[14:20 - 14:24]
そこからプロジェクトにアセットを引き込めるようにしたいのです。

[14:22 - 14:26]
または、他のプロジェクトを参照して、

[14:24 - 14:28]
以前に何かをどのように行ったかを確認したい場合もあります。

[14:28 - 14:33]
ファイル システム サーバーがあれば、これらすべてを実行できます。 そして、

[14:30 - 14:36]
AI IDE で Web 検索もできるようにしたいと考えています。

[14:33 - 14:39]
また、一部の AI アイデアには Web 検索が組み込まれています

[14:36 - 14:41]
。しかし、Brave API は、

[14:39 - 14:43]
実際に AI を内部で使用して

[14:43 - 14:47]
さまざまな Web 検索結果を要約するという点で非常に強力です。 したがって、

[14:45 - 14:48]
非常に強力な出力が得られます。

[14:47 - 14:51]
これを使用すると、使用している

[14:48 - 14:53]
ツール、ライブラリ、

[14:51 - 14:55]
フレームワークのドキュメントを取得するなどの操作を実行できます。

[14:53 - 14:57]
最後に、私が本当に使いたいのは

[14:55 - 14:59]
Git です。 その理由は、

[14:57 - 15:01]
すべてのプロジェクトを Git リポジトリとして設定する必要があるからです

[14:59 - 15:04]
。 つまり、バージョン管理が可能になるのです

[15:01 - 15:06]
。 プロジェクトのバックアップを管理し

[15:04 - 15:08]
、さまざまなバージョンを

[15:06 - 15:10]
すべて保存できます。 そして、Git MCP サーバーを使用すると、

[15:10 - 15:14]
ここに示したサンプル プロンプトのように、現在の状態に満足しているので、さらに

[15:15 - 15:19]
機能を実装する前に、

[15:17 - 15:21]
現在の状態をバックアップしておきたい、といったことを行うことができます。 したがって、

[15:19 - 15:23]
現在の状態を保存するには、git コミットを実行してください。

[15:21 - 15:25]
これは、

[15:27 - 15:31]
AI IDE に 5 件、10 件のリクエストを送信することもあるため、実行することを強くお勧めします。

[15:30 - 15:33]
これらすべてを実装すると、

[15:33 - 15:37]
5 つのリクエスト前にプロジェクトが完全に壊れていたことがわかります。 したがって、

[15:35 - 15:39]
途中でバックアップを取っていれば、

[15:37 - 15:41]
動作状態に戻すことができます。 そうしないと、

[15:41 - 15:45]
プロジェクトが完全に

[15:43 - 15:47]
壊れてしまい、行き過ぎて元に

[15:45 - 15:50]
戻れないという地獄の状態に陥ってしまうことがあります。 そこで Git が

[15:47 - 15:51]
救世主となるのです。 だからこそ、私は

[15:50 - 15:53]
このサーバーをとても愛用しているのです。

[15:51 - 15:55]
さらに、

[15:53 - 15:57]
長期記憶などが必要な場合は、AI IDE 内に rag を実装すると

[15:55 - 15:59]
、他のツールも多数あります

[15:57 - 16:01]
。 たとえば、Quadrant MCP

[15:59 - 16:04]
サーバー。

[16:01 - 16:06]
Windsurf のような多くの AI アイデアには

[16:04 - 16:08]
すでに記憶があるので、それについては触れません。

[16:06 - 16:09]
ここにアクセスして思い出を管理したり、

[16:08 - 16:11]
思い出を生成したりすることができます。

[16:09 - 16:12]
今はまだ白紙の状態ですが、プロジェクトやその他の間の思い出を記録するように依頼することができます

[16:12 - 16:16]
。 したがって、

[16:15 - 16:19]
このようなものは必要ないかも知れませんが、とにかく

[16:16 - 16:21]
素晴らしい MCP サーバーがまだ存在します。 それで、

[16:19 - 16:22]
これらすべてをセットアップしてください。 私の場合は、

[16:21 - 16:24]
ここで Windsurf に戻り、

[16:22 - 16:27]
設定を開きます。

[16:24 - 16:29]
ここで「MCP の構成」をクリックするだけです。 そして、

[16:27 - 16:32]
この MCP config.json があります。 そうですね、

[16:29 - 16:34]
ファイルシステム、Brave Search、

[16:32 - 16:36]
Git があり、また、

[16:34 - 16:38]
このビデオの範囲外ですが、

[16:38 - 16:42]
Windinsurf に組み込んだ AI エージェントビルダーである Archon もあります。 そこで私は

[16:40 - 16:45]
これらすべてのサーバーをセットアップしました。

[16:45 - 16:51]
この文書に記載されている手順に従ってください。 したがって、MCP を

[16:48 - 16:52]
セットアップし、私が説明したとおりにプロジェクト全体でそれを使用すると

[16:51 - 16:55]
、

[16:52 - 16:57]
大いに役立ちます。

[16:59 - 17:04]
MCP サーバーが構成され、グローバル ルールが

[17:02 - 17:06]
設定され、計画および

[17:04 - 17:08]
タスク ドキュメントが作成されたので、今度は AI IDE にプロジェクトを開始するための最初のプロンプトを出す必要があります。 ここで指摘したように

[17:06 - 17:10]
、AI に

[17:08 - 17:13]
高レベルの詳細を提供するドキュメントがあるにもかかわら

[17:10 - 17:15]
ず、

[17:13 - 17:18]
最初のプロンプトは非常に具体的にする必要があります。

[17:15 - 17:19]
それがプロジェクトの全体的な開始点を決定するためであり、私たちが

[17:21 - 17:24]
求めているものを非常に詳細に記述することが私たちの黄金律の 1 つだからです。

[17:23 - 17:27]
したがって、これはプロジェクトに応じてさまざまなことを意味する可能性があります

[17:24 - 17:29]
。 しかし、

[17:27 - 17:32]
ここで私がお伝えしたい重要なアドバイスは、

[17:32 - 17:36]
AI コーディング アシスタントに多くのドキュメントと例を提供することです。

[17:36 - 17:40]
例とドキュメントを提供する方法は 3 つあります。

[17:38 - 17:43]
1 つ目は、多くの AI アイデアにドキュメントを

[17:40 - 17:46]
取り込む機能が組み込まれていることです

[17:43 - 17:49]
。 たとえば、Windsurf では、

[17:46 - 17:51]
MCP に入力してから Tab キーを押すことができます。

[17:49 - 17:53]
これにより、

[17:51 - 17:55]
LLM へのプロンプトに MCP ドキュメントが含まれるようになります。

[17:53 - 17:58]
そのため、内部でラグを使用して

[17:55 - 18:00]
ドキュメントを検索し、それを使用して

[17:58 - 18:02]
回答を補強します。 カーソルなどの

[18:00 - 18:04]
他の AI アイデアでも、非常によく似たことを行うことができます

[18:02 - 18:08]
。 他のオプションとしては、

[18:04 - 18:10]
Brave MCP サーバー

[18:08 - 18:12]
または Web 検索用に設定したその他の MCP サーバーを使用する方法があります

[18:10 - 18:13]
。 したがって、

[18:12 - 18:15]
インターネットで、

[18:15 - 18:20]
使用しているライブラリやツールのドキュメントを探すように依頼することができます。たとえば、

[18:17 - 18:22]
Web で検索して、他の MCP サーバーの

[18:20 - 18:24]
実装やドキュメントを探すことができます。 したがって、

[18:22 - 18:26]
この方法で例とドキュメントを取得することも、スーパーベース MCP サーバーの作成に使用する

[18:24 - 18:28]
この例のプロンプトのように手動で提供することもできます

[18:29 - 18:34]
。 私は、Python MCP サーバーの既存の実装が

[18:32 - 18:37]
ある GitHub リポジトリへのリンクを提供するだけです

[18:37 - 18:42]
。 したがって、この

[18:40 - 18:44]
例は一種のドキュメントとして使用されており、

[18:44 - 18:48]
ここでは上部に MCP と superbase のドキュメントを呼び出しています。

[18:47 - 18:51]
これは、

[18:48 - 18:53]
私がここで作成しているものに非常に特化したサンプルプロンプトです

[18:51 - 18:54]
。 ただし、これは単なるテンプレートとして使用してください

[18:53 - 18:57]
。

[18:54 - 18:59]
ドキュメントを参照し、例を示し、

[18:57 - 19:01]
何を構築したいのかを非常に具体的に指定すると、

[19:03 - 19:08]
スーパーベースの MCP サーバーを構築するなどという非常に当たり障りのないことを言うよりもはるかに良い結果が得られます。

[19:06 - 19:10]
そこで、このプロンプトに従って、

[19:08 - 19:12]
Windsurf に進みます。 これはすでに

[19:10 - 19:13]
入力してあります。それでは、

[19:12 - 19:16]
これを送信して、リッピングする様子を見てみましょう

[19:13 - 19:18]
。 たとえば、このプロンプトのどこにも

[19:16 - 19:19]
planning.md ファイルを呼び出していません

[19:18 - 19:22]
。 ただし、MCP と Superbase のドキュメントを

[19:19 - 19:25]
取得した後も、そのドキュメントは参照されます

[19:28 - 19:33]
。これは、このワークスペースにのみ設定したプロジェクト レベルのルール、つまりグローバル ルールでそれが呼び出されているためです。

[19:31 - 19:35]
それで、まずは

[19:33 - 19:37]
私が示した GitHub の例を見てみます。

[19:35 - 19:40]
ドキュメントを確認中です。

[19:37 - 19:42]
Brave Web 検索を使用して、Superbase

[19:40 - 19:43]
Python クライアントのドキュメントを取得します。

[19:42 - 19:46]
ここでは多くのことが行われています。 そして、これは多くの

[19:43 - 19:48]
フローアクションを必要とします。 したがって、ここでは多くのクレジットが

[19:46 - 19:50]
費やされていますが、

[19:48 - 19:52]
できる限り最良の出発点を持つことが重要です。 ですから、

[19:50 - 19:54]
一般的には、

[19:52 - 19:57]
最初にかなりのことをやっても大丈夫です。 また、

[19:54 - 20:00]
いつでも、それほど多くのことを行わないように指示することができます。

[19:57 - 20:02]
ええと、

[20:02 - 20:05]
ここでこのドキュメントをすべて検索して、

[20:03 - 20:06]
次のステップに進んだら戻ってきます。

[20:05 - 20:08]
はい、これですべてのドキュメントの確認が終了しました

[20:06 - 20:10]
。 さて、それを見てください

[20:08 - 20:12]
。 ブーム。

[20:10 - 20:14]
計画ファイルとタスク ファイルの分析に移ります。 つまり、

[20:12 - 20:16]
すべての追加コンテキストを取り込んでいることになります。

[20:14 - 20:17]
そして、何らかの理由で、

[20:16 - 20:19]
ディレクトリを作成したいのだと思います。 はい、

[20:17 - 20:20]
すでにテストを書く予定です。

[20:19 - 20:22]
つまり、これは良いことです。 それは世界的なルールにも従っています

[20:20 - 20:24]
。 そこで、

[20:22 - 20:26]
そのディレクトリを作成できるようにします。 つまり、そこに

[20:24 - 20:28]
あります。 スーパーベースmcpests。

[20:26 - 20:30]
そして今、すべてをコーディングする段階に移っています

[20:28 - 20:32]
。 それで、それは requirements.ext から始まり

[20:30 - 20:33]
、それから

[20:32 - 20:35]
作成に入ると思います。はい、そうです。

[20:33 - 20:36]
server.py。 これには

[20:35 - 20:38]
かなりの量のコードが組み込まれるため、少し時間がかかります

[20:36 - 20:40]
。

[20:38 - 20:41]
ここで私がやろうとしていることは、一時停止して、

[20:41 - 20:45]
サーバーの最初の反復を実装したら戻ってくることです。 さあ、

[20:43 - 20:48]
始めましょう。  Windsurf は、

[20:45 - 20:50]
1 回のプロンプトで完全なスーパーベース MCP サーバーを作成しました

[20:48 - 20:52]
。 これは基本的な実装ではありません

[20:50 - 20:55]
。 コードはほぼ 300 行で

[20:52 - 20:58]
、見た目も非常に優れています。

[20:55 - 21:01]
レコードを削除したり、レコードを更新したり

[20:58 - 21:04]
、レコードを作成したりできます。 そして

[21:01 - 21:07]
最後に、テーブル内の行を読み取るツールがあります

[21:04 - 21:09]
。 これは、Windinsurf が MCP ドキュメントを理解していたことを如実に示しています

[21:09 - 21:12]
。

[21:11 - 21:15]
Superbase クライアントを設定し、

[21:12 - 21:17]
すべてのツールを定義する方法も同様です。 ドキュメントをよく読み

[21:15 - 21:19]
、それを

[21:17 - 21:21]
計画とタスクのマークダウン ファイルと統合して、

[21:19 - 21:23]
この美しいコードを作成しました

[21:21 - 21:25]
。 タスクの

[21:23 - 21:27]
マークダウン ファイルに移動すると、次のようになります。

[21:25 - 21:28]
タスクは完了としてマークされました。

[21:27 - 21:30]
テストも行われず、readme も更新されませんでしたが、

[21:28 - 21:32]
そうしてほしかったです。

[21:30 - 21:34]
テスト フォルダーは作成されましたが、

[21:32 - 21:35]
テストが書き込まれませんでした。これは少し奇妙です。

[21:34 - 21:37]
つまり、グローバル ルールは理解しているものの、期待どおりに動作しないという奇妙な動作が時々発生します

[21:38 - 21:41]
。 でも大丈夫です。

[21:40 - 21:42]
後続のプロンプトでそれを実行するので、すぐ

[21:41 - 21:44]
にお見せします

[21:42 - 21:46]
。 しかし、まずは実際にこれをテストして

[21:44 - 21:48]
、動作するかどうかを確認しましょう。 これで、

[21:46 - 21:51]
MCP サーバーがローカルに作成されました

[21:48 - 21:53]
。 ちなみに、MCP サーバーの作成に関する専用のビデオを作成したいと思っています

[21:53 - 21:56]
。 もし興味があればコメント欄でお知らせください

[21:54 - 21:57]
。

[21:59 - 22:03]
このビデオの目的は、MCP サーバーを

[22:01 - 22:06]
作成することではなく、AI を使用してコーディングするプロセスを示すことであるため、実装と実行については簡単に説明します

[22:03 - 22:08]
。 とにかく、

[22:06 - 22:10]
ここのクラウド デスクトップで、サーバーに接続します

[22:08 - 22:12]
。 左上の「

[22:10 - 22:14]
ファイル」、「設定」、「開発者」の順に進み、「

[22:12 - 22:17]
構成の編集」をクリックします。

[22:14 - 22:19]
構成フォルダーが開きます。  cloudmcpconfig.json にアクセスできます

[22:17 - 22:21]
。

[22:19 - 22:23]
ここで windsurf で開いている JSON ファイルです

[22:21 - 22:26]
。 ここで、

[22:23 - 22:28]
すべてのサーバーをクラウド デスクトップ専用に設定しています

[22:26 - 22:30]
。 そして、スーパーベースに追加するには、

[22:28 - 22:32]
ここにこの行を追加するか、

[22:34 - 22:37]
作成した仮想環境内の Python 実行可能ファイルにコマンドを追加します。 繰り返しますが、

[22:35 - 22:39]
これらの詳細はこのビデオではそれほど重要ではありません

[22:37 - 22:41]
。 サーバーの作成に関するフォローアップをやります

[22:39 - 22:43]
。 次に、

[22:43 - 22:47]
Windsurf が作成したサーバーを指す引数があります

[22:45 - 22:48]
。 そして私の環境では、

[22:47 - 22:51]
ここで編集した内容を渡しています

[22:48 - 22:54]
が、Superbase からの URL とサービス キーを渡しています

[22:51 - 22:55]
。 これで

[22:54 - 22:57]
、Cloud Desktop を再起動するだけです

[22:55 - 22:59]
。 次に、

[22:57 - 23:01]
利用可能な MCP ツールを開き、

[22:59 - 23:02]
最初の Superbase ツールまでスクロールします

[23:01 - 23:04]
。 はい、始めましょう。 テーブルレコードを作成します

[23:02 - 23:05]
。 これに加えて、

[23:04 - 23:07]
他に 3 つのツールがありますが

[23:05 - 23:08]
、ここにある

[23:07 - 23:10]
ツールのリストをスクロールすれば見つけることができます

[23:08 - 23:15]
。 そして、今では、ドキュメント メタデータ テーブル

[23:10 - 23:18]
にはどのようなレコードがあるかなどについて質問することができます

[23:15 - 23:20]
。 これは

[23:18 - 23:23]
私のチャンネルの別のビデオからのテーブルで、

[23:20 - 23:25]
N8N のぼろ布のものがいくつか入っています。 そして、

[23:23 - 23:27]
今度はスーパーベース ツールを呼び出します

[23:25 - 23:29]
。 このチャットを許可します。 はい、

[23:27 - 23:31]
プロンプトを 1 つ実行しました。

[23:29 - 23:34]
フォローアップのプロンプトについてはまだ何もしていません。

[23:31 - 23:37]
そしてこれを見てください。 この戦略

[23:34 - 23:39]
で、Windsurf を使って Superbase MCP サーバーを一撃で倒しました

[23:37 - 23:42]
。 そして、

[23:42 - 23:45]
私が持っているルールと、

[23:43 - 23:47]
例を示しながらドキュメントを検索するルールがなければ、これは不可能だったでしょう。

[23:45 - 23:50]
これらすべてが組み合わさって、これが可能になったのです

[23:47 - 23:52]
。 そして私は実際に

[23:50 - 23:54]
驚きました。 これは、oneot にとって大きな実装でした

[23:52 - 23:56]
。 そしてそれは

[23:54 - 23:58]
成功しました。 これらはまさに、Superbase の

[23:56 - 24:00]
このドキュメント メタデータ テーブルに保存されているレコードです

[23:58 - 24:02]
。

[24:00 - 24:05]
とても便利です。 さて、この時点で、

[24:02 - 24:07]
MCP サーバーの状態は良好で、

[24:05 - 24:08]
git を使用して保存する準備が整いました。 そのため、

[24:07 - 24:11]
将来的に

[24:11 - 24:15]
Readme を追加したり、サーバー

[24:13 - 24:17]
の機能を調整したり

[24:15 - 24:20]
、テストを追加したりする際に AI IDE が動作を中断させるような問題が発生した場合には、元の状態に戻すことができます。

[24:17 - 24:23]
ここで新しい会話に入り、

[24:20 - 24:27]
このプロジェクトの Git リポジトリを作成してコミットするように指示します

[24:23 - 24:30]
。 したがって、

[24:27 - 24:33]
git mcp サーバーを使用することも、

[24:35 - 24:39]
git リポジトリでの作業をサポートするネイティブ コマンドを備えたこれらの AI アイデアの多くを使用することもできます。 そして、

[24:37 - 24:40]
たとえばこの場合は、ツールを使用しようとしました

[24:39 - 24:42]
が、何らかの理由で失敗しました。 したがって、

[24:40 - 24:44]
今はターミナルで git status を使用するだけで

[24:42 - 24:46]
、これも機能します。

[24:44 - 24:48]
どちらでも使えます。 はい、

[24:48 - 24:51]
初期化された git リポジトリがあるようです。 先ほどこれを実行しようとしていました

[24:50 - 24:53]
。 以前に一度実行したので、

[24:51 - 24:55]
すでに git リポジトリが作成されています。 これで、

[24:53 - 24:56]
git が無視するようになりましたが、これは

[24:55 - 24:59]
良さそうです。 ぜひそれを実現したいですね。

[24:56 - 25:00]
そして今、get add コマンドを実行しています。

[24:59 - 25:03]
良さそうですね。 また、

[25:00 - 25:04]
これにも git mcp サーバーを使用できます。 うーん、でも

[25:03 - 25:07]
私はコマンドを使っているだけです。 そこでステータスを実行します

[25:04 - 25:09]
。 そして最後に

[25:07 - 25:11]
コミットを実行します。 それで、私たちはそこへ

[25:09 - 25:13]
行きます。 ブーム。 コミットします。 そして今、

[25:11 - 25:15]
私たちが持っているものはすべて保存されています。 そして、

[25:15 - 25:19]
何か問題が発生した場合には、後でこのコミットに戻すように要求することができます。

[25:17 - 25:22]
そして、私たちはこの現在の状態に移行したいと考えています

[25:19 - 25:25]
。 これで、

[25:22 - 25:27]
次のステップに進み、

[25:25 - 25:28]
テストを作成し、Readme の作成など、これまで実行できなかったいくつかの作業を実行します

[25:28 - 25:32]
。 ここで

[25:30 - 25:34]
メインのドキュメントに戻り、

[25:32 - 25:36]
ステップ 6 と 7 を

[25:34 - 25:38]
同時に実行します。 ステップ 6 では、

[25:38 - 25:42]
最初のプロンプトの後にプロジェクトを反復するとどうなるかについて説明します。

[25:42 - 25:47]
ここで取り上げられている重要なことは、

[25:45 - 25:51]
一度に 1 つの変更だけを求めるという黄金律です。

[25:47 - 25:53]
それについては良い例と非常に悪い例があります。

[25:51 - 25:56]
重要なのは、LLM に要求を詰め込み過ぎないことです

[25:53 - 25:57]
。

[25:56 - 25:59]
私たちの場合、

[25:57 - 26:01]
すぐに実装したいことがいくつかあります

[25:59 - 26:03]
。 何らかの理由で最初は作成されていなかったため、プロジェクト ドキュメントである Readme を作成したいと考えています

[26:03 - 26:06]
。 しかし、

[26:06 - 26:10]
すぐに実行したいもう 1 つのこと (これは

[26:08 - 26:12]
セクション 7 に直接つながります) は、

[26:12 - 26:17]
Superbase MCP サーバーの初期バージョンのテストを作成することです。

[26:15 - 26:20]
そこで、LLM に、サーバーで

[26:17 - 26:22]
作成されたツールごとに単体テストを作成するように依頼します

[26:20 - 26:24]
。

[26:22 - 26:25]
ここではテストのベストプラクティスについて概説しました。 これらは、

[26:25 - 26:30]
LLM に提供したいものであり、グローバル ルールで実行できます

[26:28 - 26:32]
。 グローバル ルールとして提供したこのテンプレートでは

[26:30 - 26:34]
、

[26:34 - 26:38]
テストのベスト プラクティスのセクションで説明したすべての内容を、

[26:36 - 26:40]
LLM 向けにここにリストしています。 したがって、

[26:40 - 26:43]
たとえばモッキングが何であるかを正確に理解する必要さえありません。 テスト専用のディレクトリを用意したいので、

[26:42 - 26:45]
これを LLM にルールとして渡すこともできます

[26:45 - 26:49]
。 私たちは

[26:47 - 26:51]
データベースと LLM への呼び出しを模擬したいのですが、

[26:51 - 26:55]
テストを高速かつ無料で行いたいため、実際には使用していません。 そして、

[26:53 - 26:57]
成功するシナリオもテストし

[26:55 - 26:59]
、テストでエラーが適切に処理されていることを確認します

[26:57 - 27:01]
。 そして

[26:59 - 27:03]
エッジケースも同様です。 したがって、

[27:01 - 27:06]
これらすべてをグローバル ルールとして組み込むことになります。

[27:03 - 27:08]
それで、Windsurf に戻ると、

[27:06 - 27:12]
新しい会話を開始して、

[27:08 - 27:14]
server.py のテストを作成するように要求し、

[27:14 - 27:19]
ここに既にあるテスト ディレクトリを呼び出すことができます

[27:17 - 27:21]
。 うーん、

[27:19 - 27:23]
ここにはディレクトリが多すぎるようです。 だから、

[27:21 - 27:25]
それを削除して、テストで言うと

[27:23 - 27:27]
、それで完了です。

[27:25 - 27:28]
ここではもっと明確に説明でき、おそらくさらに

[27:27 - 27:30]
いくつかの指示を提供すると役立つでしょうが、

[27:30 - 27:34]
グローバル ルールがあるため、

[27:34 - 27:40]
プロンプトで関連する操作を何も行わなくても、それらのベスト プラクティスに従うことになるということを覚えておいてください。

[27:37 - 27:42]
ですから、ここでは非常にシンプルにすることができます。 それで

[27:40 - 27:43]
、私がやろうとしていることは、最初のテストの作成が完了したら一時停止して戻ってくることです

[27:43 - 27:48]
。 さて、

[27:45 - 27:50]
windsurf がサーバーのすべてのテストを作成しました

[27:48 - 27:52]
。 そして、

[27:50 - 27:55]
当初は 12 個のテストが

[27:52 - 27:56]
合格し、その後 2 個が不合格になるという問題が発生しました。

[27:55 - 27:58]
そこで、

[27:56 - 28:00]
いくつかの

[27:58 - 28:02]
フォローアッププロンプトを付けて、少しだけ繰り返してみました。 しかし、その後は

[28:00 - 28:04]
正常に動作しています。 これで、

[28:02 - 28:06]
ターミナルで pi test コマンドを実行し

[28:04 - 28:08]
、

[28:06 - 28:11]
ルート ディレクトリからテスト フォルダーを参照できるようになりました

[28:08 - 28:14]
。 そして、この 14 のテストは

[28:11 - 28:17]
すべて合格しています。 それぞれの異なるツールについて、

[28:14 - 28:20]
成功、失敗、エッジケースのシナリオをテストしているため、14 になっています。

[28:20 - 28:23]
そして、

[28:23 - 28:26]
環境変数を使用して寿命をテストするなどの追加機能もいくつかあると思います

[28:25 - 28:29]
。 そしてこれは非常に

[28:26 - 28:32]
包括的です。 このファイルは

[28:29 - 28:34]
非常に大きく、コードが約 500 行あります。

[28:32 - 28:35]
通常、テスト ファイルは次の

[28:34 - 28:38]
ようになります。

[28:39 - 28:43]
さまざまなシナリオをすべてカバーしたいという理由だけで、ベース ファイル自体よりも長くなることがあります。 そうですね、

[28:41 - 28:45]
これらは本当にしっかりしたテストであり、

[28:43 - 28:47]
すべてがモック化されています。 これは美しいですね。

[28:45 - 28:49]
そしてこの時点で、

[28:47 - 28:51]
Superbase MCP サーバーの最初のバージョンが完成しました

[28:49 - 28:53]
。 うまくいっています。 クラウドデスクトップでテストしました

[28:51 - 28:55]
。 ユニットテストがあります。

[28:53 - 28:58]
すべて順調です。 これで、

[28:55 - 29:01]
希望どおりに反復処理に進むことができます。

[28:58 - 29:03]
Readme ファイルも作成できます。 その間、

[29:03 - 29:07]
タスクと計画マークダウン ファイルが最新の

[29:05 - 29:08]
状態に保たれていることを確認します。これは、

[29:08 - 29:12]
特に新しい会話を開始する場合に必要となる重要なコンテキストだからです

[29:10 - 29:14]
。 それから、

[29:14 - 29:18]
スーパーベース MCP サーバーで反復処理するために実行したいことが他にもたくさんあります。

[29:16 - 29:19]
ただし、

[29:18 - 29:21]
この時点で

[29:19 - 29:23]
このワークフロー全体をすでに実演しているので、カメラの外で実行します。

[29:21 - 29:25]
ここでの最後のステップは、

[29:23 - 29:27]
プロジェクトを展開することです。

[29:27 - 29:31]
構築したものを展開し、

[29:29 - 29:33]
パッケージ化してクラウドに送信し、

[29:31 - 29:35]
他の人と共有する状態になったら、AI コーディング アシスタントを使用して同じことを行うことができます

[29:33 - 29:37]
。

[29:35 - 29:39]
私が最も気に入っている方法は、

[29:37 - 29:42]
Docker や Podman などの類似のサービスを使用することです

[29:39 - 29:44]
。 そして最も素晴らしい点は、Docker が長年利用されてきたため、LLM は

[29:42 - 29:45]
Docker との連携が非常に優れていることです

[29:44 - 29:47]
。

[29:49 - 29:54]
LLM のトレーニングに使用された例はインターネット上にたくさんあります。 また、アプリケーションを

[29:51 - 29:57]
パッケージ化してデプロイするための Docker ファイルの作成を支援し、

[29:57 - 30:00]
使用するコマンドも提供します。

[29:58 - 30:02]
これは私が

[30:00 - 30:04]
ここに示してあるプロンプトの例です。 すべての Python 要件の requirements.ext ファイルを使用して、この MCP サーバー用の docker ファイルを作成するだけです

[30:06 - 30:09]
。

[30:07 - 30:11]
その後コンテナを構築するためのコマンドを教えてください。

[30:09 - 30:13]
そして私はすでにそれをやりました。 これが完了するまで

[30:11 - 30:15]
待つ詳細を説明して、皆さんを退屈させたくありませんでした

[30:13 - 30:17]
。 そこで、

[30:15 - 30:20]
MCP サーバーをパッケージ化するためにこの docker ファイルを作成しました

[30:17 - 30:22]
。 また、

[30:22 - 30:26]
一度に 1 つずつ覚えておく必要があるため、別のコマンドで readme も作成しました。

[30:24 - 30:28]
このreadmeも作成してもらいました。 したがって、すべてを

[30:26 - 30:30]
実行するための完全な手順が用意されています

[30:28 - 30:32]
。 ちなみに、git からインストールする場合は、

[30:30 - 30:33]
次の手順に従ってください。

[30:32 - 30:36]
これらの手順を

[30:33 - 30:38]
自分で実行すれば、このスーパーベース MCP

[30:36 - 30:40]
サーバーを自分で実行できます。これは本当に

[30:38 - 30:43]
すばらしいことです。 そこで、このビデオでは完全に機能する例を構築しました。

[30:40 - 30:45]
その後、コンテナーを構築し、

[30:45 - 30:50]
クラウド

[30:48 - 30:52]
デスクトップ内または Winds Surf のカーソル内で構成を設定できます。

[30:50 - 30:55]
これを構成例として使用するだけで、

[30:55 - 30:58]
開始するために必要なのはこれだけです。 これで

[30:56 - 31:00]
デプロイが完了し、文字通り

[30:58 - 31:02]
このリポジトリをクローンして、すべて自分で実行できるようになりました

[31:00 - 31:05]
。これが私たちの完全なプロセスです。 私たちは文字通り、

[31:02 - 31:08]
この文書を最初から最後まで読みました

[31:05 - 31:11]
。 アイデアの考案から

[31:08 - 31:13]
実装、テスト、ドキュメントの作成、

[31:11 - 31:16]
展開まですべて行います。 私たちがすべてを処理しました

[31:13 - 31:18]
。 それはかなり多かったです。

[31:16 - 31:19]
正直に言うと、このビデオの

[31:18 - 31:21]
準備と録画には非常に長い時間がかかりました

[31:19 - 31:24]
。 したがって、このプロセスが

[31:21 - 31:26]
あなたにとって非常に役立つことを願っています。 そうですね、別のビデオ

[31:26 - 31:30]
でさらに詳しく説明したい部分もあるかもしれません

[31:28 - 31:33]
。 また、

[31:30 - 31:35]
MCP

[31:33 - 31:36]
サーバーをゼロから構築し、

[31:35 - 31:37]
それについてさらに詳しく説明する完全なビデオを作成したいと思っています。 あなたもそれに興味があるなら、コメントで教えてください

[31:37 - 31:41]
。 したがって、このビデオが AI を使用したコーディングの

[31:39 - 31:43]
効率を大幅に高めるのに役立つことを願っています

[31:41 - 31:45]
。

[31:43 - 31:46]
あなたのプロセスがどの

[31:45 - 31:48]
ようなものか、ぜひコメント欄で教えてください。 すごく興味あります。

[31:46 - 31:50]
私が

[31:48 - 31:51]
やっていることにあなたが加えたいものがあるはずですし、あるいはあなた

[31:50 - 31:53]
にとって本当にうまく機能している他のものがあるかもしれません

[31:51 - 31:55]
。 それで、ぜひ聞きたいです。

[31:55 - 31:58]
これらの強力なツールを使用するための万能なアプローチは絶対に存在しません。

[31:58 - 32:01]
私にとってうまくいったことを共有したいと思っただけです。 したがって、このビデオを気に入っていただき

[32:00 - 32:04]
、

[32:01 - 32:05]
AI コーディングや AI エージェントに関するさらなる情報にご期待いただければ、

[32:04 - 32:07]
ぜひ「いいね」や

[32:05 - 32:10]
チャンネル登録をしていただければ幸いです。 それではまた

[32:07 - 32:10]
次回

## コメント

### 1. @ColeMedin (👍 37)
The waitlist is now OPEN for Dynamous AI Mastery - an exclusive community for early AI adopters like you to master AI & AI Agents and transform your career and business:

https://dynamous.ai

> **@Belzrox** (👍 1): Take me to the candy shop cole :) THE MAN! Appreciate you, on the right path...

> **@miselgpt** (👍 2): On it! Can't wait to see what you're cooking! 🧑‍🍳🤖

> **@Nairb932** (👍 0): id want to join the community but I'm a no coder brainlet D:

> **@MARTALIEINC** (👍 1): @@ColeMedin i signed up

> **@ErickJohnson-qx8tb** (👍 0): Can you do a video in the next steps using super base for services ad a fre lance so you can actually make $ Doa real video on that set up and 🎉

### 2. @-Monad- (👍 64)
This is the most thorough video on the actual nitty gritty of implementing this. Really appreciate you sharing this for free.

> **@ColeMedin** (👍 4): I'm glad, you bet!

### 3. @williamswartwood86 (👍 8)
Im a software architect and a lot of stuff youre doing here I just painfully figured out over months of suffering through failing and trying and repeating. I've been a dev for about 8 years now, over the past couple of years been mainly working in Python and React/JS/TS. This video is such a godsend for coders who are just starting to dabble in AI. Really AI should be a part of everyone's toolkit but man it really is muddying the waters of what makes a "developer". I am glad I got my career started before everyone and their mom started considering themselves a developer.

Just kinda rambling but you're a good dude, thank you for this video.

> **@ColeMedin** (👍 0): I agree every dev should be incorporating AI and I'm glad you think this is a good resource for that! I appreciate it a lot! It's my pleasure :)

> **@FragmentOfInfinity** (👍 0): As someone who is literally just a vibe coder who has always wanted to get into creating software but was terrified of the process and felt like my lack of knowledge was going to hold me back forever, AI has absolutely changed that for me. But these videos are amazing because they show a far more reliable and robust method and ironically teach me a lot of the processes I've been scared of haha

### 4. @cuvy500 (👍 20)
I really enjoy the "Global Rules" part.

Gj, Cole. 
(not April Fools' joke, btw)

- Cuvy Jet

> **@ColeMedin** (👍 1): Thanks man! I appreciate your constant support a ton!!

### 5. @gearscodeandfire (👍 10)
I used Cursor/Claude for the first time with a client server webrtc tonight. Your video should have been the first hit on the topic. You are so far ahead in this realm, great work

> **@ColeMedin** (👍 2): Thank you, that means a lot!

### 6. @mileshill4804 (👍 13)
Your effort, content, and clear instructions are greatly appreciated.

> **@ColeMedin** (👍 0): That means a lot, and thank you so much for your support!

### 7. @streamerfenwick6341 (👍 11)
This is the skill that will be needed for interviews in the Future.  I'm watching this again... and probably again.  Thanks again Cole

> **@ColeMedin** (👍 3): You know I've never thought about that but yeah I think you're right! You bet!

> **@Redeniush** (👍 0): We won't have jobs in the future if this keeps evolving, maybe 1% of the jobs we got right now

### 8. @guisantesconjamon (👍 2)
The video is excellent. I had some of the rules that you propose in my setup just by using intuition, but the way that you cover the whole process is  just too good. Thanks a lot!!

> **@ColeMedin** (👍 0): I appreciate it a lot! You bet :)

### 9. @SolidBuildersInc (👍 6)
Hey Cole,

This is hands down the best video I’ve come across for working with AI. The reason is that I always like to think as **RAD** as possible.  

Before AI, you might have set up a control sheet to feed f-strings into the code, creating a sort of funnel workflow for variables to avoid hardcoding. But the idea of templatizing prompts for efficient AI execution is truly a gem, and I deeply appreciate it.  

I once had AI generate a batch file for building Docker images—it was decent—but this approach is far more comprehensive. It serves as an excellent launchpad for fine-tuning future projects.  

Much appreciated, and thanks again!  

Tip:  When trying to copy a large bit of text, click at the start of your desired copy then keeping the focus on that start point go to the end of the copy location.  Hit the shift key and click to grab that section of data.  Instead of scrolling with the mouse key the whole section of data.  Comes in handy for me all the time.  It's the least I can offer for all of your contribution, 🚀

> **@ColeMedin** (👍 1): That means a lot, thank you! You are very welcome and I appreciate the tip too!

### 10. @TyMcAuley (👍 3)
Great video.  I’ve been playing with a bunch of coding assistants to see what’s possible and applying a bunch of these practices prior to seeing this video.  Great summary of how to get the most out of AI coding assistants!

### 11. @samuraiJ51 (👍 18)
Only 5 min and this is gold. Through a lot of my own experimentation I’ve learned how important having a framework and learning how to get the best results from LLMs makes all the difference. Keep it up.

> **@ColeMedin** (👍 0): I appreciate it a lot!

### 12. @MichelHabib (👍 4)
It is amazing that watching this, 80% of the rules you stated, I already learned them by using the tools for a few weeks, myself. Its just that nobody talks about them, and 99% of the tutorials online convince you that you can make a full app with one prompt, and make a snake game or flappy bird!!! Thanks for giving me confidence in my approach 😊

> **@ColeMedin** (👍 1): I appreciate it a lot. You bet!!

### 13. @michaelsaia4381 (👍 1)
Dude I've been using these IDEs since like October and have come to a lot of these ideas on my own but I still learned a ton and love some of the conventions you've got here. There's no official "best practice" yet and this migh tbe the closest thing to it.

> **@ColeMedin** (👍 0): I'm glad you got a lot out of this! I appreciate it!

### 14. @quickit (👍 5)
Just wanted to say thanks for this awesome video and that I would be very interested in a video on building custom MCP servers from scratch, all the way to making them deployable if that would make sense in the context. But either way, just any custom MCP server video 🙌

> **@ColeMedin** (👍 0): Thank you so much for your support! You are very welcome and my video I just put out covers the core of building MCP servers!

### 15. @RetiredVet1 (👍 6)
A few days ago, I created my first AI coding project.  It includes fastapi and python.  It is going pretty well, but then I had problems with simple things like changing link colors and changing functionality.  

I was just beginning to troubleshoot the problem, and I ran across this video and in the first few minutes it talked about the kinds of issues I ran into and had just started to try and solve.
I look forward to watching the entire video and have already downloaded the document for reference.
Thanks for this timely video.

> **@ColeMedin** (👍 0): Really glad I could help! You bet!!

### 16. @MrSchirtzinger (👍 15)
Yes please to the MCP deep dive video! Excited about Dynamous

> **@ColeMedin** (👍 6): MCP server deep dive coming soon! I appreciate it!

### 17. @PlectrumShorts (👍 6)
Great video and the AI Coding Process doc is gold. I’ve stumbled onto a few of the rules through trial and error. Short files, fresh conversations, and one task per message. But the PLANNING and TASK files are brilliant (as is the rest of it, really). This is going to have a huge impact on my projects!

> **@ColeMedin** (👍 1): Thanks man! I'm really glad this is going to help you out!

### 18. @daicameron6454 (👍 5)
Thanks for the high value content!

> **@ColeMedin** (👍 1): You bet - thank you so much for your support!

### 19. @MhmdJmri-ui5iu (👍 2)
This is the BEST video EVER on AI coding

### 20. @dizthewize (👍 2)
This is definitely the most informative AI starter tutorial I’ve watched, thanks! 🙌🏾

> **@ColeMedin** (👍 0): That means a lot - thank you very much! :D

