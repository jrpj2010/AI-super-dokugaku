<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Face Detection Test - MediaPipe</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }
        h1 {
            color: #333;
            text-align: center;
        }
        .container {
            display: flex;
            gap: 20px;
            margin-top: 20px;
        }
        .video-section, .log-section {
            flex: 1;
            background: white;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        #videoContainer {
            position: relative;
            width: 100%;
            max-width: 640px;
            margin: 0 auto;
        }
        #inputVideo, #outputCanvas {
            width: 100%;
            height: auto;
            display: block;
            border: 1px solid #ddd;
            border-radius: 4px;
        }
        #outputCanvas {
            position: absolute;
            top: 0;
            left: 0;
        }
        #startButton {
            display: block;
            width: 100%;
            padding: 10px;
            margin: 10px 0;
            background-color: #4CAF50;
            color: white;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            font-size: 16px;
        }
        #startButton:hover {
            background-color: #45a049;
        }
        #startButton:disabled {
            background-color: #ccc;
            cursor: not-allowed;
        }
        #logs {
            height: 400px;
            overflow-y: auto;
            border: 1px solid #ddd;
            padding: 10px;
            font-family: monospace;
            font-size: 12px;
            background-color: #f9f9f9;
            border-radius: 4px;
        }
        .log-entry {
            margin-bottom: 5px;
            padding: 5px;
            border-radius: 3px;
        }
        .log-success {
            background-color: #d4edda;
            color: #155724;
        }
        .log-error {
            background-color: #f8d7da;
            color: #721c24;
        }
        .log-info {
            background-color: #d1ecf1;
            color: #0c5460;
        }
        .stats {
            margin-top: 10px;
            padding: 10px;
            background-color: #e9ecef;
            border-radius: 4px;
        }
        .hidden {
            display: none;
        }
    </style>
</head>
<body>
    <h1>MediaPipe Face Detection Test</h1>
    
    <div class="container">
        <div class="video-section">
            <h2>カメラ映像</h2>
            <div id="videoContainer">
                <video id="inputVideo" autoplay muted></video>
                <canvas id="outputCanvas"></canvas>
            </div>
            <button id="startButton">カメラを開始</button>
            <div id="stats" class="stats hidden">
                <p>FPS: <span id="fps">0</span></p>
                <p>検出された顔: <span id="faceCount">0</span></p>
                <p>ランドマーク数: <span id="landmarkCount">0</span></p>
            </div>
        </div>
        
        <div class="log-section">
            <h2>ログ</h2>
            <div id="logs"></div>
        </div>
    </div>

    <!-- MediaPipe Scripts -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh@0.4/face_mesh.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils@0.3/camera_utils.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils@0.3/drawing_utils.js" crossorigin="anonymous"></script>

    <script>
        const videoElement = document.getElementById('inputVideo');
        const canvasElement = document.getElementById('outputCanvas');
        const canvasCtx = canvasElement.getContext('2d');
        const startButton = document.getElementById('startButton');
        const logsDiv = document.getElementById('logs');
        const statsDiv = document.getElementById('stats');
        const fpsSpan = document.getElementById('fps');
        const faceCountSpan = document.getElementById('faceCount');
        const landmarkCountSpan = document.getElementById('landmarkCount');

        let camera = null;
        let lastTime = performance.now();
        let frameCount = 0;

        function addLog(message, type = 'info') {
            const logEntry = document.createElement('div');
            logEntry.className = `log-entry log-${type}`;
            const timestamp = new Date().toLocaleTimeString();
            logEntry.textContent = `[${timestamp}] ${message}`;
            logsDiv.insertBefore(logEntry, logsDiv.firstChild);
            
            // 最大100件のログを保持
            while (logsDiv.children.length > 100) {
                logsDiv.removeChild(logsDiv.lastChild);
            }
        }

        function onResults(results) {
            // FPS計算
            frameCount++;
            const currentTime = performance.now();
            if (currentTime - lastTime >= 1000) {
                const fps = Math.round(frameCount * 1000 / (currentTime - lastTime));
                fpsSpan.textContent = fps;
                frameCount = 0;
                lastTime = currentTime;
            }

            // Canvas設定
            canvasElement.width = videoElement.videoWidth;
            canvasElement.height = videoElement.videoHeight;
            canvasCtx.save();
            canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);

            // 検出結果の描画
            if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {
                const faceCount = results.multiFaceLandmarks.length;
                faceCountSpan.textContent = faceCount;
                
                results.multiFaceLandmarks.forEach((landmarks, index) => {
                    landmarkCountSpan.textContent = landmarks.length;
                    
                    // 顔のメッシュを描画
                    drawConnectors(canvasCtx, landmarks, FACEMESH_TESSELATION,
                        {color: '#C0C0C070', lineWidth: 1});
                    drawConnectors(canvasCtx, landmarks, FACEMESH_RIGHT_EYE,
                        {color: '#FF3030'});
                    drawConnectors(canvasCtx, landmarks, FACEMESH_RIGHT_EYEBROW,
                        {color: '#FF3030'});
                    drawConnectors(canvasCtx, landmarks, FACEMESH_RIGHT_IRIS,
                        {color: '#FF3030'});
                    drawConnectors(canvasCtx, landmarks, FACEMESH_LEFT_EYE,
                        {color: '#30FF30'});
                    drawConnectors(canvasCtx, landmarks, FACEMESH_LEFT_EYEBROW,
                        {color: '#30FF30'});
                    drawConnectors(canvasCtx, landmarks, FACEMESH_LEFT_IRIS,
                        {color: '#30FF30'});
                    drawConnectors(canvasCtx, landmarks, FACEMESH_FACE_OVAL,
                        {color: '#E0E0E0'});
                    drawConnectors(canvasCtx, landmarks, FACEMESH_LIPS,
                        {color: '#E0E0E0'});
                    
                    // ランドマークポイントを描画
                    drawLandmarks(canvasCtx, landmarks,
                        {color: '#FF0000', lineWidth: 1, radius: 2});
                });
                
                if (frameCount % 30 === 0) { // 30フレームごとにログ
                    addLog(`${faceCount}個の顔を検出中 (${landmarks.length}個のランドマーク)`, 'success');
                }
            } else {
                faceCountSpan.textContent = '0';
                landmarkCountSpan.textContent = '0';
                if (frameCount % 60 === 0) { // 60フレームごとにログ
                    addLog('顔が検出されていません', 'info');
                }
            }

            canvasCtx.restore();
        }

        const faceMesh = new FaceMesh({
            locateFile: (file) => {
                addLog(`MediaPipeファイルを読み込み中: ${file}`, 'info');
                return `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh@0.4/${file}`;
            }
        });

        faceMesh.setOptions({
            maxNumFaces: 4,
            refineLandmarks: true,
            minDetectionConfidence: 0.5,
            minTrackingConfidence: 0.5
        });

        faceMesh.onResults(onResults);

        startButton.addEventListener('click', async () => {
            if (camera) {
                addLog('カメラを停止します', 'info');
                camera.stop();
                camera = null;
                startButton.textContent = 'カメラを開始';
                statsDiv.classList.add('hidden');
                canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
                return;
            }

            try {
                addLog('カメラアクセスを要求中...', 'info');
                startButton.disabled = true;
                
                // MediaPipe Cameraの初期化
                camera = new Camera(videoElement, {
                    onFrame: async () => {
                        await faceMesh.send({image: videoElement});
                    },
                    width: 640,
                    height: 480
                });
                
                await camera.start();
                
                addLog('カメラが正常に開始されました', 'success');
                addLog('顔検出を開始します', 'success');
                startButton.textContent = 'カメラを停止';
                startButton.disabled = false;
                statsDiv.classList.remove('hidden');
                
            } catch (error) {
                addLog(`カメラエラー: ${error.message}`, 'error');
                console.error('Camera error:', error);
                startButton.disabled = false;
            }
        });

        // 初期ログ
        addLog('MediaPipe Face Detection テストページが読み込まれました', 'success');
        addLog('「カメラを開始」ボタンをクリックしてテストを開始してください', 'info');
    </script>
</body>
</html>