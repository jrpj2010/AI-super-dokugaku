1
00:00.686 --> 00:11.236
はい、ということで何回目かわかりません。バージョン0.0.15で最終フィニッシュにしたいところですが、皆さんいかがお過ごしでしょうか。

2
00:11.756 --> 00:20.146
7月5日地震説というものがあるらしく、とか法則ということらしいです。来ないことを祈りますが、用心しましょう。

3
00:21.016 --> 00:36.196
何でもとから列島を近海の地震が2000年から今日に至るまで、やたらと回数を記録した時に大地震が見舞われるというようなことらしく、

4
00:37.336 --> 00:51.986
古くは鳥取の地震、東日本大震災、茨城北部の大震災、もろもろ言い当ててるということで、用心しましょうという話になってるらしいです。

5
00:53.076 --> 01:08.316
どういうことか分かりませんが、とにかく今の直近で300回以上のプチ地震が多発しており、そこから出てくるとからの法則というものが危惧されているということであります。

6
01:09.586 --> 01:28.096
さあ、いかがでしょうか?私からのこのようなお話をボイスメモという形で取ることで、音声メモがですね、生きてくるということで

7
01:29.176 --> 01:32.446
大変便利に使えるのではないかなという風に期待しております。

8
01:33.866 --> 01:47.886
これより音声をですね、ちょっと耐久テストもしないといけないので、ま、長時間喋り倒すことでもちゃんと耐えうるのかどうか、途中で止まったりするのかどうかっていうことも含めて、見ていきたいという風に思っております。

9
01:48.726 --> 01:55.206
さ、実際にはですね、もうまもなく書籍の方の最終章になるわけですが、

10
01:55.836 --> 02:06.666
その中でどこまでAIを使ってですね、ま、しっかりできるかっていうところを色々やってる最中でございますが、

11
02:08.576 --> 02:11.416
台本なくダラダラと話しております。

12
02:11.756 --> 02:22.516
さあ、どうでしょうか?いかがでしょうか?といった、あーといったところはフィラーが入りますが、それらも全て自動で除去する。そして

13
02:22.956 --> 02:35.856
専門用語でですね、Cursorや、ま、Obsidianといった専門用語、GeminiやOpenAIなどといった単語に関しては単語帳を、AIが全て持っていますんで、

14
02:36.166 --> 02:46.336
その自動変換により、より明確に、より正しい用語のところに自動変換されるという形の物になってます。

15
02:47.386 --> 02:58.116
しかもワイヤレスマイクにちゃんと対応できておりますので、パソコンに繋げたワイヤレスマイクから音声をとり、PCから離れてもですね、

16
02:58.646 --> 03:05.486
インタビューの時とかも最適なんじゃないかなと思います。画面上見た上で、対応が取れるというような状態であります。

17
03:06.326 --> 03:26.546
あまりそんなに長時間、それこそ1時間ぶん回すなんていうことの想定はあまりしてませんで、ま、ざっくり10分程度のですね、内容がちゃんと取れて、処理がですね、現実的な速さで、それができれば、最良なんではないかなというふに思っております。

18
03:27.236 --> 03:39.196
話者分離も入れたいんですが、ま、いけてるちょっとロジックはなんかあるのかな?まだ調べ尽くしてないんですけど、ま、話者分離のロジック入れるならば、ちょっと調べてみましょうか。

19
03:39.586 --> 03:56.126
話者分離世界最高峰世界最高峰の、手法や論文があれば教えてください。

20
03:57.426 --> 04:15.936
あくまで、AIが再現AIが再現できる手法で徹底的に調査してください。

21
04:17.386 --> 04:39.736
こんな感じでですね、話者分離の方法が完璧にあればスピーカーから入ってきた、単独の音声に対してどうしましょうかね。音の強弱、そういったものも含めて、ある程度見れるようにしてほしいかなと思っております。

22
04:43.256 --> 04:45.926
さあ、

23
04:46.336 --> 04:47.366
どうでしょうか?

24
04:48.426 --> 04:58.336
さあ、AIのね、答えは世界最高峰の、話者分離の方法は、はい、来ました。

25
04:59.206 --> 05:09.916
カクテルパーティー問題としても知られており、この分野特に深層学習の導入によりここ数年で劇的な進歩を遂げています。

26
05:09.916 --> 05:23.716
本稿では、伝統的なアプローチから深層学習による革命的なブレイクスルー、そして現在の最先端State of the Art、ソタ技術までを体系的に解説します。

27
05:23.996 --> 05:29.216
話者分離の基礎と伝統的なアプローチにおいては、ピッチベースの手法。

28
05:29.216 --> 05:45.196
話者の声の高さやそのバイオン構造、ハーモニクスが話者ごとに異なることを利用する手法が元々デファクトとして叫ばれている使い方、作り方になります。

29
05:45.926 --> 06:01.326
強い方の話者のピッチにし停止そのハーモニクスを強調することでその話者の音声を復元し、残りの信号から弱い方の話者の音声を抽出することで、判別ができるということでした。

30
06:02.056 --> 06:17.906
そういうちょっと細かいことは分からないですが、現在の最新最高峰でいくと、TFドメインモデルの再評価ということで、

31
06:17.906 --> 06:26.116
エンドトゥエンドの時間領域モデルが主流となりつつ一方で、TFドメインのモデルも進化をし続けており、現在最高の性能を競っています。

32
06:26.806 --> 06:52.016
TFグリッドネットこのモデルはフレーム内、周波数軸、サブバンド、フルバンドの情報を統合的に扱うための複数処理パスを持つ深層ニューラルネットワークだということで、複素スペクトルマッピングを採用し、WSJ0-2mixという標準的なデータセットで、ソタを達成しました。

33
06:52.546 --> 07:00.676
雑音や、残響にも非常に堅形頑健であることが示されているということです。

34
07:01.276 --> 07:17.806
自己注意機構を用いてTF領域における大域的、クロスバンド、ナローバンドの相関関係を捉えるモデルで、長い音声に対する性能劣化を防ぐ工夫も導入されており、こちらもソタ級の性能を誇ります。

35
07:18.966 --> 07:27.766
マルチチャンネル話者分離、空間情報の活用。複数のマイクを用いて録音された音声では話者の位置情報を一意できます。

36
07:28.466 --> 07:32.486
そらそうなんだがモノラルで見ないといけないから、

37
07:34.786 --> 07:42.336
混合音声からアトラクタと呼ばれる各話者を代表するベクトルを動的に生成します。

38
07:51.276 --> 07:59.046
すなわち何で取ればいいのかっていうことはよくわかんないけど、

39
08:00.756 --> 08:33.726
そしたら、あくまで、単独のマイクでとり、単独の音声をざっくり例えばMP3やWAVのファイルを取得して、その単独ファイルからGeminiやOpenAIやClaudeなどを使って、LLMの中から判別できる話者分離の方法を策定してみてください。

40
08:35.806 --> 08:56.366
どういう指示プロンプトによればより成功で、より柔軟な話者分離ができるかを、当社のエンジニアに対する指示文書という形で文章をまとめてください。

41
08:56.916 --> 08:59.626
コードブロックの中にまとめて書いてください。

42
10:07.989 --> 10:12.799
振り返ればそんな感じで話者分離ができるんではないかと思います。

43
10:12.799 --> 10:18.829
どうでしょうか?10分間ほど喋りました。それではこれでいきたいと思います。
